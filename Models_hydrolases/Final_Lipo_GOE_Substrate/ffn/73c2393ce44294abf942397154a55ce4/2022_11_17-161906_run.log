2022-11-18 02:41:28,769 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/73c2393ce44294abf942397154a55ce4/2022_11_17-161906",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "cat",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-18 02:41:28,777 INFO: Starting stage: BUILD FEATURIZERS
2022-11-18 02:41:28,780 INFO:   Creating esm representation model
2022-11-18 02:41:28,780 INFO:   Done esm representation model
2022-11-18 02:41:28,780 INFO: Done with stage: BUILD FEATURIZERS
2022-11-18 02:41:28,780 INFO: Starting stage: BUILDING DATASET
2022-11-18 02:41:28,837 INFO: Done with stage: BUILDING DATASET
2022-11-18 02:41:28,837 INFO: Starting stage: FEATURIZING DATA
2022-11-18 02:41:28,837 INFO:   Featurizing proteins
2022-11-18 02:41:28,839 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-18 02:41:28,855 INFO:   Loaded feature cache of size 204
2022-11-18 02:41:28,856 INFO:   Starting to pool ESM Embeddings
2022-11-18 02:41:28,963 INFO:   Featurizing molecules
2022-11-18 02:41:29,347 INFO: Done with stage: FEATURIZING DATA
2022-11-18 02:41:29,348 INFO: Starting stage: RUNNING SPLITS
2022-11-18 02:41:29,356 INFO:   Leaving out SEQ value Fold_0
2022-11-18 02:41:29,371 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:41:29,371 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:41:30,071 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:41:30,071 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:41:30,139 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:41:30,139 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:41:30,139 INFO:     No hyperparam tuning for this model
2022-11-18 02:41:30,139 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:41:30,139 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:41:30,140 INFO:     None feature selector for col prot
2022-11-18 02:41:30,140 INFO:     None feature selector for col prot
2022-11-18 02:41:30,141 INFO:     None feature selector for col prot
2022-11-18 02:41:30,141 INFO:     None feature selector for col chem
2022-11-18 02:41:30,141 INFO:     None feature selector for col chem
2022-11-18 02:41:30,142 INFO:     None feature selector for col chem
2022-11-18 02:41:30,142 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:41:30,142 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:41:30,143 INFO:     Number of params in model 168571
2022-11-18 02:41:30,144 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:41:30,144 INFO:   Starting stage: TRAINING
2022-11-18 02:41:31,739 INFO:     Val loss before train {'Reaction outcome loss': 1.040992704934852, 'Total loss': 1.040992704934852}
2022-11-18 02:41:31,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:31,739 INFO:     Epoch: 0
2022-11-18 02:41:32,520 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9101229829843654, 'Total loss': 0.9101229829843654} | train loss {'Reaction outcome loss': 0.8565406199605738, 'Total loss': 0.8565406199605738}
2022-11-18 02:41:32,521 INFO:     Found new best model at epoch 0
2022-11-18 02:41:32,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:32,522 INFO:     Epoch: 1
2022-11-18 02:41:33,269 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8798893676247708, 'Total loss': 0.8798893676247708} | train loss {'Reaction outcome loss': 0.8311631658770999, 'Total loss': 0.8311631658770999}
2022-11-18 02:41:33,269 INFO:     Found new best model at epoch 1
2022-11-18 02:41:33,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:33,270 INFO:     Epoch: 2
2022-11-18 02:41:34,049 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8897013768207195, 'Total loss': 0.8897013768207195} | train loss {'Reaction outcome loss': 0.8245014001111515, 'Total loss': 0.8245014001111515}
2022-11-18 02:41:34,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:34,049 INFO:     Epoch: 3
2022-11-18 02:41:34,822 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.9004873979923337, 'Total loss': 0.9004873979923337} | train loss {'Reaction outcome loss': 0.8171242714905348, 'Total loss': 0.8171242714905348}
2022-11-18 02:41:34,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:34,822 INFO:     Epoch: 4
2022-11-18 02:41:35,569 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9021892852561418, 'Total loss': 0.9021892852561418} | train loss {'Reaction outcome loss': 0.8146498663747896, 'Total loss': 0.8146498663747896}
2022-11-18 02:41:35,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:35,569 INFO:     Epoch: 5
2022-11-18 02:41:36,335 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8704651614954305, 'Total loss': 0.8704651614954305} | train loss {'Reaction outcome loss': 0.8163773936570667, 'Total loss': 0.8163773936570667}
2022-11-18 02:41:36,335 INFO:     Found new best model at epoch 5
2022-11-18 02:41:36,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:36,336 INFO:     Epoch: 6
2022-11-18 02:41:37,105 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.870788037776947, 'Total loss': 0.870788037776947} | train loss {'Reaction outcome loss': 0.8076535895711086, 'Total loss': 0.8076535895711086}
2022-11-18 02:41:37,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:37,105 INFO:     Epoch: 7
2022-11-18 02:41:37,892 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8771223481311354, 'Total loss': 0.8771223481311354} | train loss {'Reaction outcome loss': 0.8074341412694728, 'Total loss': 0.8074341412694728}
2022-11-18 02:41:37,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:37,892 INFO:     Epoch: 8
2022-11-18 02:41:38,633 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8568779590517975, 'Total loss': 0.8568779590517975} | train loss {'Reaction outcome loss': 0.8128053763362227, 'Total loss': 0.8128053763362227}
2022-11-18 02:41:38,634 INFO:     Found new best model at epoch 8
2022-11-18 02:41:38,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:38,635 INFO:     Epoch: 9
2022-11-18 02:41:39,419 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8726382435754289, 'Total loss': 0.8726382435754289} | train loss {'Reaction outcome loss': 0.807288935927094, 'Total loss': 0.807288935927094}
2022-11-18 02:41:39,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:39,420 INFO:     Epoch: 10
2022-11-18 02:41:40,179 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8708170389020166, 'Total loss': 0.8708170389020166} | train loss {'Reaction outcome loss': 0.8030895241459862, 'Total loss': 0.8030895241459862}
2022-11-18 02:41:40,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:40,180 INFO:     Epoch: 11
2022-11-18 02:41:40,935 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8682808626529782, 'Total loss': 0.8682808626529782} | train loss {'Reaction outcome loss': 0.8067944087698812, 'Total loss': 0.8067944087698812}
2022-11-18 02:41:40,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:40,935 INFO:     Epoch: 12
2022-11-18 02:41:41,719 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8484476340371508, 'Total loss': 0.8484476340371508} | train loss {'Reaction outcome loss': 0.8036934456131497, 'Total loss': 0.8036934456131497}
2022-11-18 02:41:41,719 INFO:     Found new best model at epoch 12
2022-11-18 02:41:41,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:41,720 INFO:     Epoch: 13
2022-11-18 02:41:42,494 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8514003337815751, 'Total loss': 0.8514003337815751} | train loss {'Reaction outcome loss': 0.8027386137696563, 'Total loss': 0.8027386137696563}
2022-11-18 02:41:42,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:42,495 INFO:     Epoch: 14
2022-11-18 02:41:43,254 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8811065291249475, 'Total loss': 0.8811065291249475} | train loss {'Reaction outcome loss': 0.8009539416334668, 'Total loss': 0.8009539416334668}
2022-11-18 02:41:43,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:43,254 INFO:     Epoch: 15
2022-11-18 02:41:44,026 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.870110071675722, 'Total loss': 0.870110071675722} | train loss {'Reaction outcome loss': 0.8034405372426158, 'Total loss': 0.8034405372426158}
2022-11-18 02:41:44,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:44,026 INFO:     Epoch: 16
2022-11-18 02:41:44,805 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.863605122233546, 'Total loss': 0.863605122233546} | train loss {'Reaction outcome loss': 0.8009097337967059, 'Total loss': 0.8009097337967059}
2022-11-18 02:41:44,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:44,805 INFO:     Epoch: 17
2022-11-18 02:41:45,576 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8663652095683786, 'Total loss': 0.8663652095683786} | train loss {'Reaction outcome loss': 0.8030598300402282, 'Total loss': 0.8030598300402282}
2022-11-18 02:41:45,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:45,576 INFO:     Epoch: 18
2022-11-18 02:41:46,328 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.857419140117113, 'Total loss': 0.857419140117113} | train loss {'Reaction outcome loss': 0.8005931675434113, 'Total loss': 0.8005931675434113}
2022-11-18 02:41:46,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:46,328 INFO:     Epoch: 19
2022-11-18 02:41:47,091 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8577432812646378, 'Total loss': 0.8577432812646378} | train loss {'Reaction outcome loss': 0.7983906681908935, 'Total loss': 0.7983906681908935}
2022-11-18 02:41:47,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:47,091 INFO:     Epoch: 20
2022-11-18 02:41:47,868 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8768325059912926, 'Total loss': 0.8768325059912926} | train loss {'Reaction outcome loss': 0.799629342971278, 'Total loss': 0.799629342971278}
2022-11-18 02:41:47,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:47,868 INFO:     Epoch: 21
2022-11-18 02:41:48,668 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8698432861372482, 'Total loss': 0.8698432861372482} | train loss {'Reaction outcome loss': 0.8027359245986235, 'Total loss': 0.8027359245986235}
2022-11-18 02:41:48,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:48,669 INFO:     Epoch: 22
2022-11-18 02:41:49,448 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8636249456294748, 'Total loss': 0.8636249456294748} | train loss {'Reaction outcome loss': 0.8050459017519092, 'Total loss': 0.8050459017519092}
2022-11-18 02:41:49,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:49,449 INFO:     Epoch: 23
2022-11-18 02:41:50,230 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8594347224679104, 'Total loss': 0.8594347224679104} | train loss {'Reaction outcome loss': 0.804680199530281, 'Total loss': 0.804680199530281}
2022-11-18 02:41:50,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:50,230 INFO:     Epoch: 24
2022-11-18 02:41:50,998 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8492483829343042, 'Total loss': 0.8492483829343042} | train loss {'Reaction outcome loss': 0.8033781106599042, 'Total loss': 0.8033781106599042}
2022-11-18 02:41:50,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:50,999 INFO:     Epoch: 25
2022-11-18 02:41:51,786 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8631949022758839, 'Total loss': 0.8631949022758839} | train loss {'Reaction outcome loss': 0.8006515675148026, 'Total loss': 0.8006515675148026}
2022-11-18 02:41:51,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:51,786 INFO:     Epoch: 26
2022-11-18 02:41:52,566 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8632804196934367, 'Total loss': 0.8632804196934367} | train loss {'Reaction outcome loss': 0.7989494682091182, 'Total loss': 0.7989494682091182}
2022-11-18 02:41:52,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:52,567 INFO:     Epoch: 27
2022-11-18 02:41:53,354 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.864745908005293, 'Total loss': 0.864745908005293} | train loss {'Reaction outcome loss': 0.8002964377891822, 'Total loss': 0.8002964377891822}
2022-11-18 02:41:53,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:53,355 INFO:     Epoch: 28
2022-11-18 02:41:54,130 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.860415497491526, 'Total loss': 0.860415497491526} | train loss {'Reaction outcome loss': 0.7993962807489223, 'Total loss': 0.7993962807489223}
2022-11-18 02:41:54,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:54,131 INFO:     Epoch: 29
2022-11-18 02:41:54,885 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8494942077370577, 'Total loss': 0.8494942077370577} | train loss {'Reaction outcome loss': 0.7947631744576282, 'Total loss': 0.7947631744576282}
2022-11-18 02:41:54,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:54,885 INFO:     Epoch: 30
2022-11-18 02:41:55,624 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8480126954788385, 'Total loss': 0.8480126954788385} | train loss {'Reaction outcome loss': 0.7941943140792065, 'Total loss': 0.7941943140792065}
2022-11-18 02:41:55,624 INFO:     Found new best model at epoch 30
2022-11-18 02:41:55,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:55,625 INFO:     Epoch: 31
2022-11-18 02:41:56,404 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8571040089740309, 'Total loss': 0.8571040089740309} | train loss {'Reaction outcome loss': 0.7972481297176393, 'Total loss': 0.7972481297176393}
2022-11-18 02:41:56,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:56,405 INFO:     Epoch: 32
2022-11-18 02:41:57,200 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.855007270047831, 'Total loss': 0.855007270047831} | train loss {'Reaction outcome loss': 0.8032948225736618, 'Total loss': 0.8032948225736618}
2022-11-18 02:41:57,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:57,200 INFO:     Epoch: 33
2022-11-18 02:41:57,979 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8537365024866059, 'Total loss': 0.8537365024866059} | train loss {'Reaction outcome loss': 0.7942438143931452, 'Total loss': 0.7942438143931452}
2022-11-18 02:41:57,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:57,979 INFO:     Epoch: 34
2022-11-18 02:41:58,759 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8710463144058405, 'Total loss': 0.8710463144058405} | train loss {'Reaction outcome loss': 0.7987447236893607, 'Total loss': 0.7987447236893607}
2022-11-18 02:41:58,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:58,759 INFO:     Epoch: 35
2022-11-18 02:41:59,556 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8524078116860501, 'Total loss': 0.8524078116860501} | train loss {'Reaction outcome loss': 0.7997307272963836, 'Total loss': 0.7997307272963836}
2022-11-18 02:41:59,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:59,557 INFO:     Epoch: 36
2022-11-18 02:42:00,312 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8523518290630606, 'Total loss': 0.8523518290630606} | train loss {'Reaction outcome loss': 0.7963973288653327, 'Total loss': 0.7963973288653327}
2022-11-18 02:42:00,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:00,313 INFO:     Epoch: 37
2022-11-18 02:42:01,056 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.857763773480127, 'Total loss': 0.857763773480127} | train loss {'Reaction outcome loss': 0.7963010523407186, 'Total loss': 0.7963010523407186}
2022-11-18 02:42:01,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:01,056 INFO:     Epoch: 38
2022-11-18 02:42:01,817 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8529771469360174, 'Total loss': 0.8529771469360174} | train loss {'Reaction outcome loss': 0.7923059941070979, 'Total loss': 0.7923059941070979}
2022-11-18 02:42:01,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:01,817 INFO:     Epoch: 39
2022-11-18 02:42:02,576 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8560017284958862, 'Total loss': 0.8560017284958862} | train loss {'Reaction outcome loss': 0.8002367358593667, 'Total loss': 0.8002367358593667}
2022-11-18 02:42:02,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:02,577 INFO:     Epoch: 40
2022-11-18 02:42:03,348 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.840371114570041, 'Total loss': 0.840371114570041} | train loss {'Reaction outcome loss': 0.7976266060207711, 'Total loss': 0.7976266060207711}
2022-11-18 02:42:03,348 INFO:     Found new best model at epoch 40
2022-11-18 02:42:03,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:03,349 INFO:     Epoch: 41
2022-11-18 02:42:04,135 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8497598753419033, 'Total loss': 0.8497598753419033} | train loss {'Reaction outcome loss': 0.7946579091128756, 'Total loss': 0.7946579091128756}
2022-11-18 02:42:04,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:04,136 INFO:     Epoch: 42
2022-11-18 02:42:04,902 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8567445402921632, 'Total loss': 0.8567445402921632} | train loss {'Reaction outcome loss': 0.7949927452890599, 'Total loss': 0.7949927452890599}
2022-11-18 02:42:04,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:04,903 INFO:     Epoch: 43
2022-11-18 02:42:05,666 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8539830279904742, 'Total loss': 0.8539830279904742} | train loss {'Reaction outcome loss': 0.7964953240312513, 'Total loss': 0.7964953240312513}
2022-11-18 02:42:05,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:05,667 INFO:     Epoch: 44
2022-11-18 02:42:06,431 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.867385616829229, 'Total loss': 0.867385616829229} | train loss {'Reaction outcome loss': 0.7933776647341056, 'Total loss': 0.7933776647341056}
2022-11-18 02:42:06,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:06,431 INFO:     Epoch: 45
2022-11-18 02:42:07,197 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.848746461230655, 'Total loss': 0.848746461230655} | train loss {'Reaction outcome loss': 0.7943816881199353, 'Total loss': 0.7943816881199353}
2022-11-18 02:42:07,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:07,198 INFO:     Epoch: 46
2022-11-18 02:42:07,952 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8638364464737648, 'Total loss': 0.8638364464737648} | train loss {'Reaction outcome loss': 0.7908872516184556, 'Total loss': 0.7908872516184556}
2022-11-18 02:42:07,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:07,952 INFO:     Epoch: 47
2022-11-18 02:42:08,716 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.9079821331556454, 'Total loss': 0.9079821331556454} | train loss {'Reaction outcome loss': 0.8012039840954249, 'Total loss': 0.8012039840954249}
2022-11-18 02:42:08,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:08,717 INFO:     Epoch: 48
2022-11-18 02:42:09,475 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8475034631962, 'Total loss': 0.8475034631962} | train loss {'Reaction outcome loss': 0.7958031184360629, 'Total loss': 0.7958031184360629}
2022-11-18 02:42:09,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:09,475 INFO:     Epoch: 49
2022-11-18 02:42:10,246 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8530357625595358, 'Total loss': 0.8530357625595358} | train loss {'Reaction outcome loss': 0.7962781902952273, 'Total loss': 0.7962781902952273}
2022-11-18 02:42:10,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:10,246 INFO:     Epoch: 50
2022-11-18 02:42:11,007 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8648721256921458, 'Total loss': 0.8648721256921458} | train loss {'Reaction outcome loss': 0.7927357859787394, 'Total loss': 0.7927357859787394}
2022-11-18 02:42:11,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:11,008 INFO:     Epoch: 51
2022-11-18 02:42:11,778 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8699887242428092, 'Total loss': 0.8699887242428092} | train loss {'Reaction outcome loss': 0.795140689635863, 'Total loss': 0.795140689635863}
2022-11-18 02:42:11,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:11,779 INFO:     Epoch: 52
2022-11-18 02:42:12,529 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8509471534296523, 'Total loss': 0.8509471534296523} | train loss {'Reaction outcome loss': 0.7993628192143362, 'Total loss': 0.7993628192143362}
2022-11-18 02:42:12,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:12,529 INFO:     Epoch: 53
2022-11-18 02:42:13,295 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8722897137320319, 'Total loss': 0.8722897137320319} | train loss {'Reaction outcome loss': 0.7906147364954479, 'Total loss': 0.7906147364954479}
2022-11-18 02:42:13,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:13,296 INFO:     Epoch: 54
2022-11-18 02:42:14,069 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8461095815481141, 'Total loss': 0.8461095815481141} | train loss {'Reaction outcome loss': 0.7960715450224329, 'Total loss': 0.7960715450224329}
2022-11-18 02:42:14,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:14,069 INFO:     Epoch: 55
2022-11-18 02:42:14,820 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.854981625495955, 'Total loss': 0.854981625495955} | train loss {'Reaction outcome loss': 0.7934198949913509, 'Total loss': 0.7934198949913509}
2022-11-18 02:42:14,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:14,820 INFO:     Epoch: 56
2022-11-18 02:42:15,579 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8727211772009383, 'Total loss': 0.8727211772009383} | train loss {'Reaction outcome loss': 0.795388818642155, 'Total loss': 0.795388818642155}
2022-11-18 02:42:15,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:15,579 INFO:     Epoch: 57
2022-11-18 02:42:16,380 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8524650681850522, 'Total loss': 0.8524650681850522} | train loss {'Reaction outcome loss': 0.7927701591712529, 'Total loss': 0.7927701591712529}
2022-11-18 02:42:16,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:16,381 INFO:     Epoch: 58
2022-11-18 02:42:17,123 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8617560295171516, 'Total loss': 0.8617560295171516} | train loss {'Reaction outcome loss': 0.7961753201289256, 'Total loss': 0.7961753201289256}
2022-11-18 02:42:17,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:17,123 INFO:     Epoch: 59
2022-11-18 02:42:17,857 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8443929241147152, 'Total loss': 0.8443929241147152} | train loss {'Reaction outcome loss': 0.7950871614891974, 'Total loss': 0.7950871614891974}
2022-11-18 02:42:17,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:17,857 INFO:     Epoch: 60
2022-11-18 02:42:18,599 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8675832637520724, 'Total loss': 0.8675832637520724} | train loss {'Reaction outcome loss': 0.7913422825150802, 'Total loss': 0.7913422825150802}
2022-11-18 02:42:18,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:18,599 INFO:     Epoch: 61
2022-11-18 02:42:19,360 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8441135522931121, 'Total loss': 0.8441135522931121} | train loss {'Reaction outcome loss': 0.7967222607770904, 'Total loss': 0.7967222607770904}
2022-11-18 02:42:19,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:19,361 INFO:     Epoch: 62
2022-11-18 02:42:20,132 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8678455560706383, 'Total loss': 0.8678455560706383} | train loss {'Reaction outcome loss': 0.7915076443650684, 'Total loss': 0.7915076443650684}
2022-11-18 02:42:20,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:20,132 INFO:     Epoch: 63
2022-11-18 02:42:20,908 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8481689899466759, 'Total loss': 0.8481689899466759} | train loss {'Reaction outcome loss': 0.7917396928199002, 'Total loss': 0.7917396928199002}
2022-11-18 02:42:20,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:20,909 INFO:     Epoch: 64
2022-11-18 02:42:21,639 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8624313196470571, 'Total loss': 0.8624313196470571} | train loss {'Reaction outcome loss': 0.7943920699543641, 'Total loss': 0.7943920699543641}
2022-11-18 02:42:21,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:21,640 INFO:     Epoch: 65
2022-11-18 02:42:22,373 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8568642818650534, 'Total loss': 0.8568642818650534} | train loss {'Reaction outcome loss': 0.7971003456193893, 'Total loss': 0.7971003456193893}
2022-11-18 02:42:22,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:22,373 INFO:     Epoch: 66
2022-11-18 02:42:23,149 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8563384067180545, 'Total loss': 0.8563384067180545} | train loss {'Reaction outcome loss': 0.789366857438791, 'Total loss': 0.789366857438791}
2022-11-18 02:42:23,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:23,149 INFO:     Epoch: 67
2022-11-18 02:42:23,909 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8497047985708991, 'Total loss': 0.8497047985708991} | train loss {'Reaction outcome loss': 0.7890014849969598, 'Total loss': 0.7890014849969598}
2022-11-18 02:42:23,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:23,910 INFO:     Epoch: 68
2022-11-18 02:42:24,667 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.855203774779342, 'Total loss': 0.855203774779342} | train loss {'Reaction outcome loss': 0.7954645071361885, 'Total loss': 0.7954645071361885}
2022-11-18 02:42:24,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:24,667 INFO:     Epoch: 69
2022-11-18 02:42:25,438 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8598956417205722, 'Total loss': 0.8598956417205722} | train loss {'Reaction outcome loss': 0.7928389728557869, 'Total loss': 0.7928389728557869}
2022-11-18 02:42:25,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:25,438 INFO:     Epoch: 70
2022-11-18 02:42:26,203 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.851650362791017, 'Total loss': 0.851650362791017} | train loss {'Reaction outcome loss': 0.7949243213553898, 'Total loss': 0.7949243213553898}
2022-11-18 02:42:26,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:26,204 INFO:     Epoch: 71
2022-11-18 02:42:26,947 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8536142415778581, 'Total loss': 0.8536142415778581} | train loss {'Reaction outcome loss': 0.7918332820055914, 'Total loss': 0.7918332820055914}
2022-11-18 02:42:26,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:26,947 INFO:     Epoch: 72
2022-11-18 02:42:27,710 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8457507040611533, 'Total loss': 0.8457507040611533} | train loss {'Reaction outcome loss': 0.7936188383180587, 'Total loss': 0.7936188383180587}
2022-11-18 02:42:27,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:27,710 INFO:     Epoch: 73
2022-11-18 02:42:28,486 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.85108490184296, 'Total loss': 0.85108490184296} | train loss {'Reaction outcome loss': 0.7897654489659872, 'Total loss': 0.7897654489659872}
2022-11-18 02:42:28,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:28,486 INFO:     Epoch: 74
2022-11-18 02:42:29,228 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8511132667231005, 'Total loss': 0.8511132667231005} | train loss {'Reaction outcome loss': 0.7958041066761876, 'Total loss': 0.7958041066761876}
2022-11-18 02:42:29,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:29,228 INFO:     Epoch: 75
2022-11-18 02:42:29,982 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8522494012533233, 'Total loss': 0.8522494012533233} | train loss {'Reaction outcome loss': 0.7929455118833996, 'Total loss': 0.7929455118833996}
2022-11-18 02:42:29,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:29,983 INFO:     Epoch: 76
2022-11-18 02:42:30,769 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8594702343608058, 'Total loss': 0.8594702343608058} | train loss {'Reaction outcome loss': 0.7905790251298029, 'Total loss': 0.7905790251298029}
2022-11-18 02:42:30,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:30,769 INFO:     Epoch: 77
2022-11-18 02:42:31,531 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8421355153239051, 'Total loss': 0.8421355153239051} | train loss {'Reaction outcome loss': 0.7904810905456543, 'Total loss': 0.7904810905456543}
2022-11-18 02:42:31,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:31,531 INFO:     Epoch: 78
2022-11-18 02:42:32,315 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8781337086544481, 'Total loss': 0.8781337086544481} | train loss {'Reaction outcome loss': 0.7949867976493523, 'Total loss': 0.7949867976493523}
2022-11-18 02:42:32,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:32,315 INFO:     Epoch: 79
2022-11-18 02:42:33,091 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8545740815096123, 'Total loss': 0.8545740815096123} | train loss {'Reaction outcome loss': 0.7944326996803284, 'Total loss': 0.7944326996803284}
2022-11-18 02:42:33,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:33,091 INFO:     Epoch: 80
2022-11-18 02:42:33,874 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8564130047033, 'Total loss': 0.8564130047033} | train loss {'Reaction outcome loss': 0.7910491389329316, 'Total loss': 0.7910491389329316}
2022-11-18 02:42:33,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:33,875 INFO:     Epoch: 81
2022-11-18 02:42:34,649 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8608811677888383, 'Total loss': 0.8608811677888383} | train loss {'Reaction outcome loss': 0.7917963823334115, 'Total loss': 0.7917963823334115}
2022-11-18 02:42:34,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:34,649 INFO:     Epoch: 82
2022-11-18 02:42:35,453 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8678876452667769, 'Total loss': 0.8678876452667769} | train loss {'Reaction outcome loss': 0.7868405762510221, 'Total loss': 0.7868405762510221}
2022-11-18 02:42:35,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:35,453 INFO:     Epoch: 83
2022-11-18 02:42:36,264 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8647288887999779, 'Total loss': 0.8647288887999779} | train loss {'Reaction outcome loss': 0.7897500554557706, 'Total loss': 0.7897500554557706}
2022-11-18 02:42:36,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:36,264 INFO:     Epoch: 84
2022-11-18 02:42:37,068 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8319335621456767, 'Total loss': 0.8319335621456767} | train loss {'Reaction outcome loss': 0.789067562364164, 'Total loss': 0.789067562364164}
2022-11-18 02:42:37,068 INFO:     Found new best model at epoch 84
2022-11-18 02:42:37,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:37,069 INFO:     Epoch: 85
2022-11-18 02:42:37,879 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8791269133257311, 'Total loss': 0.8791269133257311} | train loss {'Reaction outcome loss': 0.7861741479547297, 'Total loss': 0.7861741479547297}
2022-11-18 02:42:37,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:37,879 INFO:     Epoch: 86
2022-11-18 02:42:38,671 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8455590654251187, 'Total loss': 0.8455590654251187} | train loss {'Reaction outcome loss': 0.7920057798018221, 'Total loss': 0.7920057798018221}
2022-11-18 02:42:38,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:38,672 INFO:     Epoch: 87
2022-11-18 02:42:39,463 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8675061304901921, 'Total loss': 0.8675061304901921} | train loss {'Reaction outcome loss': 0.7872742387603541, 'Total loss': 0.7872742387603541}
2022-11-18 02:42:39,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:39,463 INFO:     Epoch: 88
2022-11-18 02:42:40,297 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8469440042972565, 'Total loss': 0.8469440042972565} | train loss {'Reaction outcome loss': 0.7882229794488579, 'Total loss': 0.7882229794488579}
2022-11-18 02:42:40,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:40,299 INFO:     Epoch: 89
2022-11-18 02:42:41,065 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8515890275323114, 'Total loss': 0.8515890275323114} | train loss {'Reaction outcome loss': 0.7868218409721969, 'Total loss': 0.7868218409721969}
2022-11-18 02:42:41,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:41,065 INFO:     Epoch: 90
2022-11-18 02:42:41,817 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8605634168136952, 'Total loss': 0.8605634168136952} | train loss {'Reaction outcome loss': 0.7865810968348237, 'Total loss': 0.7865810968348237}
2022-11-18 02:42:41,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:41,818 INFO:     Epoch: 91
2022-11-18 02:42:42,608 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8526916878167973, 'Total loss': 0.8526916878167973} | train loss {'Reaction outcome loss': 0.7847976082416831, 'Total loss': 0.7847976082416831}
2022-11-18 02:42:42,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:42,608 INFO:     Epoch: 92
2022-11-18 02:42:43,410 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8350281479746796, 'Total loss': 0.8350281479746796} | train loss {'Reaction outcome loss': 0.7866707397777526, 'Total loss': 0.7866707397777526}
2022-11-18 02:42:43,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:43,410 INFO:     Epoch: 93
2022-11-18 02:42:44,240 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8548302539559298, 'Total loss': 0.8548302539559298} | train loss {'Reaction outcome loss': 0.7906569011631559, 'Total loss': 0.7906569011631559}
2022-11-18 02:42:44,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:44,240 INFO:     Epoch: 94
2022-11-18 02:42:45,043 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.850089970023133, 'Total loss': 0.850089970023133} | train loss {'Reaction outcome loss': 0.7921702580862358, 'Total loss': 0.7921702580862358}
2022-11-18 02:42:45,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:45,043 INFO:     Epoch: 95
2022-11-18 02:42:45,834 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8397862259731737, 'Total loss': 0.8397862259731737} | train loss {'Reaction outcome loss': 0.7860630168045153, 'Total loss': 0.7860630168045153}
2022-11-18 02:42:45,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:45,834 INFO:     Epoch: 96
2022-11-18 02:42:46,649 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8317637194034665, 'Total loss': 0.8317637194034665} | train loss {'Reaction outcome loss': 0.7829819237355327, 'Total loss': 0.7829819237355327}
2022-11-18 02:42:46,650 INFO:     Found new best model at epoch 96
2022-11-18 02:42:46,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:46,650 INFO:     Epoch: 97
2022-11-18 02:42:47,472 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8520898285300232, 'Total loss': 0.8520898285300232} | train loss {'Reaction outcome loss': 0.7890022724378304, 'Total loss': 0.7890022724378304}
2022-11-18 02:42:47,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:47,472 INFO:     Epoch: 98
2022-11-18 02:42:48,254 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8525351181972859, 'Total loss': 0.8525351181972859} | train loss {'Reaction outcome loss': 0.7850530044954331, 'Total loss': 0.7850530044954331}
2022-11-18 02:42:48,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:48,255 INFO:     Epoch: 99
2022-11-18 02:42:49,046 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8382391971211101, 'Total loss': 0.8382391971211101} | train loss {'Reaction outcome loss': 0.7883580879109805, 'Total loss': 0.7883580879109805}
2022-11-18 02:42:49,047 INFO:     Best model found after epoch 97 of 100.
2022-11-18 02:42:49,047 INFO:   Done with stage: TRAINING
2022-11-18 02:42:49,047 INFO:   Starting stage: EVALUATION
2022-11-18 02:42:49,182 INFO:   Done with stage: EVALUATION
2022-11-18 02:42:49,182 INFO:   Leaving out SEQ value Fold_1
2022-11-18 02:42:49,195 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:42:49,195 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:42:49,876 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:42:49,876 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:42:49,947 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:42:49,947 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:42:49,947 INFO:     No hyperparam tuning for this model
2022-11-18 02:42:49,947 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:42:49,947 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:42:49,948 INFO:     None feature selector for col prot
2022-11-18 02:42:49,948 INFO:     None feature selector for col prot
2022-11-18 02:42:49,948 INFO:     None feature selector for col prot
2022-11-18 02:42:49,948 INFO:     None feature selector for col chem
2022-11-18 02:42:49,949 INFO:     None feature selector for col chem
2022-11-18 02:42:49,949 INFO:     None feature selector for col chem
2022-11-18 02:42:49,949 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:42:49,949 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:42:49,950 INFO:     Number of params in model 168571
2022-11-18 02:42:49,953 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:42:49,953 INFO:   Starting stage: TRAINING
2022-11-18 02:42:50,011 INFO:     Val loss before train {'Reaction outcome loss': 1.0134159360419621, 'Total loss': 1.0134159360419621}
2022-11-18 02:42:50,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:50,011 INFO:     Epoch: 0
2022-11-18 02:42:50,813 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8570673357356678, 'Total loss': 0.8570673357356678} | train loss {'Reaction outcome loss': 0.8878125649111474, 'Total loss': 0.8878125649111474}
2022-11-18 02:42:50,813 INFO:     Found new best model at epoch 0
2022-11-18 02:42:50,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:50,814 INFO:     Epoch: 1
2022-11-18 02:42:51,642 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8490733382376757, 'Total loss': 0.8490733382376757} | train loss {'Reaction outcome loss': 0.8609917708012739, 'Total loss': 0.8609917708012739}
2022-11-18 02:42:51,642 INFO:     Found new best model at epoch 1
2022-11-18 02:42:51,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:51,643 INFO:     Epoch: 2
2022-11-18 02:42:52,470 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8819890408353372, 'Total loss': 0.8819890408353372} | train loss {'Reaction outcome loss': 0.8583723420676915, 'Total loss': 0.8583723420676915}
2022-11-18 02:42:52,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:52,471 INFO:     Epoch: 3
2022-11-18 02:42:53,250 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.869455642320893, 'Total loss': 0.869455642320893} | train loss {'Reaction outcome loss': 0.8592488363928158, 'Total loss': 0.8592488363928158}
2022-11-18 02:42:53,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:53,250 INFO:     Epoch: 4
2022-11-18 02:42:54,048 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8425136222080751, 'Total loss': 0.8425136222080751} | train loss {'Reaction outcome loss': 0.8592104691001567, 'Total loss': 0.8592104691001567}
2022-11-18 02:42:54,048 INFO:     Found new best model at epoch 4
2022-11-18 02:42:54,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:54,049 INFO:     Epoch: 5
2022-11-18 02:42:54,867 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8422767100009051, 'Total loss': 0.8422767100009051} | train loss {'Reaction outcome loss': 0.8523436979002316, 'Total loss': 0.8523436979002316}
2022-11-18 02:42:54,867 INFO:     Found new best model at epoch 5
2022-11-18 02:42:54,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:54,868 INFO:     Epoch: 6
2022-11-18 02:42:55,673 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8368203612891111, 'Total loss': 0.8368203612891111} | train loss {'Reaction outcome loss': 0.8471373774503407, 'Total loss': 0.8471373774503407}
2022-11-18 02:42:55,674 INFO:     Found new best model at epoch 6
2022-11-18 02:42:55,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:55,674 INFO:     Epoch: 7
2022-11-18 02:42:56,461 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8612011508508162, 'Total loss': 0.8612011508508162} | train loss {'Reaction outcome loss': 0.8453771260827176, 'Total loss': 0.8453771260827176}
2022-11-18 02:42:56,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:56,461 INFO:     Epoch: 8
2022-11-18 02:42:57,310 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8526413996111263, 'Total loss': 0.8526413996111263} | train loss {'Reaction outcome loss': 0.8501426329014272, 'Total loss': 0.8501426329014272}
2022-11-18 02:42:57,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:57,310 INFO:     Epoch: 9
2022-11-18 02:42:58,107 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8517216132445768, 'Total loss': 0.8517216132445768} | train loss {'Reaction outcome loss': 0.8490413042456515, 'Total loss': 0.8490413042456515}
2022-11-18 02:42:58,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:58,107 INFO:     Epoch: 10
2022-11-18 02:42:58,918 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8236531723629344, 'Total loss': 0.8236531723629344} | train loss {'Reaction outcome loss': 0.8410133500149858, 'Total loss': 0.8410133500149858}
2022-11-18 02:42:58,918 INFO:     Found new best model at epoch 10
2022-11-18 02:42:58,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:58,919 INFO:     Epoch: 11
2022-11-18 02:42:59,756 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8648723018440333, 'Total loss': 0.8648723018440333} | train loss {'Reaction outcome loss': 0.838048382748959, 'Total loss': 0.838048382748959}
2022-11-18 02:42:59,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:42:59,756 INFO:     Epoch: 12
2022-11-18 02:43:00,530 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.842185605656017, 'Total loss': 0.842185605656017} | train loss {'Reaction outcome loss': 0.8375996674603297, 'Total loss': 0.8375996674603297}
2022-11-18 02:43:00,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:00,530 INFO:     Epoch: 13
2022-11-18 02:43:01,322 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8338395871899345, 'Total loss': 0.8338395871899345} | train loss {'Reaction outcome loss': 0.8365984925856957, 'Total loss': 0.8365984925856957}
2022-11-18 02:43:01,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:01,322 INFO:     Epoch: 14
2022-11-18 02:43:02,123 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8797288239002228, 'Total loss': 0.8797288239002228} | train loss {'Reaction outcome loss': 0.8351063231224956, 'Total loss': 0.8351063231224956}
2022-11-18 02:43:02,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:02,123 INFO:     Epoch: 15
2022-11-18 02:43:02,921 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.829751880331473, 'Total loss': 0.829751880331473} | train loss {'Reaction outcome loss': 0.8296792536280174, 'Total loss': 0.8296792536280174}
2022-11-18 02:43:02,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:02,921 INFO:     Epoch: 16
2022-11-18 02:43:03,740 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8278775343840773, 'Total loss': 0.8278775343840773} | train loss {'Reaction outcome loss': 0.8286905219469235, 'Total loss': 0.8286905219469235}
2022-11-18 02:43:03,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:03,741 INFO:     Epoch: 17
2022-11-18 02:43:04,551 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8288691470568831, 'Total loss': 0.8288691470568831} | train loss {'Reaction outcome loss': 0.8310035386307519, 'Total loss': 0.8310035386307519}
2022-11-18 02:43:04,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:04,552 INFO:     Epoch: 18
2022-11-18 02:43:05,351 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8753386451439424, 'Total loss': 0.8753386451439424} | train loss {'Reaction outcome loss': 0.8340903278063183, 'Total loss': 0.8340903278063183}
2022-11-18 02:43:05,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:05,351 INFO:     Epoch: 19
2022-11-18 02:43:06,184 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8224156851118262, 'Total loss': 0.8224156851118262} | train loss {'Reaction outcome loss': 0.8390583850835499, 'Total loss': 0.8390583850835499}
2022-11-18 02:43:06,184 INFO:     Found new best model at epoch 19
2022-11-18 02:43:06,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:06,185 INFO:     Epoch: 20
2022-11-18 02:43:06,996 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.819680620323528, 'Total loss': 0.819680620323528} | train loss {'Reaction outcome loss': 0.8303054488501568, 'Total loss': 0.8303054488501568}
2022-11-18 02:43:06,996 INFO:     Found new best model at epoch 20
2022-11-18 02:43:06,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:06,997 INFO:     Epoch: 21
2022-11-18 02:43:07,834 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8068420101295818, 'Total loss': 0.8068420101295818} | train loss {'Reaction outcome loss': 0.8261101386445736, 'Total loss': 0.8261101386445736}
2022-11-18 02:43:07,834 INFO:     Found new best model at epoch 21
2022-11-18 02:43:07,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:07,835 INFO:     Epoch: 22
2022-11-18 02:43:08,624 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8258669166402384, 'Total loss': 0.8258669166402384} | train loss {'Reaction outcome loss': 0.8283509170478173, 'Total loss': 0.8283509170478173}
2022-11-18 02:43:08,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:08,625 INFO:     Epoch: 23
2022-11-18 02:43:09,422 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8966155519539659, 'Total loss': 0.8966155519539659} | train loss {'Reaction outcome loss': 0.8276348742034271, 'Total loss': 0.8276348742034271}
2022-11-18 02:43:09,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:09,423 INFO:     Epoch: 24
2022-11-18 02:43:10,225 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.825867965140126, 'Total loss': 0.825867965140126} | train loss {'Reaction outcome loss': 0.8306296499151933, 'Total loss': 0.8306296499151933}
2022-11-18 02:43:10,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:10,225 INFO:     Epoch: 25
2022-11-18 02:43:11,071 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8476559032093395, 'Total loss': 0.8476559032093395} | train loss {'Reaction outcome loss': 0.8383303005927005, 'Total loss': 0.8383303005927005}
2022-11-18 02:43:11,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:11,072 INFO:     Epoch: 26
2022-11-18 02:43:11,894 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.836416745050387, 'Total loss': 0.836416745050387} | train loss {'Reaction outcome loss': 0.8433620139413517, 'Total loss': 0.8433620139413517}
2022-11-18 02:43:11,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:11,894 INFO:     Epoch: 27
2022-11-18 02:43:12,695 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.826647162437439, 'Total loss': 0.826647162437439} | train loss {'Reaction outcome loss': 0.8349118490933407, 'Total loss': 0.8349118490933407}
2022-11-18 02:43:12,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:12,695 INFO:     Epoch: 28
2022-11-18 02:43:13,481 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8522473370487039, 'Total loss': 0.8522473370487039} | train loss {'Reaction outcome loss': 0.8244980668973344, 'Total loss': 0.8244980668973344}
2022-11-18 02:43:13,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:13,481 INFO:     Epoch: 29
2022-11-18 02:43:14,265 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8445476916703311, 'Total loss': 0.8445476916703311} | train loss {'Reaction outcome loss': 0.8298490887228777, 'Total loss': 0.8298490887228777}
2022-11-18 02:43:14,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:14,265 INFO:     Epoch: 30
2022-11-18 02:43:15,078 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8237602703950622, 'Total loss': 0.8237602703950622} | train loss {'Reaction outcome loss': 0.8300933331130487, 'Total loss': 0.8300933331130487}
2022-11-18 02:43:15,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:15,078 INFO:     Epoch: 31
2022-11-18 02:43:15,866 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.819057968529788, 'Total loss': 0.819057968529788} | train loss {'Reaction outcome loss': 0.8340229539253451, 'Total loss': 0.8340229539253451}
2022-11-18 02:43:15,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:15,866 INFO:     Epoch: 32
2022-11-18 02:43:16,671 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8345424654808912, 'Total loss': 0.8345424654808912} | train loss {'Reaction outcome loss': 0.8277153378797446, 'Total loss': 0.8277153378797446}
2022-11-18 02:43:16,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:16,672 INFO:     Epoch: 33
2022-11-18 02:43:17,522 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8262757889249108, 'Total loss': 0.8262757889249108} | train loss {'Reaction outcome loss': 0.8285465086640617, 'Total loss': 0.8285465086640617}
2022-11-18 02:43:17,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:17,522 INFO:     Epoch: 34
2022-11-18 02:43:18,341 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8124387020414526, 'Total loss': 0.8124387020414526} | train loss {'Reaction outcome loss': 0.83074399949568, 'Total loss': 0.83074399949568}
2022-11-18 02:43:18,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:18,341 INFO:     Epoch: 35
2022-11-18 02:43:19,124 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8392087891697884, 'Total loss': 0.8392087891697884} | train loss {'Reaction outcome loss': 0.8294090182192413, 'Total loss': 0.8294090182192413}
2022-11-18 02:43:19,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:19,124 INFO:     Epoch: 36
2022-11-18 02:43:19,945 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8352265066721223, 'Total loss': 0.8352265066721223} | train loss {'Reaction outcome loss': 0.8284574861709888, 'Total loss': 0.8284574861709888}
2022-11-18 02:43:19,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:19,946 INFO:     Epoch: 37
2022-11-18 02:43:20,741 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.813757827336138, 'Total loss': 0.813757827336138} | train loss {'Reaction outcome loss': 0.8373720578336523, 'Total loss': 0.8373720578336523}
2022-11-18 02:43:20,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:20,742 INFO:     Epoch: 38
2022-11-18 02:43:21,551 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8199062530289997, 'Total loss': 0.8199062530289997} | train loss {'Reaction outcome loss': 0.8307832982918995, 'Total loss': 0.8307832982918995}
2022-11-18 02:43:21,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:21,551 INFO:     Epoch: 39
2022-11-18 02:43:22,371 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8388402475552126, 'Total loss': 0.8388402475552126} | train loss {'Reaction outcome loss': 0.8273510255432321, 'Total loss': 0.8273510255432321}
2022-11-18 02:43:22,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:22,371 INFO:     Epoch: 40
2022-11-18 02:43:23,168 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8264732631770048, 'Total loss': 0.8264732631770048} | train loss {'Reaction outcome loss': 0.8252829951102193, 'Total loss': 0.8252829951102193}
2022-11-18 02:43:23,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:23,169 INFO:     Epoch: 41
2022-11-18 02:43:24,003 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.836112925952131, 'Total loss': 0.836112925952131} | train loss {'Reaction outcome loss': 0.8299004127863447, 'Total loss': 0.8299004127863447}
2022-11-18 02:43:24,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:24,003 INFO:     Epoch: 42
2022-11-18 02:43:24,849 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.822121843018315, 'Total loss': 0.822121843018315} | train loss {'Reaction outcome loss': 0.8244355534493681, 'Total loss': 0.8244355534493681}
2022-11-18 02:43:24,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:24,849 INFO:     Epoch: 43
2022-11-18 02:43:25,626 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8287389766086232, 'Total loss': 0.8287389766086232} | train loss {'Reaction outcome loss': 0.8296492604108957, 'Total loss': 0.8296492604108957}
2022-11-18 02:43:25,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:25,626 INFO:     Epoch: 44
2022-11-18 02:43:26,462 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8043550117449327, 'Total loss': 0.8043550117449327} | train loss {'Reaction outcome loss': 0.8326045233711057, 'Total loss': 0.8326045233711057}
2022-11-18 02:43:26,462 INFO:     Found new best model at epoch 44
2022-11-18 02:43:26,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:26,463 INFO:     Epoch: 45
2022-11-18 02:43:27,269 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8265487402677536, 'Total loss': 0.8265487402677536} | train loss {'Reaction outcome loss': 0.8279660250463707, 'Total loss': 0.8279660250463707}
2022-11-18 02:43:27,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:27,269 INFO:     Epoch: 46
2022-11-18 02:43:28,083 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8109001693400469, 'Total loss': 0.8109001693400469} | train loss {'Reaction outcome loss': 0.8257390347569578, 'Total loss': 0.8257390347569578}
2022-11-18 02:43:28,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:28,083 INFO:     Epoch: 47
2022-11-18 02:43:28,879 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8270216760310259, 'Total loss': 0.8270216760310259} | train loss {'Reaction outcome loss': 0.8237631158669468, 'Total loss': 0.8237631158669468}
2022-11-18 02:43:28,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:28,879 INFO:     Epoch: 48
2022-11-18 02:43:29,682 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.840994116934863, 'Total loss': 0.840994116934863} | train loss {'Reaction outcome loss': 0.8271055261977771, 'Total loss': 0.8271055261977771}
2022-11-18 02:43:29,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:29,682 INFO:     Epoch: 49
2022-11-18 02:43:30,457 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8098995834589005, 'Total loss': 0.8098995834589005} | train loss {'Reaction outcome loss': 0.8249316330139453, 'Total loss': 0.8249316330139453}
2022-11-18 02:43:30,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:30,458 INFO:     Epoch: 50
2022-11-18 02:43:31,230 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8223606300624934, 'Total loss': 0.8223606300624934} | train loss {'Reaction outcome loss': 0.8370668946007486, 'Total loss': 0.8370668946007486}
2022-11-18 02:43:31,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:31,230 INFO:     Epoch: 51
2022-11-18 02:43:31,995 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8165996772321787, 'Total loss': 0.8165996772321787} | train loss {'Reaction outcome loss': 0.8288272926923235, 'Total loss': 0.8288272926923235}
2022-11-18 02:43:31,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:31,995 INFO:     Epoch: 52
2022-11-18 02:43:32,756 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8138040480288592, 'Total loss': 0.8138040480288592} | train loss {'Reaction outcome loss': 0.8282345245000322, 'Total loss': 0.8282345245000322}
2022-11-18 02:43:32,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:32,756 INFO:     Epoch: 53
2022-11-18 02:43:33,521 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8182806406508792, 'Total loss': 0.8182806406508792} | train loss {'Reaction outcome loss': 0.826683933948457, 'Total loss': 0.826683933948457}
2022-11-18 02:43:33,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:33,521 INFO:     Epoch: 54
2022-11-18 02:43:34,295 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7994915653358806, 'Total loss': 0.7994915653358806} | train loss {'Reaction outcome loss': 0.8258511810167598, 'Total loss': 0.8258511810167598}
2022-11-18 02:43:34,295 INFO:     Found new best model at epoch 54
2022-11-18 02:43:34,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:34,296 INFO:     Epoch: 55
2022-11-18 02:43:35,078 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8173875937407667, 'Total loss': 0.8173875937407667} | train loss {'Reaction outcome loss': 0.8366156466576734, 'Total loss': 0.8366156466576734}
2022-11-18 02:43:35,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:35,078 INFO:     Epoch: 56
2022-11-18 02:43:35,827 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8555396104400809, 'Total loss': 0.8555396104400809} | train loss {'Reaction outcome loss': 0.8241467438789032, 'Total loss': 0.8241467438789032}
2022-11-18 02:43:35,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:35,828 INFO:     Epoch: 57
2022-11-18 02:43:36,597 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8100142573768442, 'Total loss': 0.8100142573768442} | train loss {'Reaction outcome loss': 0.8308554052823951, 'Total loss': 0.8308554052823951}
2022-11-18 02:43:36,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:36,599 INFO:     Epoch: 58
2022-11-18 02:43:37,397 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8022628113288771, 'Total loss': 0.8022628113288771} | train loss {'Reaction outcome loss': 0.8239814852654692, 'Total loss': 0.8239814852654692}
2022-11-18 02:43:37,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:37,397 INFO:     Epoch: 59
2022-11-18 02:43:38,193 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8284983018582518, 'Total loss': 0.8284983018582518} | train loss {'Reaction outcome loss': 0.8269965057430962, 'Total loss': 0.8269965057430962}
2022-11-18 02:43:38,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:38,193 INFO:     Epoch: 60
2022-11-18 02:43:38,990 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.839124670760198, 'Total loss': 0.839124670760198} | train loss {'Reaction outcome loss': 0.8319919442358287, 'Total loss': 0.8319919442358287}
2022-11-18 02:43:38,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:38,991 INFO:     Epoch: 61
2022-11-18 02:43:39,791 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8021326247941364, 'Total loss': 0.8021326247941364} | train loss {'Reaction outcome loss': 0.8322527968449148, 'Total loss': 0.8322527968449148}
2022-11-18 02:43:39,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:39,792 INFO:     Epoch: 62
2022-11-18 02:43:40,542 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.837815216996453, 'Total loss': 0.837815216996453} | train loss {'Reaction outcome loss': 0.8262959039404325, 'Total loss': 0.8262959039404325}
2022-11-18 02:43:40,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:40,543 INFO:     Epoch: 63
2022-11-18 02:43:41,319 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8096725222739306, 'Total loss': 0.8096725222739306} | train loss {'Reaction outcome loss': 0.8341734572219462, 'Total loss': 0.8341734572219462}
2022-11-18 02:43:41,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:41,319 INFO:     Epoch: 64
2022-11-18 02:43:42,085 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8309046856381677, 'Total loss': 0.8309046856381677} | train loss {'Reaction outcome loss': 0.8325915369186324, 'Total loss': 0.8325915369186324}
2022-11-18 02:43:42,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:42,085 INFO:     Epoch: 65
2022-11-18 02:43:42,863 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8083879392255436, 'Total loss': 0.8083879392255436} | train loss {'Reaction outcome loss': 0.8262527956653704, 'Total loss': 0.8262527956653704}
2022-11-18 02:43:42,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:42,864 INFO:     Epoch: 66
2022-11-18 02:43:43,634 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8331088071519678, 'Total loss': 0.8331088071519678} | train loss {'Reaction outcome loss': 0.828715757561116, 'Total loss': 0.828715757561116}
2022-11-18 02:43:43,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:43,634 INFO:     Epoch: 67
2022-11-18 02:43:44,430 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8049754290418192, 'Total loss': 0.8049754290418192} | train loss {'Reaction outcome loss': 0.8370904309546899, 'Total loss': 0.8370904309546899}
2022-11-18 02:43:44,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:44,431 INFO:     Epoch: 68
2022-11-18 02:43:45,213 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.817182715643536, 'Total loss': 0.817182715643536} | train loss {'Reaction outcome loss': 0.8280604610347796, 'Total loss': 0.8280604610347796}
2022-11-18 02:43:45,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:45,214 INFO:     Epoch: 69
2022-11-18 02:43:45,987 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8094014037739147, 'Total loss': 0.8094014037739147} | train loss {'Reaction outcome loss': 0.8219308842893555, 'Total loss': 0.8219308842893555}
2022-11-18 02:43:45,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:45,987 INFO:     Epoch: 70
2022-11-18 02:43:46,752 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8124641240997748, 'Total loss': 0.8124641240997748} | train loss {'Reaction outcome loss': 0.8270857884333684, 'Total loss': 0.8270857884333684}
2022-11-18 02:43:46,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:46,752 INFO:     Epoch: 71
2022-11-18 02:43:47,513 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8218777220357548, 'Total loss': 0.8218777220357548} | train loss {'Reaction outcome loss': 0.8397072515024347, 'Total loss': 0.8397072515024347}
2022-11-18 02:43:47,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:47,514 INFO:     Epoch: 72
2022-11-18 02:43:48,291 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8282011510296301, 'Total loss': 0.8282011510296301} | train loss {'Reaction outcome loss': 0.8281365106342292, 'Total loss': 0.8281365106342292}
2022-11-18 02:43:48,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:48,291 INFO:     Epoch: 73
2022-11-18 02:43:49,048 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8286972933194854, 'Total loss': 0.8286972933194854} | train loss {'Reaction outcome loss': 0.8289406058276713, 'Total loss': 0.8289406058276713}
2022-11-18 02:43:49,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:49,048 INFO:     Epoch: 74
2022-11-18 02:43:49,802 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.82776824046265, 'Total loss': 0.82776824046265} | train loss {'Reaction outcome loss': 0.8312286613923818, 'Total loss': 0.8312286613923818}
2022-11-18 02:43:49,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:49,802 INFO:     Epoch: 75
2022-11-18 02:43:50,571 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8113145807927306, 'Total loss': 0.8113145807927306} | train loss {'Reaction outcome loss': 0.8307640291901253, 'Total loss': 0.8307640291901253}
2022-11-18 02:43:50,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:50,571 INFO:     Epoch: 76
2022-11-18 02:43:51,349 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.81711761247028, 'Total loss': 0.81711761247028} | train loss {'Reaction outcome loss': 0.8215859011720549, 'Total loss': 0.8215859011720549}
2022-11-18 02:43:51,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:51,349 INFO:     Epoch: 77
2022-11-18 02:43:52,130 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8268387934023683, 'Total loss': 0.8268387934023683} | train loss {'Reaction outcome loss': 0.8208149810310318, 'Total loss': 0.8208149810310318}
2022-11-18 02:43:52,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:52,130 INFO:     Epoch: 78
2022-11-18 02:43:52,901 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8100347288630225, 'Total loss': 0.8100347288630225} | train loss {'Reaction outcome loss': 0.8259571526455975, 'Total loss': 0.8259571526455975}
2022-11-18 02:43:52,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:52,902 INFO:     Epoch: 79
2022-11-18 02:43:53,717 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.806276183236729, 'Total loss': 0.806276183236729} | train loss {'Reaction outcome loss': 0.8279641614510462, 'Total loss': 0.8279641614510462}
2022-11-18 02:43:53,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:53,717 INFO:     Epoch: 80
2022-11-18 02:43:54,470 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8264681168577888, 'Total loss': 0.8264681168577888} | train loss {'Reaction outcome loss': 0.82576388301637, 'Total loss': 0.82576388301637}
2022-11-18 02:43:54,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:54,470 INFO:     Epoch: 81
2022-11-18 02:43:55,245 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8325630609284748, 'Total loss': 0.8325630609284748} | train loss {'Reaction outcome loss': 0.8262191132495278, 'Total loss': 0.8262191132495278}
2022-11-18 02:43:55,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:55,246 INFO:     Epoch: 82
2022-11-18 02:43:56,050 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8212640583515167, 'Total loss': 0.8212640583515167} | train loss {'Reaction outcome loss': 0.8306643360780801, 'Total loss': 0.8306643360780801}
2022-11-18 02:43:56,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:56,051 INFO:     Epoch: 83
2022-11-18 02:43:56,849 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8105746114795859, 'Total loss': 0.8105746114795859} | train loss {'Reaction outcome loss': 0.8261402959403722, 'Total loss': 0.8261402959403722}
2022-11-18 02:43:56,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:56,849 INFO:     Epoch: 84
2022-11-18 02:43:57,668 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8189048997380517, 'Total loss': 0.8189048997380517} | train loss {'Reaction outcome loss': 0.8284198907222825, 'Total loss': 0.8284198907222825}
2022-11-18 02:43:57,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:57,668 INFO:     Epoch: 85
2022-11-18 02:43:58,465 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8018528101119128, 'Total loss': 0.8018528101119128} | train loss {'Reaction outcome loss': 0.8309160494490674, 'Total loss': 0.8309160494490674}
2022-11-18 02:43:58,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:58,465 INFO:     Epoch: 86
2022-11-18 02:43:59,226 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8157629282637076, 'Total loss': 0.8157629282637076} | train loss {'Reaction outcome loss': 0.8357385641891464, 'Total loss': 0.8357385641891464}
2022-11-18 02:43:59,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:43:59,227 INFO:     Epoch: 87
2022-11-18 02:44:00,010 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8092047606002201, 'Total loss': 0.8092047606002201} | train loss {'Reaction outcome loss': 0.8315984571752278, 'Total loss': 0.8315984571752278}
2022-11-18 02:44:00,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:00,010 INFO:     Epoch: 88
2022-11-18 02:44:00,779 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8137005892666903, 'Total loss': 0.8137005892666903} | train loss {'Reaction outcome loss': 0.8217350322345973, 'Total loss': 0.8217350322345973}
2022-11-18 02:44:00,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:00,779 INFO:     Epoch: 89
2022-11-18 02:44:01,545 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8402239111336794, 'Total loss': 0.8402239111336794} | train loss {'Reaction outcome loss': 0.8212836571791877, 'Total loss': 0.8212836571791877}
2022-11-18 02:44:01,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:01,546 INFO:     Epoch: 90
2022-11-18 02:44:02,339 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8123418248512528, 'Total loss': 0.8123418248512528} | train loss {'Reaction outcome loss': 0.8311802718320839, 'Total loss': 0.8311802718320839}
2022-11-18 02:44:02,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:02,339 INFO:     Epoch: 91
2022-11-18 02:44:03,132 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8106558065522801, 'Total loss': 0.8106558065522801} | train loss {'Reaction outcome loss': 0.8305790090729833, 'Total loss': 0.8305790090729833}
2022-11-18 02:44:03,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:03,132 INFO:     Epoch: 92
2022-11-18 02:44:03,954 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8057511801069434, 'Total loss': 0.8057511801069434} | train loss {'Reaction outcome loss': 0.8254093934408566, 'Total loss': 0.8254093934408566}
2022-11-18 02:44:03,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:03,954 INFO:     Epoch: 93
2022-11-18 02:44:04,743 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8139561313119802, 'Total loss': 0.8139561313119802} | train loss {'Reaction outcome loss': 0.8282232434160797, 'Total loss': 0.8282232434160797}
2022-11-18 02:44:04,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:04,744 INFO:     Epoch: 94
2022-11-18 02:44:05,548 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8148035867647692, 'Total loss': 0.8148035867647692} | train loss {'Reaction outcome loss': 0.8251058425497912, 'Total loss': 0.8251058425497912}
2022-11-18 02:44:05,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:05,548 INFO:     Epoch: 95
2022-11-18 02:44:06,368 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8017202683470466, 'Total loss': 0.8017202683470466} | train loss {'Reaction outcome loss': 0.8376271571466315, 'Total loss': 0.8376271571466315}
2022-11-18 02:44:06,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:06,368 INFO:     Epoch: 96
2022-11-18 02:44:07,177 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8337592658671465, 'Total loss': 0.8337592658671465} | train loss {'Reaction outcome loss': 0.8269621763634778, 'Total loss': 0.8269621763634778}
2022-11-18 02:44:07,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:07,178 INFO:     Epoch: 97
2022-11-18 02:44:07,944 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8329947279258207, 'Total loss': 0.8329947279258207} | train loss {'Reaction outcome loss': 0.8258147071368298, 'Total loss': 0.8258147071368298}
2022-11-18 02:44:07,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:07,945 INFO:     Epoch: 98
2022-11-18 02:44:08,746 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8287172967737372, 'Total loss': 0.8287172967737372} | train loss {'Reaction outcome loss': 0.831799241092041, 'Total loss': 0.831799241092041}
2022-11-18 02:44:08,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:08,746 INFO:     Epoch: 99
2022-11-18 02:44:09,534 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8561344526030801, 'Total loss': 0.8561344526030801} | train loss {'Reaction outcome loss': 0.8207264717834198, 'Total loss': 0.8207264717834198}
2022-11-18 02:44:09,534 INFO:     Best model found after epoch 55 of 100.
2022-11-18 02:44:09,535 INFO:   Done with stage: TRAINING
2022-11-18 02:44:09,535 INFO:   Starting stage: EVALUATION
2022-11-18 02:44:09,658 INFO:   Done with stage: EVALUATION
2022-11-18 02:44:09,658 INFO:   Leaving out SEQ value Fold_2
2022-11-18 02:44:09,671 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:44:09,671 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:44:10,339 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:44:10,339 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:44:10,408 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:44:10,408 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:44:10,408 INFO:     No hyperparam tuning for this model
2022-11-18 02:44:10,409 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:44:10,409 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:44:10,409 INFO:     None feature selector for col prot
2022-11-18 02:44:10,410 INFO:     None feature selector for col prot
2022-11-18 02:44:10,410 INFO:     None feature selector for col prot
2022-11-18 02:44:10,410 INFO:     None feature selector for col chem
2022-11-18 02:44:10,410 INFO:     None feature selector for col chem
2022-11-18 02:44:10,410 INFO:     None feature selector for col chem
2022-11-18 02:44:10,410 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:44:10,410 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:44:10,412 INFO:     Number of params in model 168571
2022-11-18 02:44:10,415 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:44:10,415 INFO:   Starting stage: TRAINING
2022-11-18 02:44:10,472 INFO:     Val loss before train {'Reaction outcome loss': 0.9496387797732686, 'Total loss': 0.9496387797732686}
2022-11-18 02:44:10,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:10,472 INFO:     Epoch: 0
2022-11-18 02:44:11,276 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7719905119995738, 'Total loss': 0.7719905119995738} | train loss {'Reaction outcome loss': 0.9097728892916539, 'Total loss': 0.9097728892916539}
2022-11-18 02:44:11,276 INFO:     Found new best model at epoch 0
2022-11-18 02:44:11,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:11,277 INFO:     Epoch: 1
2022-11-18 02:44:12,053 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7650653414948042, 'Total loss': 0.7650653414948042} | train loss {'Reaction outcome loss': 0.8708407128932046, 'Total loss': 0.8708407128932046}
2022-11-18 02:44:12,054 INFO:     Found new best model at epoch 1
2022-11-18 02:44:12,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:12,054 INFO:     Epoch: 2
2022-11-18 02:44:12,877 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7628836895144263, 'Total loss': 0.7628836895144263} | train loss {'Reaction outcome loss': 0.8624769278237077, 'Total loss': 0.8624769278237077}
2022-11-18 02:44:12,877 INFO:     Found new best model at epoch 2
2022-11-18 02:44:12,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:12,878 INFO:     Epoch: 3
2022-11-18 02:44:13,662 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7753144869970721, 'Total loss': 0.7753144869970721} | train loss {'Reaction outcome loss': 0.8648975553815482, 'Total loss': 0.8648975553815482}
2022-11-18 02:44:13,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:13,663 INFO:     Epoch: 4
2022-11-18 02:44:14,419 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7741176929584769, 'Total loss': 0.7741176929584769} | train loss {'Reaction outcome loss': 0.8585839424221242, 'Total loss': 0.8585839424221242}
2022-11-18 02:44:14,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:14,420 INFO:     Epoch: 5
2022-11-18 02:44:15,250 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7591768815073856, 'Total loss': 0.7591768815073856} | train loss {'Reaction outcome loss': 0.8568794128836178, 'Total loss': 0.8568794128836178}
2022-11-18 02:44:15,250 INFO:     Found new best model at epoch 5
2022-11-18 02:44:15,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:15,251 INFO:     Epoch: 6
2022-11-18 02:44:16,052 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.770404925180036, 'Total loss': 0.770404925180036} | train loss {'Reaction outcome loss': 0.8535441038061361, 'Total loss': 0.8535441038061361}
2022-11-18 02:44:16,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:16,052 INFO:     Epoch: 7
2022-11-18 02:44:16,897 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7571871738101161, 'Total loss': 0.7571871738101161} | train loss {'Reaction outcome loss': 0.8495733465571873, 'Total loss': 0.8495733465571873}
2022-11-18 02:44:16,897 INFO:     Found new best model at epoch 7
2022-11-18 02:44:16,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:16,898 INFO:     Epoch: 8
2022-11-18 02:44:17,726 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7565104095048683, 'Total loss': 0.7565104095048683} | train loss {'Reaction outcome loss': 0.8431831669123446, 'Total loss': 0.8431831669123446}
2022-11-18 02:44:17,726 INFO:     Found new best model at epoch 8
2022-11-18 02:44:17,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:17,727 INFO:     Epoch: 9
2022-11-18 02:44:18,544 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7412395401056423, 'Total loss': 0.7412395401056423} | train loss {'Reaction outcome loss': 0.848929187679877, 'Total loss': 0.848929187679877}
2022-11-18 02:44:18,545 INFO:     Found new best model at epoch 9
2022-11-18 02:44:18,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:18,545 INFO:     Epoch: 10
2022-11-18 02:44:19,336 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7550191352533739, 'Total loss': 0.7550191352533739} | train loss {'Reaction outcome loss': 0.8476631301836889, 'Total loss': 0.8476631301836889}
2022-11-18 02:44:19,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:19,336 INFO:     Epoch: 11
2022-11-18 02:44:20,154 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7533979734709096, 'Total loss': 0.7533979734709096} | train loss {'Reaction outcome loss': 0.8438273079571177, 'Total loss': 0.8438273079571177}
2022-11-18 02:44:20,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:20,155 INFO:     Epoch: 12
2022-11-18 02:44:20,929 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7548154502413994, 'Total loss': 0.7548154502413994} | train loss {'Reaction outcome loss': 0.8507227211213503, 'Total loss': 0.8507227211213503}
2022-11-18 02:44:20,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:20,930 INFO:     Epoch: 13
2022-11-18 02:44:21,741 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7387863861960035, 'Total loss': 0.7387863861960035} | train loss {'Reaction outcome loss': 0.8466899292390855, 'Total loss': 0.8466899292390855}
2022-11-18 02:44:21,741 INFO:     Found new best model at epoch 13
2022-11-18 02:44:21,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:21,742 INFO:     Epoch: 14
2022-11-18 02:44:22,530 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7524320822815562, 'Total loss': 0.7524320822815562} | train loss {'Reaction outcome loss': 0.8393666939657243, 'Total loss': 0.8393666939657243}
2022-11-18 02:44:22,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:22,530 INFO:     Epoch: 15
2022-11-18 02:44:23,310 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7651139532410821, 'Total loss': 0.7651139532410821} | train loss {'Reaction outcome loss': 0.841073002849446, 'Total loss': 0.841073002849446}
2022-11-18 02:44:23,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:23,311 INFO:     Epoch: 16
2022-11-18 02:44:24,099 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7449621523535529, 'Total loss': 0.7449621523535529} | train loss {'Reaction outcome loss': 0.8470650571780126, 'Total loss': 0.8470650571780126}
2022-11-18 02:44:24,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:24,100 INFO:     Epoch: 17
2022-11-18 02:44:24,902 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7552506292975226, 'Total loss': 0.7552506292975226} | train loss {'Reaction outcome loss': 0.8403728265987068, 'Total loss': 0.8403728265987068}
2022-11-18 02:44:24,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:24,902 INFO:     Epoch: 18
2022-11-18 02:44:25,705 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7456228830093561, 'Total loss': 0.7456228830093561} | train loss {'Reaction outcome loss': 0.8423185370496062, 'Total loss': 0.8423185370496062}
2022-11-18 02:44:25,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:25,706 INFO:     Epoch: 19
2022-11-18 02:44:26,503 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7447506224000177, 'Total loss': 0.7447506224000177} | train loss {'Reaction outcome loss': 0.8376451972566668, 'Total loss': 0.8376451972566668}
2022-11-18 02:44:26,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:26,504 INFO:     Epoch: 20
2022-11-18 02:44:27,308 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7417926635853079, 'Total loss': 0.7417926635853079} | train loss {'Reaction outcome loss': 0.8442699664928874, 'Total loss': 0.8442699664928874}
2022-11-18 02:44:27,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:27,309 INFO:     Epoch: 21
2022-11-18 02:44:28,145 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7554865708184797, 'Total loss': 0.7554865708184797} | train loss {'Reaction outcome loss': 0.8435699118942511, 'Total loss': 0.8435699118942511}
2022-11-18 02:44:28,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:28,146 INFO:     Epoch: 22
2022-11-18 02:44:28,948 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7861887285875719, 'Total loss': 0.7861887285875719} | train loss {'Reaction outcome loss': 0.8421078430580311, 'Total loss': 0.8421078430580311}
2022-11-18 02:44:28,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:28,949 INFO:     Epoch: 23
2022-11-18 02:44:29,762 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7482491495997406, 'Total loss': 0.7482491495997406} | train loss {'Reaction outcome loss': 0.8408754654839391, 'Total loss': 0.8408754654839391}
2022-11-18 02:44:29,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:29,762 INFO:     Epoch: 24
2022-11-18 02:44:30,589 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7305245115313419, 'Total loss': 0.7305245115313419} | train loss {'Reaction outcome loss': 0.8433390628607547, 'Total loss': 0.8433390628607547}
2022-11-18 02:44:30,590 INFO:     Found new best model at epoch 24
2022-11-18 02:44:30,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:30,590 INFO:     Epoch: 25
2022-11-18 02:44:31,394 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7477758429771246, 'Total loss': 0.7477758429771246} | train loss {'Reaction outcome loss': 0.8396778410819711, 'Total loss': 0.8396778410819711}
2022-11-18 02:44:31,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:31,395 INFO:     Epoch: 26
2022-11-18 02:44:32,190 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.772816423759904, 'Total loss': 0.772816423759904} | train loss {'Reaction outcome loss': 0.8450642786309367, 'Total loss': 0.8450642786309367}
2022-11-18 02:44:32,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:32,190 INFO:     Epoch: 27
2022-11-18 02:44:32,980 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7480419908845147, 'Total loss': 0.7480419908845147} | train loss {'Reaction outcome loss': 0.8423350541318049, 'Total loss': 0.8423350541318049}
2022-11-18 02:44:32,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:32,980 INFO:     Epoch: 28
2022-11-18 02:44:33,812 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7467874163805053, 'Total loss': 0.7467874163805053} | train loss {'Reaction outcome loss': 0.8414431825035908, 'Total loss': 0.8414431825035908}
2022-11-18 02:44:33,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:33,813 INFO:     Epoch: 29
2022-11-18 02:44:34,635 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7510117493396582, 'Total loss': 0.7510117493396582} | train loss {'Reaction outcome loss': 0.8408888367111566, 'Total loss': 0.8408888367111566}
2022-11-18 02:44:34,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:34,635 INFO:     Epoch: 30
2022-11-18 02:44:35,448 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7426563002342401, 'Total loss': 0.7426563002342401} | train loss {'Reaction outcome loss': 0.8461417566801681, 'Total loss': 0.8461417566801681}
2022-11-18 02:44:35,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:35,448 INFO:     Epoch: 31
2022-11-18 02:44:36,230 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7393234684023746, 'Total loss': 0.7393234684023746} | train loss {'Reaction outcome loss': 0.8398870597364473, 'Total loss': 0.8398870597364473}
2022-11-18 02:44:36,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:36,230 INFO:     Epoch: 32
2022-11-18 02:44:37,018 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7323125621607137, 'Total loss': 0.7323125621607137} | train loss {'Reaction outcome loss': 0.84224229012845, 'Total loss': 0.84224229012845}
2022-11-18 02:44:37,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:37,018 INFO:     Epoch: 33
2022-11-18 02:44:37,806 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7642386132894561, 'Total loss': 0.7642386132894561} | train loss {'Reaction outcome loss': 0.8409151351842724, 'Total loss': 0.8409151351842724}
2022-11-18 02:44:37,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:37,806 INFO:     Epoch: 34
2022-11-18 02:44:38,576 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7401915948058284, 'Total loss': 0.7401915948058284} | train loss {'Reaction outcome loss': 0.8415652054255126, 'Total loss': 0.8415652054255126}
2022-11-18 02:44:38,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:38,578 INFO:     Epoch: 35
2022-11-18 02:44:39,345 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7460347913032355, 'Total loss': 0.7460347913032355} | train loss {'Reaction outcome loss': 0.8362097731623493, 'Total loss': 0.8362097731623493}
2022-11-18 02:44:39,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:39,345 INFO:     Epoch: 36
2022-11-18 02:44:40,136 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7500817609387774, 'Total loss': 0.7500817609387774} | train loss {'Reaction outcome loss': 0.8414335907971273, 'Total loss': 0.8414335907971273}
2022-11-18 02:44:40,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:40,136 INFO:     Epoch: 37
2022-11-18 02:44:40,890 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7423573053160379, 'Total loss': 0.7423573053160379} | train loss {'Reaction outcome loss': 0.840794932524689, 'Total loss': 0.840794932524689}
2022-11-18 02:44:40,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:40,890 INFO:     Epoch: 38
2022-11-18 02:44:41,647 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7456545906011448, 'Total loss': 0.7456545906011448} | train loss {'Reaction outcome loss': 0.8402641019860252, 'Total loss': 0.8402641019860252}
2022-11-18 02:44:41,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:41,647 INFO:     Epoch: 39
2022-11-18 02:44:42,410 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.779143075610316, 'Total loss': 0.779143075610316} | train loss {'Reaction outcome loss': 0.8389854696197588, 'Total loss': 0.8389854696197588}
2022-11-18 02:44:42,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:42,410 INFO:     Epoch: 40
2022-11-18 02:44:43,200 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.740048969207808, 'Total loss': 0.740048969207808} | train loss {'Reaction outcome loss': 0.8456359244272357, 'Total loss': 0.8456359244272357}
2022-11-18 02:44:43,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:43,201 INFO:     Epoch: 41
2022-11-18 02:44:43,976 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.767371287872625, 'Total loss': 0.767371287872625} | train loss {'Reaction outcome loss': 0.8380446182411225, 'Total loss': 0.8380446182411225}
2022-11-18 02:44:43,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:43,977 INFO:     Epoch: 42
2022-11-18 02:44:44,723 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7296543918376746, 'Total loss': 0.7296543918376746} | train loss {'Reaction outcome loss': 0.8394194110983708, 'Total loss': 0.8394194110983708}
2022-11-18 02:44:44,724 INFO:     Found new best model at epoch 42
2022-11-18 02:44:44,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:44,725 INFO:     Epoch: 43
2022-11-18 02:44:45,475 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7413480815499328, 'Total loss': 0.7413480815499328} | train loss {'Reaction outcome loss': 0.8410288918702329, 'Total loss': 0.8410288918702329}
2022-11-18 02:44:45,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:45,475 INFO:     Epoch: 44
2022-11-18 02:44:46,255 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7769924963629523, 'Total loss': 0.7769924963629523} | train loss {'Reaction outcome loss': 0.843405438495464, 'Total loss': 0.843405438495464}
2022-11-18 02:44:46,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:46,255 INFO:     Epoch: 45
2022-11-18 02:44:47,039 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7416289386361145, 'Total loss': 0.7416289386361145} | train loss {'Reaction outcome loss': 0.8416227251291275, 'Total loss': 0.8416227251291275}
2022-11-18 02:44:47,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:47,039 INFO:     Epoch: 46
2022-11-18 02:44:47,828 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.760163944821025, 'Total loss': 0.760163944821025} | train loss {'Reaction outcome loss': 0.8414785451576358, 'Total loss': 0.8414785451576358}
2022-11-18 02:44:47,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:47,828 INFO:     Epoch: 47
2022-11-18 02:44:48,598 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7383420467376709, 'Total loss': 0.7383420467376709} | train loss {'Reaction outcome loss': 0.8413559563580106, 'Total loss': 0.8413559563580106}
2022-11-18 02:44:48,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:48,598 INFO:     Epoch: 48
2022-11-18 02:44:49,360 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7417908123759336, 'Total loss': 0.7417908123759336} | train loss {'Reaction outcome loss': 0.8378424477137503, 'Total loss': 0.8378424477137503}
2022-11-18 02:44:49,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:49,360 INFO:     Epoch: 49
2022-11-18 02:44:50,154 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.746884074322013, 'Total loss': 0.746884074322013} | train loss {'Reaction outcome loss': 0.8393058089203522, 'Total loss': 0.8393058089203522}
2022-11-18 02:44:50,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:50,155 INFO:     Epoch: 50
2022-11-18 02:44:50,929 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7478752163953559, 'Total loss': 0.7478752163953559} | train loss {'Reaction outcome loss': 0.8409659292121403, 'Total loss': 0.8409659292121403}
2022-11-18 02:44:50,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:50,930 INFO:     Epoch: 51
2022-11-18 02:44:51,679 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7395641630472138, 'Total loss': 0.7395641630472138} | train loss {'Reaction outcome loss': 0.840623859743603, 'Total loss': 0.840623859743603}
2022-11-18 02:44:51,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:51,679 INFO:     Epoch: 52
2022-11-18 02:44:52,436 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7615748706252076, 'Total loss': 0.7615748706252076} | train loss {'Reaction outcome loss': 0.8378050628988469, 'Total loss': 0.8378050628988469}
2022-11-18 02:44:52,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:52,437 INFO:     Epoch: 53
2022-11-18 02:44:53,223 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7627887483253035, 'Total loss': 0.7627887483253035} | train loss {'Reaction outcome loss': 0.8436803241245082, 'Total loss': 0.8436803241245082}
2022-11-18 02:44:53,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:53,223 INFO:     Epoch: 54
2022-11-18 02:44:54,004 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7495990035145782, 'Total loss': 0.7495990035145782} | train loss {'Reaction outcome loss': 0.8372605337959821, 'Total loss': 0.8372605337959821}
2022-11-18 02:44:54,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:54,005 INFO:     Epoch: 55
2022-11-18 02:44:54,774 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.754744422297145, 'Total loss': 0.754744422297145} | train loss {'Reaction outcome loss': 0.840175590798503, 'Total loss': 0.840175590798503}
2022-11-18 02:44:54,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:54,775 INFO:     Epoch: 56
2022-11-18 02:44:55,557 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7454753109188967, 'Total loss': 0.7454753109188967} | train loss {'Reaction outcome loss': 0.8380642405054608, 'Total loss': 0.8380642405054608}
2022-11-18 02:44:55,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:55,557 INFO:     Epoch: 57
2022-11-18 02:44:56,328 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7479736326738845, 'Total loss': 0.7479736326738845} | train loss {'Reaction outcome loss': 0.8381476377854582, 'Total loss': 0.8381476377854582}
2022-11-18 02:44:56,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:56,328 INFO:     Epoch: 58
2022-11-18 02:44:57,121 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7419427265954572, 'Total loss': 0.7419427265954572} | train loss {'Reaction outcome loss': 0.8378686924449733, 'Total loss': 0.8378686924449733}
2022-11-18 02:44:57,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:57,122 INFO:     Epoch: 59
2022-11-18 02:44:57,903 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7660446970961815, 'Total loss': 0.7660446970961815} | train loss {'Reaction outcome loss': 0.8355857959536256, 'Total loss': 0.8355857959536256}
2022-11-18 02:44:57,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:57,903 INFO:     Epoch: 60
2022-11-18 02:44:58,682 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7338575367317643, 'Total loss': 0.7338575367317643} | train loss {'Reaction outcome loss': 0.8392076897816579, 'Total loss': 0.8392076897816579}
2022-11-18 02:44:58,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:58,682 INFO:     Epoch: 61
2022-11-18 02:44:59,447 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7463902844939121, 'Total loss': 0.7463902844939121} | train loss {'Reaction outcome loss': 0.8388653601535031, 'Total loss': 0.8388653601535031}
2022-11-18 02:44:59,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:44:59,448 INFO:     Epoch: 62
2022-11-18 02:45:00,238 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7390295509682145, 'Total loss': 0.7390295509682145} | train loss {'Reaction outcome loss': 0.8372206129744405, 'Total loss': 0.8372206129744405}
2022-11-18 02:45:00,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:00,238 INFO:     Epoch: 63
2022-11-18 02:45:00,993 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7427684061749037, 'Total loss': 0.7427684061749037} | train loss {'Reaction outcome loss': 0.8391031847014779, 'Total loss': 0.8391031847014779}
2022-11-18 02:45:00,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:00,994 INFO:     Epoch: 64
2022-11-18 02:45:01,789 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7379022933715997, 'Total loss': 0.7379022933715997} | train loss {'Reaction outcome loss': 0.8408155535332492, 'Total loss': 0.8408155535332492}
2022-11-18 02:45:01,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:01,790 INFO:     Epoch: 65
2022-11-18 02:45:02,553 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7509383004765178, 'Total loss': 0.7509383004765178} | train loss {'Reaction outcome loss': 0.8447366158981793, 'Total loss': 0.8447366158981793}
2022-11-18 02:45:02,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:02,553 INFO:     Epoch: 66
2022-11-18 02:45:03,328 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7340451430442722, 'Total loss': 0.7340451430442722} | train loss {'Reaction outcome loss': 0.8385727122181752, 'Total loss': 0.8385727122181752}
2022-11-18 02:45:03,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:03,328 INFO:     Epoch: 67
2022-11-18 02:45:04,119 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8088620859523152, 'Total loss': 0.8088620859523152} | train loss {'Reaction outcome loss': 0.8421844676381252, 'Total loss': 0.8421844676381252}
2022-11-18 02:45:04,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:04,119 INFO:     Epoch: 68
2022-11-18 02:45:04,899 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7401208877563477, 'Total loss': 0.7401208877563477} | train loss {'Reaction outcome loss': 0.8406822580050249, 'Total loss': 0.8406822580050249}
2022-11-18 02:45:04,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:04,900 INFO:     Epoch: 69
2022-11-18 02:45:05,657 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.741880112609198, 'Total loss': 0.741880112609198} | train loss {'Reaction outcome loss': 0.8375344150623337, 'Total loss': 0.8375344150623337}
2022-11-18 02:45:05,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:05,657 INFO:     Epoch: 70
2022-11-18 02:45:06,406 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7555664341117061, 'Total loss': 0.7555664341117061} | train loss {'Reaction outcome loss': 0.8401251391309207, 'Total loss': 0.8401251391309207}
2022-11-18 02:45:06,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:06,407 INFO:     Epoch: 71
2022-11-18 02:45:07,193 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7451016979162083, 'Total loss': 0.7451016979162083} | train loss {'Reaction outcome loss': 0.8426784559107218, 'Total loss': 0.8426784559107218}
2022-11-18 02:45:07,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:07,193 INFO:     Epoch: 72
2022-11-18 02:45:07,958 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7437007995538933, 'Total loss': 0.7437007995538933} | train loss {'Reaction outcome loss': 0.8394648024171102, 'Total loss': 0.8394648024171102}
2022-11-18 02:45:07,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:07,959 INFO:     Epoch: 73
2022-11-18 02:45:08,729 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7654231377812319, 'Total loss': 0.7654231377812319} | train loss {'Reaction outcome loss': 0.8399873383221079, 'Total loss': 0.8399873383221079}
2022-11-18 02:45:08,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:08,729 INFO:     Epoch: 74
2022-11-18 02:45:09,504 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7550747048023135, 'Total loss': 0.7550747048023135} | train loss {'Reaction outcome loss': 0.8383748152705489, 'Total loss': 0.8383748152705489}
2022-11-18 02:45:09,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:09,505 INFO:     Epoch: 75
2022-11-18 02:45:10,289 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7372752109239268, 'Total loss': 0.7372752109239268} | train loss {'Reaction outcome loss': 0.8389149256905571, 'Total loss': 0.8389149256905571}
2022-11-18 02:45:10,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:10,289 INFO:     Epoch: 76
2022-11-18 02:45:11,054 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7690253597359324, 'Total loss': 0.7690253597359324} | train loss {'Reaction outcome loss': 0.8358433218520196, 'Total loss': 0.8358433218520196}
2022-11-18 02:45:11,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:11,054 INFO:     Epoch: 77
2022-11-18 02:45:11,801 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7446995218132817, 'Total loss': 0.7446995218132817} | train loss {'Reaction outcome loss': 0.8402826368320183, 'Total loss': 0.8402826368320183}
2022-11-18 02:45:11,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:11,801 INFO:     Epoch: 78
2022-11-18 02:45:12,565 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7400719266991282, 'Total loss': 0.7400719266991282} | train loss {'Reaction outcome loss': 0.8392300858605103, 'Total loss': 0.8392300858605103}
2022-11-18 02:45:12,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:12,565 INFO:     Epoch: 79
2022-11-18 02:45:13,346 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7566235772399015, 'Total loss': 0.7566235772399015} | train loss {'Reaction outcome loss': 0.8426711422498109, 'Total loss': 0.8426711422498109}
2022-11-18 02:45:13,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:13,346 INFO:     Epoch: 80
2022-11-18 02:45:14,111 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7292773924594702, 'Total loss': 0.7292773924594702} | train loss {'Reaction outcome loss': 0.8345945550770056, 'Total loss': 0.8345945550770056}
2022-11-18 02:45:14,111 INFO:     Found new best model at epoch 80
2022-11-18 02:45:14,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:14,112 INFO:     Epoch: 81
2022-11-18 02:45:14,861 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7647339833337207, 'Total loss': 0.7647339833337207} | train loss {'Reaction outcome loss': 0.8384728840872889, 'Total loss': 0.8384728840872889}
2022-11-18 02:45:14,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:14,861 INFO:     Epoch: 82
2022-11-18 02:45:15,619 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7415289677852808, 'Total loss': 0.7415289677852808} | train loss {'Reaction outcome loss': 0.8357434973853534, 'Total loss': 0.8357434973853534}
2022-11-18 02:45:15,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:15,620 INFO:     Epoch: 83
2022-11-18 02:45:16,387 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7324314048123914, 'Total loss': 0.7324314048123914} | train loss {'Reaction outcome loss': 0.8380232927252035, 'Total loss': 0.8380232927252035}
2022-11-18 02:45:16,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:16,388 INFO:     Epoch: 84
2022-11-18 02:45:17,152 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7324890390385029, 'Total loss': 0.7324890390385029} | train loss {'Reaction outcome loss': 0.8377202473214416, 'Total loss': 0.8377202473214416}
2022-11-18 02:45:17,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:17,152 INFO:     Epoch: 85
2022-11-18 02:45:17,917 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7363724278849225, 'Total loss': 0.7363724278849225} | train loss {'Reaction outcome loss': 0.8403924516722804, 'Total loss': 0.8403924516722804}
2022-11-18 02:45:17,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:17,918 INFO:     Epoch: 86
2022-11-18 02:45:18,678 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7724487823109294, 'Total loss': 0.7724487823109294} | train loss {'Reaction outcome loss': 0.8366874797178097, 'Total loss': 0.8366874797178097}
2022-11-18 02:45:18,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:18,679 INFO:     Epoch: 87
2022-11-18 02:45:19,450 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7612512957218082, 'Total loss': 0.7612512957218082} | train loss {'Reaction outcome loss': 0.8392795270583668, 'Total loss': 0.8392795270583668}
2022-11-18 02:45:19,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:19,450 INFO:     Epoch: 88
2022-11-18 02:45:20,196 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7368372581725897, 'Total loss': 0.7368372581725897} | train loss {'Reaction outcome loss': 0.8394087559131326, 'Total loss': 0.8394087559131326}
2022-11-18 02:45:20,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:20,196 INFO:     Epoch: 89
2022-11-18 02:45:20,979 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7364994779575703, 'Total loss': 0.7364994779575703} | train loss {'Reaction outcome loss': 0.8320665788210806, 'Total loss': 0.8320665788210806}
2022-11-18 02:45:20,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:20,979 INFO:     Epoch: 90
2022-11-18 02:45:21,748 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7416721748751264, 'Total loss': 0.7416721748751264} | train loss {'Reaction outcome loss': 0.8370225168153888, 'Total loss': 0.8370225168153888}
2022-11-18 02:45:21,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:21,748 INFO:     Epoch: 91
2022-11-18 02:45:22,510 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7334575292675994, 'Total loss': 0.7334575292675994} | train loss {'Reaction outcome loss': 0.8377173496562926, 'Total loss': 0.8377173496562926}
2022-11-18 02:45:22,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:22,511 INFO:     Epoch: 92
2022-11-18 02:45:23,277 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7503406058910281, 'Total loss': 0.7503406058910281} | train loss {'Reaction outcome loss': 0.8346462053109388, 'Total loss': 0.8346462053109388}
2022-11-18 02:45:23,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:23,277 INFO:     Epoch: 93
2022-11-18 02:45:24,048 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7402380018733269, 'Total loss': 0.7402380018733269} | train loss {'Reaction outcome loss': 0.8350440724218477, 'Total loss': 0.8350440724218477}
2022-11-18 02:45:24,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:24,048 INFO:     Epoch: 94
2022-11-18 02:45:24,828 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7575474215108294, 'Total loss': 0.7575474215108294} | train loss {'Reaction outcome loss': 0.8453202769770974, 'Total loss': 0.8453202769770974}
2022-11-18 02:45:24,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:24,828 INFO:     Epoch: 95
2022-11-18 02:45:25,588 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.756915687128555, 'Total loss': 0.756915687128555} | train loss {'Reaction outcome loss': 0.836013698797734, 'Total loss': 0.836013698797734}
2022-11-18 02:45:25,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:25,588 INFO:     Epoch: 96
2022-11-18 02:45:26,364 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7374167012613874, 'Total loss': 0.7374167012613874} | train loss {'Reaction outcome loss': 0.8389452948677735, 'Total loss': 0.8389452948677735}
2022-11-18 02:45:26,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:26,364 INFO:     Epoch: 97
2022-11-18 02:45:27,123 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.752301288898601, 'Total loss': 0.752301288898601} | train loss {'Reaction outcome loss': 0.8405099410991199, 'Total loss': 0.8405099410991199}
2022-11-18 02:45:27,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:27,124 INFO:     Epoch: 98
2022-11-18 02:45:27,899 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7480945725773656, 'Total loss': 0.7480945725773656} | train loss {'Reaction outcome loss': 0.8393995388120902, 'Total loss': 0.8393995388120902}
2022-11-18 02:45:27,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:27,900 INFO:     Epoch: 99
2022-11-18 02:45:28,682 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7559229177097941, 'Total loss': 0.7559229177097941} | train loss {'Reaction outcome loss': 0.8366860279538593, 'Total loss': 0.8366860279538593}
2022-11-18 02:45:28,682 INFO:     Best model found after epoch 81 of 100.
2022-11-18 02:45:28,682 INFO:   Done with stage: TRAINING
2022-11-18 02:45:28,682 INFO:   Starting stage: EVALUATION
2022-11-18 02:45:28,817 INFO:   Done with stage: EVALUATION
2022-11-18 02:45:28,817 INFO:   Leaving out SEQ value Fold_3
2022-11-18 02:45:28,830 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 02:45:28,830 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:45:29,494 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:45:29,494 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:45:29,563 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:45:29,563 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:45:29,563 INFO:     No hyperparam tuning for this model
2022-11-18 02:45:29,563 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:45:29,563 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:45:29,564 INFO:     None feature selector for col prot
2022-11-18 02:45:29,564 INFO:     None feature selector for col prot
2022-11-18 02:45:29,564 INFO:     None feature selector for col prot
2022-11-18 02:45:29,565 INFO:     None feature selector for col chem
2022-11-18 02:45:29,565 INFO:     None feature selector for col chem
2022-11-18 02:45:29,565 INFO:     None feature selector for col chem
2022-11-18 02:45:29,565 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:45:29,565 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:45:29,567 INFO:     Number of params in model 168571
2022-11-18 02:45:29,570 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:45:29,570 INFO:   Starting stage: TRAINING
2022-11-18 02:45:29,626 INFO:     Val loss before train {'Reaction outcome loss': 1.0116627438123835, 'Total loss': 1.0116627438123835}
2022-11-18 02:45:29,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:29,626 INFO:     Epoch: 0
2022-11-18 02:45:30,380 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8483014009719672, 'Total loss': 0.8483014009719672} | train loss {'Reaction outcome loss': 0.8717928698033462, 'Total loss': 0.8717928698033462}
2022-11-18 02:45:30,380 INFO:     Found new best model at epoch 0
2022-11-18 02:45:30,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:30,381 INFO:     Epoch: 1
2022-11-18 02:45:31,144 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8595851805321005, 'Total loss': 0.8595851805321005} | train loss {'Reaction outcome loss': 0.8407953662391553, 'Total loss': 0.8407953662391553}
2022-11-18 02:45:31,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:31,145 INFO:     Epoch: 2
2022-11-18 02:45:31,899 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8497188832870749, 'Total loss': 0.8497188832870749} | train loss {'Reaction outcome loss': 0.8348461938983619, 'Total loss': 0.8348461938983619}
2022-11-18 02:45:31,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:31,899 INFO:     Epoch: 3
2022-11-18 02:45:32,695 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8772922830526219, 'Total loss': 0.8772922830526219} | train loss {'Reaction outcome loss': 0.8294561105500523, 'Total loss': 0.8294561105500523}
2022-11-18 02:45:32,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:32,695 INFO:     Epoch: 4
2022-11-18 02:45:33,440 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.835107600273088, 'Total loss': 0.835107600273088} | train loss {'Reaction outcome loss': 0.828602012906055, 'Total loss': 0.828602012906055}
2022-11-18 02:45:33,440 INFO:     Found new best model at epoch 4
2022-11-18 02:45:33,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:33,441 INFO:     Epoch: 5
2022-11-18 02:45:34,204 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8596368695414344, 'Total loss': 0.8596368695414344} | train loss {'Reaction outcome loss': 0.8171664730266288, 'Total loss': 0.8171664730266288}
2022-11-18 02:45:34,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:34,205 INFO:     Epoch: 6
2022-11-18 02:45:34,994 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8386648449786874, 'Total loss': 0.8386648449786874} | train loss {'Reaction outcome loss': 0.819182159356129, 'Total loss': 0.819182159356129}
2022-11-18 02:45:34,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:34,995 INFO:     Epoch: 7
2022-11-18 02:45:35,763 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8308174145776172, 'Total loss': 0.8308174145776172} | train loss {'Reaction outcome loss': 0.8143332816445779, 'Total loss': 0.8143332816445779}
2022-11-18 02:45:35,764 INFO:     Found new best model at epoch 7
2022-11-18 02:45:35,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:35,765 INFO:     Epoch: 8
2022-11-18 02:45:36,537 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8163828260676805, 'Total loss': 0.8163828260676805} | train loss {'Reaction outcome loss': 0.816056614703357, 'Total loss': 0.816056614703357}
2022-11-18 02:45:36,537 INFO:     Found new best model at epoch 8
2022-11-18 02:45:36,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:36,538 INFO:     Epoch: 9
2022-11-18 02:45:37,287 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8249728319256805, 'Total loss': 0.8249728319256805} | train loss {'Reaction outcome loss': 0.811501509613461, 'Total loss': 0.811501509613461}
2022-11-18 02:45:37,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:37,287 INFO:     Epoch: 10
2022-11-18 02:45:38,049 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8045419011005136, 'Total loss': 0.8045419011005136} | train loss {'Reaction outcome loss': 0.8115602810196425, 'Total loss': 0.8115602810196425}
2022-11-18 02:45:38,049 INFO:     Found new best model at epoch 10
2022-11-18 02:45:38,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:38,050 INFO:     Epoch: 11
2022-11-18 02:45:38,813 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8038742022458897, 'Total loss': 0.8038742022458897} | train loss {'Reaction outcome loss': 0.8085993950259048, 'Total loss': 0.8085993950259048}
2022-11-18 02:45:38,813 INFO:     Found new best model at epoch 11
2022-11-18 02:45:38,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:38,814 INFO:     Epoch: 12
2022-11-18 02:45:39,565 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8055994704712269, 'Total loss': 0.8055994704712269} | train loss {'Reaction outcome loss': 0.8180993150291129, 'Total loss': 0.8180993150291129}
2022-11-18 02:45:39,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:39,566 INFO:     Epoch: 13
2022-11-18 02:45:40,323 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8320862616217414, 'Total loss': 0.8320862616217414} | train loss {'Reaction outcome loss': 0.810621783566573, 'Total loss': 0.810621783566573}
2022-11-18 02:45:40,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:40,325 INFO:     Epoch: 14
2022-11-18 02:45:41,098 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8049897475298061, 'Total loss': 0.8049897475298061} | train loss {'Reaction outcome loss': 0.8138400984644399, 'Total loss': 0.8138400984644399}
2022-11-18 02:45:41,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:41,099 INFO:     Epoch: 15
2022-11-18 02:45:41,863 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8211589899174002, 'Total loss': 0.8211589899174002} | train loss {'Reaction outcome loss': 0.8144191813812335, 'Total loss': 0.8144191813812335}
2022-11-18 02:45:41,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:41,863 INFO:     Epoch: 16
2022-11-18 02:45:42,630 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8219591892042826, 'Total loss': 0.8219591892042826} | train loss {'Reaction outcome loss': 0.8092723130689237, 'Total loss': 0.8092723130689237}
2022-11-18 02:45:42,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:42,631 INFO:     Epoch: 17
2022-11-18 02:45:43,404 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8128239124320275, 'Total loss': 0.8128239124320275} | train loss {'Reaction outcome loss': 0.8167278393796442, 'Total loss': 0.8167278393796442}
2022-11-18 02:45:43,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:43,404 INFO:     Epoch: 18
2022-11-18 02:45:44,173 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8080866676430369, 'Total loss': 0.8080866676430369} | train loss {'Reaction outcome loss': 0.8055995138584341, 'Total loss': 0.8055995138584341}
2022-11-18 02:45:44,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:44,174 INFO:     Epoch: 19
2022-11-18 02:45:44,918 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8136058172514272, 'Total loss': 0.8136058172514272} | train loss {'Reaction outcome loss': 0.8109905546216808, 'Total loss': 0.8109905546216808}
2022-11-18 02:45:44,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:44,918 INFO:     Epoch: 20
2022-11-18 02:45:45,685 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.838682797066001, 'Total loss': 0.838682797066001} | train loss {'Reaction outcome loss': 0.8021001590132223, 'Total loss': 0.8021001590132223}
2022-11-18 02:45:45,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:45,686 INFO:     Epoch: 21
2022-11-18 02:45:46,460 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8267640610073888, 'Total loss': 0.8267640610073888} | train loss {'Reaction outcome loss': 0.8100354366096449, 'Total loss': 0.8100354366096449}
2022-11-18 02:45:46,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:46,461 INFO:     Epoch: 22
2022-11-18 02:45:47,228 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8200985331868016, 'Total loss': 0.8200985331868016} | train loss {'Reaction outcome loss': 0.8089807248164597, 'Total loss': 0.8089807248164597}
2022-11-18 02:45:47,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:47,229 INFO:     Epoch: 23
2022-11-18 02:45:48,016 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8028126774832259, 'Total loss': 0.8028126774832259} | train loss {'Reaction outcome loss': 0.8015121232580256, 'Total loss': 0.8015121232580256}
2022-11-18 02:45:48,016 INFO:     Found new best model at epoch 23
2022-11-18 02:45:48,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:48,017 INFO:     Epoch: 24
2022-11-18 02:45:48,767 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8104346474242765, 'Total loss': 0.8104346474242765} | train loss {'Reaction outcome loss': 0.8042820099695229, 'Total loss': 0.8042820099695229}
2022-11-18 02:45:48,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:48,767 INFO:     Epoch: 25
2022-11-18 02:45:49,526 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7998746377091075, 'Total loss': 0.7998746377091075} | train loss {'Reaction outcome loss': 0.8107426654654766, 'Total loss': 0.8107426654654766}
2022-11-18 02:45:49,526 INFO:     Found new best model at epoch 25
2022-11-18 02:45:49,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:49,527 INFO:     Epoch: 26
2022-11-18 02:45:50,294 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8012780165949533, 'Total loss': 0.8012780165949533} | train loss {'Reaction outcome loss': 0.8077124709209788, 'Total loss': 0.8077124709209788}
2022-11-18 02:45:50,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:50,295 INFO:     Epoch: 27
2022-11-18 02:45:51,065 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8210752758868906, 'Total loss': 0.8210752758868906} | train loss {'Reaction outcome loss': 0.8059656658045058, 'Total loss': 0.8059656658045058}
2022-11-18 02:45:51,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:51,066 INFO:     Epoch: 28
2022-11-18 02:45:51,868 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8230148338994314, 'Total loss': 0.8230148338994314} | train loss {'Reaction outcome loss': 0.8094585780744199, 'Total loss': 0.8094585780744199}
2022-11-18 02:45:51,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:51,869 INFO:     Epoch: 29
2022-11-18 02:45:52,659 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8431349958098212, 'Total loss': 0.8431349958098212} | train loss {'Reaction outcome loss': 0.8056627137916078, 'Total loss': 0.8056627137916078}
2022-11-18 02:45:52,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:52,659 INFO:     Epoch: 30
2022-11-18 02:45:53,436 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8184529556784519, 'Total loss': 0.8184529556784519} | train loss {'Reaction outcome loss': 0.8001068769168461, 'Total loss': 0.8001068769168461}
2022-11-18 02:45:53,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:53,437 INFO:     Epoch: 31
2022-11-18 02:45:54,192 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8152910554131796, 'Total loss': 0.8152910554131796} | train loss {'Reaction outcome loss': 0.8025498386518455, 'Total loss': 0.8025498386518455}
2022-11-18 02:45:54,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:54,193 INFO:     Epoch: 32
2022-11-18 02:45:54,934 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8217079535473225, 'Total loss': 0.8217079535473225} | train loss {'Reaction outcome loss': 0.8004835931729878, 'Total loss': 0.8004835931729878}
2022-11-18 02:45:54,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:54,934 INFO:     Epoch: 33
2022-11-18 02:45:55,698 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8095957415048466, 'Total loss': 0.8095957415048466} | train loss {'Reaction outcome loss': 0.8009272688700829, 'Total loss': 0.8009272688700829}
2022-11-18 02:45:55,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:55,698 INFO:     Epoch: 34
2022-11-18 02:45:56,450 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8062126241451086, 'Total loss': 0.8062126241451086} | train loss {'Reaction outcome loss': 0.8051417202615934, 'Total loss': 0.8051417202615934}
2022-11-18 02:45:56,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:56,451 INFO:     Epoch: 35
2022-11-18 02:45:57,218 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8325757578361866, 'Total loss': 0.8325757578361866} | train loss {'Reaction outcome loss': 0.8102499147256216, 'Total loss': 0.8102499147256216}
2022-11-18 02:45:57,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:57,218 INFO:     Epoch: 36
2022-11-18 02:45:57,963 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8516946220120718, 'Total loss': 0.8516946220120718} | train loss {'Reaction outcome loss': 0.7988461856979402, 'Total loss': 0.7988461856979402}
2022-11-18 02:45:57,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:57,963 INFO:     Epoch: 37
2022-11-18 02:45:58,719 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8092974701593089, 'Total loss': 0.8092974701593089} | train loss {'Reaction outcome loss': 0.7997134980350855, 'Total loss': 0.7997134980350855}
2022-11-18 02:45:58,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:58,720 INFO:     Epoch: 38
2022-11-18 02:45:59,488 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.796369401521461, 'Total loss': 0.796369401521461} | train loss {'Reaction outcome loss': 0.8030907430766542, 'Total loss': 0.8030907430766542}
2022-11-18 02:45:59,489 INFO:     Found new best model at epoch 38
2022-11-18 02:45:59,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:45:59,490 INFO:     Epoch: 39
2022-11-18 02:46:00,248 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8029043459615042, 'Total loss': 0.8029043459615042} | train loss {'Reaction outcome loss': 0.7993789697870796, 'Total loss': 0.7993789697870796}
2022-11-18 02:46:00,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:00,249 INFO:     Epoch: 40
2022-11-18 02:46:00,985 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8173149255819099, 'Total loss': 0.8173149255819099} | train loss {'Reaction outcome loss': 0.7972973294464158, 'Total loss': 0.7972973294464158}
2022-11-18 02:46:00,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:00,985 INFO:     Epoch: 41
2022-11-18 02:46:01,770 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8091887582180112, 'Total loss': 0.8091887582180112} | train loss {'Reaction outcome loss': 0.7995555777363326, 'Total loss': 0.7995555777363326}
2022-11-18 02:46:01,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:01,770 INFO:     Epoch: 42
2022-11-18 02:46:02,519 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8054575379504714, 'Total loss': 0.8054575379504714} | train loss {'Reaction outcome loss': 0.7976908537218109, 'Total loss': 0.7976908537218109}
2022-11-18 02:46:02,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:02,519 INFO:     Epoch: 43
2022-11-18 02:46:03,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8032052593175755, 'Total loss': 0.8032052593175755} | train loss {'Reaction outcome loss': 0.8001156701963135, 'Total loss': 0.8001156701963135}
2022-11-18 02:46:03,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:03,298 INFO:     Epoch: 44
2022-11-18 02:46:04,083 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8107114697611609, 'Total loss': 0.8107114697611609} | train loss {'Reaction outcome loss': 0.8027999797230395, 'Total loss': 0.8027999797230395}
2022-11-18 02:46:04,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:04,084 INFO:     Epoch: 45
2022-11-18 02:46:04,877 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8208345292612563, 'Total loss': 0.8208345292612563} | train loss {'Reaction outcome loss': 0.7993118691836856, 'Total loss': 0.7993118691836856}
2022-11-18 02:46:04,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:04,877 INFO:     Epoch: 46
2022-11-18 02:46:05,632 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7937924993592639, 'Total loss': 0.7937924993592639} | train loss {'Reaction outcome loss': 0.8023248076929477, 'Total loss': 0.8023248076929477}
2022-11-18 02:46:05,633 INFO:     Found new best model at epoch 46
2022-11-18 02:46:05,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:05,634 INFO:     Epoch: 47
2022-11-18 02:46:06,394 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8004384075486383, 'Total loss': 0.8004384075486383} | train loss {'Reaction outcome loss': 0.8007299344480774, 'Total loss': 0.8007299344480774}
2022-11-18 02:46:06,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:06,394 INFO:     Epoch: 48
2022-11-18 02:46:07,148 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8163117710934129, 'Total loss': 0.8163117710934129} | train loss {'Reaction outcome loss': 0.7978642845350038, 'Total loss': 0.7978642845350038}
2022-11-18 02:46:07,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:07,148 INFO:     Epoch: 49
2022-11-18 02:46:07,916 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8130936927573625, 'Total loss': 0.8130936927573625} | train loss {'Reaction outcome loss': 0.7995519967972006, 'Total loss': 0.7995519967972006}
2022-11-18 02:46:07,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:07,916 INFO:     Epoch: 50
2022-11-18 02:46:08,686 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8199309990849606, 'Total loss': 0.8199309990849606} | train loss {'Reaction outcome loss': 0.8023857663197772, 'Total loss': 0.8023857663197772}
2022-11-18 02:46:08,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:08,686 INFO:     Epoch: 51
2022-11-18 02:46:09,428 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8620392978191376, 'Total loss': 0.8620392978191376} | train loss {'Reaction outcome loss': 0.7981208479453507, 'Total loss': 0.7981208479453507}
2022-11-18 02:46:09,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:09,428 INFO:     Epoch: 52
2022-11-18 02:46:10,208 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8008396819580433, 'Total loss': 0.8008396819580433} | train loss {'Reaction outcome loss': 0.8035538631947443, 'Total loss': 0.8035538631947443}
2022-11-18 02:46:10,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:10,208 INFO:     Epoch: 53
2022-11-18 02:46:10,975 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8048936156339423, 'Total loss': 0.8048936156339423} | train loss {'Reaction outcome loss': 0.7971748503637902, 'Total loss': 0.7971748503637902}
2022-11-18 02:46:10,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:10,975 INFO:     Epoch: 54
2022-11-18 02:46:11,730 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8071087605731432, 'Total loss': 0.8071087605731432} | train loss {'Reaction outcome loss': 0.8019049665564862, 'Total loss': 0.8019049665564862}
2022-11-18 02:46:11,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:11,732 INFO:     Epoch: 55
2022-11-18 02:46:12,494 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8003655013649963, 'Total loss': 0.8003655013649963} | train loss {'Reaction outcome loss': 0.7936759090717928, 'Total loss': 0.7936759090717928}
2022-11-18 02:46:12,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:12,494 INFO:     Epoch: 56
2022-11-18 02:46:13,248 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8095136728397635, 'Total loss': 0.8095136728397635} | train loss {'Reaction outcome loss': 0.7978115668022093, 'Total loss': 0.7978115668022093}
2022-11-18 02:46:13,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:13,249 INFO:     Epoch: 57
2022-11-18 02:46:13,997 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7926331495129785, 'Total loss': 0.7926331495129785} | train loss {'Reaction outcome loss': 0.8047743702131044, 'Total loss': 0.8047743702131044}
2022-11-18 02:46:13,997 INFO:     Found new best model at epoch 57
2022-11-18 02:46:13,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:13,998 INFO:     Epoch: 58
2022-11-18 02:46:14,774 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.797045407600181, 'Total loss': 0.797045407600181} | train loss {'Reaction outcome loss': 0.7972336085858168, 'Total loss': 0.7972336085858168}
2022-11-18 02:46:14,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:14,774 INFO:     Epoch: 59
2022-11-18 02:46:15,547 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7881328144738841, 'Total loss': 0.7881328144738841} | train loss {'Reaction outcome loss': 0.7987469404077334, 'Total loss': 0.7987469404077334}
2022-11-18 02:46:15,547 INFO:     Found new best model at epoch 59
2022-11-18 02:46:15,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:15,548 INFO:     Epoch: 60
2022-11-18 02:46:16,299 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8016985959784929, 'Total loss': 0.8016985959784929} | train loss {'Reaction outcome loss': 0.7963656703385796, 'Total loss': 0.7963656703385796}
2022-11-18 02:46:16,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:16,299 INFO:     Epoch: 61
2022-11-18 02:46:17,106 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8377406403075817, 'Total loss': 0.8377406403075817} | train loss {'Reaction outcome loss': 0.7982359458634882, 'Total loss': 0.7982359458634882}
2022-11-18 02:46:17,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:17,107 INFO:     Epoch: 62
2022-11-18 02:46:17,877 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7948900981004848, 'Total loss': 0.7948900981004848} | train loss {'Reaction outcome loss': 0.8012859751412897, 'Total loss': 0.8012859751412897}
2022-11-18 02:46:17,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:17,878 INFO:     Epoch: 63
2022-11-18 02:46:18,632 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8222128395424333, 'Total loss': 0.8222128395424333} | train loss {'Reaction outcome loss': 0.7929892549789491, 'Total loss': 0.7929892549789491}
2022-11-18 02:46:18,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:18,632 INFO:     Epoch: 64
2022-11-18 02:46:19,394 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8052013876826264, 'Total loss': 0.8052013876826264} | train loss {'Reaction outcome loss': 0.7977390510064585, 'Total loss': 0.7977390510064585}
2022-11-18 02:46:19,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:19,394 INFO:     Epoch: 65
2022-11-18 02:46:20,189 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.81850114672683, 'Total loss': 0.81850114672683} | train loss {'Reaction outcome loss': 0.8007370270328757, 'Total loss': 0.8007370270328757}
2022-11-18 02:46:20,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:20,189 INFO:     Epoch: 66
2022-11-18 02:46:21,050 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7997253516385722, 'Total loss': 0.7997253516385722} | train loss {'Reaction outcome loss': 0.79613945930583, 'Total loss': 0.79613945930583}
2022-11-18 02:46:21,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:21,050 INFO:     Epoch: 67
2022-11-18 02:46:21,813 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8045939040738482, 'Total loss': 0.8045939040738482} | train loss {'Reaction outcome loss': 0.7969404103334058, 'Total loss': 0.7969404103334058}
2022-11-18 02:46:21,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:21,814 INFO:     Epoch: 68
2022-11-18 02:46:22,613 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7904138745263566, 'Total loss': 0.7904138745263566} | train loss {'Reaction outcome loss': 0.7984916542047336, 'Total loss': 0.7984916542047336}
2022-11-18 02:46:22,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:22,613 INFO:     Epoch: 69
2022-11-18 02:46:23,422 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.808891527181448, 'Total loss': 0.808891527181448} | train loss {'Reaction outcome loss': 0.7959039433870787, 'Total loss': 0.7959039433870787}
2022-11-18 02:46:23,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:23,422 INFO:     Epoch: 70
2022-11-18 02:46:24,201 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8012919495272082, 'Total loss': 0.8012919495272082} | train loss {'Reaction outcome loss': 0.79953273750627, 'Total loss': 0.79953273750627}
2022-11-18 02:46:24,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:24,201 INFO:     Epoch: 71
2022-11-18 02:46:25,006 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8137775978376699, 'Total loss': 0.8137775978376699} | train loss {'Reaction outcome loss': 0.8017577127296738, 'Total loss': 0.8017577127296738}
2022-11-18 02:46:25,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:25,006 INFO:     Epoch: 72
2022-11-18 02:46:25,809 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8524360296338104, 'Total loss': 0.8524360296338104} | train loss {'Reaction outcome loss': 0.7959659446659402, 'Total loss': 0.7959659446659402}
2022-11-18 02:46:25,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:25,809 INFO:     Epoch: 73
2022-11-18 02:46:26,608 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8109791653100834, 'Total loss': 0.8109791653100834} | train loss {'Reaction outcome loss': 0.7963357056364601, 'Total loss': 0.7963357056364601}
2022-11-18 02:46:26,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:26,608 INFO:     Epoch: 74
2022-11-18 02:46:27,377 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.814613098321959, 'Total loss': 0.814613098321959} | train loss {'Reaction outcome loss': 0.7943423928179368, 'Total loss': 0.7943423928179368}
2022-11-18 02:46:27,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:27,378 INFO:     Epoch: 75
2022-11-18 02:46:28,189 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8153068402478861, 'Total loss': 0.8153068402478861} | train loss {'Reaction outcome loss': 0.7957334488998224, 'Total loss': 0.7957334488998224}
2022-11-18 02:46:28,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:28,189 INFO:     Epoch: 76
2022-11-18 02:46:28,922 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8044909640800121, 'Total loss': 0.8044909640800121} | train loss {'Reaction outcome loss': 0.7933898701834581, 'Total loss': 0.7933898701834581}
2022-11-18 02:46:28,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:28,922 INFO:     Epoch: 77
2022-11-18 02:46:29,759 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8005923753560975, 'Total loss': 0.8005923753560975} | train loss {'Reaction outcome loss': 0.791767573896259, 'Total loss': 0.791767573896259}
2022-11-18 02:46:29,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:29,760 INFO:     Epoch: 78
2022-11-18 02:46:30,563 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8115184688290884, 'Total loss': 0.8115184688290884} | train loss {'Reaction outcome loss': 0.7964407469264765, 'Total loss': 0.7964407469264765}
2022-11-18 02:46:30,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:30,564 INFO:     Epoch: 79
2022-11-18 02:46:31,381 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8123082185900489, 'Total loss': 0.8123082185900489} | train loss {'Reaction outcome loss': 0.8003496370688388, 'Total loss': 0.8003496370688388}
2022-11-18 02:46:31,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:31,382 INFO:     Epoch: 80
2022-11-18 02:46:32,206 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8086588687674944, 'Total loss': 0.8086588687674944} | train loss {'Reaction outcome loss': 0.7947811911135544, 'Total loss': 0.7947811911135544}
2022-11-18 02:46:32,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:32,207 INFO:     Epoch: 81
2022-11-18 02:46:32,986 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8092317865338436, 'Total loss': 0.8092317865338436} | train loss {'Reaction outcome loss': 0.7949941420751344, 'Total loss': 0.7949941420751344}
2022-11-18 02:46:32,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:32,987 INFO:     Epoch: 82
2022-11-18 02:46:33,761 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8051102702007737, 'Total loss': 0.8051102702007737} | train loss {'Reaction outcome loss': 0.7947490204263616, 'Total loss': 0.7947490204263616}
2022-11-18 02:46:33,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:33,761 INFO:     Epoch: 83
2022-11-18 02:46:34,508 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7932853885861331, 'Total loss': 0.7932853885861331} | train loss {'Reaction outcome loss': 0.7941715134759989, 'Total loss': 0.7941715134759989}
2022-11-18 02:46:34,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:34,509 INFO:     Epoch: 84
2022-11-18 02:46:35,295 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8159576231657073, 'Total loss': 0.8159576231657073} | train loss {'Reaction outcome loss': 0.7907112974198267, 'Total loss': 0.7907112974198267}
2022-11-18 02:46:35,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:35,295 INFO:     Epoch: 85
2022-11-18 02:46:36,055 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7987384685250216, 'Total loss': 0.7987384685250216} | train loss {'Reaction outcome loss': 0.7995098044352277, 'Total loss': 0.7995098044352277}
2022-11-18 02:46:36,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:36,056 INFO:     Epoch: 86
2022-11-18 02:46:36,848 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.796969379103461, 'Total loss': 0.796969379103461} | train loss {'Reaction outcome loss': 0.7965051878872231, 'Total loss': 0.7965051878872231}
2022-11-18 02:46:36,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:36,849 INFO:     Epoch: 87
2022-11-18 02:46:37,656 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8014521169108014, 'Total loss': 0.8014521169108014} | train loss {'Reaction outcome loss': 0.7968777392381503, 'Total loss': 0.7968777392381503}
2022-11-18 02:46:37,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:37,657 INFO:     Epoch: 88
2022-11-18 02:46:38,511 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8025336917056594, 'Total loss': 0.8025336917056594} | train loss {'Reaction outcome loss': 0.7941541858783965, 'Total loss': 0.7941541858783965}
2022-11-18 02:46:38,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:38,511 INFO:     Epoch: 89
2022-11-18 02:46:39,302 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8016596686008365, 'Total loss': 0.8016596686008365} | train loss {'Reaction outcome loss': 0.7989026256549505, 'Total loss': 0.7989026256549505}
2022-11-18 02:46:39,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:39,302 INFO:     Epoch: 90
2022-11-18 02:46:40,078 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7805709097274515, 'Total loss': 0.7805709097274515} | train loss {'Reaction outcome loss': 0.7918633423714971, 'Total loss': 0.7918633423714971}
2022-11-18 02:46:40,079 INFO:     Found new best model at epoch 90
2022-11-18 02:46:40,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:40,079 INFO:     Epoch: 91
2022-11-18 02:46:40,862 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8080120052016059, 'Total loss': 0.8080120052016059} | train loss {'Reaction outcome loss': 0.7898033391301034, 'Total loss': 0.7898033391301034}
2022-11-18 02:46:40,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:40,863 INFO:     Epoch: 92
2022-11-18 02:46:41,632 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.793738151012465, 'Total loss': 0.793738151012465} | train loss {'Reaction outcome loss': 0.7960498329297996, 'Total loss': 0.7960498329297996}
2022-11-18 02:46:41,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:41,632 INFO:     Epoch: 93
2022-11-18 02:46:42,433 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7823360465293707, 'Total loss': 0.7823360465293707} | train loss {'Reaction outcome loss': 0.7955319780871701, 'Total loss': 0.7955319780871701}
2022-11-18 02:46:42,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:42,436 INFO:     Epoch: 94
2022-11-18 02:46:43,221 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8170947529548822, 'Total loss': 0.8170947529548822} | train loss {'Reaction outcome loss': 0.7982220693870827, 'Total loss': 0.7982220693870827}
2022-11-18 02:46:43,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:43,222 INFO:     Epoch: 95
2022-11-18 02:46:44,020 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7924051825390306, 'Total loss': 0.7924051825390306} | train loss {'Reaction outcome loss': 0.79973116333102, 'Total loss': 0.79973116333102}
2022-11-18 02:46:44,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:44,020 INFO:     Epoch: 96
2022-11-18 02:46:44,819 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7974277817925741, 'Total loss': 0.7974277817925741} | train loss {'Reaction outcome loss': 0.7938614393212667, 'Total loss': 0.7938614393212667}
2022-11-18 02:46:44,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:44,820 INFO:     Epoch: 97
2022-11-18 02:46:45,644 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7989973162495813, 'Total loss': 0.7989973162495813} | train loss {'Reaction outcome loss': 0.7876167447907935, 'Total loss': 0.7876167447907935}
2022-11-18 02:46:45,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:45,645 INFO:     Epoch: 98
2022-11-18 02:46:46,420 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7843823581933975, 'Total loss': 0.7843823581933975} | train loss {'Reaction outcome loss': 0.7921680377589332, 'Total loss': 0.7921680377589332}
2022-11-18 02:46:46,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:46,420 INFO:     Epoch: 99
2022-11-18 02:46:47,231 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8044026965318725, 'Total loss': 0.8044026965318725} | train loss {'Reaction outcome loss': 0.7907622525230847, 'Total loss': 0.7907622525230847}
2022-11-18 02:46:47,231 INFO:     Best model found after epoch 91 of 100.
2022-11-18 02:46:47,231 INFO:   Done with stage: TRAINING
2022-11-18 02:46:47,231 INFO:   Starting stage: EVALUATION
2022-11-18 02:46:47,370 INFO:   Done with stage: EVALUATION
2022-11-18 02:46:47,371 INFO:   Leaving out SEQ value Fold_4
2022-11-18 02:46:47,384 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:46:47,384 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:46:48,059 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:46:48,060 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:46:48,129 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:46:48,129 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:46:48,129 INFO:     No hyperparam tuning for this model
2022-11-18 02:46:48,129 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:46:48,129 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:46:48,130 INFO:     None feature selector for col prot
2022-11-18 02:46:48,130 INFO:     None feature selector for col prot
2022-11-18 02:46:48,130 INFO:     None feature selector for col prot
2022-11-18 02:46:48,131 INFO:     None feature selector for col chem
2022-11-18 02:46:48,131 INFO:     None feature selector for col chem
2022-11-18 02:46:48,131 INFO:     None feature selector for col chem
2022-11-18 02:46:48,131 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:46:48,131 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:46:48,132 INFO:     Number of params in model 168571
2022-11-18 02:46:48,136 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:46:48,136 INFO:   Starting stage: TRAINING
2022-11-18 02:46:48,193 INFO:     Val loss before train {'Reaction outcome loss': 1.019520191983743, 'Total loss': 1.019520191983743}
2022-11-18 02:46:48,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:48,193 INFO:     Epoch: 0
2022-11-18 02:46:49,004 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8458394218574871, 'Total loss': 0.8458394218574871} | train loss {'Reaction outcome loss': 0.8784493865513125, 'Total loss': 0.8784493865513125}
2022-11-18 02:46:49,005 INFO:     Found new best model at epoch 0
2022-11-18 02:46:49,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:49,006 INFO:     Epoch: 1
2022-11-18 02:46:49,824 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8774176416071978, 'Total loss': 0.8774176416071978} | train loss {'Reaction outcome loss': 0.8420878126312364, 'Total loss': 0.8420878126312364}
2022-11-18 02:46:49,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:49,824 INFO:     Epoch: 2
2022-11-18 02:46:50,602 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8467594168402932, 'Total loss': 0.8467594168402932} | train loss {'Reaction outcome loss': 0.834636168019009, 'Total loss': 0.834636168019009}
2022-11-18 02:46:50,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:50,602 INFO:     Epoch: 3
2022-11-18 02:46:51,389 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8524818474596197, 'Total loss': 0.8524818474596197} | train loss {'Reaction outcome loss': 0.8354019228263423, 'Total loss': 0.8354019228263423}
2022-11-18 02:46:51,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:51,389 INFO:     Epoch: 4
2022-11-18 02:46:52,215 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8416795066811822, 'Total loss': 0.8416795066811822} | train loss {'Reaction outcome loss': 0.834078152532037, 'Total loss': 0.834078152532037}
2022-11-18 02:46:52,215 INFO:     Found new best model at epoch 4
2022-11-18 02:46:52,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:52,216 INFO:     Epoch: 5
2022-11-18 02:46:53,019 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8459552838043733, 'Total loss': 0.8459552838043733} | train loss {'Reaction outcome loss': 0.8231627842795993, 'Total loss': 0.8231627842795993}
2022-11-18 02:46:53,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:53,019 INFO:     Epoch: 6
2022-11-18 02:46:53,807 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8372347314249385, 'Total loss': 0.8372347314249385} | train loss {'Reaction outcome loss': 0.821623459036051, 'Total loss': 0.821623459036051}
2022-11-18 02:46:53,807 INFO:     Found new best model at epoch 6
2022-11-18 02:46:53,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:53,808 INFO:     Epoch: 7
2022-11-18 02:46:54,636 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8646508184346285, 'Total loss': 0.8646508184346285} | train loss {'Reaction outcome loss': 0.8200973611370272, 'Total loss': 0.8200973611370272}
2022-11-18 02:46:54,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:54,636 INFO:     Epoch: 8
2022-11-18 02:46:55,448 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8379255817695097, 'Total loss': 0.8379255817695097} | train loss {'Reaction outcome loss': 0.8186966238716836, 'Total loss': 0.8186966238716836}
2022-11-18 02:46:55,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:55,448 INFO:     Epoch: 9
2022-11-18 02:46:56,287 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8432333184914156, 'Total loss': 0.8432333184914156} | train loss {'Reaction outcome loss': 0.8241912154292288, 'Total loss': 0.8241912154292288}
2022-11-18 02:46:56,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:56,288 INFO:     Epoch: 10
2022-11-18 02:46:57,084 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8531523414633491, 'Total loss': 0.8531523414633491} | train loss {'Reaction outcome loss': 0.8180443981006319, 'Total loss': 0.8180443981006319}
2022-11-18 02:46:57,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:57,085 INFO:     Epoch: 11
2022-11-18 02:46:57,889 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8634139042009007, 'Total loss': 0.8634139042009007} | train loss {'Reaction outcome loss': 0.8242905575495499, 'Total loss': 0.8242905575495499}
2022-11-18 02:46:57,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:57,889 INFO:     Epoch: 12
2022-11-18 02:46:58,667 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8427463553168557, 'Total loss': 0.8427463553168557} | train loss {'Reaction outcome loss': 0.8260911255471619, 'Total loss': 0.8260911255471619}
2022-11-18 02:46:58,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:58,667 INFO:     Epoch: 13
2022-11-18 02:46:59,464 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8483227349140428, 'Total loss': 0.8483227349140428} | train loss {'Reaction outcome loss': 0.81790846646556, 'Total loss': 0.81790846646556}
2022-11-18 02:46:59,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:46:59,464 INFO:     Epoch: 14
2022-11-18 02:47:00,304 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8419628258455883, 'Total loss': 0.8419628258455883} | train loss {'Reaction outcome loss': 0.8167776511265681, 'Total loss': 0.8167776511265681}
2022-11-18 02:47:00,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:00,305 INFO:     Epoch: 15
2022-11-18 02:47:01,108 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8453244966539469, 'Total loss': 0.8453244966539469} | train loss {'Reaction outcome loss': 0.820188707668289, 'Total loss': 0.820188707668289}
2022-11-18 02:47:01,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:01,109 INFO:     Epoch: 16
2022-11-18 02:47:01,930 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8645943172953345, 'Total loss': 0.8645943172953345} | train loss {'Reaction outcome loss': 0.8137691771754851, 'Total loss': 0.8137691771754851}
2022-11-18 02:47:01,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:01,930 INFO:     Epoch: 17
2022-11-18 02:47:02,716 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8424693982709538, 'Total loss': 0.8424693982709538} | train loss {'Reaction outcome loss': 0.8172123576948035, 'Total loss': 0.8172123576948035}
2022-11-18 02:47:02,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:02,716 INFO:     Epoch: 18
2022-11-18 02:47:03,493 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8220139172944155, 'Total loss': 0.8220139172944155} | train loss {'Reaction outcome loss': 0.8187878871494941, 'Total loss': 0.8187878871494941}
2022-11-18 02:47:03,493 INFO:     Found new best model at epoch 18
2022-11-18 02:47:03,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:03,494 INFO:     Epoch: 19
2022-11-18 02:47:04,280 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8639573373577811, 'Total loss': 0.8639573373577811} | train loss {'Reaction outcome loss': 0.8232194737866823, 'Total loss': 0.8232194737866823}
2022-11-18 02:47:04,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:04,280 INFO:     Epoch: 20
2022-11-18 02:47:05,136 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.839307610961524, 'Total loss': 0.839307610961524} | train loss {'Reaction outcome loss': 0.8173889171498024, 'Total loss': 0.8173889171498024}
2022-11-18 02:47:05,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:05,136 INFO:     Epoch: 21
2022-11-18 02:47:05,925 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8546949882398952, 'Total loss': 0.8546949882398952} | train loss {'Reaction outcome loss': 0.8190989051813539, 'Total loss': 0.8190989051813539}
2022-11-18 02:47:05,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:05,926 INFO:     Epoch: 22
2022-11-18 02:47:06,772 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8663876070217653, 'Total loss': 0.8663876070217653} | train loss {'Reaction outcome loss': 0.8222120574370086, 'Total loss': 0.8222120574370086}
2022-11-18 02:47:06,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:06,773 INFO:     Epoch: 23
2022-11-18 02:47:07,625 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8500052128325809, 'Total loss': 0.8500052128325809} | train loss {'Reaction outcome loss': 0.8197976878056159, 'Total loss': 0.8197976878056159}
2022-11-18 02:47:07,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:07,625 INFO:     Epoch: 24
2022-11-18 02:47:08,428 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8376905728470195, 'Total loss': 0.8376905728470195} | train loss {'Reaction outcome loss': 0.8275564384122609, 'Total loss': 0.8275564384122609}
2022-11-18 02:47:08,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:08,428 INFO:     Epoch: 25
2022-11-18 02:47:09,216 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8481590327891436, 'Total loss': 0.8481590327891436} | train loss {'Reaction outcome loss': 0.8096870507909218, 'Total loss': 0.8096870507909218}
2022-11-18 02:47:09,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:09,216 INFO:     Epoch: 26
2022-11-18 02:47:10,035 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.831236105073582, 'Total loss': 0.831236105073582} | train loss {'Reaction outcome loss': 0.8224048054652658, 'Total loss': 0.8224048054652658}
2022-11-18 02:47:10,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:10,036 INFO:     Epoch: 27
2022-11-18 02:47:10,881 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.833443973552097, 'Total loss': 0.833443973552097} | train loss {'Reaction outcome loss': 0.8099094624461433, 'Total loss': 0.8099094624461433}
2022-11-18 02:47:10,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:10,882 INFO:     Epoch: 28
2022-11-18 02:47:11,691 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8417732884938066, 'Total loss': 0.8417732884938066} | train loss {'Reaction outcome loss': 0.8110713959946806, 'Total loss': 0.8110713959946806}
2022-11-18 02:47:11,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:11,691 INFO:     Epoch: 29
2022-11-18 02:47:12,485 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8469991765239022, 'Total loss': 0.8469991765239022} | train loss {'Reaction outcome loss': 0.814660164267428, 'Total loss': 0.814660164267428}
2022-11-18 02:47:12,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:12,485 INFO:     Epoch: 30
2022-11-18 02:47:13,326 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8495696701786735, 'Total loss': 0.8495696701786735} | train loss {'Reaction outcome loss': 0.8107062024988143, 'Total loss': 0.8107062024988143}
2022-11-18 02:47:13,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:13,326 INFO:     Epoch: 31
2022-11-18 02:47:14,124 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8461355363780801, 'Total loss': 0.8461355363780801} | train loss {'Reaction outcome loss': 0.8121425671133435, 'Total loss': 0.8121425671133435}
2022-11-18 02:47:14,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:14,126 INFO:     Epoch: 32
2022-11-18 02:47:14,961 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8481229638511484, 'Total loss': 0.8481229638511484} | train loss {'Reaction outcome loss': 0.8109154349027073, 'Total loss': 0.8109154349027073}
2022-11-18 02:47:14,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:14,961 INFO:     Epoch: 33
2022-11-18 02:47:15,803 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8382242132316936, 'Total loss': 0.8382242132316936} | train loss {'Reaction outcome loss': 0.8124129716683979, 'Total loss': 0.8124129716683979}
2022-11-18 02:47:15,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:15,803 INFO:     Epoch: 34
2022-11-18 02:47:16,597 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8388473825021223, 'Total loss': 0.8388473825021223} | train loss {'Reaction outcome loss': 0.8207527692260047, 'Total loss': 0.8207527692260047}
2022-11-18 02:47:16,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:16,598 INFO:     Epoch: 35
2022-11-18 02:47:17,385 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8492280434478413, 'Total loss': 0.8492280434478413} | train loss {'Reaction outcome loss': 0.8171507015160704, 'Total loss': 0.8171507015160704}
2022-11-18 02:47:17,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:17,385 INFO:     Epoch: 36
2022-11-18 02:47:18,147 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8237474235621366, 'Total loss': 0.8237474235621366} | train loss {'Reaction outcome loss': 0.817522092628093, 'Total loss': 0.817522092628093}
2022-11-18 02:47:18,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:18,148 INFO:     Epoch: 37
2022-11-18 02:47:18,919 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8323082273656671, 'Total loss': 0.8323082273656671} | train loss {'Reaction outcome loss': 0.8173848878034213, 'Total loss': 0.8173848878034213}
2022-11-18 02:47:18,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:18,919 INFO:     Epoch: 38
2022-11-18 02:47:19,710 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8420800282196566, 'Total loss': 0.8420800282196566} | train loss {'Reaction outcome loss': 0.8171552356920744, 'Total loss': 0.8171552356920744}
2022-11-18 02:47:19,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:19,710 INFO:     Epoch: 39
2022-11-18 02:47:20,462 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8520612513477152, 'Total loss': 0.8520612513477152} | train loss {'Reaction outcome loss': 0.8173727291798302, 'Total loss': 0.8173727291798302}
2022-11-18 02:47:20,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:20,463 INFO:     Epoch: 40
2022-11-18 02:47:21,243 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8439823253588243, 'Total loss': 0.8439823253588243} | train loss {'Reaction outcome loss': 0.810893539233729, 'Total loss': 0.810893539233729}
2022-11-18 02:47:21,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:21,244 INFO:     Epoch: 41
2022-11-18 02:47:22,095 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8214470534162088, 'Total loss': 0.8214470534162088} | train loss {'Reaction outcome loss': 0.8177612526455389, 'Total loss': 0.8177612526455389}
2022-11-18 02:47:22,095 INFO:     Found new best model at epoch 41
2022-11-18 02:47:22,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:22,096 INFO:     Epoch: 42
2022-11-18 02:47:22,910 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8375108533284881, 'Total loss': 0.8375108533284881} | train loss {'Reaction outcome loss': 0.8156032571908434, 'Total loss': 0.8156032571908434}
2022-11-18 02:47:22,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:22,911 INFO:     Epoch: 43
2022-11-18 02:47:23,706 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8317221362482418, 'Total loss': 0.8317221362482418} | train loss {'Reaction outcome loss': 0.8197420188772534, 'Total loss': 0.8197420188772534}
2022-11-18 02:47:23,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:23,706 INFO:     Epoch: 44
2022-11-18 02:47:24,514 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8406896929849278, 'Total loss': 0.8406896929849278} | train loss {'Reaction outcome loss': 0.8121192567502922, 'Total loss': 0.8121192567502922}
2022-11-18 02:47:24,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:24,515 INFO:     Epoch: 45
2022-11-18 02:47:25,325 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8267491026358171, 'Total loss': 0.8267491026358171} | train loss {'Reaction outcome loss': 0.8084230117710979, 'Total loss': 0.8084230117710979}
2022-11-18 02:47:25,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:25,325 INFO:     Epoch: 46
2022-11-18 02:47:26,101 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8520993475209583, 'Total loss': 0.8520993475209583} | train loss {'Reaction outcome loss': 0.8100869294844175, 'Total loss': 0.8100869294844175}
2022-11-18 02:47:26,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:26,102 INFO:     Epoch: 47
2022-11-18 02:47:26,897 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8334915861487389, 'Total loss': 0.8334915861487389} | train loss {'Reaction outcome loss': 0.8113970417484098, 'Total loss': 0.8113970417484098}
2022-11-18 02:47:26,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:26,897 INFO:     Epoch: 48
2022-11-18 02:47:27,670 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8504052636298266, 'Total loss': 0.8504052636298266} | train loss {'Reaction outcome loss': 0.821627885947826, 'Total loss': 0.821627885947826}
2022-11-18 02:47:27,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:27,671 INFO:     Epoch: 49
2022-11-18 02:47:28,457 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8382220430807634, 'Total loss': 0.8382220430807634} | train loss {'Reaction outcome loss': 0.8225671550040303, 'Total loss': 0.8225671550040303}
2022-11-18 02:47:28,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:28,457 INFO:     Epoch: 50
2022-11-18 02:47:29,239 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.82911874150688, 'Total loss': 0.82911874150688} | train loss {'Reaction outcome loss': 0.8134082733438566, 'Total loss': 0.8134082733438566}
2022-11-18 02:47:29,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:29,240 INFO:     Epoch: 51
2022-11-18 02:47:30,051 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8621468699791215, 'Total loss': 0.8621468699791215} | train loss {'Reaction outcome loss': 0.8062843763635226, 'Total loss': 0.8062843763635226}
2022-11-18 02:47:30,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:30,051 INFO:     Epoch: 52
2022-11-18 02:47:30,807 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8532379459251057, 'Total loss': 0.8532379459251057} | train loss {'Reaction outcome loss': 0.8207617159555798, 'Total loss': 0.8207617159555798}
2022-11-18 02:47:30,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:30,807 INFO:     Epoch: 53
2022-11-18 02:47:31,606 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8605289689519189, 'Total loss': 0.8605289689519189} | train loss {'Reaction outcome loss': 0.821595471880214, 'Total loss': 0.821595471880214}
2022-11-18 02:47:31,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:31,606 INFO:     Epoch: 54
2022-11-18 02:47:32,372 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.832115463912487, 'Total loss': 0.832115463912487} | train loss {'Reaction outcome loss': 0.8148306134017372, 'Total loss': 0.8148306134017372}
2022-11-18 02:47:32,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:32,372 INFO:     Epoch: 55
2022-11-18 02:47:33,153 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8372474719177593, 'Total loss': 0.8372474719177593} | train loss {'Reaction outcome loss': 0.8149539992394235, 'Total loss': 0.8149539992394235}
2022-11-18 02:47:33,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:33,155 INFO:     Epoch: 56
2022-11-18 02:47:33,934 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8296237486329946, 'Total loss': 0.8296237486329946} | train loss {'Reaction outcome loss': 0.817764912418991, 'Total loss': 0.817764912418991}
2022-11-18 02:47:33,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:33,935 INFO:     Epoch: 57
2022-11-18 02:47:34,699 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.832236762073907, 'Total loss': 0.832236762073907} | train loss {'Reaction outcome loss': 0.8156822791948974, 'Total loss': 0.8156822791948974}
2022-11-18 02:47:34,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:34,700 INFO:     Epoch: 58
2022-11-18 02:47:35,484 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8273582702333276, 'Total loss': 0.8273582702333276} | train loss {'Reaction outcome loss': 0.8129246683135206, 'Total loss': 0.8129246683135206}
2022-11-18 02:47:35,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:35,485 INFO:     Epoch: 59
2022-11-18 02:47:36,290 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8246024603193457, 'Total loss': 0.8246024603193457} | train loss {'Reaction outcome loss': 0.8095562321394079, 'Total loss': 0.8095562321394079}
2022-11-18 02:47:36,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:36,290 INFO:     Epoch: 60
2022-11-18 02:47:37,065 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8382839350537821, 'Total loss': 0.8382839350537821} | train loss {'Reaction outcome loss': 0.81401953619984, 'Total loss': 0.81401953619984}
2022-11-18 02:47:37,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:37,066 INFO:     Epoch: 61
2022-11-18 02:47:37,863 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8299811407923698, 'Total loss': 0.8299811407923698} | train loss {'Reaction outcome loss': 0.8136993312401327, 'Total loss': 0.8136993312401327}
2022-11-18 02:47:37,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:37,863 INFO:     Epoch: 62
2022-11-18 02:47:38,634 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8772915344346653, 'Total loss': 0.8772915344346653} | train loss {'Reaction outcome loss': 0.8134155021264002, 'Total loss': 0.8134155021264002}
2022-11-18 02:47:38,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:38,634 INFO:     Epoch: 63
2022-11-18 02:47:39,419 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8208944919434461, 'Total loss': 0.8208944919434461} | train loss {'Reaction outcome loss': 0.8115475254985485, 'Total loss': 0.8115475254985485}
2022-11-18 02:47:39,419 INFO:     Found new best model at epoch 63
2022-11-18 02:47:39,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:39,420 INFO:     Epoch: 64
2022-11-18 02:47:40,194 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8247509056871588, 'Total loss': 0.8247509056871588} | train loss {'Reaction outcome loss': 0.8056046878278014, 'Total loss': 0.8056046878278014}
2022-11-18 02:47:40,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:40,195 INFO:     Epoch: 65
2022-11-18 02:47:40,978 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8307215679775585, 'Total loss': 0.8307215679775585} | train loss {'Reaction outcome loss': 0.8062780694922937, 'Total loss': 0.8062780694922937}
2022-11-18 02:47:40,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:40,978 INFO:     Epoch: 66
2022-11-18 02:47:41,741 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8353495706211437, 'Total loss': 0.8353495706211437} | train loss {'Reaction outcome loss': 0.8038257103156947, 'Total loss': 0.8038257103156947}
2022-11-18 02:47:41,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:41,741 INFO:     Epoch: 67
2022-11-18 02:47:42,527 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.821062601425431, 'Total loss': 0.821062601425431} | train loss {'Reaction outcome loss': 0.8039674851213873, 'Total loss': 0.8039674851213873}
2022-11-18 02:47:42,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:42,527 INFO:     Epoch: 68
2022-11-18 02:47:43,302 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8240145126527006, 'Total loss': 0.8240145126527006} | train loss {'Reaction outcome loss': 0.8157598302673231, 'Total loss': 0.8157598302673231}
2022-11-18 02:47:43,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:43,302 INFO:     Epoch: 69
2022-11-18 02:47:44,082 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8477341275323521, 'Total loss': 0.8477341275323521} | train loss {'Reaction outcome loss': 0.806270674655312, 'Total loss': 0.806270674655312}
2022-11-18 02:47:44,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:44,083 INFO:     Epoch: 70
2022-11-18 02:47:44,858 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8366030251437967, 'Total loss': 0.8366030251437967} | train loss {'Reaction outcome loss': 0.8125994670608265, 'Total loss': 0.8125994670608265}
2022-11-18 02:47:44,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:44,860 INFO:     Epoch: 71
2022-11-18 02:47:45,647 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8322453803636811, 'Total loss': 0.8322453803636811} | train loss {'Reaction outcome loss': 0.8061418532118624, 'Total loss': 0.8061418532118624}
2022-11-18 02:47:45,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:45,647 INFO:     Epoch: 72
2022-11-18 02:47:46,427 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8417780047113245, 'Total loss': 0.8417780047113245} | train loss {'Reaction outcome loss': 0.8112077810745008, 'Total loss': 0.8112077810745008}
2022-11-18 02:47:46,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:46,427 INFO:     Epoch: 73
2022-11-18 02:47:47,194 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8412560813806274, 'Total loss': 0.8412560813806274} | train loss {'Reaction outcome loss': 0.8082452996780998, 'Total loss': 0.8082452996780998}
2022-11-18 02:47:47,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:47,194 INFO:     Epoch: 74
2022-11-18 02:47:48,036 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8372075977650556, 'Total loss': 0.8372075977650556} | train loss {'Reaction outcome loss': 0.80446266582017, 'Total loss': 0.80446266582017}
2022-11-18 02:47:48,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:48,037 INFO:     Epoch: 75
2022-11-18 02:47:48,828 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8256884989413348, 'Total loss': 0.8256884989413348} | train loss {'Reaction outcome loss': 0.807064703118946, 'Total loss': 0.807064703118946}
2022-11-18 02:47:48,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:48,828 INFO:     Epoch: 76
2022-11-18 02:47:49,602 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.854842135174708, 'Total loss': 0.854842135174708} | train loss {'Reaction outcome loss': 0.8144172433658168, 'Total loss': 0.8144172433658168}
2022-11-18 02:47:49,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:49,603 INFO:     Epoch: 77
2022-11-18 02:47:50,425 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8246772898869081, 'Total loss': 0.8246772898869081} | train loss {'Reaction outcome loss': 0.8115273909831819, 'Total loss': 0.8115273909831819}
2022-11-18 02:47:50,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:50,425 INFO:     Epoch: 78
2022-11-18 02:47:51,253 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8266296088695526, 'Total loss': 0.8266296088695526} | train loss {'Reaction outcome loss': 0.8026476461696721, 'Total loss': 0.8026476461696721}
2022-11-18 02:47:51,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:51,254 INFO:     Epoch: 79
2022-11-18 02:47:52,039 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.842569769106128, 'Total loss': 0.842569769106128} | train loss {'Reaction outcome loss': 0.8042854436254694, 'Total loss': 0.8042854436254694}
2022-11-18 02:47:52,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:52,039 INFO:     Epoch: 80
2022-11-18 02:47:52,854 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8500732339241288, 'Total loss': 0.8500732339241288} | train loss {'Reaction outcome loss': 0.8073321205643025, 'Total loss': 0.8073321205643025}
2022-11-18 02:47:52,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:52,854 INFO:     Epoch: 81
2022-11-18 02:47:53,640 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8270993368192152, 'Total loss': 0.8270993368192152} | train loss {'Reaction outcome loss': 0.807417798440466, 'Total loss': 0.807417798440466}
2022-11-18 02:47:53,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:53,640 INFO:     Epoch: 82
2022-11-18 02:47:54,443 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8548552895134146, 'Total loss': 0.8548552895134146} | train loss {'Reaction outcome loss': 0.8119416690548422, 'Total loss': 0.8119416690548422}
2022-11-18 02:47:54,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:54,444 INFO:     Epoch: 83
2022-11-18 02:47:55,224 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8218699564987962, 'Total loss': 0.8218699564987962} | train loss {'Reaction outcome loss': 0.8073836870280354, 'Total loss': 0.8073836870280354}
2022-11-18 02:47:55,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:55,225 INFO:     Epoch: 84
2022-11-18 02:47:56,010 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8426889465613798, 'Total loss': 0.8426889465613798} | train loss {'Reaction outcome loss': 0.823487236190904, 'Total loss': 0.823487236190904}
2022-11-18 02:47:56,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:56,010 INFO:     Epoch: 85
2022-11-18 02:47:56,813 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8484282419085503, 'Total loss': 0.8484282419085503} | train loss {'Reaction outcome loss': 0.8145265127965796, 'Total loss': 0.8145265127965796}
2022-11-18 02:47:56,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:56,813 INFO:     Epoch: 86
2022-11-18 02:47:57,634 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8240005990320985, 'Total loss': 0.8240005990320985} | train loss {'Reaction outcome loss': 0.8135773663820043, 'Total loss': 0.8135773663820043}
2022-11-18 02:47:57,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:57,635 INFO:     Epoch: 87
2022-11-18 02:47:58,434 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.842968378554691, 'Total loss': 0.842968378554691} | train loss {'Reaction outcome loss': 0.8082074874084488, 'Total loss': 0.8082074874084488}
2022-11-18 02:47:58,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:58,435 INFO:     Epoch: 88
2022-11-18 02:47:59,244 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8727809895168651, 'Total loss': 0.8727809895168651} | train loss {'Reaction outcome loss': 0.8058441270459519, 'Total loss': 0.8058441270459519}
2022-11-18 02:47:59,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:47:59,244 INFO:     Epoch: 89
2022-11-18 02:48:00,025 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8435352864590558, 'Total loss': 0.8435352864590558} | train loss {'Reaction outcome loss': 0.808821217854496, 'Total loss': 0.808821217854496}
2022-11-18 02:48:00,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:00,025 INFO:     Epoch: 90
2022-11-18 02:48:00,858 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8442869152535092, 'Total loss': 0.8442869152535092} | train loss {'Reaction outcome loss': 0.8041885652945109, 'Total loss': 0.8041885652945109}
2022-11-18 02:48:00,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:00,858 INFO:     Epoch: 91
2022-11-18 02:48:01,648 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.81639871543104, 'Total loss': 0.81639871543104} | train loss {'Reaction outcome loss': 0.809731364853469, 'Total loss': 0.809731364853469}
2022-11-18 02:48:01,648 INFO:     Found new best model at epoch 91
2022-11-18 02:48:01,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:01,649 INFO:     Epoch: 92
2022-11-18 02:48:02,485 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8320589620958675, 'Total loss': 0.8320589620958675} | train loss {'Reaction outcome loss': 0.8142022795764058, 'Total loss': 0.8142022795764058}
2022-11-18 02:48:02,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:02,486 INFO:     Epoch: 93
2022-11-18 02:48:03,285 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8320271542126482, 'Total loss': 0.8320271542126482} | train loss {'Reaction outcome loss': 0.8038686541651907, 'Total loss': 0.8038686541651907}
2022-11-18 02:48:03,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:03,286 INFO:     Epoch: 94
2022-11-18 02:48:04,076 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8432139618830248, 'Total loss': 0.8432139618830248} | train loss {'Reaction outcome loss': 0.816189640446713, 'Total loss': 0.816189640446713}
2022-11-18 02:48:04,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:04,077 INFO:     Epoch: 95
2022-11-18 02:48:04,895 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8284444598989054, 'Total loss': 0.8284444598989054} | train loss {'Reaction outcome loss': 0.8099983201215142, 'Total loss': 0.8099983201215142}
2022-11-18 02:48:04,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:04,895 INFO:     Epoch: 96
2022-11-18 02:48:05,700 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8606586937199939, 'Total loss': 0.8606586937199939} | train loss {'Reaction outcome loss': 0.8101260383360782, 'Total loss': 0.8101260383360782}
2022-11-18 02:48:05,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:05,700 INFO:     Epoch: 97
2022-11-18 02:48:06,496 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.841238787228411, 'Total loss': 0.841238787228411} | train loss {'Reaction outcome loss': 0.8124317584732766, 'Total loss': 0.8124317584732766}
2022-11-18 02:48:06,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:06,496 INFO:     Epoch: 98
2022-11-18 02:48:07,280 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8302602300589735, 'Total loss': 0.8302602300589735} | train loss {'Reaction outcome loss': 0.8054914932381286, 'Total loss': 0.8054914932381286}
2022-11-18 02:48:07,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:07,280 INFO:     Epoch: 99
2022-11-18 02:48:08,115 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8373518166216937, 'Total loss': 0.8373518166216937} | train loss {'Reaction outcome loss': 0.8112575087228767, 'Total loss': 0.8112575087228767}
2022-11-18 02:48:08,115 INFO:     Best model found after epoch 92 of 100.
2022-11-18 02:48:08,115 INFO:   Done with stage: TRAINING
2022-11-18 02:48:08,116 INFO:   Starting stage: EVALUATION
2022-11-18 02:48:08,237 INFO:   Done with stage: EVALUATION
2022-11-18 02:48:08,238 INFO:   Leaving out SEQ value Fold_5
2022-11-18 02:48:08,251 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:48:08,251 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:48:08,923 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:48:08,923 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:48:08,992 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:48:08,992 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:48:08,992 INFO:     No hyperparam tuning for this model
2022-11-18 02:48:08,992 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:48:08,992 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:48:08,993 INFO:     None feature selector for col prot
2022-11-18 02:48:08,993 INFO:     None feature selector for col prot
2022-11-18 02:48:08,993 INFO:     None feature selector for col prot
2022-11-18 02:48:08,994 INFO:     None feature selector for col chem
2022-11-18 02:48:08,994 INFO:     None feature selector for col chem
2022-11-18 02:48:08,994 INFO:     None feature selector for col chem
2022-11-18 02:48:08,994 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:48:08,994 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:48:08,996 INFO:     Number of params in model 168571
2022-11-18 02:48:08,999 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:48:08,999 INFO:   Starting stage: TRAINING
2022-11-18 02:48:09,057 INFO:     Val loss before train {'Reaction outcome loss': 0.9958110024983232, 'Total loss': 0.9958110024983232}
2022-11-18 02:48:09,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:09,057 INFO:     Epoch: 0
2022-11-18 02:48:09,862 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.863500256430019, 'Total loss': 0.863500256430019} | train loss {'Reaction outcome loss': 0.8817447525286964, 'Total loss': 0.8817447525286964}
2022-11-18 02:48:09,862 INFO:     Found new best model at epoch 0
2022-11-18 02:48:09,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:09,863 INFO:     Epoch: 1
2022-11-18 02:48:10,632 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8496655726974661, 'Total loss': 0.8496655726974661} | train loss {'Reaction outcome loss': 0.8567704487184764, 'Total loss': 0.8567704487184764}
2022-11-18 02:48:10,632 INFO:     Found new best model at epoch 1
2022-11-18 02:48:10,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:10,633 INFO:     Epoch: 2
2022-11-18 02:48:11,487 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8578757020560178, 'Total loss': 0.8578757020560178} | train loss {'Reaction outcome loss': 0.8502460602324019, 'Total loss': 0.8502460602324019}
2022-11-18 02:48:11,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:11,487 INFO:     Epoch: 3
2022-11-18 02:48:12,310 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8416880016977136, 'Total loss': 0.8416880016977136} | train loss {'Reaction outcome loss': 0.8451653948196998, 'Total loss': 0.8451653948196998}
2022-11-18 02:48:12,311 INFO:     Found new best model at epoch 3
2022-11-18 02:48:12,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:12,312 INFO:     Epoch: 4
2022-11-18 02:48:13,112 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8340452259237116, 'Total loss': 0.8340452259237116} | train loss {'Reaction outcome loss': 0.8351248975405808, 'Total loss': 0.8351248975405808}
2022-11-18 02:48:13,112 INFO:     Found new best model at epoch 4
2022-11-18 02:48:13,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:13,113 INFO:     Epoch: 5
2022-11-18 02:48:13,933 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8151590126481923, 'Total loss': 0.8151590126481923} | train loss {'Reaction outcome loss': 0.8327921761976562, 'Total loss': 0.8327921761976562}
2022-11-18 02:48:13,933 INFO:     Found new best model at epoch 5
2022-11-18 02:48:13,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:13,934 INFO:     Epoch: 6
2022-11-18 02:48:14,748 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8048662387511947, 'Total loss': 0.8048662387511947} | train loss {'Reaction outcome loss': 0.8359857730054663, 'Total loss': 0.8359857730054663}
2022-11-18 02:48:14,748 INFO:     Found new best model at epoch 6
2022-11-18 02:48:14,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:14,749 INFO:     Epoch: 7
2022-11-18 02:48:15,551 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8355523618784818, 'Total loss': 0.8355523618784818} | train loss {'Reaction outcome loss': 0.8372389878097334, 'Total loss': 0.8372389878097334}
2022-11-18 02:48:15,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:15,553 INFO:     Epoch: 8
2022-11-18 02:48:16,317 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8180491707541726, 'Total loss': 0.8180491707541726} | train loss {'Reaction outcome loss': 0.8274844407070021, 'Total loss': 0.8274844407070021}
2022-11-18 02:48:16,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:16,317 INFO:     Epoch: 9
2022-11-18 02:48:17,098 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8037084036252715, 'Total loss': 0.8037084036252715} | train loss {'Reaction outcome loss': 0.8305451282364155, 'Total loss': 0.8305451282364155}
2022-11-18 02:48:17,098 INFO:     Found new best model at epoch 9
2022-11-18 02:48:17,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:17,099 INFO:     Epoch: 10
2022-11-18 02:48:17,902 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8330089070580222, 'Total loss': 0.8330089070580222} | train loss {'Reaction outcome loss': 0.828348440679944, 'Total loss': 0.828348440679944}
2022-11-18 02:48:17,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:17,903 INFO:     Epoch: 11
2022-11-18 02:48:18,675 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8021986037492752, 'Total loss': 0.8021986037492752} | train loss {'Reaction outcome loss': 0.8324217218377812, 'Total loss': 0.8324217218377812}
2022-11-18 02:48:18,675 INFO:     Found new best model at epoch 11
2022-11-18 02:48:18,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:18,676 INFO:     Epoch: 12
2022-11-18 02:48:19,477 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8106515353376215, 'Total loss': 0.8106515353376215} | train loss {'Reaction outcome loss': 0.8279855104110502, 'Total loss': 0.8279855104110502}
2022-11-18 02:48:19,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:19,477 INFO:     Epoch: 13
2022-11-18 02:48:20,256 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8027035431428389, 'Total loss': 0.8027035431428389} | train loss {'Reaction outcome loss': 0.831316231716017, 'Total loss': 0.831316231716017}
2022-11-18 02:48:20,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:20,256 INFO:     Epoch: 14
2022-11-18 02:48:21,048 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8118540353395722, 'Total loss': 0.8118540353395722} | train loss {'Reaction outcome loss': 0.8259990662939636, 'Total loss': 0.8259990662939636}
2022-11-18 02:48:21,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:21,048 INFO:     Epoch: 15
2022-11-18 02:48:21,803 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8113112693483179, 'Total loss': 0.8113112693483179} | train loss {'Reaction outcome loss': 0.8277118834044769, 'Total loss': 0.8277118834044769}
2022-11-18 02:48:21,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:21,804 INFO:     Epoch: 16
2022-11-18 02:48:22,570 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8227515925060619, 'Total loss': 0.8227515925060619} | train loss {'Reaction outcome loss': 0.8290799728289306, 'Total loss': 0.8290799728289306}
2022-11-18 02:48:22,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:22,570 INFO:     Epoch: 17
2022-11-18 02:48:23,334 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8109706931493499, 'Total loss': 0.8109706931493499} | train loss {'Reaction outcome loss': 0.8250764705361384, 'Total loss': 0.8250764705361384}
2022-11-18 02:48:23,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:23,334 INFO:     Epoch: 18
2022-11-18 02:48:24,141 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8071863319386136, 'Total loss': 0.8071863319386136} | train loss {'Reaction outcome loss': 0.8240459810203387, 'Total loss': 0.8240459810203387}
2022-11-18 02:48:24,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:24,142 INFO:     Epoch: 19
2022-11-18 02:48:24,886 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8162404901602052, 'Total loss': 0.8162404901602052} | train loss {'Reaction outcome loss': 0.8225239938207967, 'Total loss': 0.8225239938207967}
2022-11-18 02:48:24,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:24,887 INFO:     Epoch: 20
2022-11-18 02:48:25,653 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.83261969008229, 'Total loss': 0.83261969008229} | train loss {'Reaction outcome loss': 0.8234353527607705, 'Total loss': 0.8234353527607705}
2022-11-18 02:48:25,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:25,653 INFO:     Epoch: 21
2022-11-18 02:48:26,434 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7985934432257306, 'Total loss': 0.7985934432257306} | train loss {'Reaction outcome loss': 0.8346943357574795, 'Total loss': 0.8346943357574795}
2022-11-18 02:48:26,434 INFO:     Found new best model at epoch 21
2022-11-18 02:48:26,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:26,435 INFO:     Epoch: 22
2022-11-18 02:48:27,209 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8028972013430162, 'Total loss': 0.8028972013430162} | train loss {'Reaction outcome loss': 0.827290875347037, 'Total loss': 0.827290875347037}
2022-11-18 02:48:27,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:27,210 INFO:     Epoch: 23
2022-11-18 02:48:27,974 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7952062067660418, 'Total loss': 0.7952062067660418} | train loss {'Reaction outcome loss': 0.8357084903881135, 'Total loss': 0.8357084903881135}
2022-11-18 02:48:27,974 INFO:     Found new best model at epoch 23
2022-11-18 02:48:27,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:27,975 INFO:     Epoch: 24
2022-11-18 02:48:28,742 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8381505046378482, 'Total loss': 0.8381505046378482} | train loss {'Reaction outcome loss': 0.8242390479002646, 'Total loss': 0.8242390479002646}
2022-11-18 02:48:28,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:28,742 INFO:     Epoch: 25
2022-11-18 02:48:29,500 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8018267493356358, 'Total loss': 0.8018267493356358} | train loss {'Reaction outcome loss': 0.8199363417832958, 'Total loss': 0.8199363417832958}
2022-11-18 02:48:29,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:29,500 INFO:     Epoch: 26
2022-11-18 02:48:30,274 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8215112848715349, 'Total loss': 0.8215112848715349} | train loss {'Reaction outcome loss': 0.8332838086705459, 'Total loss': 0.8332838086705459}
2022-11-18 02:48:30,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:30,274 INFO:     Epoch: 27
2022-11-18 02:48:31,081 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8221171207048676, 'Total loss': 0.8221171207048676} | train loss {'Reaction outcome loss': 0.8239618812495397, 'Total loss': 0.8239618812495397}
2022-11-18 02:48:31,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:31,081 INFO:     Epoch: 28
2022-11-18 02:48:31,838 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8014633371071382, 'Total loss': 0.8014633371071382} | train loss {'Reaction outcome loss': 0.8292843728412983, 'Total loss': 0.8292843728412983}
2022-11-18 02:48:31,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:31,838 INFO:     Epoch: 29
2022-11-18 02:48:32,625 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8036450818181038, 'Total loss': 0.8036450818181038} | train loss {'Reaction outcome loss': 0.8239852130895684, 'Total loss': 0.8239852130895684}
2022-11-18 02:48:32,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:32,626 INFO:     Epoch: 30
2022-11-18 02:48:33,391 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8027703924612566, 'Total loss': 0.8027703924612566} | train loss {'Reaction outcome loss': 0.8280989328617991, 'Total loss': 0.8280989328617991}
2022-11-18 02:48:33,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:33,392 INFO:     Epoch: 31
2022-11-18 02:48:34,168 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8012092817913402, 'Total loss': 0.8012092817913402} | train loss {'Reaction outcome loss': 0.8225849682714051, 'Total loss': 0.8225849682714051}
2022-11-18 02:48:34,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:34,169 INFO:     Epoch: 32
2022-11-18 02:48:34,961 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8631307713010095, 'Total loss': 0.8631307713010095} | train loss {'Reaction outcome loss': 0.8268489355017782, 'Total loss': 0.8268489355017782}
2022-11-18 02:48:34,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:34,961 INFO:     Epoch: 33
2022-11-18 02:48:35,754 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7963746352629228, 'Total loss': 0.7963746352629228} | train loss {'Reaction outcome loss': 0.8374371681860101, 'Total loss': 0.8374371681860101}
2022-11-18 02:48:35,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:35,754 INFO:     Epoch: 34
2022-11-18 02:48:36,537 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7965672205794941, 'Total loss': 0.7965672205794941} | train loss {'Reaction outcome loss': 0.8249035639017217, 'Total loss': 0.8249035639017217}
2022-11-18 02:48:36,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:36,537 INFO:     Epoch: 35
2022-11-18 02:48:37,325 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7946429760618643, 'Total loss': 0.7946429760618643} | train loss {'Reaction outcome loss': 0.8201059335880434, 'Total loss': 0.8201059335880434}
2022-11-18 02:48:37,326 INFO:     Found new best model at epoch 35
2022-11-18 02:48:37,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:37,327 INFO:     Epoch: 36
2022-11-18 02:48:38,126 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8083764883604917, 'Total loss': 0.8083764883604917} | train loss {'Reaction outcome loss': 0.824084084284933, 'Total loss': 0.824084084284933}
2022-11-18 02:48:38,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:38,126 INFO:     Epoch: 37
2022-11-18 02:48:38,877 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8035335513678464, 'Total loss': 0.8035335513678464} | train loss {'Reaction outcome loss': 0.8265592799736903, 'Total loss': 0.8265592799736903}
2022-11-18 02:48:38,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:38,877 INFO:     Epoch: 38
2022-11-18 02:48:39,643 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8148796409368515, 'Total loss': 0.8148796409368515} | train loss {'Reaction outcome loss': 0.8234255867237262, 'Total loss': 0.8234255867237262}
2022-11-18 02:48:39,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:39,643 INFO:     Epoch: 39
2022-11-18 02:48:40,452 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8195503482764418, 'Total loss': 0.8195503482764418} | train loss {'Reaction outcome loss': 0.8320521562688263, 'Total loss': 0.8320521562688263}
2022-11-18 02:48:40,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:40,452 INFO:     Epoch: 40
2022-11-18 02:48:41,236 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8322463055903261, 'Total loss': 0.8322463055903261} | train loss {'Reaction outcome loss': 0.8283573696729143, 'Total loss': 0.8283573696729143}
2022-11-18 02:48:41,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:41,236 INFO:     Epoch: 41
2022-11-18 02:48:42,015 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7926021340218458, 'Total loss': 0.7926021340218458} | train loss {'Reaction outcome loss': 0.8305796400496834, 'Total loss': 0.8305796400496834}
2022-11-18 02:48:42,015 INFO:     Found new best model at epoch 41
2022-11-18 02:48:42,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:42,016 INFO:     Epoch: 42
2022-11-18 02:48:42,809 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8040001703934236, 'Total loss': 0.8040001703934236} | train loss {'Reaction outcome loss': 0.8325382636384926, 'Total loss': 0.8325382636384926}
2022-11-18 02:48:42,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:42,809 INFO:     Epoch: 43
2022-11-18 02:48:43,592 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7934479842131789, 'Total loss': 0.7934479842131789} | train loss {'Reaction outcome loss': 0.8277386717709453, 'Total loss': 0.8277386717709453}
2022-11-18 02:48:43,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:43,593 INFO:     Epoch: 44
2022-11-18 02:48:44,356 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8081273165616122, 'Total loss': 0.8081273165616122} | train loss {'Reaction outcome loss': 0.8359881966461536, 'Total loss': 0.8359881966461536}
2022-11-18 02:48:44,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:44,356 INFO:     Epoch: 45
2022-11-18 02:48:45,134 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8003654330968857, 'Total loss': 0.8003654330968857} | train loss {'Reaction outcome loss': 0.8272415544641646, 'Total loss': 0.8272415544641646}
2022-11-18 02:48:45,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:45,135 INFO:     Epoch: 46
2022-11-18 02:48:45,930 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7973813631317832, 'Total loss': 0.7973813631317832} | train loss {'Reaction outcome loss': 0.8222270022761001, 'Total loss': 0.8222270022761001}
2022-11-18 02:48:45,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:45,931 INFO:     Epoch: 47
2022-11-18 02:48:46,709 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7994446185502139, 'Total loss': 0.7994446185502139} | train loss {'Reaction outcome loss': 0.825956742893829, 'Total loss': 0.825956742893829}
2022-11-18 02:48:46,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:46,710 INFO:     Epoch: 48
2022-11-18 02:48:47,501 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.826375889507207, 'Total loss': 0.826375889507207} | train loss {'Reaction outcome loss': 0.8219517806454407, 'Total loss': 0.8219517806454407}
2022-11-18 02:48:47,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:47,503 INFO:     Epoch: 49
2022-11-18 02:48:48,295 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8014506406404756, 'Total loss': 0.8014506406404756} | train loss {'Reaction outcome loss': 0.8208736665094429, 'Total loss': 0.8208736665094429}
2022-11-18 02:48:48,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:48,295 INFO:     Epoch: 50
2022-11-18 02:48:49,077 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8035515255548737, 'Total loss': 0.8035515255548737} | train loss {'Reaction outcome loss': 0.8239480962878779, 'Total loss': 0.8239480962878779}
2022-11-18 02:48:49,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:49,077 INFO:     Epoch: 51
2022-11-18 02:48:49,828 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7961985685608604, 'Total loss': 0.7961985685608604} | train loss {'Reaction outcome loss': 0.8327577817536559, 'Total loss': 0.8327577817536559}
2022-11-18 02:48:49,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:49,828 INFO:     Epoch: 52
2022-11-18 02:48:50,589 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8290814635428515, 'Total loss': 0.8290814635428515} | train loss {'Reaction outcome loss': 0.8271615070852674, 'Total loss': 0.8271615070852674}
2022-11-18 02:48:50,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:50,589 INFO:     Epoch: 53
2022-11-18 02:48:51,421 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8323590023951097, 'Total loss': 0.8323590023951097} | train loss {'Reaction outcome loss': 0.8225877166156345, 'Total loss': 0.8225877166156345}
2022-11-18 02:48:51,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:51,421 INFO:     Epoch: 54
2022-11-18 02:48:52,221 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8035988408056173, 'Total loss': 0.8035988408056173} | train loss {'Reaction outcome loss': 0.8270416234427618, 'Total loss': 0.8270416234427618}
2022-11-18 02:48:52,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:52,221 INFO:     Epoch: 55
2022-11-18 02:48:53,040 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7932636006311937, 'Total loss': 0.7932636006311937} | train loss {'Reaction outcome loss': 0.828056092445667, 'Total loss': 0.828056092445667}
2022-11-18 02:48:53,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:53,041 INFO:     Epoch: 56
2022-11-18 02:48:53,854 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8198330510746349, 'Total loss': 0.8198330510746349} | train loss {'Reaction outcome loss': 0.8214331382681966, 'Total loss': 0.8214331382681966}
2022-11-18 02:48:53,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:53,855 INFO:     Epoch: 57
2022-11-18 02:48:54,628 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8222840374166315, 'Total loss': 0.8222840374166315} | train loss {'Reaction outcome loss': 0.8330029112848676, 'Total loss': 0.8330029112848676}
2022-11-18 02:48:54,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:54,628 INFO:     Epoch: 58
2022-11-18 02:48:55,397 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8048764426599849, 'Total loss': 0.8048764426599849} | train loss {'Reaction outcome loss': 0.8247320111463909, 'Total loss': 0.8247320111463909}
2022-11-18 02:48:55,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:55,397 INFO:     Epoch: 59
2022-11-18 02:48:56,165 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8019282336939465, 'Total loss': 0.8019282336939465} | train loss {'Reaction outcome loss': 0.8233173455183322, 'Total loss': 0.8233173455183322}
2022-11-18 02:48:56,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:56,165 INFO:     Epoch: 60
2022-11-18 02:48:56,961 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8041268214583397, 'Total loss': 0.8041268214583397} | train loss {'Reaction outcome loss': 0.8213113663408921, 'Total loss': 0.8213113663408921}
2022-11-18 02:48:56,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:56,961 INFO:     Epoch: 61
2022-11-18 02:48:57,748 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8072426718744364, 'Total loss': 0.8072426718744364} | train loss {'Reaction outcome loss': 0.8252287225322685, 'Total loss': 0.8252287225322685}
2022-11-18 02:48:57,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:57,749 INFO:     Epoch: 62
2022-11-18 02:48:58,532 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7870980074459856, 'Total loss': 0.7870980074459856} | train loss {'Reaction outcome loss': 0.8208420087813366, 'Total loss': 0.8208420087813366}
2022-11-18 02:48:58,532 INFO:     Found new best model at epoch 62
2022-11-18 02:48:58,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:58,533 INFO:     Epoch: 63
2022-11-18 02:48:59,309 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8090591051361777, 'Total loss': 0.8090591051361777} | train loss {'Reaction outcome loss': 0.8219719673638884, 'Total loss': 0.8219719673638884}
2022-11-18 02:48:59,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:48:59,309 INFO:     Epoch: 64
2022-11-18 02:49:00,112 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7936662449078127, 'Total loss': 0.7936662449078127} | train loss {'Reaction outcome loss': 0.8192147498399864, 'Total loss': 0.8192147498399864}
2022-11-18 02:49:00,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:00,112 INFO:     Epoch: 65
2022-11-18 02:49:00,895 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8591554666107352, 'Total loss': 0.8591554666107352} | train loss {'Reaction outcome loss': 0.8244240869153366, 'Total loss': 0.8244240869153366}
2022-11-18 02:49:00,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:00,896 INFO:     Epoch: 66
2022-11-18 02:49:01,676 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8058095310222019, 'Total loss': 0.8058095310222019} | train loss {'Reaction outcome loss': 0.8251447425438807, 'Total loss': 0.8251447425438807}
2022-11-18 02:49:01,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:01,677 INFO:     Epoch: 67
2022-11-18 02:49:02,460 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8118536783890291, 'Total loss': 0.8118536783890291} | train loss {'Reaction outcome loss': 0.8278598389644855, 'Total loss': 0.8278598389644855}
2022-11-18 02:49:02,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:02,460 INFO:     Epoch: 68
2022-11-18 02:49:03,230 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8191157044334845, 'Total loss': 0.8191157044334845} | train loss {'Reaction outcome loss': 0.818828332671511, 'Total loss': 0.818828332671511}
2022-11-18 02:49:03,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:03,230 INFO:     Epoch: 69
2022-11-18 02:49:04,011 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8135021017356352, 'Total loss': 0.8135021017356352} | train loss {'Reaction outcome loss': 0.8206500875412935, 'Total loss': 0.8206500875412935}
2022-11-18 02:49:04,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:04,011 INFO:     Epoch: 70
2022-11-18 02:49:04,786 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7964986765926535, 'Total loss': 0.7964986765926535} | train loss {'Reaction outcome loss': 0.8285297157793392, 'Total loss': 0.8285297157793392}
2022-11-18 02:49:04,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:04,786 INFO:     Epoch: 71
2022-11-18 02:49:05,564 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8113963068886236, 'Total loss': 0.8113963068886236} | train loss {'Reaction outcome loss': 0.8215590831993321, 'Total loss': 0.8215590831993321}
2022-11-18 02:49:05,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:05,564 INFO:     Epoch: 72
2022-11-18 02:49:06,348 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8061866949905049, 'Total loss': 0.8061866949905049} | train loss {'Reaction outcome loss': 0.8166913069437752, 'Total loss': 0.8166913069437752}
2022-11-18 02:49:06,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:06,350 INFO:     Epoch: 73
2022-11-18 02:49:07,122 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8085525625131347, 'Total loss': 0.8085525625131347} | train loss {'Reaction outcome loss': 0.8234333073954109, 'Total loss': 0.8234333073954109}
2022-11-18 02:49:07,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:07,122 INFO:     Epoch: 74
2022-11-18 02:49:07,905 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7897055331956256, 'Total loss': 0.7897055331956256} | train loss {'Reaction outcome loss': 0.8230608153922355, 'Total loss': 0.8230608153922355}
2022-11-18 02:49:07,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:07,906 INFO:     Epoch: 75
2022-11-18 02:49:08,693 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7939196215434507, 'Total loss': 0.7939196215434507} | train loss {'Reaction outcome loss': 0.8241849281044624, 'Total loss': 0.8241849281044624}
2022-11-18 02:49:08,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:08,693 INFO:     Epoch: 76
2022-11-18 02:49:09,499 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7920297783884135, 'Total loss': 0.7920297783884135} | train loss {'Reaction outcome loss': 0.8225748945585629, 'Total loss': 0.8225748945585629}
2022-11-18 02:49:09,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:09,499 INFO:     Epoch: 77
2022-11-18 02:49:10,316 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8004156987775456, 'Total loss': 0.8004156987775456} | train loss {'Reaction outcome loss': 0.8286230811464642, 'Total loss': 0.8286230811464642}
2022-11-18 02:49:10,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:10,317 INFO:     Epoch: 78
2022-11-18 02:49:11,122 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8137419481169094, 'Total loss': 0.8137419481169094} | train loss {'Reaction outcome loss': 0.8323123281301275, 'Total loss': 0.8323123281301275}
2022-11-18 02:49:11,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:11,123 INFO:     Epoch: 79
2022-11-18 02:49:11,916 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8101527230306105, 'Total loss': 0.8101527230306105} | train loss {'Reaction outcome loss': 0.8275441623892379, 'Total loss': 0.8275441623892379}
2022-11-18 02:49:11,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:11,916 INFO:     Epoch: 80
2022-11-18 02:49:12,724 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7845408571037379, 'Total loss': 0.7845408571037379} | train loss {'Reaction outcome loss': 0.8240446354213514, 'Total loss': 0.8240446354213514}
2022-11-18 02:49:12,724 INFO:     Found new best model at epoch 80
2022-11-18 02:49:12,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:12,725 INFO:     Epoch: 81
2022-11-18 02:49:13,568 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8165933198549531, 'Total loss': 0.8165933198549531} | train loss {'Reaction outcome loss': 0.8332148203965624, 'Total loss': 0.8332148203965624}
2022-11-18 02:49:13,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:13,568 INFO:     Epoch: 82
2022-11-18 02:49:14,352 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.795935296876864, 'Total loss': 0.795935296876864} | train loss {'Reaction outcome loss': 0.8253102120358934, 'Total loss': 0.8253102120358934}
2022-11-18 02:49:14,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:14,352 INFO:     Epoch: 83
2022-11-18 02:49:15,130 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8050540685653687, 'Total loss': 0.8050540685653687} | train loss {'Reaction outcome loss': 0.8223990525311304, 'Total loss': 0.8223990525311304}
2022-11-18 02:49:15,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:15,130 INFO:     Epoch: 84
2022-11-18 02:49:15,910 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7982752722772685, 'Total loss': 0.7982752722772685} | train loss {'Reaction outcome loss': 0.8230685762125953, 'Total loss': 0.8230685762125953}
2022-11-18 02:49:15,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:15,910 INFO:     Epoch: 85
2022-11-18 02:49:16,725 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8697818273847754, 'Total loss': 0.8697818273847754} | train loss {'Reaction outcome loss': 0.8270975009873811, 'Total loss': 0.8270975009873811}
2022-11-18 02:49:16,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:16,725 INFO:     Epoch: 86
2022-11-18 02:49:17,531 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8025003542954271, 'Total loss': 0.8025003542954271} | train loss {'Reaction outcome loss': 0.8237440519728642, 'Total loss': 0.8237440519728642}
2022-11-18 02:49:17,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:17,531 INFO:     Epoch: 87
2022-11-18 02:49:18,328 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8060093054717238, 'Total loss': 0.8060093054717238} | train loss {'Reaction outcome loss': 0.8214149288079033, 'Total loss': 0.8214149288079033}
2022-11-18 02:49:18,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:18,329 INFO:     Epoch: 88
2022-11-18 02:49:19,160 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8038077652454376, 'Total loss': 0.8038077652454376} | train loss {'Reaction outcome loss': 0.8214992273915634, 'Total loss': 0.8214992273915634}
2022-11-18 02:49:19,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:19,160 INFO:     Epoch: 89
2022-11-18 02:49:19,969 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8010402348908511, 'Total loss': 0.8010402348908511} | train loss {'Reaction outcome loss': 0.8264894264671001, 'Total loss': 0.8264894264671001}
2022-11-18 02:49:19,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:19,970 INFO:     Epoch: 90
2022-11-18 02:49:20,785 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7973488264463164, 'Total loss': 0.7973488264463164} | train loss {'Reaction outcome loss': 0.8205304443836212, 'Total loss': 0.8205304443836212}
2022-11-18 02:49:20,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:20,785 INFO:     Epoch: 91
2022-11-18 02:49:21,594 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7906596714800055, 'Total loss': 0.7906596714800055} | train loss {'Reaction outcome loss': 0.8164329030192815, 'Total loss': 0.8164329030192815}
2022-11-18 02:49:21,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:21,594 INFO:     Epoch: 92
2022-11-18 02:49:22,361 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8413429626009681, 'Total loss': 0.8413429626009681} | train loss {'Reaction outcome loss': 0.821941196254873, 'Total loss': 0.821941196254873}
2022-11-18 02:49:22,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:22,361 INFO:     Epoch: 93
2022-11-18 02:49:23,151 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8161874670873989, 'Total loss': 0.8161874670873989} | train loss {'Reaction outcome loss': 0.8227897227293084, 'Total loss': 0.8227897227293084}
2022-11-18 02:49:23,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:23,152 INFO:     Epoch: 94
2022-11-18 02:49:23,958 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8056460144844922, 'Total loss': 0.8056460144844922} | train loss {'Reaction outcome loss': 0.8244825470061438, 'Total loss': 0.8244825470061438}
2022-11-18 02:49:23,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:23,958 INFO:     Epoch: 95
2022-11-18 02:49:24,775 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.83243954655799, 'Total loss': 0.83243954655799} | train loss {'Reaction outcome loss': 0.8276186198116797, 'Total loss': 0.8276186198116797}
2022-11-18 02:49:24,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:24,777 INFO:     Epoch: 96
2022-11-18 02:49:25,579 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.835815357890996, 'Total loss': 0.835815357890996} | train loss {'Reaction outcome loss': 0.8488934599918875, 'Total loss': 0.8488934599918875}
2022-11-18 02:49:25,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:25,579 INFO:     Epoch: 97
2022-11-18 02:49:26,344 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8013247806917537, 'Total loss': 0.8013247806917537} | train loss {'Reaction outcome loss': 0.8302717039942259, 'Total loss': 0.8302717039942259}
2022-11-18 02:49:26,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:26,344 INFO:     Epoch: 98
2022-11-18 02:49:27,142 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8317849412560463, 'Total loss': 0.8317849412560463} | train loss {'Reaction outcome loss': 0.8328030407428741, 'Total loss': 0.8328030407428741}
2022-11-18 02:49:27,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:27,143 INFO:     Epoch: 99
2022-11-18 02:49:27,920 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8036798475818201, 'Total loss': 0.8036798475818201} | train loss {'Reaction outcome loss': 0.8360730611119676, 'Total loss': 0.8360730611119676}
2022-11-18 02:49:27,920 INFO:     Best model found after epoch 81 of 100.
2022-11-18 02:49:27,921 INFO:   Done with stage: TRAINING
2022-11-18 02:49:27,921 INFO:   Starting stage: EVALUATION
2022-11-18 02:49:28,044 INFO:   Done with stage: EVALUATION
2022-11-18 02:49:28,044 INFO:   Leaving out SEQ value Fold_6
2022-11-18 02:49:28,057 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:49:28,057 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:49:28,730 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:49:28,730 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:49:28,799 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:49:28,799 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:49:28,799 INFO:     No hyperparam tuning for this model
2022-11-18 02:49:28,799 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:49:28,799 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:49:28,800 INFO:     None feature selector for col prot
2022-11-18 02:49:28,800 INFO:     None feature selector for col prot
2022-11-18 02:49:28,800 INFO:     None feature selector for col prot
2022-11-18 02:49:28,801 INFO:     None feature selector for col chem
2022-11-18 02:49:28,801 INFO:     None feature selector for col chem
2022-11-18 02:49:28,801 INFO:     None feature selector for col chem
2022-11-18 02:49:28,801 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:49:28,801 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:49:28,803 INFO:     Number of params in model 168571
2022-11-18 02:49:28,806 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:49:28,806 INFO:   Starting stage: TRAINING
2022-11-18 02:49:28,863 INFO:     Val loss before train {'Reaction outcome loss': 1.0393194542689757, 'Total loss': 1.0393194542689757}
2022-11-18 02:49:28,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:28,864 INFO:     Epoch: 0
2022-11-18 02:49:29,675 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8677593469619751, 'Total loss': 0.8677593469619751} | train loss {'Reaction outcome loss': 0.8755894162722172, 'Total loss': 0.8755894162722172}
2022-11-18 02:49:29,675 INFO:     Found new best model at epoch 0
2022-11-18 02:49:29,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:29,676 INFO:     Epoch: 1
2022-11-18 02:49:30,512 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8600021986798807, 'Total loss': 0.8600021986798807} | train loss {'Reaction outcome loss': 0.8432162741739904, 'Total loss': 0.8432162741739904}
2022-11-18 02:49:30,513 INFO:     Found new best model at epoch 1
2022-11-18 02:49:30,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:30,514 INFO:     Epoch: 2
2022-11-18 02:49:31,351 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8649689338423989, 'Total loss': 0.8649689338423989} | train loss {'Reaction outcome loss': 0.8384101716501098, 'Total loss': 0.8384101716501098}
2022-11-18 02:49:31,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:31,351 INFO:     Epoch: 3
2022-11-18 02:49:32,135 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.864465284076604, 'Total loss': 0.864465284076604} | train loss {'Reaction outcome loss': 0.8292648398107098, 'Total loss': 0.8292648398107098}
2022-11-18 02:49:32,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:32,135 INFO:     Epoch: 4
2022-11-18 02:49:32,932 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8389957872304049, 'Total loss': 0.8389957872304049} | train loss {'Reaction outcome loss': 0.8266285488442067, 'Total loss': 0.8266285488442067}
2022-11-18 02:49:32,932 INFO:     Found new best model at epoch 4
2022-11-18 02:49:32,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:32,933 INFO:     Epoch: 5
2022-11-18 02:49:33,770 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8278946937485174, 'Total loss': 0.8278946937485174} | train loss {'Reaction outcome loss': 0.8262193937215113, 'Total loss': 0.8262193937215113}
2022-11-18 02:49:33,770 INFO:     Found new best model at epoch 5
2022-11-18 02:49:33,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:33,771 INFO:     Epoch: 6
2022-11-18 02:49:34,546 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8363038829781793, 'Total loss': 0.8363038829781793} | train loss {'Reaction outcome loss': 0.8225202674586927, 'Total loss': 0.8225202674586927}
2022-11-18 02:49:34,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:34,547 INFO:     Epoch: 7
2022-11-18 02:49:35,336 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8409623192115263, 'Total loss': 0.8409623192115263} | train loss {'Reaction outcome loss': 0.8157829821350113, 'Total loss': 0.8157829821350113}
2022-11-18 02:49:35,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:35,337 INFO:     Epoch: 8
2022-11-18 02:49:36,112 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8450022150169719, 'Total loss': 0.8450022150169719} | train loss {'Reaction outcome loss': 0.8182490339442607, 'Total loss': 0.8182490339442607}
2022-11-18 02:49:36,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:36,112 INFO:     Epoch: 9
2022-11-18 02:49:36,898 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8270568143237721, 'Total loss': 0.8270568143237721} | train loss {'Reaction outcome loss': 0.8151852007835142, 'Total loss': 0.8151852007835142}
2022-11-18 02:49:36,899 INFO:     Found new best model at epoch 9
2022-11-18 02:49:36,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:36,900 INFO:     Epoch: 10
2022-11-18 02:49:37,678 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8351713324135001, 'Total loss': 0.8351713324135001} | train loss {'Reaction outcome loss': 0.8111327636626459, 'Total loss': 0.8111327636626459}
2022-11-18 02:49:37,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:37,679 INFO:     Epoch: 11
2022-11-18 02:49:38,445 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.822704557668079, 'Total loss': 0.822704557668079} | train loss {'Reaction outcome loss': 0.8160607371359102, 'Total loss': 0.8160607371359102}
2022-11-18 02:49:38,446 INFO:     Found new best model at epoch 11
2022-11-18 02:49:38,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:38,447 INFO:     Epoch: 12
2022-11-18 02:49:39,236 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8195964084430174, 'Total loss': 0.8195964084430174} | train loss {'Reaction outcome loss': 0.8087809856740698, 'Total loss': 0.8087809856740698}
2022-11-18 02:49:39,236 INFO:     Found new best model at epoch 12
2022-11-18 02:49:39,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:39,237 INFO:     Epoch: 13
2022-11-18 02:49:40,014 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8256567371162501, 'Total loss': 0.8256567371162501} | train loss {'Reaction outcome loss': 0.8165547179598962, 'Total loss': 0.8165547179598962}
2022-11-18 02:49:40,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:40,015 INFO:     Epoch: 14
2022-11-18 02:49:40,817 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8623176907951181, 'Total loss': 0.8623176907951181} | train loss {'Reaction outcome loss': 0.810173039114283, 'Total loss': 0.810173039114283}
2022-11-18 02:49:40,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:40,817 INFO:     Epoch: 15
2022-11-18 02:49:41,655 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8285128061066974, 'Total loss': 0.8285128061066974} | train loss {'Reaction outcome loss': 0.8122331873784142, 'Total loss': 0.8122331873784142}
2022-11-18 02:49:41,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:41,656 INFO:     Epoch: 16
2022-11-18 02:49:42,453 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8339917097579349, 'Total loss': 0.8339917097579349} | train loss {'Reaction outcome loss': 0.8123272163493018, 'Total loss': 0.8123272163493018}
2022-11-18 02:49:42,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:42,454 INFO:     Epoch: 17
2022-11-18 02:49:43,268 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8296791531822898, 'Total loss': 0.8296791531822898} | train loss {'Reaction outcome loss': 0.8109446828884463, 'Total loss': 0.8109446828884463}
2022-11-18 02:49:43,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:43,269 INFO:     Epoch: 18
2022-11-18 02:49:44,105 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8332279060374607, 'Total loss': 0.8332279060374607} | train loss {'Reaction outcome loss': 0.8078234326695243, 'Total loss': 0.8078234326695243}
2022-11-18 02:49:44,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:44,105 INFO:     Epoch: 19
2022-11-18 02:49:44,886 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8314150409264998, 'Total loss': 0.8314150409264998} | train loss {'Reaction outcome loss': 0.8087137093947779, 'Total loss': 0.8087137093947779}
2022-11-18 02:49:44,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:44,887 INFO:     Epoch: 20
2022-11-18 02:49:45,655 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8335675204342062, 'Total loss': 0.8335675204342062} | train loss {'Reaction outcome loss': 0.8102751826086352, 'Total loss': 0.8102751826086352}
2022-11-18 02:49:45,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:45,655 INFO:     Epoch: 21
2022-11-18 02:49:46,473 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8581349578770724, 'Total loss': 0.8581349578770724} | train loss {'Reaction outcome loss': 0.8111068408095068, 'Total loss': 0.8111068408095068}
2022-11-18 02:49:46,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:46,473 INFO:     Epoch: 22
2022-11-18 02:49:47,250 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8287980156865987, 'Total loss': 0.8287980156865987} | train loss {'Reaction outcome loss': 0.8108914953566366, 'Total loss': 0.8108914953566366}
2022-11-18 02:49:47,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:47,250 INFO:     Epoch: 23
2022-11-18 02:49:48,075 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8240961026061665, 'Total loss': 0.8240961026061665} | train loss {'Reaction outcome loss': 0.8042176899410063, 'Total loss': 0.8042176899410063}
2022-11-18 02:49:48,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:48,075 INFO:     Epoch: 24
2022-11-18 02:49:48,854 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8328582427718423, 'Total loss': 0.8328582427718423} | train loss {'Reaction outcome loss': 0.8050816500138852, 'Total loss': 0.8050816500138852}
2022-11-18 02:49:48,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:48,854 INFO:     Epoch: 25
2022-11-18 02:49:49,666 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8330907632004131, 'Total loss': 0.8330907632004131} | train loss {'Reaction outcome loss': 0.8071548369142317, 'Total loss': 0.8071548369142317}
2022-11-18 02:49:49,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:49,668 INFO:     Epoch: 26
2022-11-18 02:49:50,480 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8251047540794719, 'Total loss': 0.8251047540794719} | train loss {'Reaction outcome loss': 0.8066428458738711, 'Total loss': 0.8066428458738711}
2022-11-18 02:49:50,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:50,480 INFO:     Epoch: 27
2022-11-18 02:49:51,318 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8376984609798952, 'Total loss': 0.8376984609798952} | train loss {'Reaction outcome loss': 0.8078009709715843, 'Total loss': 0.8078009709715843}
2022-11-18 02:49:51,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:51,318 INFO:     Epoch: 28
2022-11-18 02:49:52,109 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.838967813686891, 'Total loss': 0.838967813686891} | train loss {'Reaction outcome loss': 0.8044186747602878, 'Total loss': 0.8044186747602878}
2022-11-18 02:49:52,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:52,110 INFO:     Epoch: 29
2022-11-18 02:49:52,924 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8226114599542185, 'Total loss': 0.8226114599542185} | train loss {'Reaction outcome loss': 0.80914799772924, 'Total loss': 0.80914799772924}
2022-11-18 02:49:52,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:52,925 INFO:     Epoch: 30
2022-11-18 02:49:53,752 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.815284403887662, 'Total loss': 0.815284403887662} | train loss {'Reaction outcome loss': 0.8102205124112868, 'Total loss': 0.8102205124112868}
2022-11-18 02:49:53,752 INFO:     Found new best model at epoch 30
2022-11-18 02:49:53,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:53,753 INFO:     Epoch: 31
2022-11-18 02:49:54,541 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8531495021148161, 'Total loss': 0.8531495021148161} | train loss {'Reaction outcome loss': 0.8058781053029722, 'Total loss': 0.8058781053029722}
2022-11-18 02:49:54,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:54,542 INFO:     Epoch: 32
2022-11-18 02:49:55,356 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8201408223672346, 'Total loss': 0.8201408223672346} | train loss {'Reaction outcome loss': 0.8069137088473766, 'Total loss': 0.8069137088473766}
2022-11-18 02:49:55,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:55,356 INFO:     Epoch: 33
2022-11-18 02:49:56,184 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8207200210202824, 'Total loss': 0.8207200210202824} | train loss {'Reaction outcome loss': 0.8053580417988762, 'Total loss': 0.8053580417988762}
2022-11-18 02:49:56,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:56,185 INFO:     Epoch: 34
2022-11-18 02:49:57,031 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8200072598728266, 'Total loss': 0.8200072598728266} | train loss {'Reaction outcome loss': 0.8045840867825093, 'Total loss': 0.8045840867825093}
2022-11-18 02:49:57,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:57,031 INFO:     Epoch: 35
2022-11-18 02:49:57,843 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8219903328201987, 'Total loss': 0.8219903328201987} | train loss {'Reaction outcome loss': 0.8026931207747229, 'Total loss': 0.8026931207747229}
2022-11-18 02:49:57,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:57,843 INFO:     Epoch: 36
2022-11-18 02:49:58,652 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.816184015436606, 'Total loss': 0.816184015436606} | train loss {'Reaction outcome loss': 0.8028189407721642, 'Total loss': 0.8028189407721642}
2022-11-18 02:49:58,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:58,652 INFO:     Epoch: 37
2022-11-18 02:49:59,479 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8311267562887885, 'Total loss': 0.8311267562887885} | train loss {'Reaction outcome loss': 0.8038382039916131, 'Total loss': 0.8038382039916131}
2022-11-18 02:49:59,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:49:59,479 INFO:     Epoch: 38
2022-11-18 02:50:00,254 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8337923410263929, 'Total loss': 0.8337923410263929} | train loss {'Reaction outcome loss': 0.8051497157542936, 'Total loss': 0.8051497157542936}
2022-11-18 02:50:00,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:00,254 INFO:     Epoch: 39
2022-11-18 02:50:01,083 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8133353292942047, 'Total loss': 0.8133353292942047} | train loss {'Reaction outcome loss': 0.8030291049470825, 'Total loss': 0.8030291049470825}
2022-11-18 02:50:01,084 INFO:     Found new best model at epoch 39
2022-11-18 02:50:01,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:01,084 INFO:     Epoch: 40
2022-11-18 02:50:01,930 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.84677297080105, 'Total loss': 0.84677297080105} | train loss {'Reaction outcome loss': 0.8047234614289576, 'Total loss': 0.8047234614289576}
2022-11-18 02:50:01,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:01,930 INFO:     Epoch: 41
2022-11-18 02:50:02,745 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8246290033513849, 'Total loss': 0.8246290033513849} | train loss {'Reaction outcome loss': 0.8047621400365906, 'Total loss': 0.8047621400365906}
2022-11-18 02:50:02,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:02,745 INFO:     Epoch: 42
2022-11-18 02:50:03,553 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8141373998739503, 'Total loss': 0.8141373998739503} | train loss {'Reaction outcome loss': 0.8050855733454227, 'Total loss': 0.8050855733454227}
2022-11-18 02:50:03,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:03,554 INFO:     Epoch: 43
2022-11-18 02:50:04,342 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8300017389384183, 'Total loss': 0.8300017389384183} | train loss {'Reaction outcome loss': 0.8003145904550629, 'Total loss': 0.8003145904550629}
2022-11-18 02:50:04,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:04,342 INFO:     Epoch: 44
2022-11-18 02:50:05,157 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8342165398326787, 'Total loss': 0.8342165398326787} | train loss {'Reaction outcome loss': 0.8036723264282749, 'Total loss': 0.8036723264282749}
2022-11-18 02:50:05,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:05,158 INFO:     Epoch: 45
2022-11-18 02:50:05,961 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8349173692139712, 'Total loss': 0.8349173692139712} | train loss {'Reaction outcome loss': 0.801334438064406, 'Total loss': 0.801334438064406}
2022-11-18 02:50:05,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:05,962 INFO:     Epoch: 46
2022-11-18 02:50:06,731 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8155075690963052, 'Total loss': 0.8155075690963052} | train loss {'Reaction outcome loss': 0.8016711843590583, 'Total loss': 0.8016711843590583}
2022-11-18 02:50:06,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:06,732 INFO:     Epoch: 47
2022-11-18 02:50:07,518 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8189808861775831, 'Total loss': 0.8189808861775831} | train loss {'Reaction outcome loss': 0.799990430594452, 'Total loss': 0.799990430594452}
2022-11-18 02:50:07,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:07,518 INFO:     Epoch: 48
2022-11-18 02:50:08,343 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8282928791913119, 'Total loss': 0.8282928791913119} | train loss {'Reaction outcome loss': 0.802319266022213, 'Total loss': 0.802319266022213}
2022-11-18 02:50:08,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:08,344 INFO:     Epoch: 49
2022-11-18 02:50:09,176 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8309375535358082, 'Total loss': 0.8309375535358082} | train loss {'Reaction outcome loss': 0.8035923196904121, 'Total loss': 0.8035923196904121}
2022-11-18 02:50:09,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:09,177 INFO:     Epoch: 50
2022-11-18 02:50:09,975 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8288148330016569, 'Total loss': 0.8288148330016569} | train loss {'Reaction outcome loss': 0.7995557964088456, 'Total loss': 0.7995557964088456}
2022-11-18 02:50:09,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:09,975 INFO:     Epoch: 51
2022-11-18 02:50:10,816 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.837148364294659, 'Total loss': 0.837148364294659} | train loss {'Reaction outcome loss': 0.8062017051082465, 'Total loss': 0.8062017051082465}
2022-11-18 02:50:10,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:10,816 INFO:     Epoch: 52
2022-11-18 02:50:11,640 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8191653510386293, 'Total loss': 0.8191653510386293} | train loss {'Reaction outcome loss': 0.8030138670677139, 'Total loss': 0.8030138670677139}
2022-11-18 02:50:11,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:11,640 INFO:     Epoch: 53
2022-11-18 02:50:12,482 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8323024579069831, 'Total loss': 0.8323024579069831} | train loss {'Reaction outcome loss': 0.7979753290813777, 'Total loss': 0.7979753290813777}
2022-11-18 02:50:12,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:12,482 INFO:     Epoch: 54
2022-11-18 02:50:13,335 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8422635780139403, 'Total loss': 0.8422635780139403} | train loss {'Reaction outcome loss': 0.8050385486454733, 'Total loss': 0.8050385486454733}
2022-11-18 02:50:13,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:13,335 INFO:     Epoch: 55
2022-11-18 02:50:14,159 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8301851146600463, 'Total loss': 0.8301851146600463} | train loss {'Reaction outcome loss': 0.8008509883957524, 'Total loss': 0.8008509883957524}
2022-11-18 02:50:14,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:14,160 INFO:     Epoch: 56
2022-11-18 02:50:14,994 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.831131016666239, 'Total loss': 0.831131016666239} | train loss {'Reaction outcome loss': 0.8063074828636262, 'Total loss': 0.8063074828636262}
2022-11-18 02:50:14,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:14,994 INFO:     Epoch: 57
2022-11-18 02:50:15,857 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.81621192260222, 'Total loss': 0.81621192260222} | train loss {'Reaction outcome loss': 0.8007907506919676, 'Total loss': 0.8007907506919676}
2022-11-18 02:50:15,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:15,858 INFO:     Epoch: 58
2022-11-18 02:50:16,698 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.828936133872379, 'Total loss': 0.828936133872379} | train loss {'Reaction outcome loss': 0.8028354799795535, 'Total loss': 0.8028354799795535}
2022-11-18 02:50:16,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:16,698 INFO:     Epoch: 59
2022-11-18 02:50:17,511 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8333805420181968, 'Total loss': 0.8333805420181968} | train loss {'Reaction outcome loss': 0.7988323385436689, 'Total loss': 0.7988323385436689}
2022-11-18 02:50:17,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:17,511 INFO:     Epoch: 60
2022-11-18 02:50:18,358 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8622170686721802, 'Total loss': 0.8622170686721802} | train loss {'Reaction outcome loss': 0.8065322380392782, 'Total loss': 0.8065322380392782}
2022-11-18 02:50:18,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:18,358 INFO:     Epoch: 61
2022-11-18 02:50:19,157 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8143281780860641, 'Total loss': 0.8143281780860641} | train loss {'Reaction outcome loss': 0.8082198418917195, 'Total loss': 0.8082198418917195}
2022-11-18 02:50:19,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:19,157 INFO:     Epoch: 62
2022-11-18 02:50:20,000 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8377952954985879, 'Total loss': 0.8377952954985879} | train loss {'Reaction outcome loss': 0.799229959927259, 'Total loss': 0.799229959927259}
2022-11-18 02:50:20,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:20,000 INFO:     Epoch: 63
2022-11-18 02:50:20,808 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8367844223976135, 'Total loss': 0.8367844223976135} | train loss {'Reaction outcome loss': 0.8067739003848645, 'Total loss': 0.8067739003848645}
2022-11-18 02:50:20,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:20,810 INFO:     Epoch: 64
2022-11-18 02:50:21,673 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8419132639061321, 'Total loss': 0.8419132639061321} | train loss {'Reaction outcome loss': 0.8054138932737612, 'Total loss': 0.8054138932737612}
2022-11-18 02:50:21,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:21,674 INFO:     Epoch: 65
2022-11-18 02:50:22,500 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8289434090256691, 'Total loss': 0.8289434090256691} | train loss {'Reaction outcome loss': 0.8048331385418293, 'Total loss': 0.8048331385418293}
2022-11-18 02:50:22,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:22,500 INFO:     Epoch: 66
2022-11-18 02:50:23,319 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8169393254951998, 'Total loss': 0.8169393254951998} | train loss {'Reaction outcome loss': 0.8027748868109719, 'Total loss': 0.8027748868109719}
2022-11-18 02:50:23,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:23,320 INFO:     Epoch: 67
2022-11-18 02:50:24,094 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8172786032611673, 'Total loss': 0.8172786032611673} | train loss {'Reaction outcome loss': 0.80171944645624, 'Total loss': 0.80171944645624}
2022-11-18 02:50:24,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:24,095 INFO:     Epoch: 68
2022-11-18 02:50:24,901 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8270354345440865, 'Total loss': 0.8270354345440865} | train loss {'Reaction outcome loss': 0.802841448134953, 'Total loss': 0.802841448134953}
2022-11-18 02:50:24,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:24,901 INFO:     Epoch: 69
2022-11-18 02:50:25,742 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8321090841835196, 'Total loss': 0.8321090841835196} | train loss {'Reaction outcome loss': 0.8053042633278716, 'Total loss': 0.8053042633278716}
2022-11-18 02:50:25,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:25,742 INFO:     Epoch: 70
2022-11-18 02:50:26,553 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8137743832035498, 'Total loss': 0.8137743832035498} | train loss {'Reaction outcome loss': 0.8025855739270488, 'Total loss': 0.8025855739270488}
2022-11-18 02:50:26,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:26,553 INFO:     Epoch: 71
2022-11-18 02:50:27,337 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8343660181218927, 'Total loss': 0.8343660181218927} | train loss {'Reaction outcome loss': 0.8024939861629279, 'Total loss': 0.8024939861629279}
2022-11-18 02:50:27,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:27,338 INFO:     Epoch: 72
2022-11-18 02:50:28,116 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8379042853008617, 'Total loss': 0.8379042853008617} | train loss {'Reaction outcome loss': 0.8022046449684328, 'Total loss': 0.8022046449684328}
2022-11-18 02:50:28,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:28,116 INFO:     Epoch: 73
2022-11-18 02:50:28,904 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8291820910843936, 'Total loss': 0.8291820910843936} | train loss {'Reaction outcome loss': 0.8005775868171646, 'Total loss': 0.8005775868171646}
2022-11-18 02:50:28,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:28,904 INFO:     Epoch: 74
2022-11-18 02:50:29,682 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8108866621147502, 'Total loss': 0.8108866621147502} | train loss {'Reaction outcome loss': 0.8012899576175597, 'Total loss': 0.8012899576175597}
2022-11-18 02:50:29,682 INFO:     Found new best model at epoch 74
2022-11-18 02:50:29,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:29,683 INFO:     Epoch: 75
2022-11-18 02:50:30,473 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.817120147022334, 'Total loss': 0.817120147022334} | train loss {'Reaction outcome loss': 0.8002037119961554, 'Total loss': 0.8002037119961554}
2022-11-18 02:50:30,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:30,474 INFO:     Epoch: 76
2022-11-18 02:50:31,250 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8311027864163573, 'Total loss': 0.8311027864163573} | train loss {'Reaction outcome loss': 0.804681443278828, 'Total loss': 0.804681443278828}
2022-11-18 02:50:31,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:31,251 INFO:     Epoch: 77
2022-11-18 02:50:32,056 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8207426626573909, 'Total loss': 0.8207426626573909} | train loss {'Reaction outcome loss': 0.805737167957329, 'Total loss': 0.805737167957329}
2022-11-18 02:50:32,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:32,057 INFO:     Epoch: 78
2022-11-18 02:50:32,845 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8094675114209001, 'Total loss': 0.8094675114209001} | train loss {'Reaction outcome loss': 0.7941473637136721, 'Total loss': 0.7941473637136721}
2022-11-18 02:50:32,846 INFO:     Found new best model at epoch 78
2022-11-18 02:50:32,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:32,846 INFO:     Epoch: 79
2022-11-18 02:50:33,633 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8371747705069456, 'Total loss': 0.8371747705069456} | train loss {'Reaction outcome loss': 0.8057572637354175, 'Total loss': 0.8057572637354175}
2022-11-18 02:50:33,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:33,633 INFO:     Epoch: 80
2022-11-18 02:50:34,405 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.858191382478584, 'Total loss': 0.858191382478584} | train loss {'Reaction outcome loss': 0.797441353841174, 'Total loss': 0.797441353841174}
2022-11-18 02:50:34,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:34,405 INFO:     Epoch: 81
2022-11-18 02:50:35,232 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8183641569180922, 'Total loss': 0.8183641569180922} | train loss {'Reaction outcome loss': 0.8019940272694633, 'Total loss': 0.8019940272694633}
2022-11-18 02:50:35,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:35,233 INFO:     Epoch: 82
2022-11-18 02:50:36,036 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8179439340125431, 'Total loss': 0.8179439340125431} | train loss {'Reaction outcome loss': 0.7997714742537467, 'Total loss': 0.7997714742537467}
2022-11-18 02:50:36,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:36,036 INFO:     Epoch: 83
2022-11-18 02:50:36,863 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8258054242892698, 'Total loss': 0.8258054242892698} | train loss {'Reaction outcome loss': 0.8043470195224208, 'Total loss': 0.8043470195224208}
2022-11-18 02:50:36,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:36,863 INFO:     Epoch: 84
2022-11-18 02:50:37,710 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8218310854651711, 'Total loss': 0.8218310854651711} | train loss {'Reaction outcome loss': 0.8085913028447859, 'Total loss': 0.8085913028447859}
2022-11-18 02:50:37,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:37,711 INFO:     Epoch: 85
2022-11-18 02:50:38,529 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.839523771269755, 'Total loss': 0.839523771269755} | train loss {'Reaction outcome loss': 0.8055092394351959, 'Total loss': 0.8055092394351959}
2022-11-18 02:50:38,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:38,529 INFO:     Epoch: 86
2022-11-18 02:50:39,337 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8404508788477291, 'Total loss': 0.8404508788477291} | train loss {'Reaction outcome loss': 0.8046655248730413, 'Total loss': 0.8046655248730413}
2022-11-18 02:50:39,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:39,338 INFO:     Epoch: 87
2022-11-18 02:50:40,139 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8178745006973093, 'Total loss': 0.8178745006973093} | train loss {'Reaction outcome loss': 0.8028601153242972, 'Total loss': 0.8028601153242972}
2022-11-18 02:50:40,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:40,139 INFO:     Epoch: 88
2022-11-18 02:50:41,001 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8199201754548333, 'Total loss': 0.8199201754548333} | train loss {'Reaction outcome loss': 0.7992069309036578, 'Total loss': 0.7992069309036578}
2022-11-18 02:50:41,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:41,001 INFO:     Epoch: 89
2022-11-18 02:50:41,801 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.851327193054286, 'Total loss': 0.851327193054286} | train loss {'Reaction outcome loss': 0.8015715625257261, 'Total loss': 0.8015715625257261}
2022-11-18 02:50:41,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:41,801 INFO:     Epoch: 90
2022-11-18 02:50:42,640 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8186653547666289, 'Total loss': 0.8186653547666289} | train loss {'Reaction outcome loss': 0.804977442588537, 'Total loss': 0.804977442588537}
2022-11-18 02:50:42,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:42,641 INFO:     Epoch: 91
2022-11-18 02:50:43,420 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8251102200963281, 'Total loss': 0.8251102200963281} | train loss {'Reaction outcome loss': 0.7971066236495972, 'Total loss': 0.7971066236495972}
2022-11-18 02:50:43,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:43,421 INFO:     Epoch: 92
2022-11-18 02:50:44,232 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8563543219457973, 'Total loss': 0.8563543219457973} | train loss {'Reaction outcome loss': 0.79584501130927, 'Total loss': 0.79584501130927}
2022-11-18 02:50:44,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:44,233 INFO:     Epoch: 93
2022-11-18 02:50:45,018 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8366928791457956, 'Total loss': 0.8366928791457956} | train loss {'Reaction outcome loss': 0.8011191638727342, 'Total loss': 0.8011191638727342}
2022-11-18 02:50:45,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:45,018 INFO:     Epoch: 94
2022-11-18 02:50:45,811 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8267112530090592, 'Total loss': 0.8267112530090592} | train loss {'Reaction outcome loss': 0.8043119798023854, 'Total loss': 0.8043119798023854}
2022-11-18 02:50:45,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:45,811 INFO:     Epoch: 95
2022-11-18 02:50:46,585 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8273975822058591, 'Total loss': 0.8273975822058591} | train loss {'Reaction outcome loss': 0.7994923935301842, 'Total loss': 0.7994923935301842}
2022-11-18 02:50:46,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:46,586 INFO:     Epoch: 96
2022-11-18 02:50:47,398 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8213059211319144, 'Total loss': 0.8213059211319144} | train loss {'Reaction outcome loss': 0.7991376871303204, 'Total loss': 0.7991376871303204}
2022-11-18 02:50:47,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:47,398 INFO:     Epoch: 97
2022-11-18 02:50:48,200 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8146083720705726, 'Total loss': 0.8146083720705726} | train loss {'Reaction outcome loss': 0.8023943056262308, 'Total loss': 0.8023943056262308}
2022-11-18 02:50:48,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:48,200 INFO:     Epoch: 98
2022-11-18 02:50:48,998 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8175457878546282, 'Total loss': 0.8175457878546282} | train loss {'Reaction outcome loss': 0.7981933173873732, 'Total loss': 0.7981933173873732}
2022-11-18 02:50:48,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:48,998 INFO:     Epoch: 99
2022-11-18 02:50:49,797 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8244313380934976, 'Total loss': 0.8244313380934976} | train loss {'Reaction outcome loss': 0.8039287895925583, 'Total loss': 0.8039287895925583}
2022-11-18 02:50:49,798 INFO:     Best model found after epoch 79 of 100.
2022-11-18 02:50:49,798 INFO:   Done with stage: TRAINING
2022-11-18 02:50:49,798 INFO:   Starting stage: EVALUATION
2022-11-18 02:50:49,915 INFO:   Done with stage: EVALUATION
2022-11-18 02:50:49,915 INFO:   Leaving out SEQ value Fold_7
2022-11-18 02:50:49,928 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:50:49,928 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:50:50,595 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:50:50,595 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:50:50,667 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:50:50,667 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:50:50,667 INFO:     No hyperparam tuning for this model
2022-11-18 02:50:50,667 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:50:50,667 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:50:50,668 INFO:     None feature selector for col prot
2022-11-18 02:50:50,668 INFO:     None feature selector for col prot
2022-11-18 02:50:50,668 INFO:     None feature selector for col prot
2022-11-18 02:50:50,669 INFO:     None feature selector for col chem
2022-11-18 02:50:50,669 INFO:     None feature selector for col chem
2022-11-18 02:50:50,669 INFO:     None feature selector for col chem
2022-11-18 02:50:50,669 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:50:50,669 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:50:50,671 INFO:     Number of params in model 168571
2022-11-18 02:50:50,674 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:50:50,674 INFO:   Starting stage: TRAINING
2022-11-18 02:50:50,732 INFO:     Val loss before train {'Reaction outcome loss': 1.05874342945489, 'Total loss': 1.05874342945489}
2022-11-18 02:50:50,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:50,732 INFO:     Epoch: 0
2022-11-18 02:50:51,543 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8702514144507322, 'Total loss': 0.8702514144507322} | train loss {'Reaction outcome loss': 0.8646205337906656, 'Total loss': 0.8646205337906656}
2022-11-18 02:50:51,544 INFO:     Found new best model at epoch 0
2022-11-18 02:50:51,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:51,545 INFO:     Epoch: 1
2022-11-18 02:50:52,364 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8695893788879568, 'Total loss': 0.8695893788879568} | train loss {'Reaction outcome loss': 0.8372210142342186, 'Total loss': 0.8372210142342186}
2022-11-18 02:50:52,364 INFO:     Found new best model at epoch 1
2022-11-18 02:50:52,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:52,365 INFO:     Epoch: 2
2022-11-18 02:50:53,178 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8951031755317341, 'Total loss': 0.8951031755317341} | train loss {'Reaction outcome loss': 0.8329354337593804, 'Total loss': 0.8329354337593804}
2022-11-18 02:50:53,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:53,178 INFO:     Epoch: 3
2022-11-18 02:50:54,025 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8725732192397118, 'Total loss': 0.8725732192397118} | train loss {'Reaction outcome loss': 0.833278214762568, 'Total loss': 0.833278214762568}
2022-11-18 02:50:54,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:54,025 INFO:     Epoch: 4
2022-11-18 02:50:54,823 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8679669370705431, 'Total loss': 0.8679669370705431} | train loss {'Reaction outcome loss': 0.8288616582690945, 'Total loss': 0.8288616582690945}
2022-11-18 02:50:54,823 INFO:     Found new best model at epoch 4
2022-11-18 02:50:54,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:54,824 INFO:     Epoch: 5
2022-11-18 02:50:55,598 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8756282207640734, 'Total loss': 0.8756282207640734} | train loss {'Reaction outcome loss': 0.8278520709348594, 'Total loss': 0.8278520709348594}
2022-11-18 02:50:55,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:55,598 INFO:     Epoch: 6
2022-11-18 02:50:56,398 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8466119739142332, 'Total loss': 0.8466119739142332} | train loss {'Reaction outcome loss': 0.8195637567685201, 'Total loss': 0.8195637567685201}
2022-11-18 02:50:56,398 INFO:     Found new best model at epoch 6
2022-11-18 02:50:56,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:56,399 INFO:     Epoch: 7
2022-11-18 02:50:57,192 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8460011915727095, 'Total loss': 0.8460011915727095} | train loss {'Reaction outcome loss': 0.8190358820473135, 'Total loss': 0.8190358820473135}
2022-11-18 02:50:57,192 INFO:     Found new best model at epoch 7
2022-11-18 02:50:57,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:57,193 INFO:     Epoch: 8
2022-11-18 02:50:57,963 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8584805063226006, 'Total loss': 0.8584805063226006} | train loss {'Reaction outcome loss': 0.8175836396573285, 'Total loss': 0.8175836396573285}
2022-11-18 02:50:57,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:57,964 INFO:     Epoch: 9
2022-11-18 02:50:58,744 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8487732945518061, 'Total loss': 0.8487732945518061} | train loss {'Reaction outcome loss': 0.8173488136607143, 'Total loss': 0.8173488136607143}
2022-11-18 02:50:58,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:58,744 INFO:     Epoch: 10
2022-11-18 02:50:59,528 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8528705699877306, 'Total loss': 0.8528705699877306} | train loss {'Reaction outcome loss': 0.8145951876937136, 'Total loss': 0.8145951876937136}
2022-11-18 02:50:59,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:50:59,528 INFO:     Epoch: 11
2022-11-18 02:51:00,321 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8463888141241941, 'Total loss': 0.8463888141241941} | train loss {'Reaction outcome loss': 0.8167122972277012, 'Total loss': 0.8167122972277012}
2022-11-18 02:51:00,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:00,322 INFO:     Epoch: 12
2022-11-18 02:51:01,105 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8495061085982756, 'Total loss': 0.8495061085982756} | train loss {'Reaction outcome loss': 0.8168778135950266, 'Total loss': 0.8168778135950266}
2022-11-18 02:51:01,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:01,105 INFO:     Epoch: 13
2022-11-18 02:51:01,888 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.843877533620054, 'Total loss': 0.843877533620054} | train loss {'Reaction outcome loss': 0.8214604685663695, 'Total loss': 0.8214604685663695}
2022-11-18 02:51:01,888 INFO:     Found new best model at epoch 13
2022-11-18 02:51:01,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:01,889 INFO:     Epoch: 14
2022-11-18 02:51:02,679 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8564683375033465, 'Total loss': 0.8564683375033465} | train loss {'Reaction outcome loss': 0.8223280481963988, 'Total loss': 0.8223280481963988}
2022-11-18 02:51:02,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:02,679 INFO:     Epoch: 15
2022-11-18 02:51:03,450 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8541514324870977, 'Total loss': 0.8541514324870977} | train loss {'Reaction outcome loss': 0.818026249225323, 'Total loss': 0.818026249225323}
2022-11-18 02:51:03,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:03,451 INFO:     Epoch: 16
2022-11-18 02:51:04,265 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8572187315333973, 'Total loss': 0.8572187315333973} | train loss {'Reaction outcome loss': 0.8157854725716085, 'Total loss': 0.8157854725716085}
2022-11-18 02:51:04,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:04,266 INFO:     Epoch: 17
2022-11-18 02:51:05,034 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.842966156927022, 'Total loss': 0.842966156927022} | train loss {'Reaction outcome loss': 0.8106691252726775, 'Total loss': 0.8106691252726775}
2022-11-18 02:51:05,034 INFO:     Found new best model at epoch 17
2022-11-18 02:51:05,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:05,035 INFO:     Epoch: 18
2022-11-18 02:51:05,806 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8455361466516148, 'Total loss': 0.8455361466516148} | train loss {'Reaction outcome loss': 0.8147241960652927, 'Total loss': 0.8147241960652927}
2022-11-18 02:51:05,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:05,806 INFO:     Epoch: 19
2022-11-18 02:51:06,575 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8388444402001121, 'Total loss': 0.8388444402001121} | train loss {'Reaction outcome loss': 0.8100220422271774, 'Total loss': 0.8100220422271774}
2022-11-18 02:51:06,575 INFO:     Found new best model at epoch 19
2022-11-18 02:51:06,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:06,576 INFO:     Epoch: 20
2022-11-18 02:51:07,353 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8455788506702944, 'Total loss': 0.8455788506702944} | train loss {'Reaction outcome loss': 0.8108153598993896, 'Total loss': 0.8108153598993896}
2022-11-18 02:51:07,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:07,353 INFO:     Epoch: 21
2022-11-18 02:51:08,142 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8356545879082247, 'Total loss': 0.8356545879082247} | train loss {'Reaction outcome loss': 0.8117799919385177, 'Total loss': 0.8117799919385177}
2022-11-18 02:51:08,142 INFO:     Found new best model at epoch 21
2022-11-18 02:51:08,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:08,143 INFO:     Epoch: 22
2022-11-18 02:51:08,898 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8561133288524367, 'Total loss': 0.8561133288524367} | train loss {'Reaction outcome loss': 0.8109196954169254, 'Total loss': 0.8109196954169254}
2022-11-18 02:51:08,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:08,898 INFO:     Epoch: 23
2022-11-18 02:51:09,670 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8404512865976854, 'Total loss': 0.8404512865976854} | train loss {'Reaction outcome loss': 0.814846954847637, 'Total loss': 0.814846954847637}
2022-11-18 02:51:09,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:09,671 INFO:     Epoch: 24
2022-11-18 02:51:10,460 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8496602136980403, 'Total loss': 0.8496602136980403} | train loss {'Reaction outcome loss': 0.8153553936886884, 'Total loss': 0.8153553936886884}
2022-11-18 02:51:10,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:10,461 INFO:     Epoch: 25
2022-11-18 02:51:11,248 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.828649641437964, 'Total loss': 0.828649641437964} | train loss {'Reaction outcome loss': 0.8178023461870819, 'Total loss': 0.8178023461870819}
2022-11-18 02:51:11,248 INFO:     Found new best model at epoch 25
2022-11-18 02:51:11,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:11,249 INFO:     Epoch: 26
2022-11-18 02:51:12,036 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.842807336287065, 'Total loss': 0.842807336287065} | train loss {'Reaction outcome loss': 0.8144383461851823, 'Total loss': 0.8144383461851823}
2022-11-18 02:51:12,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:12,036 INFO:     Epoch: 27
2022-11-18 02:51:12,822 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8432803546840494, 'Total loss': 0.8432803546840494} | train loss {'Reaction outcome loss': 0.8112167596575702, 'Total loss': 0.8112167596575702}
2022-11-18 02:51:12,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:12,823 INFO:     Epoch: 28
2022-11-18 02:51:13,613 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8403031785379756, 'Total loss': 0.8403031785379756} | train loss {'Reaction outcome loss': 0.8138180975368631, 'Total loss': 0.8138180975368631}
2022-11-18 02:51:13,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:13,614 INFO:     Epoch: 29
2022-11-18 02:51:14,398 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8369868844747543, 'Total loss': 0.8369868844747543} | train loss {'Reaction outcome loss': 0.8146709746677383, 'Total loss': 0.8146709746677383}
2022-11-18 02:51:14,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:14,398 INFO:     Epoch: 30
2022-11-18 02:51:15,202 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8516786762259223, 'Total loss': 0.8516786762259223} | train loss {'Reaction outcome loss': 0.812868154845257, 'Total loss': 0.812868154845257}
2022-11-18 02:51:15,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:15,203 INFO:     Epoch: 31
2022-11-18 02:51:15,978 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8434741442853754, 'Total loss': 0.8434741442853754} | train loss {'Reaction outcome loss': 0.8111587364060676, 'Total loss': 0.8111587364060676}
2022-11-18 02:51:15,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:15,978 INFO:     Epoch: 32
2022-11-18 02:51:16,758 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8567828183824365, 'Total loss': 0.8567828183824365} | train loss {'Reaction outcome loss': 0.8092403893287365, 'Total loss': 0.8092403893287365}
2022-11-18 02:51:16,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:16,758 INFO:     Epoch: 33
2022-11-18 02:51:17,543 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8442714552987706, 'Total loss': 0.8442714552987706} | train loss {'Reaction outcome loss': 0.8100220476567503, 'Total loss': 0.8100220476567503}
2022-11-18 02:51:17,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:17,543 INFO:     Epoch: 34
2022-11-18 02:51:18,333 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8451214513995431, 'Total loss': 0.8451214513995431} | train loss {'Reaction outcome loss': 0.8117610813393766, 'Total loss': 0.8117610813393766}
2022-11-18 02:51:18,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:18,333 INFO:     Epoch: 35
2022-11-18 02:51:19,134 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8475923429835927, 'Total loss': 0.8475923429835927} | train loss {'Reaction outcome loss': 0.8096512650188646, 'Total loss': 0.8096512650188646}
2022-11-18 02:51:19,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:19,135 INFO:     Epoch: 36
2022-11-18 02:51:19,911 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8578130060976202, 'Total loss': 0.8578130060976202} | train loss {'Reaction outcome loss': 0.8244568070902033, 'Total loss': 0.8244568070902033}
2022-11-18 02:51:19,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:19,911 INFO:     Epoch: 37
2022-11-18 02:51:20,705 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.84058578312397, 'Total loss': 0.84058578312397} | train loss {'Reaction outcome loss': 0.8043439398229364, 'Total loss': 0.8043439398229364}
2022-11-18 02:51:20,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:20,705 INFO:     Epoch: 38
2022-11-18 02:51:21,477 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8500973284244537, 'Total loss': 0.8500973284244537} | train loss {'Reaction outcome loss': 0.8111714192247583, 'Total loss': 0.8111714192247583}
2022-11-18 02:51:21,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:21,477 INFO:     Epoch: 39
2022-11-18 02:51:22,276 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8671215420419519, 'Total loss': 0.8671215420419519} | train loss {'Reaction outcome loss': 0.8087873302460441, 'Total loss': 0.8087873302460441}
2022-11-18 02:51:22,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:22,278 INFO:     Epoch: 40
2022-11-18 02:51:23,050 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8514255630699071, 'Total loss': 0.8514255630699071} | train loss {'Reaction outcome loss': 0.8078827777130884, 'Total loss': 0.8078827777130884}
2022-11-18 02:51:23,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:23,050 INFO:     Epoch: 41
2022-11-18 02:51:23,815 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8464743914929304, 'Total loss': 0.8464743914929304} | train loss {'Reaction outcome loss': 0.8077091394889693, 'Total loss': 0.8077091394889693}
2022-11-18 02:51:23,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:23,815 INFO:     Epoch: 42
2022-11-18 02:51:24,605 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.884764126078649, 'Total loss': 0.884764126078649} | train loss {'Reaction outcome loss': 0.814086302692591, 'Total loss': 0.814086302692591}
2022-11-18 02:51:24,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:24,606 INFO:     Epoch: 43
2022-11-18 02:51:25,368 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8351285803047094, 'Total loss': 0.8351285803047094} | train loss {'Reaction outcome loss': 0.8151754667220811, 'Total loss': 0.8151754667220811}
2022-11-18 02:51:25,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:25,368 INFO:     Epoch: 44
2022-11-18 02:51:26,158 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8502796651287512, 'Total loss': 0.8502796651287512} | train loss {'Reaction outcome loss': 0.8064865159843615, 'Total loss': 0.8064865159843615}
2022-11-18 02:51:26,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:26,159 INFO:     Epoch: 45
2022-11-18 02:51:26,934 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8502653376622633, 'Total loss': 0.8502653376622633} | train loss {'Reaction outcome loss': 0.8111070580328041, 'Total loss': 0.8111070580328041}
2022-11-18 02:51:26,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:26,935 INFO:     Epoch: 46
2022-11-18 02:51:27,703 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8704464774240147, 'Total loss': 0.8704464774240147} | train loss {'Reaction outcome loss': 0.8082923045163213, 'Total loss': 0.8082923045163213}
2022-11-18 02:51:27,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:27,703 INFO:     Epoch: 47
2022-11-18 02:51:28,452 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8513851436701688, 'Total loss': 0.8513851436701688} | train loss {'Reaction outcome loss': 0.8044735681914125, 'Total loss': 0.8044735681914125}
2022-11-18 02:51:28,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:28,453 INFO:     Epoch: 48
2022-11-18 02:51:29,246 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8386493345553224, 'Total loss': 0.8386493345553224} | train loss {'Reaction outcome loss': 0.8150451314835413, 'Total loss': 0.8150451314835413}
2022-11-18 02:51:29,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:29,246 INFO:     Epoch: 49
2022-11-18 02:51:30,021 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8608769787983461, 'Total loss': 0.8608769787983461} | train loss {'Reaction outcome loss': 0.8101878443710234, 'Total loss': 0.8101878443710234}
2022-11-18 02:51:30,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:30,021 INFO:     Epoch: 50
2022-11-18 02:51:30,805 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.843217362057079, 'Total loss': 0.843217362057079} | train loss {'Reaction outcome loss': 0.8124267814854379, 'Total loss': 0.8124267814854379}
2022-11-18 02:51:30,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:30,805 INFO:     Epoch: 51
2022-11-18 02:51:31,588 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.83042327653278, 'Total loss': 0.83042327653278} | train loss {'Reaction outcome loss': 0.8148981023896561, 'Total loss': 0.8148981023896561}
2022-11-18 02:51:31,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:31,588 INFO:     Epoch: 52
2022-11-18 02:51:32,377 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8271012489091266, 'Total loss': 0.8271012489091266} | train loss {'Reaction outcome loss': 0.806498369948584, 'Total loss': 0.806498369948584}
2022-11-18 02:51:32,377 INFO:     Found new best model at epoch 52
2022-11-18 02:51:32,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:32,378 INFO:     Epoch: 53
2022-11-18 02:51:33,136 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8382111679423939, 'Total loss': 0.8382111679423939} | train loss {'Reaction outcome loss': 0.8046682199485872, 'Total loss': 0.8046682199485872}
2022-11-18 02:51:33,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:33,136 INFO:     Epoch: 54
2022-11-18 02:51:33,921 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8365591513839635, 'Total loss': 0.8365591513839635} | train loss {'Reaction outcome loss': 0.8062330645920053, 'Total loss': 0.8062330645920053}
2022-11-18 02:51:33,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:33,921 INFO:     Epoch: 55
2022-11-18 02:51:34,706 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8327372595667839, 'Total loss': 0.8327372595667839} | train loss {'Reaction outcome loss': 0.8136292969890935, 'Total loss': 0.8136292969890935}
2022-11-18 02:51:34,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:34,706 INFO:     Epoch: 56
2022-11-18 02:51:35,503 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8336063596335325, 'Total loss': 0.8336063596335325} | train loss {'Reaction outcome loss': 0.815964593819761, 'Total loss': 0.815964593819761}
2022-11-18 02:51:35,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:35,503 INFO:     Epoch: 57
2022-11-18 02:51:36,282 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8345384265888821, 'Total loss': 0.8345384265888821} | train loss {'Reaction outcome loss': 0.815333599986335, 'Total loss': 0.815333599986335}
2022-11-18 02:51:36,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:36,282 INFO:     Epoch: 58
2022-11-18 02:51:37,083 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8470228680155494, 'Total loss': 0.8470228680155494} | train loss {'Reaction outcome loss': 0.8106719005687034, 'Total loss': 0.8106719005687034}
2022-11-18 02:51:37,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:37,084 INFO:     Epoch: 59
2022-11-18 02:51:37,896 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.827856417406689, 'Total loss': 0.827856417406689} | train loss {'Reaction outcome loss': 0.8066964483846296, 'Total loss': 0.8066964483846296}
2022-11-18 02:51:37,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:37,896 INFO:     Epoch: 60
2022-11-18 02:51:38,661 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8289895409887488, 'Total loss': 0.8289895409887488} | train loss {'Reaction outcome loss': 0.8107332552251546, 'Total loss': 0.8107332552251546}
2022-11-18 02:51:38,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:38,661 INFO:     Epoch: 61
2022-11-18 02:51:39,428 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8291284404695034, 'Total loss': 0.8291284404695034} | train loss {'Reaction outcome loss': 0.8078836143499444, 'Total loss': 0.8078836143499444}
2022-11-18 02:51:39,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:39,429 INFO:     Epoch: 62
2022-11-18 02:51:40,209 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.841705556620251, 'Total loss': 0.841705556620251} | train loss {'Reaction outcome loss': 0.8045944980522881, 'Total loss': 0.8045944980522881}
2022-11-18 02:51:40,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:40,209 INFO:     Epoch: 63
2022-11-18 02:51:40,989 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8281693973324515, 'Total loss': 0.8281693973324515} | train loss {'Reaction outcome loss': 0.8132070936413429, 'Total loss': 0.8132070936413429}
2022-11-18 02:51:40,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:40,990 INFO:     Epoch: 64
2022-11-18 02:51:41,777 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.834039877761494, 'Total loss': 0.834039877761494} | train loss {'Reaction outcome loss': 0.8130886622286035, 'Total loss': 0.8130886622286035}
2022-11-18 02:51:41,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:41,778 INFO:     Epoch: 65
2022-11-18 02:51:42,548 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8282971077344634, 'Total loss': 0.8282971077344634} | train loss {'Reaction outcome loss': 0.8097824644945893, 'Total loss': 0.8097824644945893}
2022-11-18 02:51:42,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:42,548 INFO:     Epoch: 66
2022-11-18 02:51:43,316 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8448733504522931, 'Total loss': 0.8448733504522931} | train loss {'Reaction outcome loss': 0.8100058092520788, 'Total loss': 0.8100058092520788}
2022-11-18 02:51:43,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:43,316 INFO:     Epoch: 67
2022-11-18 02:51:44,114 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8338369659402154, 'Total loss': 0.8338369659402154} | train loss {'Reaction outcome loss': 0.8065177413374789, 'Total loss': 0.8065177413374789}
2022-11-18 02:51:44,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:44,115 INFO:     Epoch: 68
2022-11-18 02:51:44,900 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8329052247784354, 'Total loss': 0.8329052247784354} | train loss {'Reaction outcome loss': 0.8125557607484732, 'Total loss': 0.8125557607484732}
2022-11-18 02:51:44,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:44,900 INFO:     Epoch: 69
2022-11-18 02:51:45,647 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8440574549815871, 'Total loss': 0.8440574549815871} | train loss {'Reaction outcome loss': 0.8087841677762236, 'Total loss': 0.8087841677762236}
2022-11-18 02:51:45,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:45,647 INFO:     Epoch: 70
2022-11-18 02:51:46,415 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8298852802677588, 'Total loss': 0.8298852802677588} | train loss {'Reaction outcome loss': 0.8090088254647699, 'Total loss': 0.8090088254647699}
2022-11-18 02:51:46,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:46,416 INFO:     Epoch: 71
2022-11-18 02:51:47,197 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8274535590952093, 'Total loss': 0.8274535590952093} | train loss {'Reaction outcome loss': 0.8099275353225136, 'Total loss': 0.8099275353225136}
2022-11-18 02:51:47,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:47,197 INFO:     Epoch: 72
2022-11-18 02:51:47,987 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8170431730422106, 'Total loss': 0.8170431730422106} | train loss {'Reaction outcome loss': 0.8130697464412041, 'Total loss': 0.8130697464412041}
2022-11-18 02:51:47,987 INFO:     Found new best model at epoch 72
2022-11-18 02:51:47,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:47,988 INFO:     Epoch: 73
2022-11-18 02:51:48,792 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8511904586445201, 'Total loss': 0.8511904586445201} | train loss {'Reaction outcome loss': 0.8050674876944739, 'Total loss': 0.8050674876944739}
2022-11-18 02:51:48,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:48,792 INFO:     Epoch: 74
2022-11-18 02:51:49,570 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8278514993461695, 'Total loss': 0.8278514993461695} | train loss {'Reaction outcome loss': 0.8113423403699388, 'Total loss': 0.8113423403699388}
2022-11-18 02:51:49,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:49,570 INFO:     Epoch: 75
2022-11-18 02:51:50,366 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8296168189157139, 'Total loss': 0.8296168189157139} | train loss {'Reaction outcome loss': 0.8063806727347587, 'Total loss': 0.8063806727347587}
2022-11-18 02:51:50,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:50,366 INFO:     Epoch: 76
2022-11-18 02:51:51,149 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8227587111971595, 'Total loss': 0.8227587111971595} | train loss {'Reaction outcome loss': 0.8091345750368558, 'Total loss': 0.8091345750368558}
2022-11-18 02:51:51,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:51,149 INFO:     Epoch: 77
2022-11-18 02:51:51,921 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8353333317420699, 'Total loss': 0.8353333317420699} | train loss {'Reaction outcome loss': 0.8008646199004612, 'Total loss': 0.8008646199004612}
2022-11-18 02:51:51,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:51,921 INFO:     Epoch: 78
2022-11-18 02:51:52,709 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.837503120303154, 'Total loss': 0.837503120303154} | train loss {'Reaction outcome loss': 0.8104210444066205, 'Total loss': 0.8104210444066205}
2022-11-18 02:51:52,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:52,709 INFO:     Epoch: 79
2022-11-18 02:51:53,515 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8416593467647379, 'Total loss': 0.8416593467647379} | train loss {'Reaction outcome loss': 0.815664314789328, 'Total loss': 0.815664314789328}
2022-11-18 02:51:53,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:53,516 INFO:     Epoch: 80
2022-11-18 02:51:54,299 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.845029013400728, 'Total loss': 0.845029013400728} | train loss {'Reaction outcome loss': 0.8032488969535481, 'Total loss': 0.8032488969535481}
2022-11-18 02:51:54,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:54,300 INFO:     Epoch: 81
2022-11-18 02:51:55,071 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8222714649005369, 'Total loss': 0.8222714649005369} | train loss {'Reaction outcome loss': 0.8163438219773141, 'Total loss': 0.8163438219773141}
2022-11-18 02:51:55,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:55,071 INFO:     Epoch: 82
2022-11-18 02:51:55,850 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8354248865084215, 'Total loss': 0.8354248865084215} | train loss {'Reaction outcome loss': 0.80626088278255, 'Total loss': 0.80626088278255}
2022-11-18 02:51:55,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:55,850 INFO:     Epoch: 83
2022-11-18 02:51:56,642 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8313353955745697, 'Total loss': 0.8313353955745697} | train loss {'Reaction outcome loss': 0.8049530114239527, 'Total loss': 0.8049530114239527}
2022-11-18 02:51:56,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:56,642 INFO:     Epoch: 84
2022-11-18 02:51:57,440 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8533350486646999, 'Total loss': 0.8533350486646999} | train loss {'Reaction outcome loss': 0.8084649722344479, 'Total loss': 0.8084649722344479}
2022-11-18 02:51:57,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:57,441 INFO:     Epoch: 85
2022-11-18 02:51:58,222 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8342368954961951, 'Total loss': 0.8342368954961951} | train loss {'Reaction outcome loss': 0.8129030452807423, 'Total loss': 0.8129030452807423}
2022-11-18 02:51:58,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:58,222 INFO:     Epoch: 86
2022-11-18 02:51:59,014 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8348854211243716, 'Total loss': 0.8348854211243716} | train loss {'Reaction outcome loss': 0.8073169944981332, 'Total loss': 0.8073169944981332}
2022-11-18 02:51:59,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:59,014 INFO:     Epoch: 87
2022-11-18 02:51:59,797 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8211363093419508, 'Total loss': 0.8211363093419508} | train loss {'Reaction outcome loss': 0.8106916450295854, 'Total loss': 0.8106916450295854}
2022-11-18 02:51:59,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:51:59,798 INFO:     Epoch: 88
2022-11-18 02:52:00,621 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8507875935597853, 'Total loss': 0.8507875935597853} | train loss {'Reaction outcome loss': 0.8142582184148703, 'Total loss': 0.8142582184148703}
2022-11-18 02:52:00,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:00,621 INFO:     Epoch: 89
2022-11-18 02:52:01,394 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8329647820104252, 'Total loss': 0.8329647820104252} | train loss {'Reaction outcome loss': 0.8088517894870356, 'Total loss': 0.8088517894870356}
2022-11-18 02:52:01,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:01,394 INFO:     Epoch: 90
2022-11-18 02:52:02,169 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.858046520840038, 'Total loss': 0.858046520840038} | train loss {'Reaction outcome loss': 0.8156832430044166, 'Total loss': 0.8156832430044166}
2022-11-18 02:52:02,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:02,169 INFO:     Epoch: 91
2022-11-18 02:52:02,936 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8576176078482107, 'Total loss': 0.8576176078482107} | train loss {'Reaction outcome loss': 0.8107777625201684, 'Total loss': 0.8107777625201684}
2022-11-18 02:52:02,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:02,937 INFO:     Epoch: 92
2022-11-18 02:52:03,728 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8415057564323599, 'Total loss': 0.8415057564323599} | train loss {'Reaction outcome loss': 0.8142906311552535, 'Total loss': 0.8142906311552535}
2022-11-18 02:52:03,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:03,729 INFO:     Epoch: 93
2022-11-18 02:52:04,518 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8255125812508843, 'Total loss': 0.8255125812508843} | train loss {'Reaction outcome loss': 0.8173062356136106, 'Total loss': 0.8173062356136106}
2022-11-18 02:52:04,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:04,518 INFO:     Epoch: 94
2022-11-18 02:52:05,305 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8501979532566938, 'Total loss': 0.8501979532566938} | train loss {'Reaction outcome loss': 0.809397943408383, 'Total loss': 0.809397943408383}
2022-11-18 02:52:05,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:05,305 INFO:     Epoch: 95
2022-11-18 02:52:06,071 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8261386765675112, 'Total loss': 0.8261386765675112} | train loss {'Reaction outcome loss': 0.8070039866182969, 'Total loss': 0.8070039866182969}
2022-11-18 02:52:06,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:06,071 INFO:     Epoch: 96
2022-11-18 02:52:06,835 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8290752443400297, 'Total loss': 0.8290752443400297} | train loss {'Reaction outcome loss': 0.8095408700979673, 'Total loss': 0.8095408700979673}
2022-11-18 02:52:06,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:06,836 INFO:     Epoch: 97
2022-11-18 02:52:07,601 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8390866253863681, 'Total loss': 0.8390866253863681} | train loss {'Reaction outcome loss': 0.8044922553334641, 'Total loss': 0.8044922553334641}
2022-11-18 02:52:07,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:07,601 INFO:     Epoch: 98
2022-11-18 02:52:08,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8263233845884149, 'Total loss': 0.8263233845884149} | train loss {'Reaction outcome loss': 0.810470604703494, 'Total loss': 0.810470604703494}
2022-11-18 02:52:08,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:08,388 INFO:     Epoch: 99
2022-11-18 02:52:09,176 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8298518373207613, 'Total loss': 0.8298518373207613} | train loss {'Reaction outcome loss': 0.807952345141515, 'Total loss': 0.807952345141515}
2022-11-18 02:52:09,176 INFO:     Best model found after epoch 73 of 100.
2022-11-18 02:52:09,177 INFO:   Done with stage: TRAINING
2022-11-18 02:52:09,177 INFO:   Starting stage: EVALUATION
2022-11-18 02:52:09,300 INFO:   Done with stage: EVALUATION
2022-11-18 02:52:09,300 INFO:   Leaving out SEQ value Fold_8
2022-11-18 02:52:09,313 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:52:09,313 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:52:09,980 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:52:09,981 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:52:10,050 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:52:10,050 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:52:10,050 INFO:     No hyperparam tuning for this model
2022-11-18 02:52:10,050 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:52:10,050 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:52:10,051 INFO:     None feature selector for col prot
2022-11-18 02:52:10,051 INFO:     None feature selector for col prot
2022-11-18 02:52:10,051 INFO:     None feature selector for col prot
2022-11-18 02:52:10,052 INFO:     None feature selector for col chem
2022-11-18 02:52:10,052 INFO:     None feature selector for col chem
2022-11-18 02:52:10,052 INFO:     None feature selector for col chem
2022-11-18 02:52:10,052 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:52:10,052 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:52:10,054 INFO:     Number of params in model 168571
2022-11-18 02:52:10,057 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:52:10,057 INFO:   Starting stage: TRAINING
2022-11-18 02:52:10,114 INFO:     Val loss before train {'Reaction outcome loss': 1.0112685479901053, 'Total loss': 1.0112685479901053}
2022-11-18 02:52:10,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:10,115 INFO:     Epoch: 0
2022-11-18 02:52:10,927 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8134150559251959, 'Total loss': 0.8134150559251959} | train loss {'Reaction outcome loss': 0.8779990718730034, 'Total loss': 0.8779990718730034}
2022-11-18 02:52:10,927 INFO:     Found new best model at epoch 0
2022-11-18 02:52:10,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:10,928 INFO:     Epoch: 1
2022-11-18 02:52:11,690 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8213709023865786, 'Total loss': 0.8213709023865786} | train loss {'Reaction outcome loss': 0.8502663221330412, 'Total loss': 0.8502663221330412}
2022-11-18 02:52:11,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:11,690 INFO:     Epoch: 2
2022-11-18 02:52:12,448 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.824925647540526, 'Total loss': 0.824925647540526} | train loss {'Reaction outcome loss': 0.8387538277574124, 'Total loss': 0.8387538277574124}
2022-11-18 02:52:12,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:12,449 INFO:     Epoch: 3
2022-11-18 02:52:13,246 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.79162140393799, 'Total loss': 0.79162140393799} | train loss {'Reaction outcome loss': 0.8312291106389414, 'Total loss': 0.8312291106389414}
2022-11-18 02:52:13,246 INFO:     Found new best model at epoch 3
2022-11-18 02:52:13,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:13,247 INFO:     Epoch: 4
2022-11-18 02:52:14,033 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7980848320505836, 'Total loss': 0.7980848320505836} | train loss {'Reaction outcome loss': 0.836259976389908, 'Total loss': 0.836259976389908}
2022-11-18 02:52:14,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:14,034 INFO:     Epoch: 5
2022-11-18 02:52:14,811 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8011696507984941, 'Total loss': 0.8011696507984941} | train loss {'Reaction outcome loss': 0.831917097731944, 'Total loss': 0.831917097731944}
2022-11-18 02:52:14,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:14,811 INFO:     Epoch: 6
2022-11-18 02:52:15,591 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7830004360188138, 'Total loss': 0.7830004360188138} | train loss {'Reaction outcome loss': 0.8289338855012771, 'Total loss': 0.8289338855012771}
2022-11-18 02:52:15,591 INFO:     Found new best model at epoch 6
2022-11-18 02:52:15,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:15,592 INFO:     Epoch: 7
2022-11-18 02:52:16,363 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8161495327949524, 'Total loss': 0.8161495327949524} | train loss {'Reaction outcome loss': 0.8269564597116362, 'Total loss': 0.8269564597116362}
2022-11-18 02:52:16,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:16,363 INFO:     Epoch: 8
2022-11-18 02:52:17,197 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.808730124072595, 'Total loss': 0.808730124072595} | train loss {'Reaction outcome loss': 0.8280599768604001, 'Total loss': 0.8280599768604001}
2022-11-18 02:52:17,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:17,198 INFO:     Epoch: 9
2022-11-18 02:52:18,030 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.82528917491436, 'Total loss': 0.82528917491436} | train loss {'Reaction outcome loss': 0.820601177191542, 'Total loss': 0.820601177191542}
2022-11-18 02:52:18,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:18,030 INFO:     Epoch: 10
2022-11-18 02:52:18,816 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8080810823223807, 'Total loss': 0.8080810823223807} | train loss {'Reaction outcome loss': 0.8308021805940136, 'Total loss': 0.8308021805940136}
2022-11-18 02:52:18,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:18,817 INFO:     Epoch: 11
2022-11-18 02:52:19,660 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7892141552133993, 'Total loss': 0.7892141552133993} | train loss {'Reaction outcome loss': 0.8193071113238412, 'Total loss': 0.8193071113238412}
2022-11-18 02:52:19,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:19,661 INFO:     Epoch: 12
2022-11-18 02:52:20,479 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7837267538363283, 'Total loss': 0.7837267538363283} | train loss {'Reaction outcome loss': 0.8227859921753407, 'Total loss': 0.8227859921753407}
2022-11-18 02:52:20,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:20,479 INFO:     Epoch: 13
2022-11-18 02:52:21,291 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7925966043363918, 'Total loss': 0.7925966043363918} | train loss {'Reaction outcome loss': 0.8223681735896295, 'Total loss': 0.8223681735896295}
2022-11-18 02:52:21,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:21,291 INFO:     Epoch: 14
2022-11-18 02:52:22,102 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7757765318859707, 'Total loss': 0.7757765318859707} | train loss {'Reaction outcome loss': 0.8204431306690939, 'Total loss': 0.8204431306690939}
2022-11-18 02:52:22,102 INFO:     Found new best model at epoch 14
2022-11-18 02:52:22,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:22,103 INFO:     Epoch: 15
2022-11-18 02:52:22,886 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.785231699320403, 'Total loss': 0.785231699320403} | train loss {'Reaction outcome loss': 0.8161246161307057, 'Total loss': 0.8161246161307057}
2022-11-18 02:52:22,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:22,886 INFO:     Epoch: 16
2022-11-18 02:52:23,671 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7944967645135793, 'Total loss': 0.7944967645135793} | train loss {'Reaction outcome loss': 0.8181039153808548, 'Total loss': 0.8181039153808548}
2022-11-18 02:52:23,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:23,671 INFO:     Epoch: 17
2022-11-18 02:52:24,510 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7866591465744105, 'Total loss': 0.7866591465744105} | train loss {'Reaction outcome loss': 0.8211130996144587, 'Total loss': 0.8211130996144587}
2022-11-18 02:52:24,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:24,512 INFO:     Epoch: 18
2022-11-18 02:52:25,313 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8338247605345466, 'Total loss': 0.8338247605345466} | train loss {'Reaction outcome loss': 0.8199224206468751, 'Total loss': 0.8199224206468751}
2022-11-18 02:52:25,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:25,313 INFO:     Epoch: 19
2022-11-18 02:52:26,155 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8013412742452188, 'Total loss': 0.8013412742452188} | train loss {'Reaction outcome loss': 0.812911385249707, 'Total loss': 0.812911385249707}
2022-11-18 02:52:26,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:26,155 INFO:     Epoch: 20
2022-11-18 02:52:26,963 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7839877165176652, 'Total loss': 0.7839877165176652} | train loss {'Reaction outcome loss': 0.8157015445251619, 'Total loss': 0.8157015445251619}
2022-11-18 02:52:26,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:26,964 INFO:     Epoch: 21
2022-11-18 02:52:27,787 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7950786697593603, 'Total loss': 0.7950786697593603} | train loss {'Reaction outcome loss': 0.8177813251893367, 'Total loss': 0.8177813251893367}
2022-11-18 02:52:27,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:27,788 INFO:     Epoch: 22
2022-11-18 02:52:28,582 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7899431369521401, 'Total loss': 0.7899431369521401} | train loss {'Reaction outcome loss': 0.8166674892267873, 'Total loss': 0.8166674892267873}
2022-11-18 02:52:28,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:28,583 INFO:     Epoch: 23
2022-11-18 02:52:29,380 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8073225048455325, 'Total loss': 0.8073225048455325} | train loss {'Reaction outcome loss': 0.8140933514843064, 'Total loss': 0.8140933514843064}
2022-11-18 02:52:29,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:29,380 INFO:     Epoch: 24
2022-11-18 02:52:30,182 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7935440987348557, 'Total loss': 0.7935440987348557} | train loss {'Reaction outcome loss': 0.8153058214774055, 'Total loss': 0.8153058214774055}
2022-11-18 02:52:30,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:30,182 INFO:     Epoch: 25
2022-11-18 02:52:30,976 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.818165888840502, 'Total loss': 0.818165888840502} | train loss {'Reaction outcome loss': 0.8142220809935562, 'Total loss': 0.8142220809935562}
2022-11-18 02:52:30,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:30,977 INFO:     Epoch: 26
2022-11-18 02:52:31,787 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7987686239860274, 'Total loss': 0.7987686239860274} | train loss {'Reaction outcome loss': 0.8193749561905861, 'Total loss': 0.8193749561905861}
2022-11-18 02:52:31,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:31,788 INFO:     Epoch: 27
2022-11-18 02:52:32,591 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7926579747687686, 'Total loss': 0.7926579747687686} | train loss {'Reaction outcome loss': 0.8134861918947389, 'Total loss': 0.8134861918947389}
2022-11-18 02:52:32,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:32,591 INFO:     Epoch: 28
2022-11-18 02:52:33,422 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7893886566162109, 'Total loss': 0.7893886566162109} | train loss {'Reaction outcome loss': 0.8115789809774968, 'Total loss': 0.8115789809774968}
2022-11-18 02:52:33,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:33,423 INFO:     Epoch: 29
2022-11-18 02:52:34,221 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7845296602357518, 'Total loss': 0.7845296602357518} | train loss {'Reaction outcome loss': 0.8159657466796136, 'Total loss': 0.8159657466796136}
2022-11-18 02:52:34,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:34,221 INFO:     Epoch: 30
2022-11-18 02:52:34,986 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7925575829365037, 'Total loss': 0.7925575829365037} | train loss {'Reaction outcome loss': 0.8162319566453656, 'Total loss': 0.8162319566453656}
2022-11-18 02:52:34,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:34,987 INFO:     Epoch: 31
2022-11-18 02:52:35,833 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7809243364767595, 'Total loss': 0.7809243364767595} | train loss {'Reaction outcome loss': 0.8141694216718597, 'Total loss': 0.8141694216718597}
2022-11-18 02:52:35,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:35,833 INFO:     Epoch: 32
2022-11-18 02:52:36,639 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8004977296699177, 'Total loss': 0.8004977296699177} | train loss {'Reaction outcome loss': 0.8153741746660201, 'Total loss': 0.8153741746660201}
2022-11-18 02:52:36,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:36,640 INFO:     Epoch: 33
2022-11-18 02:52:37,446 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7997540499676358, 'Total loss': 0.7997540499676358} | train loss {'Reaction outcome loss': 0.8189163175561736, 'Total loss': 0.8189163175561736}
2022-11-18 02:52:37,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:37,447 INFO:     Epoch: 34
2022-11-18 02:52:38,258 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7917919944633137, 'Total loss': 0.7917919944633137} | train loss {'Reaction outcome loss': 0.8123794886614045, 'Total loss': 0.8123794886614045}
2022-11-18 02:52:38,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:38,259 INFO:     Epoch: 35
2022-11-18 02:52:39,072 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8086290752345865, 'Total loss': 0.8086290752345865} | train loss {'Reaction outcome loss': 0.8137239920756509, 'Total loss': 0.8137239920756509}
2022-11-18 02:52:39,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:39,072 INFO:     Epoch: 36
2022-11-18 02:52:39,853 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8186872899532318, 'Total loss': 0.8186872899532318} | train loss {'Reaction outcome loss': 0.8166160778172554, 'Total loss': 0.8166160778172554}
2022-11-18 02:52:39,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:39,853 INFO:     Epoch: 37
2022-11-18 02:52:40,669 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7888039336963133, 'Total loss': 0.7888039336963133} | train loss {'Reaction outcome loss': 0.8143721132749512, 'Total loss': 0.8143721132749512}
2022-11-18 02:52:40,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:40,670 INFO:     Epoch: 38
2022-11-18 02:52:41,472 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7772542908787727, 'Total loss': 0.7772542908787727} | train loss {'Reaction outcome loss': 0.8124439028061686, 'Total loss': 0.8124439028061686}
2022-11-18 02:52:41,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:41,472 INFO:     Epoch: 39
2022-11-18 02:52:42,281 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7844970605590127, 'Total loss': 0.7844970605590127} | train loss {'Reaction outcome loss': 0.8139444425581924, 'Total loss': 0.8139444425581924}
2022-11-18 02:52:42,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:42,281 INFO:     Epoch: 40
2022-11-18 02:52:43,112 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7956805025989359, 'Total loss': 0.7956805025989359} | train loss {'Reaction outcome loss': 0.8134356431903378, 'Total loss': 0.8134356431903378}
2022-11-18 02:52:43,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:43,114 INFO:     Epoch: 41
2022-11-18 02:52:43,933 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7903100821104917, 'Total loss': 0.7903100821104917} | train loss {'Reaction outcome loss': 0.813037104784481, 'Total loss': 0.813037104784481}
2022-11-18 02:52:43,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:43,934 INFO:     Epoch: 42
2022-11-18 02:52:44,736 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7994366030801426, 'Total loss': 0.7994366030801426} | train loss {'Reaction outcome loss': 0.8107639834765465, 'Total loss': 0.8107639834765465}
2022-11-18 02:52:44,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:44,737 INFO:     Epoch: 43
2022-11-18 02:52:45,530 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7886185469952497, 'Total loss': 0.7886185469952497} | train loss {'Reaction outcome loss': 0.813728699881223, 'Total loss': 0.813728699881223}
2022-11-18 02:52:45,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:45,530 INFO:     Epoch: 44
2022-11-18 02:52:46,348 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7863738137212667, 'Total loss': 0.7863738137212667} | train loss {'Reaction outcome loss': 0.8095220042572867, 'Total loss': 0.8095220042572867}
2022-11-18 02:52:46,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:46,348 INFO:     Epoch: 45
2022-11-18 02:52:47,154 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8043126260692423, 'Total loss': 0.8043126260692423} | train loss {'Reaction outcome loss': 0.810229001807109, 'Total loss': 0.810229001807109}
2022-11-18 02:52:47,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:47,154 INFO:     Epoch: 46
2022-11-18 02:52:47,949 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7959582568569616, 'Total loss': 0.7959582568569616} | train loss {'Reaction outcome loss': 0.8186692697626929, 'Total loss': 0.8186692697626929}
2022-11-18 02:52:47,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:47,949 INFO:     Epoch: 47
2022-11-18 02:52:48,769 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7817668068138036, 'Total loss': 0.7817668068138036} | train loss {'Reaction outcome loss': 0.8134082531736743, 'Total loss': 0.8134082531736743}
2022-11-18 02:52:48,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:48,770 INFO:     Epoch: 48
2022-11-18 02:52:49,573 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7839286652478304, 'Total loss': 0.7839286652478304} | train loss {'Reaction outcome loss': 0.8104608675404903, 'Total loss': 0.8104608675404903}
2022-11-18 02:52:49,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:49,574 INFO:     Epoch: 49
2022-11-18 02:52:50,392 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7936401218175888, 'Total loss': 0.7936401218175888} | train loss {'Reaction outcome loss': 0.8123689631540929, 'Total loss': 0.8123689631540929}
2022-11-18 02:52:50,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:50,392 INFO:     Epoch: 50
2022-11-18 02:52:51,230 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7860093076120723, 'Total loss': 0.7860093076120723} | train loss {'Reaction outcome loss': 0.8133838439901029, 'Total loss': 0.8133838439901029}
2022-11-18 02:52:51,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:51,230 INFO:     Epoch: 51
2022-11-18 02:52:52,016 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8025814389640634, 'Total loss': 0.8025814389640634} | train loss {'Reaction outcome loss': 0.8143616404023862, 'Total loss': 0.8143616404023862}
2022-11-18 02:52:52,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:52,017 INFO:     Epoch: 52
2022-11-18 02:52:52,839 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8116929829120636, 'Total loss': 0.8116929829120636} | train loss {'Reaction outcome loss': 0.8112566266809741, 'Total loss': 0.8112566266809741}
2022-11-18 02:52:52,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:52,840 INFO:     Epoch: 53
2022-11-18 02:52:53,668 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7863990454511209, 'Total loss': 0.7863990454511209} | train loss {'Reaction outcome loss': 0.8141166569004136, 'Total loss': 0.8141166569004136}
2022-11-18 02:52:53,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:53,668 INFO:     Epoch: 54
2022-11-18 02:52:54,483 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7900142446160316, 'Total loss': 0.7900142446160316} | train loss {'Reaction outcome loss': 0.8089943559419724, 'Total loss': 0.8089943559419724}
2022-11-18 02:52:54,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:54,483 INFO:     Epoch: 55
2022-11-18 02:52:55,291 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7866189080205831, 'Total loss': 0.7866189080205831} | train loss {'Reaction outcome loss': 0.8140059892208346, 'Total loss': 0.8140059892208346}
2022-11-18 02:52:55,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:55,293 INFO:     Epoch: 56
2022-11-18 02:52:56,115 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7798300236463547, 'Total loss': 0.7798300236463547} | train loss {'Reaction outcome loss': 0.8102284537688378, 'Total loss': 0.8102284537688378}
2022-11-18 02:52:56,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:56,115 INFO:     Epoch: 57
2022-11-18 02:52:56,891 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.806562252342701, 'Total loss': 0.806562252342701} | train loss {'Reaction outcome loss': 0.8054711045997758, 'Total loss': 0.8054711045997758}
2022-11-18 02:52:56,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:56,891 INFO:     Epoch: 58
2022-11-18 02:52:57,672 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7902337170460008, 'Total loss': 0.7902337170460008} | train loss {'Reaction outcome loss': 0.8073227679537188, 'Total loss': 0.8073227679537188}
2022-11-18 02:52:57,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:57,672 INFO:     Epoch: 59
2022-11-18 02:52:58,488 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8200767216357318, 'Total loss': 0.8200767216357318} | train loss {'Reaction outcome loss': 0.8138444587107627, 'Total loss': 0.8138444587107627}
2022-11-18 02:52:58,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:58,489 INFO:     Epoch: 60
2022-11-18 02:52:59,283 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7893048389391466, 'Total loss': 0.7893048389391466} | train loss {'Reaction outcome loss': 0.8093310493014513, 'Total loss': 0.8093310493014513}
2022-11-18 02:52:59,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:52:59,283 INFO:     Epoch: 61
2022-11-18 02:53:00,107 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8024332387880846, 'Total loss': 0.8024332387880846} | train loss {'Reaction outcome loss': 0.8165497446372625, 'Total loss': 0.8165497446372625}
2022-11-18 02:53:00,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:00,108 INFO:     Epoch: 62
2022-11-18 02:53:00,906 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7858601077036425, 'Total loss': 0.7858601077036425} | train loss {'Reaction outcome loss': 0.8120750317410115, 'Total loss': 0.8120750317410115}
2022-11-18 02:53:00,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:00,906 INFO:     Epoch: 63
2022-11-18 02:53:01,743 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7791097773747011, 'Total loss': 0.7791097773747011} | train loss {'Reaction outcome loss': 0.8093809642859043, 'Total loss': 0.8093809642859043}
2022-11-18 02:53:01,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:01,744 INFO:     Epoch: 64
2022-11-18 02:53:02,543 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7879522415724668, 'Total loss': 0.7879522415724668} | train loss {'Reaction outcome loss': 0.8126246958009659, 'Total loss': 0.8126246958009659}
2022-11-18 02:53:02,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:02,543 INFO:     Epoch: 65
2022-11-18 02:53:03,375 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7898873896761374, 'Total loss': 0.7898873896761374} | train loss {'Reaction outcome loss': 0.812505400228885, 'Total loss': 0.812505400228885}
2022-11-18 02:53:03,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:03,375 INFO:     Epoch: 66
2022-11-18 02:53:04,245 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7812008126215502, 'Total loss': 0.7812008126215502} | train loss {'Reaction outcome loss': 0.8107382988016452, 'Total loss': 0.8107382988016452}
2022-11-18 02:53:04,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:04,245 INFO:     Epoch: 67
2022-11-18 02:53:05,019 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7905210723931139, 'Total loss': 0.7905210723931139} | train loss {'Reaction outcome loss': 0.8134372145418198, 'Total loss': 0.8134372145418198}
2022-11-18 02:53:05,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:05,019 INFO:     Epoch: 68
2022-11-18 02:53:05,861 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7811676676977765, 'Total loss': 0.7811676676977765} | train loss {'Reaction outcome loss': 0.8140067146910775, 'Total loss': 0.8140067146910775}
2022-11-18 02:53:05,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:05,861 INFO:     Epoch: 69
2022-11-18 02:53:06,678 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7860343246297403, 'Total loss': 0.7860343246297403} | train loss {'Reaction outcome loss': 0.80883074780145, 'Total loss': 0.80883074780145}
2022-11-18 02:53:06,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:06,678 INFO:     Epoch: 70
2022-11-18 02:53:07,470 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.774373518472368, 'Total loss': 0.774373518472368} | train loss {'Reaction outcome loss': 0.8148965373515121, 'Total loss': 0.8148965373515121}
2022-11-18 02:53:07,470 INFO:     Found new best model at epoch 70
2022-11-18 02:53:07,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:07,471 INFO:     Epoch: 71
2022-11-18 02:53:08,289 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7785462337461385, 'Total loss': 0.7785462337461385} | train loss {'Reaction outcome loss': 0.8088605862952047, 'Total loss': 0.8088605862952047}
2022-11-18 02:53:08,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:08,289 INFO:     Epoch: 72
2022-11-18 02:53:09,110 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7793126932599328, 'Total loss': 0.7793126932599328} | train loss {'Reaction outcome loss': 0.8095201307967785, 'Total loss': 0.8095201307967785}
2022-11-18 02:53:09,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:09,111 INFO:     Epoch: 73
2022-11-18 02:53:09,908 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7833737473596226, 'Total loss': 0.7833737473596226} | train loss {'Reaction outcome loss': 0.8148071674569961, 'Total loss': 0.8148071674569961}
2022-11-18 02:53:09,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:09,908 INFO:     Epoch: 74
2022-11-18 02:53:10,719 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7861283692446622, 'Total loss': 0.7861283692446622} | train loss {'Reaction outcome loss': 0.809983504755843, 'Total loss': 0.809983504755843}
2022-11-18 02:53:10,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:10,719 INFO:     Epoch: 75
2022-11-18 02:53:11,514 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7781744599342346, 'Total loss': 0.7781744599342346} | train loss {'Reaction outcome loss': 0.8090703302333432, 'Total loss': 0.8090703302333432}
2022-11-18 02:53:11,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:11,514 INFO:     Epoch: 76
2022-11-18 02:53:12,309 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7828292000022802, 'Total loss': 0.7828292000022802} | train loss {'Reaction outcome loss': 0.809223023994315, 'Total loss': 0.809223023994315}
2022-11-18 02:53:12,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:12,309 INFO:     Epoch: 77
2022-11-18 02:53:13,122 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7837757563049143, 'Total loss': 0.7837757563049143} | train loss {'Reaction outcome loss': 0.8113492615520954, 'Total loss': 0.8113492615520954}
2022-11-18 02:53:13,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:13,123 INFO:     Epoch: 78
2022-11-18 02:53:13,937 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7767284038391981, 'Total loss': 0.7767284038391981} | train loss {'Reaction outcome loss': 0.8076673692032215, 'Total loss': 0.8076673692032215}
2022-11-18 02:53:13,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:13,939 INFO:     Epoch: 79
2022-11-18 02:53:14,733 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7936656000939283, 'Total loss': 0.7936656000939283} | train loss {'Reaction outcome loss': 0.8097653155845981, 'Total loss': 0.8097653155845981}
2022-11-18 02:53:14,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:14,733 INFO:     Epoch: 80
2022-11-18 02:53:15,517 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.783644818446853, 'Total loss': 0.783644818446853} | train loss {'Reaction outcome loss': 0.8092144570283352, 'Total loss': 0.8092144570283352}
2022-11-18 02:53:15,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:15,517 INFO:     Epoch: 81
2022-11-18 02:53:16,275 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.78978077119047, 'Total loss': 0.78978077119047} | train loss {'Reaction outcome loss': 0.8106437229341076, 'Total loss': 0.8106437229341076}
2022-11-18 02:53:16,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:16,275 INFO:     Epoch: 82
2022-11-18 02:53:17,038 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8053428483280268, 'Total loss': 0.8053428483280268} | train loss {'Reaction outcome loss': 0.8119630991451202, 'Total loss': 0.8119630991451202}
2022-11-18 02:53:17,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:17,038 INFO:     Epoch: 83
2022-11-18 02:53:17,803 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.80638902973045, 'Total loss': 0.80638902973045} | train loss {'Reaction outcome loss': 0.8112297213125613, 'Total loss': 0.8112297213125613}
2022-11-18 02:53:17,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:17,803 INFO:     Epoch: 84
2022-11-18 02:53:18,594 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7959607379003004, 'Total loss': 0.7959607379003004} | train loss {'Reaction outcome loss': 0.8070526571283417, 'Total loss': 0.8070526571283417}
2022-11-18 02:53:18,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:18,594 INFO:     Epoch: 85
2022-11-18 02:53:19,374 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7774877521124753, 'Total loss': 0.7774877521124753} | train loss {'Reaction outcome loss': 0.808626227080822, 'Total loss': 0.808626227080822}
2022-11-18 02:53:19,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:19,375 INFO:     Epoch: 86
2022-11-18 02:53:20,148 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7836500121788545, 'Total loss': 0.7836500121788545} | train loss {'Reaction outcome loss': 0.8093955270465343, 'Total loss': 0.8093955270465343}
2022-11-18 02:53:20,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:20,148 INFO:     Epoch: 87
2022-11-18 02:53:20,919 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.788169963793321, 'Total loss': 0.788169963793321} | train loss {'Reaction outcome loss': 0.809424827416097, 'Total loss': 0.809424827416097}
2022-11-18 02:53:20,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:20,919 INFO:     Epoch: 88
2022-11-18 02:53:21,703 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.812822400168939, 'Total loss': 0.812822400168939} | train loss {'Reaction outcome loss': 0.8119558790518392, 'Total loss': 0.8119558790518392}
2022-11-18 02:53:21,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:21,703 INFO:     Epoch: 89
2022-11-18 02:53:22,488 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7772142927755009, 'Total loss': 0.7772142927755009} | train loss {'Reaction outcome loss': 0.8122294148610484, 'Total loss': 0.8122294148610484}
2022-11-18 02:53:22,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:22,488 INFO:     Epoch: 90
2022-11-18 02:53:23,285 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7779309051957998, 'Total loss': 0.7779309051957998} | train loss {'Reaction outcome loss': 0.8096939279667793, 'Total loss': 0.8096939279667793}
2022-11-18 02:53:23,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:23,286 INFO:     Epoch: 91
2022-11-18 02:53:24,037 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7922702560370619, 'Total loss': 0.7922702560370619} | train loss {'Reaction outcome loss': 0.8051199711138203, 'Total loss': 0.8051199711138203}
2022-11-18 02:53:24,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:24,038 INFO:     Epoch: 92
2022-11-18 02:53:24,805 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7732235105200247, 'Total loss': 0.7732235105200247} | train loss {'Reaction outcome loss': 0.8061935413748987, 'Total loss': 0.8061935413748987}
2022-11-18 02:53:24,805 INFO:     Found new best model at epoch 92
2022-11-18 02:53:24,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:24,806 INFO:     Epoch: 93
2022-11-18 02:53:25,614 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8307998078790578, 'Total loss': 0.8307998078790578} | train loss {'Reaction outcome loss': 0.8053248802260045, 'Total loss': 0.8053248802260045}
2022-11-18 02:53:25,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:25,615 INFO:     Epoch: 94
2022-11-18 02:53:26,399 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7989403923804109, 'Total loss': 0.7989403923804109} | train loss {'Reaction outcome loss': 0.8114725231162964, 'Total loss': 0.8114725231162964}
2022-11-18 02:53:26,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:26,400 INFO:     Epoch: 95
2022-11-18 02:53:27,180 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7926533926617015, 'Total loss': 0.7926533926617015} | train loss {'Reaction outcome loss': 0.8102064067798276, 'Total loss': 0.8102064067798276}
2022-11-18 02:53:27,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:27,182 INFO:     Epoch: 96
2022-11-18 02:53:27,973 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.78834329680963, 'Total loss': 0.78834329680963} | train loss {'Reaction outcome loss': 0.8062786709877753, 'Total loss': 0.8062786709877753}
2022-11-18 02:53:27,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:27,973 INFO:     Epoch: 97
2022-11-18 02:53:28,760 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7900064851750027, 'Total loss': 0.7900064851750027} | train loss {'Reaction outcome loss': 0.8143804852039583, 'Total loss': 0.8143804852039583}
2022-11-18 02:53:28,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:28,760 INFO:     Epoch: 98
2022-11-18 02:53:29,561 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7925768928094343, 'Total loss': 0.7925768928094343} | train loss {'Reaction outcome loss': 0.8065794999561002, 'Total loss': 0.8065794999561002}
2022-11-18 02:53:29,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:29,561 INFO:     Epoch: 99
2022-11-18 02:53:30,347 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7755251310088418, 'Total loss': 0.7755251310088418} | train loss {'Reaction outcome loss': 0.8078139390676252, 'Total loss': 0.8078139390676252}
2022-11-18 02:53:30,348 INFO:     Best model found after epoch 93 of 100.
2022-11-18 02:53:30,348 INFO:   Done with stage: TRAINING
2022-11-18 02:53:30,348 INFO:   Starting stage: EVALUATION
2022-11-18 02:53:30,465 INFO:   Done with stage: EVALUATION
2022-11-18 02:53:30,465 INFO:   Leaving out SEQ value Fold_9
2022-11-18 02:53:30,478 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:53:30,478 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:53:31,143 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:53:31,144 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:53:31,214 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:53:31,214 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:53:31,214 INFO:     No hyperparam tuning for this model
2022-11-18 02:53:31,214 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:53:31,214 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:53:31,215 INFO:     None feature selector for col prot
2022-11-18 02:53:31,215 INFO:     None feature selector for col prot
2022-11-18 02:53:31,215 INFO:     None feature selector for col prot
2022-11-18 02:53:31,216 INFO:     None feature selector for col chem
2022-11-18 02:53:31,216 INFO:     None feature selector for col chem
2022-11-18 02:53:31,216 INFO:     None feature selector for col chem
2022-11-18 02:53:31,216 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:53:31,216 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:53:31,218 INFO:     Number of params in model 168571
2022-11-18 02:53:31,221 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:53:31,221 INFO:   Starting stage: TRAINING
2022-11-18 02:53:31,278 INFO:     Val loss before train {'Reaction outcome loss': 0.9261628606102683, 'Total loss': 0.9261628606102683}
2022-11-18 02:53:31,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:31,278 INFO:     Epoch: 0
2022-11-18 02:53:32,051 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7617826448245482, 'Total loss': 0.7617826448245482} | train loss {'Reaction outcome loss': 0.8943832731775699, 'Total loss': 0.8943832731775699}
2022-11-18 02:53:32,051 INFO:     Found new best model at epoch 0
2022-11-18 02:53:32,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:32,052 INFO:     Epoch: 1
2022-11-18 02:53:32,813 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7658231935717843, 'Total loss': 0.7658231935717843} | train loss {'Reaction outcome loss': 0.8540893081695803, 'Total loss': 0.8540893081695803}
2022-11-18 02:53:32,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:32,814 INFO:     Epoch: 2
2022-11-18 02:53:33,593 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7882207293402065, 'Total loss': 0.7882207293402065} | train loss {'Reaction outcome loss': 0.8526490330696106, 'Total loss': 0.8526490330696106}
2022-11-18 02:53:33,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:33,594 INFO:     Epoch: 3
2022-11-18 02:53:34,387 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7616577290675857, 'Total loss': 0.7616577290675857} | train loss {'Reaction outcome loss': 0.8523555769314689, 'Total loss': 0.8523555769314689}
2022-11-18 02:53:34,387 INFO:     Found new best model at epoch 3
2022-11-18 02:53:34,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:34,388 INFO:     Epoch: 4
2022-11-18 02:53:35,189 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7399142818017439, 'Total loss': 0.7399142818017439} | train loss {'Reaction outcome loss': 0.8485503967010206, 'Total loss': 0.8485503967010206}
2022-11-18 02:53:35,189 INFO:     Found new best model at epoch 4
2022-11-18 02:53:35,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:35,190 INFO:     Epoch: 5
2022-11-18 02:53:36,036 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.740527025677941, 'Total loss': 0.740527025677941} | train loss {'Reaction outcome loss': 0.8345667582846457, 'Total loss': 0.8345667582846457}
2022-11-18 02:53:36,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:36,037 INFO:     Epoch: 6
2022-11-18 02:53:36,845 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7357367730953477, 'Total loss': 0.7357367730953477} | train loss {'Reaction outcome loss': 0.8351812494858619, 'Total loss': 0.8351812494858619}
2022-11-18 02:53:36,845 INFO:     Found new best model at epoch 6
2022-11-18 02:53:36,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:36,846 INFO:     Epoch: 7
2022-11-18 02:53:37,673 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7528946392915465, 'Total loss': 0.7528946392915465} | train loss {'Reaction outcome loss': 0.8333735177593846, 'Total loss': 0.8333735177593846}
2022-11-18 02:53:37,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:37,673 INFO:     Epoch: 8
2022-11-18 02:53:38,461 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7728292007337917, 'Total loss': 0.7728292007337917} | train loss {'Reaction outcome loss': 0.8293960027156337, 'Total loss': 0.8293960027156337}
2022-11-18 02:53:38,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:38,461 INFO:     Epoch: 9
2022-11-18 02:53:39,255 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7582839144901796, 'Total loss': 0.7582839144901796} | train loss {'Reaction outcome loss': 0.832116088078868, 'Total loss': 0.832116088078868}
2022-11-18 02:53:39,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:39,255 INFO:     Epoch: 10
2022-11-18 02:53:40,067 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7399891912937164, 'Total loss': 0.7399891912937164} | train loss {'Reaction outcome loss': 0.8335894695933788, 'Total loss': 0.8335894695933788}
2022-11-18 02:53:40,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:40,068 INFO:     Epoch: 11
2022-11-18 02:53:40,899 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7661411579359662, 'Total loss': 0.7661411579359662} | train loss {'Reaction outcome loss': 0.8261035512531957, 'Total loss': 0.8261035512531957}
2022-11-18 02:53:40,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:40,899 INFO:     Epoch: 12
2022-11-18 02:53:41,702 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7501846599307928, 'Total loss': 0.7501846599307928} | train loss {'Reaction outcome loss': 0.8292027917360106, 'Total loss': 0.8292027917360106}
2022-11-18 02:53:41,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:41,702 INFO:     Epoch: 13
2022-11-18 02:53:42,525 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7455745955759828, 'Total loss': 0.7455745955759828} | train loss {'Reaction outcome loss': 0.8281874875387838, 'Total loss': 0.8281874875387838}
2022-11-18 02:53:42,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:42,526 INFO:     Epoch: 14
2022-11-18 02:53:43,337 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7295437116514553, 'Total loss': 0.7295437116514553} | train loss {'Reaction outcome loss': 0.8276654336481325, 'Total loss': 0.8276654336481325}
2022-11-18 02:53:43,337 INFO:     Found new best model at epoch 14
2022-11-18 02:53:43,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:43,338 INFO:     Epoch: 15
2022-11-18 02:53:44,142 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7285427871075544, 'Total loss': 0.7285427871075544} | train loss {'Reaction outcome loss': 0.8274013134500673, 'Total loss': 0.8274013134500673}
2022-11-18 02:53:44,142 INFO:     Found new best model at epoch 15
2022-11-18 02:53:44,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:44,143 INFO:     Epoch: 16
2022-11-18 02:53:44,916 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7718153338540684, 'Total loss': 0.7718153338540684} | train loss {'Reaction outcome loss': 0.8260413038153802, 'Total loss': 0.8260413038153802}
2022-11-18 02:53:44,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:44,916 INFO:     Epoch: 17
2022-11-18 02:53:45,715 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7535959184169769, 'Total loss': 0.7535959184169769} | train loss {'Reaction outcome loss': 0.826632178478664, 'Total loss': 0.826632178478664}
2022-11-18 02:53:45,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:45,717 INFO:     Epoch: 18
2022-11-18 02:53:46,550 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.733342783017592, 'Total loss': 0.733342783017592} | train loss {'Reaction outcome loss': 0.8286012847937884, 'Total loss': 0.8286012847937884}
2022-11-18 02:53:46,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:46,550 INFO:     Epoch: 19
2022-11-18 02:53:47,340 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7341615767641501, 'Total loss': 0.7341615767641501} | train loss {'Reaction outcome loss': 0.8231347089092578, 'Total loss': 0.8231347089092578}
2022-11-18 02:53:47,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:47,341 INFO:     Epoch: 20
2022-11-18 02:53:48,178 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7342549426989122, 'Total loss': 0.7342549426989122} | train loss {'Reaction outcome loss': 0.8305280665236134, 'Total loss': 0.8305280665236134}
2022-11-18 02:53:48,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:48,178 INFO:     Epoch: 21
2022-11-18 02:53:49,015 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7347222488712181, 'Total loss': 0.7347222488712181} | train loss {'Reaction outcome loss': 0.823119402532616, 'Total loss': 0.823119402532616}
2022-11-18 02:53:49,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:49,016 INFO:     Epoch: 22
2022-11-18 02:53:49,801 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7421302771703764, 'Total loss': 0.7421302771703764} | train loss {'Reaction outcome loss': 0.8265590624463174, 'Total loss': 0.8265590624463174}
2022-11-18 02:53:49,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:49,802 INFO:     Epoch: 23
2022-11-18 02:53:50,576 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.74656081199646, 'Total loss': 0.74656081199646} | train loss {'Reaction outcome loss': 0.8233371658190605, 'Total loss': 0.8233371658190605}
2022-11-18 02:53:50,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:50,576 INFO:     Epoch: 24
2022-11-18 02:53:51,371 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7427815815264528, 'Total loss': 0.7427815815264528} | train loss {'Reaction outcome loss': 0.8250689686786744, 'Total loss': 0.8250689686786744}
2022-11-18 02:53:51,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:51,372 INFO:     Epoch: 25
2022-11-18 02:53:52,146 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7402731457894499, 'Total loss': 0.7402731457894499} | train loss {'Reaction outcome loss': 0.8252202325290249, 'Total loss': 0.8252202325290249}
2022-11-18 02:53:52,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:52,146 INFO:     Epoch: 26
2022-11-18 02:53:52,936 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7430413473736156, 'Total loss': 0.7430413473736156} | train loss {'Reaction outcome loss': 0.8212370682627924, 'Total loss': 0.8212370682627924}
2022-11-18 02:53:52,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:52,937 INFO:     Epoch: 27
2022-11-18 02:53:53,718 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7285598472438075, 'Total loss': 0.7285598472438075} | train loss {'Reaction outcome loss': 0.8206425413729683, 'Total loss': 0.8206425413729683}
2022-11-18 02:53:53,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:53,719 INFO:     Epoch: 28
2022-11-18 02:53:54,482 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7373562069101767, 'Total loss': 0.7373562069101767} | train loss {'Reaction outcome loss': 0.8247739135498001, 'Total loss': 0.8247739135498001}
2022-11-18 02:53:54,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:54,483 INFO:     Epoch: 29
2022-11-18 02:53:55,274 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7359860329465433, 'Total loss': 0.7359860329465433} | train loss {'Reaction outcome loss': 0.8230671306411105, 'Total loss': 0.8230671306411105}
2022-11-18 02:53:55,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:55,274 INFO:     Epoch: 30
2022-11-18 02:53:56,061 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.726279882544821, 'Total loss': 0.726279882544821} | train loss {'Reaction outcome loss': 0.8267369738990261, 'Total loss': 0.8267369738990261}
2022-11-18 02:53:56,061 INFO:     Found new best model at epoch 30
2022-11-18 02:53:56,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:56,062 INFO:     Epoch: 31
2022-11-18 02:53:56,851 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7323454699733041, 'Total loss': 0.7323454699733041} | train loss {'Reaction outcome loss': 0.8327917503493447, 'Total loss': 0.8327917503493447}
2022-11-18 02:53:56,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:56,852 INFO:     Epoch: 32
2022-11-18 02:53:57,661 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7359041192314841, 'Total loss': 0.7359041192314841} | train loss {'Reaction outcome loss': 0.8289892829714283, 'Total loss': 0.8289892829714283}
2022-11-18 02:53:57,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:57,661 INFO:     Epoch: 33
2022-11-18 02:53:58,433 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.728992142460563, 'Total loss': 0.728992142460563} | train loss {'Reaction outcome loss': 0.8216536847814437, 'Total loss': 0.8216536847814437}
2022-11-18 02:53:58,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:58,435 INFO:     Epoch: 34
2022-11-18 02:53:59,220 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7348305650732734, 'Total loss': 0.7348305650732734} | train loss {'Reaction outcome loss': 0.8262844801910462, 'Total loss': 0.8262844801910462}
2022-11-18 02:53:59,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:59,221 INFO:     Epoch: 35
2022-11-18 02:53:59,987 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7368287891149521, 'Total loss': 0.7368287891149521} | train loss {'Reaction outcome loss': 0.8227609220531679, 'Total loss': 0.8227609220531679}
2022-11-18 02:53:59,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:53:59,987 INFO:     Epoch: 36
2022-11-18 02:54:00,782 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7325227348641916, 'Total loss': 0.7325227348641916} | train loss {'Reaction outcome loss': 0.8273543619340465, 'Total loss': 0.8273543619340465}
2022-11-18 02:54:00,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:00,782 INFO:     Epoch: 37
2022-11-18 02:54:01,573 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7405876916917887, 'Total loss': 0.7405876916917887} | train loss {'Reaction outcome loss': 0.8197554917104782, 'Total loss': 0.8197554917104782}
2022-11-18 02:54:01,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:01,573 INFO:     Epoch: 38
2022-11-18 02:54:02,359 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.736304678700187, 'Total loss': 0.736304678700187} | train loss {'Reaction outcome loss': 0.8245172165334225, 'Total loss': 0.8245172165334225}
2022-11-18 02:54:02,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:02,359 INFO:     Epoch: 39
2022-11-18 02:54:03,150 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7332283197478815, 'Total loss': 0.7332283197478815} | train loss {'Reaction outcome loss': 0.8225765659684136, 'Total loss': 0.8225765659684136}
2022-11-18 02:54:03,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:03,151 INFO:     Epoch: 40
2022-11-18 02:54:03,945 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.741956659338691, 'Total loss': 0.741956659338691} | train loss {'Reaction outcome loss': 0.8274632253714146, 'Total loss': 0.8274632253714146}
2022-11-18 02:54:03,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:03,945 INFO:     Epoch: 41
2022-11-18 02:54:04,736 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7390361333435232, 'Total loss': 0.7390361333435232} | train loss {'Reaction outcome loss': 0.8220355413373439, 'Total loss': 0.8220355413373439}
2022-11-18 02:54:04,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:04,737 INFO:     Epoch: 42
2022-11-18 02:54:05,525 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7390093024481427, 'Total loss': 0.7390093024481427} | train loss {'Reaction outcome loss': 0.8246706715754925, 'Total loss': 0.8246706715754925}
2022-11-18 02:54:05,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:05,525 INFO:     Epoch: 43
2022-11-18 02:54:06,316 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7485117783600633, 'Total loss': 0.7485117783600633} | train loss {'Reaction outcome loss': 0.8205735467133983, 'Total loss': 0.8205735467133983}
2022-11-18 02:54:06,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:06,317 INFO:     Epoch: 44
2022-11-18 02:54:07,110 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7488575272939422, 'Total loss': 0.7488575272939422} | train loss {'Reaction outcome loss': 0.8224748291315571, 'Total loss': 0.8224748291315571}
2022-11-18 02:54:07,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:07,110 INFO:     Epoch: 45
2022-11-18 02:54:07,912 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7275941446423531, 'Total loss': 0.7275941446423531} | train loss {'Reaction outcome loss': 0.8238740611460901, 'Total loss': 0.8238740611460901}
2022-11-18 02:54:07,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:07,912 INFO:     Epoch: 46
2022-11-18 02:54:08,682 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7430756193670359, 'Total loss': 0.7430756193670359} | train loss {'Reaction outcome loss': 0.8254356640240839, 'Total loss': 0.8254356640240839}
2022-11-18 02:54:08,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:08,682 INFO:     Epoch: 47
2022-11-18 02:54:09,483 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7277457876638933, 'Total loss': 0.7277457876638933} | train loss {'Reaction outcome loss': 0.823904022814766, 'Total loss': 0.823904022814766}
2022-11-18 02:54:09,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:09,483 INFO:     Epoch: 48
2022-11-18 02:54:10,281 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7341678650541739, 'Total loss': 0.7341678650541739} | train loss {'Reaction outcome loss': 0.8264335941883826, 'Total loss': 0.8264335941883826}
2022-11-18 02:54:10,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:10,281 INFO:     Epoch: 49
2022-11-18 02:54:11,063 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7431476969610561, 'Total loss': 0.7431476969610561} | train loss {'Reaction outcome loss': 0.8244281704387357, 'Total loss': 0.8244281704387357}
2022-11-18 02:54:11,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:11,064 INFO:     Epoch: 50
2022-11-18 02:54:11,876 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7315774986689741, 'Total loss': 0.7315774986689741} | train loss {'Reaction outcome loss': 0.8228209890545376, 'Total loss': 0.8228209890545376}
2022-11-18 02:54:11,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:11,876 INFO:     Epoch: 51
2022-11-18 02:54:12,655 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7589862272143364, 'Total loss': 0.7589862272143364} | train loss {'Reaction outcome loss': 0.8188787514884626, 'Total loss': 0.8188787514884626}
2022-11-18 02:54:12,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:12,655 INFO:     Epoch: 52
2022-11-18 02:54:13,427 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7464297955686395, 'Total loss': 0.7464297955686395} | train loss {'Reaction outcome loss': 0.8265248889163617, 'Total loss': 0.8265248889163617}
2022-11-18 02:54:13,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:13,427 INFO:     Epoch: 53
2022-11-18 02:54:14,226 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7332995974204757, 'Total loss': 0.7332995974204757} | train loss {'Reaction outcome loss': 0.8277435289515603, 'Total loss': 0.8277435289515603}
2022-11-18 02:54:14,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:14,226 INFO:     Epoch: 54
2022-11-18 02:54:14,997 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7247717265378345, 'Total loss': 0.7247717265378345} | train loss {'Reaction outcome loss': 0.8202908207331935, 'Total loss': 0.8202908207331935}
2022-11-18 02:54:14,997 INFO:     Found new best model at epoch 54
2022-11-18 02:54:14,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:14,998 INFO:     Epoch: 55
2022-11-18 02:54:15,778 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7838603231039915, 'Total loss': 0.7838603231039915} | train loss {'Reaction outcome loss': 0.8229331115801488, 'Total loss': 0.8229331115801488}
2022-11-18 02:54:15,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:15,779 INFO:     Epoch: 56
2022-11-18 02:54:16,554 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7652070644226941, 'Total loss': 0.7652070644226941} | train loss {'Reaction outcome loss': 0.8263264953369095, 'Total loss': 0.8263264953369095}
2022-11-18 02:54:16,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:16,554 INFO:     Epoch: 57
2022-11-18 02:54:17,337 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7382929142225872, 'Total loss': 0.7382929142225872} | train loss {'Reaction outcome loss': 0.8233734208249277, 'Total loss': 0.8233734208249277}
2022-11-18 02:54:17,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:17,339 INFO:     Epoch: 58
2022-11-18 02:54:18,145 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7318127575245771, 'Total loss': 0.7318127575245771} | train loss {'Reaction outcome loss': 0.8206559289847651, 'Total loss': 0.8206559289847651}
2022-11-18 02:54:18,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:18,146 INFO:     Epoch: 59
2022-11-18 02:54:18,910 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7484831674532457, 'Total loss': 0.7484831674532457} | train loss {'Reaction outcome loss': 0.82617825618194, 'Total loss': 0.82617825618194}
2022-11-18 02:54:18,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:18,910 INFO:     Epoch: 60
2022-11-18 02:54:19,674 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.758940118280324, 'Total loss': 0.758940118280324} | train loss {'Reaction outcome loss': 0.8233468024240386, 'Total loss': 0.8233468024240386}
2022-11-18 02:54:19,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:19,675 INFO:     Epoch: 61
2022-11-18 02:54:20,451 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.733630006286231, 'Total loss': 0.733630006286231} | train loss {'Reaction outcome loss': 0.8229106302943922, 'Total loss': 0.8229106302943922}
2022-11-18 02:54:20,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:20,452 INFO:     Epoch: 62
2022-11-18 02:54:21,215 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7533875246616927, 'Total loss': 0.7533875246616927} | train loss {'Reaction outcome loss': 0.8242709850591998, 'Total loss': 0.8242709850591998}
2022-11-18 02:54:21,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:21,215 INFO:     Epoch: 63
2022-11-18 02:54:21,998 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7392032613808458, 'Total loss': 0.7392032613808458} | train loss {'Reaction outcome loss': 0.826441161214344, 'Total loss': 0.826441161214344}
2022-11-18 02:54:21,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:21,998 INFO:     Epoch: 64
2022-11-18 02:54:22,790 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7714837071570483, 'Total loss': 0.7714837071570483} | train loss {'Reaction outcome loss': 0.8245400614555805, 'Total loss': 0.8245400614555805}
2022-11-18 02:54:22,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:22,790 INFO:     Epoch: 65
2022-11-18 02:54:23,537 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7392455210739916, 'Total loss': 0.7392455210739916} | train loss {'Reaction outcome loss': 0.8214165255908044, 'Total loss': 0.8214165255908044}
2022-11-18 02:54:23,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:23,538 INFO:     Epoch: 66
2022-11-18 02:54:24,323 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7219806516712363, 'Total loss': 0.7219806516712363} | train loss {'Reaction outcome loss': 0.8217236781793256, 'Total loss': 0.8217236781793256}
2022-11-18 02:54:24,323 INFO:     Found new best model at epoch 66
2022-11-18 02:54:24,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:24,324 INFO:     Epoch: 67
2022-11-18 02:54:25,103 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7611655816435814, 'Total loss': 0.7611655816435814} | train loss {'Reaction outcome loss': 0.8221598658109864, 'Total loss': 0.8221598658109864}
2022-11-18 02:54:25,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:25,103 INFO:     Epoch: 68
2022-11-18 02:54:25,885 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7322882576422258, 'Total loss': 0.7322882576422258} | train loss {'Reaction outcome loss': 0.8262280762916611, 'Total loss': 0.8262280762916611}
2022-11-18 02:54:25,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:25,885 INFO:     Epoch: 69
2022-11-18 02:54:26,648 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7513785748319193, 'Total loss': 0.7513785748319193} | train loss {'Reaction outcome loss': 0.8266146124130295, 'Total loss': 0.8266146124130295}
2022-11-18 02:54:26,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:26,649 INFO:     Epoch: 70
2022-11-18 02:54:27,439 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7336188514124263, 'Total loss': 0.7336188514124263} | train loss {'Reaction outcome loss': 0.8260747315662522, 'Total loss': 0.8260747315662522}
2022-11-18 02:54:27,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:27,439 INFO:     Epoch: 71
2022-11-18 02:54:28,239 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7350236536426977, 'Total loss': 0.7350236536426977} | train loss {'Reaction outcome loss': 0.8213266669021498, 'Total loss': 0.8213266669021498}
2022-11-18 02:54:28,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:28,239 INFO:     Epoch: 72
2022-11-18 02:54:29,030 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.74309818175706, 'Total loss': 0.74309818175706} | train loss {'Reaction outcome loss': 0.8231497820346586, 'Total loss': 0.8231497820346586}
2022-11-18 02:54:29,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:29,031 INFO:     Epoch: 73
2022-11-18 02:54:29,807 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7385407516902144, 'Total loss': 0.7385407516902144} | train loss {'Reaction outcome loss': 0.828292369241676, 'Total loss': 0.828292369241676}
2022-11-18 02:54:29,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:29,808 INFO:     Epoch: 74
2022-11-18 02:54:30,587 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.729476002806967, 'Total loss': 0.729476002806967} | train loss {'Reaction outcome loss': 0.8222189207951869, 'Total loss': 0.8222189207951869}
2022-11-18 02:54:30,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:30,587 INFO:     Epoch: 75
2022-11-18 02:54:31,388 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7311772047118708, 'Total loss': 0.7311772047118708} | train loss {'Reaction outcome loss': 0.8237170712842096, 'Total loss': 0.8237170712842096}
2022-11-18 02:54:31,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:31,388 INFO:     Epoch: 76
2022-11-18 02:54:32,165 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7281358885494146, 'Total loss': 0.7281358885494146} | train loss {'Reaction outcome loss': 0.8253969503266196, 'Total loss': 0.8253969503266196}
2022-11-18 02:54:32,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:32,166 INFO:     Epoch: 77
2022-11-18 02:54:32,945 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7542502202770927, 'Total loss': 0.7542502202770927} | train loss {'Reaction outcome loss': 0.8268393255289523, 'Total loss': 0.8268393255289523}
2022-11-18 02:54:32,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:32,946 INFO:     Epoch: 78
2022-11-18 02:54:33,738 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7460494590076533, 'Total loss': 0.7460494590076533} | train loss {'Reaction outcome loss': 0.8269875310361385, 'Total loss': 0.8269875310361385}
2022-11-18 02:54:33,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:33,739 INFO:     Epoch: 79
2022-11-18 02:54:34,532 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7535816972905939, 'Total loss': 0.7535816972905939} | train loss {'Reaction outcome loss': 0.8192963922216047, 'Total loss': 0.8192963922216047}
2022-11-18 02:54:34,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:34,532 INFO:     Epoch: 80
2022-11-18 02:54:35,311 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.743940104815093, 'Total loss': 0.743940104815093} | train loss {'Reaction outcome loss': 0.819304354909447, 'Total loss': 0.819304354909447}
2022-11-18 02:54:35,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:35,311 INFO:     Epoch: 81
2022-11-18 02:54:36,095 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7441165047613058, 'Total loss': 0.7441165047613058} | train loss {'Reaction outcome loss': 0.8267459424753343, 'Total loss': 0.8267459424753343}
2022-11-18 02:54:36,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:36,095 INFO:     Epoch: 82
2022-11-18 02:54:36,877 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7536760189316489, 'Total loss': 0.7536760189316489} | train loss {'Reaction outcome loss': 0.8219267235648248, 'Total loss': 0.8219267235648248}
2022-11-18 02:54:36,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:36,877 INFO:     Epoch: 83
2022-11-18 02:54:37,670 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7286887419494715, 'Total loss': 0.7286887419494715} | train loss {'Reaction outcome loss': 0.8241576165441544, 'Total loss': 0.8241576165441544}
2022-11-18 02:54:37,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:37,670 INFO:     Epoch: 84
2022-11-18 02:54:38,451 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7349469817497514, 'Total loss': 0.7349469817497514} | train loss {'Reaction outcome loss': 0.8253038930556467, 'Total loss': 0.8253038930556467}
2022-11-18 02:54:38,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:38,452 INFO:     Epoch: 85
2022-11-18 02:54:39,231 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7427982843735002, 'Total loss': 0.7427982843735002} | train loss {'Reaction outcome loss': 0.8278220255048044, 'Total loss': 0.8278220255048044}
2022-11-18 02:54:39,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:39,231 INFO:     Epoch: 86
2022-11-18 02:54:39,998 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.739824881607836, 'Total loss': 0.739824881607836} | train loss {'Reaction outcome loss': 0.8215911786162085, 'Total loss': 0.8215911786162085}
2022-11-18 02:54:39,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:39,998 INFO:     Epoch: 87
2022-11-18 02:54:40,763 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7459985478357836, 'Total loss': 0.7459985478357836} | train loss {'Reaction outcome loss': 0.8275599215299853, 'Total loss': 0.8275599215299853}
2022-11-18 02:54:40,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:40,763 INFO:     Epoch: 88
2022-11-18 02:54:41,549 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7584699182347818, 'Total loss': 0.7584699182347818} | train loss {'Reaction outcome loss': 0.8274503750426154, 'Total loss': 0.8274503750426154}
2022-11-18 02:54:41,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:41,550 INFO:     Epoch: 89
2022-11-18 02:54:42,327 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7494377771561797, 'Total loss': 0.7494377771561797} | train loss {'Reaction outcome loss': 0.8198746982361039, 'Total loss': 0.8198746982361039}
2022-11-18 02:54:42,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:42,328 INFO:     Epoch: 90
2022-11-18 02:54:43,106 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7513587840578773, 'Total loss': 0.7513587840578773} | train loss {'Reaction outcome loss': 0.8234291253311019, 'Total loss': 0.8234291253311019}
2022-11-18 02:54:43,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:43,106 INFO:     Epoch: 91
2022-11-18 02:54:43,885 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7351896844126962, 'Total loss': 0.7351896844126962} | train loss {'Reaction outcome loss': 0.8235446334846558, 'Total loss': 0.8235446334846558}
2022-11-18 02:54:43,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:43,885 INFO:     Epoch: 92
2022-11-18 02:54:44,684 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7422636727040465, 'Total loss': 0.7422636727040465} | train loss {'Reaction outcome loss': 0.8261071644242732, 'Total loss': 0.8261071644242732}
2022-11-18 02:54:44,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:44,684 INFO:     Epoch: 93
2022-11-18 02:54:45,465 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7272990942001343, 'Total loss': 0.7272990942001343} | train loss {'Reaction outcome loss': 0.8264725439010128, 'Total loss': 0.8264725439010128}
2022-11-18 02:54:45,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:45,466 INFO:     Epoch: 94
2022-11-18 02:54:46,232 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7297436059875921, 'Total loss': 0.7297436059875921} | train loss {'Reaction outcome loss': 0.8197197260395173, 'Total loss': 0.8197197260395173}
2022-11-18 02:54:46,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:46,232 INFO:     Epoch: 95
2022-11-18 02:54:47,011 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7398478558117693, 'Total loss': 0.7398478558117693} | train loss {'Reaction outcome loss': 0.826310645788908, 'Total loss': 0.826310645788908}
2022-11-18 02:54:47,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:47,011 INFO:     Epoch: 96
2022-11-18 02:54:47,783 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7303951077840545, 'Total loss': 0.7303951077840545} | train loss {'Reaction outcome loss': 0.8246091913071371, 'Total loss': 0.8246091913071371}
2022-11-18 02:54:47,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:47,783 INFO:     Epoch: 97
2022-11-18 02:54:48,572 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7405099760402333, 'Total loss': 0.7405099760402333} | train loss {'Reaction outcome loss': 0.823013869745116, 'Total loss': 0.823013869745116}
2022-11-18 02:54:48,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:48,572 INFO:     Epoch: 98
2022-11-18 02:54:49,354 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7352938279509544, 'Total loss': 0.7352938279509544} | train loss {'Reaction outcome loss': 0.8239844443817292, 'Total loss': 0.8239844443817292}
2022-11-18 02:54:49,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:49,355 INFO:     Epoch: 99
2022-11-18 02:54:50,111 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7464139271866191, 'Total loss': 0.7464139271866191} | train loss {'Reaction outcome loss': 0.8220229628345659, 'Total loss': 0.8220229628345659}
2022-11-18 02:54:50,111 INFO:     Best model found after epoch 67 of 100.
2022-11-18 02:54:50,111 INFO:   Done with stage: TRAINING
2022-11-18 02:54:50,111 INFO:   Starting stage: EVALUATION
2022-11-18 02:54:50,232 INFO:   Done with stage: EVALUATION
2022-11-18 02:54:50,240 INFO:   Leaving out SEQ value Fold_0
2022-11-18 02:54:50,254 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:54:50,254 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:54:50,916 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:54:50,917 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:54:50,986 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:54:50,987 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:54:50,987 INFO:     No hyperparam tuning for this model
2022-11-18 02:54:50,987 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:54:50,987 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:54:50,988 INFO:     None feature selector for col prot
2022-11-18 02:54:50,988 INFO:     None feature selector for col prot
2022-11-18 02:54:50,988 INFO:     None feature selector for col prot
2022-11-18 02:54:50,989 INFO:     None feature selector for col chem
2022-11-18 02:54:50,989 INFO:     None feature selector for col chem
2022-11-18 02:54:50,989 INFO:     None feature selector for col chem
2022-11-18 02:54:50,989 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:54:50,989 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:54:50,990 INFO:     Number of params in model 168571
2022-11-18 02:54:50,994 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:54:50,994 INFO:   Starting stage: TRAINING
2022-11-18 02:54:51,052 INFO:     Val loss before train {'Reaction outcome loss': 1.0006217821077867, 'Total loss': 1.0006217821077867}
2022-11-18 02:54:51,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:51,052 INFO:     Epoch: 0
2022-11-18 02:54:51,820 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8263820734891024, 'Total loss': 0.8263820734891024} | train loss {'Reaction outcome loss': 0.8709404402849625, 'Total loss': 0.8709404402849625}
2022-11-18 02:54:51,820 INFO:     Found new best model at epoch 0
2022-11-18 02:54:51,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:51,821 INFO:     Epoch: 1
2022-11-18 02:54:52,573 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8078630282120272, 'Total loss': 0.8078630282120272} | train loss {'Reaction outcome loss': 0.8372435169560569, 'Total loss': 0.8372435169560569}
2022-11-18 02:54:52,573 INFO:     Found new best model at epoch 1
2022-11-18 02:54:52,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:52,574 INFO:     Epoch: 2
2022-11-18 02:54:53,342 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8152780004523017, 'Total loss': 0.8152780004523017} | train loss {'Reaction outcome loss': 0.8352270634806886, 'Total loss': 0.8352270634806886}
2022-11-18 02:54:53,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:53,342 INFO:     Epoch: 3
2022-11-18 02:54:54,096 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8206365772268989, 'Total loss': 0.8206365772268989} | train loss {'Reaction outcome loss': 0.829730047011862, 'Total loss': 0.829730047011862}
2022-11-18 02:54:54,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:54,096 INFO:     Epoch: 4
2022-11-18 02:54:54,873 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7865534668618982, 'Total loss': 0.7865534668618982} | train loss {'Reaction outcome loss': 0.8215280751792752, 'Total loss': 0.8215280751792752}
2022-11-18 02:54:54,873 INFO:     Found new best model at epoch 4
2022-11-18 02:54:54,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:54,874 INFO:     Epoch: 5
2022-11-18 02:54:55,658 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7840772555633024, 'Total loss': 0.7840772555633024} | train loss {'Reaction outcome loss': 0.8186948614461081, 'Total loss': 0.8186948614461081}
2022-11-18 02:54:55,658 INFO:     Found new best model at epoch 5
2022-11-18 02:54:55,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:55,659 INFO:     Epoch: 6
2022-11-18 02:54:56,436 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7897006117484786, 'Total loss': 0.7897006117484786} | train loss {'Reaction outcome loss': 0.8151954750625454, 'Total loss': 0.8151954750625454}
2022-11-18 02:54:56,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:56,437 INFO:     Epoch: 7
2022-11-18 02:54:57,208 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8268770135261796, 'Total loss': 0.8268770135261796} | train loss {'Reaction outcome loss': 0.8100657671081777, 'Total loss': 0.8100657671081777}
2022-11-18 02:54:57,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:57,208 INFO:     Epoch: 8
2022-11-18 02:54:57,988 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8094966018741782, 'Total loss': 0.8094966018741782} | train loss {'Reaction outcome loss': 0.8108736681694887, 'Total loss': 0.8108736681694887}
2022-11-18 02:54:57,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:57,988 INFO:     Epoch: 9
2022-11-18 02:54:58,769 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7891321927309036, 'Total loss': 0.7891321927309036} | train loss {'Reaction outcome loss': 0.8090170880969689, 'Total loss': 0.8090170880969689}
2022-11-18 02:54:58,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:58,769 INFO:     Epoch: 10
2022-11-18 02:54:59,533 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8201457160440359, 'Total loss': 0.8201457160440359} | train loss {'Reaction outcome loss': 0.8121019931472078, 'Total loss': 0.8121019931472078}
2022-11-18 02:54:59,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:54:59,533 INFO:     Epoch: 11
2022-11-18 02:55:00,316 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.796774530952627, 'Total loss': 0.796774530952627} | train loss {'Reaction outcome loss': 0.8101088377894188, 'Total loss': 0.8101088377894188}
2022-11-18 02:55:00,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:00,318 INFO:     Epoch: 12
2022-11-18 02:55:01,108 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8026386296207254, 'Total loss': 0.8026386296207254} | train loss {'Reaction outcome loss': 0.8109185212728929, 'Total loss': 0.8109185212728929}
2022-11-18 02:55:01,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:01,109 INFO:     Epoch: 13
2022-11-18 02:55:01,912 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8067171831022609, 'Total loss': 0.8067171831022609} | train loss {'Reaction outcome loss': 0.8114716053009033, 'Total loss': 0.8114716053009033}
2022-11-18 02:55:01,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:01,912 INFO:     Epoch: 14
2022-11-18 02:55:02,719 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7676395143974911, 'Total loss': 0.7676395143974911} | train loss {'Reaction outcome loss': 0.8076417640763887, 'Total loss': 0.8076417640763887}
2022-11-18 02:55:02,719 INFO:     Found new best model at epoch 14
2022-11-18 02:55:02,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:02,720 INFO:     Epoch: 15
2022-11-18 02:55:03,486 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7799317901107398, 'Total loss': 0.7799317901107398} | train loss {'Reaction outcome loss': 0.8027942136842378, 'Total loss': 0.8027942136842378}
2022-11-18 02:55:03,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:03,487 INFO:     Epoch: 16
2022-11-18 02:55:04,292 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7809344699436968, 'Total loss': 0.7809344699436968} | train loss {'Reaction outcome loss': 0.8013187131103204, 'Total loss': 0.8013187131103204}
2022-11-18 02:55:04,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:04,292 INFO:     Epoch: 17
2022-11-18 02:55:05,098 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7758691588586027, 'Total loss': 0.7758691588586027} | train loss {'Reaction outcome loss': 0.8087158669014366, 'Total loss': 0.8087158669014366}
2022-11-18 02:55:05,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:05,098 INFO:     Epoch: 18
2022-11-18 02:55:05,881 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7880277877504175, 'Total loss': 0.7880277877504175} | train loss {'Reaction outcome loss': 0.8054269557096521, 'Total loss': 0.8054269557096521}
2022-11-18 02:55:05,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:05,881 INFO:     Epoch: 19
2022-11-18 02:55:06,679 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7996837510304018, 'Total loss': 0.7996837510304018} | train loss {'Reaction outcome loss': 0.8078701392728456, 'Total loss': 0.8078701392728456}
2022-11-18 02:55:06,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:06,680 INFO:     Epoch: 20
2022-11-18 02:55:07,432 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7798481780019674, 'Total loss': 0.7798481780019674} | train loss {'Reaction outcome loss': 0.807265795007044, 'Total loss': 0.807265795007044}
2022-11-18 02:55:07,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:07,432 INFO:     Epoch: 21
2022-11-18 02:55:08,214 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.780473145571622, 'Total loss': 0.780473145571622} | train loss {'Reaction outcome loss': 0.8024222968792428, 'Total loss': 0.8024222968792428}
2022-11-18 02:55:08,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:08,214 INFO:     Epoch: 22
2022-11-18 02:55:08,985 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7976578948172656, 'Total loss': 0.7976578948172656} | train loss {'Reaction outcome loss': 0.8041417329895253, 'Total loss': 0.8041417329895253}
2022-11-18 02:55:08,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:08,985 INFO:     Epoch: 23
2022-11-18 02:55:09,764 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.795486023480242, 'Total loss': 0.795486023480242} | train loss {'Reaction outcome loss': 0.8066257228656691, 'Total loss': 0.8066257228656691}
2022-11-18 02:55:09,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:09,764 INFO:     Epoch: 24
2022-11-18 02:55:10,550 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7919129898602312, 'Total loss': 0.7919129898602312} | train loss {'Reaction outcome loss': 0.8055775142445856, 'Total loss': 0.8055775142445856}
2022-11-18 02:55:10,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:10,551 INFO:     Epoch: 25
2022-11-18 02:55:11,330 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7634452669457956, 'Total loss': 0.7634452669457956} | train loss {'Reaction outcome loss': 0.8024794961724963, 'Total loss': 0.8024794961724963}
2022-11-18 02:55:11,331 INFO:     Found new best model at epoch 25
2022-11-18 02:55:11,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:11,331 INFO:     Epoch: 26
2022-11-18 02:55:12,092 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7957704615863886, 'Total loss': 0.7957704615863886} | train loss {'Reaction outcome loss': 0.8020549965148069, 'Total loss': 0.8020549965148069}
2022-11-18 02:55:12,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:12,093 INFO:     Epoch: 27
2022-11-18 02:55:12,870 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8063112517649477, 'Total loss': 0.8063112517649477} | train loss {'Reaction outcome loss': 0.8073123574256897, 'Total loss': 0.8073123574256897}
2022-11-18 02:55:12,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:12,870 INFO:     Epoch: 28
2022-11-18 02:55:13,654 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7904576740481637, 'Total loss': 0.7904576740481637} | train loss {'Reaction outcome loss': 0.8073743772749998, 'Total loss': 0.8073743772749998}
2022-11-18 02:55:13,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:13,655 INFO:     Epoch: 29
2022-11-18 02:55:14,456 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8140353079546582, 'Total loss': 0.8140353079546582} | train loss {'Reaction outcome loss': 0.8002021492743979, 'Total loss': 0.8002021492743979}
2022-11-18 02:55:14,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:14,456 INFO:     Epoch: 30
2022-11-18 02:55:15,254 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7847043871879578, 'Total loss': 0.7847043871879578} | train loss {'Reaction outcome loss': 0.8028082475370291, 'Total loss': 0.8028082475370291}
2022-11-18 02:55:15,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:15,255 INFO:     Epoch: 31
2022-11-18 02:55:16,051 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7704600488597696, 'Total loss': 0.7704600488597696} | train loss {'Reaction outcome loss': 0.8034693849330046, 'Total loss': 0.8034693849330046}
2022-11-18 02:55:16,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:16,052 INFO:     Epoch: 32
2022-11-18 02:55:16,879 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7736518234014511, 'Total loss': 0.7736518234014511} | train loss {'Reaction outcome loss': 0.8026448293608062, 'Total loss': 0.8026448293608062}
2022-11-18 02:55:16,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:16,880 INFO:     Epoch: 33
2022-11-18 02:55:17,691 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7911313284527172, 'Total loss': 0.7911313284527172} | train loss {'Reaction outcome loss': 0.8093846878226922, 'Total loss': 0.8093846878226922}
2022-11-18 02:55:17,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:17,691 INFO:     Epoch: 34
2022-11-18 02:55:18,490 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8018422777002508, 'Total loss': 0.8018422777002508} | train loss {'Reaction outcome loss': 0.8045427805306961, 'Total loss': 0.8045427805306961}
2022-11-18 02:55:18,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:18,490 INFO:     Epoch: 35
2022-11-18 02:55:19,348 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7762994058430195, 'Total loss': 0.7762994058430195} | train loss {'Reaction outcome loss': 0.8063946755564942, 'Total loss': 0.8063946755564942}
2022-11-18 02:55:19,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:19,349 INFO:     Epoch: 36
2022-11-18 02:55:20,157 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7840860682454976, 'Total loss': 0.7840860682454976} | train loss {'Reaction outcome loss': 0.8010417748470695, 'Total loss': 0.8010417748470695}
2022-11-18 02:55:20,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:20,158 INFO:     Epoch: 37
2022-11-18 02:55:20,914 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7731800553473559, 'Total loss': 0.7731800553473559} | train loss {'Reaction outcome loss': 0.8044098352899357, 'Total loss': 0.8044098352899357}
2022-11-18 02:55:20,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:20,914 INFO:     Epoch: 38
2022-11-18 02:55:21,704 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7705149460922588, 'Total loss': 0.7705149460922588} | train loss {'Reaction outcome loss': 0.7991533208866508, 'Total loss': 0.7991533208866508}
2022-11-18 02:55:21,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:21,704 INFO:     Epoch: 39
2022-11-18 02:55:22,502 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7964506948536093, 'Total loss': 0.7964506948536093} | train loss {'Reaction outcome loss': 0.8039774276772323, 'Total loss': 0.8039774276772323}
2022-11-18 02:55:22,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:22,503 INFO:     Epoch: 40
2022-11-18 02:55:23,305 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7969556247646158, 'Total loss': 0.7969556247646158} | train loss {'Reaction outcome loss': 0.801517093059968, 'Total loss': 0.801517093059968}
2022-11-18 02:55:23,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:23,306 INFO:     Epoch: 41
2022-11-18 02:55:24,113 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7922101108865305, 'Total loss': 0.7922101108865305} | train loss {'Reaction outcome loss': 0.8052898683718273, 'Total loss': 0.8052898683718273}
2022-11-18 02:55:24,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:24,114 INFO:     Epoch: 42
2022-11-18 02:55:24,891 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.778795263306661, 'Total loss': 0.778795263306661} | train loss {'Reaction outcome loss': 0.7975443579712692, 'Total loss': 0.7975443579712692}
2022-11-18 02:55:24,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:24,892 INFO:     Epoch: 43
2022-11-18 02:55:25,649 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8048941804604097, 'Total loss': 0.8048941804604097} | train loss {'Reaction outcome loss': 0.8000726199879938, 'Total loss': 0.8000726199879938}
2022-11-18 02:55:25,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:25,649 INFO:     Epoch: 44
2022-11-18 02:55:26,408 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7656303639100357, 'Total loss': 0.7656303639100357} | train loss {'Reaction outcome loss': 0.8001884753606757, 'Total loss': 0.8001884753606757}
2022-11-18 02:55:26,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:26,409 INFO:     Epoch: 45
2022-11-18 02:55:27,237 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.760064618831331, 'Total loss': 0.760064618831331} | train loss {'Reaction outcome loss': 0.8015179337287436, 'Total loss': 0.8015179337287436}
2022-11-18 02:55:27,237 INFO:     Found new best model at epoch 45
2022-11-18 02:55:27,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:27,238 INFO:     Epoch: 46
2022-11-18 02:55:28,048 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7668049897659909, 'Total loss': 0.7668049897659909} | train loss {'Reaction outcome loss': 0.8034366973808833, 'Total loss': 0.8034366973808833}
2022-11-18 02:55:28,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:28,048 INFO:     Epoch: 47
2022-11-18 02:55:28,872 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7922330275177956, 'Total loss': 0.7922330275177956} | train loss {'Reaction outcome loss': 0.802346446076218, 'Total loss': 0.802346446076218}
2022-11-18 02:55:28,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:28,873 INFO:     Epoch: 48
2022-11-18 02:55:29,662 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7764990112998269, 'Total loss': 0.7764990112998269} | train loss {'Reaction outcome loss': 0.796878457069397, 'Total loss': 0.796878457069397}
2022-11-18 02:55:29,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:29,662 INFO:     Epoch: 49
2022-11-18 02:55:30,435 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7788712267171253, 'Total loss': 0.7788712267171253} | train loss {'Reaction outcome loss': 0.803928959004733, 'Total loss': 0.803928959004733}
2022-11-18 02:55:30,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:30,436 INFO:     Epoch: 50
2022-11-18 02:55:31,232 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.79385676167228, 'Total loss': 0.79385676167228} | train loss {'Reaction outcome loss': 0.8009089755768679, 'Total loss': 0.8009089755768679}
2022-11-18 02:55:31,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:31,232 INFO:     Epoch: 51
2022-11-18 02:55:32,049 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7933340424841101, 'Total loss': 0.7933340424841101} | train loss {'Reaction outcome loss': 0.8011138328484126, 'Total loss': 0.8011138328484126}
2022-11-18 02:55:32,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:32,051 INFO:     Epoch: 52
2022-11-18 02:55:32,877 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7765733247453516, 'Total loss': 0.7765733247453516} | train loss {'Reaction outcome loss': 0.7983718072881504, 'Total loss': 0.7983718072881504}
2022-11-18 02:55:32,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:32,877 INFO:     Epoch: 53
2022-11-18 02:55:33,694 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.781260612336072, 'Total loss': 0.781260612336072} | train loss {'Reaction outcome loss': 0.7981213379879387, 'Total loss': 0.7981213379879387}
2022-11-18 02:55:33,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:33,695 INFO:     Epoch: 54
2022-11-18 02:55:34,532 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7936955107883974, 'Total loss': 0.7936955107883974} | train loss {'Reaction outcome loss': 0.7981837384554804, 'Total loss': 0.7981837384554804}
2022-11-18 02:55:34,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:34,532 INFO:     Epoch: 55
2022-11-18 02:55:35,342 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7887645248662342, 'Total loss': 0.7887645248662342} | train loss {'Reaction outcome loss': 0.7997710369071181, 'Total loss': 0.7997710369071181}
2022-11-18 02:55:35,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:35,342 INFO:     Epoch: 56
2022-11-18 02:55:36,129 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7850181677124717, 'Total loss': 0.7850181677124717} | train loss {'Reaction outcome loss': 0.8020217474626035, 'Total loss': 0.8020217474626035}
2022-11-18 02:55:36,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:36,129 INFO:     Epoch: 57
2022-11-18 02:55:36,924 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7909847443754022, 'Total loss': 0.7909847443754022} | train loss {'Reaction outcome loss': 0.8004067863736833, 'Total loss': 0.8004067863736833}
2022-11-18 02:55:36,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:36,925 INFO:     Epoch: 58
2022-11-18 02:55:37,681 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.777028117667545, 'Total loss': 0.777028117667545} | train loss {'Reaction outcome loss': 0.8026880225356744, 'Total loss': 0.8026880225356744}
2022-11-18 02:55:37,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:37,681 INFO:     Epoch: 59
2022-11-18 02:55:38,443 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8029315539381721, 'Total loss': 0.8029315539381721} | train loss {'Reaction outcome loss': 0.7975651344474481, 'Total loss': 0.7975651344474481}
2022-11-18 02:55:38,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:38,444 INFO:     Epoch: 60
2022-11-18 02:55:39,196 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7893406870690259, 'Total loss': 0.7893406870690259} | train loss {'Reaction outcome loss': 0.8004457049223841, 'Total loss': 0.8004457049223841}
2022-11-18 02:55:39,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:39,196 INFO:     Epoch: 61
2022-11-18 02:55:39,943 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.830880655483766, 'Total loss': 0.830880655483766} | train loss {'Reaction outcome loss': 0.8013858453351624, 'Total loss': 0.8013858453351624}
2022-11-18 02:55:39,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:39,943 INFO:     Epoch: 62
2022-11-18 02:55:40,722 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7728460451418703, 'Total loss': 0.7728460451418703} | train loss {'Reaction outcome loss': 0.7994445722930286, 'Total loss': 0.7994445722930286}
2022-11-18 02:55:40,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:40,723 INFO:     Epoch: 63
2022-11-18 02:55:41,495 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8011046918955717, 'Total loss': 0.8011046918955717} | train loss {'Reaction outcome loss': 0.8031580687785635, 'Total loss': 0.8031580687785635}
2022-11-18 02:55:41,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:41,495 INFO:     Epoch: 64
2022-11-18 02:55:42,264 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7805209037932482, 'Total loss': 0.7805209037932482} | train loss {'Reaction outcome loss': 0.7981356827580199, 'Total loss': 0.7981356827580199}
2022-11-18 02:55:42,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:42,265 INFO:     Epoch: 65
2022-11-18 02:55:43,040 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7844644046642564, 'Total loss': 0.7844644046642564} | train loss {'Reaction outcome loss': 0.8008378059280162, 'Total loss': 0.8008378059280162}
2022-11-18 02:55:43,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:43,041 INFO:     Epoch: 66
2022-11-18 02:55:43,810 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7753885280002247, 'Total loss': 0.7753885280002247} | train loss {'Reaction outcome loss': 0.7986861855399852, 'Total loss': 0.7986861855399852}
2022-11-18 02:55:43,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:43,810 INFO:     Epoch: 67
2022-11-18 02:55:44,580 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8115506686947562, 'Total loss': 0.8115506686947562} | train loss {'Reaction outcome loss': 0.7969449021378342, 'Total loss': 0.7969449021378342}
2022-11-18 02:55:44,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:44,580 INFO:     Epoch: 68
2022-11-18 02:55:45,379 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.77762847867879, 'Total loss': 0.77762847867879} | train loss {'Reaction outcome loss': 0.798462328132318, 'Total loss': 0.798462328132318}
2022-11-18 02:55:45,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:45,380 INFO:     Epoch: 69
2022-11-18 02:55:46,190 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8010109541091052, 'Total loss': 0.8010109541091052} | train loss {'Reaction outcome loss': 0.79781160853347, 'Total loss': 0.79781160853347}
2022-11-18 02:55:46,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:46,190 INFO:     Epoch: 70
2022-11-18 02:55:46,983 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7891239273277196, 'Total loss': 0.7891239273277196} | train loss {'Reaction outcome loss': 0.8030413689661999, 'Total loss': 0.8030413689661999}
2022-11-18 02:55:46,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:46,983 INFO:     Epoch: 71
2022-11-18 02:55:47,775 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7725923989306797, 'Total loss': 0.7725923989306797} | train loss {'Reaction outcome loss': 0.7954430711512663, 'Total loss': 0.7954430711512663}
2022-11-18 02:55:47,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:47,775 INFO:     Epoch: 72
2022-11-18 02:55:48,569 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7757875330068849, 'Total loss': 0.7757875330068849} | train loss {'Reaction outcome loss': 0.7988059212966842, 'Total loss': 0.7988059212966842}
2022-11-18 02:55:48,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:48,569 INFO:     Epoch: 73
2022-11-18 02:55:49,347 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7553465554321354, 'Total loss': 0.7553465554321354} | train loss {'Reaction outcome loss': 0.7956002911742852, 'Total loss': 0.7956002911742852}
2022-11-18 02:55:49,347 INFO:     Found new best model at epoch 73
2022-11-18 02:55:49,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:49,348 INFO:     Epoch: 74
2022-11-18 02:55:50,094 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7945000664754347, 'Total loss': 0.7945000664754347} | train loss {'Reaction outcome loss': 0.8013020193090244, 'Total loss': 0.8013020193090244}
2022-11-18 02:55:50,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:50,094 INFO:     Epoch: 75
2022-11-18 02:55:50,942 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7862244918942451, 'Total loss': 0.7862244918942451} | train loss {'Reaction outcome loss': 0.8035907264874906, 'Total loss': 0.8035907264874906}
2022-11-18 02:55:50,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:50,943 INFO:     Epoch: 76
2022-11-18 02:55:51,717 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7916738387535919, 'Total loss': 0.7916738387535919} | train loss {'Reaction outcome loss': 0.7953627178863604, 'Total loss': 0.7953627178863604}
2022-11-18 02:55:51,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:51,717 INFO:     Epoch: 77
2022-11-18 02:55:52,487 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7771077985790643, 'Total loss': 0.7771077985790643} | train loss {'Reaction outcome loss': 0.7964815532674595, 'Total loss': 0.7964815532674595}
2022-11-18 02:55:52,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:52,488 INFO:     Epoch: 78
2022-11-18 02:55:53,223 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7758152200417086, 'Total loss': 0.7758152200417086} | train loss {'Reaction outcome loss': 0.7959008977121237, 'Total loss': 0.7959008977121237}
2022-11-18 02:55:53,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:53,223 INFO:     Epoch: 79
2022-11-18 02:55:54,000 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7622364800084721, 'Total loss': 0.7622364800084721} | train loss {'Reaction outcome loss': 0.795947114727935, 'Total loss': 0.795947114727935}
2022-11-18 02:55:54,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:54,001 INFO:     Epoch: 80
2022-11-18 02:55:54,768 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7985580048777841, 'Total loss': 0.7985580048777841} | train loss {'Reaction outcome loss': 0.801891071151714, 'Total loss': 0.801891071151714}
2022-11-18 02:55:54,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:54,769 INFO:     Epoch: 81
2022-11-18 02:55:55,541 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7794216945767403, 'Total loss': 0.7794216945767403} | train loss {'Reaction outcome loss': 0.8003582617458032, 'Total loss': 0.8003582617458032}
2022-11-18 02:55:55,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:55,541 INFO:     Epoch: 82
2022-11-18 02:55:56,322 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7682753259485419, 'Total loss': 0.7682753259485419} | train loss {'Reaction outcome loss': 0.7978744191782815, 'Total loss': 0.7978744191782815}
2022-11-18 02:55:56,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:56,322 INFO:     Epoch: 83
2022-11-18 02:55:57,096 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8188978453928774, 'Total loss': 0.8188978453928774} | train loss {'Reaction outcome loss': 0.8006779819118733, 'Total loss': 0.8006779819118733}
2022-11-18 02:55:57,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:57,097 INFO:     Epoch: 84
2022-11-18 02:55:57,862 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7675837928598578, 'Total loss': 0.7675837928598578} | train loss {'Reaction outcome loss': 0.7964822618328795, 'Total loss': 0.7964822618328795}
2022-11-18 02:55:57,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:57,862 INFO:     Epoch: 85
2022-11-18 02:55:58,668 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7774263606830076, 'Total loss': 0.7774263606830076} | train loss {'Reaction outcome loss': 0.7979441848336434, 'Total loss': 0.7979441848336434}
2022-11-18 02:55:58,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:58,669 INFO:     Epoch: 86
2022-11-18 02:55:59,434 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7674903226169673, 'Total loss': 0.7674903226169673} | train loss {'Reaction outcome loss': 0.7966231780392783, 'Total loss': 0.7966231780392783}
2022-11-18 02:55:59,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:55:59,434 INFO:     Epoch: 87
2022-11-18 02:56:00,238 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7864379767667163, 'Total loss': 0.7864379767667163} | train loss {'Reaction outcome loss': 0.7965676970627843, 'Total loss': 0.7965676970627843}
2022-11-18 02:56:00,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:00,238 INFO:     Epoch: 88
2022-11-18 02:56:01,011 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.768216768449003, 'Total loss': 0.768216768449003} | train loss {'Reaction outcome loss': 0.799043119136168, 'Total loss': 0.799043119136168}
2022-11-18 02:56:01,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:01,011 INFO:     Epoch: 89
2022-11-18 02:56:01,779 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7960487360304053, 'Total loss': 0.7960487360304053} | train loss {'Reaction outcome loss': 0.8001026857872399, 'Total loss': 0.8001026857872399}
2022-11-18 02:56:01,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:01,780 INFO:     Epoch: 90
2022-11-18 02:56:02,578 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7943133982745084, 'Total loss': 0.7943133982745084} | train loss {'Reaction outcome loss': 0.8000926601643465, 'Total loss': 0.8000926601643465}
2022-11-18 02:56:02,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:02,578 INFO:     Epoch: 91
2022-11-18 02:56:03,351 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7819693034345453, 'Total loss': 0.7819693034345453} | train loss {'Reaction outcome loss': 0.8016643612968678, 'Total loss': 0.8016643612968678}
2022-11-18 02:56:03,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:03,353 INFO:     Epoch: 92
2022-11-18 02:56:04,102 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7774787220087919, 'Total loss': 0.7774787220087919} | train loss {'Reaction outcome loss': 0.7959572433208932, 'Total loss': 0.7959572433208932}
2022-11-18 02:56:04,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:04,102 INFO:     Epoch: 93
2022-11-18 02:56:04,868 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8191125311634757, 'Total loss': 0.8191125311634757} | train loss {'Reaction outcome loss': 0.7929181637812633, 'Total loss': 0.7929181637812633}
2022-11-18 02:56:04,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:04,869 INFO:     Epoch: 94
2022-11-18 02:56:05,663 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7990082874894142, 'Total loss': 0.7990082874894142} | train loss {'Reaction outcome loss': 0.8002719049551049, 'Total loss': 0.8002719049551049}
2022-11-18 02:56:05,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:05,663 INFO:     Epoch: 95
2022-11-18 02:56:06,436 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8061305704441938, 'Total loss': 0.8061305704441938} | train loss {'Reaction outcome loss': 0.7931141068740767, 'Total loss': 0.7931141068740767}
2022-11-18 02:56:06,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:06,436 INFO:     Epoch: 96
2022-11-18 02:56:07,218 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7682138383388519, 'Total loss': 0.7682138383388519} | train loss {'Reaction outcome loss': 0.8006536751377339, 'Total loss': 0.8006536751377339}
2022-11-18 02:56:07,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:07,219 INFO:     Epoch: 97
2022-11-18 02:56:08,007 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8026117106730287, 'Total loss': 0.8026117106730287} | train loss {'Reaction outcome loss': 0.7980214084897722, 'Total loss': 0.7980214084897722}
2022-11-18 02:56:08,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:08,007 INFO:     Epoch: 98
2022-11-18 02:56:08,784 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7812113802541386, 'Total loss': 0.7812113802541386} | train loss {'Reaction outcome loss': 0.7978177878321434, 'Total loss': 0.7978177878321434}
2022-11-18 02:56:08,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:08,784 INFO:     Epoch: 99
2022-11-18 02:56:09,572 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7871755022894252, 'Total loss': 0.7871755022894252} | train loss {'Reaction outcome loss': 0.7982180130725004, 'Total loss': 0.7982180130725004}
2022-11-18 02:56:09,573 INFO:     Best model found after epoch 74 of 100.
2022-11-18 02:56:09,573 INFO:   Done with stage: TRAINING
2022-11-18 02:56:09,573 INFO:   Starting stage: EVALUATION
2022-11-18 02:56:09,704 INFO:   Done with stage: EVALUATION
2022-11-18 02:56:09,704 INFO:   Leaving out SEQ value Fold_1
2022-11-18 02:56:09,718 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:56:09,718 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:56:10,384 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:56:10,384 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:56:10,453 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:56:10,453 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:56:10,453 INFO:     No hyperparam tuning for this model
2022-11-18 02:56:10,454 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:56:10,454 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:56:10,454 INFO:     None feature selector for col prot
2022-11-18 02:56:10,455 INFO:     None feature selector for col prot
2022-11-18 02:56:10,455 INFO:     None feature selector for col prot
2022-11-18 02:56:10,455 INFO:     None feature selector for col chem
2022-11-18 02:56:10,456 INFO:     None feature selector for col chem
2022-11-18 02:56:10,456 INFO:     None feature selector for col chem
2022-11-18 02:56:10,456 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:56:10,456 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:56:10,457 INFO:     Number of params in model 168571
2022-11-18 02:56:10,461 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:56:10,461 INFO:   Starting stage: TRAINING
2022-11-18 02:56:10,518 INFO:     Val loss before train {'Reaction outcome loss': 1.0542433668266644, 'Total loss': 1.0542433668266644}
2022-11-18 02:56:10,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:10,518 INFO:     Epoch: 0
2022-11-18 02:56:11,279 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.846447738056833, 'Total loss': 0.846447738056833} | train loss {'Reaction outcome loss': 0.875569875872865, 'Total loss': 0.875569875872865}
2022-11-18 02:56:11,279 INFO:     Found new best model at epoch 0
2022-11-18 02:56:11,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:11,280 INFO:     Epoch: 1
2022-11-18 02:56:12,067 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8498042808337645, 'Total loss': 0.8498042808337645} | train loss {'Reaction outcome loss': 0.843966843643967, 'Total loss': 0.843966843643967}
2022-11-18 02:56:12,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:12,067 INFO:     Epoch: 2
2022-11-18 02:56:12,836 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8234481804750182, 'Total loss': 0.8234481804750182} | train loss {'Reaction outcome loss': 0.8393142846165871, 'Total loss': 0.8393142846165871}
2022-11-18 02:56:12,837 INFO:     Found new best model at epoch 2
2022-11-18 02:56:12,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:12,837 INFO:     Epoch: 3
2022-11-18 02:56:13,591 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8639964772896334, 'Total loss': 0.8639964772896334} | train loss {'Reaction outcome loss': 0.8356885039076514, 'Total loss': 0.8356885039076514}
2022-11-18 02:56:13,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:13,591 INFO:     Epoch: 4
2022-11-18 02:56:14,392 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8412189896811139, 'Total loss': 0.8412189896811139} | train loss {'Reaction outcome loss': 0.8335705449386519, 'Total loss': 0.8335705449386519}
2022-11-18 02:56:14,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:14,393 INFO:     Epoch: 5
2022-11-18 02:56:15,188 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8242812691764398, 'Total loss': 0.8242812691764398} | train loss {'Reaction outcome loss': 0.8321821423209443, 'Total loss': 0.8321821423209443}
2022-11-18 02:56:15,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:15,188 INFO:     Epoch: 6
2022-11-18 02:56:15,999 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8408892384984277, 'Total loss': 0.8408892384984277} | train loss {'Reaction outcome loss': 0.8253513112360117, 'Total loss': 0.8253513112360117}
2022-11-18 02:56:15,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:15,999 INFO:     Epoch: 7
2022-11-18 02:56:16,761 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8146873306144368, 'Total loss': 0.8146873306144368} | train loss {'Reaction outcome loss': 0.826332150065169, 'Total loss': 0.826332150065169}
2022-11-18 02:56:16,761 INFO:     Found new best model at epoch 7
2022-11-18 02:56:16,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:16,762 INFO:     Epoch: 8
2022-11-18 02:56:17,577 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8112222958694805, 'Total loss': 0.8112222958694805} | train loss {'Reaction outcome loss': 0.820137505020414, 'Total loss': 0.820137505020414}
2022-11-18 02:56:17,577 INFO:     Found new best model at epoch 8
2022-11-18 02:56:17,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:17,578 INFO:     Epoch: 9
2022-11-18 02:56:18,334 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8258486972613768, 'Total loss': 0.8258486972613768} | train loss {'Reaction outcome loss': 0.8215222844055721, 'Total loss': 0.8215222844055721}
2022-11-18 02:56:18,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:18,335 INFO:     Epoch: 10
2022-11-18 02:56:19,098 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8102607652544975, 'Total loss': 0.8102607652544975} | train loss {'Reaction outcome loss': 0.8242793018720588, 'Total loss': 0.8242793018720588}
2022-11-18 02:56:19,098 INFO:     Found new best model at epoch 10
2022-11-18 02:56:19,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:19,099 INFO:     Epoch: 11
2022-11-18 02:56:19,887 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8375198062170636, 'Total loss': 0.8375198062170636} | train loss {'Reaction outcome loss': 0.8180599216295749, 'Total loss': 0.8180599216295749}
2022-11-18 02:56:19,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:19,887 INFO:     Epoch: 12
2022-11-18 02:56:20,639 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8306881473823027, 'Total loss': 0.8306881473823027} | train loss {'Reaction outcome loss': 0.8225077902784153, 'Total loss': 0.8225077902784153}
2022-11-18 02:56:20,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:20,640 INFO:     Epoch: 13
2022-11-18 02:56:21,426 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8362942459908399, 'Total loss': 0.8362942459908399} | train loss {'Reaction outcome loss': 0.8213712142438304, 'Total loss': 0.8213712142438304}
2022-11-18 02:56:21,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:21,427 INFO:     Epoch: 14
2022-11-18 02:56:22,202 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8174525025216016, 'Total loss': 0.8174525025216016} | train loss {'Reaction outcome loss': 0.8159493633678981, 'Total loss': 0.8159493633678981}
2022-11-18 02:56:22,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:22,203 INFO:     Epoch: 15
2022-11-18 02:56:22,993 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8144727884368463, 'Total loss': 0.8144727884368463} | train loss {'Reaction outcome loss': 0.8156778279615908, 'Total loss': 0.8156778279615908}
2022-11-18 02:56:22,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:22,993 INFO:     Epoch: 16
2022-11-18 02:56:23,773 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8143946968696334, 'Total loss': 0.8143946968696334} | train loss {'Reaction outcome loss': 0.8164639865865513, 'Total loss': 0.8164639865865513}
2022-11-18 02:56:23,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:23,774 INFO:     Epoch: 17
2022-11-18 02:56:24,568 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8505567481571977, 'Total loss': 0.8505567481571977} | train loss {'Reaction outcome loss': 0.8129632875627401, 'Total loss': 0.8129632875627401}
2022-11-18 02:56:24,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:24,568 INFO:     Epoch: 18
2022-11-18 02:56:25,349 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8337023976174268, 'Total loss': 0.8337023976174268} | train loss {'Reaction outcome loss': 0.8167595964305255, 'Total loss': 0.8167595964305255}
2022-11-18 02:56:25,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:25,349 INFO:     Epoch: 19
2022-11-18 02:56:26,094 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8149451396682046, 'Total loss': 0.8149451396682046} | train loss {'Reaction outcome loss': 0.8159233354792303, 'Total loss': 0.8159233354792303}
2022-11-18 02:56:26,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:26,095 INFO:     Epoch: 20
2022-11-18 02:56:26,881 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8184230375018987, 'Total loss': 0.8184230375018987} | train loss {'Reaction outcome loss': 0.8111317520238915, 'Total loss': 0.8111317520238915}
2022-11-18 02:56:26,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:26,881 INFO:     Epoch: 21
2022-11-18 02:56:27,629 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8156231296333399, 'Total loss': 0.8156231296333399} | train loss {'Reaction outcome loss': 0.8152515857803578, 'Total loss': 0.8152515857803578}
2022-11-18 02:56:27,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:27,630 INFO:     Epoch: 22
2022-11-18 02:56:28,401 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8069073151458394, 'Total loss': 0.8069073151458394} | train loss {'Reaction outcome loss': 0.812278204913042, 'Total loss': 0.812278204913042}
2022-11-18 02:56:28,401 INFO:     Found new best model at epoch 22
2022-11-18 02:56:28,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:28,402 INFO:     Epoch: 23
2022-11-18 02:56:29,178 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8043905737047846, 'Total loss': 0.8043905737047846} | train loss {'Reaction outcome loss': 0.8104563604812233, 'Total loss': 0.8104563604812233}
2022-11-18 02:56:29,178 INFO:     Found new best model at epoch 23
2022-11-18 02:56:29,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:29,179 INFO:     Epoch: 24
2022-11-18 02:56:29,972 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8011138263073835, 'Total loss': 0.8011138263073835} | train loss {'Reaction outcome loss': 0.8137772100312369, 'Total loss': 0.8137772100312369}
2022-11-18 02:56:29,972 INFO:     Found new best model at epoch 24
2022-11-18 02:56:29,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:29,973 INFO:     Epoch: 25
2022-11-18 02:56:30,743 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8347345008091493, 'Total loss': 0.8347345008091493} | train loss {'Reaction outcome loss': 0.8121323310599036, 'Total loss': 0.8121323310599036}
2022-11-18 02:56:30,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:30,743 INFO:     Epoch: 26
2022-11-18 02:56:31,507 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8095662681893869, 'Total loss': 0.8095662681893869} | train loss {'Reaction outcome loss': 0.8094707287087732, 'Total loss': 0.8094707287087732}
2022-11-18 02:56:31,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:31,507 INFO:     Epoch: 27
2022-11-18 02:56:32,352 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8293082199313424, 'Total loss': 0.8293082199313424} | train loss {'Reaction outcome loss': 0.8055484066204149, 'Total loss': 0.8055484066204149}
2022-11-18 02:56:32,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:32,352 INFO:     Epoch: 28
2022-11-18 02:56:33,139 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7968450771136717, 'Total loss': 0.7968450771136717} | train loss {'Reaction outcome loss': 0.8090960899177863, 'Total loss': 0.8090960899177863}
2022-11-18 02:56:33,140 INFO:     Found new best model at epoch 28
2022-11-18 02:56:33,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:33,141 INFO:     Epoch: 29
2022-11-18 02:56:33,960 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8297657180916179, 'Total loss': 0.8297657180916179} | train loss {'Reaction outcome loss': 0.8095665225569083, 'Total loss': 0.8095665225569083}
2022-11-18 02:56:33,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:33,961 INFO:     Epoch: 30
2022-11-18 02:56:34,744 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8394692946564067, 'Total loss': 0.8394692946564067} | train loss {'Reaction outcome loss': 0.8113413512706756, 'Total loss': 0.8113413512706756}
2022-11-18 02:56:34,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:34,744 INFO:     Epoch: 31
2022-11-18 02:56:35,504 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8198030936447057, 'Total loss': 0.8198030936447057} | train loss {'Reaction outcome loss': 0.8082449863151628, 'Total loss': 0.8082449863151628}
2022-11-18 02:56:35,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:35,505 INFO:     Epoch: 32
2022-11-18 02:56:36,310 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.810269336131486, 'Total loss': 0.810269336131486} | train loss {'Reaction outcome loss': 0.8053159038631283, 'Total loss': 0.8053159038631283}
2022-11-18 02:56:36,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:36,310 INFO:     Epoch: 33
2022-11-18 02:56:37,096 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.801640167155049, 'Total loss': 0.801640167155049} | train loss {'Reaction outcome loss': 0.8096808147673704, 'Total loss': 0.8096808147673704}
2022-11-18 02:56:37,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:37,097 INFO:     Epoch: 34
2022-11-18 02:56:37,885 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7923620106144385, 'Total loss': 0.7923620106144385} | train loss {'Reaction outcome loss': 0.8081350268149863, 'Total loss': 0.8081350268149863}
2022-11-18 02:56:37,885 INFO:     Found new best model at epoch 34
2022-11-18 02:56:37,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:37,886 INFO:     Epoch: 35
2022-11-18 02:56:38,693 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8100916675545953, 'Total loss': 0.8100916675545953} | train loss {'Reaction outcome loss': 0.806548869853117, 'Total loss': 0.806548869853117}
2022-11-18 02:56:38,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:38,693 INFO:     Epoch: 36
2022-11-18 02:56:39,475 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.805038112131032, 'Total loss': 0.805038112131032} | train loss {'Reaction outcome loss': 0.8087492701958637, 'Total loss': 0.8087492701958637}
2022-11-18 02:56:39,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:39,475 INFO:     Epoch: 37
2022-11-18 02:56:40,256 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7993727014823393, 'Total loss': 0.7993727014823393} | train loss {'Reaction outcome loss': 0.8106981352883942, 'Total loss': 0.8106981352883942}
2022-11-18 02:56:40,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:40,256 INFO:     Epoch: 38
2022-11-18 02:56:41,034 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8369996507059444, 'Total loss': 0.8369996507059444} | train loss {'Reaction outcome loss': 0.8079850672459116, 'Total loss': 0.8079850672459116}
2022-11-18 02:56:41,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:41,035 INFO:     Epoch: 39
2022-11-18 02:56:41,821 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8117265714840456, 'Total loss': 0.8117265714840456} | train loss {'Reaction outcome loss': 0.8098795439515795, 'Total loss': 0.8098795439515795}
2022-11-18 02:56:41,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:41,821 INFO:     Epoch: 40
2022-11-18 02:56:42,600 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8632328645749525, 'Total loss': 0.8632328645749525} | train loss {'Reaction outcome loss': 0.8082575964684389, 'Total loss': 0.8082575964684389}
2022-11-18 02:56:42,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:42,600 INFO:     Epoch: 41
2022-11-18 02:56:43,393 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8037194189700213, 'Total loss': 0.8037194189700213} | train loss {'Reaction outcome loss': 0.8099454199781223, 'Total loss': 0.8099454199781223}
2022-11-18 02:56:43,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:43,394 INFO:     Epoch: 42
2022-11-18 02:56:44,157 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8005900843576952, 'Total loss': 0.8005900843576952} | train loss {'Reaction outcome loss': 0.8095608339017751, 'Total loss': 0.8095608339017751}
2022-11-18 02:56:44,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:44,157 INFO:     Epoch: 43
2022-11-18 02:56:44,946 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8108408193696629, 'Total loss': 0.8108408193696629} | train loss {'Reaction outcome loss': 0.8113078326595072, 'Total loss': 0.8113078326595072}
2022-11-18 02:56:44,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:44,946 INFO:     Epoch: 44
2022-11-18 02:56:45,760 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7898842015049674, 'Total loss': 0.7898842015049674} | train loss {'Reaction outcome loss': 0.8022766728790439, 'Total loss': 0.8022766728790439}
2022-11-18 02:56:45,761 INFO:     Found new best model at epoch 44
2022-11-18 02:56:45,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:45,761 INFO:     Epoch: 45
2022-11-18 02:56:46,562 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7944216585972093, 'Total loss': 0.7944216585972093} | train loss {'Reaction outcome loss': 0.8068476144148379, 'Total loss': 0.8068476144148379}
2022-11-18 02:56:46,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:46,562 INFO:     Epoch: 46
2022-11-18 02:56:47,315 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8185998526486483, 'Total loss': 0.8185998526486483} | train loss {'Reaction outcome loss': 0.8105578103844, 'Total loss': 0.8105578103844}
2022-11-18 02:56:47,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:47,315 INFO:     Epoch: 47
2022-11-18 02:56:48,089 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7989066791805354, 'Total loss': 0.7989066791805354} | train loss {'Reaction outcome loss': 0.8078796774757152, 'Total loss': 0.8078796774757152}
2022-11-18 02:56:48,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:48,089 INFO:     Epoch: 48
2022-11-18 02:56:48,874 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.812386270951141, 'Total loss': 0.812386270951141} | train loss {'Reaction outcome loss': 0.8097073782463463, 'Total loss': 0.8097073782463463}
2022-11-18 02:56:48,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:48,874 INFO:     Epoch: 49
2022-11-18 02:56:49,620 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8021145835518837, 'Total loss': 0.8021145835518837} | train loss {'Reaction outcome loss': 0.8070976503041326, 'Total loss': 0.8070976503041326}
2022-11-18 02:56:49,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:49,621 INFO:     Epoch: 50
2022-11-18 02:56:50,385 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8019682663408193, 'Total loss': 0.8019682663408193} | train loss {'Reaction outcome loss': 0.8108408961369067, 'Total loss': 0.8108408961369067}
2022-11-18 02:56:50,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:50,385 INFO:     Epoch: 51
2022-11-18 02:56:51,164 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.835564249618487, 'Total loss': 0.835564249618487} | train loss {'Reaction outcome loss': 0.8055491013186319, 'Total loss': 0.8055491013186319}
2022-11-18 02:56:51,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:51,164 INFO:     Epoch: 52
2022-11-18 02:56:51,958 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8067079470916227, 'Total loss': 0.8067079470916227} | train loss {'Reaction outcome loss': 0.8051789160893887, 'Total loss': 0.8051789160893887}
2022-11-18 02:56:51,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:51,959 INFO:     Epoch: 53
2022-11-18 02:56:52,730 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8040667338804766, 'Total loss': 0.8040667338804766} | train loss {'Reaction outcome loss': 0.8128631691543423, 'Total loss': 0.8128631691543423}
2022-11-18 02:56:52,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:52,730 INFO:     Epoch: 54
2022-11-18 02:56:53,517 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8221557946367697, 'Total loss': 0.8221557946367697} | train loss {'Reaction outcome loss': 0.8088051755817569, 'Total loss': 0.8088051755817569}
2022-11-18 02:56:53,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:53,517 INFO:     Epoch: 55
2022-11-18 02:56:54,296 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8398875621232119, 'Total loss': 0.8398875621232119} | train loss {'Reaction outcome loss': 0.8110780663636266, 'Total loss': 0.8110780663636266}
2022-11-18 02:56:54,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:54,296 INFO:     Epoch: 56
2022-11-18 02:56:55,070 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.812293947420337, 'Total loss': 0.812293947420337} | train loss {'Reaction outcome loss': 0.8113633697130243, 'Total loss': 0.8113633697130243}
2022-11-18 02:56:55,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:55,070 INFO:     Epoch: 57
2022-11-18 02:56:55,837 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8217939592220567, 'Total loss': 0.8217939592220567} | train loss {'Reaction outcome loss': 0.8072837260304665, 'Total loss': 0.8072837260304665}
2022-11-18 02:56:55,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:55,838 INFO:     Epoch: 58
2022-11-18 02:56:56,607 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8108470927585255, 'Total loss': 0.8108470927585255} | train loss {'Reaction outcome loss': 0.8079818897101344, 'Total loss': 0.8079818897101344}
2022-11-18 02:56:56,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:56,607 INFO:     Epoch: 59
2022-11-18 02:56:57,373 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7916523583910682, 'Total loss': 0.7916523583910682} | train loss {'Reaction outcome loss': 0.8045532430921282, 'Total loss': 0.8045532430921282}
2022-11-18 02:56:57,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:57,374 INFO:     Epoch: 60
2022-11-18 02:56:58,157 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8032272607088089, 'Total loss': 0.8032272607088089} | train loss {'Reaction outcome loss': 0.8059086359277063, 'Total loss': 0.8059086359277063}
2022-11-18 02:56:58,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:58,158 INFO:     Epoch: 61
2022-11-18 02:56:58,940 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7963343831625852, 'Total loss': 0.7963343831625852} | train loss {'Reaction outcome loss': 0.8062722816759226, 'Total loss': 0.8062722816759226}
2022-11-18 02:56:58,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:58,940 INFO:     Epoch: 62
2022-11-18 02:56:59,740 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8064761805263433, 'Total loss': 0.8064761805263433} | train loss {'Reaction outcome loss': 0.8046641619838014, 'Total loss': 0.8046641619838014}
2022-11-18 02:56:59,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:56:59,740 INFO:     Epoch: 63
2022-11-18 02:57:00,499 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8103107539090243, 'Total loss': 0.8103107539090243} | train loss {'Reaction outcome loss': 0.8125596314060445, 'Total loss': 0.8125596314060445}
2022-11-18 02:57:00,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:00,499 INFO:     Epoch: 64
2022-11-18 02:57:01,260 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8134010542522777, 'Total loss': 0.8134010542522777} | train loss {'Reaction outcome loss': 0.8096182121306049, 'Total loss': 0.8096182121306049}
2022-11-18 02:57:01,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:01,260 INFO:     Epoch: 65
2022-11-18 02:57:02,047 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8209291364658963, 'Total loss': 0.8209291364658963} | train loss {'Reaction outcome loss': 0.8074532185282026, 'Total loss': 0.8074532185282026}
2022-11-18 02:57:02,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:02,047 INFO:     Epoch: 66
2022-11-18 02:57:02,815 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.807329768484289, 'Total loss': 0.807329768484289} | train loss {'Reaction outcome loss': 0.8137100921601665, 'Total loss': 0.8137100921601665}
2022-11-18 02:57:02,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:02,815 INFO:     Epoch: 67
2022-11-18 02:57:03,597 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7894000133330171, 'Total loss': 0.7894000133330171} | train loss {'Reaction outcome loss': 0.8107754301051704, 'Total loss': 0.8107754301051704}
2022-11-18 02:57:03,598 INFO:     Found new best model at epoch 67
2022-11-18 02:57:03,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:03,599 INFO:     Epoch: 68
2022-11-18 02:57:04,382 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8123129186305132, 'Total loss': 0.8123129186305132} | train loss {'Reaction outcome loss': 0.8087578423169195, 'Total loss': 0.8087578423169195}
2022-11-18 02:57:04,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:04,382 INFO:     Epoch: 69
2022-11-18 02:57:05,164 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8072826273062013, 'Total loss': 0.8072826273062013} | train loss {'Reaction outcome loss': 0.8091191089883143, 'Total loss': 0.8091191089883143}
2022-11-18 02:57:05,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:05,164 INFO:     Epoch: 70
2022-11-18 02:57:05,945 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.843847737393596, 'Total loss': 0.843847737393596} | train loss {'Reaction outcome loss': 0.8061549805864996, 'Total loss': 0.8061549805864996}
2022-11-18 02:57:05,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:05,947 INFO:     Epoch: 71
2022-11-18 02:57:06,732 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8339477140795101, 'Total loss': 0.8339477140795101} | train loss {'Reaction outcome loss': 0.8062002629649883, 'Total loss': 0.8062002629649883}
2022-11-18 02:57:06,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:06,733 INFO:     Epoch: 72
2022-11-18 02:57:07,506 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8009176105260849, 'Total loss': 0.8009176105260849} | train loss {'Reaction outcome loss': 0.8085225438585086, 'Total loss': 0.8085225438585086}
2022-11-18 02:57:07,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:07,507 INFO:     Epoch: 73
2022-11-18 02:57:08,307 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7938672798601064, 'Total loss': 0.7938672798601064} | train loss {'Reaction outcome loss': 0.8068688699177333, 'Total loss': 0.8068688699177333}
2022-11-18 02:57:08,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:08,307 INFO:     Epoch: 74
2022-11-18 02:57:09,108 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7983729365197095, 'Total loss': 0.7983729365197095} | train loss {'Reaction outcome loss': 0.8088748851600959, 'Total loss': 0.8088748851600959}
2022-11-18 02:57:09,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:09,108 INFO:     Epoch: 75
2022-11-18 02:57:09,878 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8105052228678357, 'Total loss': 0.8105052228678357} | train loss {'Reaction outcome loss': 0.8113900103131119, 'Total loss': 0.8113900103131119}
2022-11-18 02:57:09,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:09,879 INFO:     Epoch: 76
2022-11-18 02:57:10,684 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8100390529090707, 'Total loss': 0.8100390529090707} | train loss {'Reaction outcome loss': 0.8066370584526841, 'Total loss': 0.8066370584526841}
2022-11-18 02:57:10,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:10,684 INFO:     Epoch: 77
2022-11-18 02:57:11,496 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8037939091975038, 'Total loss': 0.8037939091975038} | train loss {'Reaction outcome loss': 0.8123160252765733, 'Total loss': 0.8123160252765733}
2022-11-18 02:57:11,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:11,497 INFO:     Epoch: 78
2022-11-18 02:57:12,325 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8246708112684163, 'Total loss': 0.8246708112684163} | train loss {'Reaction outcome loss': 0.8107152590946275, 'Total loss': 0.8107152590946275}
2022-11-18 02:57:12,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:12,326 INFO:     Epoch: 79
2022-11-18 02:57:13,135 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8151735785332593, 'Total loss': 0.8151735785332593} | train loss {'Reaction outcome loss': 0.8051123413504386, 'Total loss': 0.8051123413504386}
2022-11-18 02:57:13,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:13,135 INFO:     Epoch: 80
2022-11-18 02:57:13,924 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8117992227727716, 'Total loss': 0.8117992227727716} | train loss {'Reaction outcome loss': 0.8107434737439059, 'Total loss': 0.8107434737439059}
2022-11-18 02:57:13,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:13,924 INFO:     Epoch: 81
2022-11-18 02:57:14,708 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.812597704204646, 'Total loss': 0.812597704204646} | train loss {'Reaction outcome loss': 0.8071259215170024, 'Total loss': 0.8071259215170024}
2022-11-18 02:57:14,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:14,708 INFO:     Epoch: 82
2022-11-18 02:57:15,494 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8132710375569083, 'Total loss': 0.8132710375569083} | train loss {'Reaction outcome loss': 0.808195271297377, 'Total loss': 0.808195271297377}
2022-11-18 02:57:15,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:15,495 INFO:     Epoch: 83
2022-11-18 02:57:16,309 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7897336567667398, 'Total loss': 0.7897336567667398} | train loss {'Reaction outcome loss': 0.8094707192206869, 'Total loss': 0.8094707192206869}
2022-11-18 02:57:16,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:16,309 INFO:     Epoch: 84
2022-11-18 02:57:17,097 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8011509572917764, 'Total loss': 0.8011509572917764} | train loss {'Reaction outcome loss': 0.8079944086318114, 'Total loss': 0.8079944086318114}
2022-11-18 02:57:17,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:17,097 INFO:     Epoch: 85
2022-11-18 02:57:17,898 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8299297101118348, 'Total loss': 0.8299297101118348} | train loss {'Reaction outcome loss': 0.814281683673664, 'Total loss': 0.814281683673664}
2022-11-18 02:57:17,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:17,899 INFO:     Epoch: 86
2022-11-18 02:57:18,708 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8033191087571058, 'Total loss': 0.8033191087571058} | train loss {'Reaction outcome loss': 0.8067137124587078, 'Total loss': 0.8067137124587078}
2022-11-18 02:57:18,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:18,708 INFO:     Epoch: 87
2022-11-18 02:57:19,502 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8055723844604059, 'Total loss': 0.8055723844604059} | train loss {'Reaction outcome loss': 0.8062264319585294, 'Total loss': 0.8062264319585294}
2022-11-18 02:57:19,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:19,502 INFO:     Epoch: 88
2022-11-18 02:57:20,293 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8067958056926727, 'Total loss': 0.8067958056926727} | train loss {'Reaction outcome loss': 0.8136623101575035, 'Total loss': 0.8136623101575035}
2022-11-18 02:57:20,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:20,293 INFO:     Epoch: 89
2022-11-18 02:57:21,106 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8033345368775454, 'Total loss': 0.8033345368775454} | train loss {'Reaction outcome loss': 0.8025929298936104, 'Total loss': 0.8025929298936104}
2022-11-18 02:57:21,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:21,106 INFO:     Epoch: 90
2022-11-18 02:57:21,951 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.836343262005936, 'Total loss': 0.836343262005936} | train loss {'Reaction outcome loss': 0.8090193825108665, 'Total loss': 0.8090193825108665}
2022-11-18 02:57:21,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:21,952 INFO:     Epoch: 91
2022-11-18 02:57:22,779 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8082958656278524, 'Total loss': 0.8082958656278524} | train loss {'Reaction outcome loss': 0.8128387868404389, 'Total loss': 0.8128387868404389}
2022-11-18 02:57:22,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:22,779 INFO:     Epoch: 92
2022-11-18 02:57:23,579 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8030738505450162, 'Total loss': 0.8030738505450162} | train loss {'Reaction outcome loss': 0.8066739669867924, 'Total loss': 0.8066739669867924}
2022-11-18 02:57:23,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:23,579 INFO:     Epoch: 93
2022-11-18 02:57:24,363 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8059951175342907, 'Total loss': 0.8059951175342907} | train loss {'Reaction outcome loss': 0.8054595842653391, 'Total loss': 0.8054595842653391}
2022-11-18 02:57:24,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:24,364 INFO:     Epoch: 94
2022-11-18 02:57:25,141 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7902704904025252, 'Total loss': 0.7902704904025252} | train loss {'Reaction outcome loss': 0.8081304455290035, 'Total loss': 0.8081304455290035}
2022-11-18 02:57:25,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:25,142 INFO:     Epoch: 95
2022-11-18 02:57:25,917 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8205981728705493, 'Total loss': 0.8205981728705493} | train loss {'Reaction outcome loss': 0.8105683228191064, 'Total loss': 0.8105683228191064}
2022-11-18 02:57:25,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:25,917 INFO:     Epoch: 96
2022-11-18 02:57:26,744 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.816124094480818, 'Total loss': 0.816124094480818} | train loss {'Reaction outcome loss': 0.809005764430883, 'Total loss': 0.809005764430883}
2022-11-18 02:57:26,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:26,745 INFO:     Epoch: 97
2022-11-18 02:57:27,541 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8021385168487375, 'Total loss': 0.8021385168487375} | train loss {'Reaction outcome loss': 0.8073822695381787, 'Total loss': 0.8073822695381787}
2022-11-18 02:57:27,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:27,541 INFO:     Epoch: 98
2022-11-18 02:57:28,333 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.78893696855415, 'Total loss': 0.78893696855415} | train loss {'Reaction outcome loss': 0.8109941292782219, 'Total loss': 0.8109941292782219}
2022-11-18 02:57:28,333 INFO:     Found new best model at epoch 98
2022-11-18 02:57:28,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:28,334 INFO:     Epoch: 99
2022-11-18 02:57:29,119 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8019456355409189, 'Total loss': 0.8019456355409189} | train loss {'Reaction outcome loss': 0.8105813202809314, 'Total loss': 0.8105813202809314}
2022-11-18 02:57:29,120 INFO:     Best model found after epoch 99 of 100.
2022-11-18 02:57:29,120 INFO:   Done with stage: TRAINING
2022-11-18 02:57:29,120 INFO:   Starting stage: EVALUATION
2022-11-18 02:57:29,248 INFO:   Done with stage: EVALUATION
2022-11-18 02:57:29,248 INFO:   Leaving out SEQ value Fold_2
2022-11-18 02:57:29,261 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:57:29,261 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:57:29,928 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:57:29,928 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:57:29,997 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:57:29,997 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:57:29,997 INFO:     No hyperparam tuning for this model
2022-11-18 02:57:29,997 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:57:29,997 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:57:29,998 INFO:     None feature selector for col prot
2022-11-18 02:57:29,998 INFO:     None feature selector for col prot
2022-11-18 02:57:29,998 INFO:     None feature selector for col prot
2022-11-18 02:57:29,999 INFO:     None feature selector for col chem
2022-11-18 02:57:29,999 INFO:     None feature selector for col chem
2022-11-18 02:57:29,999 INFO:     None feature selector for col chem
2022-11-18 02:57:29,999 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:57:29,999 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:57:30,001 INFO:     Number of params in model 168571
2022-11-18 02:57:30,004 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:57:30,004 INFO:   Starting stage: TRAINING
2022-11-18 02:57:30,061 INFO:     Val loss before train {'Reaction outcome loss': 1.000784388808317, 'Total loss': 1.000784388808317}
2022-11-18 02:57:30,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:30,061 INFO:     Epoch: 0
2022-11-18 02:57:30,829 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8179828753305036, 'Total loss': 0.8179828753305036} | train loss {'Reaction outcome loss': 0.8891852412556038, 'Total loss': 0.8891852412556038}
2022-11-18 02:57:30,829 INFO:     Found new best model at epoch 0
2022-11-18 02:57:30,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:30,830 INFO:     Epoch: 1
2022-11-18 02:57:31,601 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.819523787775705, 'Total loss': 0.819523787775705} | train loss {'Reaction outcome loss': 0.8626141941449681, 'Total loss': 0.8626141941449681}
2022-11-18 02:57:31,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:31,602 INFO:     Epoch: 2
2022-11-18 02:57:32,408 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7946621997411861, 'Total loss': 0.7946621997411861} | train loss {'Reaction outcome loss': 0.8552567537446492, 'Total loss': 0.8552567537446492}
2022-11-18 02:57:32,408 INFO:     Found new best model at epoch 2
2022-11-18 02:57:32,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:32,409 INFO:     Epoch: 3
2022-11-18 02:57:33,178 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7997524599696315, 'Total loss': 0.7997524599696315} | train loss {'Reaction outcome loss': 0.8557060686413382, 'Total loss': 0.8557060686413382}
2022-11-18 02:57:33,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:33,178 INFO:     Epoch: 4
2022-11-18 02:57:33,946 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7958016430222711, 'Total loss': 0.7958016430222711} | train loss {'Reaction outcome loss': 0.8451195453278354, 'Total loss': 0.8451195453278354}
2022-11-18 02:57:33,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:33,947 INFO:     Epoch: 5
2022-11-18 02:57:34,711 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8366408389668132, 'Total loss': 0.8366408389668132} | train loss {'Reaction outcome loss': 0.8404467142507678, 'Total loss': 0.8404467142507678}
2022-11-18 02:57:34,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:34,712 INFO:     Epoch: 6
2022-11-18 02:57:35,531 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8350509710090105, 'Total loss': 0.8350509710090105} | train loss {'Reaction outcome loss': 0.8410969166482081, 'Total loss': 0.8410969166482081}
2022-11-18 02:57:35,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:35,531 INFO:     Epoch: 7
2022-11-18 02:57:36,344 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7934415305769721, 'Total loss': 0.7934415305769721} | train loss {'Reaction outcome loss': 0.8420352303102369, 'Total loss': 0.8420352303102369}
2022-11-18 02:57:36,345 INFO:     Found new best model at epoch 7
2022-11-18 02:57:36,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:36,345 INFO:     Epoch: 8
2022-11-18 02:57:37,142 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8353267727896224, 'Total loss': 0.8353267727896224} | train loss {'Reaction outcome loss': 0.8347207665687701, 'Total loss': 0.8347207665687701}
2022-11-18 02:57:37,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:37,144 INFO:     Epoch: 9
2022-11-18 02:57:37,916 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7887550502322441, 'Total loss': 0.7887550502322441} | train loss {'Reaction outcome loss': 0.8372381568932142, 'Total loss': 0.8372381568932142}
2022-11-18 02:57:37,916 INFO:     Found new best model at epoch 9
2022-11-18 02:57:37,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:37,917 INFO:     Epoch: 10
2022-11-18 02:57:38,668 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.812050556027612, 'Total loss': 0.812050556027612} | train loss {'Reaction outcome loss': 0.8347307734313558, 'Total loss': 0.8347307734313558}
2022-11-18 02:57:38,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:38,668 INFO:     Epoch: 11
2022-11-18 02:57:39,473 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7971472054026848, 'Total loss': 0.7971472054026848} | train loss {'Reaction outcome loss': 0.8354383333296073, 'Total loss': 0.8354383333296073}
2022-11-18 02:57:39,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:39,473 INFO:     Epoch: 12
2022-11-18 02:57:40,245 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.788118051235066, 'Total loss': 0.788118051235066} | train loss {'Reaction outcome loss': 0.8386246477727031, 'Total loss': 0.8386246477727031}
2022-11-18 02:57:40,245 INFO:     Found new best model at epoch 12
2022-11-18 02:57:40,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:40,246 INFO:     Epoch: 13
2022-11-18 02:57:41,020 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7954355720863786, 'Total loss': 0.7954355720863786} | train loss {'Reaction outcome loss': 0.8350761734315606, 'Total loss': 0.8350761734315606}
2022-11-18 02:57:41,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:41,020 INFO:     Epoch: 14
2022-11-18 02:57:41,794 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7874810175840244, 'Total loss': 0.7874810175840244} | train loss {'Reaction outcome loss': 0.8291330934792268, 'Total loss': 0.8291330934792268}
2022-11-18 02:57:41,795 INFO:     Found new best model at epoch 14
2022-11-18 02:57:41,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:41,795 INFO:     Epoch: 15
2022-11-18 02:57:42,579 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7885785969190819, 'Total loss': 0.7885785969190819} | train loss {'Reaction outcome loss': 0.8304473782171968, 'Total loss': 0.8304473782171968}
2022-11-18 02:57:42,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:42,580 INFO:     Epoch: 16
2022-11-18 02:57:43,370 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7910962652328403, 'Total loss': 0.7910962652328403} | train loss {'Reaction outcome loss': 0.830783245016317, 'Total loss': 0.830783245016317}
2022-11-18 02:57:43,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:43,371 INFO:     Epoch: 17
2022-11-18 02:57:44,143 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7800525828849437, 'Total loss': 0.7800525828849437} | train loss {'Reaction outcome loss': 0.8329122177645808, 'Total loss': 0.8329122177645808}
2022-11-18 02:57:44,144 INFO:     Found new best model at epoch 17
2022-11-18 02:57:44,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:44,145 INFO:     Epoch: 18
2022-11-18 02:57:44,935 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7908533887807713, 'Total loss': 0.7908533887807713} | train loss {'Reaction outcome loss': 0.8301780074834824, 'Total loss': 0.8301780074834824}
2022-11-18 02:57:44,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:44,935 INFO:     Epoch: 19
2022-11-18 02:57:45,722 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7949323917544165, 'Total loss': 0.7949323917544165} | train loss {'Reaction outcome loss': 0.8293843108122466, 'Total loss': 0.8293843108122466}
2022-11-18 02:57:45,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:45,722 INFO:     Epoch: 20
2022-11-18 02:57:46,481 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7872082833633867, 'Total loss': 0.7872082833633867} | train loss {'Reaction outcome loss': 0.8337402492761612, 'Total loss': 0.8337402492761612}
2022-11-18 02:57:46,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:46,482 INFO:     Epoch: 21
2022-11-18 02:57:47,268 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.787440302760102, 'Total loss': 0.787440302760102} | train loss {'Reaction outcome loss': 0.8259230900983341, 'Total loss': 0.8259230900983341}
2022-11-18 02:57:47,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:47,268 INFO:     Epoch: 22
2022-11-18 02:57:48,065 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8021781188110972, 'Total loss': 0.8021781188110972} | train loss {'Reaction outcome loss': 0.8329005104596497, 'Total loss': 0.8329005104596497}
2022-11-18 02:57:48,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:48,065 INFO:     Epoch: 23
2022-11-18 02:57:48,842 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7872205279594244, 'Total loss': 0.7872205279594244} | train loss {'Reaction outcome loss': 0.8272257667095935, 'Total loss': 0.8272257667095935}
2022-11-18 02:57:48,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:48,842 INFO:     Epoch: 24
2022-11-18 02:57:49,626 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7919258066388064, 'Total loss': 0.7919258066388064} | train loss {'Reaction outcome loss': 0.8284051804268946, 'Total loss': 0.8284051804268946}
2022-11-18 02:57:49,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:49,627 INFO:     Epoch: 25
2022-11-18 02:57:50,390 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7881568968296051, 'Total loss': 0.7881568968296051} | train loss {'Reaction outcome loss': 0.8224527529272877, 'Total loss': 0.8224527529272877}
2022-11-18 02:57:50,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:50,391 INFO:     Epoch: 26
2022-11-18 02:57:51,165 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7878500992475554, 'Total loss': 0.7878500992475554} | train loss {'Reaction outcome loss': 0.8226448993702404, 'Total loss': 0.8226448993702404}
2022-11-18 02:57:51,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:51,165 INFO:     Epoch: 27
2022-11-18 02:57:51,952 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7958805692750354, 'Total loss': 0.7958805692750354} | train loss {'Reaction outcome loss': 0.8260801212220895, 'Total loss': 0.8260801212220895}
2022-11-18 02:57:51,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:51,952 INFO:     Epoch: 28
2022-11-18 02:57:52,722 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.801157696302547, 'Total loss': 0.801157696302547} | train loss {'Reaction outcome loss': 0.8256346506417774, 'Total loss': 0.8256346506417774}
2022-11-18 02:57:52,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:52,723 INFO:     Epoch: 29
2022-11-18 02:57:53,497 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.774043740228165, 'Total loss': 0.774043740228165} | train loss {'Reaction outcome loss': 0.8233185574168065, 'Total loss': 0.8233185574168065}
2022-11-18 02:57:53,497 INFO:     Found new best model at epoch 29
2022-11-18 02:57:53,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:53,498 INFO:     Epoch: 30
2022-11-18 02:57:54,243 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7773169320683146, 'Total loss': 0.7773169320683146} | train loss {'Reaction outcome loss': 0.8218825585285171, 'Total loss': 0.8218825585285171}
2022-11-18 02:57:54,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:54,243 INFO:     Epoch: 31
2022-11-18 02:57:54,995 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7732106897720071, 'Total loss': 0.7732106897720071} | train loss {'Reaction outcome loss': 0.8270101149062641, 'Total loss': 0.8270101149062641}
2022-11-18 02:57:54,995 INFO:     Found new best model at epoch 31
2022-11-18 02:57:54,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:54,996 INFO:     Epoch: 32
2022-11-18 02:57:55,766 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.788854435432789, 'Total loss': 0.788854435432789} | train loss {'Reaction outcome loss': 0.822035936669248, 'Total loss': 0.822035936669248}
2022-11-18 02:57:55,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:55,767 INFO:     Epoch: 33
2022-11-18 02:57:56,534 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7931084910104441, 'Total loss': 0.7931084910104441} | train loss {'Reaction outcome loss': 0.8198880020712243, 'Total loss': 0.8198880020712243}
2022-11-18 02:57:56,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:56,535 INFO:     Epoch: 34
2022-11-18 02:57:57,322 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7937282469383505, 'Total loss': 0.7937282469383505} | train loss {'Reaction outcome loss': 0.8188316718232437, 'Total loss': 0.8188316718232437}
2022-11-18 02:57:57,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:57,322 INFO:     Epoch: 35
2022-11-18 02:57:58,068 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.792398237904837, 'Total loss': 0.792398237904837} | train loss {'Reaction outcome loss': 0.8225876884382279, 'Total loss': 0.8225876884382279}
2022-11-18 02:57:58,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:58,068 INFO:     Epoch: 36
2022-11-18 02:57:58,853 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.789070364347724, 'Total loss': 0.789070364347724} | train loss {'Reaction outcome loss': 0.820177996012031, 'Total loss': 0.820177996012031}
2022-11-18 02:57:58,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:58,853 INFO:     Epoch: 37
2022-11-18 02:57:59,626 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7866384303847025, 'Total loss': 0.7866384303847025} | train loss {'Reaction outcome loss': 0.8280673929658092, 'Total loss': 0.8280673929658092}
2022-11-18 02:57:59,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:57:59,627 INFO:     Epoch: 38
2022-11-18 02:58:00,394 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7962517655173014, 'Total loss': 0.7962517655173014} | train loss {'Reaction outcome loss': 0.8206236406427915, 'Total loss': 0.8206236406427915}
2022-11-18 02:58:00,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:00,395 INFO:     Epoch: 39
2022-11-18 02:58:01,162 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7857506815777269, 'Total loss': 0.7857506815777269} | train loss {'Reaction outcome loss': 0.8197929159295364, 'Total loss': 0.8197929159295364}
2022-11-18 02:58:01,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:01,162 INFO:     Epoch: 40
2022-11-18 02:58:01,947 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7817861597205318, 'Total loss': 0.7817861597205318} | train loss {'Reaction outcome loss': 0.8254054833631046, 'Total loss': 0.8254054833631046}
2022-11-18 02:58:01,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:01,947 INFO:     Epoch: 41
2022-11-18 02:58:02,706 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7866135475247406, 'Total loss': 0.7866135475247406} | train loss {'Reaction outcome loss': 0.8216080926969404, 'Total loss': 0.8216080926969404}
2022-11-18 02:58:02,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:02,706 INFO:     Epoch: 42
2022-11-18 02:58:03,459 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.776696756828663, 'Total loss': 0.776696756828663} | train loss {'Reaction outcome loss': 0.8204722058821897, 'Total loss': 0.8204722058821897}
2022-11-18 02:58:03,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:03,459 INFO:     Epoch: 43
2022-11-18 02:58:04,232 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7817675041597943, 'Total loss': 0.7817675041597943} | train loss {'Reaction outcome loss': 0.8188206719570472, 'Total loss': 0.8188206719570472}
2022-11-18 02:58:04,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:04,232 INFO:     Epoch: 44
2022-11-18 02:58:05,006 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7877322975979295, 'Total loss': 0.7877322975979295} | train loss {'Reaction outcome loss': 0.8155348766289774, 'Total loss': 0.8155348766289774}
2022-11-18 02:58:05,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:05,006 INFO:     Epoch: 45
2022-11-18 02:58:05,785 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7908561354459718, 'Total loss': 0.7908561354459718} | train loss {'Reaction outcome loss': 0.8189397016998197, 'Total loss': 0.8189397016998197}
2022-11-18 02:58:05,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:05,785 INFO:     Epoch: 46
2022-11-18 02:58:06,576 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7747841477394104, 'Total loss': 0.7747841477394104} | train loss {'Reaction outcome loss': 0.818154090252079, 'Total loss': 0.818154090252079}
2022-11-18 02:58:06,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:06,576 INFO:     Epoch: 47
2022-11-18 02:58:07,355 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7955843237943427, 'Total loss': 0.7955843237943427} | train loss {'Reaction outcome loss': 0.8161651660672954, 'Total loss': 0.8161651660672954}
2022-11-18 02:58:07,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:07,355 INFO:     Epoch: 48
2022-11-18 02:58:08,142 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7677623414716055, 'Total loss': 0.7677623414716055} | train loss {'Reaction outcome loss': 0.8155797738276545, 'Total loss': 0.8155797738276545}
2022-11-18 02:58:08,143 INFO:     Found new best model at epoch 48
2022-11-18 02:58:08,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:08,144 INFO:     Epoch: 49
2022-11-18 02:58:08,893 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.773498417333115, 'Total loss': 0.773498417333115} | train loss {'Reaction outcome loss': 0.8123650956349294, 'Total loss': 0.8123650956349294}
2022-11-18 02:58:08,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:08,893 INFO:     Epoch: 50
2022-11-18 02:58:09,663 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7960573434829712, 'Total loss': 0.7960573434829712} | train loss {'Reaction outcome loss': 0.8160354625739035, 'Total loss': 0.8160354625739035}
2022-11-18 02:58:09,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:09,664 INFO:     Epoch: 51
2022-11-18 02:58:10,447 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7665198355220085, 'Total loss': 0.7665198355220085} | train loss {'Reaction outcome loss': 0.8104652621951259, 'Total loss': 0.8104652621951259}
2022-11-18 02:58:10,447 INFO:     Found new best model at epoch 51
2022-11-18 02:58:10,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:10,448 INFO:     Epoch: 52
2022-11-18 02:58:11,231 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7889633740103522, 'Total loss': 0.7889633740103522} | train loss {'Reaction outcome loss': 0.8113325346933037, 'Total loss': 0.8113325346933037}
2022-11-18 02:58:11,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:11,231 INFO:     Epoch: 53
2022-11-18 02:58:12,010 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7713631128155908, 'Total loss': 0.7713631128155908} | train loss {'Reaction outcome loss': 0.8183379278319781, 'Total loss': 0.8183379278319781}
2022-11-18 02:58:12,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:12,011 INFO:     Epoch: 54
2022-11-18 02:58:12,770 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.767646825590799, 'Total loss': 0.767646825590799} | train loss {'Reaction outcome loss': 0.8110789208382857, 'Total loss': 0.8110789208382857}
2022-11-18 02:58:12,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:12,771 INFO:     Epoch: 55
2022-11-18 02:58:13,543 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.779335924359255, 'Total loss': 0.779335924359255} | train loss {'Reaction outcome loss': 0.8053841087661806, 'Total loss': 0.8053841087661806}
2022-11-18 02:58:13,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:13,543 INFO:     Epoch: 56
2022-11-18 02:58:14,331 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8454222637553548, 'Total loss': 0.8454222637553548} | train loss {'Reaction outcome loss': 0.805215021259472, 'Total loss': 0.805215021259472}
2022-11-18 02:58:14,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:14,332 INFO:     Epoch: 57
2022-11-18 02:58:15,112 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7554895773876545, 'Total loss': 0.7554895773876545} | train loss {'Reaction outcome loss': 0.8070450847754713, 'Total loss': 0.8070450847754713}
2022-11-18 02:58:15,112 INFO:     Found new best model at epoch 57
2022-11-18 02:58:15,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:15,113 INFO:     Epoch: 58
2022-11-18 02:58:15,895 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7800024858740873, 'Total loss': 0.7800024858740873} | train loss {'Reaction outcome loss': 0.8029148617728812, 'Total loss': 0.8029148617728812}
2022-11-18 02:58:15,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:15,895 INFO:     Epoch: 59
2022-11-18 02:58:16,682 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7787672565426937, 'Total loss': 0.7787672565426937} | train loss {'Reaction outcome loss': 0.807736222861243, 'Total loss': 0.807736222861243}
2022-11-18 02:58:16,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:16,682 INFO:     Epoch: 60
2022-11-18 02:58:17,464 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7725941261579824, 'Total loss': 0.7725941261579824} | train loss {'Reaction outcome loss': 0.8006657553745098, 'Total loss': 0.8006657553745098}
2022-11-18 02:58:17,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:17,464 INFO:     Epoch: 61
2022-11-18 02:58:18,250 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.777821191521578, 'Total loss': 0.777821191521578} | train loss {'Reaction outcome loss': 0.7979314012117074, 'Total loss': 0.7979314012117074}
2022-11-18 02:58:18,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:18,250 INFO:     Epoch: 62
2022-11-18 02:58:19,033 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7582305683646091, 'Total loss': 0.7582305683646091} | train loss {'Reaction outcome loss': 0.7993926209260206, 'Total loss': 0.7993926209260206}
2022-11-18 02:58:19,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:19,033 INFO:     Epoch: 63
2022-11-18 02:58:19,826 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7968652366205703, 'Total loss': 0.7968652366205703} | train loss {'Reaction outcome loss': 0.7934003551719618, 'Total loss': 0.7934003551719618}
2022-11-18 02:58:19,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:19,826 INFO:     Epoch: 64
2022-11-18 02:58:20,609 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7608484667400981, 'Total loss': 0.7608484667400981} | train loss {'Reaction outcome loss': 0.7897000210207017, 'Total loss': 0.7897000210207017}
2022-11-18 02:58:20,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:20,610 INFO:     Epoch: 65
2022-11-18 02:58:21,401 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7587322814520016, 'Total loss': 0.7587322814520016} | train loss {'Reaction outcome loss': 0.7933017355008204, 'Total loss': 0.7933017355008204}
2022-11-18 02:58:21,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:21,401 INFO:     Epoch: 66
2022-11-18 02:58:22,167 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7484928556652957, 'Total loss': 0.7484928556652957} | train loss {'Reaction outcome loss': 0.7905152740537144, 'Total loss': 0.7905152740537144}
2022-11-18 02:58:22,168 INFO:     Found new best model at epoch 66
2022-11-18 02:58:22,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:22,168 INFO:     Epoch: 67
2022-11-18 02:58:22,988 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7858026270256486, 'Total loss': 0.7858026270256486} | train loss {'Reaction outcome loss': 0.7812511056173043, 'Total loss': 0.7812511056173043}
2022-11-18 02:58:22,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:22,988 INFO:     Epoch: 68
2022-11-18 02:58:23,790 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7707104738368544, 'Total loss': 0.7707104738368544} | train loss {'Reaction outcome loss': 0.7865782990807393, 'Total loss': 0.7865782990807393}
2022-11-18 02:58:23,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:23,791 INFO:     Epoch: 69
2022-11-18 02:58:24,602 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.735936968132507, 'Total loss': 0.735936968132507} | train loss {'Reaction outcome loss': 0.7716378830983991, 'Total loss': 0.7716378830983991}
2022-11-18 02:58:24,603 INFO:     Found new best model at epoch 69
2022-11-18 02:58:24,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:24,603 INFO:     Epoch: 70
2022-11-18 02:58:25,369 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7213945194732311, 'Total loss': 0.7213945194732311} | train loss {'Reaction outcome loss': 0.7689296057234045, 'Total loss': 0.7689296057234045}
2022-11-18 02:58:25,369 INFO:     Found new best model at epoch 70
2022-11-18 02:58:25,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:25,370 INFO:     Epoch: 71
2022-11-18 02:58:26,168 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7311119991679524, 'Total loss': 0.7311119991679524} | train loss {'Reaction outcome loss': 0.7562862468547509, 'Total loss': 0.7562862468547509}
2022-11-18 02:58:26,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:26,168 INFO:     Epoch: 72
2022-11-18 02:58:26,966 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7110803480758223, 'Total loss': 0.7110803480758223} | train loss {'Reaction outcome loss': 0.7525334185996994, 'Total loss': 0.7525334185996994}
2022-11-18 02:58:26,967 INFO:     Found new best model at epoch 72
2022-11-18 02:58:26,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:26,968 INFO:     Epoch: 73
2022-11-18 02:58:27,783 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7656738113525302, 'Total loss': 0.7656738113525302} | train loss {'Reaction outcome loss': 0.7457553068878221, 'Total loss': 0.7457553068878221}
2022-11-18 02:58:27,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:27,784 INFO:     Epoch: 74
2022-11-18 02:58:28,584 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6797607111376386, 'Total loss': 0.6797607111376386} | train loss {'Reaction outcome loss': 0.7334320016327451, 'Total loss': 0.7334320016327451}
2022-11-18 02:58:28,584 INFO:     Found new best model at epoch 74
2022-11-18 02:58:28,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:28,585 INFO:     Epoch: 75
2022-11-18 02:58:29,372 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.6724138869795688, 'Total loss': 0.6724138869795688} | train loss {'Reaction outcome loss': 0.7276385854013631, 'Total loss': 0.7276385854013631}
2022-11-18 02:58:29,372 INFO:     Found new best model at epoch 75
2022-11-18 02:58:29,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:29,373 INFO:     Epoch: 76
2022-11-18 02:58:30,167 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6896587935991065, 'Total loss': 0.6896587935991065} | train loss {'Reaction outcome loss': 0.7017741919052406, 'Total loss': 0.7017741919052406}
2022-11-18 02:58:30,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:30,168 INFO:     Epoch: 77
2022-11-18 02:58:30,946 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6303423303504323, 'Total loss': 0.6303423303504323} | train loss {'Reaction outcome loss': 0.6796474870843966, 'Total loss': 0.6796474870843966}
2022-11-18 02:58:30,946 INFO:     Found new best model at epoch 77
2022-11-18 02:58:30,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:30,947 INFO:     Epoch: 78
2022-11-18 02:58:31,774 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6170714982720309, 'Total loss': 0.6170714982720309} | train loss {'Reaction outcome loss': 0.6662622885625871, 'Total loss': 0.6662622885625871}
2022-11-18 02:58:31,774 INFO:     Found new best model at epoch 78
2022-11-18 02:58:31,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:31,775 INFO:     Epoch: 79
2022-11-18 02:58:32,557 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6564384206782939, 'Total loss': 0.6564384206782939} | train loss {'Reaction outcome loss': 0.6470367339302282, 'Total loss': 0.6470367339302282}
2022-11-18 02:58:32,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:32,557 INFO:     Epoch: 80
2022-11-18 02:58:33,353 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5939675728942073, 'Total loss': 0.5939675728942073} | train loss {'Reaction outcome loss': 0.6394800876618408, 'Total loss': 0.6394800876618408}
2022-11-18 02:58:33,353 INFO:     Found new best model at epoch 80
2022-11-18 02:58:33,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:33,354 INFO:     Epoch: 81
2022-11-18 02:58:34,137 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6549208323622859, 'Total loss': 0.6549208323622859} | train loss {'Reaction outcome loss': 0.6147996000334864, 'Total loss': 0.6147996000334864}
2022-11-18 02:58:34,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:34,138 INFO:     Epoch: 82
2022-11-18 02:58:34,929 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.6102039924887723, 'Total loss': 0.6102039924887723} | train loss {'Reaction outcome loss': 0.6134533320294052, 'Total loss': 0.6134533320294052}
2022-11-18 02:58:34,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:34,930 INFO:     Epoch: 83
2022-11-18 02:58:35,700 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.563498891370241, 'Total loss': 0.563498891370241} | train loss {'Reaction outcome loss': 0.5949643979795644, 'Total loss': 0.5949643979795644}
2022-11-18 02:58:35,700 INFO:     Found new best model at epoch 83
2022-11-18 02:58:35,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:35,701 INFO:     Epoch: 84
2022-11-18 02:58:36,466 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.572114109992981, 'Total loss': 0.572114109992981} | train loss {'Reaction outcome loss': 0.6101923874411427, 'Total loss': 0.6101923874411427}
2022-11-18 02:58:36,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:36,466 INFO:     Epoch: 85
2022-11-18 02:58:37,273 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5415918594876001, 'Total loss': 0.5415918594876001} | train loss {'Reaction outcome loss': 0.581258375564071, 'Total loss': 0.581258375564071}
2022-11-18 02:58:37,273 INFO:     Found new best model at epoch 85
2022-11-18 02:58:37,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:37,274 INFO:     Epoch: 86
2022-11-18 02:58:38,061 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6162720488947492, 'Total loss': 0.6162720488947492} | train loss {'Reaction outcome loss': 0.5964533431363888, 'Total loss': 0.5964533431363888}
2022-11-18 02:58:38,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:38,061 INFO:     Epoch: 87
2022-11-18 02:58:38,851 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5814298335895982, 'Total loss': 0.5814298335895982} | train loss {'Reaction outcome loss': 0.5850903282522179, 'Total loss': 0.5850903282522179}
2022-11-18 02:58:38,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:38,852 INFO:     Epoch: 88
2022-11-18 02:58:39,676 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5654507716034733, 'Total loss': 0.5654507716034733} | train loss {'Reaction outcome loss': 0.6009949679623862, 'Total loss': 0.6009949679623862}
2022-11-18 02:58:39,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:39,676 INFO:     Epoch: 89
2022-11-18 02:58:40,426 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5571379391259925, 'Total loss': 0.5571379391259925} | train loss {'Reaction outcome loss': 0.5863025227531058, 'Total loss': 0.5863025227531058}
2022-11-18 02:58:40,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:40,426 INFO:     Epoch: 90
2022-11-18 02:58:41,220 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5525248300197513, 'Total loss': 0.5525248300197513} | train loss {'Reaction outcome loss': 0.5713148881665996, 'Total loss': 0.5713148881665996}
2022-11-18 02:58:41,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:41,220 INFO:     Epoch: 91
2022-11-18 02:58:42,013 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5434726972219556, 'Total loss': 0.5434726972219556} | train loss {'Reaction outcome loss': 0.5838455864396251, 'Total loss': 0.5838455864396251}
2022-11-18 02:58:42,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:42,013 INFO:     Epoch: 92
2022-11-18 02:58:42,771 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5300320567086686, 'Total loss': 0.5300320567086686} | train loss {'Reaction outcome loss': 0.5800390638044624, 'Total loss': 0.5800390638044624}
2022-11-18 02:58:42,771 INFO:     Found new best model at epoch 92
2022-11-18 02:58:42,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:42,772 INFO:     Epoch: 93
2022-11-18 02:58:43,606 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5357854823733486, 'Total loss': 0.5357854823733486} | train loss {'Reaction outcome loss': 0.5948446443701376, 'Total loss': 0.5948446443701376}
2022-11-18 02:58:43,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:43,606 INFO:     Epoch: 94
2022-11-18 02:58:44,413 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5764641217714133, 'Total loss': 0.5764641217714133} | train loss {'Reaction outcome loss': 0.5784654972128204, 'Total loss': 0.5784654972128204}
2022-11-18 02:58:44,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:44,414 INFO:     Epoch: 95
2022-11-18 02:58:45,224 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5713439847147742, 'Total loss': 0.5713439847147742} | train loss {'Reaction outcome loss': 0.5764675975212308, 'Total loss': 0.5764675975212308}
2022-11-18 02:58:45,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:45,225 INFO:     Epoch: 96
2022-11-18 02:58:45,993 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5702383358811223, 'Total loss': 0.5702383358811223} | train loss {'Reaction outcome loss': 0.5794625279844784, 'Total loss': 0.5794625279844784}
2022-11-18 02:58:45,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:45,993 INFO:     Epoch: 97
2022-11-18 02:58:46,747 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5370472392370534, 'Total loss': 0.5370472392370534} | train loss {'Reaction outcome loss': 0.5773654455532793, 'Total loss': 0.5773654455532793}
2022-11-18 02:58:46,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:46,747 INFO:     Epoch: 98
2022-11-18 02:58:47,584 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5372662045234857, 'Total loss': 0.5372662045234857} | train loss {'Reaction outcome loss': 0.5851942676379055, 'Total loss': 0.5851942676379055}
2022-11-18 02:58:47,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:47,585 INFO:     Epoch: 99
2022-11-18 02:58:48,380 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5679930885170781, 'Total loss': 0.5679930885170781} | train loss {'Reaction outcome loss': 0.5677472629630175, 'Total loss': 0.5677472629630175}
2022-11-18 02:58:48,381 INFO:     Best model found after epoch 93 of 100.
2022-11-18 02:58:48,381 INFO:   Done with stage: TRAINING
2022-11-18 02:58:48,381 INFO:   Starting stage: EVALUATION
2022-11-18 02:58:48,514 INFO:   Done with stage: EVALUATION
2022-11-18 02:58:48,515 INFO:   Leaving out SEQ value Fold_3
2022-11-18 02:58:48,528 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:58:48,528 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:58:49,198 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:58:49,198 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:58:49,267 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:58:49,267 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:58:49,267 INFO:     No hyperparam tuning for this model
2022-11-18 02:58:49,267 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:58:49,267 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:58:49,268 INFO:     None feature selector for col prot
2022-11-18 02:58:49,268 INFO:     None feature selector for col prot
2022-11-18 02:58:49,268 INFO:     None feature selector for col prot
2022-11-18 02:58:49,269 INFO:     None feature selector for col chem
2022-11-18 02:58:49,269 INFO:     None feature selector for col chem
2022-11-18 02:58:49,269 INFO:     None feature selector for col chem
2022-11-18 02:58:49,269 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:58:49,269 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:58:49,271 INFO:     Number of params in model 168571
2022-11-18 02:58:49,274 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:58:49,274 INFO:   Starting stage: TRAINING
2022-11-18 02:58:49,331 INFO:     Val loss before train {'Reaction outcome loss': 0.9982696355775346, 'Total loss': 0.9982696355775346}
2022-11-18 02:58:49,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:49,331 INFO:     Epoch: 0
2022-11-18 02:58:50,092 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8339955848316813, 'Total loss': 0.8339955848316813} | train loss {'Reaction outcome loss': 0.8743156330263029, 'Total loss': 0.8743156330263029}
2022-11-18 02:58:50,092 INFO:     Found new best model at epoch 0
2022-11-18 02:58:50,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:50,093 INFO:     Epoch: 1
2022-11-18 02:58:50,858 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8061421305634254, 'Total loss': 0.8061421305634254} | train loss {'Reaction outcome loss': 0.8447251540959858, 'Total loss': 0.8447251540959858}
2022-11-18 02:58:50,858 INFO:     Found new best model at epoch 1
2022-11-18 02:58:50,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:50,859 INFO:     Epoch: 2
2022-11-18 02:58:51,652 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8046536909979444, 'Total loss': 0.8046536909979444} | train loss {'Reaction outcome loss': 0.8278986774995679, 'Total loss': 0.8278986774995679}
2022-11-18 02:58:51,652 INFO:     Found new best model at epoch 2
2022-11-18 02:58:51,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:51,653 INFO:     Epoch: 3
2022-11-18 02:58:52,426 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8054643301076667, 'Total loss': 0.8054643301076667} | train loss {'Reaction outcome loss': 0.8249455034488538, 'Total loss': 0.8249455034488538}
2022-11-18 02:58:52,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:52,426 INFO:     Epoch: 4
2022-11-18 02:58:53,196 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8052777634110562, 'Total loss': 0.8052777634110562} | train loss {'Reaction outcome loss': 0.8224283956968393, 'Total loss': 0.8224283956968393}
2022-11-18 02:58:53,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:53,197 INFO:     Epoch: 5
2022-11-18 02:58:53,972 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7770424201044925, 'Total loss': 0.7770424201044925} | train loss {'Reaction outcome loss': 0.8227393461055443, 'Total loss': 0.8227393461055443}
2022-11-18 02:58:53,973 INFO:     Found new best model at epoch 5
2022-11-18 02:58:53,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:53,973 INFO:     Epoch: 6
2022-11-18 02:58:54,736 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7987775345181309, 'Total loss': 0.7987775345181309} | train loss {'Reaction outcome loss': 0.8156317262375941, 'Total loss': 0.8156317262375941}
2022-11-18 02:58:54,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:54,736 INFO:     Epoch: 7
2022-11-18 02:58:55,496 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7770762374234754, 'Total loss': 0.7770762374234754} | train loss {'Reaction outcome loss': 0.8145135858508407, 'Total loss': 0.8145135858508407}
2022-11-18 02:58:55,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:55,496 INFO:     Epoch: 8
2022-11-18 02:58:56,268 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8081044499264207, 'Total loss': 0.8081044499264207} | train loss {'Reaction outcome loss': 0.8133231962069136, 'Total loss': 0.8133231962069136}
2022-11-18 02:58:56,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:56,268 INFO:     Epoch: 9
2022-11-18 02:58:57,040 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7744550531686738, 'Total loss': 0.7744550531686738} | train loss {'Reaction outcome loss': 0.8130025835555108, 'Total loss': 0.8130025835555108}
2022-11-18 02:58:57,040 INFO:     Found new best model at epoch 9
2022-11-18 02:58:57,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:57,041 INFO:     Epoch: 10
2022-11-18 02:58:57,808 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7738408917604491, 'Total loss': 0.7738408917604491} | train loss {'Reaction outcome loss': 0.8082866148381936, 'Total loss': 0.8082866148381936}
2022-11-18 02:58:57,809 INFO:     Found new best model at epoch 10
2022-11-18 02:58:57,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:57,810 INFO:     Epoch: 11
2022-11-18 02:58:58,566 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7938067989293919, 'Total loss': 0.7938067989293919} | train loss {'Reaction outcome loss': 0.811639342640267, 'Total loss': 0.811639342640267}
2022-11-18 02:58:58,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:58,566 INFO:     Epoch: 12
2022-11-18 02:58:59,329 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7715844560501187, 'Total loss': 0.7715844560501187} | train loss {'Reaction outcome loss': 0.8084163497217366, 'Total loss': 0.8084163497217366}
2022-11-18 02:58:59,330 INFO:     Found new best model at epoch 12
2022-11-18 02:58:59,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:58:59,330 INFO:     Epoch: 13
2022-11-18 02:59:00,120 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7817173038804254, 'Total loss': 0.7817173038804254} | train loss {'Reaction outcome loss': 0.8093832093672674, 'Total loss': 0.8093832093672674}
2022-11-18 02:59:00,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:00,121 INFO:     Epoch: 14
2022-11-18 02:59:00,925 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7802341656629429, 'Total loss': 0.7802341656629429} | train loss {'Reaction outcome loss': 0.8062797060511151, 'Total loss': 0.8062797060511151}
2022-11-18 02:59:00,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:00,925 INFO:     Epoch: 15
2022-11-18 02:59:01,694 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7686987858872081, 'Total loss': 0.7686987858872081} | train loss {'Reaction outcome loss': 0.807838113581548, 'Total loss': 0.807838113581548}
2022-11-18 02:59:01,694 INFO:     Found new best model at epoch 15
2022-11-18 02:59:01,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:01,695 INFO:     Epoch: 16
2022-11-18 02:59:02,473 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7714997391368068, 'Total loss': 0.7714997391368068} | train loss {'Reaction outcome loss': 0.8055184339402152, 'Total loss': 0.8055184339402152}
2022-11-18 02:59:02,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:02,473 INFO:     Epoch: 17
2022-11-18 02:59:03,243 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.784818371368009, 'Total loss': 0.784818371368009} | train loss {'Reaction outcome loss': 0.8092110849550513, 'Total loss': 0.8092110849550513}
2022-11-18 02:59:03,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:03,243 INFO:     Epoch: 18
2022-11-18 02:59:04,014 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7988616020180458, 'Total loss': 0.7988616020180458} | train loss {'Reaction outcome loss': 0.8102086071596771, 'Total loss': 0.8102086071596771}
2022-11-18 02:59:04,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:04,015 INFO:     Epoch: 19
2022-11-18 02:59:04,774 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7778688655343167, 'Total loss': 0.7778688655343167} | train loss {'Reaction outcome loss': 0.8070672843299929, 'Total loss': 0.8070672843299929}
2022-11-18 02:59:04,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:04,775 INFO:     Epoch: 20
2022-11-18 02:59:05,555 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.768811303515767, 'Total loss': 0.768811303515767} | train loss {'Reaction outcome loss': 0.8053336592971302, 'Total loss': 0.8053336592971302}
2022-11-18 02:59:05,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:05,555 INFO:     Epoch: 21
2022-11-18 02:59:06,320 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7836339640062909, 'Total loss': 0.7836339640062909} | train loss {'Reaction outcome loss': 0.8057371912921061, 'Total loss': 0.8057371912921061}
2022-11-18 02:59:06,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:06,320 INFO:     Epoch: 22
2022-11-18 02:59:07,080 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7776465069415958, 'Total loss': 0.7776465069415958} | train loss {'Reaction outcome loss': 0.8060659811389251, 'Total loss': 0.8060659811389251}
2022-11-18 02:59:07,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:07,080 INFO:     Epoch: 23
2022-11-18 02:59:07,844 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7714460824811181, 'Total loss': 0.7714460824811181} | train loss {'Reaction outcome loss': 0.8036567848481115, 'Total loss': 0.8036567848481115}
2022-11-18 02:59:07,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:07,844 INFO:     Epoch: 24
2022-11-18 02:59:08,625 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7783223737117856, 'Total loss': 0.7783223737117856} | train loss {'Reaction outcome loss': 0.8011863645715792, 'Total loss': 0.8011863645715792}
2022-11-18 02:59:08,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:08,625 INFO:     Epoch: 25
2022-11-18 02:59:09,416 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7770036278769027, 'Total loss': 0.7770036278769027} | train loss {'Reaction outcome loss': 0.8066744448952987, 'Total loss': 0.8066744448952987}
2022-11-18 02:59:09,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:09,419 INFO:     Epoch: 26
2022-11-18 02:59:10,182 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7799881863039594, 'Total loss': 0.7799881863039594} | train loss {'Reaction outcome loss': 0.8022622607770513, 'Total loss': 0.8022622607770513}
2022-11-18 02:59:10,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:10,182 INFO:     Epoch: 27
2022-11-18 02:59:10,996 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7920179242311522, 'Total loss': 0.7920179242311522} | train loss {'Reaction outcome loss': 0.8063428609586153, 'Total loss': 0.8063428609586153}
2022-11-18 02:59:10,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:10,996 INFO:     Epoch: 28
2022-11-18 02:59:11,770 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7807287005491035, 'Total loss': 0.7807287005491035} | train loss {'Reaction outcome loss': 0.8037348489780896, 'Total loss': 0.8037348489780896}
2022-11-18 02:59:11,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:11,770 INFO:     Epoch: 29
2022-11-18 02:59:12,549 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.795718904151473, 'Total loss': 0.795718904151473} | train loss {'Reaction outcome loss': 0.8072974003973554, 'Total loss': 0.8072974003973554}
2022-11-18 02:59:12,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:12,549 INFO:     Epoch: 30
2022-11-18 02:59:13,325 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7690503008143846, 'Total loss': 0.7690503008143846} | train loss {'Reaction outcome loss': 0.8003658475201638, 'Total loss': 0.8003658475201638}
2022-11-18 02:59:13,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:13,326 INFO:     Epoch: 31
2022-11-18 02:59:14,107 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7789160747860753, 'Total loss': 0.7789160747860753} | train loss {'Reaction outcome loss': 0.8064203529817159, 'Total loss': 0.8064203529817159}
2022-11-18 02:59:14,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:14,107 INFO:     Epoch: 32
2022-11-18 02:59:14,877 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7710657507874245, 'Total loss': 0.7710657507874245} | train loss {'Reaction outcome loss': 0.801611701606727, 'Total loss': 0.801611701606727}
2022-11-18 02:59:14,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:14,877 INFO:     Epoch: 33
2022-11-18 02:59:15,642 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7823516449262929, 'Total loss': 0.7823516449262929} | train loss {'Reaction outcome loss': 0.8057292836611388, 'Total loss': 0.8057292836611388}
2022-11-18 02:59:15,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:15,643 INFO:     Epoch: 34
2022-11-18 02:59:16,410 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7747982913671538, 'Total loss': 0.7747982913671538} | train loss {'Reaction outcome loss': 0.7997562931697877, 'Total loss': 0.7997562931697877}
2022-11-18 02:59:16,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:16,410 INFO:     Epoch: 35
2022-11-18 02:59:17,183 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7797108722287555, 'Total loss': 0.7797108722287555} | train loss {'Reaction outcome loss': 0.8037761498670108, 'Total loss': 0.8037761498670108}
2022-11-18 02:59:17,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:17,184 INFO:     Epoch: 36
2022-11-18 02:59:17,957 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7791811685229457, 'Total loss': 0.7791811685229457} | train loss {'Reaction outcome loss': 0.8042591556173856, 'Total loss': 0.8042591556173856}
2022-11-18 02:59:17,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:17,958 INFO:     Epoch: 37
2022-11-18 02:59:18,732 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7852146001749261, 'Total loss': 0.7852146001749261} | train loss {'Reaction outcome loss': 0.8008600238893853, 'Total loss': 0.8008600238893853}
2022-11-18 02:59:18,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:18,732 INFO:     Epoch: 38
2022-11-18 02:59:19,527 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7712420474651248, 'Total loss': 0.7712420474651248} | train loss {'Reaction outcome loss': 0.7993257299798434, 'Total loss': 0.7993257299798434}
2022-11-18 02:59:19,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:19,527 INFO:     Epoch: 39
2022-11-18 02:59:20,322 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8084848010262777, 'Total loss': 0.8084848010262777} | train loss {'Reaction outcome loss': 0.8049377149245778, 'Total loss': 0.8049377149245778}
2022-11-18 02:59:20,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:20,323 INFO:     Epoch: 40
2022-11-18 02:59:21,130 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.788296174171359, 'Total loss': 0.788296174171359} | train loss {'Reaction outcome loss': 0.8033705718937467, 'Total loss': 0.8033705718937467}
2022-11-18 02:59:21,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:21,130 INFO:     Epoch: 41
2022-11-18 02:59:21,958 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7796938218349634, 'Total loss': 0.7796938218349634} | train loss {'Reaction outcome loss': 0.80859026117403, 'Total loss': 0.80859026117403}
2022-11-18 02:59:21,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:21,958 INFO:     Epoch: 42
2022-11-18 02:59:22,746 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7683373024297315, 'Total loss': 0.7683373024297315} | train loss {'Reaction outcome loss': 0.8026078383697838, 'Total loss': 0.8026078383697838}
2022-11-18 02:59:22,746 INFO:     Found new best model at epoch 42
2022-11-18 02:59:22,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:22,747 INFO:     Epoch: 43
2022-11-18 02:59:23,520 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7785695569459782, 'Total loss': 0.7785695569459782} | train loss {'Reaction outcome loss': 0.801633971514272, 'Total loss': 0.801633971514272}
2022-11-18 02:59:23,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:23,520 INFO:     Epoch: 44
2022-11-18 02:59:24,296 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7638431704321573, 'Total loss': 0.7638431704321573} | train loss {'Reaction outcome loss': 0.8053480947359664, 'Total loss': 0.8053480947359664}
2022-11-18 02:59:24,296 INFO:     Found new best model at epoch 44
2022-11-18 02:59:24,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:24,297 INFO:     Epoch: 45
2022-11-18 02:59:25,085 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7868181030417598, 'Total loss': 0.7868181030417598} | train loss {'Reaction outcome loss': 0.8057934473283955, 'Total loss': 0.8057934473283955}
2022-11-18 02:59:25,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:25,086 INFO:     Epoch: 46
2022-11-18 02:59:25,869 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7790108433989591, 'Total loss': 0.7790108433989591} | train loss {'Reaction outcome loss': 0.8055116004142605, 'Total loss': 0.8055116004142605}
2022-11-18 02:59:25,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:25,869 INFO:     Epoch: 47
2022-11-18 02:59:26,678 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7821421332137529, 'Total loss': 0.7821421332137529} | train loss {'Reaction outcome loss': 0.8035550662240044, 'Total loss': 0.8035550662240044}
2022-11-18 02:59:26,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:26,678 INFO:     Epoch: 48
2022-11-18 02:59:27,495 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.799608520297117, 'Total loss': 0.799608520297117} | train loss {'Reaction outcome loss': 0.8109241766763515, 'Total loss': 0.8109241766763515}
2022-11-18 02:59:27,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:27,496 INFO:     Epoch: 49
2022-11-18 02:59:28,342 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7888924202253652, 'Total loss': 0.7888924202253652} | train loss {'Reaction outcome loss': 0.8026901797437277, 'Total loss': 0.8026901797437277}
2022-11-18 02:59:28,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:28,343 INFO:     Epoch: 50
2022-11-18 02:59:29,106 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7687595750010291, 'Total loss': 0.7687595750010291} | train loss {'Reaction outcome loss': 0.8022408029827915, 'Total loss': 0.8022408029827915}
2022-11-18 02:59:29,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:29,106 INFO:     Epoch: 51
2022-11-18 02:59:29,934 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7724320015241933, 'Total loss': 0.7724320015241933} | train loss {'Reaction outcome loss': 0.802456578514615, 'Total loss': 0.802456578514615}
2022-11-18 02:59:29,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:29,934 INFO:     Epoch: 52
2022-11-18 02:59:30,717 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.788242406623308, 'Total loss': 0.788242406623308} | train loss {'Reaction outcome loss': 0.8023209375191908, 'Total loss': 0.8023209375191908}
2022-11-18 02:59:30,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:30,717 INFO:     Epoch: 53
2022-11-18 02:59:31,495 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7743322336396505, 'Total loss': 0.7743322336396505} | train loss {'Reaction outcome loss': 0.7994529244596841, 'Total loss': 0.7994529244596841}
2022-11-18 02:59:31,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:31,495 INFO:     Epoch: 54
2022-11-18 02:59:32,283 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.775477524413619, 'Total loss': 0.775477524413619} | train loss {'Reaction outcome loss': 0.8055372340757339, 'Total loss': 0.8055372340757339}
2022-11-18 02:59:32,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:32,284 INFO:     Epoch: 55
2022-11-18 02:59:33,086 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7822500931662183, 'Total loss': 0.7822500931662183} | train loss {'Reaction outcome loss': 0.8032390389774666, 'Total loss': 0.8032390389774666}
2022-11-18 02:59:33,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:33,086 INFO:     Epoch: 56
2022-11-18 02:59:33,930 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7887316276860792, 'Total loss': 0.7887316276860792} | train loss {'Reaction outcome loss': 0.8029081605252673, 'Total loss': 0.8029081605252673}
2022-11-18 02:59:33,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:33,930 INFO:     Epoch: 57
2022-11-18 02:59:34,725 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7799395814884541, 'Total loss': 0.7799395814884541} | train loss {'Reaction outcome loss': 0.8050362477537061, 'Total loss': 0.8050362477537061}
2022-11-18 02:59:34,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:34,725 INFO:     Epoch: 58
2022-11-18 02:59:35,499 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7723969290422839, 'Total loss': 0.7723969290422839} | train loss {'Reaction outcome loss': 0.8022326769643142, 'Total loss': 0.8022326769643142}
2022-11-18 02:59:35,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:35,499 INFO:     Epoch: 59
2022-11-18 02:59:36,304 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7831171515376069, 'Total loss': 0.7831171515376069} | train loss {'Reaction outcome loss': 0.8016273617500165, 'Total loss': 0.8016273617500165}
2022-11-18 02:59:36,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:36,304 INFO:     Epoch: 60
2022-11-18 02:59:37,051 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7812211125396019, 'Total loss': 0.7812211125396019} | train loss {'Reaction outcome loss': 0.7984307695363388, 'Total loss': 0.7984307695363388}
2022-11-18 02:59:37,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:37,051 INFO:     Epoch: 61
2022-11-18 02:59:37,830 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7793799590232761, 'Total loss': 0.7793799590232761} | train loss {'Reaction outcome loss': 0.8006668140897986, 'Total loss': 0.8006668140897986}
2022-11-18 02:59:37,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:37,830 INFO:     Epoch: 62
2022-11-18 02:59:38,622 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7857561153034831, 'Total loss': 0.7857561153034831} | train loss {'Reaction outcome loss': 0.806196960147287, 'Total loss': 0.806196960147287}
2022-11-18 02:59:38,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:38,622 INFO:     Epoch: 63
2022-11-18 02:59:39,416 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7672866908616798, 'Total loss': 0.7672866908616798} | train loss {'Reaction outcome loss': 0.8030910094986197, 'Total loss': 0.8030910094986197}
2022-11-18 02:59:39,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:39,416 INFO:     Epoch: 64
2022-11-18 02:59:40,220 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7796827804210574, 'Total loss': 0.7796827804210574} | train loss {'Reaction outcome loss': 0.7996998567317353, 'Total loss': 0.7996998567317353}
2022-11-18 02:59:40,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:40,220 INFO:     Epoch: 65
2022-11-18 02:59:41,043 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7775515248609144, 'Total loss': 0.7775515248609144} | train loss {'Reaction outcome loss': 0.8022087433787642, 'Total loss': 0.8022087433787642}
2022-11-18 02:59:41,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:41,044 INFO:     Epoch: 66
2022-11-18 02:59:41,875 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7747603959815447, 'Total loss': 0.7747603959815447} | train loss {'Reaction outcome loss': 0.8001089159582482, 'Total loss': 0.8001089159582482}
2022-11-18 02:59:41,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:41,876 INFO:     Epoch: 67
2022-11-18 02:59:42,674 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7746021463427433, 'Total loss': 0.7746021463427433} | train loss {'Reaction outcome loss': 0.7977648566736549, 'Total loss': 0.7977648566736549}
2022-11-18 02:59:42,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:42,674 INFO:     Epoch: 68
2022-11-18 02:59:43,461 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7822655321553696, 'Total loss': 0.7822655321553696} | train loss {'Reaction outcome loss': 0.8003213826994426, 'Total loss': 0.8003213826994426}
2022-11-18 02:59:43,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:43,461 INFO:     Epoch: 69
2022-11-18 02:59:44,225 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7753187279368556, 'Total loss': 0.7753187279368556} | train loss {'Reaction outcome loss': 0.8072807760756524, 'Total loss': 0.8072807760756524}
2022-11-18 02:59:44,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:44,225 INFO:     Epoch: 70
2022-11-18 02:59:45,040 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.796967743441116, 'Total loss': 0.796967743441116} | train loss {'Reaction outcome loss': 0.8018858436433995, 'Total loss': 0.8018858436433995}
2022-11-18 02:59:45,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:45,040 INFO:     Epoch: 71
2022-11-18 02:59:45,830 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7762406690176143, 'Total loss': 0.7762406690176143} | train loss {'Reaction outcome loss': 0.8037517737658297, 'Total loss': 0.8037517737658297}
2022-11-18 02:59:45,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:45,830 INFO:     Epoch: 72
2022-11-18 02:59:46,654 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7726178141527398, 'Total loss': 0.7726178141527398} | train loss {'Reaction outcome loss': 0.803817091540235, 'Total loss': 0.803817091540235}
2022-11-18 02:59:46,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:46,654 INFO:     Epoch: 73
2022-11-18 02:59:47,438 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7677257137243138, 'Total loss': 0.7677257137243138} | train loss {'Reaction outcome loss': 0.8035841536570768, 'Total loss': 0.8035841536570768}
2022-11-18 02:59:47,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:47,439 INFO:     Epoch: 74
2022-11-18 02:59:48,212 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8020706758942715, 'Total loss': 0.8020706758942715} | train loss {'Reaction outcome loss': 0.8001859947794774, 'Total loss': 0.8001859947794774}
2022-11-18 02:59:48,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:48,213 INFO:     Epoch: 75
2022-11-18 02:59:48,993 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7679087949353595, 'Total loss': 0.7679087949353595} | train loss {'Reaction outcome loss': 0.8022695243602893, 'Total loss': 0.8022695243602893}
2022-11-18 02:59:48,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:48,993 INFO:     Epoch: 76
2022-11-18 02:59:49,796 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7733897144018218, 'Total loss': 0.7733897144018218} | train loss {'Reaction outcome loss': 0.7970092093846837, 'Total loss': 0.7970092093846837}
2022-11-18 02:59:49,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:49,796 INFO:     Epoch: 77
2022-11-18 02:59:50,550 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.778993159532547, 'Total loss': 0.778993159532547} | train loss {'Reaction outcome loss': 0.7995965353778152, 'Total loss': 0.7995965353778152}
2022-11-18 02:59:50,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:50,550 INFO:     Epoch: 78
2022-11-18 02:59:51,373 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7703444500302159, 'Total loss': 0.7703444500302159} | train loss {'Reaction outcome loss': 0.7989683300256729, 'Total loss': 0.7989683300256729}
2022-11-18 02:59:51,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:51,373 INFO:     Epoch: 79
2022-11-18 02:59:52,217 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.763464153506035, 'Total loss': 0.763464153506035} | train loss {'Reaction outcome loss': 0.8053415504391076, 'Total loss': 0.8053415504391076}
2022-11-18 02:59:52,218 INFO:     Found new best model at epoch 79
2022-11-18 02:59:52,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:52,218 INFO:     Epoch: 80
2022-11-18 02:59:53,049 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7707015989824783, 'Total loss': 0.7707015989824783} | train loss {'Reaction outcome loss': 0.7973304726794118, 'Total loss': 0.7973304726794118}
2022-11-18 02:59:53,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:53,049 INFO:     Epoch: 81
2022-11-18 02:59:53,836 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7783397200495697, 'Total loss': 0.7783397200495697} | train loss {'Reaction outcome loss': 0.7984095174269598, 'Total loss': 0.7984095174269598}
2022-11-18 02:59:53,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:53,837 INFO:     Epoch: 82
2022-11-18 02:59:54,658 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.787141012590985, 'Total loss': 0.787141012590985} | train loss {'Reaction outcome loss': 0.7932531318215074, 'Total loss': 0.7932531318215074}
2022-11-18 02:59:54,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:54,658 INFO:     Epoch: 83
2022-11-18 02:59:55,450 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7860837052034777, 'Total loss': 0.7860837052034777} | train loss {'Reaction outcome loss': 0.7916881238095096, 'Total loss': 0.7916881238095096}
2022-11-18 02:59:55,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:55,450 INFO:     Epoch: 84
2022-11-18 02:59:56,233 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7813651242921519, 'Total loss': 0.7813651242921519} | train loss {'Reaction outcome loss': 0.7947859263322392, 'Total loss': 0.7947859263322392}
2022-11-18 02:59:56,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:56,233 INFO:     Epoch: 85
2022-11-18 02:59:57,025 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7706383924151576, 'Total loss': 0.7706383924151576} | train loss {'Reaction outcome loss': 0.7898678675782486, 'Total loss': 0.7898678675782486}
2022-11-18 02:59:57,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:57,025 INFO:     Epoch: 86
2022-11-18 02:59:57,849 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7660715420578801, 'Total loss': 0.7660715420578801} | train loss {'Reaction outcome loss': 0.7895514285955273, 'Total loss': 0.7895514285955273}
2022-11-18 02:59:57,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:57,849 INFO:     Epoch: 87
2022-11-18 02:59:58,675 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.76944117837174, 'Total loss': 0.76944117837174} | train loss {'Reaction outcome loss': 0.7858838572121057, 'Total loss': 0.7858838572121057}
2022-11-18 02:59:58,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:58,675 INFO:     Epoch: 88
2022-11-18 02:59:59,436 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7938189153061357, 'Total loss': 0.7938189153061357} | train loss {'Reaction outcome loss': 0.7879213615030539, 'Total loss': 0.7879213615030539}
2022-11-18 02:59:59,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:59:59,436 INFO:     Epoch: 89
2022-11-18 03:00:00,254 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7623963002548662, 'Total loss': 0.7623963002548662} | train loss {'Reaction outcome loss': 0.7873152899937551, 'Total loss': 0.7873152899937551}
2022-11-18 03:00:00,255 INFO:     Found new best model at epoch 89
2022-11-18 03:00:00,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:00,256 INFO:     Epoch: 90
2022-11-18 03:00:01,066 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7742873298567395, 'Total loss': 0.7742873298567395} | train loss {'Reaction outcome loss': 0.7814867337707614, 'Total loss': 0.7814867337707614}
2022-11-18 03:00:01,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:01,067 INFO:     Epoch: 91
2022-11-18 03:00:01,851 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7549550373886906, 'Total loss': 0.7549550373886906} | train loss {'Reaction outcome loss': 0.7845485953033947, 'Total loss': 0.7845485953033947}
2022-11-18 03:00:01,851 INFO:     Found new best model at epoch 91
2022-11-18 03:00:01,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:01,852 INFO:     Epoch: 92
2022-11-18 03:00:02,629 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7517448095388191, 'Total loss': 0.7517448095388191} | train loss {'Reaction outcome loss': 0.7787625782313894, 'Total loss': 0.7787625782313894}
2022-11-18 03:00:02,629 INFO:     Found new best model at epoch 92
2022-11-18 03:00:02,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:02,630 INFO:     Epoch: 93
2022-11-18 03:00:03,423 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7549445026142653, 'Total loss': 0.7549445026142653} | train loss {'Reaction outcome loss': 0.7776917828643908, 'Total loss': 0.7776917828643908}
2022-11-18 03:00:03,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:03,423 INFO:     Epoch: 94
2022-11-18 03:00:04,209 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7613755928915601, 'Total loss': 0.7613755928915601} | train loss {'Reaction outcome loss': 0.7680444354649449, 'Total loss': 0.7680444354649449}
2022-11-18 03:00:04,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:04,210 INFO:     Epoch: 95
2022-11-18 03:00:05,030 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.747660405414049, 'Total loss': 0.747660405414049} | train loss {'Reaction outcome loss': 0.7701654334048755, 'Total loss': 0.7701654334048755}
2022-11-18 03:00:05,030 INFO:     Found new best model at epoch 95
2022-11-18 03:00:05,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:05,031 INFO:     Epoch: 96
2022-11-18 03:00:05,844 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.744169166614843, 'Total loss': 0.744169166614843} | train loss {'Reaction outcome loss': 0.7681605873293564, 'Total loss': 0.7681605873293564}
2022-11-18 03:00:05,844 INFO:     Found new best model at epoch 96
2022-11-18 03:00:05,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:05,845 INFO:     Epoch: 97
2022-11-18 03:00:06,655 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.729417703179426, 'Total loss': 0.729417703179426} | train loss {'Reaction outcome loss': 0.767812187676547, 'Total loss': 0.767812187676547}
2022-11-18 03:00:06,655 INFO:     Found new best model at epoch 97
2022-11-18 03:00:06,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:06,656 INFO:     Epoch: 98
2022-11-18 03:00:07,473 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7374871761299843, 'Total loss': 0.7374871761299843} | train loss {'Reaction outcome loss': 0.7682733215758057, 'Total loss': 0.7682733215758057}
2022-11-18 03:00:07,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:07,473 INFO:     Epoch: 99
2022-11-18 03:00:08,301 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7328403793102087, 'Total loss': 0.7328403793102087} | train loss {'Reaction outcome loss': 0.7590584354322465, 'Total loss': 0.7590584354322465}
2022-11-18 03:00:08,301 INFO:     Best model found after epoch 98 of 100.
2022-11-18 03:00:08,301 INFO:   Done with stage: TRAINING
2022-11-18 03:00:08,301 INFO:   Starting stage: EVALUATION
2022-11-18 03:00:08,434 INFO:   Done with stage: EVALUATION
2022-11-18 03:00:08,434 INFO:   Leaving out SEQ value Fold_4
2022-11-18 03:00:08,447 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:00:08,447 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:00:09,120 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:00:09,120 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:00:09,190 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:00:09,190 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:00:09,190 INFO:     No hyperparam tuning for this model
2022-11-18 03:00:09,190 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:00:09,190 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:00:09,191 INFO:     None feature selector for col prot
2022-11-18 03:00:09,191 INFO:     None feature selector for col prot
2022-11-18 03:00:09,191 INFO:     None feature selector for col prot
2022-11-18 03:00:09,192 INFO:     None feature selector for col chem
2022-11-18 03:00:09,192 INFO:     None feature selector for col chem
2022-11-18 03:00:09,192 INFO:     None feature selector for col chem
2022-11-18 03:00:09,192 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:00:09,192 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:00:09,194 INFO:     Number of params in model 168571
2022-11-18 03:00:09,197 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:00:09,197 INFO:   Starting stage: TRAINING
2022-11-18 03:00:09,255 INFO:     Val loss before train {'Reaction outcome loss': 0.9760181483897296, 'Total loss': 0.9760181483897296}
2022-11-18 03:00:09,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:09,255 INFO:     Epoch: 0
2022-11-18 03:00:10,088 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8476699875159697, 'Total loss': 0.8476699875159697} | train loss {'Reaction outcome loss': 0.8829420599860218, 'Total loss': 0.8829420599860218}
2022-11-18 03:00:10,088 INFO:     Found new best model at epoch 0
2022-11-18 03:00:10,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:10,089 INFO:     Epoch: 1
2022-11-18 03:00:10,903 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8392929841171611, 'Total loss': 0.8392929841171611} | train loss {'Reaction outcome loss': 0.8466529046234331, 'Total loss': 0.8466529046234331}
2022-11-18 03:00:10,903 INFO:     Found new best model at epoch 1
2022-11-18 03:00:10,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:10,904 INFO:     Epoch: 2
2022-11-18 03:00:11,722 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.829757500778545, 'Total loss': 0.829757500778545} | train loss {'Reaction outcome loss': 0.8480650758453709, 'Total loss': 0.8480650758453709}
2022-11-18 03:00:11,723 INFO:     Found new best model at epoch 2
2022-11-18 03:00:11,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:11,724 INFO:     Epoch: 3
2022-11-18 03:00:12,555 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8415206155993722, 'Total loss': 0.8415206155993722} | train loss {'Reaction outcome loss': 0.839960568346958, 'Total loss': 0.839960568346958}
2022-11-18 03:00:12,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:12,557 INFO:     Epoch: 4
2022-11-18 03:00:13,381 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8112229474566199, 'Total loss': 0.8112229474566199} | train loss {'Reaction outcome loss': 0.8264368780651073, 'Total loss': 0.8264368780651073}
2022-11-18 03:00:13,381 INFO:     Found new best model at epoch 4
2022-11-18 03:00:13,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:13,382 INFO:     Epoch: 5
2022-11-18 03:00:14,173 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8344396088610996, 'Total loss': 0.8344396088610996} | train loss {'Reaction outcome loss': 0.8294641583072029, 'Total loss': 0.8294641583072029}
2022-11-18 03:00:14,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:14,173 INFO:     Epoch: 6
2022-11-18 03:00:14,978 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8269663195718419, 'Total loss': 0.8269663195718419} | train loss {'Reaction outcome loss': 0.8258498863049364, 'Total loss': 0.8258498863049364}
2022-11-18 03:00:14,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:14,978 INFO:     Epoch: 7
2022-11-18 03:00:15,743 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8250869675116106, 'Total loss': 0.8250869675116106} | train loss {'Reaction outcome loss': 0.8243824476413881, 'Total loss': 0.8243824476413881}
2022-11-18 03:00:15,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:15,743 INFO:     Epoch: 8
2022-11-18 03:00:16,526 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.818286151371219, 'Total loss': 0.818286151371219} | train loss {'Reaction outcome loss': 0.8236238879230824, 'Total loss': 0.8236238879230824}
2022-11-18 03:00:16,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:16,526 INFO:     Epoch: 9
2022-11-18 03:00:17,365 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8116261904889887, 'Total loss': 0.8116261904889887} | train loss {'Reaction outcome loss': 0.8200429571784942, 'Total loss': 0.8200429571784942}
2022-11-18 03:00:17,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:17,366 INFO:     Epoch: 10
2022-11-18 03:00:18,155 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8237914395603266, 'Total loss': 0.8237914395603266} | train loss {'Reaction outcome loss': 0.8197727909213618, 'Total loss': 0.8197727909213618}
2022-11-18 03:00:18,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:18,156 INFO:     Epoch: 11
2022-11-18 03:00:18,968 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8145103752613068, 'Total loss': 0.8145103752613068} | train loss {'Reaction outcome loss': 0.8141775015394698, 'Total loss': 0.8141775015394698}
2022-11-18 03:00:18,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:18,969 INFO:     Epoch: 12
2022-11-18 03:00:19,761 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.814349880272692, 'Total loss': 0.814349880272692} | train loss {'Reaction outcome loss': 0.8221518432321818, 'Total loss': 0.8221518432321818}
2022-11-18 03:00:19,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:19,762 INFO:     Epoch: 13
2022-11-18 03:00:20,587 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8152893862941049, 'Total loss': 0.8152893862941049} | train loss {'Reaction outcome loss': 0.8177824341333829, 'Total loss': 0.8177824341333829}
2022-11-18 03:00:20,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:20,587 INFO:     Epoch: 14
2022-11-18 03:00:21,387 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8358189897103743, 'Total loss': 0.8358189897103743} | train loss {'Reaction outcome loss': 0.8129117214969295, 'Total loss': 0.8129117214969295}
2022-11-18 03:00:21,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:21,388 INFO:     Epoch: 15
2022-11-18 03:00:22,189 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8258327767252922, 'Total loss': 0.8258327767252922} | train loss {'Reaction outcome loss': 0.8165313749902161, 'Total loss': 0.8165313749902161}
2022-11-18 03:00:22,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:22,190 INFO:     Epoch: 16
2022-11-18 03:00:22,985 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.817231104455211, 'Total loss': 0.817231104455211} | train loss {'Reaction outcome loss': 0.8150836139133102, 'Total loss': 0.8150836139133102}
2022-11-18 03:00:22,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:22,986 INFO:     Epoch: 17
2022-11-18 03:00:23,761 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.802776734937321, 'Total loss': 0.802776734937321} | train loss {'Reaction outcome loss': 0.8127245200790374, 'Total loss': 0.8127245200790374}
2022-11-18 03:00:23,761 INFO:     Found new best model at epoch 17
2022-11-18 03:00:23,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:23,762 INFO:     Epoch: 18
2022-11-18 03:00:24,524 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8043429282578555, 'Total loss': 0.8043429282578555} | train loss {'Reaction outcome loss': 0.8147722985821697, 'Total loss': 0.8147722985821697}
2022-11-18 03:00:24,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:24,525 INFO:     Epoch: 19
2022-11-18 03:00:25,308 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8232263164086775, 'Total loss': 0.8232263164086775} | train loss {'Reaction outcome loss': 0.8207696463897644, 'Total loss': 0.8207696463897644}
2022-11-18 03:00:25,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:25,308 INFO:     Epoch: 20
2022-11-18 03:00:26,067 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8459544378248128, 'Total loss': 0.8459544378248128} | train loss {'Reaction outcome loss': 0.8213399968407897, 'Total loss': 0.8213399968407897}
2022-11-18 03:00:26,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:26,067 INFO:     Epoch: 21
2022-11-18 03:00:26,845 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8195293342525308, 'Total loss': 0.8195293342525308} | train loss {'Reaction outcome loss': 0.8140926474200086, 'Total loss': 0.8140926474200086}
2022-11-18 03:00:26,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:26,846 INFO:     Epoch: 22
2022-11-18 03:00:27,635 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8303411494601857, 'Total loss': 0.8303411494601857} | train loss {'Reaction outcome loss': 0.813995898493871, 'Total loss': 0.813995898493871}
2022-11-18 03:00:27,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:27,635 INFO:     Epoch: 23
2022-11-18 03:00:28,399 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8143404796719551, 'Total loss': 0.8143404796719551} | train loss {'Reaction outcome loss': 0.817957101925182, 'Total loss': 0.817957101925182}
2022-11-18 03:00:28,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:28,399 INFO:     Epoch: 24
2022-11-18 03:00:29,162 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8401897874745455, 'Total loss': 0.8401897874745455} | train loss {'Reaction outcome loss': 0.8112197950301383, 'Total loss': 0.8112197950301383}
2022-11-18 03:00:29,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:29,162 INFO:     Epoch: 25
2022-11-18 03:00:29,938 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8106198236346245, 'Total loss': 0.8106198236346245} | train loss {'Reaction outcome loss': 0.8176801829685566, 'Total loss': 0.8176801829685566}
2022-11-18 03:00:29,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:29,938 INFO:     Epoch: 26
2022-11-18 03:00:30,730 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8291239745237611, 'Total loss': 0.8291239745237611} | train loss {'Reaction outcome loss': 0.8138814970307987, 'Total loss': 0.8138814970307987}
2022-11-18 03:00:30,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:30,731 INFO:     Epoch: 27
2022-11-18 03:00:31,530 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8272906392812729, 'Total loss': 0.8272906392812729} | train loss {'Reaction outcome loss': 0.8197848298530347, 'Total loss': 0.8197848298530347}
2022-11-18 03:00:31,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:31,531 INFO:     Epoch: 28
2022-11-18 03:00:32,332 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8014732192863118, 'Total loss': 0.8014732192863118} | train loss {'Reaction outcome loss': 0.8136540758706298, 'Total loss': 0.8136540758706298}
2022-11-18 03:00:32,332 INFO:     Found new best model at epoch 28
2022-11-18 03:00:32,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:32,333 INFO:     Epoch: 29
2022-11-18 03:00:33,113 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8148806569251147, 'Total loss': 0.8148806569251147} | train loss {'Reaction outcome loss': 0.8156996734953119, 'Total loss': 0.8156996734953119}
2022-11-18 03:00:33,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:33,113 INFO:     Epoch: 30
2022-11-18 03:00:33,880 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8090725168585777, 'Total loss': 0.8090725168585777} | train loss {'Reaction outcome loss': 0.8128253898398596, 'Total loss': 0.8128253898398596}
2022-11-18 03:00:33,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:33,880 INFO:     Epoch: 31
2022-11-18 03:00:34,653 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8256401683796536, 'Total loss': 0.8256401683796536} | train loss {'Reaction outcome loss': 0.8103502472704239, 'Total loss': 0.8103502472704239}
2022-11-18 03:00:34,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:34,653 INFO:     Epoch: 32
2022-11-18 03:00:35,438 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8088605779815804, 'Total loss': 0.8088605779815804} | train loss {'Reaction outcome loss': 0.8154890676017715, 'Total loss': 0.8154890676017715}
2022-11-18 03:00:35,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:35,438 INFO:     Epoch: 33
2022-11-18 03:00:36,229 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8121453415263783, 'Total loss': 0.8121453415263783} | train loss {'Reaction outcome loss': 0.8070035112290247, 'Total loss': 0.8070035112290247}
2022-11-18 03:00:36,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:36,229 INFO:     Epoch: 34
2022-11-18 03:00:37,001 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8226213197816502, 'Total loss': 0.8226213197816502} | train loss {'Reaction outcome loss': 0.8138643452513074, 'Total loss': 0.8138643452513074}
2022-11-18 03:00:37,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:37,001 INFO:     Epoch: 35
2022-11-18 03:00:37,785 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8055717159401287, 'Total loss': 0.8055717159401287} | train loss {'Reaction outcome loss': 0.8138964921839325, 'Total loss': 0.8138964921839325}
2022-11-18 03:00:37,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:37,786 INFO:     Epoch: 36
2022-11-18 03:00:38,574 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8125576221130111, 'Total loss': 0.8125576221130111} | train loss {'Reaction outcome loss': 0.807530499904262, 'Total loss': 0.807530499904262}
2022-11-18 03:00:38,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:38,574 INFO:     Epoch: 37
2022-11-18 03:00:39,342 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8792255575006659, 'Total loss': 0.8792255575006659} | train loss {'Reaction outcome loss': 0.8107682570272129, 'Total loss': 0.8107682570272129}
2022-11-18 03:00:39,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:39,342 INFO:     Epoch: 38
2022-11-18 03:00:40,092 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8186782056635077, 'Total loss': 0.8186782056635077} | train loss {'Reaction outcome loss': 0.8164083540198291, 'Total loss': 0.8164083540198291}
2022-11-18 03:00:40,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:40,092 INFO:     Epoch: 39
2022-11-18 03:00:40,891 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.826040817932649, 'Total loss': 0.826040817932649} | train loss {'Reaction outcome loss': 0.8083924855961491, 'Total loss': 0.8083924855961491}
2022-11-18 03:00:40,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:40,891 INFO:     Epoch: 40
2022-11-18 03:00:41,685 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.812085288492116, 'Total loss': 0.812085288492116} | train loss {'Reaction outcome loss': 0.8148063103921017, 'Total loss': 0.8148063103921017}
2022-11-18 03:00:41,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:41,685 INFO:     Epoch: 41
2022-11-18 03:00:42,457 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8196215426379984, 'Total loss': 0.8196215426379984} | train loss {'Reaction outcome loss': 0.8087961169389578, 'Total loss': 0.8087961169389578}
2022-11-18 03:00:42,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:42,457 INFO:     Epoch: 42
2022-11-18 03:00:43,225 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8166022639382969, 'Total loss': 0.8166022639382969} | train loss {'Reaction outcome loss': 0.8203358104837085, 'Total loss': 0.8203358104837085}
2022-11-18 03:00:43,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:43,225 INFO:     Epoch: 43
2022-11-18 03:00:44,001 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7985642247579314, 'Total loss': 0.7985642247579314} | train loss {'Reaction outcome loss': 0.8064446598291397, 'Total loss': 0.8064446598291397}
2022-11-18 03:00:44,002 INFO:     Found new best model at epoch 43
2022-11-18 03:00:44,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:44,003 INFO:     Epoch: 44
2022-11-18 03:00:44,810 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8043386319821532, 'Total loss': 0.8043386319821532} | train loss {'Reaction outcome loss': 0.8086763243926199, 'Total loss': 0.8086763243926199}
2022-11-18 03:00:44,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:44,810 INFO:     Epoch: 45
2022-11-18 03:00:45,592 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8030221868645061, 'Total loss': 0.8030221868645061} | train loss {'Reaction outcome loss': 0.8072888939396331, 'Total loss': 0.8072888939396331}
2022-11-18 03:00:45,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:45,593 INFO:     Epoch: 46
2022-11-18 03:00:46,396 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.823436127467589, 'Total loss': 0.823436127467589} | train loss {'Reaction outcome loss': 0.8057914639291494, 'Total loss': 0.8057914639291494}
2022-11-18 03:00:46,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:46,396 INFO:     Epoch: 47
2022-11-18 03:00:47,183 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8179479288783941, 'Total loss': 0.8179479288783941} | train loss {'Reaction outcome loss': 0.8210870346077058, 'Total loss': 0.8210870346077058}
2022-11-18 03:00:47,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:47,184 INFO:     Epoch: 48
2022-11-18 03:00:47,980 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8106156953356483, 'Total loss': 0.8106156953356483} | train loss {'Reaction outcome loss': 0.8097744726459024, 'Total loss': 0.8097744726459024}
2022-11-18 03:00:47,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:47,980 INFO:     Epoch: 49
2022-11-18 03:00:48,751 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8437109420245344, 'Total loss': 0.8437109420245344} | train loss {'Reaction outcome loss': 0.8099931485739796, 'Total loss': 0.8099931485739796}
2022-11-18 03:00:48,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:48,751 INFO:     Epoch: 50
2022-11-18 03:00:49,528 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8068655566735701, 'Total loss': 0.8068655566735701} | train loss {'Reaction outcome loss': 0.8080616574055752, 'Total loss': 0.8080616574055752}
2022-11-18 03:00:49,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:49,529 INFO:     Epoch: 51
2022-11-18 03:00:50,292 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8214714865792881, 'Total loss': 0.8214714865792881} | train loss {'Reaction outcome loss': 0.8099767411286048, 'Total loss': 0.8099767411286048}
2022-11-18 03:00:50,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:50,294 INFO:     Epoch: 52
2022-11-18 03:00:51,051 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8052220676432956, 'Total loss': 0.8052220676432956} | train loss {'Reaction outcome loss': 0.8109526574491006, 'Total loss': 0.8109526574491006}
2022-11-18 03:00:51,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:51,051 INFO:     Epoch: 53
2022-11-18 03:00:51,824 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8055388074029576, 'Total loss': 0.8055388074029576} | train loss {'Reaction outcome loss': 0.8033447507542637, 'Total loss': 0.8033447507542637}
2022-11-18 03:00:51,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:51,824 INFO:     Epoch: 54
2022-11-18 03:00:52,598 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.812771197069775, 'Total loss': 0.812771197069775} | train loss {'Reaction outcome loss': 0.8063801089641054, 'Total loss': 0.8063801089641054}
2022-11-18 03:00:52,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:52,599 INFO:     Epoch: 55
2022-11-18 03:00:53,356 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.822835505686023, 'Total loss': 0.822835505686023} | train loss {'Reaction outcome loss': 0.8111268758532489, 'Total loss': 0.8111268758532489}
2022-11-18 03:00:53,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:53,356 INFO:     Epoch: 56
2022-11-18 03:00:54,126 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8089440884915265, 'Total loss': 0.8089440884915265} | train loss {'Reaction outcome loss': 0.8089026885959301, 'Total loss': 0.8089026885959301}
2022-11-18 03:00:54,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:54,126 INFO:     Epoch: 57
2022-11-18 03:00:54,946 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8210622119632635, 'Total loss': 0.8210622119632635} | train loss {'Reaction outcome loss': 0.8120992324854198, 'Total loss': 0.8120992324854198}
2022-11-18 03:00:54,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:54,946 INFO:     Epoch: 58
2022-11-18 03:00:55,725 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8175337043675509, 'Total loss': 0.8175337043675509} | train loss {'Reaction outcome loss': 0.8082019426079414, 'Total loss': 0.8082019426079414}
2022-11-18 03:00:55,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:55,726 INFO:     Epoch: 59
2022-11-18 03:00:56,507 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8063558157194745, 'Total loss': 0.8063558157194745} | train loss {'Reaction outcome loss': 0.809947643021823, 'Total loss': 0.809947643021823}
2022-11-18 03:00:56,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:56,507 INFO:     Epoch: 60
2022-11-18 03:00:57,285 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8050345209511843, 'Total loss': 0.8050345209511843} | train loss {'Reaction outcome loss': 0.8171519352356914, 'Total loss': 0.8171519352356914}
2022-11-18 03:00:57,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:57,285 INFO:     Epoch: 61
2022-11-18 03:00:58,056 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7982772798700766, 'Total loss': 0.7982772798700766} | train loss {'Reaction outcome loss': 0.8119454749441339, 'Total loss': 0.8119454749441339}
2022-11-18 03:00:58,056 INFO:     Found new best model at epoch 61
2022-11-18 03:00:58,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:58,058 INFO:     Epoch: 62
2022-11-18 03:00:58,823 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8356480625542727, 'Total loss': 0.8356480625542727} | train loss {'Reaction outcome loss': 0.8103039335866689, 'Total loss': 0.8103039335866689}
2022-11-18 03:00:58,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:58,823 INFO:     Epoch: 63
2022-11-18 03:00:59,605 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8082306005737998, 'Total loss': 0.8082306005737998} | train loss {'Reaction outcome loss': 0.811094276033915, 'Total loss': 0.811094276033915}
2022-11-18 03:00:59,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:00:59,605 INFO:     Epoch: 64
2022-11-18 03:01:00,409 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.840934885496443, 'Total loss': 0.840934885496443} | train loss {'Reaction outcome loss': 0.8039759608656771, 'Total loss': 0.8039759608656771}
2022-11-18 03:01:00,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:00,410 INFO:     Epoch: 65
2022-11-18 03:01:01,207 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.807931352745403, 'Total loss': 0.807931352745403} | train loss {'Reaction outcome loss': 0.8167990964916554, 'Total loss': 0.8167990964916554}
2022-11-18 03:01:01,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:01,207 INFO:     Epoch: 66
2022-11-18 03:01:02,003 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8192944093184038, 'Total loss': 0.8192944093184038} | train loss {'Reaction outcome loss': 0.8105055186671284, 'Total loss': 0.8105055186671284}
2022-11-18 03:01:02,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:02,003 INFO:     Epoch: 67
2022-11-18 03:01:02,812 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8330527882684361, 'Total loss': 0.8330527882684361} | train loss {'Reaction outcome loss': 0.8141609990162405, 'Total loss': 0.8141609990162405}
2022-11-18 03:01:02,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:02,813 INFO:     Epoch: 68
2022-11-18 03:01:03,595 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8012842678210952, 'Total loss': 0.8012842678210952} | train loss {'Reaction outcome loss': 0.8098833059462217, 'Total loss': 0.8098833059462217}
2022-11-18 03:01:03,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:03,596 INFO:     Epoch: 69
2022-11-18 03:01:04,340 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8146880485794761, 'Total loss': 0.8146880485794761} | train loss {'Reaction outcome loss': 0.8088755086365982, 'Total loss': 0.8088755086365982}
2022-11-18 03:01:04,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:04,340 INFO:     Epoch: 70
2022-11-18 03:01:05,138 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.817340961234136, 'Total loss': 0.817340961234136} | train loss {'Reaction outcome loss': 0.8078102786772647, 'Total loss': 0.8078102786772647}
2022-11-18 03:01:05,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:05,138 INFO:     Epoch: 71
2022-11-18 03:01:05,922 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8198478702794422, 'Total loss': 0.8198478702794422} | train loss {'Reaction outcome loss': 0.811938308028557, 'Total loss': 0.811938308028557}
2022-11-18 03:01:05,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:05,922 INFO:     Epoch: 72
2022-11-18 03:01:06,729 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8376439410177144, 'Total loss': 0.8376439410177144} | train loss {'Reaction outcome loss': 0.8077678572884214, 'Total loss': 0.8077678572884214}
2022-11-18 03:01:06,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:06,729 INFO:     Epoch: 73
2022-11-18 03:01:07,517 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8147824277931993, 'Total loss': 0.8147824277931993} | train loss {'Reaction outcome loss': 0.8066644908686881, 'Total loss': 0.8066644908686881}
2022-11-18 03:01:07,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:07,517 INFO:     Epoch: 74
2022-11-18 03:01:08,289 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8060522512956099, 'Total loss': 0.8060522512956099} | train loss {'Reaction outcome loss': 0.8080619125955018, 'Total loss': 0.8080619125955018}
2022-11-18 03:01:08,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:08,289 INFO:     Epoch: 75
2022-11-18 03:01:09,047 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8238635442473672, 'Total loss': 0.8238635442473672} | train loss {'Reaction outcome loss': 0.809937580831741, 'Total loss': 0.809937580831741}
2022-11-18 03:01:09,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:09,048 INFO:     Epoch: 76
2022-11-18 03:01:09,842 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8136700344356623, 'Total loss': 0.8136700344356623} | train loss {'Reaction outcome loss': 0.8083134317687648, 'Total loss': 0.8083134317687648}
2022-11-18 03:01:09,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:09,842 INFO:     Epoch: 77
2022-11-18 03:01:10,632 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8542263060808182, 'Total loss': 0.8542263060808182} | train loss {'Reaction outcome loss': 0.8067638782354501, 'Total loss': 0.8067638782354501}
2022-11-18 03:01:10,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:10,633 INFO:     Epoch: 78
2022-11-18 03:01:11,429 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8104259480129589, 'Total loss': 0.8104259480129589} | train loss {'Reaction outcome loss': 0.8113485008840137, 'Total loss': 0.8113485008840137}
2022-11-18 03:01:11,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:11,430 INFO:     Epoch: 79
2022-11-18 03:01:12,207 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8321843831376596, 'Total loss': 0.8321843831376596} | train loss {'Reaction outcome loss': 0.8070548438591513, 'Total loss': 0.8070548438591513}
2022-11-18 03:01:12,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:12,207 INFO:     Epoch: 80
2022-11-18 03:01:13,017 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8165633095936342, 'Total loss': 0.8165633095936342} | train loss {'Reaction outcome loss': 0.8084237859075368, 'Total loss': 0.8084237859075368}
2022-11-18 03:01:13,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:13,018 INFO:     Epoch: 81
2022-11-18 03:01:13,817 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8423379490321333, 'Total loss': 0.8423379490321333} | train loss {'Reaction outcome loss': 0.8118229040250122, 'Total loss': 0.8118229040250122}
2022-11-18 03:01:13,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:13,817 INFO:     Epoch: 82
2022-11-18 03:01:14,602 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8057796101678502, 'Total loss': 0.8057796101678502} | train loss {'Reaction outcome loss': 0.8116609051160002, 'Total loss': 0.8116609051160002}
2022-11-18 03:01:14,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:14,604 INFO:     Epoch: 83
2022-11-18 03:01:15,371 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8110250573266636, 'Total loss': 0.8110250573266636} | train loss {'Reaction outcome loss': 0.8034138124255155, 'Total loss': 0.8034138124255155}
2022-11-18 03:01:15,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:15,371 INFO:     Epoch: 84
2022-11-18 03:01:16,175 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8228154656561938, 'Total loss': 0.8228154656561938} | train loss {'Reaction outcome loss': 0.8090111762888519, 'Total loss': 0.8090111762888519}
2022-11-18 03:01:16,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:16,175 INFO:     Epoch: 85
2022-11-18 03:01:16,965 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8113535744222727, 'Total loss': 0.8113535744222727} | train loss {'Reaction outcome loss': 0.8083627704184065, 'Total loss': 0.8083627704184065}
2022-11-18 03:01:16,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:16,965 INFO:     Epoch: 86
2022-11-18 03:01:17,762 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8051336136731234, 'Total loss': 0.8051336136731234} | train loss {'Reaction outcome loss': 0.8082157970681364, 'Total loss': 0.8082157970681364}
2022-11-18 03:01:17,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:17,763 INFO:     Epoch: 87
2022-11-18 03:01:18,549 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8154622126709331, 'Total loss': 0.8154622126709331} | train loss {'Reaction outcome loss': 0.7990029630315328, 'Total loss': 0.7990029630315328}
2022-11-18 03:01:18,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:18,549 INFO:     Epoch: 88
2022-11-18 03:01:19,300 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8017211251638152, 'Total loss': 0.8017211251638152} | train loss {'Reaction outcome loss': 0.8032696285711126, 'Total loss': 0.8032696285711126}
2022-11-18 03:01:19,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:19,300 INFO:     Epoch: 89
2022-11-18 03:01:20,071 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8232806006615813, 'Total loss': 0.8232806006615813} | train loss {'Reaction outcome loss': 0.8017914785366309, 'Total loss': 0.8017914785366309}
2022-11-18 03:01:20,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:20,071 INFO:     Epoch: 90
2022-11-18 03:01:20,829 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8034121665087613, 'Total loss': 0.8034121665087613} | train loss {'Reaction outcome loss': 0.8188572324480605, 'Total loss': 0.8188572324480605}
2022-11-18 03:01:20,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:20,830 INFO:     Epoch: 91
2022-11-18 03:01:21,625 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8070190318606116, 'Total loss': 0.8070190318606116} | train loss {'Reaction outcome loss': 0.8068981994742807, 'Total loss': 0.8068981994742807}
2022-11-18 03:01:21,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:21,625 INFO:     Epoch: 92
2022-11-18 03:01:22,387 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.846617732535709, 'Total loss': 0.846617732535709} | train loss {'Reaction outcome loss': 0.8069949895746795, 'Total loss': 0.8069949895746795}
2022-11-18 03:01:22,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:22,387 INFO:     Epoch: 93
2022-11-18 03:01:23,140 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.804889902472496, 'Total loss': 0.804889902472496} | train loss {'Reaction outcome loss': 0.8041747080290366, 'Total loss': 0.8041747080290366}
2022-11-18 03:01:23,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:23,140 INFO:     Epoch: 94
2022-11-18 03:01:23,927 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8138743835416707, 'Total loss': 0.8138743835416707} | train loss {'Reaction outcome loss': 0.7974280284845877, 'Total loss': 0.7974280284845877}
2022-11-18 03:01:23,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:23,927 INFO:     Epoch: 95
2022-11-18 03:01:24,712 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8144774883985519, 'Total loss': 0.8144774883985519} | train loss {'Reaction outcome loss': 0.8095999788417507, 'Total loss': 0.8095999788417507}
2022-11-18 03:01:24,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:24,713 INFO:     Epoch: 96
2022-11-18 03:01:25,477 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8198587609962984, 'Total loss': 0.8198587609962984} | train loss {'Reaction outcome loss': 0.8063035591652519, 'Total loss': 0.8063035591652519}
2022-11-18 03:01:25,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:25,477 INFO:     Epoch: 97
2022-11-18 03:01:26,237 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7981705624948848, 'Total loss': 0.7981705624948848} | train loss {'Reaction outcome loss': 0.8067322730535438, 'Total loss': 0.8067322730535438}
2022-11-18 03:01:26,237 INFO:     Found new best model at epoch 97
2022-11-18 03:01:26,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:26,238 INFO:     Epoch: 98
2022-11-18 03:01:27,012 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.815844058313153, 'Total loss': 0.815844058313153} | train loss {'Reaction outcome loss': 0.8050243408091156, 'Total loss': 0.8050243408091156}
2022-11-18 03:01:27,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:27,013 INFO:     Epoch: 99
2022-11-18 03:01:27,808 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8043612031774088, 'Total loss': 0.8043612031774088} | train loss {'Reaction outcome loss': 0.8013271913460271, 'Total loss': 0.8013271913460271}
2022-11-18 03:01:27,809 INFO:     Best model found after epoch 98 of 100.
2022-11-18 03:01:27,809 INFO:   Done with stage: TRAINING
2022-11-18 03:01:27,809 INFO:   Starting stage: EVALUATION
2022-11-18 03:01:27,933 INFO:   Done with stage: EVALUATION
2022-11-18 03:01:27,933 INFO:   Leaving out SEQ value Fold_5
2022-11-18 03:01:27,946 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:01:27,946 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:01:28,613 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:01:28,613 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:01:28,682 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:01:28,682 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:01:28,682 INFO:     No hyperparam tuning for this model
2022-11-18 03:01:28,683 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:01:28,683 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:01:28,683 INFO:     None feature selector for col prot
2022-11-18 03:01:28,684 INFO:     None feature selector for col prot
2022-11-18 03:01:28,684 INFO:     None feature selector for col prot
2022-11-18 03:01:28,684 INFO:     None feature selector for col chem
2022-11-18 03:01:28,684 INFO:     None feature selector for col chem
2022-11-18 03:01:28,685 INFO:     None feature selector for col chem
2022-11-18 03:01:28,685 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:01:28,685 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:01:28,686 INFO:     Number of params in model 168571
2022-11-18 03:01:28,690 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:01:28,690 INFO:   Starting stage: TRAINING
2022-11-18 03:01:28,747 INFO:     Val loss before train {'Reaction outcome loss': 1.0199504630132155, 'Total loss': 1.0199504630132155}
2022-11-18 03:01:28,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:28,748 INFO:     Epoch: 0
2022-11-18 03:01:29,533 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.826541697437113, 'Total loss': 0.826541697437113} | train loss {'Reaction outcome loss': 0.87825541481798, 'Total loss': 0.87825541481798}
2022-11-18 03:01:29,533 INFO:     Found new best model at epoch 0
2022-11-18 03:01:29,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:29,534 INFO:     Epoch: 1
2022-11-18 03:01:30,312 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8587629612196576, 'Total loss': 0.8587629612196576} | train loss {'Reaction outcome loss': 0.8515256990787954, 'Total loss': 0.8515256990787954}
2022-11-18 03:01:30,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:30,312 INFO:     Epoch: 2
2022-11-18 03:01:31,098 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8343993560834364, 'Total loss': 0.8343993560834364} | train loss {'Reaction outcome loss': 0.8426830888035809, 'Total loss': 0.8426830888035809}
2022-11-18 03:01:31,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:31,098 INFO:     Epoch: 3
2022-11-18 03:01:31,869 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8293388902463696, 'Total loss': 0.8293388902463696} | train loss {'Reaction outcome loss': 0.8430539165672503, 'Total loss': 0.8430539165672503}
2022-11-18 03:01:31,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:31,869 INFO:     Epoch: 4
2022-11-18 03:01:32,648 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8148680844090201, 'Total loss': 0.8148680844090201} | train loss {'Reaction outcome loss': 0.8415816180136523, 'Total loss': 0.8415816180136523}
2022-11-18 03:01:32,649 INFO:     Found new best model at epoch 4
2022-11-18 03:01:32,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:32,650 INFO:     Epoch: 5
2022-11-18 03:01:33,406 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8014109307392077, 'Total loss': 0.8014109307392077} | train loss {'Reaction outcome loss': 0.8297209875424382, 'Total loss': 0.8297209875424382}
2022-11-18 03:01:33,407 INFO:     Found new best model at epoch 5
2022-11-18 03:01:33,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:33,408 INFO:     Epoch: 6
2022-11-18 03:01:34,197 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8316824571652845, 'Total loss': 0.8316824571652845} | train loss {'Reaction outcome loss': 0.8323862279354319, 'Total loss': 0.8323862279354319}
2022-11-18 03:01:34,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:34,198 INFO:     Epoch: 7
2022-11-18 03:01:34,994 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8370191651311788, 'Total loss': 0.8370191651311788} | train loss {'Reaction outcome loss': 0.8267076874551503, 'Total loss': 0.8267076874551503}
2022-11-18 03:01:34,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:34,994 INFO:     Epoch: 8
2022-11-18 03:01:35,787 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8105313208970156, 'Total loss': 0.8105313208970156} | train loss {'Reaction outcome loss': 0.8317334084858296, 'Total loss': 0.8317334084858296}
2022-11-18 03:01:35,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:35,788 INFO:     Epoch: 9
2022-11-18 03:01:36,570 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8101797930218957, 'Total loss': 0.8101797930218957} | train loss {'Reaction outcome loss': 0.8311131597771818, 'Total loss': 0.8311131597771818}
2022-11-18 03:01:36,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:36,570 INFO:     Epoch: 10
2022-11-18 03:01:37,365 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8090940388766202, 'Total loss': 0.8090940388766202} | train loss {'Reaction outcome loss': 0.8319101929664612, 'Total loss': 0.8319101929664612}
2022-11-18 03:01:37,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:37,366 INFO:     Epoch: 11
2022-11-18 03:01:38,140 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.836230341006409, 'Total loss': 0.836230341006409} | train loss {'Reaction outcome loss': 0.8267573348665045, 'Total loss': 0.8267573348665045}
2022-11-18 03:01:38,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:38,140 INFO:     Epoch: 12
2022-11-18 03:01:38,919 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8048764995553277, 'Total loss': 0.8048764995553277} | train loss {'Reaction outcome loss': 0.8207429196187842, 'Total loss': 0.8207429196187842}
2022-11-18 03:01:38,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:38,920 INFO:     Epoch: 13
2022-11-18 03:01:39,726 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.843999752944166, 'Total loss': 0.843999752944166} | train loss {'Reaction outcome loss': 0.8246360073688059, 'Total loss': 0.8246360073688059}
2022-11-18 03:01:39,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:39,726 INFO:     Epoch: 14
2022-11-18 03:01:40,503 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8036176243966277, 'Total loss': 0.8036176243966277} | train loss {'Reaction outcome loss': 0.8290385151440315, 'Total loss': 0.8290385151440315}
2022-11-18 03:01:40,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:40,503 INFO:     Epoch: 15
2022-11-18 03:01:41,301 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8058082949031483, 'Total loss': 0.8058082949031483} | train loss {'Reaction outcome loss': 0.8230436066022286, 'Total loss': 0.8230436066022286}
2022-11-18 03:01:41,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:41,302 INFO:     Epoch: 16
2022-11-18 03:01:42,077 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8123727210543372, 'Total loss': 0.8123727210543372} | train loss {'Reaction outcome loss': 0.8188384855203783, 'Total loss': 0.8188384855203783}
2022-11-18 03:01:42,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:42,077 INFO:     Epoch: 17
2022-11-18 03:01:42,848 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8099426234310324, 'Total loss': 0.8099426234310324} | train loss {'Reaction outcome loss': 0.817493018336021, 'Total loss': 0.817493018336021}
2022-11-18 03:01:42,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:42,848 INFO:     Epoch: 18
2022-11-18 03:01:43,603 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.825849863615903, 'Total loss': 0.825849863615903} | train loss {'Reaction outcome loss': 0.8163891248857444, 'Total loss': 0.8163891248857444}
2022-11-18 03:01:43,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:43,604 INFO:     Epoch: 19
2022-11-18 03:01:44,380 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8053901872851632, 'Total loss': 0.8053901872851632} | train loss {'Reaction outcome loss': 0.8167002782949552, 'Total loss': 0.8167002782949552}
2022-11-18 03:01:44,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:44,381 INFO:     Epoch: 20
2022-11-18 03:01:45,168 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8078874539245259, 'Total loss': 0.8078874539245259} | train loss {'Reaction outcome loss': 0.8243987893286021, 'Total loss': 0.8243987893286021}
2022-11-18 03:01:45,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:45,168 INFO:     Epoch: 21
2022-11-18 03:01:45,959 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.831881083548069, 'Total loss': 0.831881083548069} | train loss {'Reaction outcome loss': 0.8248207338667108, 'Total loss': 0.8248207338667108}
2022-11-18 03:01:45,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:45,959 INFO:     Epoch: 22
2022-11-18 03:01:46,749 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7884504453025081, 'Total loss': 0.7884504453025081} | train loss {'Reaction outcome loss': 0.8173844325337333, 'Total loss': 0.8173844325337333}
2022-11-18 03:01:46,750 INFO:     Found new best model at epoch 22
2022-11-18 03:01:46,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:46,751 INFO:     Epoch: 23
2022-11-18 03:01:47,526 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.818149668249217, 'Total loss': 0.818149668249217} | train loss {'Reaction outcome loss': 0.8224219016217993, 'Total loss': 0.8224219016217993}
2022-11-18 03:01:47,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:47,527 INFO:     Epoch: 24
2022-11-18 03:01:48,306 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8229233439673077, 'Total loss': 0.8229233439673077} | train loss {'Reaction outcome loss': 0.8172966693094385, 'Total loss': 0.8172966693094385}
2022-11-18 03:01:48,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:48,306 INFO:     Epoch: 25
2022-11-18 03:01:49,083 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7969226864251223, 'Total loss': 0.7969226864251223} | train loss {'Reaction outcome loss': 0.8194758089689108, 'Total loss': 0.8194758089689108}
2022-11-18 03:01:49,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:49,083 INFO:     Epoch: 26
2022-11-18 03:01:49,841 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8153491331772371, 'Total loss': 0.8153491331772371} | train loss {'Reaction outcome loss': 0.8185839081100124, 'Total loss': 0.8185839081100124}
2022-11-18 03:01:49,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:49,841 INFO:     Epoch: 27
2022-11-18 03:01:50,604 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8238658823750236, 'Total loss': 0.8238658823750236} | train loss {'Reaction outcome loss': 0.8207413784646795, 'Total loss': 0.8207413784646795}
2022-11-18 03:01:50,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:50,604 INFO:     Epoch: 28
2022-11-18 03:01:51,381 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.821198204701597, 'Total loss': 0.821198204701597} | train loss {'Reaction outcome loss': 0.8196676501453768, 'Total loss': 0.8196676501453768}
2022-11-18 03:01:51,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:51,381 INFO:     Epoch: 29
2022-11-18 03:01:52,172 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8144017478281801, 'Total loss': 0.8144017478281801} | train loss {'Reaction outcome loss': 0.8175482057366776, 'Total loss': 0.8175482057366776}
2022-11-18 03:01:52,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:52,172 INFO:     Epoch: 30
2022-11-18 03:01:52,942 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8185958313671026, 'Total loss': 0.8185958313671026} | train loss {'Reaction outcome loss': 0.8153777326106543, 'Total loss': 0.8153777326106543}
2022-11-18 03:01:52,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:52,943 INFO:     Epoch: 31
2022-11-18 03:01:53,736 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7988772581924092, 'Total loss': 0.7988772581924092} | train loss {'Reaction outcome loss': 0.8216591887628502, 'Total loss': 0.8216591887628502}
2022-11-18 03:01:53,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:53,736 INFO:     Epoch: 32
2022-11-18 03:01:54,517 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7919289916753769, 'Total loss': 0.7919289916753769} | train loss {'Reaction outcome loss': 0.817199058619588, 'Total loss': 0.817199058619588}
2022-11-18 03:01:54,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:54,517 INFO:     Epoch: 33
2022-11-18 03:01:55,289 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.803649823773991, 'Total loss': 0.803649823773991} | train loss {'Reaction outcome loss': 0.8262611173907755, 'Total loss': 0.8262611173907755}
2022-11-18 03:01:55,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:55,289 INFO:     Epoch: 34
2022-11-18 03:01:56,071 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8206637853925879, 'Total loss': 0.8206637853925879} | train loss {'Reaction outcome loss': 0.8219335351878332, 'Total loss': 0.8219335351878332}
2022-11-18 03:01:56,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:56,071 INFO:     Epoch: 35
2022-11-18 03:01:56,841 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7982468422163617, 'Total loss': 0.7982468422163617} | train loss {'Reaction outcome loss': 0.8140142829372332, 'Total loss': 0.8140142829372332}
2022-11-18 03:01:56,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:56,841 INFO:     Epoch: 36
2022-11-18 03:01:57,619 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7988402484492823, 'Total loss': 0.7988402484492823} | train loss {'Reaction outcome loss': 0.8218739549158073, 'Total loss': 0.8218739549158073}
2022-11-18 03:01:57,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:57,619 INFO:     Epoch: 37
2022-11-18 03:01:58,402 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8076715943488207, 'Total loss': 0.8076715943488207} | train loss {'Reaction outcome loss': 0.8262478438948813, 'Total loss': 0.8262478438948813}
2022-11-18 03:01:58,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:58,402 INFO:     Epoch: 38
2022-11-18 03:01:59,195 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8458452197638425, 'Total loss': 0.8458452197638425} | train loss {'Reaction outcome loss': 0.8180361779836508, 'Total loss': 0.8180361779836508}
2022-11-18 03:01:59,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:59,195 INFO:     Epoch: 39
2022-11-18 03:01:59,964 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8252497566017237, 'Total loss': 0.8252497566017237} | train loss {'Reaction outcome loss': 0.8216646364343311, 'Total loss': 0.8216646364343311}
2022-11-18 03:01:59,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:01:59,965 INFO:     Epoch: 40
2022-11-18 03:02:00,741 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8296492411331697, 'Total loss': 0.8296492411331697} | train loss {'Reaction outcome loss': 0.8189508978895813, 'Total loss': 0.8189508978895813}
2022-11-18 03:02:00,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:00,741 INFO:     Epoch: 41
2022-11-18 03:02:01,530 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8085709674791857, 'Total loss': 0.8085709674791857} | train loss {'Reaction outcome loss': 0.8119497331771773, 'Total loss': 0.8119497331771773}
2022-11-18 03:02:01,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:01,530 INFO:     Epoch: 42
2022-11-18 03:02:02,309 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7841932285915721, 'Total loss': 0.7841932285915721} | train loss {'Reaction outcome loss': 0.8190042258274217, 'Total loss': 0.8190042258274217}
2022-11-18 03:02:02,309 INFO:     Found new best model at epoch 42
2022-11-18 03:02:02,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:02,310 INFO:     Epoch: 43
2022-11-18 03:02:03,098 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7867865338921547, 'Total loss': 0.7867865338921547} | train loss {'Reaction outcome loss': 0.8139163096424057, 'Total loss': 0.8139163096424057}
2022-11-18 03:02:03,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:03,099 INFO:     Epoch: 44
2022-11-18 03:02:03,879 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7856736305085096, 'Total loss': 0.7856736305085096} | train loss {'Reaction outcome loss': 0.822790080357177, 'Total loss': 0.822790080357177}
2022-11-18 03:02:03,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:03,879 INFO:     Epoch: 45
2022-11-18 03:02:04,663 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8197158331220801, 'Total loss': 0.8197158331220801} | train loss {'Reaction outcome loss': 0.8229525281108825, 'Total loss': 0.8229525281108825}
2022-11-18 03:02:04,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:04,663 INFO:     Epoch: 46
2022-11-18 03:02:05,449 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8062069849534468, 'Total loss': 0.8062069849534468} | train loss {'Reaction outcome loss': 0.8189785422583823, 'Total loss': 0.8189785422583823}
2022-11-18 03:02:05,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:05,450 INFO:     Epoch: 47
2022-11-18 03:02:06,245 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8035915101116354, 'Total loss': 0.8035915101116354} | train loss {'Reaction outcome loss': 0.8155271684833867, 'Total loss': 0.8155271684833867}
2022-11-18 03:02:06,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:06,245 INFO:     Epoch: 48
2022-11-18 03:02:07,023 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.807724497535012, 'Total loss': 0.807724497535012} | train loss {'Reaction outcome loss': 0.8128437426408776, 'Total loss': 0.8128437426408776}
2022-11-18 03:02:07,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:07,023 INFO:     Epoch: 49
2022-11-18 03:02:07,797 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8275314921682532, 'Total loss': 0.8275314921682532} | train loss {'Reaction outcome loss': 0.8262721846702128, 'Total loss': 0.8262721846702128}
2022-11-18 03:02:07,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:07,797 INFO:     Epoch: 50
2022-11-18 03:02:08,582 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8065059252760627, 'Total loss': 0.8065059252760627} | train loss {'Reaction outcome loss': 0.8187824651478273, 'Total loss': 0.8187824651478273}
2022-11-18 03:02:08,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:08,583 INFO:     Epoch: 51
2022-11-18 03:02:09,352 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7832066274502061, 'Total loss': 0.7832066274502061} | train loss {'Reaction outcome loss': 0.8117581876183328, 'Total loss': 0.8117581876183328}
2022-11-18 03:02:09,352 INFO:     Found new best model at epoch 51
2022-11-18 03:02:09,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:09,353 INFO:     Epoch: 52
2022-11-18 03:02:10,115 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8383887809785929, 'Total loss': 0.8383887809785929} | train loss {'Reaction outcome loss': 0.812830298535737, 'Total loss': 0.812830298535737}
2022-11-18 03:02:10,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:10,116 INFO:     Epoch: 53
2022-11-18 03:02:10,927 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8326435258442705, 'Total loss': 0.8326435258442705} | train loss {'Reaction outcome loss': 0.8144946651691608, 'Total loss': 0.8144946651691608}
2022-11-18 03:02:10,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:10,927 INFO:     Epoch: 54
2022-11-18 03:02:11,715 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8009777949614958, 'Total loss': 0.8009777949614958} | train loss {'Reaction outcome loss': 0.8137683641572713, 'Total loss': 0.8137683641572713}
2022-11-18 03:02:11,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:11,715 INFO:     Epoch: 55
2022-11-18 03:02:12,482 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7955773201855746, 'Total loss': 0.7955773201855746} | train loss {'Reaction outcome loss': 0.8188669442647865, 'Total loss': 0.8188669442647865}
2022-11-18 03:02:12,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:12,482 INFO:     Epoch: 56
2022-11-18 03:02:13,299 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8140072680332444, 'Total loss': 0.8140072680332444} | train loss {'Reaction outcome loss': 0.8175427758018015, 'Total loss': 0.8175427758018015}
2022-11-18 03:02:13,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:13,299 INFO:     Epoch: 57
2022-11-18 03:02:14,080 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8154657151211392, 'Total loss': 0.8154657151211392} | train loss {'Reaction outcome loss': 0.8146545537087598, 'Total loss': 0.8146545537087598}
2022-11-18 03:02:14,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:14,080 INFO:     Epoch: 58
2022-11-18 03:02:14,841 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8176405998793516, 'Total loss': 0.8176405998793516} | train loss {'Reaction outcome loss': 0.8107758717769794, 'Total loss': 0.8107758717769794}
2022-11-18 03:02:14,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:14,842 INFO:     Epoch: 59
2022-11-18 03:02:15,656 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.83480489524928, 'Total loss': 0.83480489524928} | train loss {'Reaction outcome loss': 0.8173059290237272, 'Total loss': 0.8173059290237272}
2022-11-18 03:02:15,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:15,656 INFO:     Epoch: 60
2022-11-18 03:02:16,449 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.825882613658905, 'Total loss': 0.825882613658905} | train loss {'Reaction outcome loss': 0.8155362375593378, 'Total loss': 0.8155362375593378}
2022-11-18 03:02:16,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:16,449 INFO:     Epoch: 61
2022-11-18 03:02:17,226 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7961236881938848, 'Total loss': 0.7961236881938848} | train loss {'Reaction outcome loss': 0.8261030360166481, 'Total loss': 0.8261030360166481}
2022-11-18 03:02:17,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:17,226 INFO:     Epoch: 62
2022-11-18 03:02:18,003 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8298066502267664, 'Total loss': 0.8298066502267664} | train loss {'Reaction outcome loss': 0.8120811859123137, 'Total loss': 0.8120811859123137}
2022-11-18 03:02:18,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:18,005 INFO:     Epoch: 63
2022-11-18 03:02:18,793 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7984959984367545, 'Total loss': 0.7984959984367545} | train loss {'Reaction outcome loss': 0.8176617634441206, 'Total loss': 0.8176617634441206}
2022-11-18 03:02:18,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:18,793 INFO:     Epoch: 64
2022-11-18 03:02:19,565 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7907187071713534, 'Total loss': 0.7907187071713534} | train loss {'Reaction outcome loss': 0.8101446557382823, 'Total loss': 0.8101446557382823}
2022-11-18 03:02:19,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:19,565 INFO:     Epoch: 65
2022-11-18 03:02:20,346 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7951165342872794, 'Total loss': 0.7951165342872794} | train loss {'Reaction outcome loss': 0.8126062648257746, 'Total loss': 0.8126062648257746}
2022-11-18 03:02:20,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:20,347 INFO:     Epoch: 66
2022-11-18 03:02:21,127 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7907793772491541, 'Total loss': 0.7907793772491541} | train loss {'Reaction outcome loss': 0.8181750525829763, 'Total loss': 0.8181750525829763}
2022-11-18 03:02:21,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:21,127 INFO:     Epoch: 67
2022-11-18 03:02:21,924 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7927235791629011, 'Total loss': 0.7927235791629011} | train loss {'Reaction outcome loss': 0.8151267479788437, 'Total loss': 0.8151267479788437}
2022-11-18 03:02:21,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:21,924 INFO:     Epoch: 68
2022-11-18 03:02:22,714 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8125801215117628, 'Total loss': 0.8125801215117628} | train loss {'Reaction outcome loss': 0.809784439049269, 'Total loss': 0.809784439049269}
2022-11-18 03:02:22,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:22,714 INFO:     Epoch: 69
2022-11-18 03:02:23,483 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8125354248014364, 'Total loss': 0.8125354248014364} | train loss {'Reaction outcome loss': 0.8096771689682354, 'Total loss': 0.8096771689682354}
2022-11-18 03:02:23,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:23,484 INFO:     Epoch: 70
2022-11-18 03:02:24,273 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7987426885149695, 'Total loss': 0.7987426885149695} | train loss {'Reaction outcome loss': 0.8132908115925094, 'Total loss': 0.8132908115925094}
2022-11-18 03:02:24,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:24,274 INFO:     Epoch: 71
2022-11-18 03:02:25,031 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8106230998581107, 'Total loss': 0.8106230998581107} | train loss {'Reaction outcome loss': 0.8161832451337745, 'Total loss': 0.8161832451337745}
2022-11-18 03:02:25,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:25,032 INFO:     Epoch: 72
2022-11-18 03:02:25,803 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.804970848289403, 'Total loss': 0.804970848289403} | train loss {'Reaction outcome loss': 0.8215546001065598, 'Total loss': 0.8215546001065598}
2022-11-18 03:02:25,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:25,804 INFO:     Epoch: 73
2022-11-18 03:02:26,611 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8046851015903733, 'Total loss': 0.8046851015903733} | train loss {'Reaction outcome loss': 0.8175571441409076, 'Total loss': 0.8175571441409076}
2022-11-18 03:02:26,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:26,611 INFO:     Epoch: 74
2022-11-18 03:02:27,402 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7884423251856457, 'Total loss': 0.7884423251856457} | train loss {'Reaction outcome loss': 0.8227300005644439, 'Total loss': 0.8227300005644439}
2022-11-18 03:02:27,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:27,402 INFO:     Epoch: 75
2022-11-18 03:02:28,211 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7921990941871296, 'Total loss': 0.7921990941871296} | train loss {'Reaction outcome loss': 0.8099845111490744, 'Total loss': 0.8099845111490744}
2022-11-18 03:02:28,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:28,211 INFO:     Epoch: 76
2022-11-18 03:02:29,012 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8087280412966554, 'Total loss': 0.8087280412966554} | train loss {'Reaction outcome loss': 0.8111776280017035, 'Total loss': 0.8111776280017035}
2022-11-18 03:02:29,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:29,013 INFO:     Epoch: 77
2022-11-18 03:02:29,790 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7957655963572589, 'Total loss': 0.7957655963572589} | train loss {'Reaction outcome loss': 0.8121341380332163, 'Total loss': 0.8121341380332163}
2022-11-18 03:02:29,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:29,790 INFO:     Epoch: 78
2022-11-18 03:02:30,559 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7812834388830445, 'Total loss': 0.7812834388830445} | train loss {'Reaction outcome loss': 0.8169942802263175, 'Total loss': 0.8169942802263175}
2022-11-18 03:02:30,559 INFO:     Found new best model at epoch 78
2022-11-18 03:02:30,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:30,560 INFO:     Epoch: 79
2022-11-18 03:02:31,362 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8172508125955408, 'Total loss': 0.8172508125955408} | train loss {'Reaction outcome loss': 0.8159194201804124, 'Total loss': 0.8159194201804124}
2022-11-18 03:02:31,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:31,362 INFO:     Epoch: 80
2022-11-18 03:02:32,144 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8372167267582633, 'Total loss': 0.8372167267582633} | train loss {'Reaction outcome loss': 0.8161910701135875, 'Total loss': 0.8161910701135875}
2022-11-18 03:02:32,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:32,144 INFO:     Epoch: 81
2022-11-18 03:02:32,930 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8445013273846019, 'Total loss': 0.8445013273846019} | train loss {'Reaction outcome loss': 0.8225129898260479, 'Total loss': 0.8225129898260479}
2022-11-18 03:02:32,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:32,930 INFO:     Epoch: 82
2022-11-18 03:02:33,728 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8121529336680066, 'Total loss': 0.8121529336680066} | train loss {'Reaction outcome loss': 0.81698309120379, 'Total loss': 0.81698309120379}
2022-11-18 03:02:33,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:33,729 INFO:     Epoch: 83
2022-11-18 03:02:34,534 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8197763514789668, 'Total loss': 0.8197763514789668} | train loss {'Reaction outcome loss': 0.8143578912263457, 'Total loss': 0.8143578912263457}
2022-11-18 03:02:34,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:34,535 INFO:     Epoch: 84
2022-11-18 03:02:35,308 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8073116371577437, 'Total loss': 0.8073116371577437} | train loss {'Reaction outcome loss': 0.8168523520351905, 'Total loss': 0.8168523520351905}
2022-11-18 03:02:35,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:35,309 INFO:     Epoch: 85
2022-11-18 03:02:36,082 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8118280348452654, 'Total loss': 0.8118280348452654} | train loss {'Reaction outcome loss': 0.8186026509956792, 'Total loss': 0.8186026509956792}
2022-11-18 03:02:36,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:36,082 INFO:     Epoch: 86
2022-11-18 03:02:36,876 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7930253330956806, 'Total loss': 0.7930253330956806} | train loss {'Reaction outcome loss': 0.8155619195598339, 'Total loss': 0.8155619195598339}
2022-11-18 03:02:36,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:36,877 INFO:     Epoch: 87
2022-11-18 03:02:37,646 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7867270017212088, 'Total loss': 0.7867270017212088} | train loss {'Reaction outcome loss': 0.8195680832331963, 'Total loss': 0.8195680832331963}
2022-11-18 03:02:37,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:37,646 INFO:     Epoch: 88
2022-11-18 03:02:38,403 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8183789605444128, 'Total loss': 0.8183789605444128} | train loss {'Reaction outcome loss': 0.8217499397302929, 'Total loss': 0.8217499397302929}
2022-11-18 03:02:38,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:38,404 INFO:     Epoch: 89
2022-11-18 03:02:39,187 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7945918826894327, 'Total loss': 0.7945918826894327} | train loss {'Reaction outcome loss': 0.8178477742170033, 'Total loss': 0.8178477742170033}
2022-11-18 03:02:39,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:39,187 INFO:     Epoch: 90
2022-11-18 03:02:39,949 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8055884472348473, 'Total loss': 0.8055884472348473} | train loss {'Reaction outcome loss': 0.811922485649827, 'Total loss': 0.811922485649827}
2022-11-18 03:02:39,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:39,949 INFO:     Epoch: 91
2022-11-18 03:02:40,749 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8141075061126188, 'Total loss': 0.8141075061126188} | train loss {'Reaction outcome loss': 0.8186197167767687, 'Total loss': 0.8186197167767687}
2022-11-18 03:02:40,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:40,749 INFO:     Epoch: 92
2022-11-18 03:02:41,520 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.819858855144544, 'Total loss': 0.819858855144544} | train loss {'Reaction outcome loss': 0.8186632602320991, 'Total loss': 0.8186632602320991}
2022-11-18 03:02:41,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:41,520 INFO:     Epoch: 93
2022-11-18 03:02:42,316 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7977076931433245, 'Total loss': 0.7977076931433245} | train loss {'Reaction outcome loss': 0.8144709256134535, 'Total loss': 0.8144709256134535}
2022-11-18 03:02:42,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:42,316 INFO:     Epoch: 94
2022-11-18 03:02:43,097 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8027105223048817, 'Total loss': 0.8027105223048817} | train loss {'Reaction outcome loss': 0.8159657698652523, 'Total loss': 0.8159657698652523}
2022-11-18 03:02:43,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:43,097 INFO:     Epoch: 95
2022-11-18 03:02:43,890 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.795698421922597, 'Total loss': 0.795698421922597} | train loss {'Reaction outcome loss': 0.8215279999049568, 'Total loss': 0.8215279999049568}
2022-11-18 03:02:43,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:43,890 INFO:     Epoch: 96
2022-11-18 03:02:44,671 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8063058853149414, 'Total loss': 0.8063058853149414} | train loss {'Reaction outcome loss': 0.81528108563983, 'Total loss': 0.81528108563983}
2022-11-18 03:02:44,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:44,671 INFO:     Epoch: 97
2022-11-18 03:02:45,462 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8234908269210295, 'Total loss': 0.8234908269210295} | train loss {'Reaction outcome loss': 0.8163092473016577, 'Total loss': 0.8163092473016577}
2022-11-18 03:02:45,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:45,462 INFO:     Epoch: 98
2022-11-18 03:02:46,245 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.816021129488945, 'Total loss': 0.816021129488945} | train loss {'Reaction outcome loss': 0.820146699183383, 'Total loss': 0.820146699183383}
2022-11-18 03:02:46,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:46,245 INFO:     Epoch: 99
2022-11-18 03:02:47,017 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7873448533090678, 'Total loss': 0.7873448533090678} | train loss {'Reaction outcome loss': 0.8056944906108292, 'Total loss': 0.8056944906108292}
2022-11-18 03:02:47,017 INFO:     Best model found after epoch 79 of 100.
2022-11-18 03:02:47,018 INFO:   Done with stage: TRAINING
2022-11-18 03:02:47,018 INFO:   Starting stage: EVALUATION
2022-11-18 03:02:47,140 INFO:   Done with stage: EVALUATION
2022-11-18 03:02:47,140 INFO:   Leaving out SEQ value Fold_6
2022-11-18 03:02:47,153 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:02:47,153 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:02:47,827 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:02:47,828 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:02:47,897 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:02:47,898 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:02:47,898 INFO:     No hyperparam tuning for this model
2022-11-18 03:02:47,898 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:02:47,898 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:02:47,899 INFO:     None feature selector for col prot
2022-11-18 03:02:47,899 INFO:     None feature selector for col prot
2022-11-18 03:02:47,899 INFO:     None feature selector for col prot
2022-11-18 03:02:47,900 INFO:     None feature selector for col chem
2022-11-18 03:02:47,900 INFO:     None feature selector for col chem
2022-11-18 03:02:47,900 INFO:     None feature selector for col chem
2022-11-18 03:02:47,900 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:02:47,900 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:02:47,902 INFO:     Number of params in model 168571
2022-11-18 03:02:47,905 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:02:47,905 INFO:   Starting stage: TRAINING
2022-11-18 03:02:47,971 INFO:     Val loss before train {'Reaction outcome loss': 1.0108698132363232, 'Total loss': 1.0108698132363232}
2022-11-18 03:02:47,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:47,972 INFO:     Epoch: 0
2022-11-18 03:02:48,765 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8652699704874646, 'Total loss': 0.8652699704874646} | train loss {'Reaction outcome loss': 0.8751213877431808, 'Total loss': 0.8751213877431808}
2022-11-18 03:02:48,766 INFO:     Found new best model at epoch 0
2022-11-18 03:02:48,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:48,767 INFO:     Epoch: 1
2022-11-18 03:02:49,560 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8250952180136334, 'Total loss': 0.8250952180136334} | train loss {'Reaction outcome loss': 0.8514547513857964, 'Total loss': 0.8514547513857964}
2022-11-18 03:02:49,560 INFO:     Found new best model at epoch 1
2022-11-18 03:02:49,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:49,561 INFO:     Epoch: 2
2022-11-18 03:02:50,362 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8520362092690035, 'Total loss': 0.8520362092690035} | train loss {'Reaction outcome loss': 0.8428045568927642, 'Total loss': 0.8428045568927642}
2022-11-18 03:02:50,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:50,362 INFO:     Epoch: 3
2022-11-18 03:02:51,148 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8399293815547769, 'Total loss': 0.8399293815547769} | train loss {'Reaction outcome loss': 0.8472219726010677, 'Total loss': 0.8472219726010677}
2022-11-18 03:02:51,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:51,148 INFO:     Epoch: 4
2022-11-18 03:02:51,944 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.821876355192878, 'Total loss': 0.821876355192878} | train loss {'Reaction outcome loss': 0.8443585493631901, 'Total loss': 0.8443585493631901}
2022-11-18 03:02:51,944 INFO:     Found new best model at epoch 4
2022-11-18 03:02:51,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:51,945 INFO:     Epoch: 5
2022-11-18 03:02:52,733 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8238537907600403, 'Total loss': 0.8238537907600403} | train loss {'Reaction outcome loss': 0.8333449783104081, 'Total loss': 0.8333449783104081}
2022-11-18 03:02:52,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:52,733 INFO:     Epoch: 6
2022-11-18 03:02:53,521 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8284805146130648, 'Total loss': 0.8284805146130648} | train loss {'Reaction outcome loss': 0.8366938410026412, 'Total loss': 0.8366938410026412}
2022-11-18 03:02:53,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:53,521 INFO:     Epoch: 7
2022-11-18 03:02:54,307 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8217428346926515, 'Total loss': 0.8217428346926515} | train loss {'Reaction outcome loss': 0.8417998623223074, 'Total loss': 0.8417998623223074}
2022-11-18 03:02:54,307 INFO:     Found new best model at epoch 7
2022-11-18 03:02:54,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:54,308 INFO:     Epoch: 8
2022-11-18 03:02:55,086 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8118617236614227, 'Total loss': 0.8118617236614227} | train loss {'Reaction outcome loss': 0.8311974634566615, 'Total loss': 0.8311974634566615}
2022-11-18 03:02:55,087 INFO:     Found new best model at epoch 8
2022-11-18 03:02:55,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:55,088 INFO:     Epoch: 9
2022-11-18 03:02:55,876 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8379358771172437, 'Total loss': 0.8379358771172437} | train loss {'Reaction outcome loss': 0.8285859139455903, 'Total loss': 0.8285859139455903}
2022-11-18 03:02:55,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:55,876 INFO:     Epoch: 10
2022-11-18 03:02:56,691 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8273752413012765, 'Total loss': 0.8273752413012765} | train loss {'Reaction outcome loss': 0.8287913576970177, 'Total loss': 0.8287913576970177}
2022-11-18 03:02:56,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:56,691 INFO:     Epoch: 11
2022-11-18 03:02:57,480 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8351036134091291, 'Total loss': 0.8351036134091291} | train loss {'Reaction outcome loss': 0.8292317057569181, 'Total loss': 0.8292317057569181}
2022-11-18 03:02:57,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:57,480 INFO:     Epoch: 12
2022-11-18 03:02:58,245 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8320041556249965, 'Total loss': 0.8320041556249965} | train loss {'Reaction outcome loss': 0.8271666038180551, 'Total loss': 0.8271666038180551}
2022-11-18 03:02:58,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:58,245 INFO:     Epoch: 13
2022-11-18 03:02:59,017 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.825566830960187, 'Total loss': 0.825566830960187} | train loss {'Reaction outcome loss': 0.828628386340795, 'Total loss': 0.828628386340795}
2022-11-18 03:02:59,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:59,018 INFO:     Epoch: 14
2022-11-18 03:02:59,838 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8328824598680843, 'Total loss': 0.8328824598680843} | train loss {'Reaction outcome loss': 0.8225516031586355, 'Total loss': 0.8225516031586355}
2022-11-18 03:02:59,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:02:59,838 INFO:     Epoch: 15
2022-11-18 03:03:00,603 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8194156234914606, 'Total loss': 0.8194156234914606} | train loss {'Reaction outcome loss': 0.8294743367981526, 'Total loss': 0.8294743367981526}
2022-11-18 03:03:00,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:00,603 INFO:     Epoch: 16
2022-11-18 03:03:01,376 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8186850642616098, 'Total loss': 0.8186850642616098} | train loss {'Reaction outcome loss': 0.8271454052338677, 'Total loss': 0.8271454052338677}
2022-11-18 03:03:01,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:01,377 INFO:     Epoch: 17
2022-11-18 03:03:02,160 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8129105615344915, 'Total loss': 0.8129105615344915} | train loss {'Reaction outcome loss': 0.824717418440888, 'Total loss': 0.824717418440888}
2022-11-18 03:03:02,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:02,160 INFO:     Epoch: 18
2022-11-18 03:03:02,931 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8275655155832117, 'Total loss': 0.8275655155832117} | train loss {'Reaction outcome loss': 0.8308177186596778, 'Total loss': 0.8308177186596778}
2022-11-18 03:03:02,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:02,931 INFO:     Epoch: 19
2022-11-18 03:03:03,694 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8116419518535788, 'Total loss': 0.8116419518535788} | train loss {'Reaction outcome loss': 0.8188354523191529, 'Total loss': 0.8188354523191529}
2022-11-18 03:03:03,694 INFO:     Found new best model at epoch 19
2022-11-18 03:03:03,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:03,695 INFO:     Epoch: 20
2022-11-18 03:03:04,452 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8385352824221958, 'Total loss': 0.8385352824221958} | train loss {'Reaction outcome loss': 0.8265141981743998, 'Total loss': 0.8265141981743998}
2022-11-18 03:03:04,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:04,453 INFO:     Epoch: 21
2022-11-18 03:03:05,253 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8132946586067026, 'Total loss': 0.8132946586067026} | train loss {'Reaction outcome loss': 0.8276789657050564, 'Total loss': 0.8276789657050564}
2022-11-18 03:03:05,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:05,254 INFO:     Epoch: 22
2022-11-18 03:03:06,035 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8301420509815216, 'Total loss': 0.8301420509815216} | train loss {'Reaction outcome loss': 0.8228730832136446, 'Total loss': 0.8228730832136446}
2022-11-18 03:03:06,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:06,035 INFO:     Epoch: 23
2022-11-18 03:03:06,813 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8207031481645324, 'Total loss': 0.8207031481645324} | train loss {'Reaction outcome loss': 0.8213926745999244, 'Total loss': 0.8213926745999244}
2022-11-18 03:03:06,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:06,813 INFO:     Epoch: 24
2022-11-18 03:03:07,571 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8302711458368734, 'Total loss': 0.8302711458368734} | train loss {'Reaction outcome loss': 0.8222544442021078, 'Total loss': 0.8222544442021078}
2022-11-18 03:03:07,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:07,572 INFO:     Epoch: 25
2022-11-18 03:03:08,356 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8083300299265168, 'Total loss': 0.8083300299265168} | train loss {'Reaction outcome loss': 0.8202219597033916, 'Total loss': 0.8202219597033916}
2022-11-18 03:03:08,356 INFO:     Found new best model at epoch 25
2022-11-18 03:03:08,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:08,357 INFO:     Epoch: 26
2022-11-18 03:03:09,133 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8251866860823198, 'Total loss': 0.8251866860823198} | train loss {'Reaction outcome loss': 0.8166318969620813, 'Total loss': 0.8166318969620813}
2022-11-18 03:03:09,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:09,134 INFO:     Epoch: 27
2022-11-18 03:03:09,914 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8209611827676947, 'Total loss': 0.8209611827676947} | train loss {'Reaction outcome loss': 0.8230491451198055, 'Total loss': 0.8230491451198055}
2022-11-18 03:03:09,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:09,915 INFO:     Epoch: 28
2022-11-18 03:03:10,687 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8061750497330319, 'Total loss': 0.8061750497330319} | train loss {'Reaction outcome loss': 0.8241421922801002, 'Total loss': 0.8241421922801002}
2022-11-18 03:03:10,687 INFO:     Found new best model at epoch 28
2022-11-18 03:03:10,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:10,688 INFO:     Epoch: 29
2022-11-18 03:03:11,459 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8234437080946836, 'Total loss': 0.8234437080946836} | train loss {'Reaction outcome loss': 0.8188582563832882, 'Total loss': 0.8188582563832882}
2022-11-18 03:03:11,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:11,459 INFO:     Epoch: 30
2022-11-18 03:03:12,242 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8171233575452458, 'Total loss': 0.8171233575452458} | train loss {'Reaction outcome loss': 0.8242214596079241, 'Total loss': 0.8242214596079241}
2022-11-18 03:03:12,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:12,242 INFO:     Epoch: 31
2022-11-18 03:03:13,026 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8258745419708166, 'Total loss': 0.8258745419708166} | train loss {'Reaction outcome loss': 0.8242554108221685, 'Total loss': 0.8242554108221685}
2022-11-18 03:03:13,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:13,026 INFO:     Epoch: 32
2022-11-18 03:03:13,808 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8234614316712726, 'Total loss': 0.8234614316712726} | train loss {'Reaction outcome loss': 0.8185705680760645, 'Total loss': 0.8185705680760645}
2022-11-18 03:03:13,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:13,808 INFO:     Epoch: 33
2022-11-18 03:03:14,584 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8393158689141273, 'Total loss': 0.8393158689141273} | train loss {'Reaction outcome loss': 0.8185757910532336, 'Total loss': 0.8185757910532336}
2022-11-18 03:03:14,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:14,584 INFO:     Epoch: 34
2022-11-18 03:03:15,348 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8114007772369818, 'Total loss': 0.8114007772369818} | train loss {'Reaction outcome loss': 0.8246167167540519, 'Total loss': 0.8246167167540519}
2022-11-18 03:03:15,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:15,349 INFO:     Epoch: 35
2022-11-18 03:03:16,130 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8109503266486254, 'Total loss': 0.8109503266486254} | train loss {'Reaction outcome loss': 0.8264778985852196, 'Total loss': 0.8264778985852196}
2022-11-18 03:03:16,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:16,130 INFO:     Epoch: 36
2022-11-18 03:03:16,929 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8123429824005474, 'Total loss': 0.8123429824005474} | train loss {'Reaction outcome loss': 0.8174799000543933, 'Total loss': 0.8174799000543933}
2022-11-18 03:03:16,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:16,929 INFO:     Epoch: 37
2022-11-18 03:03:17,728 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8170355226505887, 'Total loss': 0.8170355226505887} | train loss {'Reaction outcome loss': 0.8237440264032733, 'Total loss': 0.8237440264032733}
2022-11-18 03:03:17,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:17,728 INFO:     Epoch: 38
2022-11-18 03:03:18,491 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8176542595028877, 'Total loss': 0.8176542595028877} | train loss {'Reaction outcome loss': 0.8218656896102813, 'Total loss': 0.8218656896102813}
2022-11-18 03:03:18,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:18,492 INFO:     Epoch: 39
2022-11-18 03:03:19,284 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8451215326786041, 'Total loss': 0.8451215326786041} | train loss {'Reaction outcome loss': 0.8199753311853255, 'Total loss': 0.8199753311853255}
2022-11-18 03:03:19,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:19,284 INFO:     Epoch: 40
2022-11-18 03:03:20,067 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8149840716611255, 'Total loss': 0.8149840716611255} | train loss {'Reaction outcome loss': 0.8247893581226948, 'Total loss': 0.8247893581226948}
2022-11-18 03:03:20,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:20,069 INFO:     Epoch: 41
2022-11-18 03:03:20,848 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8103062889792703, 'Total loss': 0.8103062889792703} | train loss {'Reaction outcome loss': 0.8190479444399956, 'Total loss': 0.8190479444399956}
2022-11-18 03:03:20,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:20,848 INFO:     Epoch: 42
2022-11-18 03:03:21,608 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8111481707204472, 'Total loss': 0.8111481707204472} | train loss {'Reaction outcome loss': 0.8243102026322195, 'Total loss': 0.8243102026322195}
2022-11-18 03:03:21,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:21,608 INFO:     Epoch: 43
2022-11-18 03:03:22,399 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8460707224228166, 'Total loss': 0.8460707224228166} | train loss {'Reaction outcome loss': 0.8227399078107649, 'Total loss': 0.8227399078107649}
2022-11-18 03:03:22,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:22,399 INFO:     Epoch: 44
2022-11-18 03:03:23,177 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8409625908190553, 'Total loss': 0.8409625908190553} | train loss {'Reaction outcome loss': 0.8233257866194171, 'Total loss': 0.8233257866194171}
2022-11-18 03:03:23,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:23,177 INFO:     Epoch: 45
2022-11-18 03:03:23,971 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8276137533512983, 'Total loss': 0.8276137533512983} | train loss {'Reaction outcome loss': 0.8219670950164718, 'Total loss': 0.8219670950164718}
2022-11-18 03:03:23,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:23,971 INFO:     Epoch: 46
2022-11-18 03:03:24,764 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.814477533779361, 'Total loss': 0.814477533779361} | train loss {'Reaction outcome loss': 0.8241594678932621, 'Total loss': 0.8241594678932621}
2022-11-18 03:03:24,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:24,765 INFO:     Epoch: 47
2022-11-18 03:03:25,522 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8155163641680371, 'Total loss': 0.8155163641680371} | train loss {'Reaction outcome loss': 0.8189470270468343, 'Total loss': 0.8189470270468343}
2022-11-18 03:03:25,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:25,522 INFO:     Epoch: 48
2022-11-18 03:03:26,315 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8313379531556909, 'Total loss': 0.8313379531556909} | train loss {'Reaction outcome loss': 0.8227134414257542, 'Total loss': 0.8227134414257542}
2022-11-18 03:03:26,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:26,316 INFO:     Epoch: 49
2022-11-18 03:03:27,118 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8165244026617571, 'Total loss': 0.8165244026617571} | train loss {'Reaction outcome loss': 0.8296752623733012, 'Total loss': 0.8296752623733012}
2022-11-18 03:03:27,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:27,119 INFO:     Epoch: 50
2022-11-18 03:03:27,904 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8162133653055538, 'Total loss': 0.8162133653055538} | train loss {'Reaction outcome loss': 0.8204690172306953, 'Total loss': 0.8204690172306953}
2022-11-18 03:03:27,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:27,904 INFO:     Epoch: 51
2022-11-18 03:03:28,680 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8326083286242052, 'Total loss': 0.8326083286242052} | train loss {'Reaction outcome loss': 0.8215529599016712, 'Total loss': 0.8215529599016712}
2022-11-18 03:03:28,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:28,680 INFO:     Epoch: 52
2022-11-18 03:03:29,453 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.812473398717967, 'Total loss': 0.812473398717967} | train loss {'Reaction outcome loss': 0.822958613235143, 'Total loss': 0.822958613235143}
2022-11-18 03:03:29,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:29,453 INFO:     Epoch: 53
2022-11-18 03:03:30,240 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8045163303613663, 'Total loss': 0.8045163303613663} | train loss {'Reaction outcome loss': 0.8215032932498763, 'Total loss': 0.8215032932498763}
2022-11-18 03:03:30,240 INFO:     Found new best model at epoch 53
2022-11-18 03:03:30,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:30,241 INFO:     Epoch: 54
2022-11-18 03:03:31,033 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.807617231526158, 'Total loss': 0.807617231526158} | train loss {'Reaction outcome loss': 0.8247270950626943, 'Total loss': 0.8247270950626943}
2022-11-18 03:03:31,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:31,034 INFO:     Epoch: 55
2022-11-18 03:03:31,805 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8240883167494427, 'Total loss': 0.8240883167494427} | train loss {'Reaction outcome loss': 0.8242825118284072, 'Total loss': 0.8242825118284072}
2022-11-18 03:03:31,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:31,805 INFO:     Epoch: 56
2022-11-18 03:03:32,580 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.818612158975818, 'Total loss': 0.818612158975818} | train loss {'Reaction outcome loss': 0.8231300371548822, 'Total loss': 0.8231300371548822}
2022-11-18 03:03:32,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:32,580 INFO:     Epoch: 57
2022-11-18 03:03:33,349 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8021790392019532, 'Total loss': 0.8021790392019532} | train loss {'Reaction outcome loss': 0.820217581405755, 'Total loss': 0.820217581405755}
2022-11-18 03:03:33,349 INFO:     Found new best model at epoch 57
2022-11-18 03:03:33,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:33,350 INFO:     Epoch: 58
2022-11-18 03:03:34,152 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8090744296258147, 'Total loss': 0.8090744296258147} | train loss {'Reaction outcome loss': 0.8197258146059129, 'Total loss': 0.8197258146059129}
2022-11-18 03:03:34,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:34,153 INFO:     Epoch: 59
2022-11-18 03:03:34,924 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8240185562859882, 'Total loss': 0.8240185562859882} | train loss {'Reaction outcome loss': 0.8183444689118093, 'Total loss': 0.8183444689118093}
2022-11-18 03:03:34,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:34,924 INFO:     Epoch: 60
2022-11-18 03:03:35,734 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8123694996942173, 'Total loss': 0.8123694996942173} | train loss {'Reaction outcome loss': 0.8235473196593023, 'Total loss': 0.8235473196593023}
2022-11-18 03:03:35,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:35,734 INFO:     Epoch: 61
2022-11-18 03:03:36,514 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8145350028168071, 'Total loss': 0.8145350028168071} | train loss {'Reaction outcome loss': 0.8229385202209796, 'Total loss': 0.8229385202209796}
2022-11-18 03:03:36,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:36,514 INFO:     Epoch: 62
2022-11-18 03:03:37,328 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8111220875924284, 'Total loss': 0.8111220875924284} | train loss {'Reaction outcome loss': 0.8210845046466396, 'Total loss': 0.8210845046466396}
2022-11-18 03:03:37,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:37,328 INFO:     Epoch: 63
2022-11-18 03:03:38,110 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8211909261616793, 'Total loss': 0.8211909261616793} | train loss {'Reaction outcome loss': 0.8216148617286836, 'Total loss': 0.8216148617286836}
2022-11-18 03:03:38,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:38,110 INFO:     Epoch: 64
2022-11-18 03:03:38,923 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.809770976277915, 'Total loss': 0.809770976277915} | train loss {'Reaction outcome loss': 0.8234864103217279, 'Total loss': 0.8234864103217279}
2022-11-18 03:03:38,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:38,924 INFO:     Epoch: 65
2022-11-18 03:03:39,698 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8284459764307196, 'Total loss': 0.8284459764307196} | train loss {'Reaction outcome loss': 0.8225492151273835, 'Total loss': 0.8225492151273835}
2022-11-18 03:03:39,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:39,698 INFO:     Epoch: 66
2022-11-18 03:03:40,477 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8038798712871291, 'Total loss': 0.8038798712871291} | train loss {'Reaction outcome loss': 0.8238655644799432, 'Total loss': 0.8238655644799432}
2022-11-18 03:03:40,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:40,478 INFO:     Epoch: 67
2022-11-18 03:03:41,296 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.816887388175184, 'Total loss': 0.816887388175184} | train loss {'Reaction outcome loss': 0.8189351651216706, 'Total loss': 0.8189351651216706}
2022-11-18 03:03:41,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:41,296 INFO:     Epoch: 68
2022-11-18 03:03:42,105 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8175525116649541, 'Total loss': 0.8175525116649541} | train loss {'Reaction outcome loss': 0.8202008930665832, 'Total loss': 0.8202008930665832}
2022-11-18 03:03:42,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:42,105 INFO:     Epoch: 69
2022-11-18 03:03:42,861 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8325661637566306, 'Total loss': 0.8325661637566306} | train loss {'Reaction outcome loss': 0.8266185114700948, 'Total loss': 0.8266185114700948}
2022-11-18 03:03:42,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:42,861 INFO:     Epoch: 70
2022-11-18 03:03:43,629 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8156973604451526, 'Total loss': 0.8156973604451526} | train loss {'Reaction outcome loss': 0.8201494766098838, 'Total loss': 0.8201494766098838}
2022-11-18 03:03:43,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:43,630 INFO:     Epoch: 71
2022-11-18 03:03:44,403 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.822942624037916, 'Total loss': 0.822942624037916} | train loss {'Reaction outcome loss': 0.8191088506531331, 'Total loss': 0.8191088506531331}
2022-11-18 03:03:44,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:44,403 INFO:     Epoch: 72
2022-11-18 03:03:45,166 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8133338865908709, 'Total loss': 0.8133338865908709} | train loss {'Reaction outcome loss': 0.8184737609999795, 'Total loss': 0.8184737609999795}
2022-11-18 03:03:45,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:45,166 INFO:     Epoch: 73
2022-11-18 03:03:45,938 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8206457624381239, 'Total loss': 0.8206457624381239} | train loss {'Reaction outcome loss': 0.8239970775621552, 'Total loss': 0.8239970775621552}
2022-11-18 03:03:45,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:45,938 INFO:     Epoch: 74
2022-11-18 03:03:46,720 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8248952356251803, 'Total loss': 0.8248952356251803} | train loss {'Reaction outcome loss': 0.8181610138666245, 'Total loss': 0.8181610138666245}
2022-11-18 03:03:46,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:46,720 INFO:     Epoch: 75
2022-11-18 03:03:47,520 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8360830145803365, 'Total loss': 0.8360830145803365} | train loss {'Reaction outcome loss': 0.8238757092866206, 'Total loss': 0.8238757092866206}
2022-11-18 03:03:47,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:47,521 INFO:     Epoch: 76
2022-11-18 03:03:48,312 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.833576425909996, 'Total loss': 0.833576425909996} | train loss {'Reaction outcome loss': 0.8198235288502709, 'Total loss': 0.8198235288502709}
2022-11-18 03:03:48,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:48,313 INFO:     Epoch: 77
2022-11-18 03:03:49,088 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8042199090123177, 'Total loss': 0.8042199090123177} | train loss {'Reaction outcome loss': 0.8195427114204052, 'Total loss': 0.8195427114204052}
2022-11-18 03:03:49,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:49,088 INFO:     Epoch: 78
2022-11-18 03:03:49,867 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8021420430053364, 'Total loss': 0.8021420430053364} | train loss {'Reaction outcome loss': 0.8198386511254695, 'Total loss': 0.8198386511254695}
2022-11-18 03:03:49,868 INFO:     Found new best model at epoch 78
2022-11-18 03:03:49,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:49,868 INFO:     Epoch: 79
2022-11-18 03:03:50,661 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8126217011700977, 'Total loss': 0.8126217011700977} | train loss {'Reaction outcome loss': 0.8153972497149822, 'Total loss': 0.8153972497149822}
2022-11-18 03:03:50,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:50,662 INFO:     Epoch: 80
2022-11-18 03:03:51,462 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8071095279671929, 'Total loss': 0.8071095279671929} | train loss {'Reaction outcome loss': 0.8202408995599516, 'Total loss': 0.8202408995599516}
2022-11-18 03:03:51,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:51,463 INFO:     Epoch: 81
2022-11-18 03:03:52,250 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8146791661327536, 'Total loss': 0.8146791661327536} | train loss {'Reaction outcome loss': 0.8161304727677376, 'Total loss': 0.8161304727677376}
2022-11-18 03:03:52,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:52,251 INFO:     Epoch: 82
2022-11-18 03:03:53,037 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8279284712943163, 'Total loss': 0.8279284712943163} | train loss {'Reaction outcome loss': 0.814411573112011, 'Total loss': 0.814411573112011}
2022-11-18 03:03:53,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:53,038 INFO:     Epoch: 83
2022-11-18 03:03:53,815 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8084042559970509, 'Total loss': 0.8084042559970509} | train loss {'Reaction outcome loss': 0.8147903969210963, 'Total loss': 0.8147903969210963}
2022-11-18 03:03:53,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:53,816 INFO:     Epoch: 84
2022-11-18 03:03:54,616 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8172419328581203, 'Total loss': 0.8172419328581203} | train loss {'Reaction outcome loss': 0.8183720083005966, 'Total loss': 0.8183720083005966}
2022-11-18 03:03:54,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:54,618 INFO:     Epoch: 85
2022-11-18 03:03:55,396 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8128636452284727, 'Total loss': 0.8128636452284727} | train loss {'Reaction outcome loss': 0.8195756600508767, 'Total loss': 0.8195756600508767}
2022-11-18 03:03:55,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:55,397 INFO:     Epoch: 86
2022-11-18 03:03:56,179 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8035091933878985, 'Total loss': 0.8035091933878985} | train loss {'Reaction outcome loss': 0.8167336303139886, 'Total loss': 0.8167336303139886}
2022-11-18 03:03:56,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:56,180 INFO:     Epoch: 87
2022-11-18 03:03:56,940 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.801366391507062, 'Total loss': 0.801366391507062} | train loss {'Reaction outcome loss': 0.8150188981765701, 'Total loss': 0.8150188981765701}
2022-11-18 03:03:56,940 INFO:     Found new best model at epoch 87
2022-11-18 03:03:56,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:56,941 INFO:     Epoch: 88
2022-11-18 03:03:57,718 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.819974309341474, 'Total loss': 0.819974309341474} | train loss {'Reaction outcome loss': 0.817774246296575, 'Total loss': 0.817774246296575}
2022-11-18 03:03:57,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:57,719 INFO:     Epoch: 89
2022-11-18 03:03:58,507 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8071454790505496, 'Total loss': 0.8071454790505496} | train loss {'Reaction outcome loss': 0.8227318102313627, 'Total loss': 0.8227318102313627}
2022-11-18 03:03:58,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:58,507 INFO:     Epoch: 90
2022-11-18 03:03:59,298 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8207946433262392, 'Total loss': 0.8207946433262392} | train loss {'Reaction outcome loss': 0.8169756042620828, 'Total loss': 0.8169756042620828}
2022-11-18 03:03:59,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:03:59,299 INFO:     Epoch: 91
2022-11-18 03:04:00,072 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8373036391355775, 'Total loss': 0.8373036391355775} | train loss {'Reaction outcome loss': 0.8159661806158481, 'Total loss': 0.8159661806158481}
2022-11-18 03:04:00,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:00,072 INFO:     Epoch: 92
2022-11-18 03:04:00,833 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8285851126367395, 'Total loss': 0.8285851126367395} | train loss {'Reaction outcome loss': 0.822899165773584, 'Total loss': 0.822899165773584}
2022-11-18 03:04:00,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:00,834 INFO:     Epoch: 93
2022-11-18 03:04:01,611 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8311831057071686, 'Total loss': 0.8311831057071686} | train loss {'Reaction outcome loss': 0.8199075626269463, 'Total loss': 0.8199075626269463}
2022-11-18 03:04:01,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:01,611 INFO:     Epoch: 94
2022-11-18 03:04:02,399 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8181987086480315, 'Total loss': 0.8181987086480315} | train loss {'Reaction outcome loss': 0.8208105047383616, 'Total loss': 0.8208105047383616}
2022-11-18 03:04:02,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:02,399 INFO:     Epoch: 95
2022-11-18 03:04:03,193 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8153973872011359, 'Total loss': 0.8153973872011359} | train loss {'Reaction outcome loss': 0.8156992568364066, 'Total loss': 0.8156992568364066}
2022-11-18 03:04:03,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:03,193 INFO:     Epoch: 96
2022-11-18 03:04:03,959 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8253636305982416, 'Total loss': 0.8253636305982416} | train loss {'Reaction outcome loss': 0.8178675354969117, 'Total loss': 0.8178675354969117}
2022-11-18 03:04:03,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:03,959 INFO:     Epoch: 97
2022-11-18 03:04:04,755 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8079901750792157, 'Total loss': 0.8079901750792157} | train loss {'Reaction outcome loss': 0.8201456200932303, 'Total loss': 0.8201456200932303}
2022-11-18 03:04:04,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:04,755 INFO:     Epoch: 98
2022-11-18 03:04:05,523 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8050923205234788, 'Total loss': 0.8050923205234788} | train loss {'Reaction outcome loss': 0.8173949484142565, 'Total loss': 0.8173949484142565}
2022-11-18 03:04:05,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:05,523 INFO:     Epoch: 99
2022-11-18 03:04:06,315 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8259816989302635, 'Total loss': 0.8259816989302635} | train loss {'Reaction outcome loss': 0.8158685944734081, 'Total loss': 0.8158685944734081}
2022-11-18 03:04:06,315 INFO:     Best model found after epoch 88 of 100.
2022-11-18 03:04:06,315 INFO:   Done with stage: TRAINING
2022-11-18 03:04:06,315 INFO:   Starting stage: EVALUATION
2022-11-18 03:04:06,432 INFO:   Done with stage: EVALUATION
2022-11-18 03:04:06,432 INFO:   Leaving out SEQ value Fold_7
2022-11-18 03:04:06,445 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:04:06,445 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:04:07,113 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:04:07,113 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:04:07,184 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:04:07,184 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:04:07,184 INFO:     No hyperparam tuning for this model
2022-11-18 03:04:07,184 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:04:07,184 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:04:07,185 INFO:     None feature selector for col prot
2022-11-18 03:04:07,185 INFO:     None feature selector for col prot
2022-11-18 03:04:07,185 INFO:     None feature selector for col prot
2022-11-18 03:04:07,186 INFO:     None feature selector for col chem
2022-11-18 03:04:07,186 INFO:     None feature selector for col chem
2022-11-18 03:04:07,186 INFO:     None feature selector for col chem
2022-11-18 03:04:07,186 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:04:07,186 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:04:07,187 INFO:     Number of params in model 168571
2022-11-18 03:04:07,191 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:04:07,191 INFO:   Starting stage: TRAINING
2022-11-18 03:04:07,248 INFO:     Val loss before train {'Reaction outcome loss': 1.0679162415591152, 'Total loss': 1.0679162415591152}
2022-11-18 03:04:07,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:07,248 INFO:     Epoch: 0
2022-11-18 03:04:08,047 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9010714976625009, 'Total loss': 0.9010714976625009} | train loss {'Reaction outcome loss': 0.8795278160081755, 'Total loss': 0.8795278160081755}
2022-11-18 03:04:08,047 INFO:     Found new best model at epoch 0
2022-11-18 03:04:08,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:08,048 INFO:     Epoch: 1
2022-11-18 03:04:08,831 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9229312132705342, 'Total loss': 0.9229312132705342} | train loss {'Reaction outcome loss': 0.8399926731663365, 'Total loss': 0.8399926731663365}
2022-11-18 03:04:08,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:08,831 INFO:     Epoch: 2
2022-11-18 03:04:09,621 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8725027292966843, 'Total loss': 0.8725027292966843} | train loss {'Reaction outcome loss': 0.8425033129751682, 'Total loss': 0.8425033129751682}
2022-11-18 03:04:09,621 INFO:     Found new best model at epoch 2
2022-11-18 03:04:09,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:09,622 INFO:     Epoch: 3
2022-11-18 03:04:10,405 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8639273365790193, 'Total loss': 0.8639273365790193} | train loss {'Reaction outcome loss': 0.8228969130544893, 'Total loss': 0.8228969130544893}
2022-11-18 03:04:10,405 INFO:     Found new best model at epoch 3
2022-11-18 03:04:10,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:10,406 INFO:     Epoch: 4
2022-11-18 03:04:11,170 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8638496940786188, 'Total loss': 0.8638496940786188} | train loss {'Reaction outcome loss': 0.8232542199473227, 'Total loss': 0.8232542199473227}
2022-11-18 03:04:11,171 INFO:     Found new best model at epoch 4
2022-11-18 03:04:11,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:11,171 INFO:     Epoch: 5
2022-11-18 03:04:11,960 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8625340543010018, 'Total loss': 0.8625340543010018} | train loss {'Reaction outcome loss': 0.8146742578716047, 'Total loss': 0.8146742578716047}
2022-11-18 03:04:11,961 INFO:     Found new best model at epoch 5
2022-11-18 03:04:11,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:11,961 INFO:     Epoch: 6
2022-11-18 03:04:12,741 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8540820709683679, 'Total loss': 0.8540820709683679} | train loss {'Reaction outcome loss': 0.8145109346557048, 'Total loss': 0.8145109346557048}
2022-11-18 03:04:12,741 INFO:     Found new best model at epoch 6
2022-11-18 03:04:12,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:12,742 INFO:     Epoch: 7
2022-11-18 03:04:13,505 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8520484702153639, 'Total loss': 0.8520484702153639} | train loss {'Reaction outcome loss': 0.8210485783075133, 'Total loss': 0.8210485783075133}
2022-11-18 03:04:13,506 INFO:     Found new best model at epoch 7
2022-11-18 03:04:13,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:13,507 INFO:     Epoch: 8
2022-11-18 03:04:14,299 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8576264564286579, 'Total loss': 0.8576264564286579} | train loss {'Reaction outcome loss': 0.8219518285364874, 'Total loss': 0.8219518285364874}
2022-11-18 03:04:14,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:14,299 INFO:     Epoch: 9
2022-11-18 03:04:15,071 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8646238148212433, 'Total loss': 0.8646238148212433} | train loss {'Reaction outcome loss': 0.81318735896099, 'Total loss': 0.81318735896099}
2022-11-18 03:04:15,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:15,071 INFO:     Epoch: 10
2022-11-18 03:04:15,854 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8800852312283083, 'Total loss': 0.8800852312283083} | train loss {'Reaction outcome loss': 0.81756327337315, 'Total loss': 0.81756327337315}
2022-11-18 03:04:15,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:15,854 INFO:     Epoch: 11
2022-11-18 03:04:16,638 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8657472079450433, 'Total loss': 0.8657472079450433} | train loss {'Reaction outcome loss': 0.8111248898410028, 'Total loss': 0.8111248898410028}
2022-11-18 03:04:16,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:16,638 INFO:     Epoch: 12
2022-11-18 03:04:17,424 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.850007257678292, 'Total loss': 0.850007257678292} | train loss {'Reaction outcome loss': 0.8127819808019746, 'Total loss': 0.8127819808019746}
2022-11-18 03:04:17,424 INFO:     Found new best model at epoch 12
2022-11-18 03:04:17,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:17,425 INFO:     Epoch: 13
2022-11-18 03:04:18,209 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8770553002303297, 'Total loss': 0.8770553002303297} | train loss {'Reaction outcome loss': 0.8103154927732483, 'Total loss': 0.8103154927732483}
2022-11-18 03:04:18,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:18,209 INFO:     Epoch: 14
2022-11-18 03:04:18,989 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8778624961322005, 'Total loss': 0.8778624961322005} | train loss {'Reaction outcome loss': 0.8145243338038844, 'Total loss': 0.8145243338038844}
2022-11-18 03:04:18,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:18,989 INFO:     Epoch: 15
2022-11-18 03:04:19,791 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8515674647959796, 'Total loss': 0.8515674647959796} | train loss {'Reaction outcome loss': 0.8058621473610401, 'Total loss': 0.8058621473610401}
2022-11-18 03:04:19,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:19,791 INFO:     Epoch: 16
2022-11-18 03:04:20,562 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8406325626102361, 'Total loss': 0.8406325626102361} | train loss {'Reaction outcome loss': 0.8103272030430455, 'Total loss': 0.8103272030430455}
2022-11-18 03:04:20,562 INFO:     Found new best model at epoch 16
2022-11-18 03:04:20,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:20,563 INFO:     Epoch: 17
2022-11-18 03:04:21,330 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8441048697991804, 'Total loss': 0.8441048697991804} | train loss {'Reaction outcome loss': 0.8119510200715834, 'Total loss': 0.8119510200715834}
2022-11-18 03:04:21,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:21,331 INFO:     Epoch: 18
2022-11-18 03:04:22,101 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8567445291714235, 'Total loss': 0.8567445291714235} | train loss {'Reaction outcome loss': 0.8099520077868816, 'Total loss': 0.8099520077868816}
2022-11-18 03:04:22,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:22,102 INFO:     Epoch: 19
2022-11-18 03:04:22,900 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8758570992133834, 'Total loss': 0.8758570992133834} | train loss {'Reaction outcome loss': 0.8090882802442196, 'Total loss': 0.8090882802442196}
2022-11-18 03:04:22,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:22,902 INFO:     Epoch: 20
2022-11-18 03:04:23,685 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8724778132005171, 'Total loss': 0.8724778132005171} | train loss {'Reaction outcome loss': 0.8080383593276623, 'Total loss': 0.8080383593276623}
2022-11-18 03:04:23,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:23,685 INFO:     Epoch: 21
2022-11-18 03:04:24,432 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8538074425675652, 'Total loss': 0.8538074425675652} | train loss {'Reaction outcome loss': 0.8135240083980945, 'Total loss': 0.8135240083980945}
2022-11-18 03:04:24,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:24,433 INFO:     Epoch: 22
2022-11-18 03:04:25,216 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8433215414935892, 'Total loss': 0.8433215414935892} | train loss {'Reaction outcome loss': 0.809668839578667, 'Total loss': 0.809668839578667}
2022-11-18 03:04:25,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:25,216 INFO:     Epoch: 23
2022-11-18 03:04:26,030 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.873599683019248, 'Total loss': 0.873599683019248} | train loss {'Reaction outcome loss': 0.8052382518447214, 'Total loss': 0.8052382518447214}
2022-11-18 03:04:26,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:26,031 INFO:     Epoch: 24
2022-11-18 03:04:26,825 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8647328899665312, 'Total loss': 0.8647328899665312} | train loss {'Reaction outcome loss': 0.8044748153657683, 'Total loss': 0.8044748153657683}
2022-11-18 03:04:26,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:26,825 INFO:     Epoch: 25
2022-11-18 03:04:27,616 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8544392436742783, 'Total loss': 0.8544392436742783} | train loss {'Reaction outcome loss': 0.8088280411977922, 'Total loss': 0.8088280411977922}
2022-11-18 03:04:27,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:27,616 INFO:     Epoch: 26
2022-11-18 03:04:28,376 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.9008127803152258, 'Total loss': 0.9008127803152258} | train loss {'Reaction outcome loss': 0.8039797228430549, 'Total loss': 0.8039797228430549}
2022-11-18 03:04:28,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:28,377 INFO:     Epoch: 27
2022-11-18 03:04:29,146 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8487332876433026, 'Total loss': 0.8487332876433026} | train loss {'Reaction outcome loss': 0.8072309594961905, 'Total loss': 0.8072309594961905}
2022-11-18 03:04:29,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:29,147 INFO:     Epoch: 28
2022-11-18 03:04:29,911 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.835571205074137, 'Total loss': 0.835571205074137} | train loss {'Reaction outcome loss': 0.8071200967796387, 'Total loss': 0.8071200967796387}
2022-11-18 03:04:29,911 INFO:     Found new best model at epoch 28
2022-11-18 03:04:29,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:29,912 INFO:     Epoch: 29
2022-11-18 03:04:30,696 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8553492724895477, 'Total loss': 0.8553492724895477} | train loss {'Reaction outcome loss': 0.8044426194842784, 'Total loss': 0.8044426194842784}
2022-11-18 03:04:30,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:30,696 INFO:     Epoch: 30
2022-11-18 03:04:31,516 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8657532693310217, 'Total loss': 0.8657532693310217} | train loss {'Reaction outcome loss': 0.8055191520721682, 'Total loss': 0.8055191520721682}
2022-11-18 03:04:31,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:31,516 INFO:     Epoch: 31
2022-11-18 03:04:32,298 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8525143333456733, 'Total loss': 0.8525143333456733} | train loss {'Reaction outcome loss': 0.8046214120282281, 'Total loss': 0.8046214120282281}
2022-11-18 03:04:32,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:32,299 INFO:     Epoch: 32
2022-11-18 03:04:33,076 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8559213131666183, 'Total loss': 0.8559213131666183} | train loss {'Reaction outcome loss': 0.8058837956238177, 'Total loss': 0.8058837956238177}
2022-11-18 03:04:33,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:33,076 INFO:     Epoch: 33
2022-11-18 03:04:33,872 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.861098821867596, 'Total loss': 0.861098821867596} | train loss {'Reaction outcome loss': 0.8087908446548446, 'Total loss': 0.8087908446548446}
2022-11-18 03:04:33,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:33,873 INFO:     Epoch: 34
2022-11-18 03:04:34,653 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8415417359633879, 'Total loss': 0.8415417359633879} | train loss {'Reaction outcome loss': 0.8080096010479235, 'Total loss': 0.8080096010479235}
2022-11-18 03:04:34,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:34,653 INFO:     Epoch: 35
2022-11-18 03:04:35,414 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8676672374660318, 'Total loss': 0.8676672374660318} | train loss {'Reaction outcome loss': 0.8019538858244496, 'Total loss': 0.8019538858244496}
2022-11-18 03:04:35,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:35,414 INFO:     Epoch: 36
2022-11-18 03:04:36,181 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8606702184135263, 'Total loss': 0.8606702184135263} | train loss {'Reaction outcome loss': 0.8073994358701091, 'Total loss': 0.8073994358701091}
2022-11-18 03:04:36,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:36,181 INFO:     Epoch: 37
2022-11-18 03:04:36,984 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8493339534510266, 'Total loss': 0.8493339534510266} | train loss {'Reaction outcome loss': 0.8045882393996562, 'Total loss': 0.8045882393996562}
2022-11-18 03:04:36,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:36,984 INFO:     Epoch: 38
2022-11-18 03:04:37,766 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.845098116858439, 'Total loss': 0.845098116858439} | train loss {'Reaction outcome loss': 0.8071151749501305, 'Total loss': 0.8071151749501305}
2022-11-18 03:04:37,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:37,766 INFO:     Epoch: 39
2022-11-18 03:04:38,542 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8523310639641501, 'Total loss': 0.8523310639641501} | train loss {'Reaction outcome loss': 0.8074542366929592, 'Total loss': 0.8074542366929592}
2022-11-18 03:04:38,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:38,543 INFO:     Epoch: 40
2022-11-18 03:04:39,338 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8635265725580129, 'Total loss': 0.8635265725580129} | train loss {'Reaction outcome loss': 0.8085192422713002, 'Total loss': 0.8085192422713002}
2022-11-18 03:04:39,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:39,338 INFO:     Epoch: 41
2022-11-18 03:04:40,114 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8655358891595494, 'Total loss': 0.8655358891595494} | train loss {'Reaction outcome loss': 0.8084234590491941, 'Total loss': 0.8084234590491941}
2022-11-18 03:04:40,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:40,115 INFO:     Epoch: 42
2022-11-18 03:04:40,911 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.852772474966266, 'Total loss': 0.852772474966266} | train loss {'Reaction outcome loss': 0.8040123281459655, 'Total loss': 0.8040123281459655}
2022-11-18 03:04:40,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:40,911 INFO:     Epoch: 43
2022-11-18 03:04:41,736 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8473631908947771, 'Total loss': 0.8473631908947771} | train loss {'Reaction outcome loss': 0.8054518289864063, 'Total loss': 0.8054518289864063}
2022-11-18 03:04:41,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:41,737 INFO:     Epoch: 44
2022-11-18 03:04:42,534 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8494135371663354, 'Total loss': 0.8494135371663354} | train loss {'Reaction outcome loss': 0.8056117171241391, 'Total loss': 0.8056117171241391}
2022-11-18 03:04:42,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:42,534 INFO:     Epoch: 45
2022-11-18 03:04:43,334 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8345637660134922, 'Total loss': 0.8345637660134922} | train loss {'Reaction outcome loss': 0.8036066145906525, 'Total loss': 0.8036066145906525}
2022-11-18 03:04:43,334 INFO:     Found new best model at epoch 45
2022-11-18 03:04:43,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:43,335 INFO:     Epoch: 46
2022-11-18 03:04:44,168 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.85791592029008, 'Total loss': 0.85791592029008} | train loss {'Reaction outcome loss': 0.8061782968861442, 'Total loss': 0.8061782968861442}
2022-11-18 03:04:44,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:44,168 INFO:     Epoch: 47
2022-11-18 03:04:44,968 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8391579646955837, 'Total loss': 0.8391579646955837} | train loss {'Reaction outcome loss': 0.8065679378567203, 'Total loss': 0.8065679378567203}
2022-11-18 03:04:44,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:44,968 INFO:     Epoch: 48
2022-11-18 03:04:45,798 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8516974218867042, 'Total loss': 0.8516974218867042} | train loss {'Reaction outcome loss': 0.8045306305491156, 'Total loss': 0.8045306305491156}
2022-11-18 03:04:45,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:45,798 INFO:     Epoch: 49
2022-11-18 03:04:46,590 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8407109149477698, 'Total loss': 0.8407109149477698} | train loss {'Reaction outcome loss': 0.8072575807811753, 'Total loss': 0.8072575807811753}
2022-11-18 03:04:46,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:46,591 INFO:     Epoch: 50
2022-11-18 03:04:47,404 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8429930609735575, 'Total loss': 0.8429930609735575} | train loss {'Reaction outcome loss': 0.8041311532499329, 'Total loss': 0.8041311532499329}
2022-11-18 03:04:47,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:47,404 INFO:     Epoch: 51
2022-11-18 03:04:48,237 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8530347875573419, 'Total loss': 0.8530347875573419} | train loss {'Reaction outcome loss': 0.8082434250222098, 'Total loss': 0.8082434250222098}
2022-11-18 03:04:48,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:48,237 INFO:     Epoch: 52
2022-11-18 03:04:49,063 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8772357038476251, 'Total loss': 0.8772357038476251} | train loss {'Reaction outcome loss': 0.805862071533357, 'Total loss': 0.805862071533357}
2022-11-18 03:04:49,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:49,063 INFO:     Epoch: 53
2022-11-18 03:04:49,937 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8554817688736048, 'Total loss': 0.8554817688736048} | train loss {'Reaction outcome loss': 0.8054931900433956, 'Total loss': 0.8054931900433956}
2022-11-18 03:04:49,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:49,938 INFO:     Epoch: 54
2022-11-18 03:04:50,740 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8724999068812891, 'Total loss': 0.8724999068812891} | train loss {'Reaction outcome loss': 0.8040709018466934, 'Total loss': 0.8040709018466934}
2022-11-18 03:04:50,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:50,740 INFO:     Epoch: 55
2022-11-18 03:04:51,552 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8446254066445611, 'Total loss': 0.8446254066445611} | train loss {'Reaction outcome loss': 0.8008960067264496, 'Total loss': 0.8008960067264496}
2022-11-18 03:04:51,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:51,553 INFO:     Epoch: 56
2022-11-18 03:04:52,398 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8482633680105209, 'Total loss': 0.8482633680105209} | train loss {'Reaction outcome loss': 0.8074025499724573, 'Total loss': 0.8074025499724573}
2022-11-18 03:04:52,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:52,399 INFO:     Epoch: 57
2022-11-18 03:04:53,180 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8510901806029406, 'Total loss': 0.8510901806029406} | train loss {'Reaction outcome loss': 0.8051556151720786, 'Total loss': 0.8051556151720786}
2022-11-18 03:04:53,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:53,181 INFO:     Epoch: 58
2022-11-18 03:04:53,954 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8543372059410269, 'Total loss': 0.8543372059410269} | train loss {'Reaction outcome loss': 0.8085500625593047, 'Total loss': 0.8085500625593047}
2022-11-18 03:04:53,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:53,956 INFO:     Epoch: 59
2022-11-18 03:04:54,790 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.840223335406997, 'Total loss': 0.840223335406997} | train loss {'Reaction outcome loss': 0.805994258172089, 'Total loss': 0.805994258172089}
2022-11-18 03:04:54,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:54,791 INFO:     Epoch: 60
2022-11-18 03:04:55,585 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8714642809195952, 'Total loss': 0.8714642809195952} | train loss {'Reaction outcome loss': 0.8063573338572056, 'Total loss': 0.8063573338572056}
2022-11-18 03:04:55,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:55,585 INFO:     Epoch: 61
2022-11-18 03:04:56,457 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8437853848392313, 'Total loss': 0.8437853848392313} | train loss {'Reaction outcome loss': 0.8047806905402292, 'Total loss': 0.8047806905402292}
2022-11-18 03:04:56,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:56,457 INFO:     Epoch: 62
2022-11-18 03:04:57,274 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8357490070841529, 'Total loss': 0.8357490070841529} | train loss {'Reaction outcome loss': 0.8052106663104026, 'Total loss': 0.8052106663104026}
2022-11-18 03:04:57,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:57,274 INFO:     Epoch: 63
2022-11-18 03:04:58,079 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8739558322863146, 'Total loss': 0.8739558322863146} | train loss {'Reaction outcome loss': 0.8036665790263684, 'Total loss': 0.8036665790263684}
2022-11-18 03:04:58,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:58,079 INFO:     Epoch: 64
2022-11-18 03:04:58,902 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8533209453929554, 'Total loss': 0.8533209453929554} | train loss {'Reaction outcome loss': 0.8057347068623189, 'Total loss': 0.8057347068623189}
2022-11-18 03:04:58,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:58,902 INFO:     Epoch: 65
2022-11-18 03:04:59,701 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8506700979037718, 'Total loss': 0.8506700979037718} | train loss {'Reaction outcome loss': 0.8034118725167166, 'Total loss': 0.8034118725167166}
2022-11-18 03:04:59,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:04:59,702 INFO:     Epoch: 66
2022-11-18 03:05:00,531 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8642414110628042, 'Total loss': 0.8642414110628042} | train loss {'Reaction outcome loss': 0.8055850942769358, 'Total loss': 0.8055850942769358}
2022-11-18 03:05:00,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:00,532 INFO:     Epoch: 67
2022-11-18 03:05:01,341 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8571426970037547, 'Total loss': 0.8571426970037547} | train loss {'Reaction outcome loss': 0.8022219908814276, 'Total loss': 0.8022219908814276}
2022-11-18 03:05:01,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:01,341 INFO:     Epoch: 68
2022-11-18 03:05:02,185 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8452692912383513, 'Total loss': 0.8452692912383513} | train loss {'Reaction outcome loss': 0.805155117545397, 'Total loss': 0.805155117545397}
2022-11-18 03:05:02,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:02,185 INFO:     Epoch: 69
2022-11-18 03:05:03,002 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8531719093972986, 'Total loss': 0.8531719093972986} | train loss {'Reaction outcome loss': 0.8024524348157067, 'Total loss': 0.8024524348157067}
2022-11-18 03:05:03,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:03,002 INFO:     Epoch: 70
2022-11-18 03:05:03,802 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8643488694321025, 'Total loss': 0.8643488694321025} | train loss {'Reaction outcome loss': 0.8079892936493119, 'Total loss': 0.8079892936493119}
2022-11-18 03:05:03,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:03,802 INFO:     Epoch: 71
2022-11-18 03:05:04,607 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8427822901444002, 'Total loss': 0.8427822901444002} | train loss {'Reaction outcome loss': 0.8054406799135669, 'Total loss': 0.8054406799135669}
2022-11-18 03:05:04,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:04,607 INFO:     Epoch: 72
2022-11-18 03:05:05,405 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.851791197603399, 'Total loss': 0.851791197603399} | train loss {'Reaction outcome loss': 0.805406448341185, 'Total loss': 0.805406448341185}
2022-11-18 03:05:05,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:05,406 INFO:     Epoch: 73
2022-11-18 03:05:06,201 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8496459607373584, 'Total loss': 0.8496459607373584} | train loss {'Reaction outcome loss': 0.8049812272431389, 'Total loss': 0.8049812272431389}
2022-11-18 03:05:06,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:06,201 INFO:     Epoch: 74
2022-11-18 03:05:06,985 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8594572097063065, 'Total loss': 0.8594572097063065} | train loss {'Reaction outcome loss': 0.8064592844776569, 'Total loss': 0.8064592844776569}
2022-11-18 03:05:06,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:06,985 INFO:     Epoch: 75
2022-11-18 03:05:07,790 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8599169294942509, 'Total loss': 0.8599169294942509} | train loss {'Reaction outcome loss': 0.8036429658532143, 'Total loss': 0.8036429658532143}
2022-11-18 03:05:07,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:07,790 INFO:     Epoch: 76
2022-11-18 03:05:08,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8627077117562294, 'Total loss': 0.8627077117562294} | train loss {'Reaction outcome loss': 0.8108168940149969, 'Total loss': 0.8108168940149969}
2022-11-18 03:05:08,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:08,599 INFO:     Epoch: 77
2022-11-18 03:05:09,406 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8396077366037802, 'Total loss': 0.8396077366037802} | train loss {'Reaction outcome loss': 0.8112628945419865, 'Total loss': 0.8112628945419865}
2022-11-18 03:05:09,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:09,407 INFO:     Epoch: 78
2022-11-18 03:05:10,194 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8545358885418285, 'Total loss': 0.8545358885418285} | train loss {'Reaction outcome loss': 0.8042157773048647, 'Total loss': 0.8042157773048647}
2022-11-18 03:05:10,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:10,195 INFO:     Epoch: 79
2022-11-18 03:05:11,012 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.868063866414807, 'Total loss': 0.868063866414807} | train loss {'Reaction outcome loss': 0.8034945804505579, 'Total loss': 0.8034945804505579}
2022-11-18 03:05:11,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:11,013 INFO:     Epoch: 80
2022-11-18 03:05:11,841 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.846067685295235, 'Total loss': 0.846067685295235} | train loss {'Reaction outcome loss': 0.8074385175301183, 'Total loss': 0.8074385175301183}
2022-11-18 03:05:11,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:11,841 INFO:     Epoch: 81
2022-11-18 03:05:12,658 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.855186368254098, 'Total loss': 0.855186368254098} | train loss {'Reaction outcome loss': 0.8031413442184848, 'Total loss': 0.8031413442184848}
2022-11-18 03:05:12,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:12,659 INFO:     Epoch: 82
2022-11-18 03:05:13,461 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8685295324433934, 'Total loss': 0.8685295324433934} | train loss {'Reaction outcome loss': 0.8031055021189875, 'Total loss': 0.8031055021189875}
2022-11-18 03:05:13,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:13,462 INFO:     Epoch: 83
2022-11-18 03:05:14,269 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8444435007192872, 'Total loss': 0.8444435007192872} | train loss {'Reaction outcome loss': 0.8021963833560867, 'Total loss': 0.8021963833560867}
2022-11-18 03:05:14,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:14,270 INFO:     Epoch: 84
2022-11-18 03:05:15,078 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8522738638249311, 'Total loss': 0.8522738638249311} | train loss {'Reaction outcome loss': 0.8108682977336068, 'Total loss': 0.8108682977336068}
2022-11-18 03:05:15,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:15,078 INFO:     Epoch: 85
2022-11-18 03:05:15,838 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8495798124508425, 'Total loss': 0.8495798124508425} | train loss {'Reaction outcome loss': 0.806591579750661, 'Total loss': 0.806591579750661}
2022-11-18 03:05:15,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:15,838 INFO:     Epoch: 86
2022-11-18 03:05:16,617 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8432166237722744, 'Total loss': 0.8432166237722744} | train loss {'Reaction outcome loss': 0.8077860533470108, 'Total loss': 0.8077860533470108}
2022-11-18 03:05:16,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:16,617 INFO:     Epoch: 87
2022-11-18 03:05:17,426 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8660957393321124, 'Total loss': 0.8660957393321124} | train loss {'Reaction outcome loss': 0.803305962994214, 'Total loss': 0.803305962994214}
2022-11-18 03:05:17,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:17,426 INFO:     Epoch: 88
2022-11-18 03:05:18,222 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.859447183934125, 'Total loss': 0.859447183934125} | train loss {'Reaction outcome loss': 0.8023584702562901, 'Total loss': 0.8023584702562901}
2022-11-18 03:05:18,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:18,222 INFO:     Epoch: 89
2022-11-18 03:05:19,012 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8572170416062529, 'Total loss': 0.8572170416062529} | train loss {'Reaction outcome loss': 0.8099697455763817, 'Total loss': 0.8099697455763817}
2022-11-18 03:05:19,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:19,012 INFO:     Epoch: 90
2022-11-18 03:05:19,791 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.845889113843441, 'Total loss': 0.845889113843441} | train loss {'Reaction outcome loss': 0.8021357793721461, 'Total loss': 0.8021357793721461}
2022-11-18 03:05:19,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:19,791 INFO:     Epoch: 91
2022-11-18 03:05:20,572 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.851944470947439, 'Total loss': 0.851944470947439} | train loss {'Reaction outcome loss': 0.805721853649424, 'Total loss': 0.805721853649424}
2022-11-18 03:05:20,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:20,572 INFO:     Epoch: 92
2022-11-18 03:05:21,351 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8713791201060469, 'Total loss': 0.8713791201060469} | train loss {'Reaction outcome loss': 0.8068867126299489, 'Total loss': 0.8068867126299489}
2022-11-18 03:05:21,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:21,352 INFO:     Epoch: 93
2022-11-18 03:05:22,133 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8782009130174463, 'Total loss': 0.8782009130174463} | train loss {'Reaction outcome loss': 0.8042199910888749, 'Total loss': 0.8042199910888749}
2022-11-18 03:05:22,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:22,133 INFO:     Epoch: 94
2022-11-18 03:05:22,920 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8571813357147303, 'Total loss': 0.8571813357147303} | train loss {'Reaction outcome loss': 0.7986611878919986, 'Total loss': 0.7986611878919986}
2022-11-18 03:05:22,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:22,920 INFO:     Epoch: 95
2022-11-18 03:05:23,703 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8362637968225912, 'Total loss': 0.8362637968225912} | train loss {'Reaction outcome loss': 0.8074019332566569, 'Total loss': 0.8074019332566569}
2022-11-18 03:05:23,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:23,704 INFO:     Epoch: 96
2022-11-18 03:05:24,492 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.858767178925601, 'Total loss': 0.858767178925601} | train loss {'Reaction outcome loss': 0.8080743463529695, 'Total loss': 0.8080743463529695}
2022-11-18 03:05:24,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:24,494 INFO:     Epoch: 97
2022-11-18 03:05:25,271 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.854409935799512, 'Total loss': 0.854409935799512} | train loss {'Reaction outcome loss': 0.8092710576470821, 'Total loss': 0.8092710576470821}
2022-11-18 03:05:25,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:25,271 INFO:     Epoch: 98
2022-11-18 03:05:26,040 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8533508195118471, 'Total loss': 0.8533508195118471} | train loss {'Reaction outcome loss': 0.803490984463884, 'Total loss': 0.803490984463884}
2022-11-18 03:05:26,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:26,040 INFO:     Epoch: 99
2022-11-18 03:05:26,818 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8403482261029157, 'Total loss': 0.8403482261029157} | train loss {'Reaction outcome loss': 0.8075859777389034, 'Total loss': 0.8075859777389034}
2022-11-18 03:05:26,818 INFO:     Best model found after epoch 46 of 100.
2022-11-18 03:05:26,818 INFO:   Done with stage: TRAINING
2022-11-18 03:05:26,818 INFO:   Starting stage: EVALUATION
2022-11-18 03:05:26,934 INFO:   Done with stage: EVALUATION
2022-11-18 03:05:26,935 INFO:   Leaving out SEQ value Fold_8
2022-11-18 03:05:26,948 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:05:26,948 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:05:27,613 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:05:27,613 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:05:27,683 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:05:27,683 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:05:27,683 INFO:     No hyperparam tuning for this model
2022-11-18 03:05:27,683 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:05:27,683 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:05:27,684 INFO:     None feature selector for col prot
2022-11-18 03:05:27,684 INFO:     None feature selector for col prot
2022-11-18 03:05:27,684 INFO:     None feature selector for col prot
2022-11-18 03:05:27,685 INFO:     None feature selector for col chem
2022-11-18 03:05:27,685 INFO:     None feature selector for col chem
2022-11-18 03:05:27,685 INFO:     None feature selector for col chem
2022-11-18 03:05:27,685 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:05:27,685 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:05:27,687 INFO:     Number of params in model 168571
2022-11-18 03:05:27,690 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:05:27,690 INFO:   Starting stage: TRAINING
2022-11-18 03:05:27,747 INFO:     Val loss before train {'Reaction outcome loss': 0.9693544588305734, 'Total loss': 0.9693544588305734}
2022-11-18 03:05:27,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:27,748 INFO:     Epoch: 0
2022-11-18 03:05:28,522 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8385093835267153, 'Total loss': 0.8385093835267153} | train loss {'Reaction outcome loss': 0.8741308206971358, 'Total loss': 0.8741308206971358}
2022-11-18 03:05:28,522 INFO:     Found new best model at epoch 0
2022-11-18 03:05:28,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:28,523 INFO:     Epoch: 1
2022-11-18 03:05:29,323 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7968860221180049, 'Total loss': 0.7968860221180049} | train loss {'Reaction outcome loss': 0.8509571656041782, 'Total loss': 0.8509571656041782}
2022-11-18 03:05:29,323 INFO:     Found new best model at epoch 1
2022-11-18 03:05:29,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:29,324 INFO:     Epoch: 2
2022-11-18 03:05:30,124 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7891443060203032, 'Total loss': 0.7891443060203032} | train loss {'Reaction outcome loss': 0.8456284482228128, 'Total loss': 0.8456284482228128}
2022-11-18 03:05:30,125 INFO:     Found new best model at epoch 2
2022-11-18 03:05:30,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:30,125 INFO:     Epoch: 3
2022-11-18 03:05:30,921 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8076125938783992, 'Total loss': 0.8076125938783992} | train loss {'Reaction outcome loss': 0.8402175633048239, 'Total loss': 0.8402175633048239}
2022-11-18 03:05:30,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:30,922 INFO:     Epoch: 4
2022-11-18 03:05:31,689 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8088959184559908, 'Total loss': 0.8088959184559908} | train loss {'Reaction outcome loss': 0.8291347001486944, 'Total loss': 0.8291347001486944}
2022-11-18 03:05:31,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:31,689 INFO:     Epoch: 5
2022-11-18 03:05:32,459 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7799317613244057, 'Total loss': 0.7799317613244057} | train loss {'Reaction outcome loss': 0.8308679945616104, 'Total loss': 0.8308679945616104}
2022-11-18 03:05:32,459 INFO:     Found new best model at epoch 5
2022-11-18 03:05:32,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:32,460 INFO:     Epoch: 6
2022-11-18 03:05:33,259 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8062895638021556, 'Total loss': 0.8062895638021556} | train loss {'Reaction outcome loss': 0.8205359348582353, 'Total loss': 0.8205359348582353}
2022-11-18 03:05:33,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:33,259 INFO:     Epoch: 7
2022-11-18 03:05:34,082 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7950020506978035, 'Total loss': 0.7950020506978035} | train loss {'Reaction outcome loss': 0.8299387216809307, 'Total loss': 0.8299387216809307}
2022-11-18 03:05:34,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:34,082 INFO:     Epoch: 8
2022-11-18 03:05:34,888 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7914643572135405, 'Total loss': 0.7914643572135405} | train loss {'Reaction outcome loss': 0.8258442450390171, 'Total loss': 0.8258442450390171}
2022-11-18 03:05:34,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:34,888 INFO:     Epoch: 9
2022-11-18 03:05:35,720 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7967850254340605, 'Total loss': 0.7967850254340605} | train loss {'Reaction outcome loss': 0.8236232258771595, 'Total loss': 0.8236232258771595}
2022-11-18 03:05:35,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:35,720 INFO:     Epoch: 10
2022-11-18 03:05:36,529 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.799070194363594, 'Total loss': 0.799070194363594} | train loss {'Reaction outcome loss': 0.8283885226769727, 'Total loss': 0.8283885226769727}
2022-11-18 03:05:36,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:36,529 INFO:     Epoch: 11
2022-11-18 03:05:37,372 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7940176833759655, 'Total loss': 0.7940176833759655} | train loss {'Reaction outcome loss': 0.8220227382443694, 'Total loss': 0.8220227382443694}
2022-11-18 03:05:37,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:37,372 INFO:     Epoch: 12
2022-11-18 03:05:38,186 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7850565910339355, 'Total loss': 0.7850565910339355} | train loss {'Reaction outcome loss': 0.8263743671811061, 'Total loss': 0.8263743671811061}
2022-11-18 03:05:38,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:38,187 INFO:     Epoch: 13
2022-11-18 03:05:39,000 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7915984073823149, 'Total loss': 0.7915984073823149} | train loss {'Reaction outcome loss': 0.8241297638850656, 'Total loss': 0.8241297638850656}
2022-11-18 03:05:39,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:39,000 INFO:     Epoch: 14
2022-11-18 03:05:39,801 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7855635271830992, 'Total loss': 0.7855635271830992} | train loss {'Reaction outcome loss': 0.8238751446669884, 'Total loss': 0.8238751446669884}
2022-11-18 03:05:39,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:39,802 INFO:     Epoch: 15
2022-11-18 03:05:40,639 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7880773137916218, 'Total loss': 0.7880773137916218} | train loss {'Reaction outcome loss': 0.8192526821182807, 'Total loss': 0.8192526821182807}
2022-11-18 03:05:40,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:40,639 INFO:     Epoch: 16
2022-11-18 03:05:41,476 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7781278667124835, 'Total loss': 0.7781278667124835} | train loss {'Reaction outcome loss': 0.8167081488831806, 'Total loss': 0.8167081488831806}
2022-11-18 03:05:41,476 INFO:     Found new best model at epoch 16
2022-11-18 03:05:41,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:41,477 INFO:     Epoch: 17
2022-11-18 03:05:42,309 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7868483466180888, 'Total loss': 0.7868483466180888} | train loss {'Reaction outcome loss': 0.8200000034803562, 'Total loss': 0.8200000034803562}
2022-11-18 03:05:42,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:42,309 INFO:     Epoch: 18
2022-11-18 03:05:43,121 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7811052995649251, 'Total loss': 0.7811052995649251} | train loss {'Reaction outcome loss': 0.8233275661614501, 'Total loss': 0.8233275661614501}
2022-11-18 03:05:43,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:43,122 INFO:     Epoch: 19
2022-11-18 03:05:43,909 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7874789237976074, 'Total loss': 0.7874789237976074} | train loss {'Reaction outcome loss': 0.8227667549119787, 'Total loss': 0.8227667549119787}
2022-11-18 03:05:43,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:43,910 INFO:     Epoch: 20
2022-11-18 03:05:44,722 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7917150753465566, 'Total loss': 0.7917150753465566} | train loss {'Reaction outcome loss': 0.8237119447364498, 'Total loss': 0.8237119447364498}
2022-11-18 03:05:44,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:44,722 INFO:     Epoch: 21
2022-11-18 03:05:45,543 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8038278411735188, 'Total loss': 0.8038278411735188} | train loss {'Reaction outcome loss': 0.8252298030776051, 'Total loss': 0.8252298030776051}
2022-11-18 03:05:45,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:45,544 INFO:     Epoch: 22
2022-11-18 03:05:46,331 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7759703214872967, 'Total loss': 0.7759703214872967} | train loss {'Reaction outcome loss': 0.8216183262797985, 'Total loss': 0.8216183262797985}
2022-11-18 03:05:46,332 INFO:     Found new best model at epoch 22
2022-11-18 03:05:46,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:46,333 INFO:     Epoch: 23
2022-11-18 03:05:47,129 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.779658780856566, 'Total loss': 0.779658780856566} | train loss {'Reaction outcome loss': 0.8150527927918956, 'Total loss': 0.8150527927918956}
2022-11-18 03:05:47,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:47,129 INFO:     Epoch: 24
2022-11-18 03:05:47,983 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7923666977069594, 'Total loss': 0.7923666977069594} | train loss {'Reaction outcome loss': 0.8170270838959497, 'Total loss': 0.8170270838959497}
2022-11-18 03:05:47,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:47,983 INFO:     Epoch: 25
2022-11-18 03:05:48,754 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7735408409075304, 'Total loss': 0.7735408409075304} | train loss {'Reaction outcome loss': 0.8231194873570431, 'Total loss': 0.8231194873570431}
2022-11-18 03:05:48,754 INFO:     Found new best model at epoch 25
2022-11-18 03:05:48,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:48,755 INFO:     Epoch: 26
2022-11-18 03:05:49,551 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7847942174835638, 'Total loss': 0.7847942174835638} | train loss {'Reaction outcome loss': 0.8177327769487975, 'Total loss': 0.8177327769487975}
2022-11-18 03:05:49,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:49,552 INFO:     Epoch: 27
2022-11-18 03:05:50,383 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7831284606998618, 'Total loss': 0.7831284606998618} | train loss {'Reaction outcome loss': 0.8282139290440903, 'Total loss': 0.8282139290440903}
2022-11-18 03:05:50,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:50,384 INFO:     Epoch: 28
2022-11-18 03:05:51,241 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7854398726062342, 'Total loss': 0.7854398726062342} | train loss {'Reaction outcome loss': 0.8197461249615982, 'Total loss': 0.8197461249615982}
2022-11-18 03:05:51,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:51,241 INFO:     Epoch: 29
2022-11-18 03:05:52,063 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7715035615996881, 'Total loss': 0.7715035615996881} | train loss {'Reaction outcome loss': 0.8147684023206533, 'Total loss': 0.8147684023206533}
2022-11-18 03:05:52,063 INFO:     Found new best model at epoch 29
2022-11-18 03:05:52,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:52,064 INFO:     Epoch: 30
2022-11-18 03:05:52,888 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8174690522930839, 'Total loss': 0.8174690522930839} | train loss {'Reaction outcome loss': 0.8204134713541641, 'Total loss': 0.8204134713541641}
2022-11-18 03:05:52,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:52,892 INFO:     Epoch: 31
2022-11-18 03:05:53,668 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7771312892436981, 'Total loss': 0.7771312892436981} | train loss {'Reaction outcome loss': 0.8159430975373457, 'Total loss': 0.8159430975373457}
2022-11-18 03:05:53,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:53,669 INFO:     Epoch: 32
2022-11-18 03:05:54,548 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7721095897934653, 'Total loss': 0.7721095897934653} | train loss {'Reaction outcome loss': 0.8184845330502822, 'Total loss': 0.8184845330502822}
2022-11-18 03:05:54,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:54,548 INFO:     Epoch: 33
2022-11-18 03:05:55,347 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7700054882602259, 'Total loss': 0.7700054882602259} | train loss {'Reaction outcome loss': 0.8218589480589276, 'Total loss': 0.8218589480589276}
2022-11-18 03:05:55,347 INFO:     Found new best model at epoch 33
2022-11-18 03:05:55,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:55,348 INFO:     Epoch: 34
2022-11-18 03:05:56,112 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8137238106944344, 'Total loss': 0.8137238106944344} | train loss {'Reaction outcome loss': 0.8120827013966043, 'Total loss': 0.8120827013966043}
2022-11-18 03:05:56,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:56,114 INFO:     Epoch: 35
2022-11-18 03:05:56,913 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7865430211479013, 'Total loss': 0.7865430211479013} | train loss {'Reaction outcome loss': 0.8215709998298754, 'Total loss': 0.8215709998298754}
2022-11-18 03:05:56,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:56,914 INFO:     Epoch: 36
2022-11-18 03:05:57,739 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.781482644379139, 'Total loss': 0.781482644379139} | train loss {'Reaction outcome loss': 0.8158746391896777, 'Total loss': 0.8158746391896777}
2022-11-18 03:05:57,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:57,739 INFO:     Epoch: 37
2022-11-18 03:05:58,575 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7741102765906941, 'Total loss': 0.7741102765906941} | train loss {'Reaction outcome loss': 0.8151381117732901, 'Total loss': 0.8151381117732901}
2022-11-18 03:05:58,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:58,575 INFO:     Epoch: 38
2022-11-18 03:05:59,366 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7849868867884983, 'Total loss': 0.7849868867884983} | train loss {'Reaction outcome loss': 0.8223945120809532, 'Total loss': 0.8223945120809532}
2022-11-18 03:05:59,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:05:59,366 INFO:     Epoch: 39
2022-11-18 03:06:00,177 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7977998019619421, 'Total loss': 0.7977998019619421} | train loss {'Reaction outcome loss': 0.8288063526394879, 'Total loss': 0.8288063526394879}
2022-11-18 03:06:00,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:00,178 INFO:     Epoch: 40
2022-11-18 03:06:00,962 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7814855670387094, 'Total loss': 0.7814855670387094} | train loss {'Reaction outcome loss': 0.8261917110396783, 'Total loss': 0.8261917110396783}
2022-11-18 03:06:00,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:00,963 INFO:     Epoch: 41
2022-11-18 03:06:01,790 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7732126665386286, 'Total loss': 0.7732126665386286} | train loss {'Reaction outcome loss': 0.8191049482658325, 'Total loss': 0.8191049482658325}
2022-11-18 03:06:01,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:01,791 INFO:     Epoch: 42
2022-11-18 03:06:02,571 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.790156368504871, 'Total loss': 0.790156368504871} | train loss {'Reaction outcome loss': 0.825867741214119, 'Total loss': 0.825867741214119}
2022-11-18 03:06:02,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:02,572 INFO:     Epoch: 43
2022-11-18 03:06:03,388 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7730331468311223, 'Total loss': 0.7730331468311223} | train loss {'Reaction outcome loss': 0.8219200384610819, 'Total loss': 0.8219200384610819}
2022-11-18 03:06:03,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:03,388 INFO:     Epoch: 44
2022-11-18 03:06:04,163 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7893598892472007, 'Total loss': 0.7893598892472007} | train loss {'Reaction outcome loss': 0.8202331472746274, 'Total loss': 0.8202331472746274}
2022-11-18 03:06:04,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:04,163 INFO:     Epoch: 45
2022-11-18 03:06:04,939 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7932781773534688, 'Total loss': 0.7932781773534688} | train loss {'Reaction outcome loss': 0.8192639292674027, 'Total loss': 0.8192639292674027}
2022-11-18 03:06:04,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:04,939 INFO:     Epoch: 46
2022-11-18 03:06:05,720 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7898648970506408, 'Total loss': 0.7898648970506408} | train loss {'Reaction outcome loss': 0.8167784357601814, 'Total loss': 0.8167784357601814}
2022-11-18 03:06:05,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:05,720 INFO:     Epoch: 47
2022-11-18 03:06:06,567 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7821956439451738, 'Total loss': 0.7821956439451738} | train loss {'Reaction outcome loss': 0.819838609651998, 'Total loss': 0.819838609651998}
2022-11-18 03:06:06,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:06,567 INFO:     Epoch: 48
2022-11-18 03:06:07,358 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7797733050855723, 'Total loss': 0.7797733050855723} | train loss {'Reaction outcome loss': 0.8170395924253502, 'Total loss': 0.8170395924253502}
2022-11-18 03:06:07,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:07,358 INFO:     Epoch: 49
2022-11-18 03:06:08,171 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7938972725109621, 'Total loss': 0.7938972725109621} | train loss {'Reaction outcome loss': 0.8252673488155551, 'Total loss': 0.8252673488155551}
2022-11-18 03:06:08,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:08,172 INFO:     Epoch: 50
2022-11-18 03:06:09,015 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7878401895815675, 'Total loss': 0.7878401895815675} | train loss {'Reaction outcome loss': 0.8171517815184497, 'Total loss': 0.8171517815184497}
2022-11-18 03:06:09,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:09,015 INFO:     Epoch: 51
2022-11-18 03:06:09,833 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7942227978597988, 'Total loss': 0.7942227978597988} | train loss {'Reaction outcome loss': 0.820881917409086, 'Total loss': 0.820881917409086}
2022-11-18 03:06:09,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:09,833 INFO:     Epoch: 52
2022-11-18 03:06:10,627 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7854071300138127, 'Total loss': 0.7854071300138127} | train loss {'Reaction outcome loss': 0.8193580601138142, 'Total loss': 0.8193580601138142}
2022-11-18 03:06:10,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:10,627 INFO:     Epoch: 53
2022-11-18 03:06:11,420 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7769716558131304, 'Total loss': 0.7769716558131304} | train loss {'Reaction outcome loss': 0.8250470621141828, 'Total loss': 0.8250470621141828}
2022-11-18 03:06:11,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:11,421 INFO:     Epoch: 54
2022-11-18 03:06:12,257 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8045107559724287, 'Total loss': 0.8045107559724287} | train loss {'Reaction outcome loss': 0.8155373321612355, 'Total loss': 0.8155373321612355}
2022-11-18 03:06:12,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:12,257 INFO:     Epoch: 55
2022-11-18 03:06:13,068 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7881947376511313, 'Total loss': 0.7881947376511313} | train loss {'Reaction outcome loss': 0.8188503705538236, 'Total loss': 0.8188503705538236}
2022-11-18 03:06:13,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:13,068 INFO:     Epoch: 56
2022-11-18 03:06:13,872 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7834497012875297, 'Total loss': 0.7834497012875297} | train loss {'Reaction outcome loss': 0.8224893416229048, 'Total loss': 0.8224893416229048}
2022-11-18 03:06:13,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:13,872 INFO:     Epoch: 57
2022-11-18 03:06:14,659 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7830975834618915, 'Total loss': 0.7830975834618915} | train loss {'Reaction outcome loss': 0.8221086765590467, 'Total loss': 0.8221086765590467}
2022-11-18 03:06:14,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:14,660 INFO:     Epoch: 58
2022-11-18 03:06:15,459 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8013607453216206, 'Total loss': 0.8013607453216206} | train loss {'Reaction outcome loss': 0.832637873135115, 'Total loss': 0.832637873135115}
2022-11-18 03:06:15,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:15,460 INFO:     Epoch: 59
2022-11-18 03:06:16,245 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7894617854194208, 'Total loss': 0.7894617854194208} | train loss {'Reaction outcome loss': 0.8276844725676393, 'Total loss': 0.8276844725676393}
2022-11-18 03:06:16,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:16,245 INFO:     Epoch: 60
2022-11-18 03:06:17,061 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7902286276221275, 'Total loss': 0.7902286276221275} | train loss {'Reaction outcome loss': 0.817112435696096, 'Total loss': 0.817112435696096}
2022-11-18 03:06:17,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:17,061 INFO:     Epoch: 61
2022-11-18 03:06:17,863 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7969839965755289, 'Total loss': 0.7969839965755289} | train loss {'Reaction outcome loss': 0.8147514597607045, 'Total loss': 0.8147514597607045}
2022-11-18 03:06:17,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:17,863 INFO:     Epoch: 62
2022-11-18 03:06:18,682 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7823426134207032, 'Total loss': 0.7823426134207032} | train loss {'Reaction outcome loss': 0.8224000008965311, 'Total loss': 0.8224000008965311}
2022-11-18 03:06:18,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:18,682 INFO:     Epoch: 63
2022-11-18 03:06:19,490 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7943452786315571, 'Total loss': 0.7943452786315571} | train loss {'Reaction outcome loss': 0.8133878360393076, 'Total loss': 0.8133878360393076}
2022-11-18 03:06:19,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:19,490 INFO:     Epoch: 64
2022-11-18 03:06:20,258 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7742027626796202, 'Total loss': 0.7742027626796202} | train loss {'Reaction outcome loss': 0.8165522503708056, 'Total loss': 0.8165522503708056}
2022-11-18 03:06:20,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:20,258 INFO:     Epoch: 65
2022-11-18 03:06:21,075 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.771721789105372, 'Total loss': 0.771721789105372} | train loss {'Reaction outcome loss': 0.815113970745913, 'Total loss': 0.815113970745913}
2022-11-18 03:06:21,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:21,075 INFO:     Epoch: 66
2022-11-18 03:06:21,886 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7820446992462332, 'Total loss': 0.7820446992462332} | train loss {'Reaction outcome loss': 0.8158646480515901, 'Total loss': 0.8158646480515901}
2022-11-18 03:06:21,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:21,886 INFO:     Epoch: 67
2022-11-18 03:06:22,713 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8065677732229233, 'Total loss': 0.8065677732229233} | train loss {'Reaction outcome loss': 0.8135697013332777, 'Total loss': 0.8135697013332777}
2022-11-18 03:06:22,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:22,714 INFO:     Epoch: 68
2022-11-18 03:06:23,535 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7819298356771469, 'Total loss': 0.7819298356771469} | train loss {'Reaction outcome loss': 0.8210014355810065, 'Total loss': 0.8210014355810065}
2022-11-18 03:06:23,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:23,536 INFO:     Epoch: 69
2022-11-18 03:06:24,351 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7866565869613127, 'Total loss': 0.7866565869613127} | train loss {'Reaction outcome loss': 0.8149750545198619, 'Total loss': 0.8149750545198619}
2022-11-18 03:06:24,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:24,352 INFO:     Epoch: 70
2022-11-18 03:06:25,204 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7970916899767789, 'Total loss': 0.7970916899767789} | train loss {'Reaction outcome loss': 0.8198683037448992, 'Total loss': 0.8198683037448992}
2022-11-18 03:06:25,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:25,204 INFO:     Epoch: 71
2022-11-18 03:06:26,000 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7947209504517642, 'Total loss': 0.7947209504517642} | train loss {'Reaction outcome loss': 0.8213983553231727, 'Total loss': 0.8213983553231727}
2022-11-18 03:06:26,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:26,000 INFO:     Epoch: 72
2022-11-18 03:06:26,786 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.782646275379441, 'Total loss': 0.782646275379441} | train loss {'Reaction outcome loss': 0.8117614101301803, 'Total loss': 0.8117614101301803}
2022-11-18 03:06:26,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:26,787 INFO:     Epoch: 73
2022-11-18 03:06:27,605 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.783821439878507, 'Total loss': 0.783821439878507} | train loss {'Reaction outcome loss': 0.820845298197588, 'Total loss': 0.820845298197588}
2022-11-18 03:06:27,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:27,606 INFO:     Epoch: 74
2022-11-18 03:06:28,404 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7924401556903665, 'Total loss': 0.7924401556903665} | train loss {'Reaction outcome loss': 0.8170954188113271, 'Total loss': 0.8170954188113271}
2022-11-18 03:06:28,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:28,405 INFO:     Epoch: 75
2022-11-18 03:06:29,235 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7895004458048127, 'Total loss': 0.7895004458048127} | train loss {'Reaction outcome loss': 0.8175284475208777, 'Total loss': 0.8175284475208777}
2022-11-18 03:06:29,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:29,236 INFO:     Epoch: 76
2022-11-18 03:06:30,068 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7677101394669577, 'Total loss': 0.7677101394669577} | train loss {'Reaction outcome loss': 0.8174841603648807, 'Total loss': 0.8174841603648807}
2022-11-18 03:06:30,069 INFO:     Found new best model at epoch 76
2022-11-18 03:06:30,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:30,069 INFO:     Epoch: 77
2022-11-18 03:06:30,858 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7880313233895735, 'Total loss': 0.7880313233895735} | train loss {'Reaction outcome loss': 0.8199682105408024, 'Total loss': 0.8199682105408024}
2022-11-18 03:06:30,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:30,858 INFO:     Epoch: 78
2022-11-18 03:06:31,659 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7953441271727736, 'Total loss': 0.7953441271727736} | train loss {'Reaction outcome loss': 0.8121244882041143, 'Total loss': 0.8121244882041143}
2022-11-18 03:06:31,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:31,660 INFO:     Epoch: 79
2022-11-18 03:06:32,454 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7829218472946774, 'Total loss': 0.7829218472946774} | train loss {'Reaction outcome loss': 0.8153273977248775, 'Total loss': 0.8153273977248775}
2022-11-18 03:06:32,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:32,454 INFO:     Epoch: 80
2022-11-18 03:06:33,257 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7717488739978183, 'Total loss': 0.7717488739978183} | train loss {'Reaction outcome loss': 0.8091669036791875, 'Total loss': 0.8091669036791875}
2022-11-18 03:06:33,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:33,258 INFO:     Epoch: 81
2022-11-18 03:06:34,028 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7877636768601157, 'Total loss': 0.7877636768601157} | train loss {'Reaction outcome loss': 0.8105007495716033, 'Total loss': 0.8105007495716033}
2022-11-18 03:06:34,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:34,028 INFO:     Epoch: 82
2022-11-18 03:06:34,855 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7837721556425095, 'Total loss': 0.7837721556425095} | train loss {'Reaction outcome loss': 0.8149916609289193, 'Total loss': 0.8149916609289193}
2022-11-18 03:06:34,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:34,855 INFO:     Epoch: 83
2022-11-18 03:06:35,635 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.779263009401885, 'Total loss': 0.779263009401885} | train loss {'Reaction outcome loss': 0.8145797526546819, 'Total loss': 0.8145797526546819}
2022-11-18 03:06:35,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:35,636 INFO:     Epoch: 84
2022-11-18 03:06:36,473 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7733644396066666, 'Total loss': 0.7733644396066666} | train loss {'Reaction outcome loss': 0.8176859210618594, 'Total loss': 0.8176859210618594}
2022-11-18 03:06:36,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:36,473 INFO:     Epoch: 85
2022-11-18 03:06:37,273 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7855565148321065, 'Total loss': 0.7855565148321065} | train loss {'Reaction outcome loss': 0.8190131683339957, 'Total loss': 0.8190131683339957}
2022-11-18 03:06:37,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:37,273 INFO:     Epoch: 86
2022-11-18 03:06:38,076 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7829708321528002, 'Total loss': 0.7829708321528002} | train loss {'Reaction outcome loss': 0.8207102673739074, 'Total loss': 0.8207102673739074}
2022-11-18 03:06:38,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:38,077 INFO:     Epoch: 87
2022-11-18 03:06:38,888 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7802270088683475, 'Total loss': 0.7802270088683475} | train loss {'Reaction outcome loss': 0.8197020940814423, 'Total loss': 0.8197020940814423}
2022-11-18 03:06:38,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:38,888 INFO:     Epoch: 88
2022-11-18 03:06:39,695 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7987266196445986, 'Total loss': 0.7987266196445986} | train loss {'Reaction outcome loss': 0.8172207139281609, 'Total loss': 0.8172207139281609}
2022-11-18 03:06:39,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:39,695 INFO:     Epoch: 89
2022-11-18 03:06:40,493 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7808448550376025, 'Total loss': 0.7808448550376025} | train loss {'Reaction outcome loss': 0.8158157455173098, 'Total loss': 0.8158157455173098}
2022-11-18 03:06:40,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:40,493 INFO:     Epoch: 90
2022-11-18 03:06:41,311 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7888997183604674, 'Total loss': 0.7888997183604674} | train loss {'Reaction outcome loss': 0.8093704294096603, 'Total loss': 0.8093704294096603}
2022-11-18 03:06:41,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:41,311 INFO:     Epoch: 91
2022-11-18 03:06:42,095 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7768939360976219, 'Total loss': 0.7768939360976219} | train loss {'Reaction outcome loss': 0.8142124693162045, 'Total loss': 0.8142124693162045}
2022-11-18 03:06:42,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:42,095 INFO:     Epoch: 92
2022-11-18 03:06:42,927 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7656898830424655, 'Total loss': 0.7656898830424655} | train loss {'Reaction outcome loss': 0.8184472373140003, 'Total loss': 0.8184472373140003}
2022-11-18 03:06:42,927 INFO:     Found new best model at epoch 92
2022-11-18 03:06:42,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:42,928 INFO:     Epoch: 93
2022-11-18 03:06:43,743 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7844718748872931, 'Total loss': 0.7844718748872931} | train loss {'Reaction outcome loss': 0.8100733798042483, 'Total loss': 0.8100733798042483}
2022-11-18 03:06:43,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:43,743 INFO:     Epoch: 94
2022-11-18 03:06:44,529 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7847796184095469, 'Total loss': 0.7847796184095469} | train loss {'Reaction outcome loss': 0.8211795731112059, 'Total loss': 0.8211795731112059}
2022-11-18 03:06:44,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:44,530 INFO:     Epoch: 95
2022-11-18 03:06:45,307 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.779136409136382, 'Total loss': 0.779136409136382} | train loss {'Reaction outcome loss': 0.8233517734145346, 'Total loss': 0.8233517734145346}
2022-11-18 03:06:45,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:45,308 INFO:     Epoch: 96
2022-11-18 03:06:46,149 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7970368801192804, 'Total loss': 0.7970368801192804} | train loss {'Reaction outcome loss': 0.8189779316274984, 'Total loss': 0.8189779316274984}
2022-11-18 03:06:46,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:46,149 INFO:     Epoch: 97
2022-11-18 03:06:46,968 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7673587250438604, 'Total loss': 0.7673587250438604} | train loss {'Reaction outcome loss': 0.8176454176545626, 'Total loss': 0.8176454176545626}
2022-11-18 03:06:46,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:46,968 INFO:     Epoch: 98
2022-11-18 03:06:47,761 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7772797610272061, 'Total loss': 0.7772797610272061} | train loss {'Reaction outcome loss': 0.8211976261997995, 'Total loss': 0.8211976261997995}
2022-11-18 03:06:47,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:47,761 INFO:     Epoch: 99
2022-11-18 03:06:48,570 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7701964832165025, 'Total loss': 0.7701964832165025} | train loss {'Reaction outcome loss': 0.8146870372749051, 'Total loss': 0.8146870372749051}
2022-11-18 03:06:48,571 INFO:     Best model found after epoch 93 of 100.
2022-11-18 03:06:48,571 INFO:   Done with stage: TRAINING
2022-11-18 03:06:48,571 INFO:   Starting stage: EVALUATION
2022-11-18 03:06:48,695 INFO:   Done with stage: EVALUATION
2022-11-18 03:06:48,695 INFO:   Leaving out SEQ value Fold_9
2022-11-18 03:06:48,708 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:06:48,708 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:06:49,370 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:06:49,370 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:06:49,441 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:06:49,441 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:06:49,441 INFO:     No hyperparam tuning for this model
2022-11-18 03:06:49,441 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:06:49,441 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:06:49,442 INFO:     None feature selector for col prot
2022-11-18 03:06:49,442 INFO:     None feature selector for col prot
2022-11-18 03:06:49,442 INFO:     None feature selector for col prot
2022-11-18 03:06:49,443 INFO:     None feature selector for col chem
2022-11-18 03:06:49,443 INFO:     None feature selector for col chem
2022-11-18 03:06:49,443 INFO:     None feature selector for col chem
2022-11-18 03:06:49,443 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:06:49,443 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:06:49,444 INFO:     Number of params in model 168571
2022-11-18 03:06:49,448 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:06:49,448 INFO:   Starting stage: TRAINING
2022-11-18 03:06:49,505 INFO:     Val loss before train {'Reaction outcome loss': 1.0071837306022644, 'Total loss': 1.0071837306022644}
2022-11-18 03:06:49,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:49,505 INFO:     Epoch: 0
2022-11-18 03:06:50,344 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.891943021254106, 'Total loss': 0.891943021254106} | train loss {'Reaction outcome loss': 0.8948649707352102, 'Total loss': 0.8948649707352102}
2022-11-18 03:06:50,344 INFO:     Found new best model at epoch 0
2022-11-18 03:06:50,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:50,345 INFO:     Epoch: 1
2022-11-18 03:06:51,147 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8749657381664623, 'Total loss': 0.8749657381664623} | train loss {'Reaction outcome loss': 0.8703156195671452, 'Total loss': 0.8703156195671452}
2022-11-18 03:06:51,148 INFO:     Found new best model at epoch 1
2022-11-18 03:06:51,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:51,148 INFO:     Epoch: 2
2022-11-18 03:06:51,994 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8685194484212182, 'Total loss': 0.8685194484212182} | train loss {'Reaction outcome loss': 0.8554261955413741, 'Total loss': 0.8554261955413741}
2022-11-18 03:06:51,994 INFO:     Found new best model at epoch 2
2022-11-18 03:06:51,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:51,995 INFO:     Epoch: 3
2022-11-18 03:06:52,818 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8380072685805234, 'Total loss': 0.8380072685805234} | train loss {'Reaction outcome loss': 0.8625992408648193, 'Total loss': 0.8625992408648193}
2022-11-18 03:06:52,818 INFO:     Found new best model at epoch 3
2022-11-18 03:06:52,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:52,819 INFO:     Epoch: 4
2022-11-18 03:06:53,640 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8343034955588254, 'Total loss': 0.8343034955588254} | train loss {'Reaction outcome loss': 0.8489002285276347, 'Total loss': 0.8489002285276347}
2022-11-18 03:06:53,640 INFO:     Found new best model at epoch 4
2022-11-18 03:06:53,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:53,641 INFO:     Epoch: 5
2022-11-18 03:06:54,433 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.853314531120387, 'Total loss': 0.853314531120387} | train loss {'Reaction outcome loss': 0.843842508218549, 'Total loss': 0.843842508218549}
2022-11-18 03:06:54,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:54,433 INFO:     Epoch: 6
2022-11-18 03:06:55,253 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8347858854315497, 'Total loss': 0.8347858854315497} | train loss {'Reaction outcome loss': 0.8485572807460662, 'Total loss': 0.8485572807460662}
2022-11-18 03:06:55,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:55,253 INFO:     Epoch: 7
2022-11-18 03:06:56,055 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8373865580016916, 'Total loss': 0.8373865580016916} | train loss {'Reaction outcome loss': 0.8468793857435466, 'Total loss': 0.8468793857435466}
2022-11-18 03:06:56,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:56,056 INFO:     Epoch: 8
2022-11-18 03:06:56,852 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8497232876040719, 'Total loss': 0.8497232876040719} | train loss {'Reaction outcome loss': 0.8475862032006144, 'Total loss': 0.8475862032006144}
2022-11-18 03:06:56,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:56,852 INFO:     Epoch: 9
2022-11-18 03:06:57,697 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.854733709584583, 'Total loss': 0.854733709584583} | train loss {'Reaction outcome loss': 0.8429212406096671, 'Total loss': 0.8429212406096671}
2022-11-18 03:06:57,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:57,697 INFO:     Epoch: 10
2022-11-18 03:06:58,491 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8557564026930116, 'Total loss': 0.8557564026930116} | train loss {'Reaction outcome loss': 0.8461782668042279, 'Total loss': 0.8461782668042279}
2022-11-18 03:06:58,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:58,493 INFO:     Epoch: 11
2022-11-18 03:06:59,276 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.835689554837617, 'Total loss': 0.835689554837617} | train loss {'Reaction outcome loss': 0.8371045927287113, 'Total loss': 0.8371045927287113}
2022-11-18 03:06:59,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:06:59,276 INFO:     Epoch: 12
2022-11-18 03:07:00,062 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8426712168888613, 'Total loss': 0.8426712168888613} | train loss {'Reaction outcome loss': 0.8362595629595552, 'Total loss': 0.8362595629595552}
2022-11-18 03:07:00,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:00,062 INFO:     Epoch: 13
2022-11-18 03:07:00,850 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8758229870687831, 'Total loss': 0.8758229870687831} | train loss {'Reaction outcome loss': 0.8348226944203319, 'Total loss': 0.8348226944203319}
2022-11-18 03:07:00,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:00,850 INFO:     Epoch: 14
2022-11-18 03:07:01,669 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8420971300114285, 'Total loss': 0.8420971300114285} | train loss {'Reaction outcome loss': 0.8371867800531118, 'Total loss': 0.8371867800531118}
2022-11-18 03:07:01,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:01,669 INFO:     Epoch: 15
2022-11-18 03:07:02,488 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8424955267797817, 'Total loss': 0.8424955267797817} | train loss {'Reaction outcome loss': 0.8353594055301264, 'Total loss': 0.8353594055301264}
2022-11-18 03:07:02,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:02,489 INFO:     Epoch: 16
2022-11-18 03:07:03,316 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8552253354679454, 'Total loss': 0.8552253354679454} | train loss {'Reaction outcome loss': 0.832682674471666, 'Total loss': 0.832682674471666}
2022-11-18 03:07:03,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:03,316 INFO:     Epoch: 17
2022-11-18 03:07:04,147 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8445697169412266, 'Total loss': 0.8445697169412266} | train loss {'Reaction outcome loss': 0.8419371805934288, 'Total loss': 0.8419371805934288}
2022-11-18 03:07:04,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:04,148 INFO:     Epoch: 18
2022-11-18 03:07:04,963 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8631969338113611, 'Total loss': 0.8631969338113611} | train loss {'Reaction outcome loss': 0.832652456575801, 'Total loss': 0.832652456575801}
2022-11-18 03:07:04,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:04,964 INFO:     Epoch: 19
2022-11-18 03:07:05,747 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8428287709301169, 'Total loss': 0.8428287709301169} | train loss {'Reaction outcome loss': 0.8441143741733149, 'Total loss': 0.8441143741733149}
2022-11-18 03:07:05,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:05,747 INFO:     Epoch: 20
2022-11-18 03:07:06,611 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.845445609905503, 'Total loss': 0.845445609905503} | train loss {'Reaction outcome loss': 0.8261641451036972, 'Total loss': 0.8261641451036972}
2022-11-18 03:07:06,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:06,612 INFO:     Epoch: 21
2022-11-18 03:07:07,412 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8269521329890598, 'Total loss': 0.8269521329890598} | train loss {'Reaction outcome loss': 0.8368056369455237, 'Total loss': 0.8368056369455237}
2022-11-18 03:07:07,412 INFO:     Found new best model at epoch 21
2022-11-18 03:07:07,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:07,413 INFO:     Epoch: 22
2022-11-18 03:07:08,230 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8290927694602446, 'Total loss': 0.8290927694602446} | train loss {'Reaction outcome loss': 0.8309594799994457, 'Total loss': 0.8309594799994457}
2022-11-18 03:07:08,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:08,230 INFO:     Epoch: 23
2022-11-18 03:07:09,070 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8460603708570654, 'Total loss': 0.8460603708570654} | train loss {'Reaction outcome loss': 0.8318401637830233, 'Total loss': 0.8318401637830233}
2022-11-18 03:07:09,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:09,071 INFO:     Epoch: 24
2022-11-18 03:07:09,896 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8378108617934313, 'Total loss': 0.8378108617934313} | train loss {'Reaction outcome loss': 0.8460005320276809, 'Total loss': 0.8460005320276809}
2022-11-18 03:07:09,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:09,896 INFO:     Epoch: 25
2022-11-18 03:07:10,674 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.846202475103465, 'Total loss': 0.846202475103465} | train loss {'Reaction outcome loss': 0.828619821721062, 'Total loss': 0.828619821721062}
2022-11-18 03:07:10,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:10,674 INFO:     Epoch: 26
2022-11-18 03:07:11,448 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8378911302848295, 'Total loss': 0.8378911302848295} | train loss {'Reaction outcome loss': 0.8323011743394952, 'Total loss': 0.8323011743394952}
2022-11-18 03:07:11,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:11,449 INFO:     Epoch: 27
2022-11-18 03:07:12,222 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8252287412231619, 'Total loss': 0.8252287412231619} | train loss {'Reaction outcome loss': 0.8304034787633641, 'Total loss': 0.8304034787633641}
2022-11-18 03:07:12,222 INFO:     Found new best model at epoch 27
2022-11-18 03:07:12,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:12,223 INFO:     Epoch: 28
2022-11-18 03:07:13,007 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8385473002086986, 'Total loss': 0.8385473002086986} | train loss {'Reaction outcome loss': 0.8389271544782739, 'Total loss': 0.8389271544782739}
2022-11-18 03:07:13,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:13,008 INFO:     Epoch: 29
2022-11-18 03:07:13,782 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.856496197256175, 'Total loss': 0.856496197256175} | train loss {'Reaction outcome loss': 0.8317828162117042, 'Total loss': 0.8317828162117042}
2022-11-18 03:07:13,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:13,782 INFO:     Epoch: 30
2022-11-18 03:07:14,554 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8751829686489973, 'Total loss': 0.8751829686489973} | train loss {'Reaction outcome loss': 0.8321556588898786, 'Total loss': 0.8321556588898786}
2022-11-18 03:07:14,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:14,554 INFO:     Epoch: 31
2022-11-18 03:07:15,346 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8280573568560861, 'Total loss': 0.8280573568560861} | train loss {'Reaction outcome loss': 0.8313106626634174, 'Total loss': 0.8313106626634174}
2022-11-18 03:07:15,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:15,346 INFO:     Epoch: 32
2022-11-18 03:07:16,121 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8593723489479586, 'Total loss': 0.8593723489479586} | train loss {'Reaction outcome loss': 0.8326347961358214, 'Total loss': 0.8326347961358214}
2022-11-18 03:07:16,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:16,121 INFO:     Epoch: 33
2022-11-18 03:07:16,893 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8288917920806191, 'Total loss': 0.8288917920806191} | train loss {'Reaction outcome loss': 0.8412670529323069, 'Total loss': 0.8412670529323069}
2022-11-18 03:07:16,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:16,894 INFO:     Epoch: 34
2022-11-18 03:07:17,686 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.855395107106729, 'Total loss': 0.855395107106729} | train loss {'Reaction outcome loss': 0.8280194221056907, 'Total loss': 0.8280194221056907}
2022-11-18 03:07:17,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:17,687 INFO:     Epoch: 35
2022-11-18 03:07:18,480 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.827973606234247, 'Total loss': 0.827973606234247} | train loss {'Reaction outcome loss': 0.8347234851435611, 'Total loss': 0.8347234851435611}
2022-11-18 03:07:18,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:18,481 INFO:     Epoch: 36
2022-11-18 03:07:19,288 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8457687476819212, 'Total loss': 0.8457687476819212} | train loss {'Reaction outcome loss': 0.8351880062205589, 'Total loss': 0.8351880062205589}
2022-11-18 03:07:19,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:19,288 INFO:     Epoch: 37
2022-11-18 03:07:20,080 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8355861197818409, 'Total loss': 0.8355861197818409} | train loss {'Reaction outcome loss': 0.8289971061443028, 'Total loss': 0.8289971061443028}
2022-11-18 03:07:20,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:20,080 INFO:     Epoch: 38
2022-11-18 03:07:20,871 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8390473059632562, 'Total loss': 0.8390473059632562} | train loss {'Reaction outcome loss': 0.8260930452028267, 'Total loss': 0.8260930452028267}
2022-11-18 03:07:20,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:20,871 INFO:     Epoch: 39
2022-11-18 03:07:21,666 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8351854546503588, 'Total loss': 0.8351854546503588} | train loss {'Reaction outcome loss': 0.8404500222640482, 'Total loss': 0.8404500222640482}
2022-11-18 03:07:21,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:21,666 INFO:     Epoch: 40
2022-11-18 03:07:22,446 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8580608361146667, 'Total loss': 0.8580608361146667} | train loss {'Reaction outcome loss': 0.8324535501449697, 'Total loss': 0.8324535501449697}
2022-11-18 03:07:22,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:22,447 INFO:     Epoch: 41
2022-11-18 03:07:23,284 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8574117537249218, 'Total loss': 0.8574117537249218} | train loss {'Reaction outcome loss': 0.8294046913925935, 'Total loss': 0.8294046913925935}
2022-11-18 03:07:23,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:23,284 INFO:     Epoch: 42
2022-11-18 03:07:24,086 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8387040651657365, 'Total loss': 0.8387040651657365} | train loss {'Reaction outcome loss': 0.8362436728921496, 'Total loss': 0.8362436728921496}
2022-11-18 03:07:24,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:24,087 INFO:     Epoch: 43
2022-11-18 03:07:24,898 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8336200998588041, 'Total loss': 0.8336200998588041} | train loss {'Reaction outcome loss': 0.8438878513058188, 'Total loss': 0.8438878513058188}
2022-11-18 03:07:24,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:24,898 INFO:     Epoch: 44
2022-11-18 03:07:25,710 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8309481184590947, 'Total loss': 0.8309481184590947} | train loss {'Reaction outcome loss': 0.8392119950611099, 'Total loss': 0.8392119950611099}
2022-11-18 03:07:25,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:25,711 INFO:     Epoch: 45
2022-11-18 03:07:26,540 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8332147428935225, 'Total loss': 0.8332147428935225} | train loss {'Reaction outcome loss': 0.8288447714678431, 'Total loss': 0.8288447714678431}
2022-11-18 03:07:26,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:26,540 INFO:     Epoch: 46
2022-11-18 03:07:27,346 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8355711156671698, 'Total loss': 0.8355711156671698} | train loss {'Reaction outcome loss': 0.8240293666177433, 'Total loss': 0.8240293666177433}
2022-11-18 03:07:27,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:27,346 INFO:     Epoch: 47
2022-11-18 03:07:28,166 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.830555988306349, 'Total loss': 0.830555988306349} | train loss {'Reaction outcome loss': 0.8278337068523955, 'Total loss': 0.8278337068523955}
2022-11-18 03:07:28,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:28,166 INFO:     Epoch: 48
2022-11-18 03:07:28,977 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.845346141945232, 'Total loss': 0.845346141945232} | train loss {'Reaction outcome loss': 0.8369621242950802, 'Total loss': 0.8369621242950802}
2022-11-18 03:07:28,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:28,977 INFO:     Epoch: 49
2022-11-18 03:07:29,810 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.839127392931418, 'Total loss': 0.839127392931418} | train loss {'Reaction outcome loss': 0.8382146348837416, 'Total loss': 0.8382146348837416}
2022-11-18 03:07:29,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:29,812 INFO:     Epoch: 50
2022-11-18 03:07:30,623 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8302474550225518, 'Total loss': 0.8302474550225518} | train loss {'Reaction outcome loss': 0.8312008029475868, 'Total loss': 0.8312008029475868}
2022-11-18 03:07:30,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:30,624 INFO:     Epoch: 51
2022-11-18 03:07:31,457 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8375317488204349, 'Total loss': 0.8375317488204349} | train loss {'Reaction outcome loss': 0.8249153521982765, 'Total loss': 0.8249153521982765}
2022-11-18 03:07:31,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:31,458 INFO:     Epoch: 52
2022-11-18 03:07:32,277 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8377039446072145, 'Total loss': 0.8377039446072145} | train loss {'Reaction outcome loss': 0.8302020125302226, 'Total loss': 0.8302020125302226}
2022-11-18 03:07:32,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:32,277 INFO:     Epoch: 53
2022-11-18 03:07:33,076 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8556303456425667, 'Total loss': 0.8556303456425667} | train loss {'Reaction outcome loss': 0.8315574211871576, 'Total loss': 0.8315574211871576}
2022-11-18 03:07:33,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:33,076 INFO:     Epoch: 54
2022-11-18 03:07:33,914 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8386349799958143, 'Total loss': 0.8386349799958143} | train loss {'Reaction outcome loss': 0.8325554011201086, 'Total loss': 0.8325554011201086}
2022-11-18 03:07:33,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:33,914 INFO:     Epoch: 55
2022-11-18 03:07:34,715 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.829372800886631, 'Total loss': 0.829372800886631} | train loss {'Reaction outcome loss': 0.8248943221955164, 'Total loss': 0.8248943221955164}
2022-11-18 03:07:34,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:34,716 INFO:     Epoch: 56
2022-11-18 03:07:35,501 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.843089151111516, 'Total loss': 0.843089151111516} | train loss {'Reaction outcome loss': 0.8287226509167115, 'Total loss': 0.8287226509167115}
2022-11-18 03:07:35,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:35,502 INFO:     Epoch: 57
2022-11-18 03:07:36,342 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8399457660588351, 'Total loss': 0.8399457660588351} | train loss {'Reaction outcome loss': 0.8295143708164393, 'Total loss': 0.8295143708164393}
2022-11-18 03:07:36,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:36,344 INFO:     Epoch: 58
2022-11-18 03:07:37,121 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8621470792727037, 'Total loss': 0.8621470792727037} | train loss {'Reaction outcome loss': 0.8318210805234639, 'Total loss': 0.8318210805234639}
2022-11-18 03:07:37,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:37,122 INFO:     Epoch: 59
2022-11-18 03:07:37,899 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8401772413741458, 'Total loss': 0.8401772413741458} | train loss {'Reaction outcome loss': 0.8300649968960024, 'Total loss': 0.8300649968960024}
2022-11-18 03:07:37,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:37,899 INFO:     Epoch: 60
2022-11-18 03:07:38,699 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.830377764322541, 'Total loss': 0.830377764322541} | train loss {'Reaction outcome loss': 0.8364117297566371, 'Total loss': 0.8364117297566371}
2022-11-18 03:07:38,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:38,699 INFO:     Epoch: 61
2022-11-18 03:07:39,509 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8423226746645841, 'Total loss': 0.8423226746645841} | train loss {'Reaction outcome loss': 0.8387603958849965, 'Total loss': 0.8387603958849965}
2022-11-18 03:07:39,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:39,510 INFO:     Epoch: 62
2022-11-18 03:07:40,313 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8330890576947819, 'Total loss': 0.8330890576947819} | train loss {'Reaction outcome loss': 0.82740430190013, 'Total loss': 0.82740430190013}
2022-11-18 03:07:40,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:40,313 INFO:     Epoch: 63
2022-11-18 03:07:41,101 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8382120660760186, 'Total loss': 0.8382120660760186} | train loss {'Reaction outcome loss': 0.8284386786130759, 'Total loss': 0.8284386786130759}
2022-11-18 03:07:41,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:41,101 INFO:     Epoch: 64
2022-11-18 03:07:41,878 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.83572391691533, 'Total loss': 0.83572391691533} | train loss {'Reaction outcome loss': 0.8361768180783461, 'Total loss': 0.8361768180783461}
2022-11-18 03:07:41,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:41,878 INFO:     Epoch: 65
2022-11-18 03:07:42,664 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8487338085066188, 'Total loss': 0.8487338085066188} | train loss {'Reaction outcome loss': 0.8347189411943258, 'Total loss': 0.8347189411943258}
2022-11-18 03:07:42,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:42,664 INFO:     Epoch: 66
2022-11-18 03:07:43,461 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8292249684984033, 'Total loss': 0.8292249684984033} | train loss {'Reaction outcome loss': 0.840091160917089, 'Total loss': 0.840091160917089}
2022-11-18 03:07:43,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:43,462 INFO:     Epoch: 67
2022-11-18 03:07:44,230 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8389290517026727, 'Total loss': 0.8389290517026727} | train loss {'Reaction outcome loss': 0.8369248075041211, 'Total loss': 0.8369248075041211}
2022-11-18 03:07:44,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:44,231 INFO:     Epoch: 68
2022-11-18 03:07:45,035 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8244208449667151, 'Total loss': 0.8244208449667151} | train loss {'Reaction outcome loss': 0.8342535750344697, 'Total loss': 0.8342535750344697}
2022-11-18 03:07:45,035 INFO:     Found new best model at epoch 68
2022-11-18 03:07:45,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:45,036 INFO:     Epoch: 69
2022-11-18 03:07:45,819 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8119109039279547, 'Total loss': 0.8119109039279547} | train loss {'Reaction outcome loss': 0.8374049241243586, 'Total loss': 0.8374049241243586}
2022-11-18 03:07:45,819 INFO:     Found new best model at epoch 69
2022-11-18 03:07:45,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:45,820 INFO:     Epoch: 70
2022-11-18 03:07:46,617 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8265814307061109, 'Total loss': 0.8265814307061109} | train loss {'Reaction outcome loss': 0.8256214950912395, 'Total loss': 0.8256214950912395}
2022-11-18 03:07:46,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:46,618 INFO:     Epoch: 71
2022-11-18 03:07:47,384 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8403969617052511, 'Total loss': 0.8403969617052511} | train loss {'Reaction outcome loss': 0.8288952042216714, 'Total loss': 0.8288952042216714}
2022-11-18 03:07:47,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:47,384 INFO:     Epoch: 72
2022-11-18 03:07:48,165 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8307510980150916, 'Total loss': 0.8307510980150916} | train loss {'Reaction outcome loss': 0.830272110005622, 'Total loss': 0.830272110005622}
2022-11-18 03:07:48,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:48,165 INFO:     Epoch: 73
2022-11-18 03:07:48,946 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8271957500414415, 'Total loss': 0.8271957500414415} | train loss {'Reaction outcome loss': 0.8270591785791914, 'Total loss': 0.8270591785791914}
2022-11-18 03:07:48,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:48,948 INFO:     Epoch: 74
2022-11-18 03:07:49,711 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8294216062534939, 'Total loss': 0.8294216062534939} | train loss {'Reaction outcome loss': 0.8330444784058251, 'Total loss': 0.8330444784058251}
2022-11-18 03:07:49,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:49,711 INFO:     Epoch: 75
2022-11-18 03:07:50,475 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8384843902154402, 'Total loss': 0.8384843902154402} | train loss {'Reaction outcome loss': 0.8283455209271146, 'Total loss': 0.8283455209271146}
2022-11-18 03:07:50,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:50,475 INFO:     Epoch: 76
2022-11-18 03:07:51,266 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8513443327762864, 'Total loss': 0.8513443327762864} | train loss {'Reaction outcome loss': 0.827083993295909, 'Total loss': 0.827083993295909}
2022-11-18 03:07:51,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:51,267 INFO:     Epoch: 77
2022-11-18 03:07:52,028 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8274999958547679, 'Total loss': 0.8274999958547679} | train loss {'Reaction outcome loss': 0.834236204624176, 'Total loss': 0.834236204624176}
2022-11-18 03:07:52,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:52,029 INFO:     Epoch: 78
2022-11-18 03:07:52,815 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8244205032559958, 'Total loss': 0.8244205032559958} | train loss {'Reaction outcome loss': 0.8262938758139668, 'Total loss': 0.8262938758139668}
2022-11-18 03:07:52,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:52,815 INFO:     Epoch: 79
2022-11-18 03:07:53,620 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8365105227990584, 'Total loss': 0.8365105227990584} | train loss {'Reaction outcome loss': 0.8342418884217497, 'Total loss': 0.8342418884217497}
2022-11-18 03:07:53,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:53,620 INFO:     Epoch: 80
2022-11-18 03:07:54,419 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8494114598089998, 'Total loss': 0.8494114598089998} | train loss {'Reaction outcome loss': 0.830325156593552, 'Total loss': 0.830325156593552}
2022-11-18 03:07:54,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:54,419 INFO:     Epoch: 81
2022-11-18 03:07:55,196 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.842073109339584, 'Total loss': 0.842073109339584} | train loss {'Reaction outcome loss': 0.8273233422021634, 'Total loss': 0.8273233422021634}
2022-11-18 03:07:55,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:55,197 INFO:     Epoch: 82
2022-11-18 03:07:55,963 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8313702866435051, 'Total loss': 0.8313702866435051} | train loss {'Reaction outcome loss': 0.8283429735826577, 'Total loss': 0.8283429735826577}
2022-11-18 03:07:55,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:55,963 INFO:     Epoch: 83
2022-11-18 03:07:56,758 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8402812806042758, 'Total loss': 0.8402812806042758} | train loss {'Reaction outcome loss': 0.8276895540445922, 'Total loss': 0.8276895540445922}
2022-11-18 03:07:56,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:56,758 INFO:     Epoch: 84
2022-11-18 03:07:57,543 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.82777915624055, 'Total loss': 0.82777915624055} | train loss {'Reaction outcome loss': 0.8287848851941375, 'Total loss': 0.8287848851941375}
2022-11-18 03:07:57,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:57,543 INFO:     Epoch: 85
2022-11-18 03:07:58,321 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8448087166656147, 'Total loss': 0.8448087166656147} | train loss {'Reaction outcome loss': 0.8265455863796748, 'Total loss': 0.8265455863796748}
2022-11-18 03:07:58,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:58,322 INFO:     Epoch: 86
2022-11-18 03:07:59,100 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8288252367214723, 'Total loss': 0.8288252367214723} | train loss {'Reaction outcome loss': 0.8277396814301912, 'Total loss': 0.8277396814301912}
2022-11-18 03:07:59,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:59,101 INFO:     Epoch: 87
2022-11-18 03:07:59,905 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8382098796692762, 'Total loss': 0.8382098796692762} | train loss {'Reaction outcome loss': 0.8321484220836327, 'Total loss': 0.8321484220836327}
2022-11-18 03:07:59,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:07:59,905 INFO:     Epoch: 88
2022-11-18 03:08:00,674 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8283986862410199, 'Total loss': 0.8283986862410199} | train loss {'Reaction outcome loss': 0.829806410108018, 'Total loss': 0.829806410108018}
2022-11-18 03:08:00,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:00,675 INFO:     Epoch: 89
2022-11-18 03:08:01,438 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8497277288274332, 'Total loss': 0.8497277288274332} | train loss {'Reaction outcome loss': 0.8317995082270279, 'Total loss': 0.8317995082270279}
2022-11-18 03:08:01,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:01,438 INFO:     Epoch: 90
2022-11-18 03:08:02,215 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.839794471859932, 'Total loss': 0.839794471859932} | train loss {'Reaction outcome loss': 0.8349587216309691, 'Total loss': 0.8349587216309691}
2022-11-18 03:08:02,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:02,216 INFO:     Epoch: 91
2022-11-18 03:08:02,993 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8372560062191703, 'Total loss': 0.8372560062191703} | train loss {'Reaction outcome loss': 0.8326876279313554, 'Total loss': 0.8326876279313554}
2022-11-18 03:08:02,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:02,994 INFO:     Epoch: 92
2022-11-18 03:08:03,764 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8306957388466055, 'Total loss': 0.8306957388466055} | train loss {'Reaction outcome loss': 0.8371019913600042, 'Total loss': 0.8371019913600042}
2022-11-18 03:08:03,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:03,764 INFO:     Epoch: 93
2022-11-18 03:08:04,547 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8373235179619356, 'Total loss': 0.8373235179619356} | train loss {'Reaction outcome loss': 0.8342449459952381, 'Total loss': 0.8342449459952381}
2022-11-18 03:08:04,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:04,547 INFO:     Epoch: 94
2022-11-18 03:08:05,358 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8365762789141048, 'Total loss': 0.8365762789141048} | train loss {'Reaction outcome loss': 0.8365213650199566, 'Total loss': 0.8365213650199566}
2022-11-18 03:08:05,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:05,358 INFO:     Epoch: 95
2022-11-18 03:08:06,143 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8311874405904249, 'Total loss': 0.8311874405904249} | train loss {'Reaction outcome loss': 0.8292613972415809, 'Total loss': 0.8292613972415809}
2022-11-18 03:08:06,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:06,143 INFO:     Epoch: 96
2022-11-18 03:08:06,947 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8231406970457598, 'Total loss': 0.8231406970457598} | train loss {'Reaction outcome loss': 0.8344538098404765, 'Total loss': 0.8344538098404765}
2022-11-18 03:08:06,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:06,948 INFO:     Epoch: 97
2022-11-18 03:08:07,715 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8304421590133146, 'Total loss': 0.8304421590133146} | train loss {'Reaction outcome loss': 0.8335030928314456, 'Total loss': 0.8335030928314456}
2022-11-18 03:08:07,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:07,715 INFO:     Epoch: 98
2022-11-18 03:08:08,499 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8291867050257596, 'Total loss': 0.8291867050257596} | train loss {'Reaction outcome loss': 0.8305085425676122, 'Total loss': 0.8305085425676122}
2022-11-18 03:08:08,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:08,499 INFO:     Epoch: 99
2022-11-18 03:08:09,274 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8262469226663763, 'Total loss': 0.8262469226663763} | train loss {'Reaction outcome loss': 0.8288926366369734, 'Total loss': 0.8288926366369734}
2022-11-18 03:08:09,274 INFO:     Best model found after epoch 70 of 100.
2022-11-18 03:08:09,275 INFO:   Done with stage: TRAINING
2022-11-18 03:08:09,275 INFO:   Starting stage: EVALUATION
2022-11-18 03:08:09,398 INFO:   Done with stage: EVALUATION
2022-11-18 03:08:09,407 INFO:   Leaving out SEQ value Fold_0
2022-11-18 03:08:09,420 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 03:08:09,420 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:08:10,089 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:08:10,089 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:08:10,159 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:08:10,159 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:08:10,159 INFO:     No hyperparam tuning for this model
2022-11-18 03:08:10,159 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:08:10,159 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:08:10,160 INFO:     None feature selector for col prot
2022-11-18 03:08:10,160 INFO:     None feature selector for col prot
2022-11-18 03:08:10,160 INFO:     None feature selector for col prot
2022-11-18 03:08:10,161 INFO:     None feature selector for col chem
2022-11-18 03:08:10,161 INFO:     None feature selector for col chem
2022-11-18 03:08:10,161 INFO:     None feature selector for col chem
2022-11-18 03:08:10,161 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:08:10,161 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:08:10,162 INFO:     Number of params in model 168571
2022-11-18 03:08:10,166 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:08:10,166 INFO:   Starting stage: TRAINING
2022-11-18 03:08:10,224 INFO:     Val loss before train {'Reaction outcome loss': 0.9631133953278715, 'Total loss': 0.9631133953278715}
2022-11-18 03:08:10,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:10,224 INFO:     Epoch: 0
2022-11-18 03:08:11,007 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8177786713296716, 'Total loss': 0.8177786713296716} | train loss {'Reaction outcome loss': 0.890703925186274, 'Total loss': 0.890703925186274}
2022-11-18 03:08:11,007 INFO:     Found new best model at epoch 0
2022-11-18 03:08:11,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:11,008 INFO:     Epoch: 1
2022-11-18 03:08:11,758 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7978069985454733, 'Total loss': 0.7978069985454733} | train loss {'Reaction outcome loss': 0.8563503131574514, 'Total loss': 0.8563503131574514}
2022-11-18 03:08:11,758 INFO:     Found new best model at epoch 1
2022-11-18 03:08:11,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:11,759 INFO:     Epoch: 2
2022-11-18 03:08:12,568 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8178122700615362, 'Total loss': 0.8178122700615362} | train loss {'Reaction outcome loss': 0.8516940158240649, 'Total loss': 0.8516940158240649}
2022-11-18 03:08:12,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:12,569 INFO:     Epoch: 3
2022-11-18 03:08:13,396 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8028201901099898, 'Total loss': 0.8028201901099898} | train loss {'Reaction outcome loss': 0.8490466003515282, 'Total loss': 0.8490466003515282}
2022-11-18 03:08:13,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:13,397 INFO:     Epoch: 4
2022-11-18 03:08:14,219 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7959913198243488, 'Total loss': 0.7959913198243488} | train loss {'Reaction outcome loss': 0.8421393844546105, 'Total loss': 0.8421393844546105}
2022-11-18 03:08:14,219 INFO:     Found new best model at epoch 4
2022-11-18 03:08:14,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:14,220 INFO:     Epoch: 5
2022-11-18 03:08:15,102 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.798488861457868, 'Total loss': 0.798488861457868} | train loss {'Reaction outcome loss': 0.8383859644130784, 'Total loss': 0.8383859644130784}
2022-11-18 03:08:15,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:15,102 INFO:     Epoch: 6
2022-11-18 03:08:15,885 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7715026174079288, 'Total loss': 0.7715026174079288} | train loss {'Reaction outcome loss': 0.8301782469360196, 'Total loss': 0.8301782469360196}
2022-11-18 03:08:15,885 INFO:     Found new best model at epoch 6
2022-11-18 03:08:15,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:15,886 INFO:     Epoch: 7
2022-11-18 03:08:16,665 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7969206320968542, 'Total loss': 0.7969206320968542} | train loss {'Reaction outcome loss': 0.8288007407772298, 'Total loss': 0.8288007407772298}
2022-11-18 03:08:16,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:16,665 INFO:     Epoch: 8
2022-11-18 03:08:17,475 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7963205542076718, 'Total loss': 0.7963205542076718} | train loss {'Reaction outcome loss': 0.8220591104760462, 'Total loss': 0.8220591104760462}
2022-11-18 03:08:17,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:17,476 INFO:     Epoch: 9
2022-11-18 03:08:18,246 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7811261374842037, 'Total loss': 0.7811261374842037} | train loss {'Reaction outcome loss': 0.8288844534329005, 'Total loss': 0.8288844534329005}
2022-11-18 03:08:18,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:18,246 INFO:     Epoch: 10
2022-11-18 03:08:19,038 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7686837701634928, 'Total loss': 0.7686837701634928} | train loss {'Reaction outcome loss': 0.8228636467943387, 'Total loss': 0.8228636467943387}
2022-11-18 03:08:19,039 INFO:     Found new best model at epoch 10
2022-11-18 03:08:19,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:19,039 INFO:     Epoch: 11
2022-11-18 03:08:19,807 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7841170680793849, 'Total loss': 0.7841170680793849} | train loss {'Reaction outcome loss': 0.8219065269645379, 'Total loss': 0.8219065269645379}
2022-11-18 03:08:19,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:19,807 INFO:     Epoch: 12
2022-11-18 03:08:20,570 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7745962515473366, 'Total loss': 0.7745962515473366} | train loss {'Reaction outcome loss': 0.8238926440477371, 'Total loss': 0.8238926440477371}
2022-11-18 03:08:20,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:20,570 INFO:     Epoch: 13
2022-11-18 03:08:21,397 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8005109063603661, 'Total loss': 0.8005109063603661} | train loss {'Reaction outcome loss': 0.8236801520902284, 'Total loss': 0.8236801520902284}
2022-11-18 03:08:21,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:21,398 INFO:     Epoch: 14
2022-11-18 03:08:22,207 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7886833772063255, 'Total loss': 0.7886833772063255} | train loss {'Reaction outcome loss': 0.8208313931007775, 'Total loss': 0.8208313931007775}
2022-11-18 03:08:22,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:22,207 INFO:     Epoch: 15
2022-11-18 03:08:23,022 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7813031470233743, 'Total loss': 0.7813031470233743} | train loss {'Reaction outcome loss': 0.8229932607436666, 'Total loss': 0.8229932607436666}
2022-11-18 03:08:23,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:23,023 INFO:     Epoch: 16
2022-11-18 03:08:23,802 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7781110595573079, 'Total loss': 0.7781110595573079} | train loss {'Reaction outcome loss': 0.8212541720088647, 'Total loss': 0.8212541720088647}
2022-11-18 03:08:23,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:23,803 INFO:     Epoch: 17
2022-11-18 03:08:24,570 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7774205329743299, 'Total loss': 0.7774205329743299} | train loss {'Reaction outcome loss': 0.8188966333866119, 'Total loss': 0.8188966333866119}
2022-11-18 03:08:24,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:24,571 INFO:     Epoch: 18
2022-11-18 03:08:25,365 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7833308706229384, 'Total loss': 0.7833308706229384} | train loss {'Reaction outcome loss': 0.8186642632192495, 'Total loss': 0.8186642632192495}
2022-11-18 03:08:25,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:25,366 INFO:     Epoch: 19
2022-11-18 03:08:26,161 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8053912066600539, 'Total loss': 0.8053912066600539} | train loss {'Reaction outcome loss': 0.8201203272050741, 'Total loss': 0.8201203272050741}
2022-11-18 03:08:26,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:26,161 INFO:     Epoch: 20
2022-11-18 03:08:26,966 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7927014150402762, 'Total loss': 0.7927014150402762} | train loss {'Reaction outcome loss': 0.8216349905850936, 'Total loss': 0.8216349905850936}
2022-11-18 03:08:26,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:26,967 INFO:     Epoch: 21
2022-11-18 03:08:27,742 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7680485268885439, 'Total loss': 0.7680485268885439} | train loss {'Reaction outcome loss': 0.8200127809631581, 'Total loss': 0.8200127809631581}
2022-11-18 03:08:27,742 INFO:     Found new best model at epoch 21
2022-11-18 03:08:27,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:27,743 INFO:     Epoch: 22
2022-11-18 03:08:28,536 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7852830270474608, 'Total loss': 0.7852830270474608} | train loss {'Reaction outcome loss': 0.8206696989584942, 'Total loss': 0.8206696989584942}
2022-11-18 03:08:28,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:28,537 INFO:     Epoch: 23
2022-11-18 03:08:29,357 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.785758571868593, 'Total loss': 0.785758571868593} | train loss {'Reaction outcome loss': 0.8217301403989598, 'Total loss': 0.8217301403989598}
2022-11-18 03:08:29,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:29,357 INFO:     Epoch: 24
2022-11-18 03:08:30,138 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7834844839843836, 'Total loss': 0.7834844839843836} | train loss {'Reaction outcome loss': 0.8178191215408092, 'Total loss': 0.8178191215408092}
2022-11-18 03:08:30,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:30,138 INFO:     Epoch: 25
2022-11-18 03:08:30,952 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7883110623806715, 'Total loss': 0.7883110623806715} | train loss {'Reaction outcome loss': 0.8183261885934946, 'Total loss': 0.8183261885934946}
2022-11-18 03:08:30,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:30,953 INFO:     Epoch: 26
2022-11-18 03:08:31,775 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7740830724889581, 'Total loss': 0.7740830724889581} | train loss {'Reaction outcome loss': 0.8204764501172669, 'Total loss': 0.8204764501172669}
2022-11-18 03:08:31,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:31,776 INFO:     Epoch: 27
2022-11-18 03:08:32,557 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7759510068730875, 'Total loss': 0.7759510068730875} | train loss {'Reaction outcome loss': 0.8197790394023973, 'Total loss': 0.8197790394023973}
2022-11-18 03:08:32,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:32,558 INFO:     Epoch: 28
2022-11-18 03:08:33,332 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8269376036795703, 'Total loss': 0.8269376036795703} | train loss {'Reaction outcome loss': 0.8199008220312547, 'Total loss': 0.8199008220312547}
2022-11-18 03:08:33,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:33,333 INFO:     Epoch: 29
2022-11-18 03:08:34,132 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.772521747784181, 'Total loss': 0.772521747784181} | train loss {'Reaction outcome loss': 0.8252195046872509, 'Total loss': 0.8252195046872509}
2022-11-18 03:08:34,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:34,132 INFO:     Epoch: 30
2022-11-18 03:08:34,925 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7928012643348087, 'Total loss': 0.7928012643348087} | train loss {'Reaction outcome loss': 0.8186889535310317, 'Total loss': 0.8186889535310317}
2022-11-18 03:08:34,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:34,926 INFO:     Epoch: 31
2022-11-18 03:08:35,723 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7757772078568285, 'Total loss': 0.7757772078568285} | train loss {'Reaction outcome loss': 0.821474852124039, 'Total loss': 0.821474852124039}
2022-11-18 03:08:35,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:35,723 INFO:     Epoch: 32
2022-11-18 03:08:36,529 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7803408239375461, 'Total loss': 0.7803408239375461} | train loss {'Reaction outcome loss': 0.8139419854903708, 'Total loss': 0.8139419854903708}
2022-11-18 03:08:36,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:36,529 INFO:     Epoch: 33
2022-11-18 03:08:37,327 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7577608403834429, 'Total loss': 0.7577608403834429} | train loss {'Reaction outcome loss': 0.8220972899271517, 'Total loss': 0.8220972899271517}
2022-11-18 03:08:37,328 INFO:     Found new best model at epoch 33
2022-11-18 03:08:37,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:37,328 INFO:     Epoch: 34
2022-11-18 03:08:38,113 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8127772841941227, 'Total loss': 0.8127772841941227} | train loss {'Reaction outcome loss': 0.8204311541148595, 'Total loss': 0.8204311541148595}
2022-11-18 03:08:38,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:38,114 INFO:     Epoch: 35
2022-11-18 03:08:38,939 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7783880247311159, 'Total loss': 0.7783880247311159} | train loss {'Reaction outcome loss': 0.8210065499860413, 'Total loss': 0.8210065499860413}
2022-11-18 03:08:38,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:38,939 INFO:     Epoch: 36
2022-11-18 03:08:39,743 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7790341167287393, 'Total loss': 0.7790341167287393} | train loss {'Reaction outcome loss': 0.8199448393315685, 'Total loss': 0.8199448393315685}
2022-11-18 03:08:39,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:39,744 INFO:     Epoch: 37
2022-11-18 03:08:40,578 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7918985492803834, 'Total loss': 0.7918985492803834} | train loss {'Reaction outcome loss': 0.8203666078801057, 'Total loss': 0.8203666078801057}
2022-11-18 03:08:40,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:40,578 INFO:     Epoch: 38
2022-11-18 03:08:41,376 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7968929349021479, 'Total loss': 0.7968929349021479} | train loss {'Reaction outcome loss': 0.8178786534435895, 'Total loss': 0.8178786534435895}
2022-11-18 03:08:41,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:41,376 INFO:     Epoch: 39
2022-11-18 03:08:42,201 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.788894768465649, 'Total loss': 0.788894768465649} | train loss {'Reaction outcome loss': 0.8144161085693203, 'Total loss': 0.8144161085693203}
2022-11-18 03:08:42,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:42,201 INFO:     Epoch: 40
2022-11-18 03:08:43,007 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7687234309586611, 'Total loss': 0.7687234309586611} | train loss {'Reaction outcome loss': 0.8200290760215447, 'Total loss': 0.8200290760215447}
2022-11-18 03:08:43,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:43,008 INFO:     Epoch: 41
2022-11-18 03:08:43,791 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7795426168225028, 'Total loss': 0.7795426168225028} | train loss {'Reaction outcome loss': 0.8194776319727606, 'Total loss': 0.8194776319727606}
2022-11-18 03:08:43,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:43,791 INFO:     Epoch: 42
2022-11-18 03:08:44,566 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7867589884183623, 'Total loss': 0.7867589884183623} | train loss {'Reaction outcome loss': 0.8245732789136926, 'Total loss': 0.8245732789136926}
2022-11-18 03:08:44,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:44,566 INFO:     Epoch: 43
2022-11-18 03:08:45,366 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7913557311350649, 'Total loss': 0.7913557311350649} | train loss {'Reaction outcome loss': 0.8223370699249968, 'Total loss': 0.8223370699249968}
2022-11-18 03:08:45,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:45,366 INFO:     Epoch: 44
2022-11-18 03:08:46,140 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7942922562360764, 'Total loss': 0.7942922562360764} | train loss {'Reaction outcome loss': 0.8213775508257808, 'Total loss': 0.8213775508257808}
2022-11-18 03:08:46,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:46,140 INFO:     Epoch: 45
2022-11-18 03:08:46,948 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7768434380943124, 'Total loss': 0.7768434380943124} | train loss {'Reaction outcome loss': 0.8178428174281607, 'Total loss': 0.8178428174281607}
2022-11-18 03:08:46,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:46,948 INFO:     Epoch: 46
2022-11-18 03:08:47,696 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.799133874475956, 'Total loss': 0.799133874475956} | train loss {'Reaction outcome loss': 0.8160992201493711, 'Total loss': 0.8160992201493711}
2022-11-18 03:08:47,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:47,697 INFO:     Epoch: 47
2022-11-18 03:08:48,454 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7766778828068213, 'Total loss': 0.7766778828068213} | train loss {'Reaction outcome loss': 0.8243246382596542, 'Total loss': 0.8243246382596542}
2022-11-18 03:08:48,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:48,455 INFO:     Epoch: 48
2022-11-18 03:08:49,218 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7883447415449403, 'Total loss': 0.7883447415449403} | train loss {'Reaction outcome loss': 0.817677635441021, 'Total loss': 0.817677635441021}
2022-11-18 03:08:49,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:49,218 INFO:     Epoch: 49
2022-11-18 03:08:49,984 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7619493068619207, 'Total loss': 0.7619493068619207} | train loss {'Reaction outcome loss': 0.8243475231589104, 'Total loss': 0.8243475231589104}
2022-11-18 03:08:49,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:49,985 INFO:     Epoch: 50
2022-11-18 03:08:50,789 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7907841727137566, 'Total loss': 0.7907841727137566} | train loss {'Reaction outcome loss': 0.8159853384202841, 'Total loss': 0.8159853384202841}
2022-11-18 03:08:50,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:50,790 INFO:     Epoch: 51
2022-11-18 03:08:51,566 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7692455283620141, 'Total loss': 0.7692455283620141} | train loss {'Reaction outcome loss': 0.8199606053683223, 'Total loss': 0.8199606053683223}
2022-11-18 03:08:51,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:51,566 INFO:     Epoch: 52
2022-11-18 03:08:52,344 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.786990378390659, 'Total loss': 0.786990378390659} | train loss {'Reaction outcome loss': 0.8185114999206698, 'Total loss': 0.8185114999206698}
2022-11-18 03:08:52,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:52,344 INFO:     Epoch: 53
2022-11-18 03:08:53,130 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.786267948421565, 'Total loss': 0.786267948421565} | train loss {'Reaction outcome loss': 0.8205615380588843, 'Total loss': 0.8205615380588843}
2022-11-18 03:08:53,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:53,131 INFO:     Epoch: 54
2022-11-18 03:08:53,889 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7907689179886471, 'Total loss': 0.7907689179886471} | train loss {'Reaction outcome loss': 0.8177755849702018, 'Total loss': 0.8177755849702018}
2022-11-18 03:08:53,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:53,889 INFO:     Epoch: 55
2022-11-18 03:08:54,670 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7787522809071974, 'Total loss': 0.7787522809071974} | train loss {'Reaction outcome loss': 0.8186440003161528, 'Total loss': 0.8186440003161528}
2022-11-18 03:08:54,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:54,671 INFO:     Epoch: 56
2022-11-18 03:08:55,464 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7755830403078686, 'Total loss': 0.7755830403078686} | train loss {'Reaction outcome loss': 0.8194993184537304, 'Total loss': 0.8194993184537304}
2022-11-18 03:08:55,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:55,464 INFO:     Epoch: 57
2022-11-18 03:08:56,255 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8038515252145854, 'Total loss': 0.8038515252145854} | train loss {'Reaction outcome loss': 0.8193809655247902, 'Total loss': 0.8193809655247902}
2022-11-18 03:08:56,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:56,256 INFO:     Epoch: 58
2022-11-18 03:08:57,080 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7605812163515524, 'Total loss': 0.7605812163515524} | train loss {'Reaction outcome loss': 0.8173417240989451, 'Total loss': 0.8173417240989451}
2022-11-18 03:08:57,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:57,080 INFO:     Epoch: 59
2022-11-18 03:08:57,883 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.781436947259036, 'Total loss': 0.781436947259036} | train loss {'Reaction outcome loss': 0.8184338108617433, 'Total loss': 0.8184338108617433}
2022-11-18 03:08:57,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:57,883 INFO:     Epoch: 60
2022-11-18 03:08:58,684 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7726965333250436, 'Total loss': 0.7726965333250436} | train loss {'Reaction outcome loss': 0.8180025324529531, 'Total loss': 0.8180025324529531}
2022-11-18 03:08:58,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:58,684 INFO:     Epoch: 61
2022-11-18 03:08:59,501 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7820858725092628, 'Total loss': 0.7820858725092628} | train loss {'Reaction outcome loss': 0.8198576281265336, 'Total loss': 0.8198576281265336}
2022-11-18 03:08:59,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:08:59,501 INFO:     Epoch: 62
2022-11-18 03:09:00,287 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7840781780806455, 'Total loss': 0.7840781780806455} | train loss {'Reaction outcome loss': 0.8206354633885987, 'Total loss': 0.8206354633885987}
2022-11-18 03:09:00,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:00,287 INFO:     Epoch: 63
2022-11-18 03:09:01,061 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7820248529314995, 'Total loss': 0.7820248529314995} | train loss {'Reaction outcome loss': 0.8213820611944004, 'Total loss': 0.8213820611944004}
2022-11-18 03:09:01,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:01,061 INFO:     Epoch: 64
2022-11-18 03:09:01,859 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7765458056872542, 'Total loss': 0.7765458056872542} | train loss {'Reaction outcome loss': 0.8181400899984399, 'Total loss': 0.8181400899984399}
2022-11-18 03:09:01,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:01,859 INFO:     Epoch: 65
2022-11-18 03:09:02,685 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7801088413054292, 'Total loss': 0.7801088413054292} | train loss {'Reaction outcome loss': 0.8179861095486854, 'Total loss': 0.8179861095486854}
2022-11-18 03:09:02,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:02,686 INFO:     Epoch: 66
2022-11-18 03:09:03,534 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7758934199810028, 'Total loss': 0.7758934199810028} | train loss {'Reaction outcome loss': 0.8218879944207717, 'Total loss': 0.8218879944207717}
2022-11-18 03:09:03,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:03,534 INFO:     Epoch: 67
2022-11-18 03:09:04,320 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7793964506550268, 'Total loss': 0.7793964506550268} | train loss {'Reaction outcome loss': 0.8165335200270828, 'Total loss': 0.8165335200270828}
2022-11-18 03:09:04,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:04,320 INFO:     Epoch: 68
2022-11-18 03:09:05,114 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7810121645981615, 'Total loss': 0.7810121645981615} | train loss {'Reaction outcome loss': 0.8217514359221166, 'Total loss': 0.8217514359221166}
2022-11-18 03:09:05,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:05,115 INFO:     Epoch: 69
2022-11-18 03:09:05,918 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.787826657295227, 'Total loss': 0.787826657295227} | train loss {'Reaction outcome loss': 0.8168658996114926, 'Total loss': 0.8168658996114926}
2022-11-18 03:09:05,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:05,918 INFO:     Epoch: 70
2022-11-18 03:09:06,725 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8022107217799533, 'Total loss': 0.8022107217799533} | train loss {'Reaction outcome loss': 0.8182555129333419, 'Total loss': 0.8182555129333419}
2022-11-18 03:09:06,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:06,725 INFO:     Epoch: 71
2022-11-18 03:09:07,500 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7798175317319956, 'Total loss': 0.7798175317319956} | train loss {'Reaction outcome loss': 0.8234810175944348, 'Total loss': 0.8234810175944348}
2022-11-18 03:09:07,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:07,501 INFO:     Epoch: 72
2022-11-18 03:09:08,310 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7697413895617832, 'Total loss': 0.7697413895617832} | train loss {'Reaction outcome loss': 0.8167703735585116, 'Total loss': 0.8167703735585116}
2022-11-18 03:09:08,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:08,310 INFO:     Epoch: 73
2022-11-18 03:09:09,106 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7941949929703366, 'Total loss': 0.7941949929703366} | train loss {'Reaction outcome loss': 0.8202858381125392, 'Total loss': 0.8202858381125392}
2022-11-18 03:09:09,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:09,108 INFO:     Epoch: 74
2022-11-18 03:09:09,942 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7768416689200834, 'Total loss': 0.7768416689200834} | train loss {'Reaction outcome loss': 0.8252312292858046, 'Total loss': 0.8252312292858046}
2022-11-18 03:09:09,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:09,942 INFO:     Epoch: 75
2022-11-18 03:09:10,753 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.774546545337547, 'Total loss': 0.774546545337547} | train loss {'Reaction outcome loss': 0.8166037372180394, 'Total loss': 0.8166037372180394}
2022-11-18 03:09:10,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:10,753 INFO:     Epoch: 76
2022-11-18 03:09:11,532 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7960055768489838, 'Total loss': 0.7960055768489838} | train loss {'Reaction outcome loss': 0.8188605359622411, 'Total loss': 0.8188605359622411}
2022-11-18 03:09:11,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:11,533 INFO:     Epoch: 77
2022-11-18 03:09:12,306 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7665425843813203, 'Total loss': 0.7665425843813203} | train loss {'Reaction outcome loss': 0.8200661177537879, 'Total loss': 0.8200661177537879}
2022-11-18 03:09:12,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:12,307 INFO:     Epoch: 78
2022-11-18 03:09:13,077 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7749264843084596, 'Total loss': 0.7749264843084596} | train loss {'Reaction outcome loss': 0.8192806189157524, 'Total loss': 0.8192806189157524}
2022-11-18 03:09:13,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:13,077 INFO:     Epoch: 79
2022-11-18 03:09:13,854 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7706961977210912, 'Total loss': 0.7706961977210912} | train loss {'Reaction outcome loss': 0.820723908044854, 'Total loss': 0.820723908044854}
2022-11-18 03:09:13,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:13,854 INFO:     Epoch: 80
2022-11-18 03:09:14,615 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.781782828271389, 'Total loss': 0.781782828271389} | train loss {'Reaction outcome loss': 0.819680637486127, 'Total loss': 0.819680637486127}
2022-11-18 03:09:14,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:14,615 INFO:     Epoch: 81
2022-11-18 03:09:15,372 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7801711450923573, 'Total loss': 0.7801711450923573} | train loss {'Reaction outcome loss': 0.8161489129066467, 'Total loss': 0.8161489129066467}
2022-11-18 03:09:15,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:15,373 INFO:     Epoch: 82
2022-11-18 03:09:16,167 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7873088703914122, 'Total loss': 0.7873088703914122} | train loss {'Reaction outcome loss': 0.8170068801665793, 'Total loss': 0.8170068801665793}
2022-11-18 03:09:16,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:16,167 INFO:     Epoch: 83
2022-11-18 03:09:16,934 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7906844209540974, 'Total loss': 0.7906844209540974} | train loss {'Reaction outcome loss': 0.8221231891184437, 'Total loss': 0.8221231891184437}
2022-11-18 03:09:16,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:16,934 INFO:     Epoch: 84
2022-11-18 03:09:17,704 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.804542253640565, 'Total loss': 0.804542253640565} | train loss {'Reaction outcome loss': 0.8213957352297646, 'Total loss': 0.8213957352297646}
2022-11-18 03:09:17,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:17,704 INFO:     Epoch: 85
2022-11-18 03:09:18,494 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7731971530751749, 'Total loss': 0.7731971530751749} | train loss {'Reaction outcome loss': 0.8221085796550829, 'Total loss': 0.8221085796550829}
2022-11-18 03:09:18,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:18,495 INFO:     Epoch: 86
2022-11-18 03:09:19,281 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7851208428090269, 'Total loss': 0.7851208428090269} | train loss {'Reaction outcome loss': 0.8168572492745458, 'Total loss': 0.8168572492745458}
2022-11-18 03:09:19,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:19,282 INFO:     Epoch: 87
2022-11-18 03:09:20,050 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8069485459815372, 'Total loss': 0.8069485459815372} | train loss {'Reaction outcome loss': 0.8201483466187302, 'Total loss': 0.8201483466187302}
2022-11-18 03:09:20,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:20,050 INFO:     Epoch: 88
2022-11-18 03:09:20,864 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7743049153888767, 'Total loss': 0.7743049153888767} | train loss {'Reaction outcome loss': 0.8224913182307263, 'Total loss': 0.8224913182307263}
2022-11-18 03:09:20,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:20,865 INFO:     Epoch: 89
2022-11-18 03:09:21,710 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7771237458695065, 'Total loss': 0.7771237458695065} | train loss {'Reaction outcome loss': 0.8242334045925919, 'Total loss': 0.8242334045925919}
2022-11-18 03:09:21,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:21,711 INFO:     Epoch: 90
2022-11-18 03:09:22,511 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7833551845767281, 'Total loss': 0.7833551845767281} | train loss {'Reaction outcome loss': 0.8219145914729761, 'Total loss': 0.8219145914729761}
2022-11-18 03:09:22,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:22,512 INFO:     Epoch: 91
2022-11-18 03:09:23,307 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8030273467302322, 'Total loss': 0.8030273467302322} | train loss {'Reaction outcome loss': 0.8229396551239248, 'Total loss': 0.8229396551239248}
2022-11-18 03:09:23,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:23,308 INFO:     Epoch: 92
2022-11-18 03:09:24,120 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7936985357241197, 'Total loss': 0.7936985357241197} | train loss {'Reaction outcome loss': 0.8208783290824112, 'Total loss': 0.8208783290824112}
2022-11-18 03:09:24,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:24,120 INFO:     Epoch: 93
2022-11-18 03:09:24,936 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7853586247021501, 'Total loss': 0.7853586247021501} | train loss {'Reaction outcome loss': 0.82028115890464, 'Total loss': 0.82028115890464}
2022-11-18 03:09:24,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:24,937 INFO:     Epoch: 94
2022-11-18 03:09:25,752 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7896770652044903, 'Total loss': 0.7896770652044903} | train loss {'Reaction outcome loss': 0.8163977221566804, 'Total loss': 0.8163977221566804}
2022-11-18 03:09:25,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:25,753 INFO:     Epoch: 95
2022-11-18 03:09:26,537 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7688654559579763, 'Total loss': 0.7688654559579763} | train loss {'Reaction outcome loss': 0.8202464736237818, 'Total loss': 0.8202464736237818}
2022-11-18 03:09:26,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:26,538 INFO:     Epoch: 96
2022-11-18 03:09:27,341 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7652438608082858, 'Total loss': 0.7652438608082858} | train loss {'Reaction outcome loss': 0.8241174835331586, 'Total loss': 0.8241174835331586}
2022-11-18 03:09:27,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:27,341 INFO:     Epoch: 97
2022-11-18 03:09:28,148 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.782880917868831, 'Total loss': 0.782880917868831} | train loss {'Reaction outcome loss': 0.8180809029511042, 'Total loss': 0.8180809029511042}
2022-11-18 03:09:28,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:28,149 INFO:     Epoch: 98
2022-11-18 03:09:28,976 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7870723747394301, 'Total loss': 0.7870723747394301} | train loss {'Reaction outcome loss': 0.8177336928795795, 'Total loss': 0.8177336928795795}
2022-11-18 03:09:28,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:28,977 INFO:     Epoch: 99
2022-11-18 03:09:29,787 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7951592471111905, 'Total loss': 0.7951592471111905} | train loss {'Reaction outcome loss': 0.8205018382899615, 'Total loss': 0.8205018382899615}
2022-11-18 03:09:29,787 INFO:     Best model found after epoch 34 of 100.
2022-11-18 03:09:29,787 INFO:   Done with stage: TRAINING
2022-11-18 03:09:29,787 INFO:   Starting stage: EVALUATION
2022-11-18 03:09:29,916 INFO:   Done with stage: EVALUATION
2022-11-18 03:09:29,916 INFO:   Leaving out SEQ value Fold_1
2022-11-18 03:09:29,930 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 03:09:29,930 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:09:30,595 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:09:30,595 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:09:30,664 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:09:30,664 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:09:30,664 INFO:     No hyperparam tuning for this model
2022-11-18 03:09:30,664 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:09:30,664 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:09:30,665 INFO:     None feature selector for col prot
2022-11-18 03:09:30,665 INFO:     None feature selector for col prot
2022-11-18 03:09:30,665 INFO:     None feature selector for col prot
2022-11-18 03:09:30,666 INFO:     None feature selector for col chem
2022-11-18 03:09:30,666 INFO:     None feature selector for col chem
2022-11-18 03:09:30,666 INFO:     None feature selector for col chem
2022-11-18 03:09:30,666 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:09:30,666 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:09:30,668 INFO:     Number of params in model 168571
2022-11-18 03:09:30,671 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:09:30,671 INFO:   Starting stage: TRAINING
2022-11-18 03:09:30,728 INFO:     Val loss before train {'Reaction outcome loss': 0.95520026877869, 'Total loss': 0.95520026877869}
2022-11-18 03:09:30,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:30,728 INFO:     Epoch: 0
2022-11-18 03:09:31,577 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7742719878984052, 'Total loss': 0.7742719878984052} | train loss {'Reaction outcome loss': 0.8809624448662898, 'Total loss': 0.8809624448662898}
2022-11-18 03:09:31,577 INFO:     Found new best model at epoch 0
2022-11-18 03:09:31,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:31,578 INFO:     Epoch: 1
2022-11-18 03:09:32,357 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7819172850874967, 'Total loss': 0.7819172850874967} | train loss {'Reaction outcome loss': 0.8515256908340533, 'Total loss': 0.8515256908340533}
2022-11-18 03:09:32,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:32,358 INFO:     Epoch: 2
2022-11-18 03:09:33,169 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7763254032578579, 'Total loss': 0.7763254032578579} | train loss {'Reaction outcome loss': 0.8452926932788286, 'Total loss': 0.8452926932788286}
2022-11-18 03:09:33,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:33,170 INFO:     Epoch: 3
2022-11-18 03:09:33,941 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7681438444658767, 'Total loss': 0.7681438444658767} | train loss {'Reaction outcome loss': 0.8400066420435905, 'Total loss': 0.8400066420435905}
2022-11-18 03:09:33,943 INFO:     Found new best model at epoch 3
2022-11-18 03:09:33,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:33,944 INFO:     Epoch: 4
2022-11-18 03:09:34,765 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7722194083901339, 'Total loss': 0.7722194083901339} | train loss {'Reaction outcome loss': 0.8338045614664672, 'Total loss': 0.8338045614664672}
2022-11-18 03:09:34,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:34,765 INFO:     Epoch: 5
2022-11-18 03:09:35,544 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7524971407513286, 'Total loss': 0.7524971407513286} | train loss {'Reaction outcome loss': 0.8333801949610475, 'Total loss': 0.8333801949610475}
2022-11-18 03:09:35,545 INFO:     Found new best model at epoch 5
2022-11-18 03:09:35,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:35,545 INFO:     Epoch: 6
2022-11-18 03:09:36,367 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7707974162212637, 'Total loss': 0.7707974162212637} | train loss {'Reaction outcome loss': 0.8301626231338157, 'Total loss': 0.8301626231338157}
2022-11-18 03:09:36,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:36,367 INFO:     Epoch: 7
2022-11-18 03:09:37,140 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7539951066638149, 'Total loss': 0.7539951066638149} | train loss {'Reaction outcome loss': 0.8304085889067806, 'Total loss': 0.8304085889067806}
2022-11-18 03:09:37,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:37,140 INFO:     Epoch: 8
2022-11-18 03:09:37,953 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7565722624922908, 'Total loss': 0.7565722624922908} | train loss {'Reaction outcome loss': 0.8246913180976617, 'Total loss': 0.8246913180976617}
2022-11-18 03:09:37,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:37,954 INFO:     Epoch: 9
2022-11-18 03:09:38,723 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7546156346797943, 'Total loss': 0.7546156346797943} | train loss {'Reaction outcome loss': 0.826537054337439, 'Total loss': 0.826537054337439}
2022-11-18 03:09:38,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:38,723 INFO:     Epoch: 10
2022-11-18 03:09:39,502 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7567671502745429, 'Total loss': 0.7567671502745429} | train loss {'Reaction outcome loss': 0.828496877653677, 'Total loss': 0.828496877653677}
2022-11-18 03:09:39,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:39,503 INFO:     Epoch: 11
2022-11-18 03:09:40,285 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.79048162629438, 'Total loss': 0.79048162629438} | train loss {'Reaction outcome loss': 0.8221204373680178, 'Total loss': 0.8221204373680178}
2022-11-18 03:09:40,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:40,286 INFO:     Epoch: 12
2022-11-18 03:09:41,145 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7744620885959891, 'Total loss': 0.7744620885959891} | train loss {'Reaction outcome loss': 0.8307987675070763, 'Total loss': 0.8307987675070763}
2022-11-18 03:09:41,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:41,146 INFO:     Epoch: 13
2022-11-18 03:09:41,954 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7559823712637258, 'Total loss': 0.7559823712637258} | train loss {'Reaction outcome loss': 0.8250255065618969, 'Total loss': 0.8250255065618969}
2022-11-18 03:09:41,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:41,954 INFO:     Epoch: 14
2022-11-18 03:09:42,754 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7541118797867797, 'Total loss': 0.7541118797867797} | train loss {'Reaction outcome loss': 0.8256571776554232, 'Total loss': 0.8256571776554232}
2022-11-18 03:09:42,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:42,754 INFO:     Epoch: 15
2022-11-18 03:09:43,555 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.757089473480402, 'Total loss': 0.757089473480402} | train loss {'Reaction outcome loss': 0.8215272170109827, 'Total loss': 0.8215272170109827}
2022-11-18 03:09:43,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:43,556 INFO:     Epoch: 16
2022-11-18 03:09:44,329 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7523590693640154, 'Total loss': 0.7523590693640154} | train loss {'Reaction outcome loss': 0.8227352274001621, 'Total loss': 0.8227352274001621}
2022-11-18 03:09:44,329 INFO:     Found new best model at epoch 16
2022-11-18 03:09:44,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:44,330 INFO:     Epoch: 17
2022-11-18 03:09:45,111 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7506869185802548, 'Total loss': 0.7506869185802548} | train loss {'Reaction outcome loss': 0.8218315417160753, 'Total loss': 0.8218315417160753}
2022-11-18 03:09:45,111 INFO:     Found new best model at epoch 17
2022-11-18 03:09:45,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:45,112 INFO:     Epoch: 18
2022-11-18 03:09:45,937 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7509225142556567, 'Total loss': 0.7509225142556567} | train loss {'Reaction outcome loss': 0.8235875613621024, 'Total loss': 0.8235875613621024}
2022-11-18 03:09:45,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:45,938 INFO:     Epoch: 19
2022-11-18 03:09:46,774 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7537686443606089, 'Total loss': 0.7537686443606089} | train loss {'Reaction outcome loss': 0.822516105702666, 'Total loss': 0.822516105702666}
2022-11-18 03:09:46,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:46,774 INFO:     Epoch: 20
2022-11-18 03:09:47,600 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7472663029681804, 'Total loss': 0.7472663029681804} | train loss {'Reaction outcome loss': 0.8206668956602206, 'Total loss': 0.8206668956602206}
2022-11-18 03:09:47,600 INFO:     Found new best model at epoch 20
2022-11-18 03:09:47,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:47,601 INFO:     Epoch: 21
2022-11-18 03:09:48,380 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7448225291662438, 'Total loss': 0.7448225291662438} | train loss {'Reaction outcome loss': 0.8209319721724166, 'Total loss': 0.8209319721724166}
2022-11-18 03:09:48,381 INFO:     Found new best model at epoch 21
2022-11-18 03:09:48,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:48,382 INFO:     Epoch: 22
2022-11-18 03:09:49,187 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7604062162166418, 'Total loss': 0.7604062162166418} | train loss {'Reaction outcome loss': 0.8251117053823392, 'Total loss': 0.8251117053823392}
2022-11-18 03:09:49,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:49,187 INFO:     Epoch: 23
2022-11-18 03:09:50,013 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7638624054054881, 'Total loss': 0.7638624054054881} | train loss {'Reaction outcome loss': 0.82393779410202, 'Total loss': 0.82393779410202}
2022-11-18 03:09:50,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:50,014 INFO:     Epoch: 24
2022-11-18 03:09:50,838 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7730031436265901, 'Total loss': 0.7730031436265901} | train loss {'Reaction outcome loss': 0.820982220842213, 'Total loss': 0.820982220842213}
2022-11-18 03:09:50,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:50,838 INFO:     Epoch: 25
2022-11-18 03:09:51,638 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7620549992073414, 'Total loss': 0.7620549992073414} | train loss {'Reaction outcome loss': 0.8217076353240208, 'Total loss': 0.8217076353240208}
2022-11-18 03:09:51,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:51,639 INFO:     Epoch: 26
2022-11-18 03:09:52,443 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7512180832929389, 'Total loss': 0.7512180832929389} | train loss {'Reaction outcome loss': 0.8205242277901681, 'Total loss': 0.8205242277901681}
2022-11-18 03:09:52,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:52,444 INFO:     Epoch: 27
2022-11-18 03:09:53,286 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7531953474809957, 'Total loss': 0.7531953474809957} | train loss {'Reaction outcome loss': 0.8162379346665789, 'Total loss': 0.8162379346665789}
2022-11-18 03:09:53,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:53,286 INFO:     Epoch: 28
2022-11-18 03:09:54,124 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7474603216315425, 'Total loss': 0.7474603216315425} | train loss {'Reaction outcome loss': 0.8232821132071683, 'Total loss': 0.8232821132071683}
2022-11-18 03:09:54,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:54,124 INFO:     Epoch: 29
2022-11-18 03:09:54,921 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7616684305113416, 'Total loss': 0.7616684305113416} | train loss {'Reaction outcome loss': 0.8230310953298553, 'Total loss': 0.8230310953298553}
2022-11-18 03:09:54,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:54,921 INFO:     Epoch: 30
2022-11-18 03:09:55,723 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7664406978806784, 'Total loss': 0.7664406978806784} | train loss {'Reaction outcome loss': 0.8224485262495572, 'Total loss': 0.8224485262495572}
2022-11-18 03:09:55,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:55,723 INFO:     Epoch: 31
2022-11-18 03:09:56,520 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7489543640336325, 'Total loss': 0.7489543640336325} | train loss {'Reaction outcome loss': 0.8208990749277052, 'Total loss': 0.8208990749277052}
2022-11-18 03:09:56,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:56,520 INFO:     Epoch: 32
2022-11-18 03:09:57,360 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7649789130271867, 'Total loss': 0.7649789130271867} | train loss {'Reaction outcome loss': 0.8255155689892222, 'Total loss': 0.8255155689892222}
2022-11-18 03:09:57,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:57,360 INFO:     Epoch: 33
2022-11-18 03:09:58,143 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7531310583269873, 'Total loss': 0.7531310583269873} | train loss {'Reaction outcome loss': 0.8212998734145868, 'Total loss': 0.8212998734145868}
2022-11-18 03:09:58,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:58,144 INFO:     Epoch: 34
2022-11-18 03:09:58,978 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7488974762517352, 'Total loss': 0.7488974762517352} | train loss {'Reaction outcome loss': 0.8201093106973366, 'Total loss': 0.8201093106973366}
2022-11-18 03:09:58,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:58,978 INFO:     Epoch: 35
2022-11-18 03:09:59,784 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7534928910954054, 'Total loss': 0.7534928910954054} | train loss {'Reaction outcome loss': 0.8248023743756482, 'Total loss': 0.8248023743756482}
2022-11-18 03:09:59,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:09:59,784 INFO:     Epoch: 36
2022-11-18 03:10:00,607 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7521010207575421, 'Total loss': 0.7521010207575421} | train loss {'Reaction outcome loss': 0.8180870451643819, 'Total loss': 0.8180870451643819}
2022-11-18 03:10:00,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:00,607 INFO:     Epoch: 37
2022-11-18 03:10:01,395 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7549498441607453, 'Total loss': 0.7549498441607453} | train loss {'Reaction outcome loss': 0.8211728461453172, 'Total loss': 0.8211728461453172}
2022-11-18 03:10:01,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:01,395 INFO:     Epoch: 38
2022-11-18 03:10:02,194 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7544649596824202, 'Total loss': 0.7544649596824202} | train loss {'Reaction outcome loss': 0.8226573551531697, 'Total loss': 0.8226573551531697}
2022-11-18 03:10:02,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:02,194 INFO:     Epoch: 39
2022-11-18 03:10:03,020 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7528062164783478, 'Total loss': 0.7528062164783478} | train loss {'Reaction outcome loss': 0.8262956144868351, 'Total loss': 0.8262956144868351}
2022-11-18 03:10:03,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:03,020 INFO:     Epoch: 40
2022-11-18 03:10:03,807 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7464815426704495, 'Total loss': 0.7464815426704495} | train loss {'Reaction outcome loss': 0.8220929035642108, 'Total loss': 0.8220929035642108}
2022-11-18 03:10:03,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:03,807 INFO:     Epoch: 41
2022-11-18 03:10:04,631 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7631973506406297, 'Total loss': 0.7631973506406297} | train loss {'Reaction outcome loss': 0.8218429566162532, 'Total loss': 0.8218429566162532}
2022-11-18 03:10:04,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:04,633 INFO:     Epoch: 42
2022-11-18 03:10:05,437 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7616084966548654, 'Total loss': 0.7616084966548654} | train loss {'Reaction outcome loss': 0.8202562026801656, 'Total loss': 0.8202562026801656}
2022-11-18 03:10:05,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:05,438 INFO:     Epoch: 43
2022-11-18 03:10:06,239 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7492107589577519, 'Total loss': 0.7492107589577519} | train loss {'Reaction outcome loss': 0.822453862575234, 'Total loss': 0.822453862575234}
2022-11-18 03:10:06,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:06,239 INFO:     Epoch: 44
2022-11-18 03:10:07,038 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7673980704573697, 'Total loss': 0.7673980704573697} | train loss {'Reaction outcome loss': 0.8182507565275567, 'Total loss': 0.8182507565275567}
2022-11-18 03:10:07,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:07,039 INFO:     Epoch: 45
2022-11-18 03:10:07,864 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7528112378231314, 'Total loss': 0.7528112378231314} | train loss {'Reaction outcome loss': 0.8237272609697014, 'Total loss': 0.8237272609697014}
2022-11-18 03:10:07,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:07,864 INFO:     Epoch: 46
2022-11-18 03:10:08,649 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7776392864626508, 'Total loss': 0.7776392864626508} | train loss {'Reaction outcome loss': 0.820155356262551, 'Total loss': 0.820155356262551}
2022-11-18 03:10:08,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:08,649 INFO:     Epoch: 47
2022-11-18 03:10:09,457 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7508563967638238, 'Total loss': 0.7508563967638238} | train loss {'Reaction outcome loss': 0.8187525455580383, 'Total loss': 0.8187525455580383}
2022-11-18 03:10:09,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:09,457 INFO:     Epoch: 48
2022-11-18 03:10:10,253 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.755604530489722, 'Total loss': 0.755604530489722} | train loss {'Reaction outcome loss': 0.8260036875478557, 'Total loss': 0.8260036875478557}
2022-11-18 03:10:10,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:10,253 INFO:     Epoch: 49
2022-11-18 03:10:11,073 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7568256016387496, 'Total loss': 0.7568256016387496} | train loss {'Reaction outcome loss': 0.8200519597921215, 'Total loss': 0.8200519597921215}
2022-11-18 03:10:11,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:11,074 INFO:     Epoch: 50
2022-11-18 03:10:11,876 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7540140283662219, 'Total loss': 0.7540140283662219} | train loss {'Reaction outcome loss': 0.820549126164835, 'Total loss': 0.820549126164835}
2022-11-18 03:10:11,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:11,876 INFO:     Epoch: 51
2022-11-18 03:10:12,670 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7543019437512686, 'Total loss': 0.7543019437512686} | train loss {'Reaction outcome loss': 0.8189133483855451, 'Total loss': 0.8189133483855451}
2022-11-18 03:10:12,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:12,671 INFO:     Epoch: 52
2022-11-18 03:10:13,497 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7463588811630426, 'Total loss': 0.7463588811630426} | train loss {'Reaction outcome loss': 0.8188192167731582, 'Total loss': 0.8188192167731582}
2022-11-18 03:10:13,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:13,497 INFO:     Epoch: 53
2022-11-18 03:10:14,311 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7647981505061305, 'Total loss': 0.7647981505061305} | train loss {'Reaction outcome loss': 0.821024163824613, 'Total loss': 0.821024163824613}
2022-11-18 03:10:14,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:14,312 INFO:     Epoch: 54
2022-11-18 03:10:15,125 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7664009388103041, 'Total loss': 0.7664009388103041} | train loss {'Reaction outcome loss': 0.8210882993995167, 'Total loss': 0.8210882993995167}
2022-11-18 03:10:15,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:15,125 INFO:     Epoch: 55
2022-11-18 03:10:15,901 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7677745763645616, 'Total loss': 0.7677745763645616} | train loss {'Reaction outcome loss': 0.8219745063879451, 'Total loss': 0.8219745063879451}
2022-11-18 03:10:15,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:15,901 INFO:     Epoch: 56
2022-11-18 03:10:16,726 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7538120039673739, 'Total loss': 0.7538120039673739} | train loss {'Reaction outcome loss': 0.8212537145028349, 'Total loss': 0.8212537145028349}
2022-11-18 03:10:16,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:16,727 INFO:     Epoch: 57
2022-11-18 03:10:17,550 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7920540481112724, 'Total loss': 0.7920540481112724} | train loss {'Reaction outcome loss': 0.8202640674397593, 'Total loss': 0.8202640674397593}
2022-11-18 03:10:17,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:17,551 INFO:     Epoch: 58
2022-11-18 03:10:18,323 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7581673430842023, 'Total loss': 0.7581673430842023} | train loss {'Reaction outcome loss': 0.8222476070533034, 'Total loss': 0.8222476070533034}
2022-11-18 03:10:18,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:18,323 INFO:     Epoch: 59
2022-11-18 03:10:19,127 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7430468541245128, 'Total loss': 0.7430468541245128} | train loss {'Reaction outcome loss': 0.8193593359872943, 'Total loss': 0.8193593359872943}
2022-11-18 03:10:19,127 INFO:     Found new best model at epoch 59
2022-11-18 03:10:19,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:19,128 INFO:     Epoch: 60
2022-11-18 03:10:19,934 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7697872990785644, 'Total loss': 0.7697872990785644} | train loss {'Reaction outcome loss': 0.8200787631947486, 'Total loss': 0.8200787631947486}
2022-11-18 03:10:19,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:19,934 INFO:     Epoch: 61
2022-11-18 03:10:20,712 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7504349725190983, 'Total loss': 0.7504349725190983} | train loss {'Reaction outcome loss': 0.8209702695002321, 'Total loss': 0.8209702695002321}
2022-11-18 03:10:20,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:20,712 INFO:     Epoch: 62
2022-11-18 03:10:21,517 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7534602436908456, 'Total loss': 0.7534602436908456} | train loss {'Reaction outcome loss': 0.8204945606774972, 'Total loss': 0.8204945606774972}
2022-11-18 03:10:21,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:21,517 INFO:     Epoch: 63
2022-11-18 03:10:22,319 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7475883815177652, 'Total loss': 0.7475883815177652} | train loss {'Reaction outcome loss': 0.8187311351543567, 'Total loss': 0.8187311351543567}
2022-11-18 03:10:22,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:22,319 INFO:     Epoch: 64
2022-11-18 03:10:23,145 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7434671042963515, 'Total loss': 0.7434671042963515} | train loss {'Reaction outcome loss': 0.8199553912291762, 'Total loss': 0.8199553912291762}
2022-11-18 03:10:23,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:23,146 INFO:     Epoch: 65
2022-11-18 03:10:23,948 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7417158435943515, 'Total loss': 0.7417158435943515} | train loss {'Reaction outcome loss': 0.8189820312574262, 'Total loss': 0.8189820312574262}
2022-11-18 03:10:23,948 INFO:     Found new best model at epoch 65
2022-11-18 03:10:23,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:23,949 INFO:     Epoch: 66
2022-11-18 03:10:24,728 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7541736745557119, 'Total loss': 0.7541736745557119} | train loss {'Reaction outcome loss': 0.8208484645993983, 'Total loss': 0.8208484645993983}
2022-11-18 03:10:24,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:24,729 INFO:     Epoch: 67
2022-11-18 03:10:25,510 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.742002664610397, 'Total loss': 0.742002664610397} | train loss {'Reaction outcome loss': 0.8215685746953135, 'Total loss': 0.8215685746953135}
2022-11-18 03:10:25,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:25,510 INFO:     Epoch: 68
2022-11-18 03:10:26,352 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7485084845576175, 'Total loss': 0.7485084845576175} | train loss {'Reaction outcome loss': 0.8185759344306148, 'Total loss': 0.8185759344306148}
2022-11-18 03:10:26,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:26,353 INFO:     Epoch: 69
2022-11-18 03:10:27,157 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.771851263767065, 'Total loss': 0.771851263767065} | train loss {'Reaction outcome loss': 0.8216616853338773, 'Total loss': 0.8216616853338773}
2022-11-18 03:10:27,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:27,157 INFO:     Epoch: 70
2022-11-18 03:10:27,976 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.758614111778348, 'Total loss': 0.758614111778348} | train loss {'Reaction outcome loss': 0.8177567695985075, 'Total loss': 0.8177567695985075}
2022-11-18 03:10:27,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:27,977 INFO:     Epoch: 71
2022-11-18 03:10:28,776 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7515547233958577, 'Total loss': 0.7515547233958577} | train loss {'Reaction outcome loss': 0.8171784391657251, 'Total loss': 0.8171784391657251}
2022-11-18 03:10:28,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:28,776 INFO:     Epoch: 72
2022-11-18 03:10:29,565 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7521275725475577, 'Total loss': 0.7521275725475577} | train loss {'Reaction outcome loss': 0.8168117441847677, 'Total loss': 0.8168117441847677}
2022-11-18 03:10:29,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:29,565 INFO:     Epoch: 73
2022-11-18 03:10:30,391 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7522069430628489, 'Total loss': 0.7522069430628489} | train loss {'Reaction outcome loss': 0.820886286433603, 'Total loss': 0.820886286433603}
2022-11-18 03:10:30,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:30,391 INFO:     Epoch: 74
2022-11-18 03:10:31,181 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7446372640687365, 'Total loss': 0.7446372640687365} | train loss {'Reaction outcome loss': 0.8232909289539837, 'Total loss': 0.8232909289539837}
2022-11-18 03:10:31,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:31,181 INFO:     Epoch: 75
2022-11-18 03:10:31,965 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7557277083396912, 'Total loss': 0.7557277083396912} | train loss {'Reaction outcome loss': 0.8181442994563306, 'Total loss': 0.8181442994563306}
2022-11-18 03:10:31,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:31,965 INFO:     Epoch: 76
2022-11-18 03:10:32,772 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7450550136178039, 'Total loss': 0.7450550136178039} | train loss {'Reaction outcome loss': 0.8183527581515859, 'Total loss': 0.8183527581515859}
2022-11-18 03:10:32,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:32,772 INFO:     Epoch: 77
2022-11-18 03:10:33,550 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.76581473683202, 'Total loss': 0.76581473683202} | train loss {'Reaction outcome loss': 0.8177653475374472, 'Total loss': 0.8177653475374472}
2022-11-18 03:10:33,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:33,550 INFO:     Epoch: 78
2022-11-18 03:10:34,367 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7549019830171452, 'Total loss': 0.7549019830171452} | train loss {'Reaction outcome loss': 0.820487558231002, 'Total loss': 0.820487558231002}
2022-11-18 03:10:34,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:34,368 INFO:     Epoch: 79
2022-11-18 03:10:35,156 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.755622363367746, 'Total loss': 0.755622363367746} | train loss {'Reaction outcome loss': 0.8224733829742572, 'Total loss': 0.8224733829742572}
2022-11-18 03:10:35,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:35,157 INFO:     Epoch: 80
2022-11-18 03:10:35,981 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.764948332032492, 'Total loss': 0.764948332032492} | train loss {'Reaction outcome loss': 0.8193413791109304, 'Total loss': 0.8193413791109304}
2022-11-18 03:10:35,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:35,982 INFO:     Epoch: 81
2022-11-18 03:10:36,813 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7488979253658029, 'Total loss': 0.7488979253658029} | train loss {'Reaction outcome loss': 0.8225705414766171, 'Total loss': 0.8225705414766171}
2022-11-18 03:10:36,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:36,813 INFO:     Epoch: 82
2022-11-18 03:10:37,611 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.752083703529003, 'Total loss': 0.752083703529003} | train loss {'Reaction outcome loss': 0.8199832173155956, 'Total loss': 0.8199832173155956}
2022-11-18 03:10:37,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:37,611 INFO:     Epoch: 83
2022-11-18 03:10:38,401 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7633988399838292, 'Total loss': 0.7633988399838292} | train loss {'Reaction outcome loss': 0.8180537821694476, 'Total loss': 0.8180537821694476}
2022-11-18 03:10:38,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:38,401 INFO:     Epoch: 84
2022-11-18 03:10:39,195 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7621861529904742, 'Total loss': 0.7621861529904742} | train loss {'Reaction outcome loss': 0.8210491015285742, 'Total loss': 0.8210491015285742}
2022-11-18 03:10:39,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:39,195 INFO:     Epoch: 85
2022-11-18 03:10:39,997 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.773037337979605, 'Total loss': 0.773037337979605} | train loss {'Reaction outcome loss': 0.8199288830405376, 'Total loss': 0.8199288830405376}
2022-11-18 03:10:39,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:39,998 INFO:     Epoch: 86
2022-11-18 03:10:40,771 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8030486481134281, 'Total loss': 0.8030486481134281} | train loss {'Reaction outcome loss': 0.8174087396654927, 'Total loss': 0.8174087396654927}
2022-11-18 03:10:40,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:40,771 INFO:     Epoch: 87
2022-11-18 03:10:41,588 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.748855929735095, 'Total loss': 0.748855929735095} | train loss {'Reaction outcome loss': 0.8214823971273469, 'Total loss': 0.8214823971273469}
2022-11-18 03:10:41,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:41,589 INFO:     Epoch: 88
2022-11-18 03:10:42,404 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7651350304137828, 'Total loss': 0.7651350304137828} | train loss {'Reaction outcome loss': 0.8238506560198596, 'Total loss': 0.8238506560198596}
2022-11-18 03:10:42,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:42,405 INFO:     Epoch: 89
2022-11-18 03:10:43,208 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7511144550733788, 'Total loss': 0.7511144550733788} | train loss {'Reaction outcome loss': 0.8191512917153171, 'Total loss': 0.8191512917153171}
2022-11-18 03:10:43,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:43,208 INFO:     Epoch: 90
2022-11-18 03:10:44,028 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7718394447204678, 'Total loss': 0.7718394447204678} | train loss {'Reaction outcome loss': 0.8194493727117288, 'Total loss': 0.8194493727117288}
2022-11-18 03:10:44,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:44,028 INFO:     Epoch: 91
2022-11-18 03:10:44,842 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7436785150405972, 'Total loss': 0.7436785150405972} | train loss {'Reaction outcome loss': 0.819556959950533, 'Total loss': 0.819556959950533}
2022-11-18 03:10:44,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:44,843 INFO:     Epoch: 92
2022-11-18 03:10:45,629 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7705901542375254, 'Total loss': 0.7705901542375254} | train loss {'Reaction outcome loss': 0.8210032156012097, 'Total loss': 0.8210032156012097}
2022-11-18 03:10:45,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:45,629 INFO:     Epoch: 93
2022-11-18 03:10:46,433 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7596165482387987, 'Total loss': 0.7596165482387987} | train loss {'Reaction outcome loss': 0.8183771696735601, 'Total loss': 0.8183771696735601}
2022-11-18 03:10:46,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:46,433 INFO:     Epoch: 94
2022-11-18 03:10:47,239 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7693847528723783, 'Total loss': 0.7693847528723783} | train loss {'Reaction outcome loss': 0.8209090759275389, 'Total loss': 0.8209090759275389}
2022-11-18 03:10:47,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:47,240 INFO:     Epoch: 95
2022-11-18 03:10:48,073 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7612810322018557, 'Total loss': 0.7612810322018557} | train loss {'Reaction outcome loss': 0.8210210615738494, 'Total loss': 0.8210210615738494}
2022-11-18 03:10:48,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:48,073 INFO:     Epoch: 96
2022-11-18 03:10:48,930 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7489220832669458, 'Total loss': 0.7489220832669458} | train loss {'Reaction outcome loss': 0.8219945339150116, 'Total loss': 0.8219945339150116}
2022-11-18 03:10:48,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:48,930 INFO:     Epoch: 97
2022-11-18 03:10:49,741 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7740435295326765, 'Total loss': 0.7740435295326765} | train loss {'Reaction outcome loss': 0.8190904976647408, 'Total loss': 0.8190904976647408}
2022-11-18 03:10:49,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:49,742 INFO:     Epoch: 98
2022-11-18 03:10:50,567 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7468811363674873, 'Total loss': 0.7468811363674873} | train loss {'Reaction outcome loss': 0.8154206571520352, 'Total loss': 0.8154206571520352}
2022-11-18 03:10:50,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:50,568 INFO:     Epoch: 99
2022-11-18 03:10:51,362 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7550768353218256, 'Total loss': 0.7550768353218256} | train loss {'Reaction outcome loss': 0.8181159063929417, 'Total loss': 0.8181159063929417}
2022-11-18 03:10:51,362 INFO:     Best model found after epoch 66 of 100.
2022-11-18 03:10:51,362 INFO:   Done with stage: TRAINING
2022-11-18 03:10:51,362 INFO:   Starting stage: EVALUATION
2022-11-18 03:10:51,500 INFO:   Done with stage: EVALUATION
2022-11-18 03:10:51,500 INFO:   Leaving out SEQ value Fold_2
2022-11-18 03:10:51,513 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 03:10:51,513 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:10:52,181 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:10:52,181 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:10:52,249 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:10:52,249 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:10:52,249 INFO:     No hyperparam tuning for this model
2022-11-18 03:10:52,249 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:10:52,249 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:10:52,250 INFO:     None feature selector for col prot
2022-11-18 03:10:52,250 INFO:     None feature selector for col prot
2022-11-18 03:10:52,250 INFO:     None feature selector for col prot
2022-11-18 03:10:52,251 INFO:     None feature selector for col chem
2022-11-18 03:10:52,251 INFO:     None feature selector for col chem
2022-11-18 03:10:52,251 INFO:     None feature selector for col chem
2022-11-18 03:10:52,251 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:10:52,251 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:10:52,252 INFO:     Number of params in model 168571
2022-11-18 03:10:52,256 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:10:52,256 INFO:   Starting stage: TRAINING
2022-11-18 03:10:52,312 INFO:     Val loss before train {'Reaction outcome loss': 0.9981656573539557, 'Total loss': 0.9981656573539557}
2022-11-18 03:10:52,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:52,313 INFO:     Epoch: 0
2022-11-18 03:10:53,098 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8247217383495596, 'Total loss': 0.8247217383495596} | train loss {'Reaction outcome loss': 0.8741784537280047, 'Total loss': 0.8741784537280047}
2022-11-18 03:10:53,098 INFO:     Found new best model at epoch 0
2022-11-18 03:10:53,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:53,099 INFO:     Epoch: 1
2022-11-18 03:10:53,851 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8258022763008295, 'Total loss': 0.8258022763008295} | train loss {'Reaction outcome loss': 0.8510084563076742, 'Total loss': 0.8510084563076742}
2022-11-18 03:10:53,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:53,851 INFO:     Epoch: 2
2022-11-18 03:10:54,667 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8072359568850939, 'Total loss': 0.8072359568850939} | train loss {'Reaction outcome loss': 0.8423475613319334, 'Total loss': 0.8423475613319334}
2022-11-18 03:10:54,668 INFO:     Found new best model at epoch 2
2022-11-18 03:10:54,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:54,670 INFO:     Epoch: 3
2022-11-18 03:10:55,515 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8129312125749366, 'Total loss': 0.8129312125749366} | train loss {'Reaction outcome loss': 0.8424242615945055, 'Total loss': 0.8424242615945055}
2022-11-18 03:10:55,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:55,515 INFO:     Epoch: 4
2022-11-18 03:10:56,311 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8175967488177988, 'Total loss': 0.8175967488177988} | train loss {'Reaction outcome loss': 0.8302560458458009, 'Total loss': 0.8302560458458009}
2022-11-18 03:10:56,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:56,311 INFO:     Epoch: 5
2022-11-18 03:10:57,098 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8014081141283346, 'Total loss': 0.8014081141283346} | train loss {'Reaction outcome loss': 0.827230504265538, 'Total loss': 0.827230504265538}
2022-11-18 03:10:57,098 INFO:     Found new best model at epoch 5
2022-11-18 03:10:57,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:57,099 INFO:     Epoch: 6
2022-11-18 03:10:57,883 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.829265317251516, 'Total loss': 0.829265317251516} | train loss {'Reaction outcome loss': 0.8283250896037851, 'Total loss': 0.8283250896037851}
2022-11-18 03:10:57,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:57,883 INFO:     Epoch: 7
2022-11-18 03:10:58,655 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7999801795149959, 'Total loss': 0.7999801795149959} | train loss {'Reaction outcome loss': 0.8261947155979926, 'Total loss': 0.8261947155979926}
2022-11-18 03:10:58,655 INFO:     Found new best model at epoch 7
2022-11-18 03:10:58,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:58,656 INFO:     Epoch: 8
2022-11-18 03:10:59,446 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7985026760156765, 'Total loss': 0.7985026760156765} | train loss {'Reaction outcome loss': 0.8253934437355387, 'Total loss': 0.8253934437355387}
2022-11-18 03:10:59,447 INFO:     Found new best model at epoch 8
2022-11-18 03:10:59,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:10:59,448 INFO:     Epoch: 9
2022-11-18 03:11:00,237 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8433051532091096, 'Total loss': 0.8433051532091096} | train loss {'Reaction outcome loss': 0.8219529976570067, 'Total loss': 0.8219529976570067}
2022-11-18 03:11:00,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:00,238 INFO:     Epoch: 10
2022-11-18 03:11:00,995 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8079878341319949, 'Total loss': 0.8079878341319949} | train loss {'Reaction outcome loss': 0.8201555544702114, 'Total loss': 0.8201555544702114}
2022-11-18 03:11:00,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:00,995 INFO:     Epoch: 11
2022-11-18 03:11:01,782 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8075667938520742, 'Total loss': 0.8075667938520742} | train loss {'Reaction outcome loss': 0.8252798122633632, 'Total loss': 0.8252798122633632}
2022-11-18 03:11:01,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:01,783 INFO:     Epoch: 12
2022-11-18 03:11:02,523 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8036937644315321, 'Total loss': 0.8036937644315321} | train loss {'Reaction outcome loss': 0.8243521839502908, 'Total loss': 0.8243521839502908}
2022-11-18 03:11:02,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:02,523 INFO:     Epoch: 13
2022-11-18 03:11:03,275 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7956517137760339, 'Total loss': 0.7956517137760339} | train loss {'Reaction outcome loss': 0.820379744341344, 'Total loss': 0.820379744341344}
2022-11-18 03:11:03,276 INFO:     Found new best model at epoch 13
2022-11-18 03:11:03,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:03,277 INFO:     Epoch: 14
2022-11-18 03:11:04,039 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.79427018969558, 'Total loss': 0.79427018969558} | train loss {'Reaction outcome loss': 0.8172660175664925, 'Total loss': 0.8172660175664925}
2022-11-18 03:11:04,039 INFO:     Found new best model at epoch 14
2022-11-18 03:11:04,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:04,040 INFO:     Epoch: 15
2022-11-18 03:11:04,782 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8078397914420726, 'Total loss': 0.8078397914420726} | train loss {'Reaction outcome loss': 0.8156805150057553, 'Total loss': 0.8156805150057553}
2022-11-18 03:11:04,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:04,783 INFO:     Epoch: 16
2022-11-18 03:11:05,562 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8100836983946866, 'Total loss': 0.8100836983946866} | train loss {'Reaction outcome loss': 0.8159913327468276, 'Total loss': 0.8159913327468276}
2022-11-18 03:11:05,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:05,563 INFO:     Epoch: 17
2022-11-18 03:11:06,307 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8038369548875232, 'Total loss': 0.8038369548875232} | train loss {'Reaction outcome loss': 0.820527751872569, 'Total loss': 0.820527751872569}
2022-11-18 03:11:06,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:06,307 INFO:     Epoch: 18
2022-11-18 03:11:07,056 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7929993701535601, 'Total loss': 0.7929993701535601} | train loss {'Reaction outcome loss': 0.8162291301376045, 'Total loss': 0.8162291301376045}
2022-11-18 03:11:07,058 INFO:     Found new best model at epoch 18
2022-11-18 03:11:07,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:07,059 INFO:     Epoch: 19
2022-11-18 03:11:07,819 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7889456721239312, 'Total loss': 0.7889456721239312} | train loss {'Reaction outcome loss': 0.8167346487810583, 'Total loss': 0.8167346487810583}
2022-11-18 03:11:07,819 INFO:     Found new best model at epoch 19
2022-11-18 03:11:07,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:07,820 INFO:     Epoch: 20
2022-11-18 03:11:08,595 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8012481276379075, 'Total loss': 0.8012481276379075} | train loss {'Reaction outcome loss': 0.8182832710291623, 'Total loss': 0.8182832710291623}
2022-11-18 03:11:08,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:08,595 INFO:     Epoch: 21
2022-11-18 03:11:09,323 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7954614204029704, 'Total loss': 0.7954614204029704} | train loss {'Reaction outcome loss': 0.8187282956186145, 'Total loss': 0.8187282956186145}
2022-11-18 03:11:09,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:09,323 INFO:     Epoch: 22
2022-11-18 03:11:10,101 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7974478865778724, 'Total loss': 0.7974478865778724} | train loss {'Reaction outcome loss': 0.8155270312058092, 'Total loss': 0.8155270312058092}
2022-11-18 03:11:10,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:10,101 INFO:     Epoch: 23
2022-11-18 03:11:10,867 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7987958192825317, 'Total loss': 0.7987958192825317} | train loss {'Reaction outcome loss': 0.8157087624563601, 'Total loss': 0.8157087624563601}
2022-11-18 03:11:10,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:10,867 INFO:     Epoch: 24
2022-11-18 03:11:11,652 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8079950948094212, 'Total loss': 0.8079950948094212} | train loss {'Reaction outcome loss': 0.8144721175417488, 'Total loss': 0.8144721175417488}
2022-11-18 03:11:11,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:11,652 INFO:     Epoch: 25
2022-11-18 03:11:12,432 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7926875221174817, 'Total loss': 0.7926875221174817} | train loss {'Reaction outcome loss': 0.8158733842304214, 'Total loss': 0.8158733842304214}
2022-11-18 03:11:12,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:12,432 INFO:     Epoch: 26
2022-11-18 03:11:13,193 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8298534549946008, 'Total loss': 0.8298534549946008} | train loss {'Reaction outcome loss': 0.8158538186991656, 'Total loss': 0.8158538186991656}
2022-11-18 03:11:13,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:13,195 INFO:     Epoch: 27
2022-11-18 03:11:13,972 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8075114114339962, 'Total loss': 0.8075114114339962} | train loss {'Reaction outcome loss': 0.8127067160213926, 'Total loss': 0.8127067160213926}
2022-11-18 03:11:13,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:13,972 INFO:     Epoch: 28
2022-11-18 03:11:14,788 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.792169839143753, 'Total loss': 0.792169839143753} | train loss {'Reaction outcome loss': 0.8183664030744215, 'Total loss': 0.8183664030744215}
2022-11-18 03:11:14,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:14,788 INFO:     Epoch: 29
2022-11-18 03:11:15,606 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8029572360737379, 'Total loss': 0.8029572360737379} | train loss {'Reaction outcome loss': 0.8189720879366369, 'Total loss': 0.8189720879366369}
2022-11-18 03:11:15,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:15,606 INFO:     Epoch: 30
2022-11-18 03:11:16,432 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8037937297377475, 'Total loss': 0.8037937297377475} | train loss {'Reaction outcome loss': 0.8118265236846705, 'Total loss': 0.8118265236846705}
2022-11-18 03:11:16,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:16,433 INFO:     Epoch: 31
2022-11-18 03:11:17,237 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8118022257505462, 'Total loss': 0.8118022257505462} | train loss {'Reaction outcome loss': 0.8145029788277277, 'Total loss': 0.8145029788277277}
2022-11-18 03:11:17,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:17,237 INFO:     Epoch: 32
2022-11-18 03:11:17,995 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7930077986661778, 'Total loss': 0.7930077986661778} | train loss {'Reaction outcome loss': 0.8141425396679851, 'Total loss': 0.8141425396679851}
2022-11-18 03:11:17,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:17,995 INFO:     Epoch: 33
2022-11-18 03:11:18,802 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7960090304529944, 'Total loss': 0.7960090304529944} | train loss {'Reaction outcome loss': 0.8157130806043805, 'Total loss': 0.8157130806043805}
2022-11-18 03:11:18,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:18,803 INFO:     Epoch: 34
2022-11-18 03:11:19,557 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8268322598102481, 'Total loss': 0.8268322598102481} | train loss {'Reaction outcome loss': 0.8130552606818117, 'Total loss': 0.8130552606818117}
2022-11-18 03:11:19,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:19,557 INFO:     Epoch: 35
2022-11-18 03:11:20,341 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7984525755394337, 'Total loss': 0.7984525755394337} | train loss {'Reaction outcome loss': 0.8119099829422594, 'Total loss': 0.8119099829422594}
2022-11-18 03:11:20,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:20,341 INFO:     Epoch: 36
2022-11-18 03:11:21,139 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8003362223159435, 'Total loss': 0.8003362223159435} | train loss {'Reaction outcome loss': 0.8155726675143458, 'Total loss': 0.8155726675143458}
2022-11-18 03:11:21,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:21,139 INFO:     Epoch: 37
2022-11-18 03:11:21,902 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.805381553117619, 'Total loss': 0.805381553117619} | train loss {'Reaction outcome loss': 0.8146288172330385, 'Total loss': 0.8146288172330385}
2022-11-18 03:11:21,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:21,903 INFO:     Epoch: 38
2022-11-18 03:11:22,686 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7833193180172943, 'Total loss': 0.7833193180172943} | train loss {'Reaction outcome loss': 0.809004714766157, 'Total loss': 0.809004714766157}
2022-11-18 03:11:22,687 INFO:     Found new best model at epoch 38
2022-11-18 03:11:22,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:22,687 INFO:     Epoch: 39
2022-11-18 03:11:23,473 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7854141350402388, 'Total loss': 0.7854141350402388} | train loss {'Reaction outcome loss': 0.8136660612414404, 'Total loss': 0.8136660612414404}
2022-11-18 03:11:23,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:23,473 INFO:     Epoch: 40
2022-11-18 03:11:24,295 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7908504678066387, 'Total loss': 0.7908504678066387} | train loss {'Reaction outcome loss': 0.810548773886245, 'Total loss': 0.810548773886245}
2022-11-18 03:11:24,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:24,295 INFO:     Epoch: 41
2022-11-18 03:11:25,058 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7968530654907227, 'Total loss': 0.7968530654907227} | train loss {'Reaction outcome loss': 0.8112871823487459, 'Total loss': 0.8112871823487459}
2022-11-18 03:11:25,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:25,058 INFO:     Epoch: 42
2022-11-18 03:11:25,844 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8125365023003068, 'Total loss': 0.8125365023003068} | train loss {'Reaction outcome loss': 0.8135562861652531, 'Total loss': 0.8135562861652531}
2022-11-18 03:11:25,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:25,845 INFO:     Epoch: 43
2022-11-18 03:11:26,660 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7833020804926406, 'Total loss': 0.7833020804926406} | train loss {'Reaction outcome loss': 0.8126402249552095, 'Total loss': 0.8126402249552095}
2022-11-18 03:11:26,660 INFO:     Found new best model at epoch 43
2022-11-18 03:11:26,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:26,661 INFO:     Epoch: 44
2022-11-18 03:11:27,459 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8169150629708933, 'Total loss': 0.8169150629708933} | train loss {'Reaction outcome loss': 0.8103647741025367, 'Total loss': 0.8103647741025367}
2022-11-18 03:11:27,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:27,459 INFO:     Epoch: 45
2022-11-18 03:11:28,256 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8314109215902727, 'Total loss': 0.8314109215902727} | train loss {'Reaction outcome loss': 0.8133121261626114, 'Total loss': 0.8133121261626114}
2022-11-18 03:11:28,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:28,256 INFO:     Epoch: 46
2022-11-18 03:11:29,059 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7945817805999933, 'Total loss': 0.7945817805999933} | train loss {'Reaction outcome loss': 0.8157145392011713, 'Total loss': 0.8157145392011713}
2022-11-18 03:11:29,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:29,059 INFO:     Epoch: 47
2022-11-18 03:11:29,868 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7945700426434361, 'Total loss': 0.7945700426434361} | train loss {'Reaction outcome loss': 0.808223800158795, 'Total loss': 0.808223800158795}
2022-11-18 03:11:29,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:29,869 INFO:     Epoch: 48
2022-11-18 03:11:30,638 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7849729982919471, 'Total loss': 0.7849729982919471} | train loss {'Reaction outcome loss': 0.8147415524892846, 'Total loss': 0.8147415524892846}
2022-11-18 03:11:30,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:30,638 INFO:     Epoch: 49
2022-11-18 03:11:31,405 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8103785958400992, 'Total loss': 0.8103785958400992} | train loss {'Reaction outcome loss': 0.8141160167048498, 'Total loss': 0.8141160167048498}
2022-11-18 03:11:31,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:31,406 INFO:     Epoch: 50
2022-11-18 03:11:32,183 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7910393920055655, 'Total loss': 0.7910393920055655} | train loss {'Reaction outcome loss': 0.8112477801218936, 'Total loss': 0.8112477801218936}
2022-11-18 03:11:32,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:32,183 INFO:     Epoch: 51
2022-11-18 03:11:33,009 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8029805712921675, 'Total loss': 0.8029805712921675} | train loss {'Reaction outcome loss': 0.8102891587426142, 'Total loss': 0.8102891587426142}
2022-11-18 03:11:33,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:33,009 INFO:     Epoch: 52
2022-11-18 03:11:33,824 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8022019876990207, 'Total loss': 0.8022019876990207} | train loss {'Reaction outcome loss': 0.8102899871981193, 'Total loss': 0.8102899871981193}
2022-11-18 03:11:33,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:33,824 INFO:     Epoch: 53
2022-11-18 03:11:34,626 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7867514407911966, 'Total loss': 0.7867514407911966} | train loss {'Reaction outcome loss': 0.8110779581491839, 'Total loss': 0.8110779581491839}
2022-11-18 03:11:34,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:34,626 INFO:     Epoch: 54
2022-11-18 03:11:35,456 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.797115973954977, 'Total loss': 0.797115973954977} | train loss {'Reaction outcome loss': 0.8100778666543372, 'Total loss': 0.8100778666543372}
2022-11-18 03:11:35,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:35,456 INFO:     Epoch: 55
2022-11-18 03:11:36,255 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7995689046937365, 'Total loss': 0.7995689046937365} | train loss {'Reaction outcome loss': 0.81330751195366, 'Total loss': 0.81330751195366}
2022-11-18 03:11:36,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:36,255 INFO:     Epoch: 56
2022-11-18 03:11:37,032 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7946374430212864, 'Total loss': 0.7946374430212864} | train loss {'Reaction outcome loss': 0.807700672757969, 'Total loss': 0.807700672757969}
2022-11-18 03:11:37,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:37,032 INFO:     Epoch: 57
2022-11-18 03:11:37,838 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7986228784849477, 'Total loss': 0.7986228784849477} | train loss {'Reaction outcome loss': 0.8069609051623953, 'Total loss': 0.8069609051623953}
2022-11-18 03:11:37,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:37,838 INFO:     Epoch: 58
2022-11-18 03:11:38,652 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7920836376589399, 'Total loss': 0.7920836376589399} | train loss {'Reaction outcome loss': 0.8081125737217719, 'Total loss': 0.8081125737217719}
2022-11-18 03:11:38,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:38,654 INFO:     Epoch: 59
2022-11-18 03:11:39,476 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7902454900187116, 'Total loss': 0.7902454900187116} | train loss {'Reaction outcome loss': 0.8108826348320447, 'Total loss': 0.8108826348320447}
2022-11-18 03:11:39,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:39,476 INFO:     Epoch: 60
2022-11-18 03:11:40,244 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7850851146287696, 'Total loss': 0.7850851146287696} | train loss {'Reaction outcome loss': 0.8064757010328426, 'Total loss': 0.8064757010328426}
2022-11-18 03:11:40,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:40,244 INFO:     Epoch: 61
2022-11-18 03:11:41,059 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7807435788387476, 'Total loss': 0.7807435788387476} | train loss {'Reaction outcome loss': 0.817210959922139, 'Total loss': 0.817210959922139}
2022-11-18 03:11:41,059 INFO:     Found new best model at epoch 61
2022-11-18 03:11:41,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:41,060 INFO:     Epoch: 62
2022-11-18 03:11:41,838 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.78863540846248, 'Total loss': 0.78863540846248} | train loss {'Reaction outcome loss': 0.8101406909310769, 'Total loss': 0.8101406909310769}
2022-11-18 03:11:41,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:41,839 INFO:     Epoch: 63
2022-11-18 03:11:42,647 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7860273330710655, 'Total loss': 0.7860273330710655} | train loss {'Reaction outcome loss': 0.8103787273536494, 'Total loss': 0.8103787273536494}
2022-11-18 03:11:42,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:42,648 INFO:     Epoch: 64
2022-11-18 03:11:43,460 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8218361582866934, 'Total loss': 0.8218361582866934} | train loss {'Reaction outcome loss': 0.8075206135035542, 'Total loss': 0.8075206135035542}
2022-11-18 03:11:43,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:43,460 INFO:     Epoch: 65
2022-11-18 03:11:44,249 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8058897409328195, 'Total loss': 0.8058897409328195} | train loss {'Reaction outcome loss': 0.8122404622442928, 'Total loss': 0.8122404622442928}
2022-11-18 03:11:44,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:44,249 INFO:     Epoch: 66
2022-11-18 03:11:45,012 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7814895933450654, 'Total loss': 0.7814895933450654} | train loss {'Reaction outcome loss': 0.8128580067138123, 'Total loss': 0.8128580067138123}
2022-11-18 03:11:45,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:45,013 INFO:     Epoch: 67
2022-11-18 03:11:45,820 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7993965287541234, 'Total loss': 0.7993965287541234} | train loss {'Reaction outcome loss': 0.8116904492240874, 'Total loss': 0.8116904492240874}
2022-11-18 03:11:45,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:45,820 INFO:     Epoch: 68
2022-11-18 03:11:46,594 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7912146456019823, 'Total loss': 0.7912146456019823} | train loss {'Reaction outcome loss': 0.8110593446978817, 'Total loss': 0.8110593446978817}
2022-11-18 03:11:46,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:46,594 INFO:     Epoch: 69
2022-11-18 03:11:47,387 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8014369038648383, 'Total loss': 0.8014369038648383} | train loss {'Reaction outcome loss': 0.8145318818681034, 'Total loss': 0.8145318818681034}
2022-11-18 03:11:47,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:47,387 INFO:     Epoch: 70
2022-11-18 03:11:48,152 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7884102643922318, 'Total loss': 0.7884102643922318} | train loss {'Reaction outcome loss': 0.8136714798678096, 'Total loss': 0.8136714798678096}
2022-11-18 03:11:48,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:48,152 INFO:     Epoch: 71
2022-11-18 03:11:48,970 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7879709289517514, 'Total loss': 0.7879709289517514} | train loss {'Reaction outcome loss': 0.8098253418879254, 'Total loss': 0.8098253418879254}
2022-11-18 03:11:48,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:48,970 INFO:     Epoch: 72
2022-11-18 03:11:49,743 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7975584157677584, 'Total loss': 0.7975584157677584} | train loss {'Reaction outcome loss': 0.8113726863154659, 'Total loss': 0.8113726863154659}
2022-11-18 03:11:49,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:49,744 INFO:     Epoch: 73
2022-11-18 03:11:50,562 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7932813839856968, 'Total loss': 0.7932813839856968} | train loss {'Reaction outcome loss': 0.8102245847138848, 'Total loss': 0.8102245847138848}
2022-11-18 03:11:50,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:50,563 INFO:     Epoch: 74
2022-11-18 03:11:51,409 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7915097093859385, 'Total loss': 0.7915097093859385} | train loss {'Reaction outcome loss': 0.8063340886139575, 'Total loss': 0.8063340886139575}
2022-11-18 03:11:51,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:51,409 INFO:     Epoch: 75
2022-11-18 03:11:52,247 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7855216535024865, 'Total loss': 0.7855216535024865} | train loss {'Reaction outcome loss': 0.8045104431762616, 'Total loss': 0.8045104431762616}
2022-11-18 03:11:52,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:52,247 INFO:     Epoch: 76
2022-11-18 03:11:53,065 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8070504242597625, 'Total loss': 0.8070504242597625} | train loss {'Reaction outcome loss': 0.8121390026292683, 'Total loss': 0.8121390026292683}
2022-11-18 03:11:53,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:53,065 INFO:     Epoch: 77
2022-11-18 03:11:53,861 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7891947072605754, 'Total loss': 0.7891947072605754} | train loss {'Reaction outcome loss': 0.8064964641759425, 'Total loss': 0.8064964641759425}
2022-11-18 03:11:53,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:53,861 INFO:     Epoch: 78
2022-11-18 03:11:54,643 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8147289877714112, 'Total loss': 0.8147289877714112} | train loss {'Reaction outcome loss': 0.8126314788934135, 'Total loss': 0.8126314788934135}
2022-11-18 03:11:54,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:54,644 INFO:     Epoch: 79
2022-11-18 03:11:55,476 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8000169576600541, 'Total loss': 0.8000169576600541} | train loss {'Reaction outcome loss': 0.8059915042953727, 'Total loss': 0.8059915042953727}
2022-11-18 03:11:55,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:55,476 INFO:     Epoch: 80
2022-11-18 03:11:56,272 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8052523274754368, 'Total loss': 0.8052523274754368} | train loss {'Reaction outcome loss': 0.8079935048588018, 'Total loss': 0.8079935048588018}
2022-11-18 03:11:56,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:56,272 INFO:     Epoch: 81
2022-11-18 03:11:57,074 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8030270344989244, 'Total loss': 0.8030270344989244} | train loss {'Reaction outcome loss': 0.8124483444808442, 'Total loss': 0.8124483444808442}
2022-11-18 03:11:57,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:57,075 INFO:     Epoch: 82
2022-11-18 03:11:57,887 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8071350787961206, 'Total loss': 0.8071350787961206} | train loss {'Reaction outcome loss': 0.8070334308922537, 'Total loss': 0.8070334308922537}
2022-11-18 03:11:57,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:57,888 INFO:     Epoch: 83
2022-11-18 03:11:58,668 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7936283058898393, 'Total loss': 0.7936283058898393} | train loss {'Reaction outcome loss': 0.8097688911383044, 'Total loss': 0.8097688911383044}
2022-11-18 03:11:58,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:58,668 INFO:     Epoch: 84
2022-11-18 03:11:59,481 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7882246388945469, 'Total loss': 0.7882246388945469} | train loss {'Reaction outcome loss': 0.8063710264462993, 'Total loss': 0.8063710264462993}
2022-11-18 03:11:59,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:11:59,481 INFO:     Epoch: 85
2022-11-18 03:12:00,291 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.779466649127561, 'Total loss': 0.779466649127561} | train loss {'Reaction outcome loss': 0.8090591073772053, 'Total loss': 0.8090591073772053}
2022-11-18 03:12:00,291 INFO:     Found new best model at epoch 85
2022-11-18 03:12:00,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:00,292 INFO:     Epoch: 86
2022-11-18 03:12:01,065 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8071531071219333, 'Total loss': 0.8071531071219333} | train loss {'Reaction outcome loss': 0.8085821131129324, 'Total loss': 0.8085821131129324}
2022-11-18 03:12:01,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:01,065 INFO:     Epoch: 87
2022-11-18 03:12:01,835 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7856010912462722, 'Total loss': 0.7856010912462722} | train loss {'Reaction outcome loss': 0.8101901377670069, 'Total loss': 0.8101901377670069}
2022-11-18 03:12:01,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:01,835 INFO:     Epoch: 88
2022-11-18 03:12:02,663 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7848302597223327, 'Total loss': 0.7848302597223327} | train loss {'Reaction outcome loss': 0.8103076457486722, 'Total loss': 0.8103076457486722}
2022-11-18 03:12:02,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:02,663 INFO:     Epoch: 89
2022-11-18 03:12:03,482 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7953154763510061, 'Total loss': 0.7953154763510061} | train loss {'Reaction outcome loss': 0.8153520778373435, 'Total loss': 0.8153520778373435}
2022-11-18 03:12:03,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:03,483 INFO:     Epoch: 90
2022-11-18 03:12:04,271 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.783556705990503, 'Total loss': 0.783556705990503} | train loss {'Reaction outcome loss': 0.804934639621664, 'Total loss': 0.804934639621664}
2022-11-18 03:12:04,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:04,271 INFO:     Epoch: 91
2022-11-18 03:12:05,127 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7896989909715431, 'Total loss': 0.7896989909715431} | train loss {'Reaction outcome loss': 0.803411635474413, 'Total loss': 0.803411635474413}
2022-11-18 03:12:05,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:05,127 INFO:     Epoch: 92
2022-11-18 03:12:05,934 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7933834458506385, 'Total loss': 0.7933834458506385} | train loss {'Reaction outcome loss': 0.8128093068982348, 'Total loss': 0.8128093068982348}
2022-11-18 03:12:05,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:05,934 INFO:     Epoch: 93
2022-11-18 03:12:06,732 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7988692598287449, 'Total loss': 0.7988692598287449} | train loss {'Reaction outcome loss': 0.8102568119396398, 'Total loss': 0.8102568119396398}
2022-11-18 03:12:06,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:06,732 INFO:     Epoch: 94
2022-11-18 03:12:07,516 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7994977145694023, 'Total loss': 0.7994977145694023} | train loss {'Reaction outcome loss': 0.8079581705876339, 'Total loss': 0.8079581705876339}
2022-11-18 03:12:07,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:07,516 INFO:     Epoch: 95
2022-11-18 03:12:08,306 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7957975947579672, 'Total loss': 0.7957975947579672} | train loss {'Reaction outcome loss': 0.8029449557571254, 'Total loss': 0.8029449557571254}
2022-11-18 03:12:08,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:08,307 INFO:     Epoch: 96
2022-11-18 03:12:09,096 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7853685908539351, 'Total loss': 0.7853685908539351} | train loss {'Reaction outcome loss': 0.8020653522308961, 'Total loss': 0.8020653522308961}
2022-11-18 03:12:09,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:09,096 INFO:     Epoch: 97
2022-11-18 03:12:09,881 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.806833683058273, 'Total loss': 0.806833683058273} | train loss {'Reaction outcome loss': 0.8056498138011728, 'Total loss': 0.8056498138011728}
2022-11-18 03:12:09,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:09,883 INFO:     Epoch: 98
2022-11-18 03:12:10,697 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7976451530012973, 'Total loss': 0.7976451530012973} | train loss {'Reaction outcome loss': 0.8054191914114932, 'Total loss': 0.8054191914114932}
2022-11-18 03:12:10,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:10,697 INFO:     Epoch: 99
2022-11-18 03:12:11,497 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7794030398823494, 'Total loss': 0.7794030398823494} | train loss {'Reaction outcome loss': 0.8081384402979549, 'Total loss': 0.8081384402979549}
2022-11-18 03:12:11,497 INFO:     Found new best model at epoch 99
2022-11-18 03:12:11,498 INFO:     Best model found after epoch 100 of 100.
2022-11-18 03:12:11,498 INFO:   Done with stage: TRAINING
2022-11-18 03:12:11,498 INFO:   Starting stage: EVALUATION
2022-11-18 03:12:11,640 INFO:   Done with stage: EVALUATION
2022-11-18 03:12:11,640 INFO:   Leaving out SEQ value Fold_3
2022-11-18 03:12:11,653 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 03:12:11,653 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:12:12,322 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:12:12,322 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:12:12,393 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:12:12,393 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:12:12,393 INFO:     No hyperparam tuning for this model
2022-11-18 03:12:12,393 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:12:12,393 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:12:12,394 INFO:     None feature selector for col prot
2022-11-18 03:12:12,394 INFO:     None feature selector for col prot
2022-11-18 03:12:12,394 INFO:     None feature selector for col prot
2022-11-18 03:12:12,395 INFO:     None feature selector for col chem
2022-11-18 03:12:12,395 INFO:     None feature selector for col chem
2022-11-18 03:12:12,395 INFO:     None feature selector for col chem
2022-11-18 03:12:12,395 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:12:12,395 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:12:12,397 INFO:     Number of params in model 168571
2022-11-18 03:12:12,400 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:12:12,400 INFO:   Starting stage: TRAINING
2022-11-18 03:12:12,458 INFO:     Val loss before train {'Reaction outcome loss': 1.059923302043568, 'Total loss': 1.059923302043568}
2022-11-18 03:12:12,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:12,458 INFO:     Epoch: 0
2022-11-18 03:12:13,255 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9202573759989305, 'Total loss': 0.9202573759989305} | train loss {'Reaction outcome loss': 0.860522291611652, 'Total loss': 0.860522291611652}
2022-11-18 03:12:13,256 INFO:     Found new best model at epoch 0
2022-11-18 03:12:13,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:13,256 INFO:     Epoch: 1
2022-11-18 03:12:14,029 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8889088210734454, 'Total loss': 0.8889088210734454} | train loss {'Reaction outcome loss': 0.838566345706278, 'Total loss': 0.838566345706278}
2022-11-18 03:12:14,030 INFO:     Found new best model at epoch 1
2022-11-18 03:12:14,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:14,031 INFO:     Epoch: 2
2022-11-18 03:12:14,822 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8682372531091626, 'Total loss': 0.8682372531091626} | train loss {'Reaction outcome loss': 0.8294853223829853, 'Total loss': 0.8294853223829853}
2022-11-18 03:12:14,822 INFO:     Found new best model at epoch 2
2022-11-18 03:12:14,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:14,823 INFO:     Epoch: 3
2022-11-18 03:12:15,648 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8790612830357118, 'Total loss': 0.8790612830357118} | train loss {'Reaction outcome loss': 0.8271870423336418, 'Total loss': 0.8271870423336418}
2022-11-18 03:12:15,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:15,649 INFO:     Epoch: 4
2022-11-18 03:12:16,477 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8943791741674597, 'Total loss': 0.8943791741674597} | train loss {'Reaction outcome loss': 0.8217908308214071, 'Total loss': 0.8217908308214071}
2022-11-18 03:12:16,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:16,478 INFO:     Epoch: 5
2022-11-18 03:12:17,273 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8600869412449273, 'Total loss': 0.8600869412449273} | train loss {'Reaction outcome loss': 0.8194263795200659, 'Total loss': 0.8194263795200659}
2022-11-18 03:12:17,273 INFO:     Found new best model at epoch 5
2022-11-18 03:12:17,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:17,274 INFO:     Epoch: 6
2022-11-18 03:12:18,054 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8934528333219615, 'Total loss': 0.8934528333219615} | train loss {'Reaction outcome loss': 0.8152433965887342, 'Total loss': 0.8152433965887342}
2022-11-18 03:12:18,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:18,054 INFO:     Epoch: 7
2022-11-18 03:12:18,873 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8640863102945414, 'Total loss': 0.8640863102945414} | train loss {'Reaction outcome loss': 0.811824681320969, 'Total loss': 0.811824681320969}
2022-11-18 03:12:18,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:18,874 INFO:     Epoch: 8
2022-11-18 03:12:19,685 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8790101652795618, 'Total loss': 0.8790101652795618} | train loss {'Reaction outcome loss': 0.8149601197972589, 'Total loss': 0.8149601197972589}
2022-11-18 03:12:19,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:19,685 INFO:     Epoch: 9
2022-11-18 03:12:20,453 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8911289714954116, 'Total loss': 0.8911289714954116} | train loss {'Reaction outcome loss': 0.8121385064660286, 'Total loss': 0.8121385064660286}
2022-11-18 03:12:20,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:20,453 INFO:     Epoch: 10
2022-11-18 03:12:21,265 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8708297529003837, 'Total loss': 0.8708297529003837} | train loss {'Reaction outcome loss': 0.8112129749084006, 'Total loss': 0.8112129749084006}
2022-11-18 03:12:21,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:21,265 INFO:     Epoch: 11
2022-11-18 03:12:22,062 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8741841194304553, 'Total loss': 0.8741841194304553} | train loss {'Reaction outcome loss': 0.8143618940090647, 'Total loss': 0.8143618940090647}
2022-11-18 03:12:22,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:22,063 INFO:     Epoch: 12
2022-11-18 03:12:22,864 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8698810603130948, 'Total loss': 0.8698810603130948} | train loss {'Reaction outcome loss': 0.8058186871664864, 'Total loss': 0.8058186871664864}
2022-11-18 03:12:22,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:22,865 INFO:     Epoch: 13
2022-11-18 03:12:23,680 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8614272901957686, 'Total loss': 0.8614272901957686} | train loss {'Reaction outcome loss': 0.8112248109311474, 'Total loss': 0.8112248109311474}
2022-11-18 03:12:23,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:23,680 INFO:     Epoch: 14
2022-11-18 03:12:24,525 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8664106889204546, 'Total loss': 0.8664106889204546} | train loss {'Reaction outcome loss': 0.8096409845108888, 'Total loss': 0.8096409845108888}
2022-11-18 03:12:24,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:24,525 INFO:     Epoch: 15
2022-11-18 03:12:25,345 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.862397775053978, 'Total loss': 0.862397775053978} | train loss {'Reaction outcome loss': 0.8089793419351383, 'Total loss': 0.8089793419351383}
2022-11-18 03:12:25,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:25,345 INFO:     Epoch: 16
2022-11-18 03:12:26,185 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8717178140174259, 'Total loss': 0.8717178140174259} | train loss {'Reaction outcome loss': 0.807393057978883, 'Total loss': 0.807393057978883}
2022-11-18 03:12:26,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:26,185 INFO:     Epoch: 17
2022-11-18 03:12:26,972 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8645559310574423, 'Total loss': 0.8645559310574423} | train loss {'Reaction outcome loss': 0.8062026015349797, 'Total loss': 0.8062026015349797}
2022-11-18 03:12:26,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:26,973 INFO:     Epoch: 18
2022-11-18 03:12:27,780 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.882230438969352, 'Total loss': 0.882230438969352} | train loss {'Reaction outcome loss': 0.807217836501647, 'Total loss': 0.807217836501647}
2022-11-18 03:12:27,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:27,780 INFO:     Epoch: 19
2022-11-18 03:12:28,558 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8663598244840448, 'Total loss': 0.8663598244840448} | train loss {'Reaction outcome loss': 0.8024148860756232, 'Total loss': 0.8024148860756232}
2022-11-18 03:12:28,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:28,559 INFO:     Epoch: 20
2022-11-18 03:12:29,377 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8661134642633525, 'Total loss': 0.8661134642633525} | train loss {'Reaction outcome loss': 0.803228844428549, 'Total loss': 0.803228844428549}
2022-11-18 03:12:29,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:29,377 INFO:     Epoch: 21
2022-11-18 03:12:30,157 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.9024418111551892, 'Total loss': 0.9024418111551892} | train loss {'Reaction outcome loss': 0.8045203556819838, 'Total loss': 0.8045203556819838}
2022-11-18 03:12:30,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:30,158 INFO:     Epoch: 22
2022-11-18 03:12:30,944 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8701618984341621, 'Total loss': 0.8701618984341621} | train loss {'Reaction outcome loss': 0.8063710179864144, 'Total loss': 0.8063710179864144}
2022-11-18 03:12:30,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:30,944 INFO:     Epoch: 23
2022-11-18 03:12:31,741 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8699900548566472, 'Total loss': 0.8699900548566472} | train loss {'Reaction outcome loss': 0.8061184414795467, 'Total loss': 0.8061184414795467}
2022-11-18 03:12:31,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:31,742 INFO:     Epoch: 24
2022-11-18 03:12:32,555 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8664465018294074, 'Total loss': 0.8664465018294074} | train loss {'Reaction outcome loss': 0.8047392964363098, 'Total loss': 0.8047392964363098}
2022-11-18 03:12:32,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:32,556 INFO:     Epoch: 25
2022-11-18 03:12:33,377 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8659589913758364, 'Total loss': 0.8659589913758364} | train loss {'Reaction outcome loss': 0.8052662312984467, 'Total loss': 0.8052662312984467}
2022-11-18 03:12:33,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:33,377 INFO:     Epoch: 26
2022-11-18 03:12:34,154 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8552894578738646, 'Total loss': 0.8552894578738646} | train loss {'Reaction outcome loss': 0.8043554876531873, 'Total loss': 0.8043554876531873}
2022-11-18 03:12:34,154 INFO:     Found new best model at epoch 26
2022-11-18 03:12:34,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:34,155 INFO:     Epoch: 27
2022-11-18 03:12:34,956 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8823984170501883, 'Total loss': 0.8823984170501883} | train loss {'Reaction outcome loss': 0.8039190252216495, 'Total loss': 0.8039190252216495}
2022-11-18 03:12:34,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:34,957 INFO:     Epoch: 28
2022-11-18 03:12:35,735 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8841176960955967, 'Total loss': 0.8841176960955967} | train loss {'Reaction outcome loss': 0.8035266388435753, 'Total loss': 0.8035266388435753}
2022-11-18 03:12:35,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:35,735 INFO:     Epoch: 29
2022-11-18 03:12:36,548 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8637262826616113, 'Total loss': 0.8637262826616113} | train loss {'Reaction outcome loss': 0.80139759924947, 'Total loss': 0.80139759924947}
2022-11-18 03:12:36,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:36,548 INFO:     Epoch: 30
2022-11-18 03:12:37,338 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8728459938005968, 'Total loss': 0.8728459938005968} | train loss {'Reaction outcome loss': 0.8012618613486387, 'Total loss': 0.8012618613486387}
2022-11-18 03:12:37,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:37,339 INFO:     Epoch: 31
2022-11-18 03:12:38,155 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8928667063062842, 'Total loss': 0.8928667063062842} | train loss {'Reaction outcome loss': 0.8023937180334207, 'Total loss': 0.8023937180334207}
2022-11-18 03:12:38,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:38,155 INFO:     Epoch: 32
2022-11-18 03:12:38,953 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8984156874093142, 'Total loss': 0.8984156874093142} | train loss {'Reaction outcome loss': 0.8034384759104982, 'Total loss': 0.8034384759104982}
2022-11-18 03:12:38,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:38,953 INFO:     Epoch: 33
2022-11-18 03:12:39,791 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8595200330018997, 'Total loss': 0.8595200330018997} | train loss {'Reaction outcome loss': 0.804340468255841, 'Total loss': 0.804340468255841}
2022-11-18 03:12:39,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:39,791 INFO:     Epoch: 34
2022-11-18 03:12:40,593 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8594954068010504, 'Total loss': 0.8594954068010504} | train loss {'Reaction outcome loss': 0.8076357486296674, 'Total loss': 0.8076357486296674}
2022-11-18 03:12:40,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:40,595 INFO:     Epoch: 35
2022-11-18 03:12:41,382 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8839998624541543, 'Total loss': 0.8839998624541543} | train loss {'Reaction outcome loss': 0.8018075220438898, 'Total loss': 0.8018075220438898}
2022-11-18 03:12:41,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:41,382 INFO:     Epoch: 36
2022-11-18 03:12:42,193 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8680823662064292, 'Total loss': 0.8680823662064292} | train loss {'Reaction outcome loss': 0.8048833669448385, 'Total loss': 0.8048833669448385}
2022-11-18 03:12:42,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:42,194 INFO:     Epoch: 37
2022-11-18 03:12:43,018 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8470028936862946, 'Total loss': 0.8470028936862946} | train loss {'Reaction outcome loss': 0.8011266260730977, 'Total loss': 0.8011266260730977}
2022-11-18 03:12:43,018 INFO:     Found new best model at epoch 37
2022-11-18 03:12:43,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:43,019 INFO:     Epoch: 38
2022-11-18 03:12:43,797 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.9027404981580648, 'Total loss': 0.9027404981580648} | train loss {'Reaction outcome loss': 0.8025912984293334, 'Total loss': 0.8025912984293334}
2022-11-18 03:12:43,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:43,797 INFO:     Epoch: 39
2022-11-18 03:12:44,564 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8847392648458481, 'Total loss': 0.8847392648458481} | train loss {'Reaction outcome loss': 0.8030882257588056, 'Total loss': 0.8030882257588056}
2022-11-18 03:12:44,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:44,564 INFO:     Epoch: 40
2022-11-18 03:12:45,398 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8794283995574171, 'Total loss': 0.8794283995574171} | train loss {'Reaction outcome loss': 0.8033560477957433, 'Total loss': 0.8033560477957433}
2022-11-18 03:12:45,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:45,398 INFO:     Epoch: 41
2022-11-18 03:12:46,232 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.880105355923826, 'Total loss': 0.880105355923826} | train loss {'Reaction outcome loss': 0.80066810347596, 'Total loss': 0.80066810347596}
2022-11-18 03:12:46,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:46,233 INFO:     Epoch: 42
2022-11-18 03:12:47,023 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8858413967219266, 'Total loss': 0.8858413967219266} | train loss {'Reaction outcome loss': 0.8030274147890052, 'Total loss': 0.8030274147890052}
2022-11-18 03:12:47,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:47,024 INFO:     Epoch: 43
2022-11-18 03:12:47,801 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8669545460831035, 'Total loss': 0.8669545460831035} | train loss {'Reaction outcome loss': 0.8051881161271309, 'Total loss': 0.8051881161271309}
2022-11-18 03:12:47,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:47,802 INFO:     Epoch: 44
2022-11-18 03:12:48,575 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8577213924039494, 'Total loss': 0.8577213924039494} | train loss {'Reaction outcome loss': 0.8055854854535084, 'Total loss': 0.8055854854535084}
2022-11-18 03:12:48,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:48,576 INFO:     Epoch: 45
2022-11-18 03:12:49,394 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.856952082704414, 'Total loss': 0.856952082704414} | train loss {'Reaction outcome loss': 0.8017962154077024, 'Total loss': 0.8017962154077024}
2022-11-18 03:12:49,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:49,394 INFO:     Epoch: 46
2022-11-18 03:12:50,180 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8510995290496133, 'Total loss': 0.8510995290496133} | train loss {'Reaction outcome loss': 0.8050337292710129, 'Total loss': 0.8050337292710129}
2022-11-18 03:12:50,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:50,180 INFO:     Epoch: 47
2022-11-18 03:12:50,993 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8726944923400879, 'Total loss': 0.8726944923400879} | train loss {'Reaction outcome loss': 0.8019307396849807, 'Total loss': 0.8019307396849807}
2022-11-18 03:12:50,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:50,993 INFO:     Epoch: 48
2022-11-18 03:12:51,834 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8772207329219038, 'Total loss': 0.8772207329219038} | train loss {'Reaction outcome loss': 0.8026691517051385, 'Total loss': 0.8026691517051385}
2022-11-18 03:12:51,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:51,834 INFO:     Epoch: 49
2022-11-18 03:12:52,643 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8735055307095702, 'Total loss': 0.8735055307095702} | train loss {'Reaction outcome loss': 0.8052009541161206, 'Total loss': 0.8052009541161206}
2022-11-18 03:12:52,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:52,643 INFO:     Epoch: 50
2022-11-18 03:12:53,428 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8854761550372298, 'Total loss': 0.8854761550372298} | train loss {'Reaction outcome loss': 0.8067534333589126, 'Total loss': 0.8067534333589126}
2022-11-18 03:12:53,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:53,428 INFO:     Epoch: 51
2022-11-18 03:12:54,242 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8670724820006978, 'Total loss': 0.8670724820006978} | train loss {'Reaction outcome loss': 0.7996047248645705, 'Total loss': 0.7996047248645705}
2022-11-18 03:12:54,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:54,243 INFO:     Epoch: 52
2022-11-18 03:12:55,060 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8467287075790492, 'Total loss': 0.8467287075790492} | train loss {'Reaction outcome loss': 0.8013475466747673, 'Total loss': 0.8013475466747673}
2022-11-18 03:12:55,060 INFO:     Found new best model at epoch 52
2022-11-18 03:12:55,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:55,061 INFO:     Epoch: 53
2022-11-18 03:12:55,853 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8541620463471521, 'Total loss': 0.8541620463471521} | train loss {'Reaction outcome loss': 0.8059854975768498, 'Total loss': 0.8059854975768498}
2022-11-18 03:12:55,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:55,853 INFO:     Epoch: 54
2022-11-18 03:12:56,690 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8676343296061862, 'Total loss': 0.8676343296061862} | train loss {'Reaction outcome loss': 0.801813092888618, 'Total loss': 0.801813092888618}
2022-11-18 03:12:56,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:56,690 INFO:     Epoch: 55
2022-11-18 03:12:57,487 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8694249797951091, 'Total loss': 0.8694249797951091} | train loss {'Reaction outcome loss': 0.8025630129843342, 'Total loss': 0.8025630129843342}
2022-11-18 03:12:57,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:57,488 INFO:     Epoch: 56
2022-11-18 03:12:58,298 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.867445972155441, 'Total loss': 0.867445972155441} | train loss {'Reaction outcome loss': 0.8041678793576299, 'Total loss': 0.8041678793576299}
2022-11-18 03:12:58,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:58,298 INFO:     Epoch: 57
2022-11-18 03:12:59,089 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8812654214826497, 'Total loss': 0.8812654214826497} | train loss {'Reaction outcome loss': 0.8016394684509355, 'Total loss': 0.8016394684509355}
2022-11-18 03:12:59,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:59,090 INFO:     Epoch: 58
2022-11-18 03:12:59,914 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8732679269530557, 'Total loss': 0.8732679269530557} | train loss {'Reaction outcome loss': 0.8023610093155685, 'Total loss': 0.8023610093155685}
2022-11-18 03:12:59,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:12:59,914 INFO:     Epoch: 59
2022-11-18 03:13:00,711 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8541973707350817, 'Total loss': 0.8541973707350817} | train loss {'Reaction outcome loss': 0.8020823159996344, 'Total loss': 0.8020823159996344}
2022-11-18 03:13:00,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:00,712 INFO:     Epoch: 60
2022-11-18 03:13:01,556 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8985798182812604, 'Total loss': 0.8985798182812604} | train loss {'Reaction outcome loss': 0.8013632679472165, 'Total loss': 0.8013632679472165}
2022-11-18 03:13:01,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:01,556 INFO:     Epoch: 61
2022-11-18 03:13:02,401 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8663224604996768, 'Total loss': 0.8663224604996768} | train loss {'Reaction outcome loss': 0.7981690938375434, 'Total loss': 0.7981690938375434}
2022-11-18 03:13:02,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:02,402 INFO:     Epoch: 62
2022-11-18 03:13:03,236 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8559909198771823, 'Total loss': 0.8559909198771823} | train loss {'Reaction outcome loss': 0.8024519060339247, 'Total loss': 0.8024519060339247}
2022-11-18 03:13:03,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:03,236 INFO:     Epoch: 63
2022-11-18 03:13:04,059 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8661407564174045, 'Total loss': 0.8661407564174045} | train loss {'Reaction outcome loss': 0.8015783972886144, 'Total loss': 0.8015783972886144}
2022-11-18 03:13:04,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:04,059 INFO:     Epoch: 64
2022-11-18 03:13:04,900 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8649371652440592, 'Total loss': 0.8649371652440592} | train loss {'Reaction outcome loss': 0.8034846699967676, 'Total loss': 0.8034846699967676}
2022-11-18 03:13:04,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:04,900 INFO:     Epoch: 65
2022-11-18 03:13:05,712 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8735727593302727, 'Total loss': 0.8735727593302727} | train loss {'Reaction outcome loss': 0.8019563275940564, 'Total loss': 0.8019563275940564}
2022-11-18 03:13:05,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:05,712 INFO:     Epoch: 66
2022-11-18 03:13:06,588 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8960825685750354, 'Total loss': 0.8960825685750354} | train loss {'Reaction outcome loss': 0.8052815388660042, 'Total loss': 0.8052815388660042}
2022-11-18 03:13:06,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:06,588 INFO:     Epoch: 67
2022-11-18 03:13:07,368 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8869627781889655, 'Total loss': 0.8869627781889655} | train loss {'Reaction outcome loss': 0.8057764324606681, 'Total loss': 0.8057764324606681}
2022-11-18 03:13:07,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:07,369 INFO:     Epoch: 68
2022-11-18 03:13:08,159 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8736895959485661, 'Total loss': 0.8736895959485661} | train loss {'Reaction outcome loss': 0.8063752066115943, 'Total loss': 0.8063752066115943}
2022-11-18 03:13:08,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:08,160 INFO:     Epoch: 69
2022-11-18 03:13:08,973 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.889917182651433, 'Total loss': 0.889917182651433} | train loss {'Reaction outcome loss': 0.804140830039978, 'Total loss': 0.804140830039978}
2022-11-18 03:13:08,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:08,973 INFO:     Epoch: 70
2022-11-18 03:13:09,788 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8946306353265588, 'Total loss': 0.8946306353265588} | train loss {'Reaction outcome loss': 0.8036691942993476, 'Total loss': 0.8036691942993476}
2022-11-18 03:13:09,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:09,788 INFO:     Epoch: 71
2022-11-18 03:13:10,606 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8645426204258745, 'Total loss': 0.8645426204258745} | train loss {'Reaction outcome loss': 0.8068495619053744, 'Total loss': 0.8068495619053744}
2022-11-18 03:13:10,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:10,606 INFO:     Epoch: 72
2022-11-18 03:13:11,416 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.848377565768632, 'Total loss': 0.848377565768632} | train loss {'Reaction outcome loss': 0.8029748369236381, 'Total loss': 0.8029748369236381}
2022-11-18 03:13:11,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:11,416 INFO:     Epoch: 73
2022-11-18 03:13:12,210 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8631165169856765, 'Total loss': 0.8631165169856765} | train loss {'Reaction outcome loss': 0.8054920206264574, 'Total loss': 0.8054920206264574}
2022-11-18 03:13:12,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:12,211 INFO:     Epoch: 74
2022-11-18 03:13:12,955 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8676477548750964, 'Total loss': 0.8676477548750964} | train loss {'Reaction outcome loss': 0.8046929218331161, 'Total loss': 0.8046929218331161}
2022-11-18 03:13:12,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:12,955 INFO:     Epoch: 75
2022-11-18 03:13:13,762 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8626419461586259, 'Total loss': 0.8626419461586259} | train loss {'Reaction outcome loss': 0.7979775670839816, 'Total loss': 0.7979775670839816}
2022-11-18 03:13:13,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:13,762 INFO:     Epoch: 76
2022-11-18 03:13:14,532 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8831930499185215, 'Total loss': 0.8831930499185215} | train loss {'Reaction outcome loss': 0.8030830085277557, 'Total loss': 0.8030830085277557}
2022-11-18 03:13:14,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:14,532 INFO:     Epoch: 77
2022-11-18 03:13:15,316 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8852611477063461, 'Total loss': 0.8852611477063461} | train loss {'Reaction outcome loss': 0.8014860627602558, 'Total loss': 0.8014860627602558}
2022-11-18 03:13:15,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:15,316 INFO:     Epoch: 78
2022-11-18 03:13:16,110 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8663813959468495, 'Total loss': 0.8663813959468495} | train loss {'Reaction outcome loss': 0.803829497342207, 'Total loss': 0.803829497342207}
2022-11-18 03:13:16,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:16,111 INFO:     Epoch: 79
2022-11-18 03:13:16,936 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8881027590144764, 'Total loss': 0.8881027590144764} | train loss {'Reaction outcome loss': 0.8031049423071803, 'Total loss': 0.8031049423071803}
2022-11-18 03:13:16,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:16,936 INFO:     Epoch: 80
2022-11-18 03:13:17,737 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8817980113354597, 'Total loss': 0.8817980113354597} | train loss {'Reaction outcome loss': 0.8035480586849914, 'Total loss': 0.8035480586849914}
2022-11-18 03:13:17,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:17,737 INFO:     Epoch: 81
2022-11-18 03:13:18,540 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.9373535500331358, 'Total loss': 0.9373535500331358} | train loss {'Reaction outcome loss': 0.7998715720614609, 'Total loss': 0.7998715720614609}
2022-11-18 03:13:18,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:18,541 INFO:     Epoch: 82
2022-11-18 03:13:19,337 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8646157783540812, 'Total loss': 0.8646157783540812} | train loss {'Reaction outcome loss': 0.8038790421826499, 'Total loss': 0.8038790421826499}
2022-11-18 03:13:19,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:19,338 INFO:     Epoch: 83
2022-11-18 03:13:20,141 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.887650573795492, 'Total loss': 0.887650573795492} | train loss {'Reaction outcome loss': 0.8005706957408361, 'Total loss': 0.8005706957408361}
2022-11-18 03:13:20,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:20,141 INFO:     Epoch: 84
2022-11-18 03:13:20,940 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8646042848175223, 'Total loss': 0.8646042848175223} | train loss {'Reaction outcome loss': 0.8027622541602777, 'Total loss': 0.8027622541602777}
2022-11-18 03:13:20,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:20,940 INFO:     Epoch: 85
2022-11-18 03:13:21,712 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8713987733830105, 'Total loss': 0.8713987733830105} | train loss {'Reaction outcome loss': 0.8024796417781285, 'Total loss': 0.8024796417781285}
2022-11-18 03:13:21,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:21,713 INFO:     Epoch: 86
2022-11-18 03:13:22,489 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8619776882908561, 'Total loss': 0.8619776882908561} | train loss {'Reaction outcome loss': 0.8021214002249192, 'Total loss': 0.8021214002249192}
2022-11-18 03:13:22,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:22,489 INFO:     Epoch: 87
2022-11-18 03:13:23,280 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8568069362504915, 'Total loss': 0.8568069362504915} | train loss {'Reaction outcome loss': 0.8036835764135634, 'Total loss': 0.8036835764135634}
2022-11-18 03:13:23,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:23,280 INFO:     Epoch: 88
2022-11-18 03:13:24,108 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8807193020528014, 'Total loss': 0.8807193020528014} | train loss {'Reaction outcome loss': 0.8017206896324547, 'Total loss': 0.8017206896324547}
2022-11-18 03:13:24,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:24,109 INFO:     Epoch: 89
2022-11-18 03:13:24,886 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8963350335305388, 'Total loss': 0.8963350335305388} | train loss {'Reaction outcome loss': 0.8055932043766488, 'Total loss': 0.8055932043766488}
2022-11-18 03:13:24,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:24,887 INFO:     Epoch: 90
2022-11-18 03:13:25,714 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8830106962810863, 'Total loss': 0.8830106962810863} | train loss {'Reaction outcome loss': 0.8089481556902126, 'Total loss': 0.8089481556902126}
2022-11-18 03:13:25,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:25,714 INFO:     Epoch: 91
2022-11-18 03:13:26,489 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8512190573594787, 'Total loss': 0.8512190573594787} | train loss {'Reaction outcome loss': 0.8015985780832718, 'Total loss': 0.8015985780832718}
2022-11-18 03:13:26,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:26,490 INFO:     Epoch: 92
2022-11-18 03:13:27,332 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8611725582317873, 'Total loss': 0.8611725582317873} | train loss {'Reaction outcome loss': 0.8008928162711008, 'Total loss': 0.8008928162711008}
2022-11-18 03:13:27,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:27,332 INFO:     Epoch: 93
2022-11-18 03:13:28,148 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8617082041772929, 'Total loss': 0.8617082041772929} | train loss {'Reaction outcome loss': 0.8011726511984455, 'Total loss': 0.8011726511984455}
2022-11-18 03:13:28,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:28,148 INFO:     Epoch: 94
2022-11-18 03:13:28,953 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8780150609937581, 'Total loss': 0.8780150609937581} | train loss {'Reaction outcome loss': 0.8069671029947242, 'Total loss': 0.8069671029947242}
2022-11-18 03:13:28,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:28,954 INFO:     Epoch: 95
2022-11-18 03:13:29,746 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8738022243434732, 'Total loss': 0.8738022243434732} | train loss {'Reaction outcome loss': 0.8063617553029742, 'Total loss': 0.8063617553029742}
2022-11-18 03:13:29,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:29,746 INFO:     Epoch: 96
2022-11-18 03:13:30,523 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8832540600137277, 'Total loss': 0.8832540600137277} | train loss {'Reaction outcome loss': 0.8030408066146227, 'Total loss': 0.8030408066146227}
2022-11-18 03:13:30,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:30,523 INFO:     Epoch: 97
2022-11-18 03:13:31,329 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8714948012070223, 'Total loss': 0.8714948012070223} | train loss {'Reaction outcome loss': 0.8049745126646393, 'Total loss': 0.8049745126646393}
2022-11-18 03:13:31,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:31,330 INFO:     Epoch: 98
2022-11-18 03:13:32,147 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8784823167053136, 'Total loss': 0.8784823167053136} | train loss {'Reaction outcome loss': 0.8019909245627267, 'Total loss': 0.8019909245627267}
2022-11-18 03:13:32,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:32,147 INFO:     Epoch: 99
2022-11-18 03:13:32,938 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8904635032469576, 'Total loss': 0.8904635032469576} | train loss {'Reaction outcome loss': 0.8007142877092167, 'Total loss': 0.8007142877092167}
2022-11-18 03:13:32,938 INFO:     Best model found after epoch 53 of 100.
2022-11-18 03:13:32,939 INFO:   Done with stage: TRAINING
2022-11-18 03:13:32,939 INFO:   Starting stage: EVALUATION
2022-11-18 03:13:33,068 INFO:   Done with stage: EVALUATION
2022-11-18 03:13:33,068 INFO:   Leaving out SEQ value Fold_4
2022-11-18 03:13:33,084 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:13:33,085 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:13:33,765 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:13:33,765 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:13:33,835 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:13:33,835 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:13:33,835 INFO:     No hyperparam tuning for this model
2022-11-18 03:13:33,835 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:13:33,835 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:13:33,836 INFO:     None feature selector for col prot
2022-11-18 03:13:33,836 INFO:     None feature selector for col prot
2022-11-18 03:13:33,836 INFO:     None feature selector for col prot
2022-11-18 03:13:33,837 INFO:     None feature selector for col chem
2022-11-18 03:13:33,837 INFO:     None feature selector for col chem
2022-11-18 03:13:33,837 INFO:     None feature selector for col chem
2022-11-18 03:13:33,837 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:13:33,837 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:13:33,839 INFO:     Number of params in model 168571
2022-11-18 03:13:33,842 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:13:33,842 INFO:   Starting stage: TRAINING
2022-11-18 03:13:33,900 INFO:     Val loss before train {'Reaction outcome loss': 1.0157046548344872, 'Total loss': 1.0157046548344872}
2022-11-18 03:13:33,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:33,900 INFO:     Epoch: 0
2022-11-18 03:13:34,717 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8712325868281451, 'Total loss': 0.8712325868281451} | train loss {'Reaction outcome loss': 0.8927914416117053, 'Total loss': 0.8927914416117053}
2022-11-18 03:13:34,717 INFO:     Found new best model at epoch 0
2022-11-18 03:13:34,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:34,718 INFO:     Epoch: 1
2022-11-18 03:13:35,561 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8815161003307863, 'Total loss': 0.8815161003307863} | train loss {'Reaction outcome loss': 0.8589594659786071, 'Total loss': 0.8589594659786071}
2022-11-18 03:13:35,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:35,562 INFO:     Epoch: 2
2022-11-18 03:13:36,355 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8329379951412027, 'Total loss': 0.8329379951412027} | train loss {'Reaction outcome loss': 0.8517436057088836, 'Total loss': 0.8517436057088836}
2022-11-18 03:13:36,356 INFO:     Found new best model at epoch 2
2022-11-18 03:13:36,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:36,356 INFO:     Epoch: 3
2022-11-18 03:13:37,172 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8455304862423376, 'Total loss': 0.8455304862423376} | train loss {'Reaction outcome loss': 0.8446898721158504, 'Total loss': 0.8446898721158504}
2022-11-18 03:13:37,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:37,172 INFO:     Epoch: 4
2022-11-18 03:13:37,939 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8336592770435594, 'Total loss': 0.8336592770435594} | train loss {'Reaction outcome loss': 0.8477900195265969, 'Total loss': 0.8477900195265969}
2022-11-18 03:13:37,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:37,939 INFO:     Epoch: 5
2022-11-18 03:13:38,744 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8392400206489996, 'Total loss': 0.8392400206489996} | train loss {'Reaction outcome loss': 0.8415003064418992, 'Total loss': 0.8415003064418992}
2022-11-18 03:13:38,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:38,744 INFO:     Epoch: 6
2022-11-18 03:13:39,535 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8219737396998839, 'Total loss': 0.8219737396998839} | train loss {'Reaction outcome loss': 0.8365276667379564, 'Total loss': 0.8365276667379564}
2022-11-18 03:13:39,535 INFO:     Found new best model at epoch 6
2022-11-18 03:13:39,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:39,536 INFO:     Epoch: 7
2022-11-18 03:13:40,297 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8652171492576599, 'Total loss': 0.8652171492576599} | train loss {'Reaction outcome loss': 0.8374113376823163, 'Total loss': 0.8374113376823163}
2022-11-18 03:13:40,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:40,297 INFO:     Epoch: 8
2022-11-18 03:13:41,074 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8305413485928015, 'Total loss': 0.8305413485928015} | train loss {'Reaction outcome loss': 0.840283653308307, 'Total loss': 0.840283653308307}
2022-11-18 03:13:41,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:41,075 INFO:     Epoch: 9
2022-11-18 03:13:41,864 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8193292793902484, 'Total loss': 0.8193292793902484} | train loss {'Reaction outcome loss': 0.8325929183873438, 'Total loss': 0.8325929183873438}
2022-11-18 03:13:41,864 INFO:     Found new best model at epoch 9
2022-11-18 03:13:41,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:41,865 INFO:     Epoch: 10
2022-11-18 03:13:42,658 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8298790346492421, 'Total loss': 0.8298790346492421} | train loss {'Reaction outcome loss': 0.8291695896656283, 'Total loss': 0.8291695896656283}
2022-11-18 03:13:42,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:42,658 INFO:     Epoch: 11
2022-11-18 03:13:43,429 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8438542214306918, 'Total loss': 0.8438542214306918} | train loss {'Reaction outcome loss': 0.8318958308908248, 'Total loss': 0.8318958308908248}
2022-11-18 03:13:43,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:43,431 INFO:     Epoch: 12
2022-11-18 03:13:44,193 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8286759047345682, 'Total loss': 0.8286759047345682} | train loss {'Reaction outcome loss': 0.8300740598070044, 'Total loss': 0.8300740598070044}
2022-11-18 03:13:44,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:44,193 INFO:     Epoch: 13
2022-11-18 03:13:44,960 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8256191672249273, 'Total loss': 0.8256191672249273} | train loss {'Reaction outcome loss': 0.8301401681477024, 'Total loss': 0.8301401681477024}
2022-11-18 03:13:44,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:44,961 INFO:     Epoch: 14
2022-11-18 03:13:45,780 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8369425779039209, 'Total loss': 0.8369425779039209} | train loss {'Reaction outcome loss': 0.8249508350366547, 'Total loss': 0.8249508350366547}
2022-11-18 03:13:45,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:45,780 INFO:     Epoch: 15
2022-11-18 03:13:46,536 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8198436965996568, 'Total loss': 0.8198436965996568} | train loss {'Reaction outcome loss': 0.8299257512534818, 'Total loss': 0.8299257512534818}
2022-11-18 03:13:46,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:46,536 INFO:     Epoch: 16
2022-11-18 03:13:47,307 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8332257264039733, 'Total loss': 0.8332257264039733} | train loss {'Reaction outcome loss': 0.8325865965697073, 'Total loss': 0.8325865965697073}
2022-11-18 03:13:47,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:47,307 INFO:     Epoch: 17
2022-11-18 03:13:48,101 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8410318493843079, 'Total loss': 0.8410318493843079} | train loss {'Reaction outcome loss': 0.830593840609635, 'Total loss': 0.830593840609635}
2022-11-18 03:13:48,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:48,101 INFO:     Epoch: 18
2022-11-18 03:13:48,864 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8270756873217496, 'Total loss': 0.8270756873217496} | train loss {'Reaction outcome loss': 0.8299810388876546, 'Total loss': 0.8299810388876546}
2022-11-18 03:13:48,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:48,864 INFO:     Epoch: 19
2022-11-18 03:13:49,636 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.876701371236281, 'Total loss': 0.876701371236281} | train loss {'Reaction outcome loss': 0.8285865163610827, 'Total loss': 0.8285865163610827}
2022-11-18 03:13:49,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:49,637 INFO:     Epoch: 20
2022-11-18 03:13:50,462 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.809467573734847, 'Total loss': 0.809467573734847} | train loss {'Reaction outcome loss': 0.8281343988473376, 'Total loss': 0.8281343988473376}
2022-11-18 03:13:50,462 INFO:     Found new best model at epoch 20
2022-11-18 03:13:50,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:50,463 INFO:     Epoch: 21
2022-11-18 03:13:51,291 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8218201249837875, 'Total loss': 0.8218201249837875} | train loss {'Reaction outcome loss': 0.8246904086441763, 'Total loss': 0.8246904086441763}
2022-11-18 03:13:51,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:51,292 INFO:     Epoch: 22
2022-11-18 03:13:52,051 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8347268666733395, 'Total loss': 0.8347268666733395} | train loss {'Reaction outcome loss': 0.8267844965861689, 'Total loss': 0.8267844965861689}
2022-11-18 03:13:52,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:52,052 INFO:     Epoch: 23
2022-11-18 03:13:52,881 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8083025725050406, 'Total loss': 0.8083025725050406} | train loss {'Reaction outcome loss': 0.8252042540379109, 'Total loss': 0.8252042540379109}
2022-11-18 03:13:52,881 INFO:     Found new best model at epoch 23
2022-11-18 03:13:52,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:52,882 INFO:     Epoch: 24
2022-11-18 03:13:53,726 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8110122477466409, 'Total loss': 0.8110122477466409} | train loss {'Reaction outcome loss': 0.8253431431949139, 'Total loss': 0.8253431431949139}
2022-11-18 03:13:53,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:53,727 INFO:     Epoch: 25
2022-11-18 03:13:54,596 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8163344711065292, 'Total loss': 0.8163344711065292} | train loss {'Reaction outcome loss': 0.8251322397301274, 'Total loss': 0.8251322397301274}
2022-11-18 03:13:54,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:54,596 INFO:     Epoch: 26
2022-11-18 03:13:55,400 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8129739043387499, 'Total loss': 0.8129739043387499} | train loss {'Reaction outcome loss': 0.8274243352634292, 'Total loss': 0.8274243352634292}
2022-11-18 03:13:55,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:55,400 INFO:     Epoch: 27
2022-11-18 03:13:56,248 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8270283923907713, 'Total loss': 0.8270283923907713} | train loss {'Reaction outcome loss': 0.8303223193412826, 'Total loss': 0.8303223193412826}
2022-11-18 03:13:56,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:56,249 INFO:     Epoch: 28
2022-11-18 03:13:57,071 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8192318285053427, 'Total loss': 0.8192318285053427} | train loss {'Reaction outcome loss': 0.8247170551649986, 'Total loss': 0.8247170551649986}
2022-11-18 03:13:57,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:57,071 INFO:     Epoch: 29
2022-11-18 03:13:57,874 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8262555382468484, 'Total loss': 0.8262555382468484} | train loss {'Reaction outcome loss': 0.827171224980585, 'Total loss': 0.827171224980585}
2022-11-18 03:13:57,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:57,874 INFO:     Epoch: 30
2022-11-18 03:13:58,674 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8263127492232756, 'Total loss': 0.8263127492232756} | train loss {'Reaction outcome loss': 0.8238808905645725, 'Total loss': 0.8238808905645725}
2022-11-18 03:13:58,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:58,674 INFO:     Epoch: 31
2022-11-18 03:13:59,467 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.819185882806778, 'Total loss': 0.819185882806778} | train loss {'Reaction outcome loss': 0.8266006678102478, 'Total loss': 0.8266006678102478}
2022-11-18 03:13:59,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:13:59,467 INFO:     Epoch: 32
2022-11-18 03:14:00,292 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8128745488145135, 'Total loss': 0.8128745488145135} | train loss {'Reaction outcome loss': 0.8261033175212722, 'Total loss': 0.8261033175212722}
2022-11-18 03:14:00,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:00,292 INFO:     Epoch: 33
2022-11-18 03:14:01,086 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8191256482492794, 'Total loss': 0.8191256482492794} | train loss {'Reaction outcome loss': 0.8253245725026054, 'Total loss': 0.8253245725026054}
2022-11-18 03:14:01,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:01,087 INFO:     Epoch: 34
2022-11-18 03:14:01,892 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8246025619181719, 'Total loss': 0.8246025619181719} | train loss {'Reaction outcome loss': 0.8233348983189752, 'Total loss': 0.8233348983189752}
2022-11-18 03:14:01,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:01,893 INFO:     Epoch: 35
2022-11-18 03:14:02,736 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8086435659365221, 'Total loss': 0.8086435659365221} | train loss {'Reaction outcome loss': 0.8263540104512246, 'Total loss': 0.8263540104512246}
2022-11-18 03:14:02,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:02,736 INFO:     Epoch: 36
2022-11-18 03:14:03,584 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8058192492886023, 'Total loss': 0.8058192492886023} | train loss {'Reaction outcome loss': 0.8220033791036375, 'Total loss': 0.8220033791036375}
2022-11-18 03:14:03,585 INFO:     Found new best model at epoch 36
2022-11-18 03:14:03,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:03,586 INFO:     Epoch: 37
2022-11-18 03:14:04,433 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8269720978357575, 'Total loss': 0.8269720978357575} | train loss {'Reaction outcome loss': 0.824758780939925, 'Total loss': 0.824758780939925}
2022-11-18 03:14:04,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:04,433 INFO:     Epoch: 38
2022-11-18 03:14:05,207 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8227175629951737, 'Total loss': 0.8227175629951737} | train loss {'Reaction outcome loss': 0.8256605293962264, 'Total loss': 0.8256605293962264}
2022-11-18 03:14:05,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:05,208 INFO:     Epoch: 39
2022-11-18 03:14:05,995 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8127635785124518, 'Total loss': 0.8127635785124518} | train loss {'Reaction outcome loss': 0.8274593397734626, 'Total loss': 0.8274593397734626}
2022-11-18 03:14:05,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:05,995 INFO:     Epoch: 40
2022-11-18 03:14:06,817 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8194812278855931, 'Total loss': 0.8194812278855931} | train loss {'Reaction outcome loss': 0.8227007362631059, 'Total loss': 0.8227007362631059}
2022-11-18 03:14:06,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:06,817 INFO:     Epoch: 41
2022-11-18 03:14:07,610 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8259140754287894, 'Total loss': 0.8259140754287894} | train loss {'Reaction outcome loss': 0.8244106451109532, 'Total loss': 0.8244106451109532}
2022-11-18 03:14:07,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:07,611 INFO:     Epoch: 42
2022-11-18 03:14:08,435 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.814068125730211, 'Total loss': 0.814068125730211} | train loss {'Reaction outcome loss': 0.8239231149275457, 'Total loss': 0.8239231149275457}
2022-11-18 03:14:08,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:08,436 INFO:     Epoch: 43
2022-11-18 03:14:09,256 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8304704820567911, 'Total loss': 0.8304704820567911} | train loss {'Reaction outcome loss': 0.8224248454695747, 'Total loss': 0.8224248454695747}
2022-11-18 03:14:09,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:09,256 INFO:     Epoch: 44
2022-11-18 03:14:10,029 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.807381883263588, 'Total loss': 0.807381883263588} | train loss {'Reaction outcome loss': 0.8285498061487752, 'Total loss': 0.8285498061487752}
2022-11-18 03:14:10,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:10,030 INFO:     Epoch: 45
2022-11-18 03:14:10,843 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.845045034180988, 'Total loss': 0.845045034180988} | train loss {'Reaction outcome loss': 0.8235566191855939, 'Total loss': 0.8235566191855939}
2022-11-18 03:14:10,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:10,843 INFO:     Epoch: 46
2022-11-18 03:14:11,637 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8079080148176714, 'Total loss': 0.8079080148176714} | train loss {'Reaction outcome loss': 0.8258192915349237, 'Total loss': 0.8258192915349237}
2022-11-18 03:14:11,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:11,638 INFO:     Epoch: 47
2022-11-18 03:14:12,450 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8053686747496779, 'Total loss': 0.8053686747496779} | train loss {'Reaction outcome loss': 0.8230186235760489, 'Total loss': 0.8230186235760489}
2022-11-18 03:14:12,450 INFO:     Found new best model at epoch 47
2022-11-18 03:14:12,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:12,451 INFO:     Epoch: 48
2022-11-18 03:14:13,272 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.896171477030624, 'Total loss': 0.896171477030624} | train loss {'Reaction outcome loss': 0.8245380514812085, 'Total loss': 0.8245380514812085}
2022-11-18 03:14:13,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:13,273 INFO:     Epoch: 49
2022-11-18 03:14:14,086 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.822092937474901, 'Total loss': 0.822092937474901} | train loss {'Reaction outcome loss': 0.8204238135968486, 'Total loss': 0.8204238135968486}
2022-11-18 03:14:14,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:14,088 INFO:     Epoch: 50
2022-11-18 03:14:14,923 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8266370012001558, 'Total loss': 0.8266370012001558} | train loss {'Reaction outcome loss': 0.8220360684058359, 'Total loss': 0.8220360684058359}
2022-11-18 03:14:14,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:14,923 INFO:     Epoch: 51
2022-11-18 03:14:15,692 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8351025317202915, 'Total loss': 0.8351025317202915} | train loss {'Reaction outcome loss': 0.8232762144217568, 'Total loss': 0.8232762144217568}
2022-11-18 03:14:15,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:15,692 INFO:     Epoch: 52
2022-11-18 03:14:16,470 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8063730732961134, 'Total loss': 0.8063730732961134} | train loss {'Reaction outcome loss': 0.8245875638338828, 'Total loss': 0.8245875638338828}
2022-11-18 03:14:16,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:16,471 INFO:     Epoch: 53
2022-11-18 03:14:17,295 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8102227090434595, 'Total loss': 0.8102227090434595} | train loss {'Reaction outcome loss': 0.8201614174871675, 'Total loss': 0.8201614174871675}
2022-11-18 03:14:17,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:17,295 INFO:     Epoch: 54
2022-11-18 03:14:18,122 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8130591674284502, 'Total loss': 0.8130591674284502} | train loss {'Reaction outcome loss': 0.8255793852431159, 'Total loss': 0.8255793852431159}
2022-11-18 03:14:18,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:18,122 INFO:     Epoch: 55
2022-11-18 03:14:18,913 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8297281163659963, 'Total loss': 0.8297281163659963} | train loss {'Reaction outcome loss': 0.821059039763866, 'Total loss': 0.821059039763866}
2022-11-18 03:14:18,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:18,913 INFO:     Epoch: 56
2022-11-18 03:14:19,716 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7965039468624375, 'Total loss': 0.7965039468624375} | train loss {'Reaction outcome loss': 0.8256749567245284, 'Total loss': 0.8256749567245284}
2022-11-18 03:14:19,716 INFO:     Found new best model at epoch 56
2022-11-18 03:14:19,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:19,717 INFO:     Epoch: 57
2022-11-18 03:14:20,537 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8302763835950331, 'Total loss': 0.8302763835950331} | train loss {'Reaction outcome loss': 0.8176616486762801, 'Total loss': 0.8176616486762801}
2022-11-18 03:14:20,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:20,538 INFO:     Epoch: 58
2022-11-18 03:14:21,345 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.808429865674539, 'Total loss': 0.808429865674539} | train loss {'Reaction outcome loss': 0.819622345749409, 'Total loss': 0.819622345749409}
2022-11-18 03:14:21,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:21,345 INFO:     Epoch: 59
2022-11-18 03:14:22,148 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.812469719485803, 'Total loss': 0.812469719485803} | train loss {'Reaction outcome loss': 0.8267894317546198, 'Total loss': 0.8267894317546198}
2022-11-18 03:14:22,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:22,148 INFO:     Epoch: 60
2022-11-18 03:14:22,937 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8078939752145247, 'Total loss': 0.8078939752145247} | train loss {'Reaction outcome loss': 0.8242130897218182, 'Total loss': 0.8242130897218182}
2022-11-18 03:14:22,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:22,937 INFO:     Epoch: 61
2022-11-18 03:14:23,748 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8143794875253331, 'Total loss': 0.8143794875253331} | train loss {'Reaction outcome loss': 0.823182451148187, 'Total loss': 0.823182451148187}
2022-11-18 03:14:23,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:23,748 INFO:     Epoch: 62
2022-11-18 03:14:24,593 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.82134425369176, 'Total loss': 0.82134425369176} | train loss {'Reaction outcome loss': 0.8236810387142243, 'Total loss': 0.8236810387142243}
2022-11-18 03:14:24,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:24,594 INFO:     Epoch: 63
2022-11-18 03:14:25,412 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8132267723029311, 'Total loss': 0.8132267723029311} | train loss {'Reaction outcome loss': 0.8232247311501734, 'Total loss': 0.8232247311501734}
2022-11-18 03:14:25,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:25,412 INFO:     Epoch: 64
2022-11-18 03:14:26,258 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8267191242087971, 'Total loss': 0.8267191242087971} | train loss {'Reaction outcome loss': 0.8237427435815334, 'Total loss': 0.8237427435815334}
2022-11-18 03:14:26,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:26,258 INFO:     Epoch: 65
2022-11-18 03:14:27,134 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8134119226173921, 'Total loss': 0.8134119226173921} | train loss {'Reaction outcome loss': 0.8205007244983027, 'Total loss': 0.8205007244983027}
2022-11-18 03:14:27,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:27,135 INFO:     Epoch: 66
2022-11-18 03:14:27,972 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8022249462929639, 'Total loss': 0.8022249462929639} | train loss {'Reaction outcome loss': 0.8237739600721867, 'Total loss': 0.8237739600721867}
2022-11-18 03:14:27,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:27,973 INFO:     Epoch: 67
2022-11-18 03:14:28,799 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8257645273750479, 'Total loss': 0.8257645273750479} | train loss {'Reaction outcome loss': 0.8249295397150901, 'Total loss': 0.8249295397150901}
2022-11-18 03:14:28,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:28,799 INFO:     Epoch: 68
2022-11-18 03:14:29,613 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8148231411522086, 'Total loss': 0.8148231411522086} | train loss {'Reaction outcome loss': 0.8245555282600464, 'Total loss': 0.8245555282600464}
2022-11-18 03:14:29,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:29,613 INFO:     Epoch: 69
2022-11-18 03:14:30,428 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8056785728443753, 'Total loss': 0.8056785728443753} | train loss {'Reaction outcome loss': 0.8288461390522218, 'Total loss': 0.8288461390522218}
2022-11-18 03:14:30,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:30,428 INFO:     Epoch: 70
2022-11-18 03:14:31,269 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8049638149413195, 'Total loss': 0.8049638149413195} | train loss {'Reaction outcome loss': 0.8200445169162366, 'Total loss': 0.8200445169162366}
2022-11-18 03:14:31,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:31,269 INFO:     Epoch: 71
2022-11-18 03:14:32,120 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8426458063450727, 'Total loss': 0.8426458063450727} | train loss {'Reaction outcome loss': 0.8210684055041882, 'Total loss': 0.8210684055041882}
2022-11-18 03:14:32,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:32,120 INFO:     Epoch: 72
2022-11-18 03:14:32,916 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8339230953292414, 'Total loss': 0.8339230953292414} | train loss {'Reaction outcome loss': 0.8228670005356112, 'Total loss': 0.8228670005356112}
2022-11-18 03:14:32,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:32,917 INFO:     Epoch: 73
2022-11-18 03:14:33,740 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8265980583700266, 'Total loss': 0.8265980583700266} | train loss {'Reaction outcome loss': 0.824021861557999, 'Total loss': 0.824021861557999}
2022-11-18 03:14:33,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:33,741 INFO:     Epoch: 74
2022-11-18 03:14:34,528 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8548476574095812, 'Total loss': 0.8548476574095812} | train loss {'Reaction outcome loss': 0.8232795760756538, 'Total loss': 0.8232795760756538}
2022-11-18 03:14:34,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:34,528 INFO:     Epoch: 75
2022-11-18 03:14:35,359 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8042532991279255, 'Total loss': 0.8042532991279255} | train loss {'Reaction outcome loss': 0.8251215748248562, 'Total loss': 0.8251215748248562}
2022-11-18 03:14:35,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:35,359 INFO:     Epoch: 76
2022-11-18 03:14:36,127 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8076351887800477, 'Total loss': 0.8076351887800477} | train loss {'Reaction outcome loss': 0.8307725061332026, 'Total loss': 0.8307725061332026}
2022-11-18 03:14:36,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:36,127 INFO:     Epoch: 77
2022-11-18 03:14:36,923 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8261239643801342, 'Total loss': 0.8261239643801342} | train loss {'Reaction outcome loss': 0.823007058352232, 'Total loss': 0.823007058352232}
2022-11-18 03:14:36,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:36,924 INFO:     Epoch: 78
2022-11-18 03:14:37,764 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8056561811403795, 'Total loss': 0.8056561811403795} | train loss {'Reaction outcome loss': 0.822813261420496, 'Total loss': 0.822813261420496}
2022-11-18 03:14:37,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:37,764 INFO:     Epoch: 79
2022-11-18 03:14:38,575 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8089847347953103, 'Total loss': 0.8089847347953103} | train loss {'Reaction outcome loss': 0.8212694511298211, 'Total loss': 0.8212694511298211}
2022-11-18 03:14:38,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:38,575 INFO:     Epoch: 80
2022-11-18 03:14:39,342 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8140333484519612, 'Total loss': 0.8140333484519612} | train loss {'Reaction outcome loss': 0.8262971092856699, 'Total loss': 0.8262971092856699}
2022-11-18 03:14:39,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:39,342 INFO:     Epoch: 81
2022-11-18 03:14:40,164 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8245046802542426, 'Total loss': 0.8245046802542426} | train loss {'Reaction outcome loss': 0.826335453698712, 'Total loss': 0.826335453698712}
2022-11-18 03:14:40,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:40,164 INFO:     Epoch: 82
2022-11-18 03:14:40,983 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8333072885870934, 'Total loss': 0.8333072885870934} | train loss {'Reaction outcome loss': 0.8210336825539989, 'Total loss': 0.8210336825539989}
2022-11-18 03:14:40,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:40,983 INFO:     Epoch: 83
2022-11-18 03:14:41,785 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8354801454327323, 'Total loss': 0.8354801454327323} | train loss {'Reaction outcome loss': 0.8247397927747618, 'Total loss': 0.8247397927747618}
2022-11-18 03:14:41,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:41,785 INFO:     Epoch: 84
2022-11-18 03:14:42,610 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8122277639128945, 'Total loss': 0.8122277639128945} | train loss {'Reaction outcome loss': 0.8254115940822709, 'Total loss': 0.8254115940822709}
2022-11-18 03:14:42,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:42,610 INFO:     Epoch: 85
2022-11-18 03:14:43,406 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8191004503857006, 'Total loss': 0.8191004503857006} | train loss {'Reaction outcome loss': 0.8233689532404945, 'Total loss': 0.8233689532404945}
2022-11-18 03:14:43,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:43,406 INFO:     Epoch: 86
2022-11-18 03:14:44,221 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8018786954608831, 'Total loss': 0.8018786954608831} | train loss {'Reaction outcome loss': 0.819906692831747, 'Total loss': 0.819906692831747}
2022-11-18 03:14:44,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:44,221 INFO:     Epoch: 87
2022-11-18 03:14:45,020 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8212638504125855, 'Total loss': 0.8212638504125855} | train loss {'Reaction outcome loss': 0.8210512396068342, 'Total loss': 0.8210512396068342}
2022-11-18 03:14:45,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:45,020 INFO:     Epoch: 88
2022-11-18 03:14:45,821 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8261587822979147, 'Total loss': 0.8261587822979147} | train loss {'Reaction outcome loss': 0.8231767263383635, 'Total loss': 0.8231767263383635}
2022-11-18 03:14:45,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:45,822 INFO:     Epoch: 89
2022-11-18 03:14:46,632 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8135376355864785, 'Total loss': 0.8135376355864785} | train loss {'Reaction outcome loss': 0.8214451721118342, 'Total loss': 0.8214451721118342}
2022-11-18 03:14:46,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:46,632 INFO:     Epoch: 90
2022-11-18 03:14:47,437 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8078764446757056, 'Total loss': 0.8078764446757056} | train loss {'Reaction outcome loss': 0.8215095707245411, 'Total loss': 0.8215095707245411}
2022-11-18 03:14:47,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:47,437 INFO:     Epoch: 91
2022-11-18 03:14:48,253 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8120369985699654, 'Total loss': 0.8120369985699654} | train loss {'Reaction outcome loss': 0.8224325654727798, 'Total loss': 0.8224325654727798}
2022-11-18 03:14:48,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:48,253 INFO:     Epoch: 92
2022-11-18 03:14:49,068 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8428719450126995, 'Total loss': 0.8428719450126995} | train loss {'Reaction outcome loss': 0.818934022358829, 'Total loss': 0.818934022358829}
2022-11-18 03:14:49,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:49,069 INFO:     Epoch: 93
2022-11-18 03:14:49,878 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8214502470059828, 'Total loss': 0.8214502470059828} | train loss {'Reaction outcome loss': 0.8211761542385624, 'Total loss': 0.8211761542385624}
2022-11-18 03:14:49,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:49,878 INFO:     Epoch: 94
2022-11-18 03:14:50,679 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.810559482737021, 'Total loss': 0.810559482737021} | train loss {'Reaction outcome loss': 0.816832170491257, 'Total loss': 0.816832170491257}
2022-11-18 03:14:50,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:50,679 INFO:     Epoch: 95
2022-11-18 03:14:51,481 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8212155957113613, 'Total loss': 0.8212155957113613} | train loss {'Reaction outcome loss': 0.8178494752895448, 'Total loss': 0.8178494752895448}
2022-11-18 03:14:51,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:51,481 INFO:     Epoch: 96
2022-11-18 03:14:52,313 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7967779629609801, 'Total loss': 0.7967779629609801} | train loss {'Reaction outcome loss': 0.8221104393803305, 'Total loss': 0.8221104393803305}
2022-11-18 03:14:52,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:52,314 INFO:     Epoch: 97
2022-11-18 03:14:53,115 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8156705166805874, 'Total loss': 0.8156705166805874} | train loss {'Reaction outcome loss': 0.8211123344878997, 'Total loss': 0.8211123344878997}
2022-11-18 03:14:53,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:53,115 INFO:     Epoch: 98
2022-11-18 03:14:53,898 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8095136758956042, 'Total loss': 0.8095136758956042} | train loss {'Reaction outcome loss': 0.8154363274093597, 'Total loss': 0.8154363274093597}
2022-11-18 03:14:53,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:53,898 INFO:     Epoch: 99
2022-11-18 03:14:54,731 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8038195893168449, 'Total loss': 0.8038195893168449} | train loss {'Reaction outcome loss': 0.8151988571569804, 'Total loss': 0.8151988571569804}
2022-11-18 03:14:54,732 INFO:     Best model found after epoch 57 of 100.
2022-11-18 03:14:54,732 INFO:   Done with stage: TRAINING
2022-11-18 03:14:54,732 INFO:   Starting stage: EVALUATION
2022-11-18 03:14:54,849 INFO:   Done with stage: EVALUATION
2022-11-18 03:14:54,849 INFO:   Leaving out SEQ value Fold_5
2022-11-18 03:14:54,862 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:14:54,862 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:14:55,544 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:14:55,544 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:14:55,614 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:14:55,615 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:14:55,615 INFO:     No hyperparam tuning for this model
2022-11-18 03:14:55,615 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:14:55,615 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:14:55,616 INFO:     None feature selector for col prot
2022-11-18 03:14:55,616 INFO:     None feature selector for col prot
2022-11-18 03:14:55,616 INFO:     None feature selector for col prot
2022-11-18 03:14:55,616 INFO:     None feature selector for col chem
2022-11-18 03:14:55,617 INFO:     None feature selector for col chem
2022-11-18 03:14:55,617 INFO:     None feature selector for col chem
2022-11-18 03:14:55,617 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:14:55,617 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:14:55,618 INFO:     Number of params in model 168571
2022-11-18 03:14:55,621 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:14:55,622 INFO:   Starting stage: TRAINING
2022-11-18 03:14:55,679 INFO:     Val loss before train {'Reaction outcome loss': 0.9216809624975378, 'Total loss': 0.9216809624975378}
2022-11-18 03:14:55,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:55,679 INFO:     Epoch: 0
2022-11-18 03:14:56,539 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7486264136704531, 'Total loss': 0.7486264136704531} | train loss {'Reaction outcome loss': 0.8804097688726841, 'Total loss': 0.8804097688726841}
2022-11-18 03:14:56,539 INFO:     Found new best model at epoch 0
2022-11-18 03:14:56,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:56,540 INFO:     Epoch: 1
2022-11-18 03:14:57,344 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7652264907956123, 'Total loss': 0.7652264907956123} | train loss {'Reaction outcome loss': 0.8484754264354706, 'Total loss': 0.8484754264354706}
2022-11-18 03:14:57,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:57,344 INFO:     Epoch: 2
2022-11-18 03:14:58,165 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7797826711427082, 'Total loss': 0.7797826711427082} | train loss {'Reaction outcome loss': 0.842045162954638, 'Total loss': 0.842045162954638}
2022-11-18 03:14:58,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:58,166 INFO:     Epoch: 3
2022-11-18 03:14:58,972 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7457940253344449, 'Total loss': 0.7457940253344449} | train loss {'Reaction outcome loss': 0.8388469759975711, 'Total loss': 0.8388469759975711}
2022-11-18 03:14:58,972 INFO:     Found new best model at epoch 3
2022-11-18 03:14:58,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:58,973 INFO:     Epoch: 4
2022-11-18 03:14:59,766 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7699505239725113, 'Total loss': 0.7699505239725113} | train loss {'Reaction outcome loss': 0.8331476850134711, 'Total loss': 0.8331476850134711}
2022-11-18 03:14:59,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:14:59,766 INFO:     Epoch: 5
2022-11-18 03:15:00,531 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7410675192421133, 'Total loss': 0.7410675192421133} | train loss {'Reaction outcome loss': 0.8259345698020151, 'Total loss': 0.8259345698020151}
2022-11-18 03:15:00,531 INFO:     Found new best model at epoch 5
2022-11-18 03:15:00,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:00,532 INFO:     Epoch: 6
2022-11-18 03:15:01,356 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.734923432496461, 'Total loss': 0.734923432496461} | train loss {'Reaction outcome loss': 0.8280235182854437, 'Total loss': 0.8280235182854437}
2022-11-18 03:15:01,357 INFO:     Found new best model at epoch 6
2022-11-18 03:15:01,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:01,357 INFO:     Epoch: 7
2022-11-18 03:15:02,146 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7664475420659239, 'Total loss': 0.7664475420659239} | train loss {'Reaction outcome loss': 0.8211343413399111, 'Total loss': 0.8211343413399111}
2022-11-18 03:15:02,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:02,146 INFO:     Epoch: 8
2022-11-18 03:15:02,974 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7216148281639273, 'Total loss': 0.7216148281639273} | train loss {'Reaction outcome loss': 0.8216877147074668, 'Total loss': 0.8216877147074668}
2022-11-18 03:15:02,975 INFO:     Found new best model at epoch 8
2022-11-18 03:15:02,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:02,975 INFO:     Epoch: 9
2022-11-18 03:15:03,790 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7555019855499268, 'Total loss': 0.7555019855499268} | train loss {'Reaction outcome loss': 0.8231593863137306, 'Total loss': 0.8231593863137306}
2022-11-18 03:15:03,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:03,790 INFO:     Epoch: 10
2022-11-18 03:15:04,588 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7443654320456765, 'Total loss': 0.7443654320456765} | train loss {'Reaction outcome loss': 0.8175142260809098, 'Total loss': 0.8175142260809098}
2022-11-18 03:15:04,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:04,589 INFO:     Epoch: 11
2022-11-18 03:15:05,456 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7298459532586011, 'Total loss': 0.7298459532586011} | train loss {'Reaction outcome loss': 0.8170572294583244, 'Total loss': 0.8170572294583244}
2022-11-18 03:15:05,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:05,456 INFO:     Epoch: 12
2022-11-18 03:15:06,243 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7426481809128415, 'Total loss': 0.7426481809128415} | train loss {'Reaction outcome loss': 0.8144496586774627, 'Total loss': 0.8144496586774627}
2022-11-18 03:15:06,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:06,244 INFO:     Epoch: 13
2022-11-18 03:15:07,026 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7529664561152458, 'Total loss': 0.7529664561152458} | train loss {'Reaction outcome loss': 0.8158943632677678, 'Total loss': 0.8158943632677678}
2022-11-18 03:15:07,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:07,026 INFO:     Epoch: 14
2022-11-18 03:15:07,846 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7247727438807487, 'Total loss': 0.7247727438807487} | train loss {'Reaction outcome loss': 0.8165272928534015, 'Total loss': 0.8165272928534015}
2022-11-18 03:15:07,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:07,846 INFO:     Epoch: 15
2022-11-18 03:15:08,632 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7539809766140851, 'Total loss': 0.7539809766140851} | train loss {'Reaction outcome loss': 0.8135704661328946, 'Total loss': 0.8135704661328946}
2022-11-18 03:15:08,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:08,632 INFO:     Epoch: 16
2022-11-18 03:15:09,488 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7480615587397055, 'Total loss': 0.7480615587397055} | train loss {'Reaction outcome loss': 0.8207059051360814, 'Total loss': 0.8207059051360814}
2022-11-18 03:15:09,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:09,488 INFO:     Epoch: 17
2022-11-18 03:15:10,299 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7293717082251202, 'Total loss': 0.7293717082251202} | train loss {'Reaction outcome loss': 0.8187478715854306, 'Total loss': 0.8187478715854306}
2022-11-18 03:15:10,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:10,299 INFO:     Epoch: 18
2022-11-18 03:15:11,095 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7312731309370561, 'Total loss': 0.7312731309370561} | train loss {'Reaction outcome loss': 0.8147830370693437, 'Total loss': 0.8147830370693437}
2022-11-18 03:15:11,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:11,096 INFO:     Epoch: 19
2022-11-18 03:15:11,873 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7186278301206502, 'Total loss': 0.7186278301206502} | train loss {'Reaction outcome loss': 0.8120214511309901, 'Total loss': 0.8120214511309901}
2022-11-18 03:15:11,873 INFO:     Found new best model at epoch 19
2022-11-18 03:15:11,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:11,874 INFO:     Epoch: 20
2022-11-18 03:15:12,680 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7187880223447626, 'Total loss': 0.7187880223447626} | train loss {'Reaction outcome loss': 0.8156324580552117, 'Total loss': 0.8156324580552117}
2022-11-18 03:15:12,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:12,681 INFO:     Epoch: 21
2022-11-18 03:15:13,500 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7457731745459817, 'Total loss': 0.7457731745459817} | train loss {'Reaction outcome loss': 0.8156903472638899, 'Total loss': 0.8156903472638899}
2022-11-18 03:15:13,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:13,500 INFO:     Epoch: 22
2022-11-18 03:15:14,362 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7163034772331064, 'Total loss': 0.7163034772331064} | train loss {'Reaction outcome loss': 0.8146410293636783, 'Total loss': 0.8146410293636783}
2022-11-18 03:15:14,362 INFO:     Found new best model at epoch 22
2022-11-18 03:15:14,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:14,363 INFO:     Epoch: 23
2022-11-18 03:15:15,207 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7365924485705115, 'Total loss': 0.7365924485705115} | train loss {'Reaction outcome loss': 0.813208073137268, 'Total loss': 0.813208073137268}
2022-11-18 03:15:15,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:15,207 INFO:     Epoch: 24
2022-11-18 03:15:16,012 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.735556769777428, 'Total loss': 0.735556769777428} | train loss {'Reaction outcome loss': 0.8138907673137803, 'Total loss': 0.8138907673137803}
2022-11-18 03:15:16,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:16,012 INFO:     Epoch: 25
2022-11-18 03:15:16,836 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7279121205210686, 'Total loss': 0.7279121205210686} | train loss {'Reaction outcome loss': 0.809607460854515, 'Total loss': 0.809607460854515}
2022-11-18 03:15:16,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:16,838 INFO:     Epoch: 26
2022-11-18 03:15:17,645 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7419387312097983, 'Total loss': 0.7419387312097983} | train loss {'Reaction outcome loss': 0.8116469857913833, 'Total loss': 0.8116469857913833}
2022-11-18 03:15:17,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:17,645 INFO:     Epoch: 27
2022-11-18 03:15:18,412 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.759744293987751, 'Total loss': 0.759744293987751} | train loss {'Reaction outcome loss': 0.8169904253896205, 'Total loss': 0.8169904253896205}
2022-11-18 03:15:18,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:18,412 INFO:     Epoch: 28
2022-11-18 03:15:19,243 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7355530885132876, 'Total loss': 0.7355530885132876} | train loss {'Reaction outcome loss': 0.8148755238902184, 'Total loss': 0.8148755238902184}
2022-11-18 03:15:19,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:19,243 INFO:     Epoch: 29
2022-11-18 03:15:20,073 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7319986515424468, 'Total loss': 0.7319986515424468} | train loss {'Reaction outcome loss': 0.8128045798549729, 'Total loss': 0.8128045798549729}
2022-11-18 03:15:20,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:20,073 INFO:     Epoch: 30
2022-11-18 03:15:20,895 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7483724748546426, 'Total loss': 0.7483724748546426} | train loss {'Reaction outcome loss': 0.8107057263053232, 'Total loss': 0.8107057263053232}
2022-11-18 03:15:20,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:20,896 INFO:     Epoch: 31
2022-11-18 03:15:21,722 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.722863142463294, 'Total loss': 0.722863142463294} | train loss {'Reaction outcome loss': 0.8098125619994055, 'Total loss': 0.8098125619994055}
2022-11-18 03:15:21,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:21,723 INFO:     Epoch: 32
2022-11-18 03:15:22,546 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7325729301029985, 'Total loss': 0.7325729301029985} | train loss {'Reaction outcome loss': 0.8104528188705444, 'Total loss': 0.8104528188705444}
2022-11-18 03:15:22,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:22,546 INFO:     Epoch: 33
2022-11-18 03:15:23,340 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7201935025778684, 'Total loss': 0.7201935025778684} | train loss {'Reaction outcome loss': 0.816584387253369, 'Total loss': 0.816584387253369}
2022-11-18 03:15:23,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:23,341 INFO:     Epoch: 34
2022-11-18 03:15:24,155 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7430282174186273, 'Total loss': 0.7430282174186273} | train loss {'Reaction outcome loss': 0.8152361120427808, 'Total loss': 0.8152361120427808}
2022-11-18 03:15:24,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:24,155 INFO:     Epoch: 35
2022-11-18 03:15:24,946 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7782575806433504, 'Total loss': 0.7782575806433504} | train loss {'Reaction outcome loss': 0.8071769111819805, 'Total loss': 0.8071769111819805}
2022-11-18 03:15:24,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:24,946 INFO:     Epoch: 36
2022-11-18 03:15:25,736 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7337821457873691, 'Total loss': 0.7337821457873691} | train loss {'Reaction outcome loss': 0.8154248025628829, 'Total loss': 0.8154248025628829}
2022-11-18 03:15:25,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:25,736 INFO:     Epoch: 37
2022-11-18 03:15:26,519 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7497023181481794, 'Total loss': 0.7497023181481794} | train loss {'Reaction outcome loss': 0.8092659169868115, 'Total loss': 0.8092659169868115}
2022-11-18 03:15:26,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:26,520 INFO:     Epoch: 38
2022-11-18 03:15:27,324 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7812720029191538, 'Total loss': 0.7812720029191538} | train loss {'Reaction outcome loss': 0.8101869986182259, 'Total loss': 0.8101869986182259}
2022-11-18 03:15:27,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:27,324 INFO:     Epoch: 39
2022-11-18 03:15:28,133 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7373363267291676, 'Total loss': 0.7373363267291676} | train loss {'Reaction outcome loss': 0.8171309833565066, 'Total loss': 0.8171309833565066}
2022-11-18 03:15:28,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:28,134 INFO:     Epoch: 40
2022-11-18 03:15:28,930 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7328798283230175, 'Total loss': 0.7328798283230175} | train loss {'Reaction outcome loss': 0.8148723732559912, 'Total loss': 0.8148723732559912}
2022-11-18 03:15:28,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:28,930 INFO:     Epoch: 41
2022-11-18 03:15:29,730 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7479021298614416, 'Total loss': 0.7479021298614416} | train loss {'Reaction outcome loss': 0.814660673900958, 'Total loss': 0.814660673900958}
2022-11-18 03:15:29,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:29,731 INFO:     Epoch: 42
2022-11-18 03:15:30,506 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7333055301146074, 'Total loss': 0.7333055301146074} | train loss {'Reaction outcome loss': 0.8152546245724924, 'Total loss': 0.8152546245724924}
2022-11-18 03:15:30,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:30,507 INFO:     Epoch: 43
2022-11-18 03:15:31,359 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7611808018250898, 'Total loss': 0.7611808018250898} | train loss {'Reaction outcome loss': 0.8134140747208749, 'Total loss': 0.8134140747208749}
2022-11-18 03:15:31,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:31,359 INFO:     Epoch: 44
2022-11-18 03:15:32,230 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.722925946793773, 'Total loss': 0.722925946793773} | train loss {'Reaction outcome loss': 0.8129121568654815, 'Total loss': 0.8129121568654815}
2022-11-18 03:15:32,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:32,230 INFO:     Epoch: 45
2022-11-18 03:15:33,062 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7448383319106969, 'Total loss': 0.7448383319106969} | train loss {'Reaction outcome loss': 0.809144691353844, 'Total loss': 0.809144691353844}
2022-11-18 03:15:33,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:33,062 INFO:     Epoch: 46
2022-11-18 03:15:33,883 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7085016620430079, 'Total loss': 0.7085016620430079} | train loss {'Reaction outcome loss': 0.8130788505077362, 'Total loss': 0.8130788505077362}
2022-11-18 03:15:33,883 INFO:     Found new best model at epoch 46
2022-11-18 03:15:33,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:33,884 INFO:     Epoch: 47
2022-11-18 03:15:34,692 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7341499552130699, 'Total loss': 0.7341499552130699} | train loss {'Reaction outcome loss': 0.8119789805383452, 'Total loss': 0.8119789805383452}
2022-11-18 03:15:34,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:34,692 INFO:     Epoch: 48
2022-11-18 03:15:35,544 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7151033912192691, 'Total loss': 0.7151033912192691} | train loss {'Reaction outcome loss': 0.8163651747088279, 'Total loss': 0.8163651747088279}
2022-11-18 03:15:35,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:35,545 INFO:     Epoch: 49
2022-11-18 03:15:36,370 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7135857546871359, 'Total loss': 0.7135857546871359} | train loss {'Reaction outcome loss': 0.8112349779375138, 'Total loss': 0.8112349779375138}
2022-11-18 03:15:36,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:36,370 INFO:     Epoch: 50
2022-11-18 03:15:37,215 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7356572659178213, 'Total loss': 0.7356572659178213} | train loss {'Reaction outcome loss': 0.8120988184405912, 'Total loss': 0.8120988184405912}
2022-11-18 03:15:37,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:37,215 INFO:     Epoch: 51
2022-11-18 03:15:37,989 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7388110980391502, 'Total loss': 0.7388110980391502} | train loss {'Reaction outcome loss': 0.8101248687073108, 'Total loss': 0.8101248687073108}
2022-11-18 03:15:37,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:37,990 INFO:     Epoch: 52
2022-11-18 03:15:38,820 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.747002739797939, 'Total loss': 0.747002739797939} | train loss {'Reaction outcome loss': 0.8130812060929113, 'Total loss': 0.8130812060929113}
2022-11-18 03:15:38,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:38,820 INFO:     Epoch: 53
2022-11-18 03:15:39,668 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7380459064787085, 'Total loss': 0.7380459064787085} | train loss {'Reaction outcome loss': 0.8108636239363302, 'Total loss': 0.8108636239363302}
2022-11-18 03:15:39,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:39,669 INFO:     Epoch: 54
2022-11-18 03:15:40,467 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7215120027011092, 'Total loss': 0.7215120027011092} | train loss {'Reaction outcome loss': 0.812641580378817, 'Total loss': 0.812641580378817}
2022-11-18 03:15:40,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:40,468 INFO:     Epoch: 55
2022-11-18 03:15:41,296 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7310400984504006, 'Total loss': 0.7310400984504006} | train loss {'Reaction outcome loss': 0.8104063571701127, 'Total loss': 0.8104063571701127}
2022-11-18 03:15:41,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:41,296 INFO:     Epoch: 56
2022-11-18 03:15:42,135 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7380482269959017, 'Total loss': 0.7380482269959017} | train loss {'Reaction outcome loss': 0.8155664638165505, 'Total loss': 0.8155664638165505}
2022-11-18 03:15:42,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:42,135 INFO:     Epoch: 57
2022-11-18 03:15:42,949 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7357567277821627, 'Total loss': 0.7357567277821627} | train loss {'Reaction outcome loss': 0.8122922097963672, 'Total loss': 0.8122922097963672}
2022-11-18 03:15:42,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:42,949 INFO:     Epoch: 58
2022-11-18 03:15:43,765 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7255860248749907, 'Total loss': 0.7255860248749907} | train loss {'Reaction outcome loss': 0.8101688682311966, 'Total loss': 0.8101688682311966}
2022-11-18 03:15:43,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:43,765 INFO:     Epoch: 59
2022-11-18 03:15:44,554 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7380267036232081, 'Total loss': 0.7380267036232081} | train loss {'Reaction outcome loss': 0.8110040104196917, 'Total loss': 0.8110040104196917}
2022-11-18 03:15:44,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:44,555 INFO:     Epoch: 60
2022-11-18 03:15:45,337 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7343041876500304, 'Total loss': 0.7343041876500304} | train loss {'Reaction outcome loss': 0.8148828792956567, 'Total loss': 0.8148828792956567}
2022-11-18 03:15:45,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:45,337 INFO:     Epoch: 61
2022-11-18 03:15:46,113 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7686273076317527, 'Total loss': 0.7686273076317527} | train loss {'Reaction outcome loss': 0.8114302516464265, 'Total loss': 0.8114302516464265}
2022-11-18 03:15:46,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:46,113 INFO:     Epoch: 62
2022-11-18 03:15:46,876 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7393687618049708, 'Total loss': 0.7393687618049708} | train loss {'Reaction outcome loss': 0.8106826096773148, 'Total loss': 0.8106826096773148}
2022-11-18 03:15:46,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:46,876 INFO:     Epoch: 63
2022-11-18 03:15:47,691 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7339996201070872, 'Total loss': 0.7339996201070872} | train loss {'Reaction outcome loss': 0.8056858983491698, 'Total loss': 0.8056858983491698}
2022-11-18 03:15:47,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:47,692 INFO:     Epoch: 64
2022-11-18 03:15:48,471 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7566512098366563, 'Total loss': 0.7566512098366563} | train loss {'Reaction outcome loss': 0.8140010291770581, 'Total loss': 0.8140010291770581}
2022-11-18 03:15:48,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:48,472 INFO:     Epoch: 65
2022-11-18 03:15:49,266 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7310453070835634, 'Total loss': 0.7310453070835634} | train loss {'Reaction outcome loss': 0.8115058001731673, 'Total loss': 0.8115058001731673}
2022-11-18 03:15:49,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:49,267 INFO:     Epoch: 66
2022-11-18 03:15:50,045 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7485123852437193, 'Total loss': 0.7485123852437193} | train loss {'Reaction outcome loss': 0.8091826276673425, 'Total loss': 0.8091826276673425}
2022-11-18 03:15:50,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:50,045 INFO:     Epoch: 67
2022-11-18 03:15:50,841 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7376757731491869, 'Total loss': 0.7376757731491869} | train loss {'Reaction outcome loss': 0.8120606370991276, 'Total loss': 0.8120606370991276}
2022-11-18 03:15:50,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:50,841 INFO:     Epoch: 68
2022-11-18 03:15:51,652 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.742449477314949, 'Total loss': 0.742449477314949} | train loss {'Reaction outcome loss': 0.816537530551995, 'Total loss': 0.816537530551995}
2022-11-18 03:15:51,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:51,652 INFO:     Epoch: 69
2022-11-18 03:15:52,437 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7137530114163052, 'Total loss': 0.7137530114163052} | train loss {'Reaction outcome loss': 0.8101181544123157, 'Total loss': 0.8101181544123157}
2022-11-18 03:15:52,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:52,437 INFO:     Epoch: 70
2022-11-18 03:15:53,210 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7177952480587092, 'Total loss': 0.7177952480587092} | train loss {'Reaction outcome loss': 0.8077871823503125, 'Total loss': 0.8077871823503125}
2022-11-18 03:15:53,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:53,210 INFO:     Epoch: 71
2022-11-18 03:15:53,981 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7150081003254111, 'Total loss': 0.7150081003254111} | train loss {'Reaction outcome loss': 0.8124808475615517, 'Total loss': 0.8124808475615517}
2022-11-18 03:15:53,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:53,982 INFO:     Epoch: 72
2022-11-18 03:15:54,758 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7298356165940111, 'Total loss': 0.7298356165940111} | train loss {'Reaction outcome loss': 0.8069325499236584, 'Total loss': 0.8069325499236584}
2022-11-18 03:15:54,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:54,758 INFO:     Epoch: 73
2022-11-18 03:15:55,529 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7422570030797612, 'Total loss': 0.7422570030797612} | train loss {'Reaction outcome loss': 0.8112762612440894, 'Total loss': 0.8112762612440894}
2022-11-18 03:15:55,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:55,529 INFO:     Epoch: 74
2022-11-18 03:15:56,319 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7143837423487143, 'Total loss': 0.7143837423487143} | train loss {'Reaction outcome loss': 0.8136967920487926, 'Total loss': 0.8136967920487926}
2022-11-18 03:15:56,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:56,320 INFO:     Epoch: 75
2022-11-18 03:15:57,090 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7510383508422158, 'Total loss': 0.7510383508422158} | train loss {'Reaction outcome loss': 0.8152464273716172, 'Total loss': 0.8152464273716172}
2022-11-18 03:15:57,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:57,090 INFO:     Epoch: 76
2022-11-18 03:15:57,870 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7211904661221937, 'Total loss': 0.7211904661221937} | train loss {'Reaction outcome loss': 0.8148764057024833, 'Total loss': 0.8148764057024833}
2022-11-18 03:15:57,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:57,871 INFO:     Epoch: 77
2022-11-18 03:15:58,648 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7396449446678162, 'Total loss': 0.7396449446678162} | train loss {'Reaction outcome loss': 0.8117992368436628, 'Total loss': 0.8117992368436628}
2022-11-18 03:15:58,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:58,648 INFO:     Epoch: 78
2022-11-18 03:15:59,417 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7335221354256977, 'Total loss': 0.7335221354256977} | train loss {'Reaction outcome loss': 0.8069499965396619, 'Total loss': 0.8069499965396619}
2022-11-18 03:15:59,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:15:59,417 INFO:     Epoch: 79
2022-11-18 03:16:00,247 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7356181673028253, 'Total loss': 0.7356181673028253} | train loss {'Reaction outcome loss': 0.8120034627856747, 'Total loss': 0.8120034627856747}
2022-11-18 03:16:00,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:00,247 INFO:     Epoch: 80
2022-11-18 03:16:01,028 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7618087503043088, 'Total loss': 0.7618087503043088} | train loss {'Reaction outcome loss': 0.8108450677846709, 'Total loss': 0.8108450677846709}
2022-11-18 03:16:01,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:01,028 INFO:     Epoch: 81
2022-11-18 03:16:01,819 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7452590411359613, 'Total loss': 0.7452590411359613} | train loss {'Reaction outcome loss': 0.8146602333553375, 'Total loss': 0.8146602333553375}
2022-11-18 03:16:01,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:01,819 INFO:     Epoch: 82
2022-11-18 03:16:02,618 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7345230044289068, 'Total loss': 0.7345230044289068} | train loss {'Reaction outcome loss': 0.8083384378302482, 'Total loss': 0.8083384378302482}
2022-11-18 03:16:02,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:02,618 INFO:     Epoch: 83
2022-11-18 03:16:03,417 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7364113527265462, 'Total loss': 0.7364113527265462} | train loss {'Reaction outcome loss': 0.809877366668755, 'Total loss': 0.809877366668755}
2022-11-18 03:16:03,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:03,418 INFO:     Epoch: 84
2022-11-18 03:16:04,223 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7076062404296615, 'Total loss': 0.7076062404296615} | train loss {'Reaction outcome loss': 0.80639185035421, 'Total loss': 0.80639185035421}
2022-11-18 03:16:04,223 INFO:     Found new best model at epoch 84
2022-11-18 03:16:04,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:04,224 INFO:     Epoch: 85
2022-11-18 03:16:04,992 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7249779694459655, 'Total loss': 0.7249779694459655} | train loss {'Reaction outcome loss': 0.8105040255092806, 'Total loss': 0.8105040255092806}
2022-11-18 03:16:04,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:04,992 INFO:     Epoch: 86
2022-11-18 03:16:05,777 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7277580757032741, 'Total loss': 0.7277580757032741} | train loss {'Reaction outcome loss': 0.8151318144894415, 'Total loss': 0.8151318144894415}
2022-11-18 03:16:05,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:05,777 INFO:     Epoch: 87
2022-11-18 03:16:06,546 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.735350868918679, 'Total loss': 0.735350868918679} | train loss {'Reaction outcome loss': 0.811134778804356, 'Total loss': 0.811134778804356}
2022-11-18 03:16:06,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:06,547 INFO:     Epoch: 88
2022-11-18 03:16:07,343 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7273168408057906, 'Total loss': 0.7273168408057906} | train loss {'Reaction outcome loss': 0.8102413373849084, 'Total loss': 0.8102413373849084}
2022-11-18 03:16:07,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:07,344 INFO:     Epoch: 89
2022-11-18 03:16:08,148 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7373287684538148, 'Total loss': 0.7373287684538148} | train loss {'Reaction outcome loss': 0.810946405414612, 'Total loss': 0.810946405414612}
2022-11-18 03:16:08,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:08,149 INFO:     Epoch: 90
2022-11-18 03:16:08,931 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7408358244733377, 'Total loss': 0.7408358244733377} | train loss {'Reaction outcome loss': 0.8133246296596143, 'Total loss': 0.8133246296596143}
2022-11-18 03:16:08,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:08,931 INFO:     Epoch: 91
2022-11-18 03:16:09,756 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7652903205969117, 'Total loss': 0.7652903205969117} | train loss {'Reaction outcome loss': 0.8121965130971324, 'Total loss': 0.8121965130971324}
2022-11-18 03:16:09,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:09,757 INFO:     Epoch: 92
2022-11-18 03:16:10,545 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7273807634006847, 'Total loss': 0.7273807634006847} | train loss {'Reaction outcome loss': 0.8141062329373052, 'Total loss': 0.8141062329373052}
2022-11-18 03:16:10,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:10,546 INFO:     Epoch: 93
2022-11-18 03:16:11,353 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7265255864370953, 'Total loss': 0.7265255864370953} | train loss {'Reaction outcome loss': 0.8150395801471125, 'Total loss': 0.8150395801471125}
2022-11-18 03:16:11,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:11,353 INFO:     Epoch: 94
2022-11-18 03:16:12,190 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7350846163251183, 'Total loss': 0.7350846163251183} | train loss {'Reaction outcome loss': 0.8127083697867009, 'Total loss': 0.8127083697867009}
2022-11-18 03:16:12,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:12,190 INFO:     Epoch: 95
2022-11-18 03:16:12,997 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7364879616282203, 'Total loss': 0.7364879616282203} | train loss {'Reaction outcome loss': 0.8146060367505397, 'Total loss': 0.8146060367505397}
2022-11-18 03:16:12,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:12,998 INFO:     Epoch: 96
2022-11-18 03:16:13,798 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7225440022620288, 'Total loss': 0.7225440022620288} | train loss {'Reaction outcome loss': 0.8102201730493577, 'Total loss': 0.8102201730493577}
2022-11-18 03:16:13,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:13,799 INFO:     Epoch: 97
2022-11-18 03:16:14,584 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7320291521874341, 'Total loss': 0.7320291521874341} | train loss {'Reaction outcome loss': 0.8132809463047213, 'Total loss': 0.8132809463047213}
2022-11-18 03:16:14,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:14,584 INFO:     Epoch: 98
2022-11-18 03:16:15,368 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7179615849798376, 'Total loss': 0.7179615849798376} | train loss {'Reaction outcome loss': 0.8107929013429149, 'Total loss': 0.8107929013429149}
2022-11-18 03:16:15,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:15,368 INFO:     Epoch: 99
2022-11-18 03:16:16,196 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7262421853163026, 'Total loss': 0.7262421853163026} | train loss {'Reaction outcome loss': 0.8064982021047223, 'Total loss': 0.8064982021047223}
2022-11-18 03:16:16,196 INFO:     Best model found after epoch 85 of 100.
2022-11-18 03:16:16,197 INFO:   Done with stage: TRAINING
2022-11-18 03:16:16,197 INFO:   Starting stage: EVALUATION
2022-11-18 03:16:16,313 INFO:   Done with stage: EVALUATION
2022-11-18 03:16:16,314 INFO:   Leaving out SEQ value Fold_6
2022-11-18 03:16:16,327 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:16:16,327 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:16:16,998 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:16:16,998 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:16:17,070 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:16:17,070 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:16:17,070 INFO:     No hyperparam tuning for this model
2022-11-18 03:16:17,070 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:16:17,070 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:16:17,071 INFO:     None feature selector for col prot
2022-11-18 03:16:17,071 INFO:     None feature selector for col prot
2022-11-18 03:16:17,071 INFO:     None feature selector for col prot
2022-11-18 03:16:17,072 INFO:     None feature selector for col chem
2022-11-18 03:16:17,072 INFO:     None feature selector for col chem
2022-11-18 03:16:17,072 INFO:     None feature selector for col chem
2022-11-18 03:16:17,072 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:16:17,072 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:16:17,074 INFO:     Number of params in model 168571
2022-11-18 03:16:17,077 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:16:17,077 INFO:   Starting stage: TRAINING
2022-11-18 03:16:17,135 INFO:     Val loss before train {'Reaction outcome loss': 0.9247026375748895, 'Total loss': 0.9247026375748895}
2022-11-18 03:16:17,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:17,135 INFO:     Epoch: 0
2022-11-18 03:16:17,933 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7704458060589704, 'Total loss': 0.7704458060589704} | train loss {'Reaction outcome loss': 0.8879132747890488, 'Total loss': 0.8879132747890488}
2022-11-18 03:16:17,933 INFO:     Found new best model at epoch 0
2022-11-18 03:16:17,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:17,934 INFO:     Epoch: 1
2022-11-18 03:16:18,778 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7716221064329147, 'Total loss': 0.7716221064329147} | train loss {'Reaction outcome loss': 0.8573709268483424, 'Total loss': 0.8573709268483424}
2022-11-18 03:16:18,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:18,780 INFO:     Epoch: 2
2022-11-18 03:16:19,567 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7456403330645778, 'Total loss': 0.7456403330645778} | train loss {'Reaction outcome loss': 0.848951849245256, 'Total loss': 0.848951849245256}
2022-11-18 03:16:19,567 INFO:     Found new best model at epoch 2
2022-11-18 03:16:19,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:19,568 INFO:     Epoch: 3
2022-11-18 03:16:20,378 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.758411826735193, 'Total loss': 0.758411826735193} | train loss {'Reaction outcome loss': 0.8495152043479104, 'Total loss': 0.8495152043479104}
2022-11-18 03:16:20,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:20,379 INFO:     Epoch: 4
2022-11-18 03:16:21,178 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7484174452044747, 'Total loss': 0.7484174452044747} | train loss {'Reaction outcome loss': 0.8401737429441944, 'Total loss': 0.8401737429441944}
2022-11-18 03:16:21,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:21,179 INFO:     Epoch: 5
2022-11-18 03:16:21,999 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7683890021660111, 'Total loss': 0.7683890021660111} | train loss {'Reaction outcome loss': 0.8405454694744079, 'Total loss': 0.8405454694744079}
2022-11-18 03:16:21,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:21,999 INFO:     Epoch: 6
2022-11-18 03:16:22,757 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7319927974180742, 'Total loss': 0.7319927974180742} | train loss {'Reaction outcome loss': 0.8341795943917767, 'Total loss': 0.8341795943917767}
2022-11-18 03:16:22,758 INFO:     Found new best model at epoch 6
2022-11-18 03:16:22,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:22,759 INFO:     Epoch: 7
2022-11-18 03:16:23,564 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7672836414792321, 'Total loss': 0.7672836414792321} | train loss {'Reaction outcome loss': 0.8334885531615827, 'Total loss': 0.8334885531615827}
2022-11-18 03:16:23,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:23,564 INFO:     Epoch: 8
2022-11-18 03:16:24,373 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7491131899031725, 'Total loss': 0.7491131899031725} | train loss {'Reaction outcome loss': 0.8363680062034438, 'Total loss': 0.8363680062034438}
2022-11-18 03:16:24,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:24,374 INFO:     Epoch: 9
2022-11-18 03:16:25,171 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7489851774139837, 'Total loss': 0.7489851774139837} | train loss {'Reaction outcome loss': 0.8310409394964096, 'Total loss': 0.8310409394964096}
2022-11-18 03:16:25,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:25,172 INFO:     Epoch: 10
2022-11-18 03:16:25,967 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7463455078276721, 'Total loss': 0.7463455078276721} | train loss {'Reaction outcome loss': 0.8295112606738845, 'Total loss': 0.8295112606738845}
2022-11-18 03:16:25,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:25,967 INFO:     Epoch: 11
2022-11-18 03:16:26,755 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7477436837824908, 'Total loss': 0.7477436837824908} | train loss {'Reaction outcome loss': 0.8304738806140038, 'Total loss': 0.8304738806140038}
2022-11-18 03:16:26,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:26,755 INFO:     Epoch: 12
2022-11-18 03:16:27,558 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7547430802475322, 'Total loss': 0.7547430802475322} | train loss {'Reaction outcome loss': 0.8288931069114516, 'Total loss': 0.8288931069114516}
2022-11-18 03:16:27,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:27,559 INFO:     Epoch: 13
2022-11-18 03:16:28,366 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7518572895364328, 'Total loss': 0.7518572895364328} | train loss {'Reaction outcome loss': 0.8316545248512299, 'Total loss': 0.8316545248512299}
2022-11-18 03:16:28,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:28,366 INFO:     Epoch: 14
2022-11-18 03:16:29,134 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7317037304694002, 'Total loss': 0.7317037304694002} | train loss {'Reaction outcome loss': 0.824736972369494, 'Total loss': 0.824736972369494}
2022-11-18 03:16:29,134 INFO:     Found new best model at epoch 14
2022-11-18 03:16:29,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:29,135 INFO:     Epoch: 15
2022-11-18 03:16:29,985 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.74188182502985, 'Total loss': 0.74188182502985} | train loss {'Reaction outcome loss': 0.8277539290007083, 'Total loss': 0.8277539290007083}
2022-11-18 03:16:29,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:29,985 INFO:     Epoch: 16
2022-11-18 03:16:30,805 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7398062504150651, 'Total loss': 0.7398062504150651} | train loss {'Reaction outcome loss': 0.8279817932315411, 'Total loss': 0.8279817932315411}
2022-11-18 03:16:30,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:30,806 INFO:     Epoch: 17
2022-11-18 03:16:31,602 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7430545152588324, 'Total loss': 0.7430545152588324} | train loss {'Reaction outcome loss': 0.8301589980481132, 'Total loss': 0.8301589980481132}
2022-11-18 03:16:31,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:31,603 INFO:     Epoch: 18
2022-11-18 03:16:32,412 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7473293265158479, 'Total loss': 0.7473293265158479} | train loss {'Reaction outcome loss': 0.8277990045326371, 'Total loss': 0.8277990045326371}
2022-11-18 03:16:32,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:32,413 INFO:     Epoch: 19
2022-11-18 03:16:33,184 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.726630680940368, 'Total loss': 0.726630680940368} | train loss {'Reaction outcome loss': 0.8284562988387, 'Total loss': 0.8284562988387}
2022-11-18 03:16:33,185 INFO:     Found new best model at epoch 19
2022-11-18 03:16:33,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:33,186 INFO:     Epoch: 20
2022-11-18 03:16:33,953 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7460962906479836, 'Total loss': 0.7460962906479836} | train loss {'Reaction outcome loss': 0.8224785275036289, 'Total loss': 0.8224785275036289}
2022-11-18 03:16:33,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:33,954 INFO:     Epoch: 21
2022-11-18 03:16:34,753 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7378574751994826, 'Total loss': 0.7378574751994826} | train loss {'Reaction outcome loss': 0.8284395388778178, 'Total loss': 0.8284395388778178}
2022-11-18 03:16:34,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:34,754 INFO:     Epoch: 22
2022-11-18 03:16:35,551 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.746740002523769, 'Total loss': 0.746740002523769} | train loss {'Reaction outcome loss': 0.8247335447419074, 'Total loss': 0.8247335447419074}
2022-11-18 03:16:35,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:35,552 INFO:     Epoch: 23
2022-11-18 03:16:36,332 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7424529242244634, 'Total loss': 0.7424529242244634} | train loss {'Reaction outcome loss': 0.8244016051532761, 'Total loss': 0.8244016051532761}
2022-11-18 03:16:36,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:36,333 INFO:     Epoch: 24
2022-11-18 03:16:37,133 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7517981806939299, 'Total loss': 0.7517981806939299} | train loss {'Reaction outcome loss': 0.8280467940193992, 'Total loss': 0.8280467940193992}
2022-11-18 03:16:37,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:37,134 INFO:     Epoch: 25
2022-11-18 03:16:37,901 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7327431657097556, 'Total loss': 0.7327431657097556} | train loss {'Reaction outcome loss': 0.8274566163459132, 'Total loss': 0.8274566163459132}
2022-11-18 03:16:37,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:37,902 INFO:     Epoch: 26
2022-11-18 03:16:38,726 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7609877477992665, 'Total loss': 0.7609877477992665} | train loss {'Reaction outcome loss': 0.8260180137811168, 'Total loss': 0.8260180137811168}
2022-11-18 03:16:38,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:38,727 INFO:     Epoch: 27
2022-11-18 03:16:39,536 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7256705801595341, 'Total loss': 0.7256705801595341} | train loss {'Reaction outcome loss': 0.8238433026258023, 'Total loss': 0.8238433026258023}
2022-11-18 03:16:39,536 INFO:     Found new best model at epoch 27
2022-11-18 03:16:39,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:39,537 INFO:     Epoch: 28
2022-11-18 03:16:40,305 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7394566224379973, 'Total loss': 0.7394566224379973} | train loss {'Reaction outcome loss': 0.8235967153262708, 'Total loss': 0.8235967153262708}
2022-11-18 03:16:40,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:40,305 INFO:     Epoch: 29
2022-11-18 03:16:41,057 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7311571843244813, 'Total loss': 0.7311571843244813} | train loss {'Reaction outcome loss': 0.8223130442202091, 'Total loss': 0.8223130442202091}
2022-11-18 03:16:41,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:41,057 INFO:     Epoch: 30
2022-11-18 03:16:41,873 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7318342768333175, 'Total loss': 0.7318342768333175} | train loss {'Reaction outcome loss': 0.8233957281035762, 'Total loss': 0.8233957281035762}
2022-11-18 03:16:41,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:41,873 INFO:     Epoch: 31
2022-11-18 03:16:42,678 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7337405850941484, 'Total loss': 0.7337405850941484} | train loss {'Reaction outcome loss': 0.8256862646629733, 'Total loss': 0.8256862646629733}
2022-11-18 03:16:42,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:42,679 INFO:     Epoch: 32
2022-11-18 03:16:43,452 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7375988641923125, 'Total loss': 0.7375988641923125} | train loss {'Reaction outcome loss': 0.8170103440361638, 'Total loss': 0.8170103440361638}
2022-11-18 03:16:43,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:43,453 INFO:     Epoch: 33
2022-11-18 03:16:44,230 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7330531532114203, 'Total loss': 0.7330531532114203} | train loss {'Reaction outcome loss': 0.8200170903676941, 'Total loss': 0.8200170903676941}
2022-11-18 03:16:44,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:44,230 INFO:     Epoch: 34
2022-11-18 03:16:45,038 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7352437302470207, 'Total loss': 0.7352437302470207} | train loss {'Reaction outcome loss': 0.8226727099428254, 'Total loss': 0.8226727099428254}
2022-11-18 03:16:45,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:45,038 INFO:     Epoch: 35
2022-11-18 03:16:45,844 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.741044663570144, 'Total loss': 0.741044663570144} | train loss {'Reaction outcome loss': 0.8194335346981403, 'Total loss': 0.8194335346981403}
2022-11-18 03:16:45,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:45,844 INFO:     Epoch: 36
2022-11-18 03:16:46,618 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7463348020206798, 'Total loss': 0.7463348020206798} | train loss {'Reaction outcome loss': 0.82227319358818, 'Total loss': 0.82227319358818}
2022-11-18 03:16:46,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:46,618 INFO:     Epoch: 37
2022-11-18 03:16:47,406 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.735272347249768, 'Total loss': 0.735272347249768} | train loss {'Reaction outcome loss': 0.8213818677731098, 'Total loss': 0.8213818677731098}
2022-11-18 03:16:47,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:47,406 INFO:     Epoch: 38
2022-11-18 03:16:48,226 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7185452695597302, 'Total loss': 0.7185452695597302} | train loss {'Reaction outcome loss': 0.8262138341463381, 'Total loss': 0.8262138341463381}
2022-11-18 03:16:48,226 INFO:     Found new best model at epoch 38
2022-11-18 03:16:48,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:48,227 INFO:     Epoch: 39
2022-11-18 03:16:49,013 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7567349895834923, 'Total loss': 0.7567349895834923} | train loss {'Reaction outcome loss': 0.8234158927394498, 'Total loss': 0.8234158927394498}
2022-11-18 03:16:49,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:49,013 INFO:     Epoch: 40
2022-11-18 03:16:49,807 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7437366660345684, 'Total loss': 0.7437366660345684} | train loss {'Reaction outcome loss': 0.8184579134948792, 'Total loss': 0.8184579134948792}
2022-11-18 03:16:49,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:49,809 INFO:     Epoch: 41
2022-11-18 03:16:50,621 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7384967099536549, 'Total loss': 0.7384967099536549} | train loss {'Reaction outcome loss': 0.8239235378080799, 'Total loss': 0.8239235378080799}
2022-11-18 03:16:50,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:50,621 INFO:     Epoch: 42
2022-11-18 03:16:51,384 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7405761114575646, 'Total loss': 0.7405761114575646} | train loss {'Reaction outcome loss': 0.8196399834367537, 'Total loss': 0.8196399834367537}
2022-11-18 03:16:51,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:51,385 INFO:     Epoch: 43
2022-11-18 03:16:52,163 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7353846065022729, 'Total loss': 0.7353846065022729} | train loss {'Reaction outcome loss': 0.8238389764822298, 'Total loss': 0.8238389764822298}
2022-11-18 03:16:52,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:52,163 INFO:     Epoch: 44
2022-11-18 03:16:52,964 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7317786677317186, 'Total loss': 0.7317786677317186} | train loss {'Reaction outcome loss': 0.8249969493237234, 'Total loss': 0.8249969493237234}
2022-11-18 03:16:52,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:52,964 INFO:     Epoch: 45
2022-11-18 03:16:53,735 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7359598468650471, 'Total loss': 0.7359598468650471} | train loss {'Reaction outcome loss': 0.8226575445263616, 'Total loss': 0.8226575445263616}
2022-11-18 03:16:53,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:53,735 INFO:     Epoch: 46
2022-11-18 03:16:54,516 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7286143059080298, 'Total loss': 0.7286143059080298} | train loss {'Reaction outcome loss': 0.8185565209677143, 'Total loss': 0.8185565209677143}
2022-11-18 03:16:54,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:54,516 INFO:     Epoch: 47
2022-11-18 03:16:55,287 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7477084195072, 'Total loss': 0.7477084195072} | train loss {'Reaction outcome loss': 0.8238636651827443, 'Total loss': 0.8238636651827443}
2022-11-18 03:16:55,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:55,287 INFO:     Epoch: 48
2022-11-18 03:16:56,039 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7321996241807938, 'Total loss': 0.7321996241807938} | train loss {'Reaction outcome loss': 0.8234411077874322, 'Total loss': 0.8234411077874322}
2022-11-18 03:16:56,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:56,040 INFO:     Epoch: 49
2022-11-18 03:16:56,835 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7384416765787385, 'Total loss': 0.7384416765787385} | train loss {'Reaction outcome loss': 0.8212916069934445, 'Total loss': 0.8212916069934445}
2022-11-18 03:16:56,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:56,835 INFO:     Epoch: 50
2022-11-18 03:16:57,610 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7604803422635252, 'Total loss': 0.7604803422635252} | train loss {'Reaction outcome loss': 0.8218328704036051, 'Total loss': 0.8218328704036051}
2022-11-18 03:16:57,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:57,611 INFO:     Epoch: 51
2022-11-18 03:16:58,369 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.757828639312224, 'Total loss': 0.757828639312224} | train loss {'Reaction outcome loss': 0.8228003442768128, 'Total loss': 0.8228003442768128}
2022-11-18 03:16:58,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:58,369 INFO:     Epoch: 52
2022-11-18 03:16:59,141 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7602779296311465, 'Total loss': 0.7602779296311465} | train loss {'Reaction outcome loss': 0.8214739164517771, 'Total loss': 0.8214739164517771}
2022-11-18 03:16:59,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:59,141 INFO:     Epoch: 53
2022-11-18 03:16:59,910 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7213721078905192, 'Total loss': 0.7213721078905192} | train loss {'Reaction outcome loss': 0.8216789640005557, 'Total loss': 0.8216789640005557}
2022-11-18 03:16:59,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:16:59,910 INFO:     Epoch: 54
2022-11-18 03:17:00,706 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7524895254861225, 'Total loss': 0.7524895254861225} | train loss {'Reaction outcome loss': 0.8183988329143294, 'Total loss': 0.8183988329143294}
2022-11-18 03:17:00,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:00,706 INFO:     Epoch: 55
2022-11-18 03:17:01,479 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7471335658972914, 'Total loss': 0.7471335658972914} | train loss {'Reaction outcome loss': 0.8204509796154115, 'Total loss': 0.8204509796154115}
2022-11-18 03:17:01,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:01,479 INFO:     Epoch: 56
2022-11-18 03:17:02,261 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7283449911258437, 'Total loss': 0.7283449911258437} | train loss {'Reaction outcome loss': 0.8196341181474347, 'Total loss': 0.8196341181474347}
2022-11-18 03:17:02,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:02,261 INFO:     Epoch: 57
2022-11-18 03:17:03,056 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7394400997595354, 'Total loss': 0.7394400997595354} | train loss {'Reaction outcome loss': 0.8251648345781911, 'Total loss': 0.8251648345781911}
2022-11-18 03:17:03,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:03,056 INFO:     Epoch: 58
2022-11-18 03:17:03,859 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7345046678727324, 'Total loss': 0.7345046678727324} | train loss {'Reaction outcome loss': 0.820173809244748, 'Total loss': 0.820173809244748}
2022-11-18 03:17:03,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:03,859 INFO:     Epoch: 59
2022-11-18 03:17:04,644 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7359599369493398, 'Total loss': 0.7359599369493398} | train loss {'Reaction outcome loss': 0.8202832079222125, 'Total loss': 0.8202832079222125}
2022-11-18 03:17:04,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:04,644 INFO:     Epoch: 60
2022-11-18 03:17:05,411 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7344291264360602, 'Total loss': 0.7344291264360602} | train loss {'Reaction outcome loss': 0.817081842210985, 'Total loss': 0.817081842210985}
2022-11-18 03:17:05,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:05,412 INFO:     Epoch: 61
2022-11-18 03:17:06,190 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7459637305953286, 'Total loss': 0.7459637305953286} | train loss {'Reaction outcome loss': 0.819742901791488, 'Total loss': 0.819742901791488}
2022-11-18 03:17:06,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:06,190 INFO:     Epoch: 62
2022-11-18 03:17:06,988 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7662010247057135, 'Total loss': 0.7662010247057135} | train loss {'Reaction outcome loss': 0.8224173197823186, 'Total loss': 0.8224173197823186}
2022-11-18 03:17:06,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:06,988 INFO:     Epoch: 63
2022-11-18 03:17:07,762 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7290589362382889, 'Total loss': 0.7290589362382889} | train loss {'Reaction outcome loss': 0.8195524200076058, 'Total loss': 0.8195524200076058}
2022-11-18 03:17:07,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:07,762 INFO:     Epoch: 64
2022-11-18 03:17:08,549 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7287823822010647, 'Total loss': 0.7287823822010647} | train loss {'Reaction outcome loss': 0.8181739462719809, 'Total loss': 0.8181739462719809}
2022-11-18 03:17:08,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:08,550 INFO:     Epoch: 65
2022-11-18 03:17:09,335 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7232654433358799, 'Total loss': 0.7232654433358799} | train loss {'Reaction outcome loss': 0.8198814972514107, 'Total loss': 0.8198814972514107}
2022-11-18 03:17:09,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:09,335 INFO:     Epoch: 66
2022-11-18 03:17:10,099 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7325155335393819, 'Total loss': 0.7325155335393819} | train loss {'Reaction outcome loss': 0.8189836659979436, 'Total loss': 0.8189836659979436}
2022-11-18 03:17:10,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:10,100 INFO:     Epoch: 67
2022-11-18 03:17:10,868 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7367741641673174, 'Total loss': 0.7367741641673174} | train loss {'Reaction outcome loss': 0.8184394825610423, 'Total loss': 0.8184394825610423}
2022-11-18 03:17:10,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:10,869 INFO:     Epoch: 68
2022-11-18 03:17:11,668 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7465104474262758, 'Total loss': 0.7465104474262758} | train loss {'Reaction outcome loss': 0.8206919410055683, 'Total loss': 0.8206919410055683}
2022-11-18 03:17:11,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:11,669 INFO:     Epoch: 69
2022-11-18 03:17:12,440 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7509300939061425, 'Total loss': 0.7509300939061425} | train loss {'Reaction outcome loss': 0.82139259120149, 'Total loss': 0.82139259120149}
2022-11-18 03:17:12,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:12,440 INFO:     Epoch: 70
2022-11-18 03:17:13,231 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7379459142684937, 'Total loss': 0.7379459142684937} | train loss {'Reaction outcome loss': 0.8185670720713754, 'Total loss': 0.8185670720713754}
2022-11-18 03:17:13,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:13,231 INFO:     Epoch: 71
2022-11-18 03:17:14,016 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7325153973969546, 'Total loss': 0.7325153973969546} | train loss {'Reaction outcome loss': 0.8171289376914501, 'Total loss': 0.8171289376914501}
2022-11-18 03:17:14,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:14,017 INFO:     Epoch: 72
2022-11-18 03:17:14,832 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7381763106042688, 'Total loss': 0.7381763106042688} | train loss {'Reaction outcome loss': 0.8140720676991248, 'Total loss': 0.8140720676991248}
2022-11-18 03:17:14,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:14,833 INFO:     Epoch: 73
2022-11-18 03:17:15,624 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7308904521844604, 'Total loss': 0.7308904521844604} | train loss {'Reaction outcome loss': 0.8202253558462665, 'Total loss': 0.8202253558462665}
2022-11-18 03:17:15,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:15,624 INFO:     Epoch: 74
2022-11-18 03:17:16,397 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7287627709182826, 'Total loss': 0.7287627709182826} | train loss {'Reaction outcome loss': 0.8199586518589528, 'Total loss': 0.8199586518589528}
2022-11-18 03:17:16,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:16,398 INFO:     Epoch: 75
2022-11-18 03:17:17,189 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7330334328792312, 'Total loss': 0.7330334328792312} | train loss {'Reaction outcome loss': 0.8196313221368098, 'Total loss': 0.8196313221368098}
2022-11-18 03:17:17,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:17,189 INFO:     Epoch: 76
2022-11-18 03:17:17,963 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7529160610654138, 'Total loss': 0.7529160610654138} | train loss {'Reaction outcome loss': 0.81864555768909, 'Total loss': 0.81864555768909}
2022-11-18 03:17:17,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:17,963 INFO:     Epoch: 77
2022-11-18 03:17:18,766 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7324781201102517, 'Total loss': 0.7324781201102517} | train loss {'Reaction outcome loss': 0.8209906927039546, 'Total loss': 0.8209906927039546}
2022-11-18 03:17:18,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:18,766 INFO:     Epoch: 78
2022-11-18 03:17:19,566 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.749414446001703, 'Total loss': 0.749414446001703} | train loss {'Reaction outcome loss': 0.8152080822375513, 'Total loss': 0.8152080822375513}
2022-11-18 03:17:19,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:19,566 INFO:     Epoch: 79
2022-11-18 03:17:20,398 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7338458489287983, 'Total loss': 0.7338458489287983} | train loss {'Reaction outcome loss': 0.8237130685198691, 'Total loss': 0.8237130685198691}
2022-11-18 03:17:20,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:20,398 INFO:     Epoch: 80
2022-11-18 03:17:21,204 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7272743785923178, 'Total loss': 0.7272743785923178} | train loss {'Reaction outcome loss': 0.8197741682731337, 'Total loss': 0.8197741682731337}
2022-11-18 03:17:21,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:21,206 INFO:     Epoch: 81
2022-11-18 03:17:22,022 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7310416488484903, 'Total loss': 0.7310416488484903} | train loss {'Reaction outcome loss': 0.8171234033521144, 'Total loss': 0.8171234033521144}
2022-11-18 03:17:22,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:22,022 INFO:     Epoch: 82
2022-11-18 03:17:22,859 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.734550381925973, 'Total loss': 0.734550381925973} | train loss {'Reaction outcome loss': 0.8206207580383746, 'Total loss': 0.8206207580383746}
2022-11-18 03:17:22,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:22,859 INFO:     Epoch: 83
2022-11-18 03:17:23,691 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7297810194167224, 'Total loss': 0.7297810194167224} | train loss {'Reaction outcome loss': 0.819468088327877, 'Total loss': 0.819468088327877}
2022-11-18 03:17:23,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:23,691 INFO:     Epoch: 84
2022-11-18 03:17:24,475 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.726200842383233, 'Total loss': 0.726200842383233} | train loss {'Reaction outcome loss': 0.8232873211945256, 'Total loss': 0.8232873211945256}
2022-11-18 03:17:24,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:24,475 INFO:     Epoch: 85
2022-11-18 03:17:25,289 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7366771074858579, 'Total loss': 0.7366771074858579} | train loss {'Reaction outcome loss': 0.8182541049055515, 'Total loss': 0.8182541049055515}
2022-11-18 03:17:25,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:25,290 INFO:     Epoch: 86
2022-11-18 03:17:26,110 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7377070601690899, 'Total loss': 0.7377070601690899} | train loss {'Reaction outcome loss': 0.8188401219104567, 'Total loss': 0.8188401219104567}
2022-11-18 03:17:26,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:26,111 INFO:     Epoch: 87
2022-11-18 03:17:26,922 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.74295923858881, 'Total loss': 0.74295923858881} | train loss {'Reaction outcome loss': 0.8217591151835457, 'Total loss': 0.8217591151835457}
2022-11-18 03:17:26,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:26,922 INFO:     Epoch: 88
2022-11-18 03:17:27,744 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7358613136139783, 'Total loss': 0.7358613136139783} | train loss {'Reaction outcome loss': 0.8157645532440755, 'Total loss': 0.8157645532440755}
2022-11-18 03:17:27,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:27,745 INFO:     Epoch: 89
2022-11-18 03:17:28,538 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7388364767486398, 'Total loss': 0.7388364767486398} | train loss {'Reaction outcome loss': 0.8199759442960063, 'Total loss': 0.8199759442960063}
2022-11-18 03:17:28,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:28,538 INFO:     Epoch: 90
2022-11-18 03:17:29,326 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7287866026163101, 'Total loss': 0.7287866026163101} | train loss {'Reaction outcome loss': 0.8201140926009224, 'Total loss': 0.8201140926009224}
2022-11-18 03:17:29,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:29,327 INFO:     Epoch: 91
2022-11-18 03:17:30,136 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7244752625172789, 'Total loss': 0.7244752625172789} | train loss {'Reaction outcome loss': 0.8170759388275685, 'Total loss': 0.8170759388275685}
2022-11-18 03:17:30,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:30,136 INFO:     Epoch: 92
2022-11-18 03:17:30,986 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7270518968051131, 'Total loss': 0.7270518968051131} | train loss {'Reaction outcome loss': 0.8189646578844516, 'Total loss': 0.8189646578844516}
2022-11-18 03:17:30,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:30,987 INFO:     Epoch: 93
2022-11-18 03:17:31,774 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7385529868982055, 'Total loss': 0.7385529868982055} | train loss {'Reaction outcome loss': 0.8141756557649181, 'Total loss': 0.8141756557649181}
2022-11-18 03:17:31,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:31,774 INFO:     Epoch: 94
2022-11-18 03:17:32,550 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7566381421956149, 'Total loss': 0.7566381421956149} | train loss {'Reaction outcome loss': 0.8198429610460035, 'Total loss': 0.8198429610460035}
2022-11-18 03:17:32,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:32,550 INFO:     Epoch: 95
2022-11-18 03:17:33,353 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7355933263897896, 'Total loss': 0.7355933263897896} | train loss {'Reaction outcome loss': 0.8180438143111044, 'Total loss': 0.8180438143111044}
2022-11-18 03:17:33,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:33,353 INFO:     Epoch: 96
2022-11-18 03:17:34,215 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.730811480094086, 'Total loss': 0.730811480094086} | train loss {'Reaction outcome loss': 0.8176758862551181, 'Total loss': 0.8176758862551181}
2022-11-18 03:17:34,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:34,215 INFO:     Epoch: 97
2022-11-18 03:17:35,004 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7392107580195774, 'Total loss': 0.7392107580195774} | train loss {'Reaction outcome loss': 0.8160688744317139, 'Total loss': 0.8160688744317139}
2022-11-18 03:17:35,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:35,004 INFO:     Epoch: 98
2022-11-18 03:17:35,799 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7677718827670271, 'Total loss': 0.7677718827670271} | train loss {'Reaction outcome loss': 0.818305600314371, 'Total loss': 0.818305600314371}
2022-11-18 03:17:35,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:35,799 INFO:     Epoch: 99
2022-11-18 03:17:36,615 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7427991540594534, 'Total loss': 0.7427991540594534} | train loss {'Reaction outcome loss': 0.8259800902057078, 'Total loss': 0.8259800902057078}
2022-11-18 03:17:36,616 INFO:     Best model found after epoch 39 of 100.
2022-11-18 03:17:36,616 INFO:   Done with stage: TRAINING
2022-11-18 03:17:36,616 INFO:   Starting stage: EVALUATION
2022-11-18 03:17:36,737 INFO:   Done with stage: EVALUATION
2022-11-18 03:17:36,737 INFO:   Leaving out SEQ value Fold_7
2022-11-18 03:17:36,750 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:17:36,750 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:17:37,419 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:17:37,419 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:17:37,488 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:17:37,488 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:17:37,489 INFO:     No hyperparam tuning for this model
2022-11-18 03:17:37,489 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:17:37,489 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:17:37,490 INFO:     None feature selector for col prot
2022-11-18 03:17:37,490 INFO:     None feature selector for col prot
2022-11-18 03:17:37,490 INFO:     None feature selector for col prot
2022-11-18 03:17:37,490 INFO:     None feature selector for col chem
2022-11-18 03:17:37,491 INFO:     None feature selector for col chem
2022-11-18 03:17:37,491 INFO:     None feature selector for col chem
2022-11-18 03:17:37,491 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:17:37,491 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:17:37,492 INFO:     Number of params in model 168571
2022-11-18 03:17:37,496 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:17:37,496 INFO:   Starting stage: TRAINING
2022-11-18 03:17:37,554 INFO:     Val loss before train {'Reaction outcome loss': 0.989813896742734, 'Total loss': 0.989813896742734}
2022-11-18 03:17:37,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:37,554 INFO:     Epoch: 0
2022-11-18 03:17:38,385 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8458487025716088, 'Total loss': 0.8458487025716088} | train loss {'Reaction outcome loss': 0.8799172225258043, 'Total loss': 0.8799172225258043}
2022-11-18 03:17:38,385 INFO:     Found new best model at epoch 0
2022-11-18 03:17:38,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:38,386 INFO:     Epoch: 1
2022-11-18 03:17:39,170 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8489705087109045, 'Total loss': 0.8489705087109045} | train loss {'Reaction outcome loss': 0.8566690908083993, 'Total loss': 0.8566690908083993}
2022-11-18 03:17:39,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:39,170 INFO:     Epoch: 2
2022-11-18 03:17:39,985 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8430754095315933, 'Total loss': 0.8430754095315933} | train loss {'Reaction outcome loss': 0.8519936544039557, 'Total loss': 0.8519936544039557}
2022-11-18 03:17:39,986 INFO:     Found new best model at epoch 2
2022-11-18 03:17:39,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:39,987 INFO:     Epoch: 3
2022-11-18 03:17:40,803 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8946144106713209, 'Total loss': 0.8946144106713209} | train loss {'Reaction outcome loss': 0.8481858050630938, 'Total loss': 0.8481858050630938}
2022-11-18 03:17:40,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:40,803 INFO:     Epoch: 4
2022-11-18 03:17:41,569 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8371913385662165, 'Total loss': 0.8371913385662165} | train loss {'Reaction outcome loss': 0.8409974784139664, 'Total loss': 0.8409974784139664}
2022-11-18 03:17:41,569 INFO:     Found new best model at epoch 4
2022-11-18 03:17:41,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:41,570 INFO:     Epoch: 5
2022-11-18 03:17:42,397 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8293577988039363, 'Total loss': 0.8293577988039363} | train loss {'Reaction outcome loss': 0.8285186589965897, 'Total loss': 0.8285186589965897}
2022-11-18 03:17:42,397 INFO:     Found new best model at epoch 5
2022-11-18 03:17:42,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:42,398 INFO:     Epoch: 6
2022-11-18 03:17:43,202 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8450098769231276, 'Total loss': 0.8450098769231276} | train loss {'Reaction outcome loss': 0.8340908805689504, 'Total loss': 0.8340908805689504}
2022-11-18 03:17:43,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:43,202 INFO:     Epoch: 7
2022-11-18 03:17:44,057 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8316660767251794, 'Total loss': 0.8316660767251794} | train loss {'Reaction outcome loss': 0.8311429344598324, 'Total loss': 0.8311429344598324}
2022-11-18 03:17:44,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:44,057 INFO:     Epoch: 8
2022-11-18 03:17:44,895 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.848646997728131, 'Total loss': 0.848646997728131} | train loss {'Reaction outcome loss': 0.8307143238282972, 'Total loss': 0.8307143238282972}
2022-11-18 03:17:44,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:44,895 INFO:     Epoch: 9
2022-11-18 03:17:45,711 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8369733982465484, 'Total loss': 0.8369733982465484} | train loss {'Reaction outcome loss': 0.8261962790162333, 'Total loss': 0.8261962790162333}
2022-11-18 03:17:45,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:45,712 INFO:     Epoch: 10
2022-11-18 03:17:46,540 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8416796760125593, 'Total loss': 0.8416796760125593} | train loss {'Reaction outcome loss': 0.8292724599521006, 'Total loss': 0.8292724599521006}
2022-11-18 03:17:46,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:46,540 INFO:     Epoch: 11
2022-11-18 03:17:47,354 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8534473113038323, 'Total loss': 0.8534473113038323} | train loss {'Reaction outcome loss': 0.8244109808677628, 'Total loss': 0.8244109808677628}
2022-11-18 03:17:47,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:47,354 INFO:     Epoch: 12
2022-11-18 03:17:48,156 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8782557845115662, 'Total loss': 0.8782557845115662} | train loss {'Reaction outcome loss': 0.8250525239254197, 'Total loss': 0.8250525239254197}
2022-11-18 03:17:48,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:48,156 INFO:     Epoch: 13
2022-11-18 03:17:48,957 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8355598815462806, 'Total loss': 0.8355598815462806} | train loss {'Reaction outcome loss': 0.8258298522522373, 'Total loss': 0.8258298522522373}
2022-11-18 03:17:48,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:48,957 INFO:     Epoch: 14
2022-11-18 03:17:49,759 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8145280954512683, 'Total loss': 0.8145280954512683} | train loss {'Reaction outcome loss': 0.822228938941994, 'Total loss': 0.822228938941994}
2022-11-18 03:17:49,759 INFO:     Found new best model at epoch 14
2022-11-18 03:17:49,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:49,760 INFO:     Epoch: 15
2022-11-18 03:17:50,593 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.819746767255393, 'Total loss': 0.819746767255393} | train loss {'Reaction outcome loss': 0.822701207932926, 'Total loss': 0.822701207932926}
2022-11-18 03:17:50,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:50,593 INFO:     Epoch: 16
2022-11-18 03:17:51,433 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8324103917587887, 'Total loss': 0.8324103917587887} | train loss {'Reaction outcome loss': 0.830328736934931, 'Total loss': 0.830328736934931}
2022-11-18 03:17:51,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:51,433 INFO:     Epoch: 17
2022-11-18 03:17:52,234 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8156697993928735, 'Total loss': 0.8156697993928735} | train loss {'Reaction outcome loss': 0.8248680729058481, 'Total loss': 0.8248680729058481}
2022-11-18 03:17:52,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:52,235 INFO:     Epoch: 18
2022-11-18 03:17:53,051 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8423072932796045, 'Total loss': 0.8423072932796045} | train loss {'Reaction outcome loss': 0.8219529768872645, 'Total loss': 0.8219529768872645}
2022-11-18 03:17:53,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:53,052 INFO:     Epoch: 19
2022-11-18 03:17:53,878 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8433721620928157, 'Total loss': 0.8433721620928157} | train loss {'Reaction outcome loss': 0.8209301099902199, 'Total loss': 0.8209301099902199}
2022-11-18 03:17:53,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:53,879 INFO:     Epoch: 20
2022-11-18 03:17:54,657 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.827283304523338, 'Total loss': 0.827283304523338} | train loss {'Reaction outcome loss': 0.8270617927755078, 'Total loss': 0.8270617927755078}
2022-11-18 03:17:54,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:54,657 INFO:     Epoch: 21
2022-11-18 03:17:55,467 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8294468373060226, 'Total loss': 0.8294468373060226} | train loss {'Reaction outcome loss': 0.8250792938615045, 'Total loss': 0.8250792938615045}
2022-11-18 03:17:55,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:55,467 INFO:     Epoch: 22
2022-11-18 03:17:56,251 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8454875708980993, 'Total loss': 0.8454875708980993} | train loss {'Reaction outcome loss': 0.8162561152731219, 'Total loss': 0.8162561152731219}
2022-11-18 03:17:56,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:56,252 INFO:     Epoch: 23
2022-11-18 03:17:57,091 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8173245665701953, 'Total loss': 0.8173245665701953} | train loss {'Reaction outcome loss': 0.8271074600277408, 'Total loss': 0.8271074600277408}
2022-11-18 03:17:57,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:57,091 INFO:     Epoch: 24
2022-11-18 03:17:57,906 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8319395604458723, 'Total loss': 0.8319395604458723} | train loss {'Reaction outcome loss': 0.8216087019010898, 'Total loss': 0.8216087019010898}
2022-11-18 03:17:57,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:57,907 INFO:     Epoch: 25
2022-11-18 03:17:58,716 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.821086273951964, 'Total loss': 0.821086273951964} | train loss {'Reaction outcome loss': 0.8206714666899173, 'Total loss': 0.8206714666899173}
2022-11-18 03:17:58,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:58,717 INFO:     Epoch: 26
2022-11-18 03:17:59,515 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8308035304600542, 'Total loss': 0.8308035304600542} | train loss {'Reaction outcome loss': 0.8186755759581443, 'Total loss': 0.8186755759581443}
2022-11-18 03:17:59,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:17:59,515 INFO:     Epoch: 27
2022-11-18 03:18:00,321 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8252660456028852, 'Total loss': 0.8252660456028852} | train loss {'Reaction outcome loss': 0.8257076840006536, 'Total loss': 0.8257076840006536}
2022-11-18 03:18:00,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:00,322 INFO:     Epoch: 28
2022-11-18 03:18:01,128 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8194078091870655, 'Total loss': 0.8194078091870655} | train loss {'Reaction outcome loss': 0.8230060850900989, 'Total loss': 0.8230060850900989}
2022-11-18 03:18:01,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:01,129 INFO:     Epoch: 29
2022-11-18 03:18:01,896 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8272371712056074, 'Total loss': 0.8272371712056074} | train loss {'Reaction outcome loss': 0.8239742921244714, 'Total loss': 0.8239742921244714}
2022-11-18 03:18:01,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:01,896 INFO:     Epoch: 30
2022-11-18 03:18:02,712 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8335202417590402, 'Total loss': 0.8335202417590402} | train loss {'Reaction outcome loss': 0.8190486318161411, 'Total loss': 0.8190486318161411}
2022-11-18 03:18:02,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:02,712 INFO:     Epoch: 31
2022-11-18 03:18:03,530 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8226089423353021, 'Total loss': 0.8226089423353021} | train loss {'Reaction outcome loss': 0.8261793049112442, 'Total loss': 0.8261793049112442}
2022-11-18 03:18:03,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:03,531 INFO:     Epoch: 32
2022-11-18 03:18:04,375 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8187774609435688, 'Total loss': 0.8187774609435688} | train loss {'Reaction outcome loss': 0.8244461536167129, 'Total loss': 0.8244461536167129}
2022-11-18 03:18:04,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:04,375 INFO:     Epoch: 33
2022-11-18 03:18:05,171 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8154884021390568, 'Total loss': 0.8154884021390568} | train loss {'Reaction outcome loss': 0.8213052001571463, 'Total loss': 0.8213052001571463}
2022-11-18 03:18:05,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:05,172 INFO:     Epoch: 34
2022-11-18 03:18:05,977 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8292280273004011, 'Total loss': 0.8292280273004011} | train loss {'Reaction outcome loss': 0.8240407166942474, 'Total loss': 0.8240407166942474}
2022-11-18 03:18:05,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:05,978 INFO:     Epoch: 35
2022-11-18 03:18:06,759 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8389113985679366, 'Total loss': 0.8389113985679366} | train loss {'Reaction outcome loss': 0.8232531598018061, 'Total loss': 0.8232531598018061}
2022-11-18 03:18:06,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:06,759 INFO:     Epoch: 36
2022-11-18 03:18:07,595 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8159599710594524, 'Total loss': 0.8159599710594524} | train loss {'Reaction outcome loss': 0.8241469003260136, 'Total loss': 0.8241469003260136}
2022-11-18 03:18:07,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:07,595 INFO:     Epoch: 37
2022-11-18 03:18:08,426 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8468762636184692, 'Total loss': 0.8468762636184692} | train loss {'Reaction outcome loss': 0.8164675750078694, 'Total loss': 0.8164675750078694}
2022-11-18 03:18:08,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:08,426 INFO:     Epoch: 38
2022-11-18 03:18:09,249 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8332504657181826, 'Total loss': 0.8332504657181826} | train loss {'Reaction outcome loss': 0.8197709122492421, 'Total loss': 0.8197709122492421}
2022-11-18 03:18:09,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:09,250 INFO:     Epoch: 39
2022-11-18 03:18:10,060 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8279800774021582, 'Total loss': 0.8279800774021582} | train loss {'Reaction outcome loss': 0.8216989004323559, 'Total loss': 0.8216989004323559}
2022-11-18 03:18:10,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:10,061 INFO:     Epoch: 40
2022-11-18 03:18:10,883 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.837777011773803, 'Total loss': 0.837777011773803} | train loss {'Reaction outcome loss': 0.8216781332608192, 'Total loss': 0.8216781332608192}
2022-11-18 03:18:10,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:10,884 INFO:     Epoch: 41
2022-11-18 03:18:11,695 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8375547656958754, 'Total loss': 0.8375547656958754} | train loss {'Reaction outcome loss': 0.8217751538801578, 'Total loss': 0.8217751538801578}
2022-11-18 03:18:11,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:11,695 INFO:     Epoch: 42
2022-11-18 03:18:12,495 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8257113491947, 'Total loss': 0.8257113491947} | train loss {'Reaction outcome loss': 0.82325020756933, 'Total loss': 0.82325020756933}
2022-11-18 03:18:12,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:12,496 INFO:     Epoch: 43
2022-11-18 03:18:13,321 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8255218524824489, 'Total loss': 0.8255218524824489} | train loss {'Reaction outcome loss': 0.82088503241539, 'Total loss': 0.82088503241539}
2022-11-18 03:18:13,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:13,321 INFO:     Epoch: 44
2022-11-18 03:18:14,166 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8360396962274205, 'Total loss': 0.8360396962274205} | train loss {'Reaction outcome loss': 0.8202206754396039, 'Total loss': 0.8202206754396039}
2022-11-18 03:18:14,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:14,167 INFO:     Epoch: 45
2022-11-18 03:18:14,968 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8173894340341742, 'Total loss': 0.8173894340341742} | train loss {'Reaction outcome loss': 0.822323557109602, 'Total loss': 0.822323557109602}
2022-11-18 03:18:14,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:14,968 INFO:     Epoch: 46
2022-11-18 03:18:15,770 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8277193646539341, 'Total loss': 0.8277193646539341} | train loss {'Reaction outcome loss': 0.8217202304832397, 'Total loss': 0.8217202304832397}
2022-11-18 03:18:15,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:15,770 INFO:     Epoch: 47
2022-11-18 03:18:16,590 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8305202817375009, 'Total loss': 0.8305202817375009} | train loss {'Reaction outcome loss': 0.829384813746137, 'Total loss': 0.829384813746137}
2022-11-18 03:18:16,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:16,591 INFO:     Epoch: 48
2022-11-18 03:18:17,384 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8197871582074598, 'Total loss': 0.8197871582074598} | train loss {'Reaction outcome loss': 0.8253026514524414, 'Total loss': 0.8253026514524414}
2022-11-18 03:18:17,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:17,384 INFO:     Epoch: 49
2022-11-18 03:18:18,211 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8453389331698418, 'Total loss': 0.8453389331698418} | train loss {'Reaction outcome loss': 0.8216299024080077, 'Total loss': 0.8216299024080077}
2022-11-18 03:18:18,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:18,211 INFO:     Epoch: 50
2022-11-18 03:18:19,017 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.840369236740199, 'Total loss': 0.840369236740199} | train loss {'Reaction outcome loss': 0.817536901442274, 'Total loss': 0.817536901442274}
2022-11-18 03:18:19,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:19,018 INFO:     Epoch: 51
2022-11-18 03:18:19,815 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.848927531730045, 'Total loss': 0.848927531730045} | train loss {'Reaction outcome loss': 0.8186994038161731, 'Total loss': 0.8186994038161731}
2022-11-18 03:18:19,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:19,816 INFO:     Epoch: 52
2022-11-18 03:18:20,626 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8239200508052652, 'Total loss': 0.8239200508052652} | train loss {'Reaction outcome loss': 0.8209709001164283, 'Total loss': 0.8209709001164283}
2022-11-18 03:18:20,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:20,626 INFO:     Epoch: 53
2022-11-18 03:18:21,457 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8248596509749239, 'Total loss': 0.8248596509749239} | train loss {'Reaction outcome loss': 0.8249637628755262, 'Total loss': 0.8249637628755262}
2022-11-18 03:18:21,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:21,457 INFO:     Epoch: 54
2022-11-18 03:18:22,278 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8213138241659511, 'Total loss': 0.8213138241659511} | train loss {'Reaction outcome loss': 0.8169029976331419, 'Total loss': 0.8169029976331419}
2022-11-18 03:18:22,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:22,278 INFO:     Epoch: 55
2022-11-18 03:18:23,106 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8239908184517514, 'Total loss': 0.8239908184517514} | train loss {'Reaction outcome loss': 0.8228346747496436, 'Total loss': 0.8228346747496436}
2022-11-18 03:18:23,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:23,108 INFO:     Epoch: 56
2022-11-18 03:18:23,900 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8154839074069803, 'Total loss': 0.8154839074069803} | train loss {'Reaction outcome loss': 0.8194630093151524, 'Total loss': 0.8194630093151524}
2022-11-18 03:18:23,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:23,900 INFO:     Epoch: 57
2022-11-18 03:18:24,699 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8240485841577704, 'Total loss': 0.8240485841577704} | train loss {'Reaction outcome loss': 0.8216663270948394, 'Total loss': 0.8216663270948394}
2022-11-18 03:18:24,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:24,700 INFO:     Epoch: 58
2022-11-18 03:18:25,556 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8393117433244531, 'Total loss': 0.8393117433244531} | train loss {'Reaction outcome loss': 0.822844416744286, 'Total loss': 0.822844416744286}
2022-11-18 03:18:25,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:25,556 INFO:     Epoch: 59
2022-11-18 03:18:26,333 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8362162167375738, 'Total loss': 0.8362162167375738} | train loss {'Reaction outcome loss': 0.8176798447966576, 'Total loss': 0.8176798447966576}
2022-11-18 03:18:26,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:26,334 INFO:     Epoch: 60
2022-11-18 03:18:27,160 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8304182284257628, 'Total loss': 0.8304182284257628} | train loss {'Reaction outcome loss': 0.8180940564601652, 'Total loss': 0.8180940564601652}
2022-11-18 03:18:27,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:27,160 INFO:     Epoch: 61
2022-11-18 03:18:28,005 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8183503604748033, 'Total loss': 0.8183503604748033} | train loss {'Reaction outcome loss': 0.8245993683174733, 'Total loss': 0.8245993683174733}
2022-11-18 03:18:28,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:28,005 INFO:     Epoch: 62
2022-11-18 03:18:28,831 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8171429281884973, 'Total loss': 0.8171429281884973} | train loss {'Reaction outcome loss': 0.820441011699938, 'Total loss': 0.820441011699938}
2022-11-18 03:18:28,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:28,832 INFO:     Epoch: 63
2022-11-18 03:18:29,677 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8185025033625689, 'Total loss': 0.8185025033625689} | train loss {'Reaction outcome loss': 0.8225008911423145, 'Total loss': 0.8225008911423145}
2022-11-18 03:18:29,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:29,678 INFO:     Epoch: 64
2022-11-18 03:18:30,473 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8291941799900748, 'Total loss': 0.8291941799900748} | train loss {'Reaction outcome loss': 0.8164646805774781, 'Total loss': 0.8164646805774781}
2022-11-18 03:18:30,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:30,474 INFO:     Epoch: 65
2022-11-18 03:18:31,269 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8338413963263686, 'Total loss': 0.8338413963263686} | train loss {'Reaction outcome loss': 0.8161021341239253, 'Total loss': 0.8161021341239253}
2022-11-18 03:18:31,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:31,269 INFO:     Epoch: 66
2022-11-18 03:18:32,037 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8298261003060774, 'Total loss': 0.8298261003060774} | train loss {'Reaction outcome loss': 0.8252905930482572, 'Total loss': 0.8252905930482572}
2022-11-18 03:18:32,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:32,037 INFO:     Epoch: 67
2022-11-18 03:18:32,824 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8256272064013914, 'Total loss': 0.8256272064013914} | train loss {'Reaction outcome loss': 0.8155623944776673, 'Total loss': 0.8155623944776673}
2022-11-18 03:18:32,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:32,824 INFO:     Epoch: 68
2022-11-18 03:18:33,648 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8152745311910455, 'Total loss': 0.8152745311910455} | train loss {'Reaction outcome loss': 0.8230342868595354, 'Total loss': 0.8230342868595354}
2022-11-18 03:18:33,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:33,649 INFO:     Epoch: 69
2022-11-18 03:18:34,515 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.826761784878644, 'Total loss': 0.826761784878644} | train loss {'Reaction outcome loss': 0.8223863466372413, 'Total loss': 0.8223863466372413}
2022-11-18 03:18:34,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:34,515 INFO:     Epoch: 70
2022-11-18 03:18:35,319 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8162206357175653, 'Total loss': 0.8162206357175653} | train loss {'Reaction outcome loss': 0.8255175502309876, 'Total loss': 0.8255175502309876}
2022-11-18 03:18:35,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:35,319 INFO:     Epoch: 71
2022-11-18 03:18:36,143 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8484169109301134, 'Total loss': 0.8484169109301134} | train loss {'Reaction outcome loss': 0.822586216393017, 'Total loss': 0.822586216393017}
2022-11-18 03:18:36,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:36,143 INFO:     Epoch: 72
2022-11-18 03:18:36,946 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8184470778161829, 'Total loss': 0.8184470778161829} | train loss {'Reaction outcome loss': 0.8258766737436095, 'Total loss': 0.8258766737436095}
2022-11-18 03:18:36,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:36,946 INFO:     Epoch: 73
2022-11-18 03:18:37,746 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8070426847447049, 'Total loss': 0.8070426847447049} | train loss {'Reaction outcome loss': 0.8229639101172647, 'Total loss': 0.8229639101172647}
2022-11-18 03:18:37,746 INFO:     Found new best model at epoch 73
2022-11-18 03:18:37,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:37,747 INFO:     Epoch: 74
2022-11-18 03:18:38,552 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8500935631719503, 'Total loss': 0.8500935631719503} | train loss {'Reaction outcome loss': 0.8212282440114406, 'Total loss': 0.8212282440114406}
2022-11-18 03:18:38,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:38,552 INFO:     Epoch: 75
2022-11-18 03:18:39,401 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8159365227276628, 'Total loss': 0.8159365227276628} | train loss {'Reaction outcome loss': 0.8161668057643598, 'Total loss': 0.8161668057643598}
2022-11-18 03:18:39,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:39,401 INFO:     Epoch: 76
2022-11-18 03:18:40,224 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8132216544313864, 'Total loss': 0.8132216544313864} | train loss {'Reaction outcome loss': 0.8203106312261473, 'Total loss': 0.8203106312261473}
2022-11-18 03:18:40,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:40,225 INFO:     Epoch: 77
2022-11-18 03:18:41,092 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8564247597347606, 'Total loss': 0.8564247597347606} | train loss {'Reaction outcome loss': 0.8189481827280214, 'Total loss': 0.8189481827280214}
2022-11-18 03:18:41,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:41,093 INFO:     Epoch: 78
2022-11-18 03:18:41,872 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8196337263692509, 'Total loss': 0.8196337263692509} | train loss {'Reaction outcome loss': 0.8181096840529672, 'Total loss': 0.8181096840529672}
2022-11-18 03:18:41,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:41,874 INFO:     Epoch: 79
2022-11-18 03:18:42,720 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8290902782570232, 'Total loss': 0.8290902782570232} | train loss {'Reaction outcome loss': 0.8147920368900222, 'Total loss': 0.8147920368900222}
2022-11-18 03:18:42,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:42,720 INFO:     Epoch: 80
2022-11-18 03:18:43,506 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8137845654379238, 'Total loss': 0.8137845654379238} | train loss {'Reaction outcome loss': 0.8173980872717596, 'Total loss': 0.8173980872717596}
2022-11-18 03:18:43,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:43,506 INFO:     Epoch: 81
2022-11-18 03:18:44,311 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8258659433234822, 'Total loss': 0.8258659433234822} | train loss {'Reaction outcome loss': 0.8191066804912782, 'Total loss': 0.8191066804912782}
2022-11-18 03:18:44,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:44,311 INFO:     Epoch: 82
2022-11-18 03:18:45,142 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.818839514797384, 'Total loss': 0.818839514797384} | train loss {'Reaction outcome loss': 0.8225517271747512, 'Total loss': 0.8225517271747512}
2022-11-18 03:18:45,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:45,143 INFO:     Epoch: 83
2022-11-18 03:18:45,908 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8300626271150329, 'Total loss': 0.8300626271150329} | train loss {'Reaction outcome loss': 0.8159607556318084, 'Total loss': 0.8159607556318084}
2022-11-18 03:18:45,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:45,909 INFO:     Epoch: 84
2022-11-18 03:18:46,697 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8223599561236121, 'Total loss': 0.8223599561236121} | train loss {'Reaction outcome loss': 0.8217779532555611, 'Total loss': 0.8217779532555611}
2022-11-18 03:18:46,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:46,698 INFO:     Epoch: 85
2022-11-18 03:18:47,459 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.814247650178996, 'Total loss': 0.814247650178996} | train loss {'Reaction outcome loss': 0.8171541321902506, 'Total loss': 0.8171541321902506}
2022-11-18 03:18:47,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:47,459 INFO:     Epoch: 86
2022-11-18 03:18:48,275 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8317989856004715, 'Total loss': 0.8317989856004715} | train loss {'Reaction outcome loss': 0.8240568452785092, 'Total loss': 0.8240568452785092}
2022-11-18 03:18:48,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:48,275 INFO:     Epoch: 87
2022-11-18 03:18:49,053 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8403887322003191, 'Total loss': 0.8403887322003191} | train loss {'Reaction outcome loss': 0.8197744444252983, 'Total loss': 0.8197744444252983}
2022-11-18 03:18:49,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:49,053 INFO:     Epoch: 88
2022-11-18 03:18:49,850 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8256291008808396, 'Total loss': 0.8256291008808396} | train loss {'Reaction outcome loss': 0.8175607292402175, 'Total loss': 0.8175607292402175}
2022-11-18 03:18:49,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:49,851 INFO:     Epoch: 89
2022-11-18 03:18:50,668 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8269184949723157, 'Total loss': 0.8269184949723157} | train loss {'Reaction outcome loss': 0.815110383915805, 'Total loss': 0.815110383915805}
2022-11-18 03:18:50,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:50,668 INFO:     Epoch: 90
2022-11-18 03:18:51,431 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8193273740735921, 'Total loss': 0.8193273740735921} | train loss {'Reaction outcome loss': 0.8185305809301715, 'Total loss': 0.8185305809301715}
2022-11-18 03:18:51,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:51,432 INFO:     Epoch: 91
2022-11-18 03:18:52,221 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8201029232957147, 'Total loss': 0.8201029232957147} | train loss {'Reaction outcome loss': 0.8186297842091129, 'Total loss': 0.8186297842091129}
2022-11-18 03:18:52,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:52,221 INFO:     Epoch: 92
2022-11-18 03:18:52,990 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8165720132264224, 'Total loss': 0.8165720132264224} | train loss {'Reaction outcome loss': 0.8166470040957774, 'Total loss': 0.8166470040957774}
2022-11-18 03:18:52,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:52,990 INFO:     Epoch: 93
2022-11-18 03:18:53,783 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.819555789232254, 'Total loss': 0.819555789232254} | train loss {'Reaction outcome loss': 0.8175005090813483, 'Total loss': 0.8175005090813483}
2022-11-18 03:18:53,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:53,785 INFO:     Epoch: 94
2022-11-18 03:18:54,577 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8172341896729036, 'Total loss': 0.8172341896729036} | train loss {'Reaction outcome loss': 0.8168107316859307, 'Total loss': 0.8168107316859307}
2022-11-18 03:18:54,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:54,577 INFO:     Epoch: 95
2022-11-18 03:18:55,362 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8314669633453543, 'Total loss': 0.8314669633453543} | train loss {'Reaction outcome loss': 0.8184675522629292, 'Total loss': 0.8184675522629292}
2022-11-18 03:18:55,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:55,363 INFO:     Epoch: 96
2022-11-18 03:18:56,148 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8277353326028044, 'Total loss': 0.8277353326028044} | train loss {'Reaction outcome loss': 0.8163453731085023, 'Total loss': 0.8163453731085023}
2022-11-18 03:18:56,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:56,148 INFO:     Epoch: 97
2022-11-18 03:18:56,938 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8424723832444712, 'Total loss': 0.8424723832444712} | train loss {'Reaction outcome loss': 0.8172471531696858, 'Total loss': 0.8172471531696858}
2022-11-18 03:18:56,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:56,938 INFO:     Epoch: 98
2022-11-18 03:18:57,718 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8204757611859929, 'Total loss': 0.8204757611859929} | train loss {'Reaction outcome loss': 0.8233735364290976, 'Total loss': 0.8233735364290976}
2022-11-18 03:18:57,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:57,718 INFO:     Epoch: 99
2022-11-18 03:18:58,463 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.829660177230835, 'Total loss': 0.829660177230835} | train loss {'Reaction outcome loss': 0.8175214480969214, 'Total loss': 0.8175214480969214}
2022-11-18 03:18:58,463 INFO:     Best model found after epoch 74 of 100.
2022-11-18 03:18:58,463 INFO:   Done with stage: TRAINING
2022-11-18 03:18:58,463 INFO:   Starting stage: EVALUATION
2022-11-18 03:18:58,582 INFO:   Done with stage: EVALUATION
2022-11-18 03:18:58,582 INFO:   Leaving out SEQ value Fold_8
2022-11-18 03:18:58,597 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 03:18:58,597 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:18:59,260 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:18:59,260 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:18:59,329 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:18:59,329 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:18:59,329 INFO:     No hyperparam tuning for this model
2022-11-18 03:18:59,329 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:18:59,329 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:18:59,330 INFO:     None feature selector for col prot
2022-11-18 03:18:59,330 INFO:     None feature selector for col prot
2022-11-18 03:18:59,330 INFO:     None feature selector for col prot
2022-11-18 03:18:59,331 INFO:     None feature selector for col chem
2022-11-18 03:18:59,331 INFO:     None feature selector for col chem
2022-11-18 03:18:59,331 INFO:     None feature selector for col chem
2022-11-18 03:18:59,331 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:18:59,331 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:18:59,332 INFO:     Number of params in model 168571
2022-11-18 03:18:59,336 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:18:59,336 INFO:   Starting stage: TRAINING
2022-11-18 03:18:59,394 INFO:     Val loss before train {'Reaction outcome loss': 1.007643077861179, 'Total loss': 1.007643077861179}
2022-11-18 03:18:59,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:18:59,394 INFO:     Epoch: 0
2022-11-18 03:19:00,191 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8531454449350183, 'Total loss': 0.8531454449350183} | train loss {'Reaction outcome loss': 0.8750241488826518, 'Total loss': 0.8750241488826518}
2022-11-18 03:19:00,192 INFO:     Found new best model at epoch 0
2022-11-18 03:19:00,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:00,193 INFO:     Epoch: 1
2022-11-18 03:19:00,989 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8394169042056258, 'Total loss': 0.8394169042056258} | train loss {'Reaction outcome loss': 0.8517174492076952, 'Total loss': 0.8517174492076952}
2022-11-18 03:19:00,989 INFO:     Found new best model at epoch 1
2022-11-18 03:19:00,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:00,990 INFO:     Epoch: 2
2022-11-18 03:19:01,776 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8549536690115929, 'Total loss': 0.8549536690115929} | train loss {'Reaction outcome loss': 0.8386513911947913, 'Total loss': 0.8386513911947913}
2022-11-18 03:19:01,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:01,776 INFO:     Epoch: 3
2022-11-18 03:19:02,558 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8598512627861716, 'Total loss': 0.8598512627861716} | train loss {'Reaction outcome loss': 0.8358620667944149, 'Total loss': 0.8358620667944149}
2022-11-18 03:19:02,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:02,559 INFO:     Epoch: 4
2022-11-18 03:19:03,324 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.852307375181805, 'Total loss': 0.852307375181805} | train loss {'Reaction outcome loss': 0.8320939919170068, 'Total loss': 0.8320939919170068}
2022-11-18 03:19:03,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:03,325 INFO:     Epoch: 5
2022-11-18 03:19:04,083 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.840704621239142, 'Total loss': 0.840704621239142} | train loss {'Reaction outcome loss': 0.8276415894226152, 'Total loss': 0.8276415894226152}
2022-11-18 03:19:04,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:04,083 INFO:     Epoch: 6
2022-11-18 03:19:04,857 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8204884678125381, 'Total loss': 0.8204884678125381} | train loss {'Reaction outcome loss': 0.8269010613159258, 'Total loss': 0.8269010613159258}
2022-11-18 03:19:04,857 INFO:     Found new best model at epoch 6
2022-11-18 03:19:04,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:04,858 INFO:     Epoch: 7
2022-11-18 03:19:05,622 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.844483959403905, 'Total loss': 0.844483959403905} | train loss {'Reaction outcome loss': 0.822631765993274, 'Total loss': 0.822631765993274}
2022-11-18 03:19:05,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:05,622 INFO:     Epoch: 8
2022-11-18 03:19:06,401 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8735383667729117, 'Total loss': 0.8735383667729117} | train loss {'Reaction outcome loss': 0.8240731502065853, 'Total loss': 0.8240731502065853}
2022-11-18 03:19:06,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:06,401 INFO:     Epoch: 9
2022-11-18 03:19:07,169 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8178826963359659, 'Total loss': 0.8178826963359659} | train loss {'Reaction outcome loss': 0.8230804395918944, 'Total loss': 0.8230804395918944}
2022-11-18 03:19:07,170 INFO:     Found new best model at epoch 9
2022-11-18 03:19:07,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:07,171 INFO:     Epoch: 10
2022-11-18 03:19:07,944 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8243659091266718, 'Total loss': 0.8243659091266718} | train loss {'Reaction outcome loss': 0.8222934325738829, 'Total loss': 0.8222934325738829}
2022-11-18 03:19:07,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:07,945 INFO:     Epoch: 11
2022-11-18 03:19:08,735 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8209580210122195, 'Total loss': 0.8209580210122195} | train loss {'Reaction outcome loss': 0.8210087779833346, 'Total loss': 0.8210087779833346}
2022-11-18 03:19:08,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:08,735 INFO:     Epoch: 12
2022-11-18 03:19:09,521 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8461128093979575, 'Total loss': 0.8461128093979575} | train loss {'Reaction outcome loss': 0.8184339379777714, 'Total loss': 0.8184339379777714}
2022-11-18 03:19:09,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:09,521 INFO:     Epoch: 13
2022-11-18 03:19:10,296 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8759238306771625, 'Total loss': 0.8759238306771625} | train loss {'Reaction outcome loss': 0.8220105075106329, 'Total loss': 0.8220105075106329}
2022-11-18 03:19:10,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:10,296 INFO:     Epoch: 14
2022-11-18 03:19:11,063 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8259875964034687, 'Total loss': 0.8259875964034687} | train loss {'Reaction outcome loss': 0.8178648303966133, 'Total loss': 0.8178648303966133}
2022-11-18 03:19:11,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:11,063 INFO:     Epoch: 15
2022-11-18 03:19:11,862 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8418879766355861, 'Total loss': 0.8418879766355861} | train loss {'Reaction outcome loss': 0.8231306503013689, 'Total loss': 0.8231306503013689}
2022-11-18 03:19:11,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:11,862 INFO:     Epoch: 16
2022-11-18 03:19:12,636 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.839651722799648, 'Total loss': 0.839651722799648} | train loss {'Reaction outcome loss': 0.8195589508329119, 'Total loss': 0.8195589508329119}
2022-11-18 03:19:12,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:12,637 INFO:     Epoch: 17
2022-11-18 03:19:13,394 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8383956212889064, 'Total loss': 0.8383956212889064} | train loss {'Reaction outcome loss': 0.8194663016163573, 'Total loss': 0.8194663016163573}
2022-11-18 03:19:13,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:13,394 INFO:     Epoch: 18
2022-11-18 03:19:14,175 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8250425295396284, 'Total loss': 0.8250425295396284} | train loss {'Reaction outcome loss': 0.8198965956970137, 'Total loss': 0.8198965956970137}
2022-11-18 03:19:14,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:14,175 INFO:     Epoch: 19
2022-11-18 03:19:14,938 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8226063305681403, 'Total loss': 0.8226063305681403} | train loss {'Reaction outcome loss': 0.8189497838214952, 'Total loss': 0.8189497838214952}
2022-11-18 03:19:14,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:14,938 INFO:     Epoch: 20
2022-11-18 03:19:15,691 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8140643442218954, 'Total loss': 0.8140643442218954} | train loss {'Reaction outcome loss': 0.8164094168312696, 'Total loss': 0.8164094168312696}
2022-11-18 03:19:15,692 INFO:     Found new best model at epoch 20
2022-11-18 03:19:15,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:15,693 INFO:     Epoch: 21
2022-11-18 03:19:16,439 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8368927579034459, 'Total loss': 0.8368927579034459} | train loss {'Reaction outcome loss': 0.8163241588339514, 'Total loss': 0.8163241588339514}
2022-11-18 03:19:16,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:16,439 INFO:     Epoch: 22
2022-11-18 03:19:17,203 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8185377540913495, 'Total loss': 0.8185377540913495} | train loss {'Reaction outcome loss': 0.8209962518847719, 'Total loss': 0.8209962518847719}
2022-11-18 03:19:17,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:17,204 INFO:     Epoch: 23
2022-11-18 03:19:17,951 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8614487756382335, 'Total loss': 0.8614487756382335} | train loss {'Reaction outcome loss': 0.81692513069328, 'Total loss': 0.81692513069328}
2022-11-18 03:19:17,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:17,951 INFO:     Epoch: 24
2022-11-18 03:19:18,737 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8376628742976622, 'Total loss': 0.8376628742976622} | train loss {'Reaction outcome loss': 0.8122591225468383, 'Total loss': 0.8122591225468383}
2022-11-18 03:19:18,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:18,738 INFO:     Epoch: 25
2022-11-18 03:19:19,526 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8114633695645765, 'Total loss': 0.8114633695645765} | train loss {'Reaction outcome loss': 0.8191635776539238, 'Total loss': 0.8191635776539238}
2022-11-18 03:19:19,526 INFO:     Found new best model at epoch 25
2022-11-18 03:19:19,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:19,527 INFO:     Epoch: 26
2022-11-18 03:19:20,294 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8263764821670272, 'Total loss': 0.8263764821670272} | train loss {'Reaction outcome loss': 0.81861287014825, 'Total loss': 0.81861287014825}
2022-11-18 03:19:20,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:20,295 INFO:     Epoch: 27
2022-11-18 03:19:21,075 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8303526856682517, 'Total loss': 0.8303526856682517} | train loss {'Reaction outcome loss': 0.8172531126713266, 'Total loss': 0.8172531126713266}
2022-11-18 03:19:21,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:21,075 INFO:     Epoch: 28
2022-11-18 03:19:21,862 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8392338725653562, 'Total loss': 0.8392338725653562} | train loss {'Reaction outcome loss': 0.8209814463951149, 'Total loss': 0.8209814463951149}
2022-11-18 03:19:21,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:21,862 INFO:     Epoch: 29
2022-11-18 03:19:22,627 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8050080713900652, 'Total loss': 0.8050080713900652} | train loss {'Reaction outcome loss': 0.8182801605487356, 'Total loss': 0.8182801605487356}
2022-11-18 03:19:22,627 INFO:     Found new best model at epoch 29
2022-11-18 03:19:22,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:22,628 INFO:     Epoch: 30
2022-11-18 03:19:23,394 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8568816510113803, 'Total loss': 0.8568816510113803} | train loss {'Reaction outcome loss': 0.8171451776611561, 'Total loss': 0.8171451776611561}
2022-11-18 03:19:23,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:23,394 INFO:     Epoch: 31
2022-11-18 03:19:24,200 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8119485527276993, 'Total loss': 0.8119485527276993} | train loss {'Reaction outcome loss': 0.8174074722796071, 'Total loss': 0.8174074722796071}
2022-11-18 03:19:24,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:24,200 INFO:     Epoch: 32
2022-11-18 03:19:24,948 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8127640350298448, 'Total loss': 0.8127640350298448} | train loss {'Reaction outcome loss': 0.8154107091378192, 'Total loss': 0.8154107091378192}
2022-11-18 03:19:24,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:24,950 INFO:     Epoch: 33
2022-11-18 03:19:25,727 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8562303368340839, 'Total loss': 0.8562303368340839} | train loss {'Reaction outcome loss': 0.8179505299548714, 'Total loss': 0.8179505299548714}
2022-11-18 03:19:25,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:25,728 INFO:     Epoch: 34
2022-11-18 03:19:26,538 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8333283676342531, 'Total loss': 0.8333283676342531} | train loss {'Reaction outcome loss': 0.8209508921418871, 'Total loss': 0.8209508921418871}
2022-11-18 03:19:26,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:26,538 INFO:     Epoch: 35
2022-11-18 03:19:27,342 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8293145407329906, 'Total loss': 0.8293145407329906} | train loss {'Reaction outcome loss': 0.8177566236379196, 'Total loss': 0.8177566236379196}
2022-11-18 03:19:27,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:27,342 INFO:     Epoch: 36
2022-11-18 03:19:28,156 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8112353614785455, 'Total loss': 0.8112353614785455} | train loss {'Reaction outcome loss': 0.8170015046791155, 'Total loss': 0.8170015046791155}
2022-11-18 03:19:28,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:28,156 INFO:     Epoch: 37
2022-11-18 03:19:28,926 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8108974911949851, 'Total loss': 0.8108974911949851} | train loss {'Reaction outcome loss': 0.8135247829009076, 'Total loss': 0.8135247829009076}
2022-11-18 03:19:28,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:28,926 INFO:     Epoch: 38
2022-11-18 03:19:29,702 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8313726904717359, 'Total loss': 0.8313726904717359} | train loss {'Reaction outcome loss': 0.8231178707006026, 'Total loss': 0.8231178707006026}
2022-11-18 03:19:29,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:29,702 INFO:     Epoch: 39
2022-11-18 03:19:30,497 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8308867236429994, 'Total loss': 0.8308867236429994} | train loss {'Reaction outcome loss': 0.8164907521131087, 'Total loss': 0.8164907521131087}
2022-11-18 03:19:30,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:30,498 INFO:     Epoch: 40
2022-11-18 03:19:31,288 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8285542482679541, 'Total loss': 0.8285542482679541} | train loss {'Reaction outcome loss': 0.8182684217180525, 'Total loss': 0.8182684217180525}
2022-11-18 03:19:31,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:31,289 INFO:     Epoch: 41
2022-11-18 03:19:32,168 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8304481113498862, 'Total loss': 0.8304481113498862} | train loss {'Reaction outcome loss': 0.8129640942933608, 'Total loss': 0.8129640942933608}
2022-11-18 03:19:32,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:32,169 INFO:     Epoch: 42
2022-11-18 03:19:32,993 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.815219867635857, 'Total loss': 0.815219867635857} | train loss {'Reaction outcome loss': 0.8185045760505053, 'Total loss': 0.8185045760505053}
2022-11-18 03:19:32,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:32,993 INFO:     Epoch: 43
2022-11-18 03:19:33,844 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8094998733563856, 'Total loss': 0.8094998733563856} | train loss {'Reaction outcome loss': 0.8237406349911982, 'Total loss': 0.8237406349911982}
2022-11-18 03:19:33,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:33,845 INFO:     Epoch: 44
2022-11-18 03:19:34,632 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8265866562724113, 'Total loss': 0.8265866562724113} | train loss {'Reaction outcome loss': 0.8165622754972808, 'Total loss': 0.8165622754972808}
2022-11-18 03:19:34,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:34,632 INFO:     Epoch: 45
2022-11-18 03:19:35,471 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8507210354913365, 'Total loss': 0.8507210354913365} | train loss {'Reaction outcome loss': 0.8141147490666837, 'Total loss': 0.8141147490666837}
2022-11-18 03:19:35,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:35,471 INFO:     Epoch: 46
2022-11-18 03:19:36,291 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8361792699857191, 'Total loss': 0.8361792699857191} | train loss {'Reaction outcome loss': 0.8167194979531425, 'Total loss': 0.8167194979531425}
2022-11-18 03:19:36,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:36,291 INFO:     Epoch: 47
2022-11-18 03:19:37,086 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8426124873486432, 'Total loss': 0.8426124873486432} | train loss {'Reaction outcome loss': 0.8202789693462605, 'Total loss': 0.8202789693462605}
2022-11-18 03:19:37,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:37,086 INFO:     Epoch: 48
2022-11-18 03:19:37,893 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8445164073597301, 'Total loss': 0.8445164073597301} | train loss {'Reaction outcome loss': 0.8166163547914855, 'Total loss': 0.8166163547914855}
2022-11-18 03:19:37,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:37,893 INFO:     Epoch: 49
2022-11-18 03:19:38,667 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.848175594752485, 'Total loss': 0.848175594752485} | train loss {'Reaction outcome loss': 0.8161393689865969, 'Total loss': 0.8161393689865969}
2022-11-18 03:19:38,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:38,668 INFO:     Epoch: 50
2022-11-18 03:19:39,444 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8242684169249102, 'Total loss': 0.8242684169249102} | train loss {'Reaction outcome loss': 0.8184407211079889, 'Total loss': 0.8184407211079889}
2022-11-18 03:19:39,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:39,445 INFO:     Epoch: 51
2022-11-18 03:19:40,233 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8159012957052751, 'Total loss': 0.8159012957052751} | train loss {'Reaction outcome loss': 0.8172022845063891, 'Total loss': 0.8172022845063891}
2022-11-18 03:19:40,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:40,233 INFO:     Epoch: 52
2022-11-18 03:19:40,979 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8144488835876639, 'Total loss': 0.8144488835876639} | train loss {'Reaction outcome loss': 0.813062755550657, 'Total loss': 0.813062755550657}
2022-11-18 03:19:40,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:40,979 INFO:     Epoch: 53
2022-11-18 03:19:41,783 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.812021751972762, 'Total loss': 0.812021751972762} | train loss {'Reaction outcome loss': 0.8133445755559571, 'Total loss': 0.8133445755559571}
2022-11-18 03:19:41,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:41,783 INFO:     Epoch: 54
2022-11-18 03:19:42,612 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.819691002368927, 'Total loss': 0.819691002368927} | train loss {'Reaction outcome loss': 0.8163618328619976, 'Total loss': 0.8163618328619976}
2022-11-18 03:19:42,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:42,612 INFO:     Epoch: 55
2022-11-18 03:19:43,419 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.825208183716644, 'Total loss': 0.825208183716644} | train loss {'Reaction outcome loss': 0.815789602605664, 'Total loss': 0.815789602605664}
2022-11-18 03:19:43,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:43,420 INFO:     Epoch: 56
2022-11-18 03:19:44,260 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8102106323296373, 'Total loss': 0.8102106323296373} | train loss {'Reaction outcome loss': 0.8150000189031873, 'Total loss': 0.8150000189031873}
2022-11-18 03:19:44,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:44,260 INFO:     Epoch: 57
2022-11-18 03:19:45,089 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8234357332641428, 'Total loss': 0.8234357332641428} | train loss {'Reaction outcome loss': 0.8194225975445338, 'Total loss': 0.8194225975445338}
2022-11-18 03:19:45,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:45,089 INFO:     Epoch: 58
2022-11-18 03:19:45,883 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8284949907525019, 'Total loss': 0.8284949907525019} | train loss {'Reaction outcome loss': 0.8142242593424661, 'Total loss': 0.8142242593424661}
2022-11-18 03:19:45,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:45,883 INFO:     Epoch: 59
2022-11-18 03:19:46,644 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8424451256340201, 'Total loss': 0.8424451256340201} | train loss {'Reaction outcome loss': 0.8159260209725827, 'Total loss': 0.8159260209725827}
2022-11-18 03:19:46,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:46,644 INFO:     Epoch: 60
2022-11-18 03:19:47,443 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8309121890501543, 'Total loss': 0.8309121890501543} | train loss {'Reaction outcome loss': 0.8171031729299195, 'Total loss': 0.8171031729299195}
2022-11-18 03:19:47,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:47,443 INFO:     Epoch: 61
2022-11-18 03:19:48,249 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8244226490232077, 'Total loss': 0.8244226490232077} | train loss {'Reaction outcome loss': 0.8113108388015202, 'Total loss': 0.8113108388015202}
2022-11-18 03:19:48,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:48,249 INFO:     Epoch: 62
2022-11-18 03:19:49,027 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8394617025147785, 'Total loss': 0.8394617025147785} | train loss {'Reaction outcome loss': 0.814154998623595, 'Total loss': 0.814154998623595}
2022-11-18 03:19:49,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:49,027 INFO:     Epoch: 63
2022-11-18 03:19:49,859 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8316056403246793, 'Total loss': 0.8316056403246793} | train loss {'Reaction outcome loss': 0.8198073923587799, 'Total loss': 0.8198073923587799}
2022-11-18 03:19:49,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:49,860 INFO:     Epoch: 64
2022-11-18 03:19:50,615 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8325729024681178, 'Total loss': 0.8325729024681178} | train loss {'Reaction outcome loss': 0.8196230816597841, 'Total loss': 0.8196230816597841}
2022-11-18 03:19:50,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:50,615 INFO:     Epoch: 65
2022-11-18 03:19:51,454 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8580556708303365, 'Total loss': 0.8580556708303365} | train loss {'Reaction outcome loss': 0.8190923507116279, 'Total loss': 0.8190923507116279}
2022-11-18 03:19:51,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:51,455 INFO:     Epoch: 66
2022-11-18 03:19:52,271 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8391406786712733, 'Total loss': 0.8391406786712733} | train loss {'Reaction outcome loss': 0.8175835403860832, 'Total loss': 0.8175835403860832}
2022-11-18 03:19:52,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:52,271 INFO:     Epoch: 67
2022-11-18 03:19:53,076 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8234226994893767, 'Total loss': 0.8234226994893767} | train loss {'Reaction outcome loss': 0.8165701596104369, 'Total loss': 0.8165701596104369}
2022-11-18 03:19:53,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:53,076 INFO:     Epoch: 68
2022-11-18 03:19:53,915 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8263186555017125, 'Total loss': 0.8263186555017125} | train loss {'Reaction outcome loss': 0.8174621065052188, 'Total loss': 0.8174621065052188}
2022-11-18 03:19:53,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:53,915 INFO:     Epoch: 69
2022-11-18 03:19:54,721 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.804628842256286, 'Total loss': 0.804628842256286} | train loss {'Reaction outcome loss': 0.8156647099524128, 'Total loss': 0.8156647099524128}
2022-11-18 03:19:54,721 INFO:     Found new best model at epoch 69
2022-11-18 03:19:54,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:54,722 INFO:     Epoch: 70
2022-11-18 03:19:55,529 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8272034857760776, 'Total loss': 0.8272034857760776} | train loss {'Reaction outcome loss': 0.8166521354597442, 'Total loss': 0.8166521354597442}
2022-11-18 03:19:55,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:55,530 INFO:     Epoch: 71
2022-11-18 03:19:56,366 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8183968040076169, 'Total loss': 0.8183968040076169} | train loss {'Reaction outcome loss': 0.8149604371615818, 'Total loss': 0.8149604371615818}
2022-11-18 03:19:56,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:56,368 INFO:     Epoch: 72
2022-11-18 03:19:57,214 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8414070599458434, 'Total loss': 0.8414070599458434} | train loss {'Reaction outcome loss': 0.8173468719939796, 'Total loss': 0.8173468719939796}
2022-11-18 03:19:57,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:57,214 INFO:     Epoch: 73
2022-11-18 03:19:58,039 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8665807924487374, 'Total loss': 0.8665807924487374} | train loss {'Reaction outcome loss': 0.8204644175816556, 'Total loss': 0.8204644175816556}
2022-11-18 03:19:58,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:58,039 INFO:     Epoch: 74
2022-11-18 03:19:58,810 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8739695941860025, 'Total loss': 0.8739695941860025} | train loss {'Reaction outcome loss': 0.8181974760123661, 'Total loss': 0.8181974760123661}
2022-11-18 03:19:58,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:58,810 INFO:     Epoch: 75
2022-11-18 03:19:59,620 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8257175236940384, 'Total loss': 0.8257175236940384} | train loss {'Reaction outcome loss': 0.8157797533638623, 'Total loss': 0.8157797533638623}
2022-11-18 03:19:59,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:19:59,620 INFO:     Epoch: 76
2022-11-18 03:20:00,394 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8411472168835726, 'Total loss': 0.8411472168835726} | train loss {'Reaction outcome loss': 0.8092186585981018, 'Total loss': 0.8092186585981018}
2022-11-18 03:20:00,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:00,394 INFO:     Epoch: 77
2022-11-18 03:20:01,229 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8430367030880668, 'Total loss': 0.8430367030880668} | train loss {'Reaction outcome loss': 0.8146255654948098, 'Total loss': 0.8146255654948098}
2022-11-18 03:20:01,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:01,229 INFO:     Epoch: 78
2022-11-18 03:20:02,023 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8911497918042269, 'Total loss': 0.8911497918042269} | train loss {'Reaction outcome loss': 0.8111790727595893, 'Total loss': 0.8111790727595893}
2022-11-18 03:20:02,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:02,023 INFO:     Epoch: 79
2022-11-18 03:20:02,793 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8154586228457364, 'Total loss': 0.8154586228457364} | train loss {'Reaction outcome loss': 0.8186636035539666, 'Total loss': 0.8186636035539666}
2022-11-18 03:20:02,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:02,794 INFO:     Epoch: 80
2022-11-18 03:20:03,602 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8112338009205732, 'Total loss': 0.8112338009205732} | train loss {'Reaction outcome loss': 0.8139736892009268, 'Total loss': 0.8139736892009268}
2022-11-18 03:20:03,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:03,602 INFO:     Epoch: 81
2022-11-18 03:20:04,385 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8309537050398913, 'Total loss': 0.8309537050398913} | train loss {'Reaction outcome loss': 0.813158158258516, 'Total loss': 0.813158158258516}
2022-11-18 03:20:04,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:04,385 INFO:     Epoch: 82
2022-11-18 03:20:05,180 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.82789142226631, 'Total loss': 0.82789142226631} | train loss {'Reaction outcome loss': 0.8130723122431307, 'Total loss': 0.8130723122431307}
2022-11-18 03:20:05,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:05,180 INFO:     Epoch: 83
2022-11-18 03:20:05,987 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8282085494561628, 'Total loss': 0.8282085494561628} | train loss {'Reaction outcome loss': 0.8148473559593667, 'Total loss': 0.8148473559593667}
2022-11-18 03:20:05,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:05,987 INFO:     Epoch: 84
2022-11-18 03:20:06,787 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8403881503777071, 'Total loss': 0.8403881503777071} | train loss {'Reaction outcome loss': 0.818275349359123, 'Total loss': 0.818275349359123}
2022-11-18 03:20:06,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:06,787 INFO:     Epoch: 85
2022-11-18 03:20:07,563 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8304311457005414, 'Total loss': 0.8304311457005414} | train loss {'Reaction outcome loss': 0.8137381796325956, 'Total loss': 0.8137381796325956}
2022-11-18 03:20:07,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:07,564 INFO:     Epoch: 86
2022-11-18 03:20:08,346 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8279441540891473, 'Total loss': 0.8279441540891473} | train loss {'Reaction outcome loss': 0.8132932762710415, 'Total loss': 0.8132932762710415}
2022-11-18 03:20:08,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:08,346 INFO:     Epoch: 87
2022-11-18 03:20:09,151 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8273719928481362, 'Total loss': 0.8273719928481362} | train loss {'Reaction outcome loss': 0.8157914768676369, 'Total loss': 0.8157914768676369}
2022-11-18 03:20:09,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:09,151 INFO:     Epoch: 88
2022-11-18 03:20:09,907 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8473326787352562, 'Total loss': 0.8473326787352562} | train loss {'Reaction outcome loss': 0.8160961609713885, 'Total loss': 0.8160961609713885}
2022-11-18 03:20:09,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:09,908 INFO:     Epoch: 89
2022-11-18 03:20:10,675 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.815452325750481, 'Total loss': 0.815452325750481} | train loss {'Reaction outcome loss': 0.8145578627683678, 'Total loss': 0.8145578627683678}
2022-11-18 03:20:10,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:10,675 INFO:     Epoch: 90
2022-11-18 03:20:11,445 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8285289623520591, 'Total loss': 0.8285289623520591} | train loss {'Reaction outcome loss': 0.8171570001816263, 'Total loss': 0.8171570001816263}
2022-11-18 03:20:11,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:11,445 INFO:     Epoch: 91
2022-11-18 03:20:12,228 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8650847896933556, 'Total loss': 0.8650847896933556} | train loss {'Reaction outcome loss': 0.8111827570564892, 'Total loss': 0.8111827570564892}
2022-11-18 03:20:12,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:12,229 INFO:     Epoch: 92
2022-11-18 03:20:13,058 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.810421615161679, 'Total loss': 0.810421615161679} | train loss {'Reaction outcome loss': 0.8135942258396928, 'Total loss': 0.8135942258396928}
2022-11-18 03:20:13,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:13,058 INFO:     Epoch: 93
2022-11-18 03:20:13,828 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8571782396598295, 'Total loss': 0.8571782396598295} | train loss {'Reaction outcome loss': 0.8148371188008056, 'Total loss': 0.8148371188008056}
2022-11-18 03:20:13,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:13,828 INFO:     Epoch: 94
2022-11-18 03:20:14,647 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8281799500638788, 'Total loss': 0.8281799500638788} | train loss {'Reaction outcome loss': 0.8142810359293101, 'Total loss': 0.8142810359293101}
2022-11-18 03:20:14,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:14,647 INFO:     Epoch: 95
2022-11-18 03:20:15,407 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8390826704827222, 'Total loss': 0.8390826704827222} | train loss {'Reaction outcome loss': 0.8113667922360557, 'Total loss': 0.8113667922360557}
2022-11-18 03:20:15,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:15,409 INFO:     Epoch: 96
2022-11-18 03:20:16,239 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8294127732515335, 'Total loss': 0.8294127732515335} | train loss {'Reaction outcome loss': 0.8140434110651211, 'Total loss': 0.8140434110651211}
2022-11-18 03:20:16,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:16,239 INFO:     Epoch: 97
2022-11-18 03:20:17,055 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.813778588717634, 'Total loss': 0.813778588717634} | train loss {'Reaction outcome loss': 0.808342383224137, 'Total loss': 0.808342383224137}
2022-11-18 03:20:17,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:17,056 INFO:     Epoch: 98
2022-11-18 03:20:17,845 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8819639560851184, 'Total loss': 0.8819639560851184} | train loss {'Reaction outcome loss': 0.8188071365259132, 'Total loss': 0.8188071365259132}
2022-11-18 03:20:17,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:17,846 INFO:     Epoch: 99
2022-11-18 03:20:18,689 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8208981420506131, 'Total loss': 0.8208981420506131} | train loss {'Reaction outcome loss': 0.8115752508445662, 'Total loss': 0.8115752508445662}
2022-11-18 03:20:18,689 INFO:     Best model found after epoch 70 of 100.
2022-11-18 03:20:18,689 INFO:   Done with stage: TRAINING
2022-11-18 03:20:18,690 INFO:   Starting stage: EVALUATION
2022-11-18 03:20:18,818 INFO:   Done with stage: EVALUATION
2022-11-18 03:20:18,818 INFO:   Leaving out SEQ value Fold_9
2022-11-18 03:20:18,831 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:20:18,831 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:20:19,506 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:20:19,506 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:20:19,576 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:20:19,576 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:20:19,576 INFO:     No hyperparam tuning for this model
2022-11-18 03:20:19,576 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:20:19,576 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:20:19,577 INFO:     None feature selector for col prot
2022-11-18 03:20:19,577 INFO:     None feature selector for col prot
2022-11-18 03:20:19,577 INFO:     None feature selector for col prot
2022-11-18 03:20:19,578 INFO:     None feature selector for col chem
2022-11-18 03:20:19,578 INFO:     None feature selector for col chem
2022-11-18 03:20:19,578 INFO:     None feature selector for col chem
2022-11-18 03:20:19,578 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:20:19,578 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:20:19,580 INFO:     Number of params in model 168571
2022-11-18 03:20:19,583 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:20:19,583 INFO:   Starting stage: TRAINING
2022-11-18 03:20:19,641 INFO:     Val loss before train {'Reaction outcome loss': 1.0172820714387028, 'Total loss': 1.0172820714387028}
2022-11-18 03:20:19,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:19,641 INFO:     Epoch: 0
2022-11-18 03:20:20,473 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8999897228045897, 'Total loss': 0.8999897228045897} | train loss {'Reaction outcome loss': 0.8732984940774045, 'Total loss': 0.8732984940774045}
2022-11-18 03:20:20,474 INFO:     Found new best model at epoch 0
2022-11-18 03:20:20,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:20,474 INFO:     Epoch: 1
2022-11-18 03:20:21,231 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8711794425140728, 'Total loss': 0.8711794425140728} | train loss {'Reaction outcome loss': 0.8473962302270689, 'Total loss': 0.8473962302270689}
2022-11-18 03:20:21,232 INFO:     Found new best model at epoch 1
2022-11-18 03:20:21,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:21,232 INFO:     Epoch: 2
2022-11-18 03:20:22,035 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8555328378623183, 'Total loss': 0.8555328378623183} | train loss {'Reaction outcome loss': 0.8419912272860647, 'Total loss': 0.8419912272860647}
2022-11-18 03:20:22,035 INFO:     Found new best model at epoch 2
2022-11-18 03:20:22,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:22,036 INFO:     Epoch: 3
2022-11-18 03:20:22,844 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8665918342091821, 'Total loss': 0.8665918342091821} | train loss {'Reaction outcome loss': 0.8304522111106981, 'Total loss': 0.8304522111106981}
2022-11-18 03:20:22,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:22,845 INFO:     Epoch: 4
2022-11-18 03:20:23,670 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8691645203666254, 'Total loss': 0.8691645203666254} | train loss {'Reaction outcome loss': 0.8286865956870167, 'Total loss': 0.8286865956870167}
2022-11-18 03:20:23,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:23,671 INFO:     Epoch: 5
2022-11-18 03:20:24,486 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.842241258783774, 'Total loss': 0.842241258783774} | train loss {'Reaction outcome loss': 0.8248958187064661, 'Total loss': 0.8248958187064661}
2022-11-18 03:20:24,486 INFO:     Found new best model at epoch 5
2022-11-18 03:20:24,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:24,487 INFO:     Epoch: 6
2022-11-18 03:20:25,335 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9072038944471966, 'Total loss': 0.9072038944471966} | train loss {'Reaction outcome loss': 0.8190280960397682, 'Total loss': 0.8190280960397682}
2022-11-18 03:20:25,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:25,336 INFO:     Epoch: 7
2022-11-18 03:20:26,129 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8521061187440698, 'Total loss': 0.8521061187440698} | train loss {'Reaction outcome loss': 0.8153757402288769, 'Total loss': 0.8153757402288769}
2022-11-18 03:20:26,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:26,129 INFO:     Epoch: 8
2022-11-18 03:20:26,915 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8487259596586227, 'Total loss': 0.8487259596586227} | train loss {'Reaction outcome loss': 0.8163311719170466, 'Total loss': 0.8163311719170466}
2022-11-18 03:20:26,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:26,917 INFO:     Epoch: 9
2022-11-18 03:20:27,726 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8370844538916241, 'Total loss': 0.8370844538916241} | train loss {'Reaction outcome loss': 0.8203734689757891, 'Total loss': 0.8203734689757891}
2022-11-18 03:20:27,726 INFO:     Found new best model at epoch 9
2022-11-18 03:20:27,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:27,727 INFO:     Epoch: 10
2022-11-18 03:20:28,520 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.850308662111109, 'Total loss': 0.850308662111109} | train loss {'Reaction outcome loss': 0.8193040380352422, 'Total loss': 0.8193040380352422}
2022-11-18 03:20:28,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:28,520 INFO:     Epoch: 11
2022-11-18 03:20:29,297 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8433345014398749, 'Total loss': 0.8433345014398749} | train loss {'Reaction outcome loss': 0.8249816052344164, 'Total loss': 0.8249816052344164}
2022-11-18 03:20:29,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:29,297 INFO:     Epoch: 12
2022-11-18 03:20:30,093 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8463336757638238, 'Total loss': 0.8463336757638238} | train loss {'Reaction outcome loss': 0.8202768122618981, 'Total loss': 0.8202768122618981}
2022-11-18 03:20:30,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:30,093 INFO:     Epoch: 13
2022-11-18 03:20:30,907 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8323404274203561, 'Total loss': 0.8323404274203561} | train loss {'Reaction outcome loss': 0.819001252472642, 'Total loss': 0.819001252472642}
2022-11-18 03:20:30,907 INFO:     Found new best model at epoch 13
2022-11-18 03:20:30,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:30,908 INFO:     Epoch: 14
2022-11-18 03:20:31,687 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8483106378804554, 'Total loss': 0.8483106378804554} | train loss {'Reaction outcome loss': 0.8116128433209199, 'Total loss': 0.8116128433209199}
2022-11-18 03:20:31,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:31,687 INFO:     Epoch: 15
2022-11-18 03:20:32,496 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8465422039682214, 'Total loss': 0.8465422039682214} | train loss {'Reaction outcome loss': 0.8131008203394017, 'Total loss': 0.8131008203394017}
2022-11-18 03:20:32,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:32,496 INFO:     Epoch: 16
2022-11-18 03:20:33,322 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8714726784012534, 'Total loss': 0.8714726784012534} | train loss {'Reaction outcome loss': 0.8202095701385607, 'Total loss': 0.8202095701385607}
2022-11-18 03:20:33,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:33,323 INFO:     Epoch: 17
2022-11-18 03:20:34,102 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8420574570244009, 'Total loss': 0.8420574570244009} | train loss {'Reaction outcome loss': 0.8175872277151718, 'Total loss': 0.8175872277151718}
2022-11-18 03:20:34,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:34,102 INFO:     Epoch: 18
2022-11-18 03:20:34,924 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8407943086190657, 'Total loss': 0.8407943086190657} | train loss {'Reaction outcome loss': 0.8119288212977923, 'Total loss': 0.8119288212977923}
2022-11-18 03:20:34,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:34,925 INFO:     Epoch: 19
2022-11-18 03:20:35,719 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8304503661665049, 'Total loss': 0.8304503661665049} | train loss {'Reaction outcome loss': 0.8169624780112432, 'Total loss': 0.8169624780112432}
2022-11-18 03:20:35,719 INFO:     Found new best model at epoch 19
2022-11-18 03:20:35,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:35,720 INFO:     Epoch: 20
2022-11-18 03:20:36,484 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8404879962856119, 'Total loss': 0.8404879962856119} | train loss {'Reaction outcome loss': 0.8147118303939881, 'Total loss': 0.8147118303939881}
2022-11-18 03:20:36,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:36,484 INFO:     Epoch: 21
2022-11-18 03:20:37,283 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8484210385517641, 'Total loss': 0.8484210385517641} | train loss {'Reaction outcome loss': 0.8165892200913989, 'Total loss': 0.8165892200913989}
2022-11-18 03:20:37,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:37,284 INFO:     Epoch: 22
2022-11-18 03:20:38,088 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8423874818465926, 'Total loss': 0.8423874818465926} | train loss {'Reaction outcome loss': 0.8180512090926229, 'Total loss': 0.8180512090926229}
2022-11-18 03:20:38,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:38,088 INFO:     Epoch: 23
2022-11-18 03:20:38,921 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8613581786101515, 'Total loss': 0.8613581786101515} | train loss {'Reaction outcome loss': 0.8117545668171485, 'Total loss': 0.8117545668171485}
2022-11-18 03:20:38,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:38,921 INFO:     Epoch: 24
2022-11-18 03:20:39,715 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8496925370259718, 'Total loss': 0.8496925370259718} | train loss {'Reaction outcome loss': 0.8211199002951263, 'Total loss': 0.8211199002951263}
2022-11-18 03:20:39,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:39,716 INFO:     Epoch: 25
2022-11-18 03:20:40,524 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8514876189556989, 'Total loss': 0.8514876189556989} | train loss {'Reaction outcome loss': 0.8150021967134977, 'Total loss': 0.8150021967134977}
2022-11-18 03:20:40,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:40,525 INFO:     Epoch: 26
2022-11-18 03:20:41,325 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8310464010997252, 'Total loss': 0.8310464010997252} | train loss {'Reaction outcome loss': 0.8125494966803775, 'Total loss': 0.8125494966803775}
2022-11-18 03:20:41,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:41,325 INFO:     Epoch: 27
2022-11-18 03:20:42,124 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.866345149549571, 'Total loss': 0.866345149549571} | train loss {'Reaction outcome loss': 0.810154394220244, 'Total loss': 0.810154394220244}
2022-11-18 03:20:42,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:42,124 INFO:     Epoch: 28
2022-11-18 03:20:42,900 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8246442289514975, 'Total loss': 0.8246442289514975} | train loss {'Reaction outcome loss': 0.8105591209680747, 'Total loss': 0.8105591209680747}
2022-11-18 03:20:42,900 INFO:     Found new best model at epoch 28
2022-11-18 03:20:42,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:42,901 INFO:     Epoch: 29
2022-11-18 03:20:43,682 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8441109257665548, 'Total loss': 0.8441109257665548} | train loss {'Reaction outcome loss': 0.813025472617825, 'Total loss': 0.813025472617825}
2022-11-18 03:20:43,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:43,683 INFO:     Epoch: 30
2022-11-18 03:20:44,471 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8415529321540486, 'Total loss': 0.8415529321540486} | train loss {'Reaction outcome loss': 0.808463833773667, 'Total loss': 0.808463833773667}
2022-11-18 03:20:44,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:44,472 INFO:     Epoch: 31
2022-11-18 03:20:45,238 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8491104665127668, 'Total loss': 0.8491104665127668} | train loss {'Reaction outcome loss': 0.8164211331832747, 'Total loss': 0.8164211331832747}
2022-11-18 03:20:45,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:45,238 INFO:     Epoch: 32
2022-11-18 03:20:46,005 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8468588665127754, 'Total loss': 0.8468588665127754} | train loss {'Reaction outcome loss': 0.8203054441342711, 'Total loss': 0.8203054441342711}
2022-11-18 03:20:46,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:46,006 INFO:     Epoch: 33
2022-11-18 03:20:46,803 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8421660052104429, 'Total loss': 0.8421660052104429} | train loss {'Reaction outcome loss': 0.8118246367827118, 'Total loss': 0.8118246367827118}
2022-11-18 03:20:46,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:46,803 INFO:     Epoch: 34
2022-11-18 03:20:47,568 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8321103345264088, 'Total loss': 0.8321103345264088} | train loss {'Reaction outcome loss': 0.8111894333410842, 'Total loss': 0.8111894333410842}
2022-11-18 03:20:47,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:47,569 INFO:     Epoch: 35
2022-11-18 03:20:48,343 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8707385279915549, 'Total loss': 0.8707385279915549} | train loss {'Reaction outcome loss': 0.8147492689883661, 'Total loss': 0.8147492689883661}
2022-11-18 03:20:48,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:48,343 INFO:     Epoch: 36
2022-11-18 03:20:49,139 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8375300751491026, 'Total loss': 0.8375300751491026} | train loss {'Reaction outcome loss': 0.815713986814746, 'Total loss': 0.815713986814746}
2022-11-18 03:20:49,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:49,139 INFO:     Epoch: 37
2022-11-18 03:20:49,914 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8347611217336222, 'Total loss': 0.8347611217336222} | train loss {'Reaction outcome loss': 0.8179146145519457, 'Total loss': 0.8179146145519457}
2022-11-18 03:20:49,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:49,915 INFO:     Epoch: 38
2022-11-18 03:20:50,692 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8439224626530301, 'Total loss': 0.8439224626530301} | train loss {'Reaction outcome loss': 0.8088733793390908, 'Total loss': 0.8088733793390908}
2022-11-18 03:20:50,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:50,692 INFO:     Epoch: 39
2022-11-18 03:20:51,448 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8451744521206076, 'Total loss': 0.8451744521206076} | train loss {'Reaction outcome loss': 0.809045774733972, 'Total loss': 0.809045774733972}
2022-11-18 03:20:51,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:51,449 INFO:     Epoch: 40
2022-11-18 03:20:52,257 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8366988192905079, 'Total loss': 0.8366988192905079} | train loss {'Reaction outcome loss': 0.8137788037780808, 'Total loss': 0.8137788037780808}
2022-11-18 03:20:52,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:52,258 INFO:     Epoch: 41
2022-11-18 03:20:53,039 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8420173180374232, 'Total loss': 0.8420173180374232} | train loss {'Reaction outcome loss': 0.8112185757290497, 'Total loss': 0.8112185757290497}
2022-11-18 03:20:53,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:53,039 INFO:     Epoch: 42
2022-11-18 03:20:53,824 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8444037694822658, 'Total loss': 0.8444037694822658} | train loss {'Reaction outcome loss': 0.8114698838729125, 'Total loss': 0.8114698838729125}
2022-11-18 03:20:53,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:53,824 INFO:     Epoch: 43
2022-11-18 03:20:54,615 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8347626328468323, 'Total loss': 0.8347626328468323} | train loss {'Reaction outcome loss': 0.8116340805297559, 'Total loss': 0.8116340805297559}
2022-11-18 03:20:54,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:54,615 INFO:     Epoch: 44
2022-11-18 03:20:55,396 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8530216813087463, 'Total loss': 0.8530216813087463} | train loss {'Reaction outcome loss': 0.8091419480348888, 'Total loss': 0.8091419480348888}
2022-11-18 03:20:55,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:55,396 INFO:     Epoch: 45
2022-11-18 03:20:56,180 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8374089077115059, 'Total loss': 0.8374089077115059} | train loss {'Reaction outcome loss': 0.8158157084152283, 'Total loss': 0.8158157084152283}
2022-11-18 03:20:56,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:56,180 INFO:     Epoch: 46
2022-11-18 03:20:56,958 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8359777399084785, 'Total loss': 0.8359777399084785} | train loss {'Reaction outcome loss': 0.813031639617223, 'Total loss': 0.813031639617223}
2022-11-18 03:20:56,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:56,958 INFO:     Epoch: 47
2022-11-18 03:20:57,729 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8504350957545367, 'Total loss': 0.8504350957545367} | train loss {'Reaction outcome loss': 0.8155887733828201, 'Total loss': 0.8155887733828201}
2022-11-18 03:20:57,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:57,729 INFO:     Epoch: 48
2022-11-18 03:20:58,515 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8819888383150101, 'Total loss': 0.8819888383150101} | train loss {'Reaction outcome loss': 0.8240989245142532, 'Total loss': 0.8240989245142532}
2022-11-18 03:20:58,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:58,517 INFO:     Epoch: 49
2022-11-18 03:20:59,271 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8609000173482028, 'Total loss': 0.8609000173482028} | train loss {'Reaction outcome loss': 0.8137207487334124, 'Total loss': 0.8137207487334124}
2022-11-18 03:20:59,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:20:59,271 INFO:     Epoch: 50
2022-11-18 03:21:00,076 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8456624035130847, 'Total loss': 0.8456624035130847} | train loss {'Reaction outcome loss': 0.8064524667707049, 'Total loss': 0.8064524667707049}
2022-11-18 03:21:00,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:00,077 INFO:     Epoch: 51
2022-11-18 03:21:00,854 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8406066738746383, 'Total loss': 0.8406066738746383} | train loss {'Reaction outcome loss': 0.8100721065844843, 'Total loss': 0.8100721065844843}
2022-11-18 03:21:00,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:00,854 INFO:     Epoch: 52
2022-11-18 03:21:01,626 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8558346723968332, 'Total loss': 0.8558346723968332} | train loss {'Reaction outcome loss': 0.8094678937423567, 'Total loss': 0.8094678937423567}
2022-11-18 03:21:01,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:01,626 INFO:     Epoch: 53
2022-11-18 03:21:02,413 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8527107692577622, 'Total loss': 0.8527107692577622} | train loss {'Reaction outcome loss': 0.8157436023598258, 'Total loss': 0.8157436023598258}
2022-11-18 03:21:02,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:02,413 INFO:     Epoch: 54
2022-11-18 03:21:03,193 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8458181341940706, 'Total loss': 0.8458181341940706} | train loss {'Reaction outcome loss': 0.8100030659603686, 'Total loss': 0.8100030659603686}
2022-11-18 03:21:03,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:03,193 INFO:     Epoch: 55
2022-11-18 03:21:03,957 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8348744755441492, 'Total loss': 0.8348744755441492} | train loss {'Reaction outcome loss': 0.8088056717203697, 'Total loss': 0.8088056717203697}
2022-11-18 03:21:03,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:03,957 INFO:     Epoch: 56
2022-11-18 03:21:04,748 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8315440497615121, 'Total loss': 0.8315440497615121} | train loss {'Reaction outcome loss': 0.8105279134835309, 'Total loss': 0.8105279134835309}
2022-11-18 03:21:04,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:04,749 INFO:     Epoch: 57
2022-11-18 03:21:05,549 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8509083613753319, 'Total loss': 0.8509083613753319} | train loss {'Reaction outcome loss': 0.8076139641435522, 'Total loss': 0.8076139641435522}
2022-11-18 03:21:05,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:05,550 INFO:     Epoch: 58
2022-11-18 03:21:06,324 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8525856164368716, 'Total loss': 0.8525856164368716} | train loss {'Reaction outcome loss': 0.811409118687093, 'Total loss': 0.811409118687093}
2022-11-18 03:21:06,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:06,324 INFO:     Epoch: 59
2022-11-18 03:21:07,107 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8439930921251123, 'Total loss': 0.8439930921251123} | train loss {'Reaction outcome loss': 0.8089369471497864, 'Total loss': 0.8089369471497864}
2022-11-18 03:21:07,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:07,108 INFO:     Epoch: 60
2022-11-18 03:21:07,887 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8342285833575509, 'Total loss': 0.8342285833575509} | train loss {'Reaction outcome loss': 0.8097949542014705, 'Total loss': 0.8097949542014705}
2022-11-18 03:21:07,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:07,887 INFO:     Epoch: 61
2022-11-18 03:21:08,653 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8546973880041729, 'Total loss': 0.8546973880041729} | train loss {'Reaction outcome loss': 0.8120988969378143, 'Total loss': 0.8120988969378143}
2022-11-18 03:21:08,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:08,653 INFO:     Epoch: 62
2022-11-18 03:21:09,435 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8683852661739696, 'Total loss': 0.8683852661739696} | train loss {'Reaction outcome loss': 0.8106575920755564, 'Total loss': 0.8106575920755564}
2022-11-18 03:21:09,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:09,436 INFO:     Epoch: 63
2022-11-18 03:21:10,226 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.852025870572437, 'Total loss': 0.852025870572437} | train loss {'Reaction outcome loss': 0.8122525575913881, 'Total loss': 0.8122525575913881}
2022-11-18 03:21:10,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:10,227 INFO:     Epoch: 64
2022-11-18 03:21:11,033 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8434234065088358, 'Total loss': 0.8434234065088358} | train loss {'Reaction outcome loss': 0.8079188294738893, 'Total loss': 0.8079188294738893}
2022-11-18 03:21:11,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:11,033 INFO:     Epoch: 65
2022-11-18 03:21:11,801 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8540402542461049, 'Total loss': 0.8540402542461049} | train loss {'Reaction outcome loss': 0.8085873434659441, 'Total loss': 0.8085873434659441}
2022-11-18 03:21:11,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:11,801 INFO:     Epoch: 66
2022-11-18 03:21:12,579 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8348425003615293, 'Total loss': 0.8348425003615293} | train loss {'Reaction outcome loss': 0.8146149855152316, 'Total loss': 0.8146149855152316}
2022-11-18 03:21:12,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:12,579 INFO:     Epoch: 67
2022-11-18 03:21:13,372 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8532746867700056, 'Total loss': 0.8532746867700056} | train loss {'Reaction outcome loss': 0.8067614183372814, 'Total loss': 0.8067614183372814}
2022-11-18 03:21:13,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:13,372 INFO:     Epoch: 68
2022-11-18 03:21:14,138 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8457015319304033, 'Total loss': 0.8457015319304033} | train loss {'Reaction outcome loss': 0.8071731266825788, 'Total loss': 0.8071731266825788}
2022-11-18 03:21:14,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:14,139 INFO:     Epoch: 69
2022-11-18 03:21:14,922 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8478952781720595, 'Total loss': 0.8478952781720595} | train loss {'Reaction outcome loss': 0.8146738697160111, 'Total loss': 0.8146738697160111}
2022-11-18 03:21:14,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:14,922 INFO:     Epoch: 70
2022-11-18 03:21:15,724 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8345597697929903, 'Total loss': 0.8345597697929903} | train loss {'Reaction outcome loss': 0.8050385611018671, 'Total loss': 0.8050385611018671}
2022-11-18 03:21:15,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:15,724 INFO:     Epoch: 71
2022-11-18 03:21:16,511 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8412868543104692, 'Total loss': 0.8412868543104692} | train loss {'Reaction outcome loss': 0.8154181018773361, 'Total loss': 0.8154181018773361}
2022-11-18 03:21:16,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:16,512 INFO:     Epoch: 72
2022-11-18 03:21:17,293 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8452424474737861, 'Total loss': 0.8452424474737861} | train loss {'Reaction outcome loss': 0.8096967597722042, 'Total loss': 0.8096967597722042}
2022-11-18 03:21:17,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:17,294 INFO:     Epoch: 73
2022-11-18 03:21:18,072 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8915433802387931, 'Total loss': 0.8915433802387931} | train loss {'Reaction outcome loss': 0.8067908133813727, 'Total loss': 0.8067908133813727}
2022-11-18 03:21:18,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:18,073 INFO:     Epoch: 74
2022-11-18 03:21:18,857 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8418615047227253, 'Total loss': 0.8418615047227253} | train loss {'Reaction outcome loss': 0.8099327560830937, 'Total loss': 0.8099327560830937}
2022-11-18 03:21:18,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:18,857 INFO:     Epoch: 75
2022-11-18 03:21:19,624 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8515373481945558, 'Total loss': 0.8515373481945558} | train loss {'Reaction outcome loss': 0.8088188836207757, 'Total loss': 0.8088188836207757}
2022-11-18 03:21:19,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:19,625 INFO:     Epoch: 76
2022-11-18 03:21:20,395 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8646603314713999, 'Total loss': 0.8646603314713999} | train loss {'Reaction outcome loss': 0.8143299294386798, 'Total loss': 0.8143299294386798}
2022-11-18 03:21:20,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:20,395 INFO:     Epoch: 77
2022-11-18 03:21:21,174 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8865648897534067, 'Total loss': 0.8865648897534067} | train loss {'Reaction outcome loss': 0.810554408411748, 'Total loss': 0.810554408411748}
2022-11-18 03:21:21,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:21,174 INFO:     Epoch: 78
2022-11-18 03:21:21,986 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8505223352800716, 'Total loss': 0.8505223352800716} | train loss {'Reaction outcome loss': 0.8119018401211573, 'Total loss': 0.8119018401211573}
2022-11-18 03:21:21,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:21,986 INFO:     Epoch: 79
2022-11-18 03:21:22,768 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8450759053230286, 'Total loss': 0.8450759053230286} | train loss {'Reaction outcome loss': 0.8057861097669794, 'Total loss': 0.8057861097669794}
2022-11-18 03:21:22,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:22,768 INFO:     Epoch: 80
2022-11-18 03:21:23,562 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8371624756943096, 'Total loss': 0.8371624756943096} | train loss {'Reaction outcome loss': 0.8081644347186393, 'Total loss': 0.8081644347186393}
2022-11-18 03:21:23,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:23,562 INFO:     Epoch: 81
2022-11-18 03:21:24,325 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8490139855579897, 'Total loss': 0.8490139855579897} | train loss {'Reaction outcome loss': 0.812291378796342, 'Total loss': 0.812291378796342}
2022-11-18 03:21:24,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:24,325 INFO:     Epoch: 82
2022-11-18 03:21:25,117 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8496177203275941, 'Total loss': 0.8496177203275941} | train loss {'Reaction outcome loss': 0.8201750534990055, 'Total loss': 0.8201750534990055}
2022-11-18 03:21:25,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:25,118 INFO:     Epoch: 83
2022-11-18 03:21:25,911 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8548028116876428, 'Total loss': 0.8548028116876428} | train loss {'Reaction outcome loss': 0.807366542940439, 'Total loss': 0.807366542940439}
2022-11-18 03:21:25,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:25,911 INFO:     Epoch: 84
2022-11-18 03:21:26,656 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8875561099160801, 'Total loss': 0.8875561099160801} | train loss {'Reaction outcome loss': 0.8072736766415569, 'Total loss': 0.8072736766415569}
2022-11-18 03:21:26,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:26,656 INFO:     Epoch: 85
2022-11-18 03:21:27,410 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8557468517260118, 'Total loss': 0.8557468517260118} | train loss {'Reaction outcome loss': 0.8185637648771649, 'Total loss': 0.8185637648771649}
2022-11-18 03:21:27,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:27,410 INFO:     Epoch: 86
2022-11-18 03:21:28,216 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8483763933181763, 'Total loss': 0.8483763933181763} | train loss {'Reaction outcome loss': 0.8054307620399274, 'Total loss': 0.8054307620399274}
2022-11-18 03:21:28,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:28,216 INFO:     Epoch: 87
2022-11-18 03:21:28,981 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8506409417499196, 'Total loss': 0.8506409417499196} | train loss {'Reaction outcome loss': 0.8071450235148673, 'Total loss': 0.8071450235148673}
2022-11-18 03:21:28,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:28,981 INFO:     Epoch: 88
2022-11-18 03:21:29,772 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8499863350933249, 'Total loss': 0.8499863350933249} | train loss {'Reaction outcome loss': 0.8120492932043577, 'Total loss': 0.8120492932043577}
2022-11-18 03:21:29,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:29,773 INFO:     Epoch: 89
2022-11-18 03:21:30,558 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8325682770122181, 'Total loss': 0.8325682770122181} | train loss {'Reaction outcome loss': 0.8066023970663789, 'Total loss': 0.8066023970663789}
2022-11-18 03:21:30,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:30,558 INFO:     Epoch: 90
2022-11-18 03:21:31,376 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.835686133666472, 'Total loss': 0.835686133666472} | train loss {'Reaction outcome loss': 0.8113440255887112, 'Total loss': 0.8113440255887112}
2022-11-18 03:21:31,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:31,377 INFO:     Epoch: 91
2022-11-18 03:21:32,181 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8255761963399973, 'Total loss': 0.8255761963399973} | train loss {'Reaction outcome loss': 0.8096533912396141, 'Total loss': 0.8096533912396141}
2022-11-18 03:21:32,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:32,182 INFO:     Epoch: 92
2022-11-18 03:21:32,958 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8445942469618537, 'Total loss': 0.8445942469618537} | train loss {'Reaction outcome loss': 0.8077083565445564, 'Total loss': 0.8077083565445564}
2022-11-18 03:21:32,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:32,959 INFO:     Epoch: 93
2022-11-18 03:21:33,753 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8900936191732233, 'Total loss': 0.8900936191732233} | train loss {'Reaction outcome loss': 0.809662769288428, 'Total loss': 0.809662769288428}
2022-11-18 03:21:33,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:33,753 INFO:     Epoch: 94
2022-11-18 03:21:34,611 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8317794413729147, 'Total loss': 0.8317794413729147} | train loss {'Reaction outcome loss': 0.8059806713932439, 'Total loss': 0.8059806713932439}
2022-11-18 03:21:34,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:34,611 INFO:     Epoch: 95
2022-11-18 03:21:35,460 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8519684299826622, 'Total loss': 0.8519684299826622} | train loss {'Reaction outcome loss': 0.8096599537833982, 'Total loss': 0.8096599537833982}
2022-11-18 03:21:35,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:35,460 INFO:     Epoch: 96
2022-11-18 03:21:36,259 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.844357667998834, 'Total loss': 0.844357667998834} | train loss {'Reaction outcome loss': 0.8052749770131671, 'Total loss': 0.8052749770131671}
2022-11-18 03:21:36,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:36,260 INFO:     Epoch: 97
2022-11-18 03:21:37,060 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.831959874115207, 'Total loss': 0.831959874115207} | train loss {'Reaction outcome loss': 0.8100011195489752, 'Total loss': 0.8100011195489752}
2022-11-18 03:21:37,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:37,061 INFO:     Epoch: 98
2022-11-18 03:21:37,850 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8722521364688873, 'Total loss': 0.8722521364688873} | train loss {'Reaction outcome loss': 0.8038974423036884, 'Total loss': 0.8038974423036884}
2022-11-18 03:21:37,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:37,851 INFO:     Epoch: 99
2022-11-18 03:21:38,665 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8547544100067832, 'Total loss': 0.8547544100067832} | train loss {'Reaction outcome loss': 0.8081562595087507, 'Total loss': 0.8081562595087507}
2022-11-18 03:21:38,665 INFO:     Best model found after epoch 29 of 100.
2022-11-18 03:21:38,665 INFO:   Done with stage: TRAINING
2022-11-18 03:21:38,665 INFO:   Starting stage: EVALUATION
2022-11-18 03:21:38,789 INFO:   Done with stage: EVALUATION
2022-11-18 03:21:38,798 INFO:   Leaving out SEQ value Fold_0
2022-11-18 03:21:38,811 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 03:21:38,811 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:21:39,481 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:21:39,481 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:21:39,551 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:21:39,551 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:21:39,551 INFO:     No hyperparam tuning for this model
2022-11-18 03:21:39,551 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:21:39,551 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:21:39,552 INFO:     None feature selector for col prot
2022-11-18 03:21:39,552 INFO:     None feature selector for col prot
2022-11-18 03:21:39,552 INFO:     None feature selector for col prot
2022-11-18 03:21:39,553 INFO:     None feature selector for col chem
2022-11-18 03:21:39,553 INFO:     None feature selector for col chem
2022-11-18 03:21:39,553 INFO:     None feature selector for col chem
2022-11-18 03:21:39,553 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:21:39,553 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:21:39,555 INFO:     Number of params in model 168571
2022-11-18 03:21:39,558 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:21:39,558 INFO:   Starting stage: TRAINING
2022-11-18 03:21:39,615 INFO:     Val loss before train {'Reaction outcome loss': 0.9783980257289354, 'Total loss': 0.9783980257289354}
2022-11-18 03:21:39,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:39,616 INFO:     Epoch: 0
2022-11-18 03:21:40,409 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8685649342315142, 'Total loss': 0.8685649342315142} | train loss {'Reaction outcome loss': 0.8712009988694525, 'Total loss': 0.8712009988694525}
2022-11-18 03:21:40,409 INFO:     Found new best model at epoch 0
2022-11-18 03:21:40,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:40,410 INFO:     Epoch: 1
2022-11-18 03:21:41,183 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8548213091007498, 'Total loss': 0.8548213091007498} | train loss {'Reaction outcome loss': 0.8372368434819665, 'Total loss': 0.8372368434819665}
2022-11-18 03:21:41,184 INFO:     Found new best model at epoch 1
2022-11-18 03:21:41,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:41,184 INFO:     Epoch: 2
2022-11-18 03:21:41,994 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8614533051501873, 'Total loss': 0.8614533051501873} | train loss {'Reaction outcome loss': 0.8304074096336286, 'Total loss': 0.8304074096336286}
2022-11-18 03:21:41,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:41,994 INFO:     Epoch: 3
2022-11-18 03:21:42,763 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8380427686280982, 'Total loss': 0.8380427686280982} | train loss {'Reaction outcome loss': 0.8243369684543138, 'Total loss': 0.8243369684543138}
2022-11-18 03:21:42,763 INFO:     Found new best model at epoch 3
2022-11-18 03:21:42,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:42,764 INFO:     Epoch: 4
2022-11-18 03:21:43,557 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8388993206412293, 'Total loss': 0.8388993206412293} | train loss {'Reaction outcome loss': 0.8195968045864577, 'Total loss': 0.8195968045864577}
2022-11-18 03:21:43,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:43,558 INFO:     Epoch: 5
2022-11-18 03:21:44,368 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8546252902164015, 'Total loss': 0.8546252902164015} | train loss {'Reaction outcome loss': 0.8141210383348504, 'Total loss': 0.8141210383348504}
2022-11-18 03:21:44,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:44,368 INFO:     Epoch: 6
2022-11-18 03:21:45,147 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.856503565644109, 'Total loss': 0.856503565644109} | train loss {'Reaction outcome loss': 0.8154504960517824, 'Total loss': 0.8154504960517824}
2022-11-18 03:21:45,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:45,148 INFO:     Epoch: 7
2022-11-18 03:21:45,964 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.822339363569437, 'Total loss': 0.822339363569437} | train loss {'Reaction outcome loss': 0.8151369885897931, 'Total loss': 0.8151369885897931}
2022-11-18 03:21:45,964 INFO:     Found new best model at epoch 7
2022-11-18 03:21:45,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:45,965 INFO:     Epoch: 8
2022-11-18 03:21:46,768 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8374008335346399, 'Total loss': 0.8374008335346399} | train loss {'Reaction outcome loss': 0.8121377721490193, 'Total loss': 0.8121377721490193}
2022-11-18 03:21:46,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:46,769 INFO:     Epoch: 9
2022-11-18 03:21:47,553 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8319787390010301, 'Total loss': 0.8319787390010301} | train loss {'Reaction outcome loss': 0.8148302816069175, 'Total loss': 0.8148302816069175}
2022-11-18 03:21:47,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:47,553 INFO:     Epoch: 10
2022-11-18 03:21:48,338 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8366820243901985, 'Total loss': 0.8366820243901985} | train loss {'Reaction outcome loss': 0.8101754323445229, 'Total loss': 0.8101754323445229}
2022-11-18 03:21:48,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:48,339 INFO:     Epoch: 11
2022-11-18 03:21:49,161 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8271055374034616, 'Total loss': 0.8271055374034616} | train loss {'Reaction outcome loss': 0.8066879466114711, 'Total loss': 0.8066879466114711}
2022-11-18 03:21:49,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:49,162 INFO:     Epoch: 12
2022-11-18 03:21:49,930 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8323839396931404, 'Total loss': 0.8323839396931404} | train loss {'Reaction outcome loss': 0.8119874724144798, 'Total loss': 0.8119874724144798}
2022-11-18 03:21:49,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:49,930 INFO:     Epoch: 13
2022-11-18 03:21:50,738 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8345300028490465, 'Total loss': 0.8345300028490465} | train loss {'Reaction outcome loss': 0.8118873169883288, 'Total loss': 0.8118873169883288}
2022-11-18 03:21:50,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:50,739 INFO:     Epoch: 14
2022-11-18 03:21:51,504 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8279086053371429, 'Total loss': 0.8279086053371429} | train loss {'Reaction outcome loss': 0.8042594524322714, 'Total loss': 0.8042594524322714}
2022-11-18 03:21:51,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:51,504 INFO:     Epoch: 15
2022-11-18 03:21:52,304 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8411621624647185, 'Total loss': 0.8411621624647185} | train loss {'Reaction outcome loss': 0.8127087463812573, 'Total loss': 0.8127087463812573}
2022-11-18 03:21:52,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:52,304 INFO:     Epoch: 16
2022-11-18 03:21:53,112 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8565560177315114, 'Total loss': 0.8565560177315114} | train loss {'Reaction outcome loss': 0.8107869735470524, 'Total loss': 0.8107869735470524}
2022-11-18 03:21:53,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:53,112 INFO:     Epoch: 17
2022-11-18 03:21:53,886 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8489001635895219, 'Total loss': 0.8489001635895219} | train loss {'Reaction outcome loss': 0.8039706007198051, 'Total loss': 0.8039706007198051}
2022-11-18 03:21:53,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:53,886 INFO:     Epoch: 18
2022-11-18 03:21:54,727 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8345232661380324, 'Total loss': 0.8345232661380324} | train loss {'Reaction outcome loss': 0.8064120931880464, 'Total loss': 0.8064120931880464}
2022-11-18 03:21:54,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:54,727 INFO:     Epoch: 19
2022-11-18 03:21:55,521 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8405296830243842, 'Total loss': 0.8405296830243842} | train loss {'Reaction outcome loss': 0.81165965373624, 'Total loss': 0.81165965373624}
2022-11-18 03:21:55,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:55,521 INFO:     Epoch: 20
2022-11-18 03:21:56,317 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8272493155889733, 'Total loss': 0.8272493155889733} | train loss {'Reaction outcome loss': 0.8026912527565112, 'Total loss': 0.8026912527565112}
2022-11-18 03:21:56,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:56,317 INFO:     Epoch: 21
2022-11-18 03:21:57,086 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8304922213388044, 'Total loss': 0.8304922213388044} | train loss {'Reaction outcome loss': 0.8034138620635609, 'Total loss': 0.8034138620635609}
2022-11-18 03:21:57,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:57,086 INFO:     Epoch: 22
2022-11-18 03:21:57,860 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8347964979881464, 'Total loss': 0.8347964979881464} | train loss {'Reaction outcome loss': 0.8055348759325444, 'Total loss': 0.8055348759325444}
2022-11-18 03:21:57,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:57,860 INFO:     Epoch: 23
2022-11-18 03:21:58,679 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8410813170810079, 'Total loss': 0.8410813170810079} | train loss {'Reaction outcome loss': 0.808608942990931, 'Total loss': 0.808608942990931}
2022-11-18 03:21:58,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:58,679 INFO:     Epoch: 24
2022-11-18 03:21:59,486 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.829316726950712, 'Total loss': 0.829316726950712} | train loss {'Reaction outcome loss': 0.8070619886304126, 'Total loss': 0.8070619886304126}
2022-11-18 03:21:59,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:21:59,486 INFO:     Epoch: 25
2022-11-18 03:22:00,297 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8384877533413643, 'Total loss': 0.8384877533413643} | train loss {'Reaction outcome loss': 0.8048603804513751, 'Total loss': 0.8048603804513751}
2022-11-18 03:22:00,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:00,297 INFO:     Epoch: 26
2022-11-18 03:22:01,108 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8233459931473399, 'Total loss': 0.8233459931473399} | train loss {'Reaction outcome loss': 0.802672851723408, 'Total loss': 0.802672851723408}
2022-11-18 03:22:01,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:01,110 INFO:     Epoch: 27
2022-11-18 03:22:01,924 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.888846990674041, 'Total loss': 0.888846990674041} | train loss {'Reaction outcome loss': 0.8062579487086323, 'Total loss': 0.8062579487086323}
2022-11-18 03:22:01,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:01,924 INFO:     Epoch: 28
2022-11-18 03:22:02,745 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8250864446163177, 'Total loss': 0.8250864446163177} | train loss {'Reaction outcome loss': 0.8035476443208294, 'Total loss': 0.8035476443208294}
2022-11-18 03:22:02,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:02,746 INFO:     Epoch: 29
2022-11-18 03:22:03,565 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8330914149450701, 'Total loss': 0.8330914149450701} | train loss {'Reaction outcome loss': 0.8055518643600951, 'Total loss': 0.8055518643600951}
2022-11-18 03:22:03,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:03,565 INFO:     Epoch: 30
2022-11-18 03:22:04,358 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8358561680760495, 'Total loss': 0.8358561680760495} | train loss {'Reaction outcome loss': 0.8049784491582171, 'Total loss': 0.8049784491582171}
2022-11-18 03:22:04,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:04,358 INFO:     Epoch: 31
2022-11-18 03:22:05,116 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.827491793521615, 'Total loss': 0.827491793521615} | train loss {'Reaction outcome loss': 0.8054335804142579, 'Total loss': 0.8054335804142579}
2022-11-18 03:22:05,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:05,116 INFO:     Epoch: 32
2022-11-18 03:22:05,911 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8314629238705302, 'Total loss': 0.8314629238705302} | train loss {'Reaction outcome loss': 0.802485798979983, 'Total loss': 0.802485798979983}
2022-11-18 03:22:05,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:05,911 INFO:     Epoch: 33
2022-11-18 03:22:06,682 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8471082102420718, 'Total loss': 0.8471082102420718} | train loss {'Reaction outcome loss': 0.8010250794176211, 'Total loss': 0.8010250794176211}
2022-11-18 03:22:06,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:06,683 INFO:     Epoch: 34
2022-11-18 03:22:07,471 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8304992997369101, 'Total loss': 0.8304992997369101} | train loss {'Reaction outcome loss': 0.8079840559282421, 'Total loss': 0.8079840559282421}
2022-11-18 03:22:07,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:07,472 INFO:     Epoch: 35
2022-11-18 03:22:08,251 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8442545145056969, 'Total loss': 0.8442545145056969} | train loss {'Reaction outcome loss': 0.8010790890136373, 'Total loss': 0.8010790890136373}
2022-11-18 03:22:08,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:08,251 INFO:     Epoch: 36
2022-11-18 03:22:09,032 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8332733539647834, 'Total loss': 0.8332733539647834} | train loss {'Reaction outcome loss': 0.8079700507990126, 'Total loss': 0.8079700507990126}
2022-11-18 03:22:09,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:09,033 INFO:     Epoch: 37
2022-11-18 03:22:09,810 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8301806082559187, 'Total loss': 0.8301806082559187} | train loss {'Reaction outcome loss': 0.8028186199105816, 'Total loss': 0.8028186199105816}
2022-11-18 03:22:09,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:09,810 INFO:     Epoch: 38
2022-11-18 03:22:10,600 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.839493380036465, 'Total loss': 0.839493380036465} | train loss {'Reaction outcome loss': 0.8017068766517403, 'Total loss': 0.8017068766517403}
2022-11-18 03:22:10,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:10,600 INFO:     Epoch: 39
2022-11-18 03:22:11,399 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8491239589314128, 'Total loss': 0.8491239589314128} | train loss {'Reaction outcome loss': 0.8026384875607588, 'Total loss': 0.8026384875607588}
2022-11-18 03:22:11,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:11,399 INFO:     Epoch: 40
2022-11-18 03:22:12,241 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.834449133900709, 'Total loss': 0.834449133900709} | train loss {'Reaction outcome loss': 0.8052452706996306, 'Total loss': 0.8052452706996306}
2022-11-18 03:22:12,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:12,242 INFO:     Epoch: 41
2022-11-18 03:22:13,072 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.831602229628452, 'Total loss': 0.831602229628452} | train loss {'Reaction outcome loss': 0.8020220174465651, 'Total loss': 0.8020220174465651}
2022-11-18 03:22:13,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:13,072 INFO:     Epoch: 42
2022-11-18 03:22:13,833 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8462281130081, 'Total loss': 0.8462281130081} | train loss {'Reaction outcome loss': 0.8053441290502195, 'Total loss': 0.8053441290502195}
2022-11-18 03:22:13,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:13,834 INFO:     Epoch: 43
2022-11-18 03:22:14,630 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8272476847781691, 'Total loss': 0.8272476847781691} | train loss {'Reaction outcome loss': 0.8061056512373465, 'Total loss': 0.8061056512373465}
2022-11-18 03:22:14,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:14,630 INFO:     Epoch: 44
2022-11-18 03:22:15,406 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8258253245852715, 'Total loss': 0.8258253245852715} | train loss {'Reaction outcome loss': 0.8047996738565312, 'Total loss': 0.8047996738565312}
2022-11-18 03:22:15,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:15,406 INFO:     Epoch: 45
2022-11-18 03:22:16,227 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8301595324693725, 'Total loss': 0.8301595324693725} | train loss {'Reaction outcome loss': 0.8051860182864186, 'Total loss': 0.8051860182864186}
2022-11-18 03:22:16,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:16,227 INFO:     Epoch: 46
2022-11-18 03:22:17,015 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8614859400793563, 'Total loss': 0.8614859400793563} | train loss {'Reaction outcome loss': 0.8012853597172003, 'Total loss': 0.8012853597172003}
2022-11-18 03:22:17,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:17,015 INFO:     Epoch: 47
2022-11-18 03:22:17,827 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8282240448996078, 'Total loss': 0.8282240448996078} | train loss {'Reaction outcome loss': 0.805196098952627, 'Total loss': 0.805196098952627}
2022-11-18 03:22:17,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:17,827 INFO:     Epoch: 48
2022-11-18 03:22:18,624 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8391434092854344, 'Total loss': 0.8391434092854344} | train loss {'Reaction outcome loss': 0.8056800193747375, 'Total loss': 0.8056800193747375}
2022-11-18 03:22:18,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:18,625 INFO:     Epoch: 49
2022-11-18 03:22:19,405 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8251604514066563, 'Total loss': 0.8251604514066563} | train loss {'Reaction outcome loss': 0.8028038754875277, 'Total loss': 0.8028038754875277}
2022-11-18 03:22:19,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:19,406 INFO:     Epoch: 50
2022-11-18 03:22:20,239 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.824852705001831, 'Total loss': 0.824852705001831} | train loss {'Reaction outcome loss': 0.8007112508448063, 'Total loss': 0.8007112508448063}
2022-11-18 03:22:20,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:20,240 INFO:     Epoch: 51
2022-11-18 03:22:21,026 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8234916551168575, 'Total loss': 0.8234916551168575} | train loss {'Reaction outcome loss': 0.8055911677364459, 'Total loss': 0.8055911677364459}
2022-11-18 03:22:21,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:21,026 INFO:     Epoch: 52
2022-11-18 03:22:21,818 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8302134788313578, 'Total loss': 0.8302134788313578} | train loss {'Reaction outcome loss': 0.8060737068270459, 'Total loss': 0.8060737068270459}
2022-11-18 03:22:21,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:21,818 INFO:     Epoch: 53
2022-11-18 03:22:22,576 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8263536088688429, 'Total loss': 0.8263536088688429} | train loss {'Reaction outcome loss': 0.8033394098527147, 'Total loss': 0.8033394098527147}
2022-11-18 03:22:22,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:22,576 INFO:     Epoch: 54
2022-11-18 03:22:23,374 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8269750926383707, 'Total loss': 0.8269750926383707} | train loss {'Reaction outcome loss': 0.8006929703700689, 'Total loss': 0.8006929703700689}
2022-11-18 03:22:23,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:23,374 INFO:     Epoch: 55
2022-11-18 03:22:24,163 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8182314377884532, 'Total loss': 0.8182314377884532} | train loss {'Reaction outcome loss': 0.8042057813930904, 'Total loss': 0.8042057813930904}
2022-11-18 03:22:24,163 INFO:     Found new best model at epoch 55
2022-11-18 03:22:24,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:24,164 INFO:     Epoch: 56
2022-11-18 03:22:24,975 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8250179602656253, 'Total loss': 0.8250179602656253} | train loss {'Reaction outcome loss': 0.8016046706295799, 'Total loss': 0.8016046706295799}
2022-11-18 03:22:24,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:24,975 INFO:     Epoch: 57
2022-11-18 03:22:25,791 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8444278163965359, 'Total loss': 0.8444278163965359} | train loss {'Reaction outcome loss': 0.8035652980882935, 'Total loss': 0.8035652980882935}
2022-11-18 03:22:25,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:25,792 INFO:     Epoch: 58
2022-11-18 03:22:26,579 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8388828420361807, 'Total loss': 0.8388828420361807} | train loss {'Reaction outcome loss': 0.8037743846820705, 'Total loss': 0.8037743846820705}
2022-11-18 03:22:26,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:26,579 INFO:     Epoch: 59
2022-11-18 03:22:27,395 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8317892717760663, 'Total loss': 0.8317892717760663} | train loss {'Reaction outcome loss': 0.8003581080417084, 'Total loss': 0.8003581080417084}
2022-11-18 03:22:27,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:27,396 INFO:     Epoch: 60
2022-11-18 03:22:28,192 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8336411347222883, 'Total loss': 0.8336411347222883} | train loss {'Reaction outcome loss': 0.8064052931075234, 'Total loss': 0.8064052931075234}
2022-11-18 03:22:28,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:28,193 INFO:     Epoch: 61
2022-11-18 03:22:28,993 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8297994310079619, 'Total loss': 0.8297994310079619} | train loss {'Reaction outcome loss': 0.8013012171282199, 'Total loss': 0.8013012171282199}
2022-11-18 03:22:28,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:28,994 INFO:     Epoch: 62
2022-11-18 03:22:29,821 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8344656145849894, 'Total loss': 0.8344656145849894} | train loss {'Reaction outcome loss': 0.8086277928371979, 'Total loss': 0.8086277928371979}
2022-11-18 03:22:29,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:29,821 INFO:     Epoch: 63
2022-11-18 03:22:30,584 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8393363744713539, 'Total loss': 0.8393363744713539} | train loss {'Reaction outcome loss': 0.8043004433804579, 'Total loss': 0.8043004433804579}
2022-11-18 03:22:30,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:30,584 INFO:     Epoch: 64
2022-11-18 03:22:31,375 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8200244716433591, 'Total loss': 0.8200244716433591} | train loss {'Reaction outcome loss': 0.8042607617721637, 'Total loss': 0.8042607617721637}
2022-11-18 03:22:31,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:31,375 INFO:     Epoch: 65
2022-11-18 03:22:32,188 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8277940431306529, 'Total loss': 0.8277940431306529} | train loss {'Reaction outcome loss': 0.8029618279801475, 'Total loss': 0.8029618279801475}
2022-11-18 03:22:32,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:32,189 INFO:     Epoch: 66
2022-11-18 03:22:32,972 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8362760626992514, 'Total loss': 0.8362760626992514} | train loss {'Reaction outcome loss': 0.8000167895246435, 'Total loss': 0.8000167895246435}
2022-11-18 03:22:32,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:32,972 INFO:     Epoch: 67
2022-11-18 03:22:33,775 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8391301832919897, 'Total loss': 0.8391301832919897} | train loss {'Reaction outcome loss': 0.80371423905769, 'Total loss': 0.80371423905769}
2022-11-18 03:22:33,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:33,775 INFO:     Epoch: 68
2022-11-18 03:22:34,566 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8494989802671034, 'Total loss': 0.8494989802671034} | train loss {'Reaction outcome loss': 0.8015259924984763, 'Total loss': 0.8015259924984763}
2022-11-18 03:22:34,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:34,566 INFO:     Epoch: 69
2022-11-18 03:22:35,373 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8169791954894399, 'Total loss': 0.8169791954894399} | train loss {'Reaction outcome loss': 0.8059966875692454, 'Total loss': 0.8059966875692454}
2022-11-18 03:22:35,374 INFO:     Found new best model at epoch 69
2022-11-18 03:22:35,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:35,374 INFO:     Epoch: 70
2022-11-18 03:22:36,171 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8273702714332315, 'Total loss': 0.8273702714332315} | train loss {'Reaction outcome loss': 0.8024238471876938, 'Total loss': 0.8024238471876938}
2022-11-18 03:22:36,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:36,171 INFO:     Epoch: 71
2022-11-18 03:22:36,984 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8289969362491785, 'Total loss': 0.8289969362491785} | train loss {'Reaction outcome loss': 0.8066177138821088, 'Total loss': 0.8066177138821088}
2022-11-18 03:22:36,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:36,984 INFO:     Epoch: 72
2022-11-18 03:22:37,758 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8507934753284898, 'Total loss': 0.8507934753284898} | train loss {'Reaction outcome loss': 0.8042335707709622, 'Total loss': 0.8042335707709622}
2022-11-18 03:22:37,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:37,758 INFO:     Epoch: 73
2022-11-18 03:22:38,566 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8333462712376617, 'Total loss': 0.8333462712376617} | train loss {'Reaction outcome loss': 0.8042769271405146, 'Total loss': 0.8042769271405146}
2022-11-18 03:22:38,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:38,567 INFO:     Epoch: 74
2022-11-18 03:22:39,340 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8343581183012142, 'Total loss': 0.8343581183012142} | train loss {'Reaction outcome loss': 0.8059055151517499, 'Total loss': 0.8059055151517499}
2022-11-18 03:22:39,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:39,340 INFO:     Epoch: 75
2022-11-18 03:22:40,154 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.834562348071919, 'Total loss': 0.834562348071919} | train loss {'Reaction outcome loss': 0.804103559182014, 'Total loss': 0.804103559182014}
2022-11-18 03:22:40,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:40,154 INFO:     Epoch: 76
2022-11-18 03:22:40,933 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8319368022818898, 'Total loss': 0.8319368022818898} | train loss {'Reaction outcome loss': 0.800917603474095, 'Total loss': 0.800917603474095}
2022-11-18 03:22:40,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:40,933 INFO:     Epoch: 77
2022-11-18 03:22:41,752 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8377784462862237, 'Total loss': 0.8377784462862237} | train loss {'Reaction outcome loss': 0.8097177877592943, 'Total loss': 0.8097177877592943}
2022-11-18 03:22:41,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:41,752 INFO:     Epoch: 78
2022-11-18 03:22:42,563 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8265942702459734, 'Total loss': 0.8265942702459734} | train loss {'Reaction outcome loss': 0.8070942142618046, 'Total loss': 0.8070942142618046}
2022-11-18 03:22:42,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:42,563 INFO:     Epoch: 79
2022-11-18 03:22:43,328 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8233443429303724, 'Total loss': 0.8233443429303724} | train loss {'Reaction outcome loss': 0.8076568707026572, 'Total loss': 0.8076568707026572}
2022-11-18 03:22:43,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:43,328 INFO:     Epoch: 80
2022-11-18 03:22:44,123 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8335813741351283, 'Total loss': 0.8335813741351283} | train loss {'Reaction outcome loss': 0.7998622316453192, 'Total loss': 0.7998622316453192}
2022-11-18 03:22:44,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:44,123 INFO:     Epoch: 81
2022-11-18 03:22:44,919 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8308640572913858, 'Total loss': 0.8308640572913858} | train loss {'Reaction outcome loss': 0.8031898308928611, 'Total loss': 0.8031898308928611}
2022-11-18 03:22:44,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:44,920 INFO:     Epoch: 82
2022-11-18 03:22:45,695 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8577646204205447, 'Total loss': 0.8577646204205447} | train loss {'Reaction outcome loss': 0.8050398301685788, 'Total loss': 0.8050398301685788}
2022-11-18 03:22:45,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:45,695 INFO:     Epoch: 83
2022-11-18 03:22:46,495 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8276813279750735, 'Total loss': 0.8276813279750735} | train loss {'Reaction outcome loss': 0.805681319884312, 'Total loss': 0.805681319884312}
2022-11-18 03:22:46,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:46,495 INFO:     Epoch: 84
2022-11-18 03:22:47,285 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8442525953747505, 'Total loss': 0.8442525953747505} | train loss {'Reaction outcome loss': 0.8051321983582689, 'Total loss': 0.8051321983582689}
2022-11-18 03:22:47,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:47,286 INFO:     Epoch: 85
2022-11-18 03:22:48,071 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8329548503077308, 'Total loss': 0.8329548503077308} | train loss {'Reaction outcome loss': 0.8058751410662882, 'Total loss': 0.8058751410662882}
2022-11-18 03:22:48,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:48,072 INFO:     Epoch: 86
2022-11-18 03:22:48,870 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8325992815716322, 'Total loss': 0.8325992815716322} | train loss {'Reaction outcome loss': 0.8002927961295524, 'Total loss': 0.8002927961295524}
2022-11-18 03:22:48,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:48,870 INFO:     Epoch: 87
2022-11-18 03:22:49,627 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8290314078330994, 'Total loss': 0.8290314078330994} | train loss {'Reaction outcome loss': 0.8044128779766491, 'Total loss': 0.8044128779766491}
2022-11-18 03:22:49,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:49,627 INFO:     Epoch: 88
2022-11-18 03:22:50,411 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8456110288930494, 'Total loss': 0.8456110288930494} | train loss {'Reaction outcome loss': 0.8040818765207574, 'Total loss': 0.8040818765207574}
2022-11-18 03:22:50,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:50,412 INFO:     Epoch: 89
2022-11-18 03:22:51,194 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8444521628146948, 'Total loss': 0.8444521628146948} | train loss {'Reaction outcome loss': 0.806073881471108, 'Total loss': 0.806073881471108}
2022-11-18 03:22:51,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:51,196 INFO:     Epoch: 90
2022-11-18 03:22:52,001 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.856436571409536, 'Total loss': 0.856436571409536} | train loss {'Reaction outcome loss': 0.8020139139130282, 'Total loss': 0.8020139139130282}
2022-11-18 03:22:52,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:52,002 INFO:     Epoch: 91
2022-11-18 03:22:52,804 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8325957891552948, 'Total loss': 0.8325957891552948} | train loss {'Reaction outcome loss': 0.8033683431246643, 'Total loss': 0.8033683431246643}
2022-11-18 03:22:52,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:52,805 INFO:     Epoch: 92
2022-11-18 03:22:53,598 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8488588915314785, 'Total loss': 0.8488588915314785} | train loss {'Reaction outcome loss': 0.8032545373763567, 'Total loss': 0.8032545373763567}
2022-11-18 03:22:53,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:53,598 INFO:     Epoch: 93
2022-11-18 03:22:54,412 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.82876558913741, 'Total loss': 0.82876558913741} | train loss {'Reaction outcome loss': 0.8019489648410812, 'Total loss': 0.8019489648410812}
2022-11-18 03:22:54,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:54,412 INFO:     Epoch: 94
2022-11-18 03:22:55,233 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8236654414687046, 'Total loss': 0.8236654414687046} | train loss {'Reaction outcome loss': 0.8044664457501698, 'Total loss': 0.8044664457501698}
2022-11-18 03:22:55,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:55,233 INFO:     Epoch: 95
2022-11-18 03:22:56,033 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.825834475284399, 'Total loss': 0.825834475284399} | train loss {'Reaction outcome loss': 0.8035884346245739, 'Total loss': 0.8035884346245739}
2022-11-18 03:22:56,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:56,033 INFO:     Epoch: 96
2022-11-18 03:22:56,852 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8311614602111107, 'Total loss': 0.8311614602111107} | train loss {'Reaction outcome loss': 0.8052180731983342, 'Total loss': 0.8052180731983342}
2022-11-18 03:22:56,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:56,853 INFO:     Epoch: 97
2022-11-18 03:22:57,642 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8228891519613044, 'Total loss': 0.8228891519613044} | train loss {'Reaction outcome loss': 0.8091855652538347, 'Total loss': 0.8091855652538347}
2022-11-18 03:22:57,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:57,642 INFO:     Epoch: 98
2022-11-18 03:22:58,384 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8297410357830136, 'Total loss': 0.8297410357830136} | train loss {'Reaction outcome loss': 0.8064189967181947, 'Total loss': 0.8064189967181947}
2022-11-18 03:22:58,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:22:58,384 INFO:     Epoch: 99
2022-11-18 03:22:59,163 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8453431018563204, 'Total loss': 0.8453431018563204} | train loss {'Reaction outcome loss': 0.8045225003619253, 'Total loss': 0.8045225003619253}
2022-11-18 03:22:59,163 INFO:     Best model found after epoch 70 of 100.
2022-11-18 03:22:59,163 INFO:   Done with stage: TRAINING
2022-11-18 03:22:59,163 INFO:   Starting stage: EVALUATION
2022-11-18 03:22:59,302 INFO:   Done with stage: EVALUATION
2022-11-18 03:22:59,302 INFO:   Leaving out SEQ value Fold_1
2022-11-18 03:22:59,315 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 03:22:59,316 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:22:59,992 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:22:59,993 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:23:00,061 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:23:00,062 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:23:00,062 INFO:     No hyperparam tuning for this model
2022-11-18 03:23:00,062 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:23:00,062 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:23:00,063 INFO:     None feature selector for col prot
2022-11-18 03:23:00,063 INFO:     None feature selector for col prot
2022-11-18 03:23:00,063 INFO:     None feature selector for col prot
2022-11-18 03:23:00,064 INFO:     None feature selector for col chem
2022-11-18 03:23:00,064 INFO:     None feature selector for col chem
2022-11-18 03:23:00,064 INFO:     None feature selector for col chem
2022-11-18 03:23:00,064 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:23:00,064 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:23:00,065 INFO:     Number of params in model 168571
2022-11-18 03:23:00,069 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:23:00,069 INFO:   Starting stage: TRAINING
2022-11-18 03:23:00,129 INFO:     Val loss before train {'Reaction outcome loss': 1.0110259719870307, 'Total loss': 1.0110259719870307}
2022-11-18 03:23:00,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:00,130 INFO:     Epoch: 0
2022-11-18 03:23:00,917 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8234930769963698, 'Total loss': 0.8234930769963698} | train loss {'Reaction outcome loss': 0.8895067943602192, 'Total loss': 0.8895067943602192}
2022-11-18 03:23:00,917 INFO:     Found new best model at epoch 0
2022-11-18 03:23:00,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:00,918 INFO:     Epoch: 1
2022-11-18 03:23:01,740 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8342225118116899, 'Total loss': 0.8342225118116899} | train loss {'Reaction outcome loss': 0.8617573673627814, 'Total loss': 0.8617573673627814}
2022-11-18 03:23:01,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:01,740 INFO:     Epoch: 2
2022-11-18 03:23:02,543 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8295281807130034, 'Total loss': 0.8295281807130034} | train loss {'Reaction outcome loss': 0.8497970471576769, 'Total loss': 0.8497970471576769}
2022-11-18 03:23:02,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:02,544 INFO:     Epoch: 3
2022-11-18 03:23:03,307 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8077509938315912, 'Total loss': 0.8077509938315912} | train loss {'Reaction outcome loss': 0.849504802786574, 'Total loss': 0.849504802786574}
2022-11-18 03:23:03,309 INFO:     Found new best model at epoch 3
2022-11-18 03:23:03,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:03,310 INFO:     Epoch: 4
2022-11-18 03:23:04,134 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8203346160325137, 'Total loss': 0.8203346160325137} | train loss {'Reaction outcome loss': 0.8402715367930276, 'Total loss': 0.8402715367930276}
2022-11-18 03:23:04,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:04,134 INFO:     Epoch: 5
2022-11-18 03:23:04,913 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8144497546282682, 'Total loss': 0.8144497546282682} | train loss {'Reaction outcome loss': 0.8348278163647165, 'Total loss': 0.8348278163647165}
2022-11-18 03:23:04,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:04,913 INFO:     Epoch: 6
2022-11-18 03:23:05,698 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8053836463527246, 'Total loss': 0.8053836463527246} | train loss {'Reaction outcome loss': 0.8375777770061882, 'Total loss': 0.8375777770061882}
2022-11-18 03:23:05,698 INFO:     Found new best model at epoch 6
2022-11-18 03:23:05,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:05,699 INFO:     Epoch: 7
2022-11-18 03:23:06,496 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8376970087940042, 'Total loss': 0.8376970087940042} | train loss {'Reaction outcome loss': 0.8329705428104012, 'Total loss': 0.8329705428104012}
2022-11-18 03:23:06,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:06,496 INFO:     Epoch: 8
2022-11-18 03:23:07,288 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7904192659665238, 'Total loss': 0.7904192659665238} | train loss {'Reaction outcome loss': 0.8382107212835429, 'Total loss': 0.8382107212835429}
2022-11-18 03:23:07,288 INFO:     Found new best model at epoch 8
2022-11-18 03:23:07,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:07,289 INFO:     Epoch: 9
2022-11-18 03:23:08,111 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8061331612142649, 'Total loss': 0.8061331612142649} | train loss {'Reaction outcome loss': 0.8291619050259493, 'Total loss': 0.8291619050259493}
2022-11-18 03:23:08,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:08,111 INFO:     Epoch: 10
2022-11-18 03:23:08,898 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7906889644536105, 'Total loss': 0.7906889644536105} | train loss {'Reaction outcome loss': 0.8324785340805443, 'Total loss': 0.8324785340805443}
2022-11-18 03:23:08,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:08,899 INFO:     Epoch: 11
2022-11-18 03:23:09,688 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8224019882353869, 'Total loss': 0.8224019882353869} | train loss {'Reaction outcome loss': 0.8301818716282747, 'Total loss': 0.8301818716282747}
2022-11-18 03:23:09,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:09,689 INFO:     Epoch: 12
2022-11-18 03:23:10,501 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8268499665639617, 'Total loss': 0.8268499665639617} | train loss {'Reaction outcome loss': 0.8307175866195133, 'Total loss': 0.8307175866195133}
2022-11-18 03:23:10,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:10,501 INFO:     Epoch: 13
2022-11-18 03:23:11,298 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7914497269825502, 'Total loss': 0.7914497269825502} | train loss {'Reaction outcome loss': 0.8301912133791008, 'Total loss': 0.8301912133791008}
2022-11-18 03:23:11,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:11,298 INFO:     Epoch: 14
2022-11-18 03:23:12,095 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7907334200360558, 'Total loss': 0.7907334200360558} | train loss {'Reaction outcome loss': 0.8307143015520914, 'Total loss': 0.8307143015520914}
2022-11-18 03:23:12,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:12,095 INFO:     Epoch: 15
2022-11-18 03:23:12,870 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7818390154703097, 'Total loss': 0.7818390154703097} | train loss {'Reaction outcome loss': 0.8243586944074047, 'Total loss': 0.8243586944074047}
2022-11-18 03:23:12,870 INFO:     Found new best model at epoch 15
2022-11-18 03:23:12,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:12,871 INFO:     Epoch: 16
2022-11-18 03:23:13,680 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8164831271225755, 'Total loss': 0.8164831271225755} | train loss {'Reaction outcome loss': 0.8279697598243246, 'Total loss': 0.8279697598243246}
2022-11-18 03:23:13,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:13,680 INFO:     Epoch: 17
2022-11-18 03:23:14,466 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8006431690671227, 'Total loss': 0.8006431690671227} | train loss {'Reaction outcome loss': 0.8315124283031542, 'Total loss': 0.8315124283031542}
2022-11-18 03:23:14,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:14,467 INFO:     Epoch: 18
2022-11-18 03:23:15,225 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8302020620216023, 'Total loss': 0.8302020620216023} | train loss {'Reaction outcome loss': 0.8271390433214149, 'Total loss': 0.8271390433214149}
2022-11-18 03:23:15,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:15,225 INFO:     Epoch: 19
2022-11-18 03:23:16,048 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8269823430614038, 'Total loss': 0.8269823430614038} | train loss {'Reaction outcome loss': 0.8258697810221691, 'Total loss': 0.8258697810221691}
2022-11-18 03:23:16,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:16,049 INFO:     Epoch: 20
2022-11-18 03:23:16,834 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8104359324682843, 'Total loss': 0.8104359324682843} | train loss {'Reaction outcome loss': 0.8242943348933239, 'Total loss': 0.8242943348933239}
2022-11-18 03:23:16,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:16,835 INFO:     Epoch: 21
2022-11-18 03:23:17,633 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8047472089529037, 'Total loss': 0.8047472089529037} | train loss {'Reaction outcome loss': 0.8290681349987886, 'Total loss': 0.8290681349987886}
2022-11-18 03:23:17,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:17,633 INFO:     Epoch: 22
2022-11-18 03:23:18,403 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8028525892983783, 'Total loss': 0.8028525892983783} | train loss {'Reaction outcome loss': 0.8290263882705143, 'Total loss': 0.8290263882705143}
2022-11-18 03:23:18,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:18,403 INFO:     Epoch: 23
2022-11-18 03:23:19,164 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8196002034978433, 'Total loss': 0.8196002034978433} | train loss {'Reaction outcome loss': 0.8302964054808325, 'Total loss': 0.8302964054808325}
2022-11-18 03:23:19,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:19,165 INFO:     Epoch: 24
2022-11-18 03:23:19,930 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.800535147163001, 'Total loss': 0.800535147163001} | train loss {'Reaction outcome loss': 0.827395713207673, 'Total loss': 0.827395713207673}
2022-11-18 03:23:19,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:19,930 INFO:     Epoch: 25
2022-11-18 03:23:20,705 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.819055359471928, 'Total loss': 0.819055359471928} | train loss {'Reaction outcome loss': 0.8235551242925683, 'Total loss': 0.8235551242925683}
2022-11-18 03:23:20,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:20,705 INFO:     Epoch: 26
2022-11-18 03:23:21,474 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.807425550439141, 'Total loss': 0.807425550439141} | train loss {'Reaction outcome loss': 0.8316276308225126, 'Total loss': 0.8316276308225126}
2022-11-18 03:23:21,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:21,474 INFO:     Epoch: 27
2022-11-18 03:23:22,230 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8033618737350811, 'Total loss': 0.8033618737350811} | train loss {'Reaction outcome loss': 0.8250514285905021, 'Total loss': 0.8250514285905021}
2022-11-18 03:23:22,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:22,231 INFO:     Epoch: 28
2022-11-18 03:23:23,022 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.819056819785725, 'Total loss': 0.819056819785725} | train loss {'Reaction outcome loss': 0.827414653982435, 'Total loss': 0.827414653982435}
2022-11-18 03:23:23,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:23,023 INFO:     Epoch: 29
2022-11-18 03:23:23,806 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8298675648190759, 'Total loss': 0.8298675648190759} | train loss {'Reaction outcome loss': 0.8254429761244326, 'Total loss': 0.8254429761244326}
2022-11-18 03:23:23,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:23,807 INFO:     Epoch: 30
2022-11-18 03:23:24,581 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8355351984500885, 'Total loss': 0.8355351984500885} | train loss {'Reaction outcome loss': 0.8289177159873806, 'Total loss': 0.8289177159873806}
2022-11-18 03:23:24,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:24,581 INFO:     Epoch: 31
2022-11-18 03:23:25,376 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8039747368205677, 'Total loss': 0.8039747368205677} | train loss {'Reaction outcome loss': 0.8263918163825055, 'Total loss': 0.8263918163825055}
2022-11-18 03:23:25,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:25,377 INFO:     Epoch: 32
2022-11-18 03:23:26,137 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8080144802277739, 'Total loss': 0.8080144802277739} | train loss {'Reaction outcome loss': 0.8268186763841279, 'Total loss': 0.8268186763841279}
2022-11-18 03:23:26,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:26,137 INFO:     Epoch: 33
2022-11-18 03:23:26,908 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7949930497191169, 'Total loss': 0.7949930497191169} | train loss {'Reaction outcome loss': 0.8261954389056381, 'Total loss': 0.8261954389056381}
2022-11-18 03:23:26,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:26,908 INFO:     Epoch: 34
2022-11-18 03:23:27,684 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8204846016385339, 'Total loss': 0.8204846016385339} | train loss {'Reaction outcome loss': 0.8268670908042363, 'Total loss': 0.8268670908042363}
2022-11-18 03:23:27,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:27,684 INFO:     Epoch: 35
2022-11-18 03:23:28,451 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8347736326130953, 'Total loss': 0.8347736326130953} | train loss {'Reaction outcome loss': 0.8272582801020876, 'Total loss': 0.8272582801020876}
2022-11-18 03:23:28,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:28,451 INFO:     Epoch: 36
2022-11-18 03:23:29,284 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.789199985563755, 'Total loss': 0.789199985563755} | train loss {'Reaction outcome loss': 0.8282391067670316, 'Total loss': 0.8282391067670316}
2022-11-18 03:23:29,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:29,284 INFO:     Epoch: 37
2022-11-18 03:23:30,087 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8136938688429919, 'Total loss': 0.8136938688429919} | train loss {'Reaction outcome loss': 0.825805771715787, 'Total loss': 0.825805771715787}
2022-11-18 03:23:30,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:30,087 INFO:     Epoch: 38
2022-11-18 03:23:30,900 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8025041608647867, 'Total loss': 0.8025041608647867} | train loss {'Reaction outcome loss': 0.8248013829698368, 'Total loss': 0.8248013829698368}
2022-11-18 03:23:30,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:30,901 INFO:     Epoch: 39
2022-11-18 03:23:31,748 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8116824437271465, 'Total loss': 0.8116824437271465} | train loss {'Reaction outcome loss': 0.8239957040669966, 'Total loss': 0.8239957040669966}
2022-11-18 03:23:31,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:31,748 INFO:     Epoch: 40
2022-11-18 03:23:32,541 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.805576233023947, 'Total loss': 0.805576233023947} | train loss {'Reaction outcome loss': 0.8266913373859561, 'Total loss': 0.8266913373859561}
2022-11-18 03:23:32,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:32,541 INFO:     Epoch: 41
2022-11-18 03:23:33,348 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7903579229658301, 'Total loss': 0.7903579229658301} | train loss {'Reaction outcome loss': 0.8300153749329703, 'Total loss': 0.8300153749329703}
2022-11-18 03:23:33,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:33,349 INFO:     Epoch: 42
2022-11-18 03:23:34,126 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8202294063839045, 'Total loss': 0.8202294063839045} | train loss {'Reaction outcome loss': 0.8256718994403373, 'Total loss': 0.8256718994403373}
2022-11-18 03:23:34,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:34,128 INFO:     Epoch: 43
2022-11-18 03:23:34,917 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8017925789410417, 'Total loss': 0.8017925789410417} | train loss {'Reaction outcome loss': 0.8279048014052061, 'Total loss': 0.8279048014052061}
2022-11-18 03:23:34,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:34,918 INFO:     Epoch: 44
2022-11-18 03:23:35,732 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7972627607258883, 'Total loss': 0.7972627607258883} | train loss {'Reaction outcome loss': 0.825701155224625, 'Total loss': 0.825701155224625}
2022-11-18 03:23:35,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:35,732 INFO:     Epoch: 45
2022-11-18 03:23:36,533 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8088761432604357, 'Total loss': 0.8088761432604357} | train loss {'Reaction outcome loss': 0.8271260141109934, 'Total loss': 0.8271260141109934}
2022-11-18 03:23:36,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:36,533 INFO:     Epoch: 46
2022-11-18 03:23:37,343 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7975617064671083, 'Total loss': 0.7975617064671083} | train loss {'Reaction outcome loss': 0.8278381582425565, 'Total loss': 0.8278381582425565}
2022-11-18 03:23:37,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:37,343 INFO:     Epoch: 47
2022-11-18 03:23:38,148 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8093516576019201, 'Total loss': 0.8093516576019201} | train loss {'Reaction outcome loss': 0.8268038341585471, 'Total loss': 0.8268038341585471}
2022-11-18 03:23:38,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:38,148 INFO:     Epoch: 48
2022-11-18 03:23:38,941 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.806800289587541, 'Total loss': 0.806800289587541} | train loss {'Reaction outcome loss': 0.8198140191788577, 'Total loss': 0.8198140191788577}
2022-11-18 03:23:38,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:38,942 INFO:     Epoch: 49
2022-11-18 03:23:39,727 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7940853183919733, 'Total loss': 0.7940853183919733} | train loss {'Reaction outcome loss': 0.8313604379186825, 'Total loss': 0.8313604379186825}
2022-11-18 03:23:39,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:39,728 INFO:     Epoch: 50
2022-11-18 03:23:40,562 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8146052157337015, 'Total loss': 0.8146052157337015} | train loss {'Reaction outcome loss': 0.8250178970852676, 'Total loss': 0.8250178970852676}
2022-11-18 03:23:40,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:40,564 INFO:     Epoch: 51
2022-11-18 03:23:41,381 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7999757426706228, 'Total loss': 0.7999757426706228} | train loss {'Reaction outcome loss': 0.8265360658266107, 'Total loss': 0.8265360658266107}
2022-11-18 03:23:41,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:41,381 INFO:     Epoch: 52
2022-11-18 03:23:42,190 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8032803630286997, 'Total loss': 0.8032803630286997} | train loss {'Reaction outcome loss': 0.826035491422731, 'Total loss': 0.826035491422731}
2022-11-18 03:23:42,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:42,190 INFO:     Epoch: 53
2022-11-18 03:23:42,973 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8023440661755475, 'Total loss': 0.8023440661755475} | train loss {'Reaction outcome loss': 0.8271213145888582, 'Total loss': 0.8271213145888582}
2022-11-18 03:23:42,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:42,974 INFO:     Epoch: 54
2022-11-18 03:23:43,815 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8159854168241675, 'Total loss': 0.8159854168241675} | train loss {'Reaction outcome loss': 0.8273308504600914, 'Total loss': 0.8273308504600914}
2022-11-18 03:23:43,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:43,815 INFO:     Epoch: 55
2022-11-18 03:23:44,670 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8040720332752574, 'Total loss': 0.8040720332752574} | train loss {'Reaction outcome loss': 0.8214648861057904, 'Total loss': 0.8214648861057904}
2022-11-18 03:23:44,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:44,671 INFO:     Epoch: 56
2022-11-18 03:23:45,472 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8033996075391769, 'Total loss': 0.8033996075391769} | train loss {'Reaction outcome loss': 0.8287395428638069, 'Total loss': 0.8287395428638069}
2022-11-18 03:23:45,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:45,472 INFO:     Epoch: 57
2022-11-18 03:23:46,274 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8137008520689878, 'Total loss': 0.8137008520689878} | train loss {'Reaction outcome loss': 0.8238013547293994, 'Total loss': 0.8238013547293994}
2022-11-18 03:23:46,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:46,275 INFO:     Epoch: 58
2022-11-18 03:23:47,109 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7915216081521728, 'Total loss': 0.7915216081521728} | train loss {'Reaction outcome loss': 0.8231705597468785, 'Total loss': 0.8231705597468785}
2022-11-18 03:23:47,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:47,110 INFO:     Epoch: 59
2022-11-18 03:23:47,881 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7971880354664542, 'Total loss': 0.7971880354664542} | train loss {'Reaction outcome loss': 0.8198431311821451, 'Total loss': 0.8198431311821451}
2022-11-18 03:23:47,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:47,881 INFO:     Epoch: 60
2022-11-18 03:23:48,689 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8007265309041197, 'Total loss': 0.8007265309041197} | train loss {'Reaction outcome loss': 0.826828397171838, 'Total loss': 0.826828397171838}
2022-11-18 03:23:48,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:48,690 INFO:     Epoch: 61
2022-11-18 03:23:49,521 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7924886264584281, 'Total loss': 0.7924886264584281} | train loss {'Reaction outcome loss': 0.8265458441510493, 'Total loss': 0.8265458441510493}
2022-11-18 03:23:49,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:49,521 INFO:     Epoch: 62
2022-11-18 03:23:50,314 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8038502145897258, 'Total loss': 0.8038502145897258} | train loss {'Reaction outcome loss': 0.8269846945392842, 'Total loss': 0.8269846945392842}
2022-11-18 03:23:50,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:50,314 INFO:     Epoch: 63
2022-11-18 03:23:51,116 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8155704967000268, 'Total loss': 0.8155704967000268} | train loss {'Reaction outcome loss': 0.8232204401979641, 'Total loss': 0.8232204401979641}
2022-11-18 03:23:51,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:51,116 INFO:     Epoch: 64
2022-11-18 03:23:51,904 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8065511604601686, 'Total loss': 0.8065511604601686} | train loss {'Reaction outcome loss': 0.8275125014538668, 'Total loss': 0.8275125014538668}
2022-11-18 03:23:51,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:51,904 INFO:     Epoch: 65
2022-11-18 03:23:52,689 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7941632873632691, 'Total loss': 0.7941632873632691} | train loss {'Reaction outcome loss': 0.8251571427802651, 'Total loss': 0.8251571427802651}
2022-11-18 03:23:52,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:52,690 INFO:     Epoch: 66
2022-11-18 03:23:53,569 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8133015070449222, 'Total loss': 0.8133015070449222} | train loss {'Reaction outcome loss': 0.825382665468722, 'Total loss': 0.825382665468722}
2022-11-18 03:23:53,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:53,569 INFO:     Epoch: 67
2022-11-18 03:23:54,379 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7937729087742892, 'Total loss': 0.7937729087742892} | train loss {'Reaction outcome loss': 0.8306515904105439, 'Total loss': 0.8306515904105439}
2022-11-18 03:23:54,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:54,379 INFO:     Epoch: 68
2022-11-18 03:23:55,172 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.822430740703236, 'Total loss': 0.822430740703236} | train loss {'Reaction outcome loss': 0.8263720851771685, 'Total loss': 0.8263720851771685}
2022-11-18 03:23:55,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:55,172 INFO:     Epoch: 69
2022-11-18 03:23:55,976 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7899589511481199, 'Total loss': 0.7899589511481199} | train loss {'Reaction outcome loss': 0.8261319735828712, 'Total loss': 0.8261319735828712}
2022-11-18 03:23:55,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:55,976 INFO:     Epoch: 70
2022-11-18 03:23:56,774 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7987738028168678, 'Total loss': 0.7987738028168678} | train loss {'Reaction outcome loss': 0.8279417101217776, 'Total loss': 0.8279417101217776}
2022-11-18 03:23:56,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:56,774 INFO:     Epoch: 71
2022-11-18 03:23:57,555 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7995788048614155, 'Total loss': 0.7995788048614155} | train loss {'Reaction outcome loss': 0.8274766392853795, 'Total loss': 0.8274766392853795}
2022-11-18 03:23:57,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:57,556 INFO:     Epoch: 72
2022-11-18 03:23:58,356 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8087572279301557, 'Total loss': 0.8087572279301557} | train loss {'Reaction outcome loss': 0.8227209672635916, 'Total loss': 0.8227209672635916}
2022-11-18 03:23:58,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:58,356 INFO:     Epoch: 73
2022-11-18 03:23:59,190 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8154256689277563, 'Total loss': 0.8154256689277563} | train loss {'Reaction outcome loss': 0.8275304108249898, 'Total loss': 0.8275304108249898}
2022-11-18 03:23:59,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:23:59,190 INFO:     Epoch: 74
2022-11-18 03:24:00,014 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7853285101327029, 'Total loss': 0.7853285101327029} | train loss {'Reaction outcome loss': 0.8250683277237172, 'Total loss': 0.8250683277237172}
2022-11-18 03:24:00,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:00,014 INFO:     Epoch: 75
2022-11-18 03:24:00,831 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8068655261939223, 'Total loss': 0.8068655261939223} | train loss {'Reaction outcome loss': 0.8243214457618947, 'Total loss': 0.8243214457618947}
2022-11-18 03:24:00,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:00,831 INFO:     Epoch: 76
2022-11-18 03:24:01,626 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7960494688966058, 'Total loss': 0.7960494688966058} | train loss {'Reaction outcome loss': 0.8217773463044847, 'Total loss': 0.8217773463044847}
2022-11-18 03:24:01,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:01,627 INFO:     Epoch: 77
2022-11-18 03:24:02,436 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7825386273590001, 'Total loss': 0.7825386273590001} | train loss {'Reaction outcome loss': 0.8288337997027806, 'Total loss': 0.8288337997027806}
2022-11-18 03:24:02,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:02,436 INFO:     Epoch: 78
2022-11-18 03:24:03,255 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8008390140127052, 'Total loss': 0.8008390140127052} | train loss {'Reaction outcome loss': 0.8223761733697386, 'Total loss': 0.8223761733697386}
2022-11-18 03:24:03,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:03,256 INFO:     Epoch: 79
2022-11-18 03:24:04,077 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7904168577356772, 'Total loss': 0.7904168577356772} | train loss {'Reaction outcome loss': 0.8225385207302717, 'Total loss': 0.8225385207302717}
2022-11-18 03:24:04,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:04,078 INFO:     Epoch: 80
2022-11-18 03:24:04,884 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8022774336012927, 'Total loss': 0.8022774336012927} | train loss {'Reaction outcome loss': 0.8271184759480613, 'Total loss': 0.8271184759480613}
2022-11-18 03:24:04,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:04,885 INFO:     Epoch: 81
2022-11-18 03:24:05,683 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8344857807863842, 'Total loss': 0.8344857807863842} | train loss {'Reaction outcome loss': 0.8261722842041327, 'Total loss': 0.8261722842041327}
2022-11-18 03:24:05,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:05,683 INFO:     Epoch: 82
2022-11-18 03:24:06,484 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8251818838444623, 'Total loss': 0.8251818838444623} | train loss {'Reaction outcome loss': 0.8306484533815968, 'Total loss': 0.8306484533815968}
2022-11-18 03:24:06,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:06,484 INFO:     Epoch: 83
2022-11-18 03:24:07,298 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8201002708890222, 'Total loss': 0.8201002708890222} | train loss {'Reaction outcome loss': 0.8304989646892158, 'Total loss': 0.8304989646892158}
2022-11-18 03:24:07,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:07,298 INFO:     Epoch: 84
2022-11-18 03:24:08,108 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7791839255528017, 'Total loss': 0.7791839255528017} | train loss {'Reaction outcome loss': 0.8274550007314098, 'Total loss': 0.8274550007314098}
2022-11-18 03:24:08,108 INFO:     Found new best model at epoch 84
2022-11-18 03:24:08,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:08,109 INFO:     Epoch: 85
2022-11-18 03:24:08,902 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8388989439064806, 'Total loss': 0.8388989439064806} | train loss {'Reaction outcome loss': 0.8222892994783363, 'Total loss': 0.8222892994783363}
2022-11-18 03:24:08,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:08,902 INFO:     Epoch: 86
2022-11-18 03:24:09,713 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7962847426533699, 'Total loss': 0.7962847426533699} | train loss {'Reaction outcome loss': 0.8200690242708946, 'Total loss': 0.8200690242708946}
2022-11-18 03:24:09,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:09,714 INFO:     Epoch: 87
2022-11-18 03:24:10,489 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.834475885738026, 'Total loss': 0.834475885738026} | train loss {'Reaction outcome loss': 0.823786633476919, 'Total loss': 0.823786633476919}
2022-11-18 03:24:10,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:10,489 INFO:     Epoch: 88
2022-11-18 03:24:11,348 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8184336843815717, 'Total loss': 0.8184336843815717} | train loss {'Reaction outcome loss': 0.8277140596691444, 'Total loss': 0.8277140596691444}
2022-11-18 03:24:11,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:11,349 INFO:     Epoch: 89
2022-11-18 03:24:12,166 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7970719107172706, 'Total loss': 0.7970719107172706} | train loss {'Reaction outcome loss': 0.8291137256184403, 'Total loss': 0.8291137256184403}
2022-11-18 03:24:12,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:12,166 INFO:     Epoch: 90
2022-11-18 03:24:12,958 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.816299709406766, 'Total loss': 0.816299709406766} | train loss {'Reaction outcome loss': 0.8247187813934015, 'Total loss': 0.8247187813934015}
2022-11-18 03:24:12,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:12,958 INFO:     Epoch: 91
2022-11-18 03:24:13,744 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.779217123307965, 'Total loss': 0.779217123307965} | train loss {'Reaction outcome loss': 0.8260935583893134, 'Total loss': 0.8260935583893134}
2022-11-18 03:24:13,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:13,744 INFO:     Epoch: 92
2022-11-18 03:24:14,570 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8034612380645492, 'Total loss': 0.8034612380645492} | train loss {'Reaction outcome loss': 0.8213114066999786, 'Total loss': 0.8213114066999786}
2022-11-18 03:24:14,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:14,570 INFO:     Epoch: 93
2022-11-18 03:24:15,344 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8197631551460787, 'Total loss': 0.8197631551460787} | train loss {'Reaction outcome loss': 0.8272359384565937, 'Total loss': 0.8272359384565937}
2022-11-18 03:24:15,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:15,344 INFO:     Epoch: 94
2022-11-18 03:24:16,136 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.817349680445411, 'Total loss': 0.817349680445411} | train loss {'Reaction outcome loss': 0.8248985895088741, 'Total loss': 0.8248985895088741}
2022-11-18 03:24:16,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:16,136 INFO:     Epoch: 95
2022-11-18 03:24:16,932 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7823782685128126, 'Total loss': 0.7823782685128126} | train loss {'Reaction outcome loss': 0.8239783538239343, 'Total loss': 0.8239783538239343}
2022-11-18 03:24:16,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:16,933 INFO:     Epoch: 96
2022-11-18 03:24:17,744 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7976691363887354, 'Total loss': 0.7976691363887354} | train loss {'Reaction outcome loss': 0.8302006421648727, 'Total loss': 0.8302006421648727}
2022-11-18 03:24:17,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:17,744 INFO:     Epoch: 97
2022-11-18 03:24:18,575 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8035239509560845, 'Total loss': 0.8035239509560845} | train loss {'Reaction outcome loss': 0.8230823324651134, 'Total loss': 0.8230823324651134}
2022-11-18 03:24:18,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:18,575 INFO:     Epoch: 98
2022-11-18 03:24:19,387 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7996598041870377, 'Total loss': 0.7996598041870377} | train loss {'Reaction outcome loss': 0.8269980155691808, 'Total loss': 0.8269980155691808}
2022-11-18 03:24:19,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:19,388 INFO:     Epoch: 99
2022-11-18 03:24:20,191 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8116915852508761, 'Total loss': 0.8116915852508761} | train loss {'Reaction outcome loss': 0.8202014482751184, 'Total loss': 0.8202014482751184}
2022-11-18 03:24:20,191 INFO:     Best model found after epoch 85 of 100.
2022-11-18 03:24:20,191 INFO:   Done with stage: TRAINING
2022-11-18 03:24:20,191 INFO:   Starting stage: EVALUATION
2022-11-18 03:24:20,319 INFO:   Done with stage: EVALUATION
2022-11-18 03:24:20,319 INFO:   Leaving out SEQ value Fold_2
2022-11-18 03:24:20,332 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:24:20,333 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:24:21,007 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:24:21,007 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:24:21,076 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:24:21,076 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:24:21,077 INFO:     No hyperparam tuning for this model
2022-11-18 03:24:21,077 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:24:21,077 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:24:21,077 INFO:     None feature selector for col prot
2022-11-18 03:24:21,078 INFO:     None feature selector for col prot
2022-11-18 03:24:21,078 INFO:     None feature selector for col prot
2022-11-18 03:24:21,078 INFO:     None feature selector for col chem
2022-11-18 03:24:21,078 INFO:     None feature selector for col chem
2022-11-18 03:24:21,078 INFO:     None feature selector for col chem
2022-11-18 03:24:21,079 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:24:21,079 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:24:21,080 INFO:     Number of params in model 168571
2022-11-18 03:24:21,083 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:24:21,083 INFO:   Starting stage: TRAINING
2022-11-18 03:24:21,141 INFO:     Val loss before train {'Reaction outcome loss': 1.0122364122759213, 'Total loss': 1.0122364122759213}
2022-11-18 03:24:21,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:21,142 INFO:     Epoch: 0
2022-11-18 03:24:21,946 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8877517445520922, 'Total loss': 0.8877517445520922} | train loss {'Reaction outcome loss': 0.8863590499650129, 'Total loss': 0.8863590499650129}
2022-11-18 03:24:21,946 INFO:     Found new best model at epoch 0
2022-11-18 03:24:21,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:21,947 INFO:     Epoch: 1
2022-11-18 03:24:22,769 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8521339866248044, 'Total loss': 0.8521339866248044} | train loss {'Reaction outcome loss': 0.8566637559216997, 'Total loss': 0.8566637559216997}
2022-11-18 03:24:22,769 INFO:     Found new best model at epoch 1
2022-11-18 03:24:22,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:22,770 INFO:     Epoch: 2
2022-11-18 03:24:23,607 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8498416962948713, 'Total loss': 0.8498416962948713} | train loss {'Reaction outcome loss': 0.8388487107840626, 'Total loss': 0.8388487107840626}
2022-11-18 03:24:23,608 INFO:     Found new best model at epoch 2
2022-11-18 03:24:23,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:23,608 INFO:     Epoch: 3
2022-11-18 03:24:24,456 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8295946547930891, 'Total loss': 0.8295946547930891} | train loss {'Reaction outcome loss': 0.8331920957034417, 'Total loss': 0.8331920957034417}
2022-11-18 03:24:24,456 INFO:     Found new best model at epoch 3
2022-11-18 03:24:24,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:24,457 INFO:     Epoch: 4
2022-11-18 03:24:25,270 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8682561225511811, 'Total loss': 0.8682561225511811} | train loss {'Reaction outcome loss': 0.8435493776431451, 'Total loss': 0.8435493776431451}
2022-11-18 03:24:25,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:25,270 INFO:     Epoch: 5
2022-11-18 03:24:26,120 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8386531594124708, 'Total loss': 0.8386531594124708} | train loss {'Reaction outcome loss': 0.8337176831868979, 'Total loss': 0.8337176831868979}
2022-11-18 03:24:26,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:26,120 INFO:     Epoch: 6
2022-11-18 03:24:26,926 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.838010083545338, 'Total loss': 0.838010083545338} | train loss {'Reaction outcome loss': 0.8331453003864057, 'Total loss': 0.8331453003864057}
2022-11-18 03:24:26,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:26,926 INFO:     Epoch: 7
2022-11-18 03:24:27,767 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8458466136997397, 'Total loss': 0.8458466136997397} | train loss {'Reaction outcome loss': 0.8250344799235765, 'Total loss': 0.8250344799235765}
2022-11-18 03:24:27,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:27,768 INFO:     Epoch: 8
2022-11-18 03:24:28,608 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8308053944598545, 'Total loss': 0.8308053944598545} | train loss {'Reaction outcome loss': 0.826156608971507, 'Total loss': 0.826156608971507}
2022-11-18 03:24:28,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:28,608 INFO:     Epoch: 9
2022-11-18 03:24:29,420 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8456870595162566, 'Total loss': 0.8456870595162566} | train loss {'Reaction outcome loss': 0.8297180125587865, 'Total loss': 0.8297180125587865}
2022-11-18 03:24:29,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:29,421 INFO:     Epoch: 10
2022-11-18 03:24:30,232 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8438143594698473, 'Total loss': 0.8438143594698473} | train loss {'Reaction outcome loss': 0.8225838273220699, 'Total loss': 0.8225838273220699}
2022-11-18 03:24:30,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:30,233 INFO:     Epoch: 11
2022-11-18 03:24:30,994 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8319899758154695, 'Total loss': 0.8319899758154695} | train loss {'Reaction outcome loss': 0.8168498550651044, 'Total loss': 0.8168498550651044}
2022-11-18 03:24:30,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:30,995 INFO:     Epoch: 12
2022-11-18 03:24:31,804 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8221661380746148, 'Total loss': 0.8221661380746148} | train loss {'Reaction outcome loss': 0.8151540816855817, 'Total loss': 0.8151540816855817}
2022-11-18 03:24:31,804 INFO:     Found new best model at epoch 12
2022-11-18 03:24:31,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:31,805 INFO:     Epoch: 13
2022-11-18 03:24:32,615 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8298881609331478, 'Total loss': 0.8298881609331478} | train loss {'Reaction outcome loss': 0.8211839470544807, 'Total loss': 0.8211839470544807}
2022-11-18 03:24:32,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:32,615 INFO:     Epoch: 14
2022-11-18 03:24:33,450 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8404050753875212, 'Total loss': 0.8404050753875212} | train loss {'Reaction outcome loss': 0.8143738586651651, 'Total loss': 0.8143738586651651}
2022-11-18 03:24:33,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:33,451 INFO:     Epoch: 15
2022-11-18 03:24:34,240 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8283132450147108, 'Total loss': 0.8283132450147108} | train loss {'Reaction outcome loss': 0.8210815118874616, 'Total loss': 0.8210815118874616}
2022-11-18 03:24:34,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:34,241 INFO:     Epoch: 16
2022-11-18 03:24:35,032 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8158280443061482, 'Total loss': 0.8158280443061482} | train loss {'Reaction outcome loss': 0.8172814572750315, 'Total loss': 0.8172814572750315}
2022-11-18 03:24:35,032 INFO:     Found new best model at epoch 16
2022-11-18 03:24:35,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:35,033 INFO:     Epoch: 17
2022-11-18 03:24:35,802 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8252760036425157, 'Total loss': 0.8252760036425157} | train loss {'Reaction outcome loss': 0.8247175137041068, 'Total loss': 0.8247175137041068}
2022-11-18 03:24:35,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:35,802 INFO:     Epoch: 18
2022-11-18 03:24:36,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8207057667049494, 'Total loss': 0.8207057667049494} | train loss {'Reaction outcome loss': 0.8202197825619084, 'Total loss': 0.8202197825619084}
2022-11-18 03:24:36,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:36,569 INFO:     Epoch: 19
2022-11-18 03:24:37,361 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8250437764958902, 'Total loss': 0.8250437764958902} | train loss {'Reaction outcome loss': 0.8219032880024388, 'Total loss': 0.8219032880024388}
2022-11-18 03:24:37,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:37,362 INFO:     Epoch: 20
2022-11-18 03:24:38,137 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8172956583174792, 'Total loss': 0.8172956583174792} | train loss {'Reaction outcome loss': 0.8119075908080527, 'Total loss': 0.8119075908080527}
2022-11-18 03:24:38,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:38,138 INFO:     Epoch: 21
2022-11-18 03:24:38,951 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8219322799281641, 'Total loss': 0.8219322799281641} | train loss {'Reaction outcome loss': 0.8150356678586257, 'Total loss': 0.8150356678586257}
2022-11-18 03:24:38,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:38,951 INFO:     Epoch: 22
2022-11-18 03:24:39,714 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8437136763876135, 'Total loss': 0.8437136763876135} | train loss {'Reaction outcome loss': 0.8161570386667001, 'Total loss': 0.8161570386667001}
2022-11-18 03:24:39,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:39,714 INFO:     Epoch: 23
2022-11-18 03:24:40,516 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.853064473379742, 'Total loss': 0.853064473379742} | train loss {'Reaction outcome loss': 0.8163090336177996, 'Total loss': 0.8163090336177996}
2022-11-18 03:24:40,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:40,516 INFO:     Epoch: 24
2022-11-18 03:24:41,292 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8455576192248951, 'Total loss': 0.8455576192248951} | train loss {'Reaction outcome loss': 0.8232077547171821, 'Total loss': 0.8232077547171821}
2022-11-18 03:24:41,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:41,292 INFO:     Epoch: 25
2022-11-18 03:24:42,086 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8156997412443161, 'Total loss': 0.8156997412443161} | train loss {'Reaction outcome loss': 0.8291031586737768, 'Total loss': 0.8291031586737768}
2022-11-18 03:24:42,086 INFO:     Found new best model at epoch 25
2022-11-18 03:24:42,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:42,087 INFO:     Epoch: 26
2022-11-18 03:24:42,862 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8491270379586653, 'Total loss': 0.8491270379586653} | train loss {'Reaction outcome loss': 0.8190234952610032, 'Total loss': 0.8190234952610032}
2022-11-18 03:24:42,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:42,863 INFO:     Epoch: 27
2022-11-18 03:24:43,636 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8271805772727187, 'Total loss': 0.8271805772727187} | train loss {'Reaction outcome loss': 0.8162889361743503, 'Total loss': 0.8162889361743503}
2022-11-18 03:24:43,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:43,636 INFO:     Epoch: 28
2022-11-18 03:24:44,412 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8216168433427811, 'Total loss': 0.8216168433427811} | train loss {'Reaction outcome loss': 0.8128030791215086, 'Total loss': 0.8128030791215086}
2022-11-18 03:24:44,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:44,412 INFO:     Epoch: 29
2022-11-18 03:24:45,199 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8165775991298936, 'Total loss': 0.8165775991298936} | train loss {'Reaction outcome loss': 0.8128338966232079, 'Total loss': 0.8128338966232079}
2022-11-18 03:24:45,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:45,200 INFO:     Epoch: 30
2022-11-18 03:24:45,993 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8232274915684353, 'Total loss': 0.8232274915684353} | train loss {'Reaction outcome loss': 0.8170035434396643, 'Total loss': 0.8170035434396643}
2022-11-18 03:24:45,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:45,994 INFO:     Epoch: 31
2022-11-18 03:24:46,784 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8127478327263485, 'Total loss': 0.8127478327263485} | train loss {'Reaction outcome loss': 0.8187543448166326, 'Total loss': 0.8187543448166326}
2022-11-18 03:24:46,785 INFO:     Found new best model at epoch 31
2022-11-18 03:24:46,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:46,786 INFO:     Epoch: 32
2022-11-18 03:24:47,554 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.851321475749666, 'Total loss': 0.851321475749666} | train loss {'Reaction outcome loss': 0.8131241745915008, 'Total loss': 0.8131241745915008}
2022-11-18 03:24:47,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:47,554 INFO:     Epoch: 33
2022-11-18 03:24:48,350 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8262848434123126, 'Total loss': 0.8262848434123126} | train loss {'Reaction outcome loss': 0.8125511530620849, 'Total loss': 0.8125511530620849}
2022-11-18 03:24:48,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:48,350 INFO:     Epoch: 34
2022-11-18 03:24:49,138 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8100906569849361, 'Total loss': 0.8100906569849361} | train loss {'Reaction outcome loss': 0.8216623084747839, 'Total loss': 0.8216623084747839}
2022-11-18 03:24:49,138 INFO:     Found new best model at epoch 34
2022-11-18 03:24:49,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:49,139 INFO:     Epoch: 35
2022-11-18 03:24:49,919 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.840622905980457, 'Total loss': 0.840622905980457} | train loss {'Reaction outcome loss': 0.817454385130029, 'Total loss': 0.817454385130029}
2022-11-18 03:24:49,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:49,919 INFO:     Epoch: 36
2022-11-18 03:24:50,696 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8294612535021522, 'Total loss': 0.8294612535021522} | train loss {'Reaction outcome loss': 0.8154854216435661, 'Total loss': 0.8154854216435661}
2022-11-18 03:24:50,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:50,696 INFO:     Epoch: 37
2022-11-18 03:24:51,478 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8192773048173297, 'Total loss': 0.8192773048173297} | train loss {'Reaction outcome loss': 0.8095341242759334, 'Total loss': 0.8095341242759334}
2022-11-18 03:24:51,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:51,478 INFO:     Epoch: 38
2022-11-18 03:24:52,264 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8297089758244428, 'Total loss': 0.8297089758244428} | train loss {'Reaction outcome loss': 0.8153794401811685, 'Total loss': 0.8153794401811685}
2022-11-18 03:24:52,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:52,265 INFO:     Epoch: 39
2022-11-18 03:24:53,093 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8240653466094624, 'Total loss': 0.8240653466094624} | train loss {'Reaction outcome loss': 0.8179583013781652, 'Total loss': 0.8179583013781652}
2022-11-18 03:24:53,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:53,094 INFO:     Epoch: 40
2022-11-18 03:24:53,880 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8110151148655198, 'Total loss': 0.8110151148655198} | train loss {'Reaction outcome loss': 0.8131706981282485, 'Total loss': 0.8131706981282485}
2022-11-18 03:24:53,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:53,880 INFO:     Epoch: 41
2022-11-18 03:24:54,674 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8217273489995436, 'Total loss': 0.8217273489995436} | train loss {'Reaction outcome loss': 0.8080020964386975, 'Total loss': 0.8080020964386975}
2022-11-18 03:24:54,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:54,675 INFO:     Epoch: 42
2022-11-18 03:24:55,449 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8407720015807585, 'Total loss': 0.8407720015807585} | train loss {'Reaction outcome loss': 0.8125057995078052, 'Total loss': 0.8125057995078052}
2022-11-18 03:24:55,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:55,450 INFO:     Epoch: 43
2022-11-18 03:24:56,238 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8154296245087277, 'Total loss': 0.8154296245087277} | train loss {'Reaction outcome loss': 0.8126376930337685, 'Total loss': 0.8126376930337685}
2022-11-18 03:24:56,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:56,238 INFO:     Epoch: 44
2022-11-18 03:24:57,017 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8195553984154355, 'Total loss': 0.8195553984154355} | train loss {'Reaction outcome loss': 0.8109704100409982, 'Total loss': 0.8109704100409982}
2022-11-18 03:24:57,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:57,017 INFO:     Epoch: 45
2022-11-18 03:24:57,819 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8248109478842128, 'Total loss': 0.8248109478842128} | train loss {'Reaction outcome loss': 0.8184141403267741, 'Total loss': 0.8184141403267741}
2022-11-18 03:24:57,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:57,819 INFO:     Epoch: 46
2022-11-18 03:24:58,614 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8211275921626524, 'Total loss': 0.8211275921626524} | train loss {'Reaction outcome loss': 0.8106517029194696, 'Total loss': 0.8106517029194696}
2022-11-18 03:24:58,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:58,614 INFO:     Epoch: 47
2022-11-18 03:24:59,390 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.814954316074198, 'Total loss': 0.814954316074198} | train loss {'Reaction outcome loss': 0.8173144966484565, 'Total loss': 0.8173144966484565}
2022-11-18 03:24:59,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:24:59,390 INFO:     Epoch: 48
2022-11-18 03:25:00,160 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8155721107667143, 'Total loss': 0.8155721107667143} | train loss {'Reaction outcome loss': 0.8119024942037065, 'Total loss': 0.8119024942037065}
2022-11-18 03:25:00,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:00,161 INFO:     Epoch: 49
2022-11-18 03:25:00,945 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8233381902629678, 'Total loss': 0.8233381902629678} | train loss {'Reaction outcome loss': 0.80570049963982, 'Total loss': 0.80570049963982}
2022-11-18 03:25:00,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:00,945 INFO:     Epoch: 50
2022-11-18 03:25:01,734 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8487906767563387, 'Total loss': 0.8487906767563387} | train loss {'Reaction outcome loss': 0.8077538696377866, 'Total loss': 0.8077538696377866}
2022-11-18 03:25:01,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:01,735 INFO:     Epoch: 51
2022-11-18 03:25:02,531 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8411885872483253, 'Total loss': 0.8411885872483253} | train loss {'Reaction outcome loss': 0.8151701305076661, 'Total loss': 0.8151701305076661}
2022-11-18 03:25:02,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:02,531 INFO:     Epoch: 52
2022-11-18 03:25:03,321 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.817036057060415, 'Total loss': 0.817036057060415} | train loss {'Reaction outcome loss': 0.810493661950414, 'Total loss': 0.810493661950414}
2022-11-18 03:25:03,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:03,321 INFO:     Epoch: 53
2022-11-18 03:25:04,094 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8556415668942712, 'Total loss': 0.8556415668942712} | train loss {'Reaction outcome loss': 0.8155777642601415, 'Total loss': 0.8155777642601415}
2022-11-18 03:25:04,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:04,094 INFO:     Epoch: 54
2022-11-18 03:25:04,908 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8549248447472398, 'Total loss': 0.8549248447472398} | train loss {'Reaction outcome loss': 0.8138915612871348, 'Total loss': 0.8138915612871348}
2022-11-18 03:25:04,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:04,908 INFO:     Epoch: 55
2022-11-18 03:25:05,715 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8168879225850105, 'Total loss': 0.8168879225850105} | train loss {'Reaction outcome loss': 0.8143810158075109, 'Total loss': 0.8143810158075109}
2022-11-18 03:25:05,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:05,715 INFO:     Epoch: 56
2022-11-18 03:25:06,504 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.845888849009167, 'Total loss': 0.845888849009167} | train loss {'Reaction outcome loss': 0.810855649381514, 'Total loss': 0.810855649381514}
2022-11-18 03:25:06,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:06,504 INFO:     Epoch: 57
2022-11-18 03:25:07,283 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8193680887872522, 'Total loss': 0.8193680887872522} | train loss {'Reaction outcome loss': 0.806832788444241, 'Total loss': 0.806832788444241}
2022-11-18 03:25:07,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:07,285 INFO:     Epoch: 58
2022-11-18 03:25:08,073 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8154481283643029, 'Total loss': 0.8154481283643029} | train loss {'Reaction outcome loss': 0.8099449282956992, 'Total loss': 0.8099449282956992}
2022-11-18 03:25:08,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:08,074 INFO:     Epoch: 59
2022-11-18 03:25:08,886 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8302867304195057, 'Total loss': 0.8302867304195057} | train loss {'Reaction outcome loss': 0.8154964217772851, 'Total loss': 0.8154964217772851}
2022-11-18 03:25:08,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:08,886 INFO:     Epoch: 60
2022-11-18 03:25:09,707 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8201248740608041, 'Total loss': 0.8201248740608041} | train loss {'Reaction outcome loss': 0.8147947750080694, 'Total loss': 0.8147947750080694}
2022-11-18 03:25:09,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:09,707 INFO:     Epoch: 61
2022-11-18 03:25:10,523 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8190528540448709, 'Total loss': 0.8190528540448709} | train loss {'Reaction outcome loss': 0.8078128142878112, 'Total loss': 0.8078128142878112}
2022-11-18 03:25:10,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:10,523 INFO:     Epoch: 62
2022-11-18 03:25:11,340 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8453867482868108, 'Total loss': 0.8453867482868108} | train loss {'Reaction outcome loss': 0.8145792121105349, 'Total loss': 0.8145792121105349}
2022-11-18 03:25:11,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:11,340 INFO:     Epoch: 63
2022-11-18 03:25:12,138 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8416358191858638, 'Total loss': 0.8416358191858638} | train loss {'Reaction outcome loss': 0.8245653519746263, 'Total loss': 0.8245653519746263}
2022-11-18 03:25:12,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:12,139 INFO:     Epoch: 64
2022-11-18 03:25:12,950 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8162021989172156, 'Total loss': 0.8162021989172156} | train loss {'Reaction outcome loss': 0.8145369865030412, 'Total loss': 0.8145369865030412}
2022-11-18 03:25:12,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:12,950 INFO:     Epoch: 65
2022-11-18 03:25:13,751 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8173106983304024, 'Total loss': 0.8173106983304024} | train loss {'Reaction outcome loss': 0.8067983793102296, 'Total loss': 0.8067983793102296}
2022-11-18 03:25:13,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:13,752 INFO:     Epoch: 66
2022-11-18 03:25:14,537 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.828671855005351, 'Total loss': 0.828671855005351} | train loss {'Reaction outcome loss': 0.8204493368202858, 'Total loss': 0.8204493368202858}
2022-11-18 03:25:14,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:14,537 INFO:     Epoch: 67
2022-11-18 03:25:15,359 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8398497389121489, 'Total loss': 0.8398497389121489} | train loss {'Reaction outcome loss': 0.8146394315036202, 'Total loss': 0.8146394315036202}
2022-11-18 03:25:15,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:15,359 INFO:     Epoch: 68
2022-11-18 03:25:16,212 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8459162820469249, 'Total loss': 0.8459162820469249} | train loss {'Reaction outcome loss': 0.8131464471821843, 'Total loss': 0.8131464471821843}
2022-11-18 03:25:16,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:16,213 INFO:     Epoch: 69
2022-11-18 03:25:17,041 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8438846414739435, 'Total loss': 0.8438846414739435} | train loss {'Reaction outcome loss': 0.8212507878720519, 'Total loss': 0.8212507878720519}
2022-11-18 03:25:17,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:17,041 INFO:     Epoch: 70
2022-11-18 03:25:17,866 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8194410834800113, 'Total loss': 0.8194410834800113} | train loss {'Reaction outcome loss': 0.8120790281698771, 'Total loss': 0.8120790281698771}
2022-11-18 03:25:17,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:17,866 INFO:     Epoch: 71
2022-11-18 03:25:18,686 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.826263539493084, 'Total loss': 0.826263539493084} | train loss {'Reaction outcome loss': 0.8243175608667768, 'Total loss': 0.8243175608667768}
2022-11-18 03:25:18,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:18,686 INFO:     Epoch: 72
2022-11-18 03:25:19,495 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8327886990525506, 'Total loss': 0.8327886990525506} | train loss {'Reaction outcome loss': 0.8185608012956164, 'Total loss': 0.8185608012956164}
2022-11-18 03:25:19,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:19,495 INFO:     Epoch: 73
2022-11-18 03:25:20,271 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8112716742537238, 'Total loss': 0.8112716742537238} | train loss {'Reaction outcome loss': 0.8086633262816469, 'Total loss': 0.8086633262816469}
2022-11-18 03:25:20,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:20,272 INFO:     Epoch: 74
2022-11-18 03:25:21,099 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8255861401557922, 'Total loss': 0.8255861401557922} | train loss {'Reaction outcome loss': 0.8114144452187696, 'Total loss': 0.8114144452187696}
2022-11-18 03:25:21,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:21,099 INFO:     Epoch: 75
2022-11-18 03:25:21,931 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8249854906038805, 'Total loss': 0.8249854906038805} | train loss {'Reaction outcome loss': 0.8093914488549174, 'Total loss': 0.8093914488549174}
2022-11-18 03:25:21,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:21,931 INFO:     Epoch: 76
2022-11-18 03:25:22,728 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8138153939084574, 'Total loss': 0.8138153939084574} | train loss {'Reaction outcome loss': 0.8089220942514628, 'Total loss': 0.8089220942514628}
2022-11-18 03:25:22,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:22,728 INFO:     Epoch: 77
2022-11-18 03:25:23,542 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8173931782895868, 'Total loss': 0.8173931782895868} | train loss {'Reaction outcome loss': 0.8057714881684616, 'Total loss': 0.8057714881684616}
2022-11-18 03:25:23,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:23,542 INFO:     Epoch: 78
2022-11-18 03:25:24,369 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8302490372549404, 'Total loss': 0.8302490372549404} | train loss {'Reaction outcome loss': 0.8148446601894703, 'Total loss': 0.8148446601894703}
2022-11-18 03:25:24,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:24,369 INFO:     Epoch: 79
2022-11-18 03:25:25,190 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8161829750646244, 'Total loss': 0.8161829750646244} | train loss {'Reaction outcome loss': 0.8141257388871691, 'Total loss': 0.8141257388871691}
2022-11-18 03:25:25,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:25,191 INFO:     Epoch: 80
2022-11-18 03:25:25,968 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.819004317576235, 'Total loss': 0.819004317576235} | train loss {'Reaction outcome loss': 0.8091338404458062, 'Total loss': 0.8091338404458062}
2022-11-18 03:25:25,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:25,969 INFO:     Epoch: 81
2022-11-18 03:25:26,799 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8151296038519252, 'Total loss': 0.8151296038519252} | train loss {'Reaction outcome loss': 0.80964838414781, 'Total loss': 0.80964838414781}
2022-11-18 03:25:26,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:26,800 INFO:     Epoch: 82
2022-11-18 03:25:27,592 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8246136057105932, 'Total loss': 0.8246136057105932} | train loss {'Reaction outcome loss': 0.8223851332780321, 'Total loss': 0.8223851332780321}
2022-11-18 03:25:27,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:27,593 INFO:     Epoch: 83
2022-11-18 03:25:28,415 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8089721290902658, 'Total loss': 0.8089721290902658} | train loss {'Reaction outcome loss': 0.8124669214733217, 'Total loss': 0.8124669214733217}
2022-11-18 03:25:28,415 INFO:     Found new best model at epoch 83
2022-11-18 03:25:28,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:28,416 INFO:     Epoch: 84
2022-11-18 03:25:29,223 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8067737336863171, 'Total loss': 0.8067737336863171} | train loss {'Reaction outcome loss': 0.8169274477340914, 'Total loss': 0.8169274477340914}
2022-11-18 03:25:29,223 INFO:     Found new best model at epoch 84
2022-11-18 03:25:29,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:29,224 INFO:     Epoch: 85
2022-11-18 03:25:30,041 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8398553119464354, 'Total loss': 0.8398553119464354} | train loss {'Reaction outcome loss': 0.8165292465976375, 'Total loss': 0.8165292465976375}
2022-11-18 03:25:30,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:30,042 INFO:     Epoch: 86
2022-11-18 03:25:30,842 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8242668970064684, 'Total loss': 0.8242668970064684} | train loss {'Reaction outcome loss': 0.8267037428101065, 'Total loss': 0.8267037428101065}
2022-11-18 03:25:30,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:30,843 INFO:     Epoch: 87
2022-11-18 03:25:31,611 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8161956911737268, 'Total loss': 0.8161956911737268} | train loss {'Reaction outcome loss': 0.8132886972263275, 'Total loss': 0.8132886972263275}
2022-11-18 03:25:31,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:31,612 INFO:     Epoch: 88
2022-11-18 03:25:32,423 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8271503827788613, 'Total loss': 0.8271503827788613} | train loss {'Reaction outcome loss': 0.8116632295764892, 'Total loss': 0.8116632295764892}
2022-11-18 03:25:32,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:32,424 INFO:     Epoch: 89
2022-11-18 03:25:33,261 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8324621333317324, 'Total loss': 0.8324621333317324} | train loss {'Reaction outcome loss': 0.8191181797730295, 'Total loss': 0.8191181797730295}
2022-11-18 03:25:33,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:33,261 INFO:     Epoch: 90
2022-11-18 03:25:34,043 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8260561525821686, 'Total loss': 0.8260561525821686} | train loss {'Reaction outcome loss': 0.8096460800633015, 'Total loss': 0.8096460800633015}
2022-11-18 03:25:34,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:34,044 INFO:     Epoch: 91
2022-11-18 03:25:34,862 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.825717572461475, 'Total loss': 0.825717572461475} | train loss {'Reaction outcome loss': 0.8090839342549745, 'Total loss': 0.8090839342549745}
2022-11-18 03:25:34,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:34,862 INFO:     Epoch: 92
2022-11-18 03:25:35,655 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8125865879383954, 'Total loss': 0.8125865879383954} | train loss {'Reaction outcome loss': 0.8105129457195761, 'Total loss': 0.8105129457195761}
2022-11-18 03:25:35,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:35,663 INFO:     Epoch: 93
2022-11-18 03:25:36,517 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8297771709886465, 'Total loss': 0.8297771709886465} | train loss {'Reaction outcome loss': 0.8101054103630274, 'Total loss': 0.8101054103630274}
2022-11-18 03:25:36,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:36,517 INFO:     Epoch: 94
2022-11-18 03:25:37,327 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8629870902408253, 'Total loss': 0.8629870902408253} | train loss {'Reaction outcome loss': 0.8074894939899927, 'Total loss': 0.8074894939899927}
2022-11-18 03:25:37,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:37,327 INFO:     Epoch: 95
2022-11-18 03:25:38,113 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8177694922143762, 'Total loss': 0.8177694922143762} | train loss {'Reaction outcome loss': 0.8127080058520623, 'Total loss': 0.8127080058520623}
2022-11-18 03:25:38,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:38,114 INFO:     Epoch: 96
2022-11-18 03:25:38,920 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8315125568346544, 'Total loss': 0.8315125568346544} | train loss {'Reaction outcome loss': 0.8211259119182464, 'Total loss': 0.8211259119182464}
2022-11-18 03:25:38,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:38,922 INFO:     Epoch: 97
2022-11-18 03:25:39,718 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.834513321518898, 'Total loss': 0.834513321518898} | train loss {'Reaction outcome loss': 0.8191974192013142, 'Total loss': 0.8191974192013142}
2022-11-18 03:25:39,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:39,718 INFO:     Epoch: 98
2022-11-18 03:25:40,510 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8444747389717535, 'Total loss': 0.8444747389717535} | train loss {'Reaction outcome loss': 0.8124977282063681, 'Total loss': 0.8124977282063681}
2022-11-18 03:25:40,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:40,511 INFO:     Epoch: 99
2022-11-18 03:25:41,332 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8232289078560743, 'Total loss': 0.8232289078560743} | train loss {'Reaction outcome loss': 0.814020762725277, 'Total loss': 0.814020762725277}
2022-11-18 03:25:41,333 INFO:     Best model found after epoch 85 of 100.
2022-11-18 03:25:41,333 INFO:   Done with stage: TRAINING
2022-11-18 03:25:41,333 INFO:   Starting stage: EVALUATION
2022-11-18 03:25:41,456 INFO:   Done with stage: EVALUATION
2022-11-18 03:25:41,456 INFO:   Leaving out SEQ value Fold_3
2022-11-18 03:25:41,469 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:25:41,470 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:25:42,139 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:25:42,139 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:25:42,209 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:25:42,209 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:25:42,209 INFO:     No hyperparam tuning for this model
2022-11-18 03:25:42,209 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:25:42,209 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:25:42,210 INFO:     None feature selector for col prot
2022-11-18 03:25:42,210 INFO:     None feature selector for col prot
2022-11-18 03:25:42,210 INFO:     None feature selector for col prot
2022-11-18 03:25:42,211 INFO:     None feature selector for col chem
2022-11-18 03:25:42,211 INFO:     None feature selector for col chem
2022-11-18 03:25:42,211 INFO:     None feature selector for col chem
2022-11-18 03:25:42,211 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:25:42,211 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:25:42,212 INFO:     Number of params in model 168571
2022-11-18 03:25:42,215 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:25:42,216 INFO:   Starting stage: TRAINING
2022-11-18 03:25:42,273 INFO:     Val loss before train {'Reaction outcome loss': 1.0193268819288774, 'Total loss': 1.0193268819288774}
2022-11-18 03:25:42,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:42,274 INFO:     Epoch: 0
2022-11-18 03:25:43,076 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8760118633508682, 'Total loss': 0.8760118633508682} | train loss {'Reaction outcome loss': 0.876169984277926, 'Total loss': 0.876169984277926}
2022-11-18 03:25:43,076 INFO:     Found new best model at epoch 0
2022-11-18 03:25:43,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:43,077 INFO:     Epoch: 1
2022-11-18 03:25:43,899 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8699655112895098, 'Total loss': 0.8699655112895098} | train loss {'Reaction outcome loss': 0.8652625597922908, 'Total loss': 0.8652625597922908}
2022-11-18 03:25:43,899 INFO:     Found new best model at epoch 1
2022-11-18 03:25:43,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:43,900 INFO:     Epoch: 2
2022-11-18 03:25:44,700 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8359702026302164, 'Total loss': 0.8359702026302164} | train loss {'Reaction outcome loss': 0.8456077915936829, 'Total loss': 0.8456077915936829}
2022-11-18 03:25:44,700 INFO:     Found new best model at epoch 2
2022-11-18 03:25:44,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:44,700 INFO:     Epoch: 3
2022-11-18 03:25:45,487 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8480040525848215, 'Total loss': 0.8480040525848215} | train loss {'Reaction outcome loss': 0.84846182981966, 'Total loss': 0.84846182981966}
2022-11-18 03:25:45,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:45,488 INFO:     Epoch: 4
2022-11-18 03:25:46,291 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8158869560469281, 'Total loss': 0.8158869560469281} | train loss {'Reaction outcome loss': 0.840863621910574, 'Total loss': 0.840863621910574}
2022-11-18 03:25:46,291 INFO:     Found new best model at epoch 4
2022-11-18 03:25:46,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:46,292 INFO:     Epoch: 5
2022-11-18 03:25:47,107 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8503493023189631, 'Total loss': 0.8503493023189631} | train loss {'Reaction outcome loss': 0.8334166923997856, 'Total loss': 0.8334166923997856}
2022-11-18 03:25:47,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:47,107 INFO:     Epoch: 6
2022-11-18 03:25:47,890 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8457275331020355, 'Total loss': 0.8457275331020355} | train loss {'Reaction outcome loss': 0.8314342065620036, 'Total loss': 0.8314342065620036}
2022-11-18 03:25:47,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:47,890 INFO:     Epoch: 7
2022-11-18 03:25:48,707 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8266259919513356, 'Total loss': 0.8266259919513356} | train loss {'Reaction outcome loss': 0.8350841107397426, 'Total loss': 0.8350841107397426}
2022-11-18 03:25:48,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:48,707 INFO:     Epoch: 8
2022-11-18 03:25:49,479 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8233569765632803, 'Total loss': 0.8233569765632803} | train loss {'Reaction outcome loss': 0.8316095144401195, 'Total loss': 0.8316095144401195}
2022-11-18 03:25:49,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:49,479 INFO:     Epoch: 9
2022-11-18 03:25:50,249 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8333413180979815, 'Total loss': 0.8333413180979815} | train loss {'Reaction outcome loss': 0.8291981955047562, 'Total loss': 0.8291981955047562}
2022-11-18 03:25:50,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:50,249 INFO:     Epoch: 10
2022-11-18 03:25:51,054 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8214551467787136, 'Total loss': 0.8214551467787136} | train loss {'Reaction outcome loss': 0.8392405327756395, 'Total loss': 0.8392405327756395}
2022-11-18 03:25:51,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:51,054 INFO:     Epoch: 11
2022-11-18 03:25:51,879 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8251918811689724, 'Total loss': 0.8251918811689724} | train loss {'Reaction outcome loss': 0.8275853666940681, 'Total loss': 0.8275853666940681}
2022-11-18 03:25:51,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:51,879 INFO:     Epoch: 12
2022-11-18 03:25:52,674 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8203973499211398, 'Total loss': 0.8203973499211398} | train loss {'Reaction outcome loss': 0.823620803563701, 'Total loss': 0.823620803563701}
2022-11-18 03:25:52,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:52,674 INFO:     Epoch: 13
2022-11-18 03:25:53,486 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8181830454956401, 'Total loss': 0.8181830454956401} | train loss {'Reaction outcome loss': 0.8204668480375035, 'Total loss': 0.8204668480375035}
2022-11-18 03:25:53,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:53,486 INFO:     Epoch: 14
2022-11-18 03:25:54,291 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8450156145475127, 'Total loss': 0.8450156145475127} | train loss {'Reaction outcome loss': 0.8201555777416538, 'Total loss': 0.8201555777416538}
2022-11-18 03:25:54,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:54,292 INFO:     Epoch: 15
2022-11-18 03:25:55,115 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8466404635797847, 'Total loss': 0.8466404635797847} | train loss {'Reaction outcome loss': 0.8237373411414112, 'Total loss': 0.8237373411414112}
2022-11-18 03:25:55,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:55,115 INFO:     Epoch: 16
2022-11-18 03:25:55,921 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8192923969843171, 'Total loss': 0.8192923969843171} | train loss {'Reaction outcome loss': 0.8211253808004412, 'Total loss': 0.8211253808004412}
2022-11-18 03:25:55,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:55,921 INFO:     Epoch: 17
2022-11-18 03:25:56,711 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8282752287658778, 'Total loss': 0.8282752287658778} | train loss {'Reaction outcome loss': 0.8199874014265625, 'Total loss': 0.8199874014265625}
2022-11-18 03:25:56,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:56,711 INFO:     Epoch: 18
2022-11-18 03:25:57,550 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8284311443567276, 'Total loss': 0.8284311443567276} | train loss {'Reaction outcome loss': 0.8180942594522407, 'Total loss': 0.8180942594522407}
2022-11-18 03:25:57,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:57,551 INFO:     Epoch: 19
2022-11-18 03:25:58,392 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8328271196647123, 'Total loss': 0.8328271196647123} | train loss {'Reaction outcome loss': 0.8197340146008774, 'Total loss': 0.8197340146008774}
2022-11-18 03:25:58,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:58,392 INFO:     Epoch: 20
2022-11-18 03:25:59,221 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8493207747286017, 'Total loss': 0.8493207747286017} | train loss {'Reaction outcome loss': 0.8234176879469682, 'Total loss': 0.8234176879469682}
2022-11-18 03:25:59,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:25:59,221 INFO:     Epoch: 21
2022-11-18 03:26:00,060 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.815641584044153, 'Total loss': 0.815641584044153} | train loss {'Reaction outcome loss': 0.8185952804107898, 'Total loss': 0.8185952804107898}
2022-11-18 03:26:00,060 INFO:     Found new best model at epoch 21
2022-11-18 03:26:00,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:00,061 INFO:     Epoch: 22
2022-11-18 03:26:00,896 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8334912644191221, 'Total loss': 0.8334912644191221} | train loss {'Reaction outcome loss': 0.8160071375323572, 'Total loss': 0.8160071375323572}
2022-11-18 03:26:00,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:00,896 INFO:     Epoch: 23
2022-11-18 03:26:01,669 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8199106630953875, 'Total loss': 0.8199106630953875} | train loss {'Reaction outcome loss': 0.8189312516436403, 'Total loss': 0.8189312516436403}
2022-11-18 03:26:01,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:01,670 INFO:     Epoch: 24
2022-11-18 03:26:02,507 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.820939149368893, 'Total loss': 0.820939149368893} | train loss {'Reaction outcome loss': 0.818348588851782, 'Total loss': 0.818348588851782}
2022-11-18 03:26:02,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:02,508 INFO:     Epoch: 25
2022-11-18 03:26:03,313 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8178500763394616, 'Total loss': 0.8178500763394616} | train loss {'Reaction outcome loss': 0.816201428049489, 'Total loss': 0.816201428049489}
2022-11-18 03:26:03,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:03,313 INFO:     Epoch: 26
2022-11-18 03:26:04,110 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8270592405037447, 'Total loss': 0.8270592405037447} | train loss {'Reaction outcome loss': 0.8232384308388359, 'Total loss': 0.8232384308388359}
2022-11-18 03:26:04,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:04,110 INFO:     Epoch: 27
2022-11-18 03:26:04,935 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8233031833713705, 'Total loss': 0.8233031833713705} | train loss {'Reaction outcome loss': 0.8194999465575585, 'Total loss': 0.8194999465575585}
2022-11-18 03:26:04,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:04,936 INFO:     Epoch: 28
2022-11-18 03:26:05,750 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.834207954054529, 'Total loss': 0.834207954054529} | train loss {'Reaction outcome loss': 0.8159062920613327, 'Total loss': 0.8159062920613327}
2022-11-18 03:26:05,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:05,751 INFO:     Epoch: 29
2022-11-18 03:26:06,565 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.815297320485115, 'Total loss': 0.815297320485115} | train loss {'Reaction outcome loss': 0.8135172267433121, 'Total loss': 0.8135172267433121}
2022-11-18 03:26:06,565 INFO:     Found new best model at epoch 29
2022-11-18 03:26:06,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:06,566 INFO:     Epoch: 30
2022-11-18 03:26:07,413 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8192615461620417, 'Total loss': 0.8192615461620417} | train loss {'Reaction outcome loss': 0.8210222593203247, 'Total loss': 0.8210222593203247}
2022-11-18 03:26:07,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:07,413 INFO:     Epoch: 31
2022-11-18 03:26:08,186 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8245006637139753, 'Total loss': 0.8245006637139753} | train loss {'Reaction outcome loss': 0.8170485442225267, 'Total loss': 0.8170485442225267}
2022-11-18 03:26:08,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:08,186 INFO:     Epoch: 32
2022-11-18 03:26:09,025 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.825407782738859, 'Total loss': 0.825407782738859} | train loss {'Reaction outcome loss': 0.8154844369000269, 'Total loss': 0.8154844369000269}
2022-11-18 03:26:09,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:09,025 INFO:     Epoch: 33
2022-11-18 03:26:09,828 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8330673324790868, 'Total loss': 0.8330673324790868} | train loss {'Reaction outcome loss': 0.8157719573993915, 'Total loss': 0.8157719573993915}
2022-11-18 03:26:09,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:09,829 INFO:     Epoch: 34
2022-11-18 03:26:10,620 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8411114290356636, 'Total loss': 0.8411114290356636} | train loss {'Reaction outcome loss': 0.8203841714482558, 'Total loss': 0.8203841714482558}
2022-11-18 03:26:10,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:10,620 INFO:     Epoch: 35
2022-11-18 03:26:11,424 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8210392215035178, 'Total loss': 0.8210392215035178} | train loss {'Reaction outcome loss': 0.8199887054893169, 'Total loss': 0.8199887054893169}
2022-11-18 03:26:11,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:11,424 INFO:     Epoch: 36
2022-11-18 03:26:12,250 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8315649384802039, 'Total loss': 0.8315649384802039} | train loss {'Reaction outcome loss': 0.8189101117825218, 'Total loss': 0.8189101117825218}
2022-11-18 03:26:12,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:12,251 INFO:     Epoch: 37
2022-11-18 03:26:13,060 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8290862745859406, 'Total loss': 0.8290862745859406} | train loss {'Reaction outcome loss': 0.8204969907337837, 'Total loss': 0.8204969907337837}
2022-11-18 03:26:13,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:13,060 INFO:     Epoch: 38
2022-11-18 03:26:13,840 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8644971982999281, 'Total loss': 0.8644971982999281} | train loss {'Reaction outcome loss': 0.8194964003225087, 'Total loss': 0.8194964003225087}
2022-11-18 03:26:13,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:13,841 INFO:     Epoch: 39
2022-11-18 03:26:14,643 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8163845539093018, 'Total loss': 0.8163845539093018} | train loss {'Reaction outcome loss': 0.8269790085221109, 'Total loss': 0.8269790085221109}
2022-11-18 03:26:14,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:14,643 INFO:     Epoch: 40
2022-11-18 03:26:15,421 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8119646988131783, 'Total loss': 0.8119646988131783} | train loss {'Reaction outcome loss': 0.8141818356658765, 'Total loss': 0.8141818356658765}
2022-11-18 03:26:15,422 INFO:     Found new best model at epoch 40
2022-11-18 03:26:15,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:15,423 INFO:     Epoch: 41
2022-11-18 03:26:16,256 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8165525048971176, 'Total loss': 0.8165525048971176} | train loss {'Reaction outcome loss': 0.8178320517424147, 'Total loss': 0.8178320517424147}
2022-11-18 03:26:16,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:16,257 INFO:     Epoch: 42
2022-11-18 03:26:17,087 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8278247829188, 'Total loss': 0.8278247829188} | train loss {'Reaction outcome loss': 0.8220376379576771, 'Total loss': 0.8220376379576771}
2022-11-18 03:26:17,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:17,088 INFO:     Epoch: 43
2022-11-18 03:26:17,890 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8205865221944723, 'Total loss': 0.8205865221944723} | train loss {'Reaction outcome loss': 0.8147451900518857, 'Total loss': 0.8147451900518857}
2022-11-18 03:26:17,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:17,890 INFO:     Epoch: 44
2022-11-18 03:26:18,682 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8080356967720118, 'Total loss': 0.8080356967720118} | train loss {'Reaction outcome loss': 0.8161633109998124, 'Total loss': 0.8161633109998124}
2022-11-18 03:26:18,682 INFO:     Found new best model at epoch 44
2022-11-18 03:26:18,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:18,683 INFO:     Epoch: 45
2022-11-18 03:26:19,477 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8191802779381926, 'Total loss': 0.8191802779381926} | train loss {'Reaction outcome loss': 0.8154135197401047, 'Total loss': 0.8154135197401047}
2022-11-18 03:26:19,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:19,478 INFO:     Epoch: 46
2022-11-18 03:26:20,258 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8233937214721333, 'Total loss': 0.8233937214721333} | train loss {'Reaction outcome loss': 0.8153195673758201, 'Total loss': 0.8153195673758201}
2022-11-18 03:26:20,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:20,259 INFO:     Epoch: 47
2022-11-18 03:26:21,098 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8320340656421401, 'Total loss': 0.8320340656421401} | train loss {'Reaction outcome loss': 0.8135338239824241, 'Total loss': 0.8135338239824241}
2022-11-18 03:26:21,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:21,099 INFO:     Epoch: 48
2022-11-18 03:26:21,935 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8223297921094027, 'Total loss': 0.8223297921094027} | train loss {'Reaction outcome loss': 0.8149886498084435, 'Total loss': 0.8149886498084435}
2022-11-18 03:26:21,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:21,936 INFO:     Epoch: 49
2022-11-18 03:26:22,728 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.838589416986162, 'Total loss': 0.838589416986162} | train loss {'Reaction outcome loss': 0.8143563628920659, 'Total loss': 0.8143563628920659}
2022-11-18 03:26:22,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:22,728 INFO:     Epoch: 50
2022-11-18 03:26:23,559 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8409097296270457, 'Total loss': 0.8409097296270457} | train loss {'Reaction outcome loss': 0.8255041580692477, 'Total loss': 0.8255041580692477}
2022-11-18 03:26:23,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:23,559 INFO:     Epoch: 51
2022-11-18 03:26:24,382 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8290922384370457, 'Total loss': 0.8290922384370457} | train loss {'Reaction outcome loss': 0.8192729534890487, 'Total loss': 0.8192729534890487}
2022-11-18 03:26:24,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:24,383 INFO:     Epoch: 52
2022-11-18 03:26:25,187 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8264939825643193, 'Total loss': 0.8264939825643193} | train loss {'Reaction outcome loss': 0.817184590738312, 'Total loss': 0.817184590738312}
2022-11-18 03:26:25,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:25,187 INFO:     Epoch: 53
2022-11-18 03:26:26,001 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8331239047375593, 'Total loss': 0.8331239047375593} | train loss {'Reaction outcome loss': 0.8207592313830187, 'Total loss': 0.8207592313830187}
2022-11-18 03:26:26,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:26,002 INFO:     Epoch: 54
2022-11-18 03:26:26,826 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8302035548470237, 'Total loss': 0.8302035548470237} | train loss {'Reaction outcome loss': 0.8135203394571296, 'Total loss': 0.8135203394571296}
2022-11-18 03:26:26,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:26,827 INFO:     Epoch: 55
2022-11-18 03:26:27,648 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8198994486169382, 'Total loss': 0.8198994486169382} | train loss {'Reaction outcome loss': 0.8193926648331075, 'Total loss': 0.8193926648331075}
2022-11-18 03:26:27,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:27,648 INFO:     Epoch: 56
2022-11-18 03:26:28,438 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8216604095968333, 'Total loss': 0.8216604095968333} | train loss {'Reaction outcome loss': 0.8119822277231254, 'Total loss': 0.8119822277231254}
2022-11-18 03:26:28,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:28,439 INFO:     Epoch: 57
2022-11-18 03:26:29,211 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.807778924703598, 'Total loss': 0.807778924703598} | train loss {'Reaction outcome loss': 0.8174301797320486, 'Total loss': 0.8174301797320486}
2022-11-18 03:26:29,211 INFO:     Found new best model at epoch 57
2022-11-18 03:26:29,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:29,212 INFO:     Epoch: 58
2022-11-18 03:26:29,994 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8170051832090724, 'Total loss': 0.8170051832090724} | train loss {'Reaction outcome loss': 0.8245768475870372, 'Total loss': 0.8245768475870372}
2022-11-18 03:26:29,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:29,994 INFO:     Epoch: 59
2022-11-18 03:26:30,793 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8661675453186035, 'Total loss': 0.8661675453186035} | train loss {'Reaction outcome loss': 0.8157142453830735, 'Total loss': 0.8157142453830735}
2022-11-18 03:26:30,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:30,794 INFO:     Epoch: 60
2022-11-18 03:26:31,603 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8262969865040346, 'Total loss': 0.8262969865040346} | train loss {'Reaction outcome loss': 0.8229185668261427, 'Total loss': 0.8229185668261427}
2022-11-18 03:26:31,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:31,603 INFO:     Epoch: 61
2022-11-18 03:26:32,407 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8394741896878589, 'Total loss': 0.8394741896878589} | train loss {'Reaction outcome loss': 0.8160785312353358, 'Total loss': 0.8160785312353358}
2022-11-18 03:26:32,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:32,407 INFO:     Epoch: 62
2022-11-18 03:26:33,224 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8323115157810125, 'Total loss': 0.8323115157810125} | train loss {'Reaction outcome loss': 0.8212941822252775, 'Total loss': 0.8212941822252775}
2022-11-18 03:26:33,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:33,224 INFO:     Epoch: 63
2022-11-18 03:26:34,040 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8322606018998406, 'Total loss': 0.8322606018998406} | train loss {'Reaction outcome loss': 0.8212448459887794, 'Total loss': 0.8212448459887794}
2022-11-18 03:26:34,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:34,041 INFO:     Epoch: 64
2022-11-18 03:26:34,810 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8081316561861471, 'Total loss': 0.8081316561861471} | train loss {'Reaction outcome loss': 0.8181101084962065, 'Total loss': 0.8181101084962065}
2022-11-18 03:26:34,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:34,810 INFO:     Epoch: 65
2022-11-18 03:26:35,587 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8122838234359567, 'Total loss': 0.8122838234359567} | train loss {'Reaction outcome loss': 0.8333476507953304, 'Total loss': 0.8333476507953304}
2022-11-18 03:26:35,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:35,588 INFO:     Epoch: 66
2022-11-18 03:26:36,400 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8220147077332843, 'Total loss': 0.8220147077332843} | train loss {'Reaction outcome loss': 0.8177568571046296, 'Total loss': 0.8177568571046296}
2022-11-18 03:26:36,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:36,400 INFO:     Epoch: 67
2022-11-18 03:26:37,173 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8420371873812242, 'Total loss': 0.8420371873812242} | train loss {'Reaction outcome loss': 0.8194840829140744, 'Total loss': 0.8194840829140744}
2022-11-18 03:26:37,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:37,173 INFO:     Epoch: 68
2022-11-18 03:26:37,963 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8125006542964415, 'Total loss': 0.8125006542964415} | train loss {'Reaction outcome loss': 0.8134296308403556, 'Total loss': 0.8134296308403556}
2022-11-18 03:26:37,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:37,964 INFO:     Epoch: 69
2022-11-18 03:26:38,742 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8290603973648765, 'Total loss': 0.8290603973648765} | train loss {'Reaction outcome loss': 0.8216434460178561, 'Total loss': 0.8216434460178561}
2022-11-18 03:26:38,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:38,742 INFO:     Epoch: 70
2022-11-18 03:26:39,529 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8294514363462274, 'Total loss': 0.8294514363462274} | train loss {'Reaction outcome loss': 0.8178878829546785, 'Total loss': 0.8178878829546785}
2022-11-18 03:26:39,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:39,529 INFO:     Epoch: 71
2022-11-18 03:26:40,304 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8212999207052317, 'Total loss': 0.8212999207052317} | train loss {'Reaction outcome loss': 0.8178412700712923, 'Total loss': 0.8178412700712923}
2022-11-18 03:26:40,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:40,306 INFO:     Epoch: 72
2022-11-18 03:26:41,105 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8222200139002367, 'Total loss': 0.8222200139002367} | train loss {'Reaction outcome loss': 0.8185008735309246, 'Total loss': 0.8185008735309246}
2022-11-18 03:26:41,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:41,105 INFO:     Epoch: 73
2022-11-18 03:26:41,856 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8248372795906934, 'Total loss': 0.8248372795906934} | train loss {'Reaction outcome loss': 0.8194424826123936, 'Total loss': 0.8194424826123936}
2022-11-18 03:26:41,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:41,856 INFO:     Epoch: 74
2022-11-18 03:26:42,627 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8248206715692173, 'Total loss': 0.8248206715692173} | train loss {'Reaction outcome loss': 0.8193315831031877, 'Total loss': 0.8193315831031877}
2022-11-18 03:26:42,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:42,627 INFO:     Epoch: 75
2022-11-18 03:26:43,402 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8504640852863138, 'Total loss': 0.8504640852863138} | train loss {'Reaction outcome loss': 0.8150426902269062, 'Total loss': 0.8150426902269062}
2022-11-18 03:26:43,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:43,402 INFO:     Epoch: 76
2022-11-18 03:26:44,198 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8285561698404226, 'Total loss': 0.8285561698404226} | train loss {'Reaction outcome loss': 0.8149766152807576, 'Total loss': 0.8149766152807576}
2022-11-18 03:26:44,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:44,198 INFO:     Epoch: 77
2022-11-18 03:26:44,995 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8262880891561508, 'Total loss': 0.8262880891561508} | train loss {'Reaction outcome loss': 0.8134330152439685, 'Total loss': 0.8134330152439685}
2022-11-18 03:26:44,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:44,995 INFO:     Epoch: 78
2022-11-18 03:26:45,780 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8034372102807869, 'Total loss': 0.8034372102807869} | train loss {'Reaction outcome loss': 0.8263828819579924, 'Total loss': 0.8263828819579924}
2022-11-18 03:26:45,780 INFO:     Found new best model at epoch 78
2022-11-18 03:26:45,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:45,781 INFO:     Epoch: 79
2022-11-18 03:26:46,582 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.819909662685611, 'Total loss': 0.819909662685611} | train loss {'Reaction outcome loss': 0.8282645349560479, 'Total loss': 0.8282645349560479}
2022-11-18 03:26:46,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:46,583 INFO:     Epoch: 80
2022-11-18 03:26:47,366 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8138233802535317, 'Total loss': 0.8138233802535317} | train loss {'Reaction outcome loss': 0.8160356730825988, 'Total loss': 0.8160356730825988}
2022-11-18 03:26:47,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:47,366 INFO:     Epoch: 81
2022-11-18 03:26:48,141 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8240691308270801, 'Total loss': 0.8240691308270801} | train loss {'Reaction outcome loss': 0.8232561530854537, 'Total loss': 0.8232561530854537}
2022-11-18 03:26:48,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:48,141 INFO:     Epoch: 82
2022-11-18 03:26:48,941 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.813399197703058, 'Total loss': 0.813399197703058} | train loss {'Reaction outcome loss': 0.8148634642483252, 'Total loss': 0.8148634642483252}
2022-11-18 03:26:48,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:48,941 INFO:     Epoch: 83
2022-11-18 03:26:49,748 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.819868153469129, 'Total loss': 0.819868153469129} | train loss {'Reaction outcome loss': 0.8134575922962143, 'Total loss': 0.8134575922962143}
2022-11-18 03:26:49,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:49,748 INFO:     Epoch: 84
2022-11-18 03:26:50,534 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8149810169230808, 'Total loss': 0.8149810169230808} | train loss {'Reaction outcome loss': 0.8148863593093779, 'Total loss': 0.8148863593093779}
2022-11-18 03:26:50,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:50,534 INFO:     Epoch: 85
2022-11-18 03:26:51,319 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8139649494127794, 'Total loss': 0.8139649494127794} | train loss {'Reaction outcome loss': 0.810286471416593, 'Total loss': 0.810286471416593}
2022-11-18 03:26:51,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:51,319 INFO:     Epoch: 86
2022-11-18 03:26:52,112 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8401300758123398, 'Total loss': 0.8401300758123398} | train loss {'Reaction outcome loss': 0.8091524216810219, 'Total loss': 0.8091524216810219}
2022-11-18 03:26:52,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:52,112 INFO:     Epoch: 87
2022-11-18 03:26:52,899 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8235439725897529, 'Total loss': 0.8235439725897529} | train loss {'Reaction outcome loss': 0.8207718586390801, 'Total loss': 0.8207718586390801}
2022-11-18 03:26:52,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:52,900 INFO:     Epoch: 88
2022-11-18 03:26:53,688 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8064978908408772, 'Total loss': 0.8064978908408772} | train loss {'Reaction outcome loss': 0.8147231648234945, 'Total loss': 0.8147231648234945}
2022-11-18 03:26:53,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:53,689 INFO:     Epoch: 89
2022-11-18 03:26:54,477 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8097111196680502, 'Total loss': 0.8097111196680502} | train loss {'Reaction outcome loss': 0.812240581039475, 'Total loss': 0.812240581039475}
2022-11-18 03:26:54,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:54,478 INFO:     Epoch: 90
2022-11-18 03:26:55,248 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8045592145486311, 'Total loss': 0.8045592145486311} | train loss {'Reaction outcome loss': 0.8111749357781429, 'Total loss': 0.8111749357781429}
2022-11-18 03:26:55,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:55,248 INFO:     Epoch: 91
2022-11-18 03:26:56,025 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8217718438668684, 'Total loss': 0.8217718438668684} | train loss {'Reaction outcome loss': 0.8161452376408133, 'Total loss': 0.8161452376408133}
2022-11-18 03:26:56,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:56,025 INFO:     Epoch: 92
2022-11-18 03:26:56,800 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8029467924074694, 'Total loss': 0.8029467924074694} | train loss {'Reaction outcome loss': 0.8153745977260806, 'Total loss': 0.8153745977260806}
2022-11-18 03:26:56,800 INFO:     Found new best model at epoch 92
2022-11-18 03:26:56,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:56,801 INFO:     Epoch: 93
2022-11-18 03:26:57,591 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8049178712747314, 'Total loss': 0.8049178712747314} | train loss {'Reaction outcome loss': 0.8114470709793964, 'Total loss': 0.8114470709793964}
2022-11-18 03:26:57,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:57,591 INFO:     Epoch: 94
2022-11-18 03:26:58,382 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8315931836312468, 'Total loss': 0.8315931836312468} | train loss {'Reaction outcome loss': 0.8115564774163821, 'Total loss': 0.8115564774163821}
2022-11-18 03:26:58,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:58,383 INFO:     Epoch: 95
2022-11-18 03:26:59,166 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8092327680100094, 'Total loss': 0.8092327680100094} | train loss {'Reaction outcome loss': 0.8199718302560721, 'Total loss': 0.8199718302560721}
2022-11-18 03:26:59,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:26:59,167 INFO:     Epoch: 96
2022-11-18 03:27:00,002 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8104664155028083, 'Total loss': 0.8104664155028083} | train loss {'Reaction outcome loss': 0.8185875499055453, 'Total loss': 0.8185875499055453}
2022-11-18 03:27:00,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:00,003 INFO:     Epoch: 97
2022-11-18 03:27:00,779 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8241047317331488, 'Total loss': 0.8241047317331488} | train loss {'Reaction outcome loss': 0.8232313330598205, 'Total loss': 0.8232313330598205}
2022-11-18 03:27:00,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:00,780 INFO:     Epoch: 98
2022-11-18 03:27:01,545 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8042258464477279, 'Total loss': 0.8042258464477279} | train loss {'Reaction outcome loss': 0.8124386470327493, 'Total loss': 0.8124386470327493}
2022-11-18 03:27:01,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:01,545 INFO:     Epoch: 99
2022-11-18 03:27:02,330 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.817238374189897, 'Total loss': 0.817238374189897} | train loss {'Reaction outcome loss': 0.815675699879766, 'Total loss': 0.815675699879766}
2022-11-18 03:27:02,330 INFO:     Best model found after epoch 93 of 100.
2022-11-18 03:27:02,330 INFO:   Done with stage: TRAINING
2022-11-18 03:27:02,330 INFO:   Starting stage: EVALUATION
2022-11-18 03:27:02,453 INFO:   Done with stage: EVALUATION
2022-11-18 03:27:02,453 INFO:   Leaving out SEQ value Fold_4
2022-11-18 03:27:02,467 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:27:02,467 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:27:03,133 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:27:03,133 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:27:03,205 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:27:03,205 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:27:03,205 INFO:     No hyperparam tuning for this model
2022-11-18 03:27:03,205 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:27:03,205 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:27:03,206 INFO:     None feature selector for col prot
2022-11-18 03:27:03,206 INFO:     None feature selector for col prot
2022-11-18 03:27:03,206 INFO:     None feature selector for col prot
2022-11-18 03:27:03,207 INFO:     None feature selector for col chem
2022-11-18 03:27:03,207 INFO:     None feature selector for col chem
2022-11-18 03:27:03,207 INFO:     None feature selector for col chem
2022-11-18 03:27:03,207 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:27:03,207 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:27:03,208 INFO:     Number of params in model 168571
2022-11-18 03:27:03,212 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:27:03,212 INFO:   Starting stage: TRAINING
2022-11-18 03:27:03,270 INFO:     Val loss before train {'Reaction outcome loss': 1.012668246572668, 'Total loss': 1.012668246572668}
2022-11-18 03:27:03,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:03,270 INFO:     Epoch: 0
2022-11-18 03:27:04,053 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.901949860832908, 'Total loss': 0.901949860832908} | train loss {'Reaction outcome loss': 0.8806673382078448, 'Total loss': 0.8806673382078448}
2022-11-18 03:27:04,053 INFO:     Found new best model at epoch 0
2022-11-18 03:27:04,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:04,054 INFO:     Epoch: 1
2022-11-18 03:27:04,862 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8684243695302443, 'Total loss': 0.8684243695302443} | train loss {'Reaction outcome loss': 0.8513651402486909, 'Total loss': 0.8513651402486909}
2022-11-18 03:27:04,862 INFO:     Found new best model at epoch 1
2022-11-18 03:27:04,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:04,863 INFO:     Epoch: 2
2022-11-18 03:27:05,678 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8199717165394262, 'Total loss': 0.8199717165394262} | train loss {'Reaction outcome loss': 0.8410544132273043, 'Total loss': 0.8410544132273043}
2022-11-18 03:27:05,678 INFO:     Found new best model at epoch 2
2022-11-18 03:27:05,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:05,679 INFO:     Epoch: 3
2022-11-18 03:27:06,439 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8003858612342314, 'Total loss': 0.8003858612342314} | train loss {'Reaction outcome loss': 0.8407416645317308, 'Total loss': 0.8407416645317308}
2022-11-18 03:27:06,439 INFO:     Found new best model at epoch 3
2022-11-18 03:27:06,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:06,440 INFO:     Epoch: 4
2022-11-18 03:27:07,223 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8079339428381487, 'Total loss': 0.8079339428381487} | train loss {'Reaction outcome loss': 0.830906129652454, 'Total loss': 0.830906129652454}
2022-11-18 03:27:07,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:07,223 INFO:     Epoch: 5
2022-11-18 03:27:07,985 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8041696724566546, 'Total loss': 0.8041696724566546} | train loss {'Reaction outcome loss': 0.8289018876610263, 'Total loss': 0.8289018876610263}
2022-11-18 03:27:07,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:07,986 INFO:     Epoch: 6
2022-11-18 03:27:08,757 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8144120215014978, 'Total loss': 0.8144120215014978} | train loss {'Reaction outcome loss': 0.8270889524250261, 'Total loss': 0.8270889524250261}
2022-11-18 03:27:08,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:08,758 INFO:     Epoch: 7
2022-11-18 03:27:09,554 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8119147765365514, 'Total loss': 0.8119147765365514} | train loss {'Reaction outcome loss': 0.8248175501583084, 'Total loss': 0.8248175501583084}
2022-11-18 03:27:09,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:09,555 INFO:     Epoch: 8
2022-11-18 03:27:10,352 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8118783987381242, 'Total loss': 0.8118783987381242} | train loss {'Reaction outcome loss': 0.8268856555223465, 'Total loss': 0.8268856555223465}
2022-11-18 03:27:10,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:10,352 INFO:     Epoch: 9
2022-11-18 03:27:11,151 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.797786031934348, 'Total loss': 0.797786031934348} | train loss {'Reaction outcome loss': 0.8234024774884025, 'Total loss': 0.8234024774884025}
2022-11-18 03:27:11,152 INFO:     Found new best model at epoch 9
2022-11-18 03:27:11,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:11,152 INFO:     Epoch: 10
2022-11-18 03:27:11,948 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8128970488905907, 'Total loss': 0.8128970488905907} | train loss {'Reaction outcome loss': 0.8278305121967869, 'Total loss': 0.8278305121967869}
2022-11-18 03:27:11,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:11,950 INFO:     Epoch: 11
2022-11-18 03:27:12,739 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.818904771046205, 'Total loss': 0.818904771046205} | train loss {'Reaction outcome loss': 0.8197804245977632, 'Total loss': 0.8197804245977632}
2022-11-18 03:27:12,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:12,739 INFO:     Epoch: 12
2022-11-18 03:27:13,507 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8071666353128173, 'Total loss': 0.8071666353128173} | train loss {'Reaction outcome loss': 0.8231138453608559, 'Total loss': 0.8231138453608559}
2022-11-18 03:27:13,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:13,508 INFO:     Epoch: 13
2022-11-18 03:27:14,295 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8169507526538589, 'Total loss': 0.8169507526538589} | train loss {'Reaction outcome loss': 0.8187637476911468, 'Total loss': 0.8187637476911468}
2022-11-18 03:27:14,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:14,295 INFO:     Epoch: 14
2022-11-18 03:27:15,073 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8154112913391807, 'Total loss': 0.8154112913391807} | train loss {'Reaction outcome loss': 0.8187669050549308, 'Total loss': 0.8187669050549308}
2022-11-18 03:27:15,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:15,073 INFO:     Epoch: 15
2022-11-18 03:27:15,851 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7944945706562563, 'Total loss': 0.7944945706562563} | train loss {'Reaction outcome loss': 0.8173574563115835, 'Total loss': 0.8173574563115835}
2022-11-18 03:27:15,851 INFO:     Found new best model at epoch 15
2022-11-18 03:27:15,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:15,852 INFO:     Epoch: 16
2022-11-18 03:27:16,636 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8022701814770699, 'Total loss': 0.8022701814770699} | train loss {'Reaction outcome loss': 0.8154259500724654, 'Total loss': 0.8154259500724654}
2022-11-18 03:27:16,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:16,636 INFO:     Epoch: 17
2022-11-18 03:27:17,423 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.796874846924435, 'Total loss': 0.796874846924435} | train loss {'Reaction outcome loss': 0.8180079946835195, 'Total loss': 0.8180079946835195}
2022-11-18 03:27:17,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:17,423 INFO:     Epoch: 18
2022-11-18 03:27:18,199 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8011108122088693, 'Total loss': 0.8011108122088693} | train loss {'Reaction outcome loss': 0.8155405314699296, 'Total loss': 0.8155405314699296}
2022-11-18 03:27:18,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:18,200 INFO:     Epoch: 19
2022-11-18 03:27:18,993 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7951649440960451, 'Total loss': 0.7951649440960451} | train loss {'Reaction outcome loss': 0.8145218497562793, 'Total loss': 0.8145218497562793}
2022-11-18 03:27:18,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:18,993 INFO:     Epoch: 20
2022-11-18 03:27:19,780 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7951714924790643, 'Total loss': 0.7951714924790643} | train loss {'Reaction outcome loss': 0.8156606795326355, 'Total loss': 0.8156606795326355}
2022-11-18 03:27:19,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:19,781 INFO:     Epoch: 21
2022-11-18 03:27:20,549 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8081165619871833, 'Total loss': 0.8081165619871833} | train loss {'Reaction outcome loss': 0.8201938707741999, 'Total loss': 0.8201938707741999}
2022-11-18 03:27:20,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:20,549 INFO:     Epoch: 22
2022-11-18 03:27:21,332 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8144769925962795, 'Total loss': 0.8144769925962795} | train loss {'Reaction outcome loss': 0.813587661832571, 'Total loss': 0.813587661832571}
2022-11-18 03:27:21,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:21,332 INFO:     Epoch: 23
2022-11-18 03:27:22,142 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8067517707293684, 'Total loss': 0.8067517707293684} | train loss {'Reaction outcome loss': 0.8153599322803559, 'Total loss': 0.8153599322803559}
2022-11-18 03:27:22,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:22,142 INFO:     Epoch: 24
2022-11-18 03:27:22,923 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8006791533394293, 'Total loss': 0.8006791533394293} | train loss {'Reaction outcome loss': 0.815771650643118, 'Total loss': 0.815771650643118}
2022-11-18 03:27:22,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:22,923 INFO:     Epoch: 25
2022-11-18 03:27:23,693 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.799406923353672, 'Total loss': 0.799406923353672} | train loss {'Reaction outcome loss': 0.8141174652884083, 'Total loss': 0.8141174652884083}
2022-11-18 03:27:23,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:23,693 INFO:     Epoch: 26
2022-11-18 03:27:24,482 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7987186949361454, 'Total loss': 0.7987186949361454} | train loss {'Reaction outcome loss': 0.8198562221181008, 'Total loss': 0.8198562221181008}
2022-11-18 03:27:24,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:24,483 INFO:     Epoch: 27
2022-11-18 03:27:25,272 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8028077564456246, 'Total loss': 0.8028077564456246} | train loss {'Reaction outcome loss': 0.8195798744357401, 'Total loss': 0.8195798744357401}
2022-11-18 03:27:25,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:25,273 INFO:     Epoch: 28
2022-11-18 03:27:26,063 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8057476627555761, 'Total loss': 0.8057476627555761} | train loss {'Reaction outcome loss': 0.8130310777454607, 'Total loss': 0.8130310777454607}
2022-11-18 03:27:26,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:26,063 INFO:     Epoch: 29
2022-11-18 03:27:26,847 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8098483959382231, 'Total loss': 0.8098483959382231} | train loss {'Reaction outcome loss': 0.8135260820629135, 'Total loss': 0.8135260820629135}
2022-11-18 03:27:26,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:26,848 INFO:     Epoch: 30
2022-11-18 03:27:27,616 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7905479127710516, 'Total loss': 0.7905479127710516} | train loss {'Reaction outcome loss': 0.8175497207670442, 'Total loss': 0.8175497207670442}
2022-11-18 03:27:27,616 INFO:     Found new best model at epoch 30
2022-11-18 03:27:27,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:27,617 INFO:     Epoch: 31
2022-11-18 03:27:28,427 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8051185350526463, 'Total loss': 0.8051185350526463} | train loss {'Reaction outcome loss': 0.8224911241521758, 'Total loss': 0.8224911241521758}
2022-11-18 03:27:28,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:28,427 INFO:     Epoch: 32
2022-11-18 03:27:29,196 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8083382519808683, 'Total loss': 0.8083382519808683} | train loss {'Reaction outcome loss': 0.811933699754938, 'Total loss': 0.811933699754938}
2022-11-18 03:27:29,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:29,197 INFO:     Epoch: 33
2022-11-18 03:27:29,979 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.820154838941314, 'Total loss': 0.820154838941314} | train loss {'Reaction outcome loss': 0.8099883318908753, 'Total loss': 0.8099883318908753}
2022-11-18 03:27:29,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:29,979 INFO:     Epoch: 34
2022-11-18 03:27:30,754 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7994167825037782, 'Total loss': 0.7994167825037782} | train loss {'Reaction outcome loss': 0.8169667643885459, 'Total loss': 0.8169667643885459}
2022-11-18 03:27:30,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:30,756 INFO:     Epoch: 35
2022-11-18 03:27:31,539 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7956503670323979, 'Total loss': 0.7956503670323979} | train loss {'Reaction outcome loss': 0.8146069361077201, 'Total loss': 0.8146069361077201}
2022-11-18 03:27:31,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:31,539 INFO:     Epoch: 36
2022-11-18 03:27:32,314 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8100674531676553, 'Total loss': 0.8100674531676553} | train loss {'Reaction outcome loss': 0.8160608263025361, 'Total loss': 0.8160608263025361}
2022-11-18 03:27:32,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:32,314 INFO:     Epoch: 37
2022-11-18 03:27:33,101 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8013844713568687, 'Total loss': 0.8013844713568687} | train loss {'Reaction outcome loss': 0.8117055241619388, 'Total loss': 0.8117055241619388}
2022-11-18 03:27:33,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:33,102 INFO:     Epoch: 38
2022-11-18 03:27:33,868 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.806329645216465, 'Total loss': 0.806329645216465} | train loss {'Reaction outcome loss': 0.8167219899835125, 'Total loss': 0.8167219899835125}
2022-11-18 03:27:33,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:33,869 INFO:     Epoch: 39
2022-11-18 03:27:34,684 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8057498417117379, 'Total loss': 0.8057498417117379} | train loss {'Reaction outcome loss': 0.8122434267593969, 'Total loss': 0.8122434267593969}
2022-11-18 03:27:34,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:34,684 INFO:     Epoch: 40
2022-11-18 03:27:35,505 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.806948260827498, 'Total loss': 0.806948260827498} | train loss {'Reaction outcome loss': 0.8203559824295582, 'Total loss': 0.8203559824295582}
2022-11-18 03:27:35,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:35,505 INFO:     Epoch: 41
2022-11-18 03:27:36,315 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8180633891712535, 'Total loss': 0.8180633891712535} | train loss {'Reaction outcome loss': 0.8139949913226789, 'Total loss': 0.8139949913226789}
2022-11-18 03:27:36,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:36,315 INFO:     Epoch: 42
2022-11-18 03:27:37,147 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7917333868416873, 'Total loss': 0.7917333868416873} | train loss {'Reaction outcome loss': 0.8173122509352623, 'Total loss': 0.8173122509352623}
2022-11-18 03:27:37,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:37,147 INFO:     Epoch: 43
2022-11-18 03:27:37,919 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8055387010628526, 'Total loss': 0.8055387010628526} | train loss {'Reaction outcome loss': 0.8123536816527767, 'Total loss': 0.8123536816527767}
2022-11-18 03:27:37,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:37,919 INFO:     Epoch: 44
2022-11-18 03:27:38,673 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8076390651139346, 'Total loss': 0.8076390651139346} | train loss {'Reaction outcome loss': 0.8163974482205606, 'Total loss': 0.8163974482205606}
2022-11-18 03:27:38,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:38,673 INFO:     Epoch: 45
2022-11-18 03:27:39,457 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8032784888690169, 'Total loss': 0.8032784888690169} | train loss {'Reaction outcome loss': 0.8149094878425521, 'Total loss': 0.8149094878425521}
2022-11-18 03:27:39,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:39,457 INFO:     Epoch: 46
2022-11-18 03:27:40,258 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.791167526082559, 'Total loss': 0.791167526082559} | train loss {'Reaction outcome loss': 0.8094695204448316, 'Total loss': 0.8094695204448316}
2022-11-18 03:27:40,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:40,258 INFO:     Epoch: 47
2022-11-18 03:27:41,036 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8033582337877967, 'Total loss': 0.8033582337877967} | train loss {'Reaction outcome loss': 0.8134853862706692, 'Total loss': 0.8134853862706692}
2022-11-18 03:27:41,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:41,036 INFO:     Epoch: 48
2022-11-18 03:27:41,810 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.787825212221254, 'Total loss': 0.787825212221254} | train loss {'Reaction outcome loss': 0.8128444586069353, 'Total loss': 0.8128444586069353}
2022-11-18 03:27:41,811 INFO:     Found new best model at epoch 48
2022-11-18 03:27:41,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:41,811 INFO:     Epoch: 49
2022-11-18 03:27:42,602 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8060316714373502, 'Total loss': 0.8060316714373502} | train loss {'Reaction outcome loss': 0.8132351468647679, 'Total loss': 0.8132351468647679}
2022-11-18 03:27:42,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:42,602 INFO:     Epoch: 50
2022-11-18 03:27:43,416 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8070585009726611, 'Total loss': 0.8070585009726611} | train loss {'Reaction outcome loss': 0.8169667827746561, 'Total loss': 0.8169667827746561}
2022-11-18 03:27:43,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:43,418 INFO:     Epoch: 51
2022-11-18 03:27:44,214 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.828149364753203, 'Total loss': 0.828149364753203} | train loss {'Reaction outcome loss': 0.8141160556866277, 'Total loss': 0.8141160556866277}
2022-11-18 03:27:44,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:44,214 INFO:     Epoch: 52
2022-11-18 03:27:45,037 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.817979711023244, 'Total loss': 0.817979711023244} | train loss {'Reaction outcome loss': 0.8106898497189244, 'Total loss': 0.8106898497189244}
2022-11-18 03:27:45,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:45,038 INFO:     Epoch: 53
2022-11-18 03:27:45,850 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8108657225966454, 'Total loss': 0.8108657225966454} | train loss {'Reaction outcome loss': 0.8093098855066684, 'Total loss': 0.8093098855066684}
2022-11-18 03:27:45,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:45,850 INFO:     Epoch: 54
2022-11-18 03:27:46,728 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7918169877745889, 'Total loss': 0.7918169877745889} | train loss {'Reaction outcome loss': 0.814996830277866, 'Total loss': 0.814996830277866}
2022-11-18 03:27:46,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:46,729 INFO:     Epoch: 55
2022-11-18 03:27:47,570 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7961178977381099, 'Total loss': 0.7961178977381099} | train loss {'Reaction outcome loss': 0.8112581940668244, 'Total loss': 0.8112581940668244}
2022-11-18 03:27:47,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:47,570 INFO:     Epoch: 56
2022-11-18 03:27:48,366 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7997555590488694, 'Total loss': 0.7997555590488694} | train loss {'Reaction outcome loss': 0.8143591284751892, 'Total loss': 0.8143591284751892}
2022-11-18 03:27:48,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:48,366 INFO:     Epoch: 57
2022-11-18 03:27:49,135 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7908999940211122, 'Total loss': 0.7908999940211122} | train loss {'Reaction outcome loss': 0.815436557055481, 'Total loss': 0.815436557055481}
2022-11-18 03:27:49,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:49,136 INFO:     Epoch: 58
2022-11-18 03:27:49,922 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8117701350287958, 'Total loss': 0.8117701350287958} | train loss {'Reaction outcome loss': 0.8131418743681523, 'Total loss': 0.8131418743681523}
2022-11-18 03:27:49,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:49,923 INFO:     Epoch: 59
2022-11-18 03:27:50,695 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7946648428385908, 'Total loss': 0.7946648428385908} | train loss {'Reaction outcome loss': 0.816114672009022, 'Total loss': 0.816114672009022}
2022-11-18 03:27:50,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:50,695 INFO:     Epoch: 60
2022-11-18 03:27:51,477 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7964076995849609, 'Total loss': 0.7964076995849609} | train loss {'Reaction outcome loss': 0.8121117975923323, 'Total loss': 0.8121117975923323}
2022-11-18 03:27:51,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:51,478 INFO:     Epoch: 61
2022-11-18 03:27:52,255 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8211289590055292, 'Total loss': 0.8211289590055292} | train loss {'Reaction outcome loss': 0.815214563761988, 'Total loss': 0.815214563761988}
2022-11-18 03:27:52,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:52,255 INFO:     Epoch: 62
2022-11-18 03:27:53,022 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8055227053436366, 'Total loss': 0.8055227053436366} | train loss {'Reaction outcome loss': 0.8122522297405428, 'Total loss': 0.8122522297405428}
2022-11-18 03:27:53,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:53,023 INFO:     Epoch: 63
2022-11-18 03:27:53,814 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8003919632597403, 'Total loss': 0.8003919632597403} | train loss {'Reaction outcome loss': 0.8165175447300557, 'Total loss': 0.8165175447300557}
2022-11-18 03:27:53,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:53,814 INFO:     Epoch: 64
2022-11-18 03:27:54,579 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8134267201477831, 'Total loss': 0.8134267201477831} | train loss {'Reaction outcome loss': 0.8146731274262551, 'Total loss': 0.8146731274262551}
2022-11-18 03:27:54,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:54,579 INFO:     Epoch: 65
2022-11-18 03:27:55,358 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.784957580268383, 'Total loss': 0.784957580268383} | train loss {'Reaction outcome loss': 0.8114702784486355, 'Total loss': 0.8114702784486355}
2022-11-18 03:27:55,358 INFO:     Found new best model at epoch 65
2022-11-18 03:27:55,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:55,359 INFO:     Epoch: 66
2022-11-18 03:27:56,142 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8000776869329539, 'Total loss': 0.8000776869329539} | train loss {'Reaction outcome loss': 0.810534413423269, 'Total loss': 0.810534413423269}
2022-11-18 03:27:56,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:56,143 INFO:     Epoch: 67
2022-11-18 03:27:56,938 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8155408799648285, 'Total loss': 0.8155408799648285} | train loss {'Reaction outcome loss': 0.8119147151948944, 'Total loss': 0.8119147151948944}
2022-11-18 03:27:56,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:56,938 INFO:     Epoch: 68
2022-11-18 03:27:57,742 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8194215406071056, 'Total loss': 0.8194215406071056} | train loss {'Reaction outcome loss': 0.8131189875064357, 'Total loss': 0.8131189875064357}
2022-11-18 03:27:57,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:57,742 INFO:     Epoch: 69
2022-11-18 03:27:58,541 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7926631576635621, 'Total loss': 0.7926631576635621} | train loss {'Reaction outcome loss': 0.8097010555286561, 'Total loss': 0.8097010555286561}
2022-11-18 03:27:58,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:58,542 INFO:     Epoch: 70
2022-11-18 03:27:59,332 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7889098497954282, 'Total loss': 0.7889098497954282} | train loss {'Reaction outcome loss': 0.8098004264456611, 'Total loss': 0.8098004264456611}
2022-11-18 03:27:59,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:27:59,332 INFO:     Epoch: 71
2022-11-18 03:28:00,119 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7955488847060637, 'Total loss': 0.7955488847060637} | train loss {'Reaction outcome loss': 0.8119790748723091, 'Total loss': 0.8119790748723091}
2022-11-18 03:28:00,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:00,121 INFO:     Epoch: 72
2022-11-18 03:28:00,907 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7998733412135731, 'Total loss': 0.7998733412135731} | train loss {'Reaction outcome loss': 0.8067811369415252, 'Total loss': 0.8067811369415252}
2022-11-18 03:28:00,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:00,907 INFO:     Epoch: 73
2022-11-18 03:28:01,714 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8001891936768185, 'Total loss': 0.8001891936768185} | train loss {'Reaction outcome loss': 0.8135085287353685, 'Total loss': 0.8135085287353685}
2022-11-18 03:28:01,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:01,714 INFO:     Epoch: 74
2022-11-18 03:28:02,487 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7888378270647742, 'Total loss': 0.7888378270647742} | train loss {'Reaction outcome loss': 0.8153697688493037, 'Total loss': 0.8153697688493037}
2022-11-18 03:28:02,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:02,487 INFO:     Epoch: 75
2022-11-18 03:28:03,259 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8060730729590763, 'Total loss': 0.8060730729590763} | train loss {'Reaction outcome loss': 0.8096065969476777, 'Total loss': 0.8096065969476777}
2022-11-18 03:28:03,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:03,260 INFO:     Epoch: 76
2022-11-18 03:28:04,042 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7882132083177567, 'Total loss': 0.7882132083177567} | train loss {'Reaction outcome loss': 0.809641819086767, 'Total loss': 0.809641819086767}
2022-11-18 03:28:04,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:04,042 INFO:     Epoch: 77
2022-11-18 03:28:04,804 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.789532449435104, 'Total loss': 0.789532449435104} | train loss {'Reaction outcome loss': 0.811302640625546, 'Total loss': 0.811302640625546}
2022-11-18 03:28:04,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:04,804 INFO:     Epoch: 78
2022-11-18 03:28:05,577 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7840288748795335, 'Total loss': 0.7840288748795335} | train loss {'Reaction outcome loss': 0.8088866337653129, 'Total loss': 0.8088866337653129}
2022-11-18 03:28:05,579 INFO:     Found new best model at epoch 78
2022-11-18 03:28:05,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:05,580 INFO:     Epoch: 79
2022-11-18 03:28:06,349 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7889884073625911, 'Total loss': 0.7889884073625911} | train loss {'Reaction outcome loss': 0.8149571764853693, 'Total loss': 0.8149571764853693}
2022-11-18 03:28:06,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:06,349 INFO:     Epoch: 80
2022-11-18 03:28:07,135 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8171210607344453, 'Total loss': 0.8171210607344453} | train loss {'Reaction outcome loss': 0.81334163621068, 'Total loss': 0.81334163621068}
2022-11-18 03:28:07,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:07,135 INFO:     Epoch: 81
2022-11-18 03:28:07,935 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7871580963784998, 'Total loss': 0.7871580963784998} | train loss {'Reaction outcome loss': 0.8187800647630807, 'Total loss': 0.8187800647630807}
2022-11-18 03:28:07,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:07,935 INFO:     Epoch: 82
2022-11-18 03:28:08,719 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7898432741110976, 'Total loss': 0.7898432741110976} | train loss {'Reaction outcome loss': 0.8138695317170312, 'Total loss': 0.8138695317170312}
2022-11-18 03:28:08,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:08,719 INFO:     Epoch: 83
2022-11-18 03:28:09,505 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.804382782090794, 'Total loss': 0.804382782090794} | train loss {'Reaction outcome loss': 0.8099847717150566, 'Total loss': 0.8099847717150566}
2022-11-18 03:28:09,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:09,506 INFO:     Epoch: 84
2022-11-18 03:28:10,292 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8072394911538471, 'Total loss': 0.8072394911538471} | train loss {'Reaction outcome loss': 0.8099678042194536, 'Total loss': 0.8099678042194536}
2022-11-18 03:28:10,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:10,292 INFO:     Epoch: 85
2022-11-18 03:28:11,082 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7980226034467871, 'Total loss': 0.7980226034467871} | train loss {'Reaction outcome loss': 0.8099163910073619, 'Total loss': 0.8099163910073619}
2022-11-18 03:28:11,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:11,084 INFO:     Epoch: 86
2022-11-18 03:28:11,860 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7975124256177382, 'Total loss': 0.7975124256177382} | train loss {'Reaction outcome loss': 0.8098875912687471, 'Total loss': 0.8098875912687471}
2022-11-18 03:28:11,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:11,861 INFO:     Epoch: 87
2022-11-18 03:28:12,659 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8051413196054372, 'Total loss': 0.8051413196054372} | train loss {'Reaction outcome loss': 0.8094125272285554, 'Total loss': 0.8094125272285554}
2022-11-18 03:28:12,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:12,659 INFO:     Epoch: 88
2022-11-18 03:28:13,414 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.827066799456423, 'Total loss': 0.827066799456423} | train loss {'Reaction outcome loss': 0.8099250968906188, 'Total loss': 0.8099250968906188}
2022-11-18 03:28:13,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:13,414 INFO:     Epoch: 89
2022-11-18 03:28:14,196 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7929937832734801, 'Total loss': 0.7929937832734801} | train loss {'Reaction outcome loss': 0.8170340231830074, 'Total loss': 0.8170340231830074}
2022-11-18 03:28:14,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:14,196 INFO:     Epoch: 90
2022-11-18 03:28:14,999 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7935279648412358, 'Total loss': 0.7935279648412358} | train loss {'Reaction outcome loss': 0.8123396037807388, 'Total loss': 0.8123396037807388}
2022-11-18 03:28:14,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:14,999 INFO:     Epoch: 91
2022-11-18 03:28:15,799 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7818695184859362, 'Total loss': 0.7818695184859362} | train loss {'Reaction outcome loss': 0.8060687525618461, 'Total loss': 0.8060687525618461}
2022-11-18 03:28:15,800 INFO:     Found new best model at epoch 91
2022-11-18 03:28:15,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:15,801 INFO:     Epoch: 92
2022-11-18 03:28:16,586 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7876329300078478, 'Total loss': 0.7876329300078478} | train loss {'Reaction outcome loss': 0.8137443001952863, 'Total loss': 0.8137443001952863}
2022-11-18 03:28:16,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:16,588 INFO:     Epoch: 93
2022-11-18 03:28:17,368 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7918562259186398, 'Total loss': 0.7918562259186398} | train loss {'Reaction outcome loss': 0.8091057060707, 'Total loss': 0.8091057060707}
2022-11-18 03:28:17,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:17,369 INFO:     Epoch: 94
2022-11-18 03:28:18,164 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7990674092011019, 'Total loss': 0.7990674092011019} | train loss {'Reaction outcome loss': 0.8101835170340154, 'Total loss': 0.8101835170340154}
2022-11-18 03:28:18,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:18,164 INFO:     Epoch: 95
2022-11-18 03:28:18,962 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7927989309484308, 'Total loss': 0.7927989309484308} | train loss {'Reaction outcome loss': 0.8115626005155425, 'Total loss': 0.8115626005155425}
2022-11-18 03:28:18,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:18,962 INFO:     Epoch: 96
2022-11-18 03:28:19,738 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7893914302641695, 'Total loss': 0.7893914302641695} | train loss {'Reaction outcome loss': 0.8141608709289182, 'Total loss': 0.8141608709289182}
2022-11-18 03:28:19,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:19,738 INFO:     Epoch: 97
2022-11-18 03:28:20,542 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8089465370232408, 'Total loss': 0.8089465370232408} | train loss {'Reaction outcome loss': 0.8144347763830616, 'Total loss': 0.8144347763830616}
2022-11-18 03:28:20,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:20,542 INFO:     Epoch: 98
2022-11-18 03:28:21,322 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7898844487287782, 'Total loss': 0.7898844487287782} | train loss {'Reaction outcome loss': 0.8135442438144838, 'Total loss': 0.8135442438144838}
2022-11-18 03:28:21,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:21,323 INFO:     Epoch: 99
2022-11-18 03:28:22,118 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7914829762144522, 'Total loss': 0.7914829762144522} | train loss {'Reaction outcome loss': 0.8093345766105959, 'Total loss': 0.8093345766105959}
2022-11-18 03:28:22,120 INFO:     Best model found after epoch 92 of 100.
2022-11-18 03:28:22,120 INFO:   Done with stage: TRAINING
2022-11-18 03:28:22,120 INFO:   Starting stage: EVALUATION
2022-11-18 03:28:22,238 INFO:   Done with stage: EVALUATION
2022-11-18 03:28:22,238 INFO:   Leaving out SEQ value Fold_5
2022-11-18 03:28:22,251 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 03:28:22,251 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:28:22,925 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:28:22,925 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:28:22,994 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:28:22,994 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:28:22,994 INFO:     No hyperparam tuning for this model
2022-11-18 03:28:22,994 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:28:22,994 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:28:22,995 INFO:     None feature selector for col prot
2022-11-18 03:28:22,995 INFO:     None feature selector for col prot
2022-11-18 03:28:22,995 INFO:     None feature selector for col prot
2022-11-18 03:28:22,996 INFO:     None feature selector for col chem
2022-11-18 03:28:22,996 INFO:     None feature selector for col chem
2022-11-18 03:28:22,996 INFO:     None feature selector for col chem
2022-11-18 03:28:22,996 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:28:22,996 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:28:22,997 INFO:     Number of params in model 168571
2022-11-18 03:28:23,001 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:28:23,001 INFO:   Starting stage: TRAINING
2022-11-18 03:28:23,058 INFO:     Val loss before train {'Reaction outcome loss': 0.9631574223326012, 'Total loss': 0.9631574223326012}
2022-11-18 03:28:23,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:23,058 INFO:     Epoch: 0
2022-11-18 03:28:23,838 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8031965358690782, 'Total loss': 0.8031965358690782} | train loss {'Reaction outcome loss': 0.8820104803357806, 'Total loss': 0.8820104803357806}
2022-11-18 03:28:23,839 INFO:     Found new best model at epoch 0
2022-11-18 03:28:23,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:23,839 INFO:     Epoch: 1
2022-11-18 03:28:24,622 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7952971112999049, 'Total loss': 0.7952971112999049} | train loss {'Reaction outcome loss': 0.850691854102271, 'Total loss': 0.850691854102271}
2022-11-18 03:28:24,622 INFO:     Found new best model at epoch 1
2022-11-18 03:28:24,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:24,624 INFO:     Epoch: 2
2022-11-18 03:28:25,417 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8027105954560366, 'Total loss': 0.8027105954560366} | train loss {'Reaction outcome loss': 0.841215486794102, 'Total loss': 0.841215486794102}
2022-11-18 03:28:25,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:25,417 INFO:     Epoch: 3
2022-11-18 03:28:26,197 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8110017539425329, 'Total loss': 0.8110017539425329} | train loss {'Reaction outcome loss': 0.8419907765729087, 'Total loss': 0.8419907765729087}
2022-11-18 03:28:26,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:26,197 INFO:     Epoch: 4
2022-11-18 03:28:26,983 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.798331699588082, 'Total loss': 0.798331699588082} | train loss {'Reaction outcome loss': 0.8349463670837636, 'Total loss': 0.8349463670837636}
2022-11-18 03:28:26,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:26,983 INFO:     Epoch: 5
2022-11-18 03:28:27,774 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8040634820407088, 'Total loss': 0.8040634820407088} | train loss {'Reaction outcome loss': 0.8350188869602826, 'Total loss': 0.8350188869602826}
2022-11-18 03:28:27,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:27,776 INFO:     Epoch: 6
2022-11-18 03:28:28,563 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8045718602158807, 'Total loss': 0.8045718602158807} | train loss {'Reaction outcome loss': 0.8296159336761553, 'Total loss': 0.8296159336761553}
2022-11-18 03:28:28,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:28,563 INFO:     Epoch: 7
2022-11-18 03:28:29,317 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7799716591835022, 'Total loss': 0.7799716591835022} | train loss {'Reaction outcome loss': 0.8308711113978405, 'Total loss': 0.8308711113978405}
2022-11-18 03:28:29,317 INFO:     Found new best model at epoch 7
2022-11-18 03:28:29,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:29,318 INFO:     Epoch: 8
2022-11-18 03:28:30,085 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8051402399485762, 'Total loss': 0.8051402399485762} | train loss {'Reaction outcome loss': 0.8301628939959468, 'Total loss': 0.8301628939959468}
2022-11-18 03:28:30,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:30,085 INFO:     Epoch: 9
2022-11-18 03:28:30,877 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8117174055765976, 'Total loss': 0.8117174055765976} | train loss {'Reaction outcome loss': 0.825124434305697, 'Total loss': 0.825124434305697}
2022-11-18 03:28:30,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:30,877 INFO:     Epoch: 10
2022-11-18 03:28:31,634 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7905931940132921, 'Total loss': 0.7905931940132921} | train loss {'Reaction outcome loss': 0.8289929477535949, 'Total loss': 0.8289929477535949}
2022-11-18 03:28:31,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:31,634 INFO:     Epoch: 11
2022-11-18 03:28:32,400 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7961142699826848, 'Total loss': 0.7961142699826848} | train loss {'Reaction outcome loss': 0.8206463776072678, 'Total loss': 0.8206463776072678}
2022-11-18 03:28:32,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:32,400 INFO:     Epoch: 12
2022-11-18 03:28:33,169 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7718848586082458, 'Total loss': 0.7718848586082458} | train loss {'Reaction outcome loss': 0.8249483848104672, 'Total loss': 0.8249483848104672}
2022-11-18 03:28:33,171 INFO:     Found new best model at epoch 12
2022-11-18 03:28:33,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:33,172 INFO:     Epoch: 13
2022-11-18 03:28:33,980 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7914190407503735, 'Total loss': 0.7914190407503735} | train loss {'Reaction outcome loss': 0.824243665471369, 'Total loss': 0.824243665471369}
2022-11-18 03:28:33,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:33,980 INFO:     Epoch: 14
2022-11-18 03:28:34,762 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7959425652568991, 'Total loss': 0.7959425652568991} | train loss {'Reaction outcome loss': 0.8239611837328696, 'Total loss': 0.8239611837328696}
2022-11-18 03:28:34,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:34,762 INFO:     Epoch: 15
2022-11-18 03:28:35,565 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7705694497986273, 'Total loss': 0.7705694497986273} | train loss {'Reaction outcome loss': 0.8253268885369204, 'Total loss': 0.8253268885369204}
2022-11-18 03:28:35,565 INFO:     Found new best model at epoch 15
2022-11-18 03:28:35,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:35,566 INFO:     Epoch: 16
2022-11-18 03:28:36,383 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7768435430797663, 'Total loss': 0.7768435430797663} | train loss {'Reaction outcome loss': 0.8186613646088814, 'Total loss': 0.8186613646088814}
2022-11-18 03:28:36,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:36,383 INFO:     Epoch: 17
2022-11-18 03:28:37,133 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7789572490887209, 'Total loss': 0.7789572490887209} | train loss {'Reaction outcome loss': 0.8234332381462565, 'Total loss': 0.8234332381462565}
2022-11-18 03:28:37,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:37,133 INFO:     Epoch: 18
2022-11-18 03:28:37,965 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7689160338856957, 'Total loss': 0.7689160338856957} | train loss {'Reaction outcome loss': 0.8194069993131015, 'Total loss': 0.8194069993131015}
2022-11-18 03:28:37,966 INFO:     Found new best model at epoch 18
2022-11-18 03:28:37,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:37,967 INFO:     Epoch: 19
2022-11-18 03:28:38,780 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7727654691446911, 'Total loss': 0.7727654691446911} | train loss {'Reaction outcome loss': 0.818257302897317, 'Total loss': 0.818257302897317}
2022-11-18 03:28:38,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:38,782 INFO:     Epoch: 20
2022-11-18 03:28:39,566 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8007875288074667, 'Total loss': 0.8007875288074667} | train loss {'Reaction outcome loss': 0.8207568911873564, 'Total loss': 0.8207568911873564}
2022-11-18 03:28:39,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:39,566 INFO:     Epoch: 21
2022-11-18 03:28:40,377 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7949593615802851, 'Total loss': 0.7949593615802851} | train loss {'Reaction outcome loss': 0.8193637582720542, 'Total loss': 0.8193637582720542}
2022-11-18 03:28:40,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:40,378 INFO:     Epoch: 22
2022-11-18 03:28:41,180 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7709960625930266, 'Total loss': 0.7709960625930266} | train loss {'Reaction outcome loss': 0.8175171242684734, 'Total loss': 0.8175171242684734}
2022-11-18 03:28:41,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:41,180 INFO:     Epoch: 23
2022-11-18 03:28:41,993 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7896897826682437, 'Total loss': 0.7896897826682437} | train loss {'Reaction outcome loss': 0.8168397416873854, 'Total loss': 0.8168397416873854}
2022-11-18 03:28:41,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:41,993 INFO:     Epoch: 24
2022-11-18 03:28:42,796 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.783419248055328, 'Total loss': 0.783419248055328} | train loss {'Reaction outcome loss': 0.8180155069244152, 'Total loss': 0.8180155069244152}
2022-11-18 03:28:42,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:42,797 INFO:     Epoch: 25
2022-11-18 03:28:43,586 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7812151543118737, 'Total loss': 0.7812151543118737} | train loss {'Reaction outcome loss': 0.8241913946307435, 'Total loss': 0.8241913946307435}
2022-11-18 03:28:43,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:43,586 INFO:     Epoch: 26
2022-11-18 03:28:44,363 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7743233753876253, 'Total loss': 0.7743233753876253} | train loss {'Reaction outcome loss': 0.8246909983304083, 'Total loss': 0.8246909983304083}
2022-11-18 03:28:44,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:44,366 INFO:     Epoch: 27
2022-11-18 03:28:45,173 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7798250994899056, 'Total loss': 0.7798250994899056} | train loss {'Reaction outcome loss': 0.8193621258346402, 'Total loss': 0.8193621258346402}
2022-11-18 03:28:45,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:45,173 INFO:     Epoch: 28
2022-11-18 03:28:45,971 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7763232290744781, 'Total loss': 0.7763232290744781} | train loss {'Reaction outcome loss': 0.8225953134955192, 'Total loss': 0.8225953134955192}
2022-11-18 03:28:45,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:45,972 INFO:     Epoch: 29
2022-11-18 03:28:46,800 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7754256996241483, 'Total loss': 0.7754256996241483} | train loss {'Reaction outcome loss': 0.8181775279191076, 'Total loss': 0.8181775279191076}
2022-11-18 03:28:46,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:46,800 INFO:     Epoch: 30
2022-11-18 03:28:47,615 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8001499900763686, 'Total loss': 0.8001499900763686} | train loss {'Reaction outcome loss': 0.8192365544182914, 'Total loss': 0.8192365544182914}
2022-11-18 03:28:47,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:47,615 INFO:     Epoch: 31
2022-11-18 03:28:48,482 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7952071225101297, 'Total loss': 0.7952071225101297} | train loss {'Reaction outcome loss': 0.8186731917517526, 'Total loss': 0.8186731917517526}
2022-11-18 03:28:48,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:48,483 INFO:     Epoch: 32
2022-11-18 03:28:49,299 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7940983589399945, 'Total loss': 0.7940983589399945} | train loss {'Reaction outcome loss': 0.8190099504529214, 'Total loss': 0.8190099504529214}
2022-11-18 03:28:49,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:49,300 INFO:     Epoch: 33
2022-11-18 03:28:50,063 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7787424806844104, 'Total loss': 0.7787424806844104} | train loss {'Reaction outcome loss': 0.8213169236572422, 'Total loss': 0.8213169236572422}
2022-11-18 03:28:50,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:50,064 INFO:     Epoch: 34
2022-11-18 03:28:50,840 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7860825969414278, 'Total loss': 0.7860825969414278} | train loss {'Reaction outcome loss': 0.8237973805592984, 'Total loss': 0.8237973805592984}
2022-11-18 03:28:50,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:50,841 INFO:     Epoch: 35
2022-11-18 03:28:51,590 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.779138443144885, 'Total loss': 0.779138443144885} | train loss {'Reaction outcome loss': 0.8190467353986234, 'Total loss': 0.8190467353986234}
2022-11-18 03:28:51,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:51,590 INFO:     Epoch: 36
2022-11-18 03:28:52,395 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7736056155779145, 'Total loss': 0.7736056155779145} | train loss {'Reaction outcome loss': 0.8178139893376097, 'Total loss': 0.8178139893376097}
2022-11-18 03:28:52,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:52,395 INFO:     Epoch: 37
2022-11-18 03:28:53,170 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7901024303653024, 'Total loss': 0.7901024303653024} | train loss {'Reaction outcome loss': 0.8165429800140614, 'Total loss': 0.8165429800140614}
2022-11-18 03:28:53,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:53,170 INFO:     Epoch: 38
2022-11-18 03:28:53,955 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7698473395271734, 'Total loss': 0.7698473395271734} | train loss {'Reaction outcome loss': 0.8171135185932626, 'Total loss': 0.8171135185932626}
2022-11-18 03:28:53,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:53,956 INFO:     Epoch: 39
2022-11-18 03:28:54,734 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7668262713334777, 'Total loss': 0.7668262713334777} | train loss {'Reaction outcome loss': 0.8184326991742971, 'Total loss': 0.8184326991742971}
2022-11-18 03:28:54,734 INFO:     Found new best model at epoch 39
2022-11-18 03:28:54,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:54,735 INFO:     Epoch: 40
2022-11-18 03:28:55,464 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7997683422131971, 'Total loss': 0.7997683422131971} | train loss {'Reaction outcome loss': 0.8221400153880216, 'Total loss': 0.8221400153880216}
2022-11-18 03:28:55,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:55,465 INFO:     Epoch: 41
2022-11-18 03:28:56,237 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7750848911025308, 'Total loss': 0.7750848911025308} | train loss {'Reaction outcome loss': 0.8164823321663603, 'Total loss': 0.8164823321663603}
2022-11-18 03:28:56,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:56,237 INFO:     Epoch: 42
2022-11-18 03:28:56,998 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7769436226649717, 'Total loss': 0.7769436226649717} | train loss {'Reaction outcome loss': 0.8118789158305343, 'Total loss': 0.8118789158305343}
2022-11-18 03:28:56,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:56,998 INFO:     Epoch: 43
2022-11-18 03:28:57,775 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8008774972774766, 'Total loss': 0.8008774972774766} | train loss {'Reaction outcome loss': 0.8128897626789249, 'Total loss': 0.8128897626789249}
2022-11-18 03:28:57,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:57,775 INFO:     Epoch: 44
2022-11-18 03:28:58,567 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7818844575773586, 'Total loss': 0.7818844575773586} | train loss {'Reaction outcome loss': 0.8150596045717902, 'Total loss': 0.8150596045717902}
2022-11-18 03:28:58,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:58,568 INFO:     Epoch: 45
2022-11-18 03:28:59,341 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7674835839054801, 'Total loss': 0.7674835839054801} | train loss {'Reaction outcome loss': 0.815654426326557, 'Total loss': 0.815654426326557}
2022-11-18 03:28:59,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:28:59,341 INFO:     Epoch: 46
2022-11-18 03:29:00,116 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7699105448343537, 'Total loss': 0.7699105448343537} | train loss {'Reaction outcome loss': 0.8157661751824983, 'Total loss': 0.8157661751824983}
2022-11-18 03:29:00,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:00,116 INFO:     Epoch: 47
2022-11-18 03:29:00,886 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7667915990406816, 'Total loss': 0.7667915990406816} | train loss {'Reaction outcome loss': 0.818485275944885, 'Total loss': 0.818485275944885}
2022-11-18 03:29:00,887 INFO:     Found new best model at epoch 47
2022-11-18 03:29:00,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:00,888 INFO:     Epoch: 48
2022-11-18 03:29:01,661 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7809250192208723, 'Total loss': 0.7809250192208723} | train loss {'Reaction outcome loss': 0.8140676770891462, 'Total loss': 0.8140676770891462}
2022-11-18 03:29:01,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:01,661 INFO:     Epoch: 49
2022-11-18 03:29:02,449 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.784156474200162, 'Total loss': 0.784156474200162} | train loss {'Reaction outcome loss': 0.8175659487442094, 'Total loss': 0.8175659487442094}
2022-11-18 03:29:02,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:02,450 INFO:     Epoch: 50
2022-11-18 03:29:03,226 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.786929002539678, 'Total loss': 0.786929002539678} | train loss {'Reaction outcome loss': 0.8196629746836059, 'Total loss': 0.8196629746836059}
2022-11-18 03:29:03,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:03,226 INFO:     Epoch: 51
2022-11-18 03:29:04,005 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7495937008749355, 'Total loss': 0.7495937008749355} | train loss {'Reaction outcome loss': 0.8127593085473898, 'Total loss': 0.8127593085473898}
2022-11-18 03:29:04,005 INFO:     Found new best model at epoch 51
2022-11-18 03:29:04,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:04,006 INFO:     Epoch: 52
2022-11-18 03:29:04,781 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7738804024728861, 'Total loss': 0.7738804024728861} | train loss {'Reaction outcome loss': 0.813565984064219, 'Total loss': 0.813565984064219}
2022-11-18 03:29:04,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:04,781 INFO:     Epoch: 53
2022-11-18 03:29:05,558 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7796991575847972, 'Total loss': 0.7796991575847972} | train loss {'Reaction outcome loss': 0.8177150569400009, 'Total loss': 0.8177150569400009}
2022-11-18 03:29:05,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:05,558 INFO:     Epoch: 54
2022-11-18 03:29:06,347 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7963924638249658, 'Total loss': 0.7963924638249658} | train loss {'Reaction outcome loss': 0.8165436455181667, 'Total loss': 0.8165436455181667}
2022-11-18 03:29:06,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:06,349 INFO:     Epoch: 55
2022-11-18 03:29:07,139 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7815518020228907, 'Total loss': 0.7815518020228907} | train loss {'Reaction outcome loss': 0.8137916314358614, 'Total loss': 0.8137916314358614}
2022-11-18 03:29:07,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:07,139 INFO:     Epoch: 56
2022-11-18 03:29:07,912 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7811902361837301, 'Total loss': 0.7811902361837301} | train loss {'Reaction outcome loss': 0.8199084604881248, 'Total loss': 0.8199084604881248}
2022-11-18 03:29:07,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:07,912 INFO:     Epoch: 57
2022-11-18 03:29:08,725 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.792962911454114, 'Total loss': 0.792962911454114} | train loss {'Reaction outcome loss': 0.8163124423854206, 'Total loss': 0.8163124423854206}
2022-11-18 03:29:08,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:08,725 INFO:     Epoch: 58
2022-11-18 03:29:09,507 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7759854170409116, 'Total loss': 0.7759854170409116} | train loss {'Reaction outcome loss': 0.8165654398957077, 'Total loss': 0.8165654398957077}
2022-11-18 03:29:09,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:09,508 INFO:     Epoch: 59
2022-11-18 03:29:10,299 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7603388577699661, 'Total loss': 0.7603388577699661} | train loss {'Reaction outcome loss': 0.8170148943151746, 'Total loss': 0.8170148943151746}
2022-11-18 03:29:10,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:10,300 INFO:     Epoch: 60
2022-11-18 03:29:11,082 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7872457131743431, 'Total loss': 0.7872457131743431} | train loss {'Reaction outcome loss': 0.8140692011434205, 'Total loss': 0.8140692011434205}
2022-11-18 03:29:11,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:11,082 INFO:     Epoch: 61
2022-11-18 03:29:11,860 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7666683346033096, 'Total loss': 0.7666683346033096} | train loss {'Reaction outcome loss': 0.8176224591780682, 'Total loss': 0.8176224591780682}
2022-11-18 03:29:11,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:11,862 INFO:     Epoch: 62
2022-11-18 03:29:12,648 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7853820899670775, 'Total loss': 0.7853820899670775} | train loss {'Reaction outcome loss': 0.815314091589986, 'Total loss': 0.815314091589986}
2022-11-18 03:29:12,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:12,649 INFO:     Epoch: 63
2022-11-18 03:29:13,415 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7724734399129044, 'Total loss': 0.7724734399129044} | train loss {'Reaction outcome loss': 0.8113669164326727, 'Total loss': 0.8113669164326727}
2022-11-18 03:29:13,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:13,416 INFO:     Epoch: 64
2022-11-18 03:29:14,220 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7701712616465308, 'Total loss': 0.7701712616465308} | train loss {'Reaction outcome loss': 0.8125905944376576, 'Total loss': 0.8125905944376576}
2022-11-18 03:29:14,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:14,221 INFO:     Epoch: 65
2022-11-18 03:29:15,004 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7784593775868416, 'Total loss': 0.7784593775868416} | train loss {'Reaction outcome loss': 0.8142699094451203, 'Total loss': 0.8142699094451203}
2022-11-18 03:29:15,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:15,004 INFO:     Epoch: 66
2022-11-18 03:29:15,812 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7871484350074421, 'Total loss': 0.7871484350074421} | train loss {'Reaction outcome loss': 0.8133440533462836, 'Total loss': 0.8133440533462836}
2022-11-18 03:29:15,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:15,813 INFO:     Epoch: 67
2022-11-18 03:29:16,579 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7809628776528619, 'Total loss': 0.7809628776528619} | train loss {'Reaction outcome loss': 0.8151721459262226, 'Total loss': 0.8151721459262226}
2022-11-18 03:29:16,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:16,580 INFO:     Epoch: 68
2022-11-18 03:29:17,357 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7693179954182018, 'Total loss': 0.7693179954182018} | train loss {'Reaction outcome loss': 0.8194757439652268, 'Total loss': 0.8194757439652268}
2022-11-18 03:29:17,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:17,358 INFO:     Epoch: 69
2022-11-18 03:29:18,167 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7627885246818716, 'Total loss': 0.7627885246818716} | train loss {'Reaction outcome loss': 0.810984146351717, 'Total loss': 0.810984146351717}
2022-11-18 03:29:18,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:18,168 INFO:     Epoch: 70
2022-11-18 03:29:18,946 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7614105960184877, 'Total loss': 0.7614105960184877} | train loss {'Reaction outcome loss': 0.8126691060406821, 'Total loss': 0.8126691060406821}
2022-11-18 03:29:18,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:18,947 INFO:     Epoch: 71
2022-11-18 03:29:19,718 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7754700874740427, 'Total loss': 0.7754700874740427} | train loss {'Reaction outcome loss': 0.8161320522123453, 'Total loss': 0.8161320522123453}
2022-11-18 03:29:19,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:19,719 INFO:     Epoch: 72
2022-11-18 03:29:20,478 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7877646406943147, 'Total loss': 0.7877646406943147} | train loss {'Reaction outcome loss': 0.8165538702692304, 'Total loss': 0.8165538702692304}
2022-11-18 03:29:20,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:20,478 INFO:     Epoch: 73
2022-11-18 03:29:21,265 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7895855571735989, 'Total loss': 0.7895855571735989} | train loss {'Reaction outcome loss': 0.8145660678951108, 'Total loss': 0.8145660678951108}
2022-11-18 03:29:21,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:21,265 INFO:     Epoch: 74
2022-11-18 03:29:22,024 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7695731818675995, 'Total loss': 0.7695731818675995} | train loss {'Reaction outcome loss': 0.8112448778687691, 'Total loss': 0.8112448778687691}
2022-11-18 03:29:22,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:22,024 INFO:     Epoch: 75
2022-11-18 03:29:22,804 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7873808341947469, 'Total loss': 0.7873808341947469} | train loss {'Reaction outcome loss': 0.8147956436994125, 'Total loss': 0.8147956436994125}
2022-11-18 03:29:22,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:22,805 INFO:     Epoch: 76
2022-11-18 03:29:23,602 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7786886549808762, 'Total loss': 0.7786886549808762} | train loss {'Reaction outcome loss': 0.8169339721300164, 'Total loss': 0.8169339721300164}
2022-11-18 03:29:23,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:23,602 INFO:     Epoch: 77
2022-11-18 03:29:24,396 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7537830746309324, 'Total loss': 0.7537830746309324} | train loss {'Reaction outcome loss': 0.8139953519616808, 'Total loss': 0.8139953519616808}
2022-11-18 03:29:24,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:24,397 INFO:     Epoch: 78
2022-11-18 03:29:25,140 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7563834271647714, 'Total loss': 0.7563834271647714} | train loss {'Reaction outcome loss': 0.8161514148420217, 'Total loss': 0.8161514148420217}
2022-11-18 03:29:25,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:25,141 INFO:     Epoch: 79
2022-11-18 03:29:25,912 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7709231755950234, 'Total loss': 0.7709231755950234} | train loss {'Reaction outcome loss': 0.8157562792301178, 'Total loss': 0.8157562792301178}
2022-11-18 03:29:25,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:25,912 INFO:     Epoch: 80
2022-11-18 03:29:26,694 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7821205427700822, 'Total loss': 0.7821205427700822} | train loss {'Reaction outcome loss': 0.8146441346528579, 'Total loss': 0.8146441346528579}
2022-11-18 03:29:26,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:26,694 INFO:     Epoch: 81
2022-11-18 03:29:27,467 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7903375706889413, 'Total loss': 0.7903375706889413} | train loss {'Reaction outcome loss': 0.8151890760781814, 'Total loss': 0.8151890760781814}
2022-11-18 03:29:27,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:27,467 INFO:     Epoch: 82
2022-11-18 03:29:28,248 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7781390913508155, 'Total loss': 0.7781390913508155} | train loss {'Reaction outcome loss': 0.8146901208527234, 'Total loss': 0.8146901208527234}
2022-11-18 03:29:28,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:28,249 INFO:     Epoch: 83
2022-11-18 03:29:29,038 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.772727142680775, 'Total loss': 0.772727142680775} | train loss {'Reaction outcome loss': 0.8172581488988837, 'Total loss': 0.8172581488988837}
2022-11-18 03:29:29,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:29,038 INFO:     Epoch: 84
2022-11-18 03:29:29,837 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7724887268109755, 'Total loss': 0.7724887268109755} | train loss {'Reaction outcome loss': 0.8133445917343607, 'Total loss': 0.8133445917343607}
2022-11-18 03:29:29,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:29,837 INFO:     Epoch: 85
2022-11-18 03:29:30,627 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7667361890727823, 'Total loss': 0.7667361890727823} | train loss {'Reaction outcome loss': 0.8163115384627362, 'Total loss': 0.8163115384627362}
2022-11-18 03:29:30,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:30,627 INFO:     Epoch: 86
2022-11-18 03:29:31,421 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7860781699419022, 'Total loss': 0.7860781699419022} | train loss {'Reaction outcome loss': 0.8160640761560324, 'Total loss': 0.8160640761560324}
2022-11-18 03:29:31,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:31,421 INFO:     Epoch: 87
2022-11-18 03:29:32,186 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7750713567842137, 'Total loss': 0.7750713567842137} | train loss {'Reaction outcome loss': 0.8166238348094784, 'Total loss': 0.8166238348094784}
2022-11-18 03:29:32,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:32,186 INFO:     Epoch: 88
2022-11-18 03:29:32,934 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7856170982122421, 'Total loss': 0.7856170982122421} | train loss {'Reaction outcome loss': 0.816408280815397, 'Total loss': 0.816408280815397}
2022-11-18 03:29:32,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:32,934 INFO:     Epoch: 89
2022-11-18 03:29:33,713 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7780946533788334, 'Total loss': 0.7780946533788334} | train loss {'Reaction outcome loss': 0.8164393845869571, 'Total loss': 0.8164393845869571}
2022-11-18 03:29:33,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:33,714 INFO:     Epoch: 90
2022-11-18 03:29:34,498 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7800619588656859, 'Total loss': 0.7800619588656859} | train loss {'Reaction outcome loss': 0.8104313022019912, 'Total loss': 0.8104313022019912}
2022-11-18 03:29:34,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:34,498 INFO:     Epoch: 91
2022-11-18 03:29:35,258 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7859345024282282, 'Total loss': 0.7859345024282282} | train loss {'Reaction outcome loss': 0.8120576103122867, 'Total loss': 0.8120576103122867}
2022-11-18 03:29:35,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:35,258 INFO:     Epoch: 92
2022-11-18 03:29:36,038 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7824620489369739, 'Total loss': 0.7824620489369739} | train loss {'Reaction outcome loss': 0.8164449403480608, 'Total loss': 0.8164449403480608}
2022-11-18 03:29:36,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:36,038 INFO:     Epoch: 93
2022-11-18 03:29:36,818 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7546892074698751, 'Total loss': 0.7546892074698751} | train loss {'Reaction outcome loss': 0.8118482089772516, 'Total loss': 0.8118482089772516}
2022-11-18 03:29:36,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:36,818 INFO:     Epoch: 94
2022-11-18 03:29:37,597 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7976024218580939, 'Total loss': 0.7976024218580939} | train loss {'Reaction outcome loss': 0.8132443227330033, 'Total loss': 0.8132443227330033}
2022-11-18 03:29:37,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:37,597 INFO:     Epoch: 95
2022-11-18 03:29:38,363 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7911274189298804, 'Total loss': 0.7911274189298804} | train loss {'Reaction outcome loss': 0.8127168863403554, 'Total loss': 0.8127168863403554}
2022-11-18 03:29:38,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:38,363 INFO:     Epoch: 96
2022-11-18 03:29:39,146 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7767063404687427, 'Total loss': 0.7767063404687427} | train loss {'Reaction outcome loss': 0.8118284150045745, 'Total loss': 0.8118284150045745}
2022-11-18 03:29:39,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:39,147 INFO:     Epoch: 97
2022-11-18 03:29:39,922 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7635832818394358, 'Total loss': 0.7635832818394358} | train loss {'Reaction outcome loss': 0.8186626901431959, 'Total loss': 0.8186626901431959}
2022-11-18 03:29:39,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:39,922 INFO:     Epoch: 98
2022-11-18 03:29:40,752 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7679411762140014, 'Total loss': 0.7679411762140014} | train loss {'Reaction outcome loss': 0.8140269123778051, 'Total loss': 0.8140269123778051}
2022-11-18 03:29:40,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:40,753 INFO:     Epoch: 99
2022-11-18 03:29:41,527 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7736550183458761, 'Total loss': 0.7736550183458761} | train loss {'Reaction outcome loss': 0.8158608752854016, 'Total loss': 0.8158608752854016}
2022-11-18 03:29:41,527 INFO:     Best model found after epoch 52 of 100.
2022-11-18 03:29:41,527 INFO:   Done with stage: TRAINING
2022-11-18 03:29:41,527 INFO:   Starting stage: EVALUATION
2022-11-18 03:29:41,656 INFO:   Done with stage: EVALUATION
2022-11-18 03:29:41,656 INFO:   Leaving out SEQ value Fold_6
2022-11-18 03:29:41,670 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 03:29:41,670 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:29:42,328 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:29:42,328 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:29:42,397 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:29:42,397 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:29:42,398 INFO:     No hyperparam tuning for this model
2022-11-18 03:29:42,398 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:29:42,398 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:29:42,399 INFO:     None feature selector for col prot
2022-11-18 03:29:42,399 INFO:     None feature selector for col prot
2022-11-18 03:29:42,399 INFO:     None feature selector for col prot
2022-11-18 03:29:42,400 INFO:     None feature selector for col chem
2022-11-18 03:29:42,400 INFO:     None feature selector for col chem
2022-11-18 03:29:42,400 INFO:     None feature selector for col chem
2022-11-18 03:29:42,401 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:29:42,401 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:29:42,403 INFO:     Number of params in model 168571
2022-11-18 03:29:42,406 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:29:42,407 INFO:   Starting stage: TRAINING
2022-11-18 03:29:42,463 INFO:     Val loss before train {'Reaction outcome loss': 1.0461134674937227, 'Total loss': 1.0461134674937227}
2022-11-18 03:29:42,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:42,463 INFO:     Epoch: 0
2022-11-18 03:29:43,240 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8754169580548309, 'Total loss': 0.8754169580548309} | train loss {'Reaction outcome loss': 0.8649770160678958, 'Total loss': 0.8649770160678958}
2022-11-18 03:29:43,240 INFO:     Found new best model at epoch 0
2022-11-18 03:29:43,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:43,241 INFO:     Epoch: 1
2022-11-18 03:29:43,995 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8459394019703532, 'Total loss': 0.8459394019703532} | train loss {'Reaction outcome loss': 0.8375273307815927, 'Total loss': 0.8375273307815927}
2022-11-18 03:29:43,995 INFO:     Found new best model at epoch 1
2022-11-18 03:29:43,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:43,996 INFO:     Epoch: 2
2022-11-18 03:29:44,788 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8671006047448446, 'Total loss': 0.8671006047448446} | train loss {'Reaction outcome loss': 0.8269193851556934, 'Total loss': 0.8269193851556934}
2022-11-18 03:29:44,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:44,790 INFO:     Epoch: 3
2022-11-18 03:29:45,557 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.853675341883371, 'Total loss': 0.853675341883371} | train loss {'Reaction outcome loss': 0.8300102660890485, 'Total loss': 0.8300102660890485}
2022-11-18 03:29:45,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:45,557 INFO:     Epoch: 4
2022-11-18 03:29:46,329 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8566627544026042, 'Total loss': 0.8566627544026042} | train loss {'Reaction outcome loss': 0.8204509658647365, 'Total loss': 0.8204509658647365}
2022-11-18 03:29:46,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:46,330 INFO:     Epoch: 5
2022-11-18 03:29:47,109 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8412741921668829, 'Total loss': 0.8412741921668829} | train loss {'Reaction outcome loss': 0.8192250709064671, 'Total loss': 0.8192250709064671}
2022-11-18 03:29:47,109 INFO:     Found new best model at epoch 5
2022-11-18 03:29:47,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:47,110 INFO:     Epoch: 6
2022-11-18 03:29:47,892 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.884253345256628, 'Total loss': 0.884253345256628} | train loss {'Reaction outcome loss': 0.8151060815473072, 'Total loss': 0.8151060815473072}
2022-11-18 03:29:47,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:47,892 INFO:     Epoch: 7
2022-11-18 03:29:48,683 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8435653586720311, 'Total loss': 0.8435653586720311} | train loss {'Reaction outcome loss': 0.8116134766672478, 'Total loss': 0.8116134766672478}
2022-11-18 03:29:48,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:48,683 INFO:     Epoch: 8
2022-11-18 03:29:49,471 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8369755135026089, 'Total loss': 0.8369755135026089} | train loss {'Reaction outcome loss': 0.8091698020208077, 'Total loss': 0.8091698020208077}
2022-11-18 03:29:49,471 INFO:     Found new best model at epoch 8
2022-11-18 03:29:49,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:49,473 INFO:     Epoch: 9
2022-11-18 03:29:50,244 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8311314555101617, 'Total loss': 0.8311314555101617} | train loss {'Reaction outcome loss': 0.8120291892622338, 'Total loss': 0.8120291892622338}
2022-11-18 03:29:50,245 INFO:     Found new best model at epoch 9
2022-11-18 03:29:50,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:50,246 INFO:     Epoch: 10
2022-11-18 03:29:51,024 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8465873543606248, 'Total loss': 0.8465873543606248} | train loss {'Reaction outcome loss': 0.8077392595224693, 'Total loss': 0.8077392595224693}
2022-11-18 03:29:51,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:51,025 INFO:     Epoch: 11
2022-11-18 03:29:51,804 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8378461932027063, 'Total loss': 0.8378461932027063} | train loss {'Reaction outcome loss': 0.8083414214312054, 'Total loss': 0.8083414214312054}
2022-11-18 03:29:51,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:51,804 INFO:     Epoch: 12
2022-11-18 03:29:52,589 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8460974610129068, 'Total loss': 0.8460974610129068} | train loss {'Reaction outcome loss': 0.8044203030037098, 'Total loss': 0.8044203030037098}
2022-11-18 03:29:52,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:52,589 INFO:     Epoch: 13
2022-11-18 03:29:53,363 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.845392728267714, 'Total loss': 0.845392728267714} | train loss {'Reaction outcome loss': 0.8065831518319787, 'Total loss': 0.8065831518319787}
2022-11-18 03:29:53,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:53,363 INFO:     Epoch: 14
2022-11-18 03:29:54,133 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8378494603689327, 'Total loss': 0.8378494603689327} | train loss {'Reaction outcome loss': 0.8020337270420106, 'Total loss': 0.8020337270420106}
2022-11-18 03:29:54,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:54,133 INFO:     Epoch: 15
2022-11-18 03:29:54,915 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8416715222735738, 'Total loss': 0.8416715222735738} | train loss {'Reaction outcome loss': 0.8062146033664219, 'Total loss': 0.8062146033664219}
2022-11-18 03:29:54,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:54,915 INFO:     Epoch: 16
2022-11-18 03:29:55,697 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8527283405148706, 'Total loss': 0.8527283405148706} | train loss {'Reaction outcome loss': 0.8055964235643871, 'Total loss': 0.8055964235643871}
2022-11-18 03:29:55,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:55,698 INFO:     Epoch: 17
2022-11-18 03:29:56,474 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8419301149457, 'Total loss': 0.8419301149457} | train loss {'Reaction outcome loss': 0.808098024764999, 'Total loss': 0.808098024764999}
2022-11-18 03:29:56,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:56,475 INFO:     Epoch: 18
2022-11-18 03:29:57,253 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8509106344954912, 'Total loss': 0.8509106344954912} | train loss {'Reaction outcome loss': 0.8032737287585853, 'Total loss': 0.8032737287585853}
2022-11-18 03:29:57,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:57,253 INFO:     Epoch: 19
2022-11-18 03:29:58,022 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8646021707113399, 'Total loss': 0.8646021707113399} | train loss {'Reaction outcome loss': 0.8058743370605297, 'Total loss': 0.8058743370605297}
2022-11-18 03:29:58,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:58,022 INFO:     Epoch: 20
2022-11-18 03:29:58,791 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8808736024900924, 'Total loss': 0.8808736024900924} | train loss {'Reaction outcome loss': 0.8068882948795303, 'Total loss': 0.8068882948795303}
2022-11-18 03:29:58,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:58,791 INFO:     Epoch: 21
2022-11-18 03:29:59,581 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8359852786674056, 'Total loss': 0.8359852786674056} | train loss {'Reaction outcome loss': 0.8054881768881298, 'Total loss': 0.8054881768881298}
2022-11-18 03:29:59,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:29:59,582 INFO:     Epoch: 22
2022-11-18 03:30:00,367 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8382756869460262, 'Total loss': 0.8382756869460262} | train loss {'Reaction outcome loss': 0.8038260355347493, 'Total loss': 0.8038260355347493}
2022-11-18 03:30:00,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:00,368 INFO:     Epoch: 23
2022-11-18 03:30:01,153 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8504901313504507, 'Total loss': 0.8504901313504507} | train loss {'Reaction outcome loss': 0.7990631022658504, 'Total loss': 0.7990631022658504}
2022-11-18 03:30:01,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:01,154 INFO:     Epoch: 24
2022-11-18 03:30:01,908 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8483147662739421, 'Total loss': 0.8483147662739421} | train loss {'Reaction outcome loss': 0.8076122404366243, 'Total loss': 0.8076122404366243}
2022-11-18 03:30:01,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:01,908 INFO:     Epoch: 25
2022-11-18 03:30:02,686 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8360973430234332, 'Total loss': 0.8360973430234332} | train loss {'Reaction outcome loss': 0.800065106666479, 'Total loss': 0.800065106666479}
2022-11-18 03:30:02,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:02,687 INFO:     Epoch: 26
2022-11-18 03:30:03,465 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8510093009749125, 'Total loss': 0.8510093009749125} | train loss {'Reaction outcome loss': 0.8013419765429418, 'Total loss': 0.8013419765429418}
2022-11-18 03:30:03,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:03,465 INFO:     Epoch: 27
2022-11-18 03:30:04,258 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8723537824874701, 'Total loss': 0.8723537824874701} | train loss {'Reaction outcome loss': 0.798387424256958, 'Total loss': 0.798387424256958}
2022-11-18 03:30:04,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:04,258 INFO:     Epoch: 28
2022-11-18 03:30:05,060 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8479969196541365, 'Total loss': 0.8479969196541365} | train loss {'Reaction outcome loss': 0.8010646038856662, 'Total loss': 0.8010646038856662}
2022-11-18 03:30:05,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:05,060 INFO:     Epoch: 29
2022-11-18 03:30:05,851 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8546243656513303, 'Total loss': 0.8546243656513303} | train loss {'Reaction outcome loss': 0.8049347459292803, 'Total loss': 0.8049347459292803}
2022-11-18 03:30:05,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:05,851 INFO:     Epoch: 30
2022-11-18 03:30:06,622 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8390423482240632, 'Total loss': 0.8390423482240632} | train loss {'Reaction outcome loss': 0.7990275913330375, 'Total loss': 0.7990275913330375}
2022-11-18 03:30:06,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:06,623 INFO:     Epoch: 31
2022-11-18 03:30:07,446 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8444819824640141, 'Total loss': 0.8444819824640141} | train loss {'Reaction outcome loss': 0.8004132504345941, 'Total loss': 0.8004132504345941}
2022-11-18 03:30:07,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:07,447 INFO:     Epoch: 32
2022-11-18 03:30:08,267 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8312279103800307, 'Total loss': 0.8312279103800307} | train loss {'Reaction outcome loss': 0.7990520773608176, 'Total loss': 0.7990520773608176}
2022-11-18 03:30:08,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:08,267 INFO:     Epoch: 33
2022-11-18 03:30:09,016 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8467816904533741, 'Total loss': 0.8467816904533741} | train loss {'Reaction outcome loss': 0.7961573462139387, 'Total loss': 0.7961573462139387}
2022-11-18 03:30:09,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:09,017 INFO:     Epoch: 34
2022-11-18 03:30:09,816 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8300724112710287, 'Total loss': 0.8300724112710287} | train loss {'Reaction outcome loss': 0.801464924313983, 'Total loss': 0.801464924313983}
2022-11-18 03:30:09,816 INFO:     Found new best model at epoch 34
2022-11-18 03:30:09,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:09,817 INFO:     Epoch: 35
2022-11-18 03:30:10,603 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8330593067546224, 'Total loss': 0.8330593067546224} | train loss {'Reaction outcome loss': 0.8022560265953423, 'Total loss': 0.8022560265953423}
2022-11-18 03:30:10,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:10,603 INFO:     Epoch: 36
2022-11-18 03:30:11,413 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8318397111670915, 'Total loss': 0.8318397111670915} | train loss {'Reaction outcome loss': 0.7979592431764133, 'Total loss': 0.7979592431764133}
2022-11-18 03:30:11,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:11,414 INFO:     Epoch: 37
2022-11-18 03:30:12,230 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8381277184153713, 'Total loss': 0.8381277184153713} | train loss {'Reaction outcome loss': 0.7960615537938525, 'Total loss': 0.7960615537938525}
2022-11-18 03:30:12,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:12,230 INFO:     Epoch: 38
2022-11-18 03:30:13,016 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8619016221789426, 'Total loss': 0.8619016221789426} | train loss {'Reaction outcome loss': 0.7951726351605087, 'Total loss': 0.7951726351605087}
2022-11-18 03:30:13,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:13,018 INFO:     Epoch: 39
2022-11-18 03:30:13,821 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8314597371012665, 'Total loss': 0.8314597371012665} | train loss {'Reaction outcome loss': 0.8015510729346119, 'Total loss': 0.8015510729346119}
2022-11-18 03:30:13,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:13,821 INFO:     Epoch: 40
2022-11-18 03:30:14,629 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8274206325065258, 'Total loss': 0.8274206325065258} | train loss {'Reaction outcome loss': 0.7994277736202615, 'Total loss': 0.7994277736202615}
2022-11-18 03:30:14,629 INFO:     Found new best model at epoch 40
2022-11-18 03:30:14,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:14,630 INFO:     Epoch: 41
2022-11-18 03:30:15,451 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8476101915503658, 'Total loss': 0.8476101915503658} | train loss {'Reaction outcome loss': 0.7973179035499448, 'Total loss': 0.7973179035499448}
2022-11-18 03:30:15,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:15,451 INFO:     Epoch: 42
2022-11-18 03:30:16,254 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8361366127812585, 'Total loss': 0.8361366127812585} | train loss {'Reaction outcome loss': 0.7990422097385906, 'Total loss': 0.7990422097385906}
2022-11-18 03:30:16,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:16,255 INFO:     Epoch: 43
2022-11-18 03:30:17,082 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8571962326071983, 'Total loss': 0.8571962326071983} | train loss {'Reaction outcome loss': 0.7941525723846232, 'Total loss': 0.7941525723846232}
2022-11-18 03:30:17,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:17,082 INFO:     Epoch: 44
2022-11-18 03:30:17,897 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8481942831083785, 'Total loss': 0.8481942831083785} | train loss {'Reaction outcome loss': 0.8030160774217278, 'Total loss': 0.8030160774217278}
2022-11-18 03:30:17,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:17,897 INFO:     Epoch: 45
2022-11-18 03:30:18,685 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8340701481630636, 'Total loss': 0.8340701481630636} | train loss {'Reaction outcome loss': 0.8005010429464403, 'Total loss': 0.8005010429464403}
2022-11-18 03:30:18,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:18,685 INFO:     Epoch: 46
2022-11-18 03:30:19,466 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8435887985451277, 'Total loss': 0.8435887985451277} | train loss {'Reaction outcome loss': 0.7985443312857972, 'Total loss': 0.7985443312857972}
2022-11-18 03:30:19,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:19,467 INFO:     Epoch: 47
2022-11-18 03:30:20,259 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.9218399746473446, 'Total loss': 0.9218399746473446} | train loss {'Reaction outcome loss': 0.7935548898626547, 'Total loss': 0.7935548898626547}
2022-11-18 03:30:20,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:20,259 INFO:     Epoch: 48
2022-11-18 03:30:21,053 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8405605942703956, 'Total loss': 0.8405605942703956} | train loss {'Reaction outcome loss': 0.7983541423912908, 'Total loss': 0.7983541423912908}
2022-11-18 03:30:21,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:21,054 INFO:     Epoch: 49
2022-11-18 03:30:21,871 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8289262721704882, 'Total loss': 0.8289262721704882} | train loss {'Reaction outcome loss': 0.7963908011796045, 'Total loss': 0.7963908011796045}
2022-11-18 03:30:21,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:21,871 INFO:     Epoch: 50
2022-11-18 03:30:22,667 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8280324048774187, 'Total loss': 0.8280324048774187} | train loss {'Reaction outcome loss': 0.7984761517555987, 'Total loss': 0.7984761517555987}
2022-11-18 03:30:22,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:22,668 INFO:     Epoch: 51
2022-11-18 03:30:23,452 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8386788908825364, 'Total loss': 0.8386788908825364} | train loss {'Reaction outcome loss': 0.7978199279454888, 'Total loss': 0.7978199279454888}
2022-11-18 03:30:23,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:23,452 INFO:     Epoch: 52
2022-11-18 03:30:24,252 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8335867011269857, 'Total loss': 0.8335867011269857} | train loss {'Reaction outcome loss': 0.7956307413148098, 'Total loss': 0.7956307413148098}
2022-11-18 03:30:24,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:24,252 INFO:     Epoch: 53
2022-11-18 03:30:25,063 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8293595064518063, 'Total loss': 0.8293595064518063} | train loss {'Reaction outcome loss': 0.7956002331415161, 'Total loss': 0.7956002331415161}
2022-11-18 03:30:25,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:25,064 INFO:     Epoch: 54
2022-11-18 03:30:25,827 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8289277248604353, 'Total loss': 0.8289277248604353} | train loss {'Reaction outcome loss': 0.8016308833096848, 'Total loss': 0.8016308833096848}
2022-11-18 03:30:25,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:25,828 INFO:     Epoch: 55
2022-11-18 03:30:26,629 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8328422093114187, 'Total loss': 0.8328422093114187} | train loss {'Reaction outcome loss': 0.7979711749758877, 'Total loss': 0.7979711749758877}
2022-11-18 03:30:26,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:26,629 INFO:     Epoch: 56
2022-11-18 03:30:27,432 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8355765321920084, 'Total loss': 0.8355765321920084} | train loss {'Reaction outcome loss': 0.792924023676114, 'Total loss': 0.792924023676114}
2022-11-18 03:30:27,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:27,432 INFO:     Epoch: 57
2022-11-18 03:30:28,238 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8244114157765411, 'Total loss': 0.8244114157765411} | train loss {'Reaction outcome loss': 0.7992269417545834, 'Total loss': 0.7992269417545834}
2022-11-18 03:30:28,239 INFO:     Found new best model at epoch 57
2022-11-18 03:30:28,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:28,239 INFO:     Epoch: 58
2022-11-18 03:30:29,011 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8330535944118056, 'Total loss': 0.8330535944118056} | train loss {'Reaction outcome loss': 0.7915971213188328, 'Total loss': 0.7915971213188328}
2022-11-18 03:30:29,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:29,012 INFO:     Epoch: 59
2022-11-18 03:30:29,830 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8271399389865787, 'Total loss': 0.8271399389865787} | train loss {'Reaction outcome loss': 0.7950797965292071, 'Total loss': 0.7950797965292071}
2022-11-18 03:30:29,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:29,830 INFO:     Epoch: 60
2022-11-18 03:30:30,604 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8294916728208231, 'Total loss': 0.8294916728208231} | train loss {'Reaction outcome loss': 0.7974204044239442, 'Total loss': 0.7974204044239442}
2022-11-18 03:30:30,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:30,604 INFO:     Epoch: 61
2022-11-18 03:30:31,410 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8291765132615733, 'Total loss': 0.8291765132615733} | train loss {'Reaction outcome loss': 0.7958554007479401, 'Total loss': 0.7958554007479401}
2022-11-18 03:30:31,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:31,410 INFO:     Epoch: 62
2022-11-18 03:30:32,205 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8516401274259701, 'Total loss': 0.8516401274259701} | train loss {'Reaction outcome loss': 0.7966418858678614, 'Total loss': 0.7966418858678614}
2022-11-18 03:30:32,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:32,205 INFO:     Epoch: 63
2022-11-18 03:30:32,983 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8304923135180806, 'Total loss': 0.8304923135180806} | train loss {'Reaction outcome loss': 0.795059496017753, 'Total loss': 0.795059496017753}
2022-11-18 03:30:32,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:32,983 INFO:     Epoch: 64
2022-11-18 03:30:33,768 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8403547725012136, 'Total loss': 0.8403547725012136} | train loss {'Reaction outcome loss': 0.7946002192673136, 'Total loss': 0.7946002192673136}
2022-11-18 03:30:33,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:33,768 INFO:     Epoch: 65
2022-11-18 03:30:34,564 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8461566900098046, 'Total loss': 0.8461566900098046} | train loss {'Reaction outcome loss': 0.7978237808727827, 'Total loss': 0.7978237808727827}
2022-11-18 03:30:34,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:34,564 INFO:     Epoch: 66
2022-11-18 03:30:35,370 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8504680512949477, 'Total loss': 0.8504680512949477} | train loss {'Reaction outcome loss': 0.7954398767381418, 'Total loss': 0.7954398767381418}
2022-11-18 03:30:35,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:35,370 INFO:     Epoch: 67
2022-11-18 03:30:36,175 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8289527116819869, 'Total loss': 0.8289527116819869} | train loss {'Reaction outcome loss': 0.7939639123248272, 'Total loss': 0.7939639123248272}
2022-11-18 03:30:36,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:36,176 INFO:     Epoch: 68
2022-11-18 03:30:36,959 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8300916011943373, 'Total loss': 0.8300916011943373} | train loss {'Reaction outcome loss': 0.7982886604598312, 'Total loss': 0.7982886604598312}
2022-11-18 03:30:36,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:36,959 INFO:     Epoch: 69
2022-11-18 03:30:37,775 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.835044288358023, 'Total loss': 0.835044288358023} | train loss {'Reaction outcome loss': 0.7933610627641443, 'Total loss': 0.7933610627641443}
2022-11-18 03:30:37,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:37,777 INFO:     Epoch: 70
2022-11-18 03:30:38,554 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8342181659022043, 'Total loss': 0.8342181659022043} | train loss {'Reaction outcome loss': 0.7933364490993687, 'Total loss': 0.7933364490993687}
2022-11-18 03:30:38,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:38,554 INFO:     Epoch: 71
2022-11-18 03:30:39,358 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8372504953728166, 'Total loss': 0.8372504953728166} | train loss {'Reaction outcome loss': 0.7934542493742021, 'Total loss': 0.7934542493742021}
2022-11-18 03:30:39,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:39,359 INFO:     Epoch: 72
2022-11-18 03:30:40,166 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8338854278242865, 'Total loss': 0.8338854278242865} | train loss {'Reaction outcome loss': 0.7913541046322369, 'Total loss': 0.7913541046322369}
2022-11-18 03:30:40,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:40,166 INFO:     Epoch: 73
2022-11-18 03:30:40,966 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8428774864174599, 'Total loss': 0.8428774864174599} | train loss {'Reaction outcome loss': 0.799490327717828, 'Total loss': 0.799490327717828}
2022-11-18 03:30:40,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:40,966 INFO:     Epoch: 74
2022-11-18 03:30:41,770 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8513394511023233, 'Total loss': 0.8513394511023233} | train loss {'Reaction outcome loss': 0.7964341914067503, 'Total loss': 0.7964341914067503}
2022-11-18 03:30:41,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:41,770 INFO:     Epoch: 75
2022-11-18 03:30:42,536 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8266940865405771, 'Total loss': 0.8266940865405771} | train loss {'Reaction outcome loss': 0.7951150115151875, 'Total loss': 0.7951150115151875}
2022-11-18 03:30:42,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:42,537 INFO:     Epoch: 76
2022-11-18 03:30:43,375 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8375420057496359, 'Total loss': 0.8375420057496359} | train loss {'Reaction outcome loss': 0.7905142756759144, 'Total loss': 0.7905142756759144}
2022-11-18 03:30:43,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:43,375 INFO:     Epoch: 77
2022-11-18 03:30:44,167 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8498372338538946, 'Total loss': 0.8498372338538946} | train loss {'Reaction outcome loss': 0.7913344958033718, 'Total loss': 0.7913344958033718}
2022-11-18 03:30:44,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:44,168 INFO:     Epoch: 78
2022-11-18 03:30:44,953 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8287459196046342, 'Total loss': 0.8287459196046342} | train loss {'Reaction outcome loss': 0.7901541394044141, 'Total loss': 0.7901541394044141}
2022-11-18 03:30:44,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:44,954 INFO:     Epoch: 79
2022-11-18 03:30:45,755 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8327559911927511, 'Total loss': 0.8327559911927511} | train loss {'Reaction outcome loss': 0.7970669936449801, 'Total loss': 0.7970669936449801}
2022-11-18 03:30:45,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:45,755 INFO:     Epoch: 80
2022-11-18 03:30:46,543 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8354033439658409, 'Total loss': 0.8354033439658409} | train loss {'Reaction outcome loss': 0.7888940542203481, 'Total loss': 0.7888940542203481}
2022-11-18 03:30:46,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:46,543 INFO:     Epoch: 81
2022-11-18 03:30:47,356 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8318770541701206, 'Total loss': 0.8318770541701206} | train loss {'Reaction outcome loss': 0.791041337686484, 'Total loss': 0.791041337686484}
2022-11-18 03:30:47,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:47,356 INFO:     Epoch: 82
2022-11-18 03:30:48,146 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8373426053413126, 'Total loss': 0.8373426053413126} | train loss {'Reaction outcome loss': 0.7889059358200089, 'Total loss': 0.7889059358200089}
2022-11-18 03:30:48,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:48,147 INFO:     Epoch: 83
2022-11-18 03:30:48,915 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8266174675420274, 'Total loss': 0.8266174675420274} | train loss {'Reaction outcome loss': 0.7931166318107824, 'Total loss': 0.7931166318107824}
2022-11-18 03:30:48,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:48,916 INFO:     Epoch: 84
2022-11-18 03:30:49,720 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8355927342592284, 'Total loss': 0.8355927342592284} | train loss {'Reaction outcome loss': 0.7904573915923228, 'Total loss': 0.7904573915923228}
2022-11-18 03:30:49,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:49,720 INFO:     Epoch: 85
2022-11-18 03:30:50,484 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8390567538350128, 'Total loss': 0.8390567538350128} | train loss {'Reaction outcome loss': 0.7892138000394477, 'Total loss': 0.7892138000394477}
2022-11-18 03:30:50,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:50,484 INFO:     Epoch: 86
2022-11-18 03:30:51,297 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.831816935955092, 'Total loss': 0.831816935955092} | train loss {'Reaction outcome loss': 0.7905761137848994, 'Total loss': 0.7905761137848994}
2022-11-18 03:30:51,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:51,297 INFO:     Epoch: 87
2022-11-18 03:30:52,067 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8546397699866184, 'Total loss': 0.8546397699866184} | train loss {'Reaction outcome loss': 0.7882036975905543, 'Total loss': 0.7882036975905543}
2022-11-18 03:30:52,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:52,067 INFO:     Epoch: 88
2022-11-18 03:30:52,844 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8296709975530935, 'Total loss': 0.8296709975530935} | train loss {'Reaction outcome loss': 0.7945468563769684, 'Total loss': 0.7945468563769684}
2022-11-18 03:30:52,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:52,844 INFO:     Epoch: 89
2022-11-18 03:30:53,665 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8616019792334978, 'Total loss': 0.8616019792334978} | train loss {'Reaction outcome loss': 0.7884339548525263, 'Total loss': 0.7884339548525263}
2022-11-18 03:30:53,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:53,665 INFO:     Epoch: 90
2022-11-18 03:30:54,474 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.832515898832055, 'Total loss': 0.832515898832055} | train loss {'Reaction outcome loss': 0.7871787294012601, 'Total loss': 0.7871787294012601}
2022-11-18 03:30:54,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:54,474 INFO:     Epoch: 91
2022-11-18 03:30:55,251 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8286102511161981, 'Total loss': 0.8286102511161981} | train loss {'Reaction outcome loss': 0.7863099407710012, 'Total loss': 0.7863099407710012}
2022-11-18 03:30:55,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:55,252 INFO:     Epoch: 92
2022-11-18 03:30:56,072 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8356583631315897, 'Total loss': 0.8356583631315897} | train loss {'Reaction outcome loss': 0.7846099447275772, 'Total loss': 0.7846099447275772}
2022-11-18 03:30:56,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:56,072 INFO:     Epoch: 93
2022-11-18 03:30:56,874 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8474957707316376, 'Total loss': 0.8474957707316376} | train loss {'Reaction outcome loss': 0.7887819157760652, 'Total loss': 0.7887819157760652}
2022-11-18 03:30:56,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:56,875 INFO:     Epoch: 94
2022-11-18 03:30:57,662 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8434078222097352, 'Total loss': 0.8434078222097352} | train loss {'Reaction outcome loss': 0.7854610610692228, 'Total loss': 0.7854610610692228}
2022-11-18 03:30:57,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:57,662 INFO:     Epoch: 95
2022-11-18 03:30:58,482 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8348860200061354, 'Total loss': 0.8348860200061354} | train loss {'Reaction outcome loss': 0.7874205723160603, 'Total loss': 0.7874205723160603}
2022-11-18 03:30:58,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:58,482 INFO:     Epoch: 96
2022-11-18 03:30:59,275 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8291270663571912, 'Total loss': 0.8291270663571912} | train loss {'Reaction outcome loss': 0.7876168534648224, 'Total loss': 0.7876168534648224}
2022-11-18 03:30:59,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:30:59,275 INFO:     Epoch: 97
2022-11-18 03:31:00,072 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8225262781908346, 'Total loss': 0.8225262781908346} | train loss {'Reaction outcome loss': 0.782622858271247, 'Total loss': 0.782622858271247}
2022-11-18 03:31:00,072 INFO:     Found new best model at epoch 97
2022-11-18 03:31:00,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:00,073 INFO:     Epoch: 98
2022-11-18 03:31:00,870 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8220762887666392, 'Total loss': 0.8220762887666392} | train loss {'Reaction outcome loss': 0.787291633667516, 'Total loss': 0.787291633667516}
2022-11-18 03:31:00,870 INFO:     Found new best model at epoch 98
2022-11-18 03:31:00,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:00,871 INFO:     Epoch: 99
2022-11-18 03:31:01,674 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8207212942977284, 'Total loss': 0.8207212942977284} | train loss {'Reaction outcome loss': 0.7836212083453038, 'Total loss': 0.7836212083453038}
2022-11-18 03:31:01,674 INFO:     Found new best model at epoch 99
2022-11-18 03:31:01,675 INFO:     Best model found after epoch 100 of 100.
2022-11-18 03:31:01,675 INFO:   Done with stage: TRAINING
2022-11-18 03:31:01,675 INFO:   Starting stage: EVALUATION
2022-11-18 03:31:01,810 INFO:   Done with stage: EVALUATION
2022-11-18 03:31:01,810 INFO:   Leaving out SEQ value Fold_7
2022-11-18 03:31:01,823 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:31:01,823 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:31:02,511 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:31:02,511 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:31:02,582 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:31:02,582 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:31:02,582 INFO:     No hyperparam tuning for this model
2022-11-18 03:31:02,582 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:31:02,582 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:31:02,583 INFO:     None feature selector for col prot
2022-11-18 03:31:02,583 INFO:     None feature selector for col prot
2022-11-18 03:31:02,583 INFO:     None feature selector for col prot
2022-11-18 03:31:02,584 INFO:     None feature selector for col chem
2022-11-18 03:31:02,584 INFO:     None feature selector for col chem
2022-11-18 03:31:02,584 INFO:     None feature selector for col chem
2022-11-18 03:31:02,584 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:31:02,584 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:31:02,586 INFO:     Number of params in model 168571
2022-11-18 03:31:02,589 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:31:02,589 INFO:   Starting stage: TRAINING
2022-11-18 03:31:02,648 INFO:     Val loss before train {'Reaction outcome loss': 1.0486575866287404, 'Total loss': 1.0486575866287404}
2022-11-18 03:31:02,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:02,649 INFO:     Epoch: 0
2022-11-18 03:31:03,454 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9076592448082837, 'Total loss': 0.9076592448082837} | train loss {'Reaction outcome loss': 0.8792581228959945, 'Total loss': 0.8792581228959945}
2022-11-18 03:31:03,454 INFO:     Found new best model at epoch 0
2022-11-18 03:31:03,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:03,455 INFO:     Epoch: 1
2022-11-18 03:31:04,276 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9095900573513724, 'Total loss': 0.9095900573513724} | train loss {'Reaction outcome loss': 0.846012982149278, 'Total loss': 0.846012982149278}
2022-11-18 03:31:04,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:04,276 INFO:     Epoch: 2
2022-11-18 03:31:05,095 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8963286267085508, 'Total loss': 0.8963286267085508} | train loss {'Reaction outcome loss': 0.8363733188279213, 'Total loss': 0.8363733188279213}
2022-11-18 03:31:05,095 INFO:     Found new best model at epoch 2
2022-11-18 03:31:05,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:05,096 INFO:     Epoch: 3
2022-11-18 03:31:05,857 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8926197669722817, 'Total loss': 0.8926197669722817} | train loss {'Reaction outcome loss': 0.8415591329816849, 'Total loss': 0.8415591329816849}
2022-11-18 03:31:05,857 INFO:     Found new best model at epoch 3
2022-11-18 03:31:05,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:05,858 INFO:     Epoch: 4
2022-11-18 03:31:06,684 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8841820440509103, 'Total loss': 0.8841820440509103} | train loss {'Reaction outcome loss': 0.8298060875986853, 'Total loss': 0.8298060875986853}
2022-11-18 03:31:06,684 INFO:     Found new best model at epoch 4
2022-11-18 03:31:06,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:06,685 INFO:     Epoch: 5
2022-11-18 03:31:07,461 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.883004290136424, 'Total loss': 0.883004290136424} | train loss {'Reaction outcome loss': 0.830555526119086, 'Total loss': 0.830555526119086}
2022-11-18 03:31:07,461 INFO:     Found new best model at epoch 5
2022-11-18 03:31:07,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:07,462 INFO:     Epoch: 6
2022-11-18 03:31:08,281 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9054202715104277, 'Total loss': 0.9054202715104277} | train loss {'Reaction outcome loss': 0.8246969766914845, 'Total loss': 0.8246969766914845}
2022-11-18 03:31:08,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:08,281 INFO:     Epoch: 7
2022-11-18 03:31:09,054 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8850089115175334, 'Total loss': 0.8850089115175334} | train loss {'Reaction outcome loss': 0.8243673324825302, 'Total loss': 0.8243673324825302}
2022-11-18 03:31:09,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:09,056 INFO:     Epoch: 8
2022-11-18 03:31:09,855 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8864507241682573, 'Total loss': 0.8864507241682573} | train loss {'Reaction outcome loss': 0.8231068593600104, 'Total loss': 0.8231068593600104}
2022-11-18 03:31:09,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:09,855 INFO:     Epoch: 9
2022-11-18 03:31:10,662 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8907119740139354, 'Total loss': 0.8907119740139354} | train loss {'Reaction outcome loss': 0.8272699214998753, 'Total loss': 0.8272699214998753}
2022-11-18 03:31:10,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:10,662 INFO:     Epoch: 10
2022-11-18 03:31:11,474 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.9017014225775545, 'Total loss': 0.9017014225775545} | train loss {'Reaction outcome loss': 0.8239285778855124, 'Total loss': 0.8239285778855124}
2022-11-18 03:31:11,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:11,474 INFO:     Epoch: 11
2022-11-18 03:31:12,314 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8913158489899202, 'Total loss': 0.8913158489899202} | train loss {'Reaction outcome loss': 0.823812541101248, 'Total loss': 0.823812541101248}
2022-11-18 03:31:12,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:12,314 INFO:     Epoch: 12
2022-11-18 03:31:13,114 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8806362931023944, 'Total loss': 0.8806362931023944} | train loss {'Reaction outcome loss': 0.8189984007227805, 'Total loss': 0.8189984007227805}
2022-11-18 03:31:13,114 INFO:     Found new best model at epoch 12
2022-11-18 03:31:13,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:13,114 INFO:     Epoch: 13
2022-11-18 03:31:13,932 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.886608213186264, 'Total loss': 0.886608213186264} | train loss {'Reaction outcome loss': 0.82092916484802, 'Total loss': 0.82092916484802}
2022-11-18 03:31:13,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:13,933 INFO:     Epoch: 14
2022-11-18 03:31:14,733 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8857608315619555, 'Total loss': 0.8857608315619555} | train loss {'Reaction outcome loss': 0.8208363550084252, 'Total loss': 0.8208363550084252}
2022-11-18 03:31:14,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:14,733 INFO:     Epoch: 15
2022-11-18 03:31:15,555 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8828560527075421, 'Total loss': 0.8828560527075421} | train loss {'Reaction outcome loss': 0.8238219805061817, 'Total loss': 0.8238219805061817}
2022-11-18 03:31:15,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:15,556 INFO:     Epoch: 16
2022-11-18 03:31:16,389 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8764825612306595, 'Total loss': 0.8764825612306595} | train loss {'Reaction outcome loss': 0.8176117295459393, 'Total loss': 0.8176117295459393}
2022-11-18 03:31:16,389 INFO:     Found new best model at epoch 16
2022-11-18 03:31:16,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:16,390 INFO:     Epoch: 17
2022-11-18 03:31:17,220 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8770967959003015, 'Total loss': 0.8770967959003015} | train loss {'Reaction outcome loss': 0.8231979528021428, 'Total loss': 0.8231979528021428}
2022-11-18 03:31:17,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:17,220 INFO:     Epoch: 18
2022-11-18 03:31:18,048 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8831116922877051, 'Total loss': 0.8831116922877051} | train loss {'Reaction outcome loss': 0.8147573898276014, 'Total loss': 0.8147573898276014}
2022-11-18 03:31:18,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:18,048 INFO:     Epoch: 19
2022-11-18 03:31:18,882 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8826578598130833, 'Total loss': 0.8826578598130833} | train loss {'Reaction outcome loss': 0.8160749637792187, 'Total loss': 0.8160749637792187}
2022-11-18 03:31:18,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:18,882 INFO:     Epoch: 20
2022-11-18 03:31:19,682 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8816266256299886, 'Total loss': 0.8816266256299886} | train loss {'Reaction outcome loss': 0.8159049726541965, 'Total loss': 0.8159049726541965}
2022-11-18 03:31:19,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:19,682 INFO:     Epoch: 21
2022-11-18 03:31:20,493 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8758850355039943, 'Total loss': 0.8758850355039943} | train loss {'Reaction outcome loss': 0.8194306728339964, 'Total loss': 0.8194306728339964}
2022-11-18 03:31:20,494 INFO:     Found new best model at epoch 21
2022-11-18 03:31:20,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:20,495 INFO:     Epoch: 22
2022-11-18 03:31:21,303 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.9269641570069573, 'Total loss': 0.9269641570069573} | train loss {'Reaction outcome loss': 0.8148912444951073, 'Total loss': 0.8148912444951073}
2022-11-18 03:31:21,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:21,303 INFO:     Epoch: 23
2022-11-18 03:31:22,112 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8672456632960927, 'Total loss': 0.8672456632960927} | train loss {'Reaction outcome loss': 0.8171220472262751, 'Total loss': 0.8171220472262751}
2022-11-18 03:31:22,112 INFO:     Found new best model at epoch 23
2022-11-18 03:31:22,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:22,113 INFO:     Epoch: 24
2022-11-18 03:31:22,899 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8638635433532975, 'Total loss': 0.8638635433532975} | train loss {'Reaction outcome loss': 0.815819030928035, 'Total loss': 0.815819030928035}
2022-11-18 03:31:22,899 INFO:     Found new best model at epoch 24
2022-11-18 03:31:22,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:22,900 INFO:     Epoch: 25
2022-11-18 03:31:23,714 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8920032300732352, 'Total loss': 0.8920032300732352} | train loss {'Reaction outcome loss': 0.8168731206847776, 'Total loss': 0.8168731206847776}
2022-11-18 03:31:23,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:23,715 INFO:     Epoch: 26
2022-11-18 03:31:24,529 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8957864100282843, 'Total loss': 0.8957864100282843} | train loss {'Reaction outcome loss': 0.814551713005189, 'Total loss': 0.814551713005189}
2022-11-18 03:31:24,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:24,529 INFO:     Epoch: 27
2022-11-18 03:31:25,367 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8695524795488878, 'Total loss': 0.8695524795488878} | train loss {'Reaction outcome loss': 0.8103369508058794, 'Total loss': 0.8103369508058794}
2022-11-18 03:31:25,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:25,368 INFO:     Epoch: 28
2022-11-18 03:31:26,171 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.891203217885711, 'Total loss': 0.891203217885711} | train loss {'Reaction outcome loss': 0.8111473604916565, 'Total loss': 0.8111473604916565}
2022-11-18 03:31:26,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:26,171 INFO:     Epoch: 29
2022-11-18 03:31:26,971 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.9098290990699421, 'Total loss': 0.9098290990699421} | train loss {'Reaction outcome loss': 0.8129016498644506, 'Total loss': 0.8129016498644506}
2022-11-18 03:31:26,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:26,972 INFO:     Epoch: 30
2022-11-18 03:31:27,781 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.862343511798165, 'Total loss': 0.862343511798165} | train loss {'Reaction outcome loss': 0.8091418621761184, 'Total loss': 0.8091418621761184}
2022-11-18 03:31:27,782 INFO:     Found new best model at epoch 30
2022-11-18 03:31:27,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:27,782 INFO:     Epoch: 31
2022-11-18 03:31:28,581 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8804742707447573, 'Total loss': 0.8804742707447573} | train loss {'Reaction outcome loss': 0.8139068763102254, 'Total loss': 0.8139068763102254}
2022-11-18 03:31:28,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:28,582 INFO:     Epoch: 32
2022-11-18 03:31:29,370 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.9057831987738609, 'Total loss': 0.9057831987738609} | train loss {'Reaction outcome loss': 0.8131255593992048, 'Total loss': 0.8131255593992048}
2022-11-18 03:31:29,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:29,370 INFO:     Epoch: 33
2022-11-18 03:31:30,168 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8983678438446738, 'Total loss': 0.8983678438446738} | train loss {'Reaction outcome loss': 0.8161965880182481, 'Total loss': 0.8161965880182481}
2022-11-18 03:31:30,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:30,169 INFO:     Epoch: 34
2022-11-18 03:31:30,995 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8751180991530418, 'Total loss': 0.8751180991530418} | train loss {'Reaction outcome loss': 0.8151884203956973, 'Total loss': 0.8151884203956973}
2022-11-18 03:31:30,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:30,995 INFO:     Epoch: 35
2022-11-18 03:31:31,787 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8715932667255402, 'Total loss': 0.8715932667255402} | train loss {'Reaction outcome loss': 0.8127204879157005, 'Total loss': 0.8127204879157005}
2022-11-18 03:31:31,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:31,788 INFO:     Epoch: 36
2022-11-18 03:31:32,574 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8727937774224714, 'Total loss': 0.8727937774224714} | train loss {'Reaction outcome loss': 0.8173953541103871, 'Total loss': 0.8173953541103871}
2022-11-18 03:31:32,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:32,574 INFO:     Epoch: 37
2022-11-18 03:31:33,385 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8825651651079004, 'Total loss': 0.8825651651079004} | train loss {'Reaction outcome loss': 0.80988180889718, 'Total loss': 0.80988180889718}
2022-11-18 03:31:33,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:33,386 INFO:     Epoch: 38
2022-11-18 03:31:34,202 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8824410330165516, 'Total loss': 0.8824410330165516} | train loss {'Reaction outcome loss': 0.8082406750369456, 'Total loss': 0.8082406750369456}
2022-11-18 03:31:34,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:34,202 INFO:     Epoch: 39
2022-11-18 03:31:35,045 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8709982592951168, 'Total loss': 0.8709982592951168} | train loss {'Reaction outcome loss': 0.8137437806975457, 'Total loss': 0.8137437806975457}
2022-11-18 03:31:35,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:35,046 INFO:     Epoch: 40
2022-11-18 03:31:35,871 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.87389782612974, 'Total loss': 0.87389782612974} | train loss {'Reaction outcome loss': 0.814395570226254, 'Total loss': 0.814395570226254}
2022-11-18 03:31:35,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:35,871 INFO:     Epoch: 41
2022-11-18 03:31:36,702 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8739963228052313, 'Total loss': 0.8739963228052313} | train loss {'Reaction outcome loss': 0.8120170421297511, 'Total loss': 0.8120170421297511}
2022-11-18 03:31:36,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:36,703 INFO:     Epoch: 42
2022-11-18 03:31:37,531 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8813151243058118, 'Total loss': 0.8813151243058118} | train loss {'Reaction outcome loss': 0.8083093672269775, 'Total loss': 0.8083093672269775}
2022-11-18 03:31:37,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:37,531 INFO:     Epoch: 43
2022-11-18 03:31:38,357 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8600119013677944, 'Total loss': 0.8600119013677944} | train loss {'Reaction outcome loss': 0.8122928302374578, 'Total loss': 0.8122928302374578}
2022-11-18 03:31:38,357 INFO:     Found new best model at epoch 43
2022-11-18 03:31:38,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:38,358 INFO:     Epoch: 44
2022-11-18 03:31:39,156 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8681731230833314, 'Total loss': 0.8681731230833314} | train loss {'Reaction outcome loss': 0.8167540862435295, 'Total loss': 0.8167540862435295}
2022-11-18 03:31:39,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:39,156 INFO:     Epoch: 45
2022-11-18 03:31:39,939 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8856014568697322, 'Total loss': 0.8856014568697322} | train loss {'Reaction outcome loss': 0.8099743713053965, 'Total loss': 0.8099743713053965}
2022-11-18 03:31:39,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:39,940 INFO:     Epoch: 46
2022-11-18 03:31:40,756 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8749586614695463, 'Total loss': 0.8749586614695463} | train loss {'Reaction outcome loss': 0.8077911327803328, 'Total loss': 0.8077911327803328}
2022-11-18 03:31:40,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:40,756 INFO:     Epoch: 47
2022-11-18 03:31:41,609 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8821542263031006, 'Total loss': 0.8821542263031006} | train loss {'Reaction outcome loss': 0.8123935090918695, 'Total loss': 0.8123935090918695}
2022-11-18 03:31:41,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:41,610 INFO:     Epoch: 48
2022-11-18 03:31:42,426 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8654157194224271, 'Total loss': 0.8654157194224271} | train loss {'Reaction outcome loss': 0.8149545767134235, 'Total loss': 0.8149545767134235}
2022-11-18 03:31:42,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:42,426 INFO:     Epoch: 49
2022-11-18 03:31:43,250 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.873869236220013, 'Total loss': 0.873869236220013} | train loss {'Reaction outcome loss': 0.8132155654170821, 'Total loss': 0.8132155654170821}
2022-11-18 03:31:43,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:43,250 INFO:     Epoch: 50
2022-11-18 03:31:44,089 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.866818988865072, 'Total loss': 0.866818988865072} | train loss {'Reaction outcome loss': 0.8088916972760232, 'Total loss': 0.8088916972760232}
2022-11-18 03:31:44,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:44,089 INFO:     Epoch: 51
2022-11-18 03:31:44,939 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8862248842011798, 'Total loss': 0.8862248842011798} | train loss {'Reaction outcome loss': 0.8108453188211687, 'Total loss': 0.8108453188211687}
2022-11-18 03:31:44,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:44,939 INFO:     Epoch: 52
2022-11-18 03:31:45,784 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8700235614722426, 'Total loss': 0.8700235614722426} | train loss {'Reaction outcome loss': 0.8115474890557027, 'Total loss': 0.8115474890557027}
2022-11-18 03:31:45,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:45,785 INFO:     Epoch: 53
2022-11-18 03:31:46,604 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8782007396221161, 'Total loss': 0.8782007396221161} | train loss {'Reaction outcome loss': 0.8156389095369847, 'Total loss': 0.8156389095369847}
2022-11-18 03:31:46,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:46,605 INFO:     Epoch: 54
2022-11-18 03:31:47,436 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8755638558756221, 'Total loss': 0.8755638558756221} | train loss {'Reaction outcome loss': 0.8132685082213532, 'Total loss': 0.8132685082213532}
2022-11-18 03:31:47,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:47,436 INFO:     Epoch: 55
2022-11-18 03:31:48,266 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8624641692096536, 'Total loss': 0.8624641692096536} | train loss {'Reaction outcome loss': 0.809013094753027, 'Total loss': 0.809013094753027}
2022-11-18 03:31:48,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:48,267 INFO:     Epoch: 56
2022-11-18 03:31:49,084 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.866627424955368, 'Total loss': 0.866627424955368} | train loss {'Reaction outcome loss': 0.8094427071271404, 'Total loss': 0.8094427071271404}
2022-11-18 03:31:49,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:49,085 INFO:     Epoch: 57
2022-11-18 03:31:49,868 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8613700101321394, 'Total loss': 0.8613700101321394} | train loss {'Reaction outcome loss': 0.8063933104276657, 'Total loss': 0.8063933104276657}
2022-11-18 03:31:49,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:49,868 INFO:     Epoch: 58
2022-11-18 03:31:50,694 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8660731532356956, 'Total loss': 0.8660731532356956} | train loss {'Reaction outcome loss': 0.8062273748219013, 'Total loss': 0.8062273748219013}
2022-11-18 03:31:50,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:50,694 INFO:     Epoch: 59
2022-11-18 03:31:51,506 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8674466217106039, 'Total loss': 0.8674466217106039} | train loss {'Reaction outcome loss': 0.80990818154908, 'Total loss': 0.80990818154908}
2022-11-18 03:31:51,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:51,506 INFO:     Epoch: 60
2022-11-18 03:31:52,295 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8737387453967874, 'Total loss': 0.8737387453967874} | train loss {'Reaction outcome loss': 0.8126828789470657, 'Total loss': 0.8126828789470657}
2022-11-18 03:31:52,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:52,295 INFO:     Epoch: 61
2022-11-18 03:31:53,127 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8652307201515544, 'Total loss': 0.8652307201515544} | train loss {'Reaction outcome loss': 0.8094440126611341, 'Total loss': 0.8094440126611341}
2022-11-18 03:31:53,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:53,128 INFO:     Epoch: 62
2022-11-18 03:31:53,947 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8759535076943311, 'Total loss': 0.8759535076943311} | train loss {'Reaction outcome loss': 0.8113331191482083, 'Total loss': 0.8113331191482083}
2022-11-18 03:31:53,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:53,948 INFO:     Epoch: 63
2022-11-18 03:31:54,772 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8624249317429282, 'Total loss': 0.8624249317429282} | train loss {'Reaction outcome loss': 0.807380291723436, 'Total loss': 0.807380291723436}
2022-11-18 03:31:54,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:54,773 INFO:     Epoch: 64
2022-11-18 03:31:55,626 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.860119799321348, 'Total loss': 0.860119799321348} | train loss {'Reaction outcome loss': 0.8111221071693205, 'Total loss': 0.8111221071693205}
2022-11-18 03:31:55,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:55,626 INFO:     Epoch: 65
2022-11-18 03:31:56,435 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8887943097136237, 'Total loss': 0.8887943097136237} | train loss {'Reaction outcome loss': 0.8105855256078704, 'Total loss': 0.8105855256078704}
2022-11-18 03:31:56,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:56,435 INFO:     Epoch: 66
2022-11-18 03:31:57,256 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8725008361718871, 'Total loss': 0.8725008361718871} | train loss {'Reaction outcome loss': 0.8082560560395641, 'Total loss': 0.8082560560395641}
2022-11-18 03:31:57,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:57,256 INFO:     Epoch: 67
2022-11-18 03:31:58,091 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8592108176513151, 'Total loss': 0.8592108176513151} | train loss {'Reaction outcome loss': 0.8079925082143276, 'Total loss': 0.8079925082143276}
2022-11-18 03:31:58,092 INFO:     Found new best model at epoch 67
2022-11-18 03:31:58,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:58,093 INFO:     Epoch: 68
2022-11-18 03:31:58,909 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.867291967977177, 'Total loss': 0.867291967977177} | train loss {'Reaction outcome loss': 0.8102701561104867, 'Total loss': 0.8102701561104867}
2022-11-18 03:31:58,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:58,911 INFO:     Epoch: 69
2022-11-18 03:31:59,758 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8672551133415916, 'Total loss': 0.8672551133415916} | train loss {'Reaction outcome loss': 0.8095890681349462, 'Total loss': 0.8095890681349462}
2022-11-18 03:31:59,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:31:59,758 INFO:     Epoch: 70
2022-11-18 03:32:00,572 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8582942309704694, 'Total loss': 0.8582942309704694} | train loss {'Reaction outcome loss': 0.8071345888799236, 'Total loss': 0.8071345888799236}
2022-11-18 03:32:00,572 INFO:     Found new best model at epoch 70
2022-11-18 03:32:00,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:00,573 INFO:     Epoch: 71
2022-11-18 03:32:01,385 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8688018877397884, 'Total loss': 0.8688018877397884} | train loss {'Reaction outcome loss': 0.8122091306553733, 'Total loss': 0.8122091306553733}
2022-11-18 03:32:01,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:01,385 INFO:     Epoch: 72
2022-11-18 03:32:02,200 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8723284832455895, 'Total loss': 0.8723284832455895} | train loss {'Reaction outcome loss': 0.8112249451298867, 'Total loss': 0.8112249451298867}
2022-11-18 03:32:02,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:02,200 INFO:     Epoch: 73
2022-11-18 03:32:03,009 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.9183860150250521, 'Total loss': 0.9183860150250521} | train loss {'Reaction outcome loss': 0.810839468793523, 'Total loss': 0.810839468793523}
2022-11-18 03:32:03,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:03,010 INFO:     Epoch: 74
2022-11-18 03:32:03,815 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8706479275768454, 'Total loss': 0.8706479275768454} | train loss {'Reaction outcome loss': 0.8130635033932424, 'Total loss': 0.8130635033932424}
2022-11-18 03:32:03,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:03,815 INFO:     Epoch: 75
2022-11-18 03:32:04,629 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8738456253301013, 'Total loss': 0.8738456253301013} | train loss {'Reaction outcome loss': 0.8073379750693997, 'Total loss': 0.8073379750693997}
2022-11-18 03:32:04,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:04,629 INFO:     Epoch: 76
2022-11-18 03:32:05,429 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8629252470352433, 'Total loss': 0.8629252470352433} | train loss {'Reaction outcome loss': 0.8024485524623625, 'Total loss': 0.8024485524623625}
2022-11-18 03:32:05,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:05,429 INFO:     Epoch: 77
2022-11-18 03:32:06,260 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8654577528888528, 'Total loss': 0.8654577528888528} | train loss {'Reaction outcome loss': 0.8142097644027202, 'Total loss': 0.8142097644027202}
2022-11-18 03:32:06,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:06,261 INFO:     Epoch: 78
2022-11-18 03:32:07,056 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8848217807032845, 'Total loss': 0.8848217807032845} | train loss {'Reaction outcome loss': 0.8107097023316929, 'Total loss': 0.8107097023316929}
2022-11-18 03:32:07,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:07,056 INFO:     Epoch: 79
2022-11-18 03:32:07,886 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8717253045602278, 'Total loss': 0.8717253045602278} | train loss {'Reaction outcome loss': 0.807374116273657, 'Total loss': 0.807374116273657}
2022-11-18 03:32:07,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:07,886 INFO:     Epoch: 80
2022-11-18 03:32:08,717 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.867326564409516, 'Total loss': 0.867326564409516} | train loss {'Reaction outcome loss': 0.8062392204038559, 'Total loss': 0.8062392204038559}
2022-11-18 03:32:08,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:08,718 INFO:     Epoch: 81
2022-11-18 03:32:09,522 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8722532337362116, 'Total loss': 0.8722532337362116} | train loss {'Reaction outcome loss': 0.8087425241547246, 'Total loss': 0.8087425241547246}
2022-11-18 03:32:09,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:09,522 INFO:     Epoch: 82
2022-11-18 03:32:10,395 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8636977415193211, 'Total loss': 0.8636977415193211} | train loss {'Reaction outcome loss': 0.808429658172592, 'Total loss': 0.808429658172592}
2022-11-18 03:32:10,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:10,395 INFO:     Epoch: 83
2022-11-18 03:32:11,247 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.88169026510282, 'Total loss': 0.88169026510282} | train loss {'Reaction outcome loss': 0.8060837394047168, 'Total loss': 0.8060837394047168}
2022-11-18 03:32:11,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:11,248 INFO:     Epoch: 84
2022-11-18 03:32:12,068 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.877917777408253, 'Total loss': 0.877917777408253} | train loss {'Reaction outcome loss': 0.8081309163281994, 'Total loss': 0.8081309163281994}
2022-11-18 03:32:12,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:12,068 INFO:     Epoch: 85
2022-11-18 03:32:12,894 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.875686676664786, 'Total loss': 0.875686676664786} | train loss {'Reaction outcome loss': 0.8093037701422169, 'Total loss': 0.8093037701422169}
2022-11-18 03:32:12,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:12,894 INFO:     Epoch: 86
2022-11-18 03:32:13,692 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.890288841995326, 'Total loss': 0.890288841995326} | train loss {'Reaction outcome loss': 0.8144195613361174, 'Total loss': 0.8144195613361174}
2022-11-18 03:32:13,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:13,692 INFO:     Epoch: 87
2022-11-18 03:32:14,494 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8643976267088543, 'Total loss': 0.8643976267088543} | train loss {'Reaction outcome loss': 0.8093699286842058, 'Total loss': 0.8093699286842058}
2022-11-18 03:32:14,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:14,494 INFO:     Epoch: 88
2022-11-18 03:32:15,340 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.881056006659161, 'Total loss': 0.881056006659161} | train loss {'Reaction outcome loss': 0.806942819948158, 'Total loss': 0.806942819948158}
2022-11-18 03:32:15,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:15,340 INFO:     Epoch: 89
2022-11-18 03:32:16,163 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8749521225690842, 'Total loss': 0.8749521225690842} | train loss {'Reaction outcome loss': 0.8079466357106163, 'Total loss': 0.8079466357106163}
2022-11-18 03:32:16,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:16,163 INFO:     Epoch: 90
2022-11-18 03:32:16,957 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8732611279595982, 'Total loss': 0.8732611279595982} | train loss {'Reaction outcome loss': 0.813874333616226, 'Total loss': 0.813874333616226}
2022-11-18 03:32:16,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:16,957 INFO:     Epoch: 91
2022-11-18 03:32:17,783 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8689507036046549, 'Total loss': 0.8689507036046549} | train loss {'Reaction outcome loss': 0.8110464869006988, 'Total loss': 0.8110464869006988}
2022-11-18 03:32:17,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:17,784 INFO:     Epoch: 92
2022-11-18 03:32:18,615 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8663367480039597, 'Total loss': 0.8663367480039597} | train loss {'Reaction outcome loss': 0.8092406889603984, 'Total loss': 0.8092406889603984}
2022-11-18 03:32:18,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:18,615 INFO:     Epoch: 93
2022-11-18 03:32:19,408 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8872921805490147, 'Total loss': 0.8872921805490147} | train loss {'Reaction outcome loss': 0.8067997636333588, 'Total loss': 0.8067997636333588}
2022-11-18 03:32:19,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:19,409 INFO:     Epoch: 94
2022-11-18 03:32:20,206 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8877748447385702, 'Total loss': 0.8877748447385702} | train loss {'Reaction outcome loss': 0.8064989031803224, 'Total loss': 0.8064989031803224}
2022-11-18 03:32:20,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:20,206 INFO:     Epoch: 95
2022-11-18 03:32:21,038 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8690473532134836, 'Total loss': 0.8690473532134836} | train loss {'Reaction outcome loss': 0.8091092311566875, 'Total loss': 0.8091092311566875}
2022-11-18 03:32:21,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:21,038 INFO:     Epoch: 96
2022-11-18 03:32:21,812 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8805167363448576, 'Total loss': 0.8805167363448576} | train loss {'Reaction outcome loss': 0.8137461945654885, 'Total loss': 0.8137461945654885}
2022-11-18 03:32:21,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:21,812 INFO:     Epoch: 97
2022-11-18 03:32:22,657 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.872996368191459, 'Total loss': 0.872996368191459} | train loss {'Reaction outcome loss': 0.8089919272930391, 'Total loss': 0.8089919272930391}
2022-11-18 03:32:22,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:22,657 INFO:     Epoch: 98
2022-11-18 03:32:23,453 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8666783652522347, 'Total loss': 0.8666783652522347} | train loss {'Reaction outcome loss': 0.8100597458260674, 'Total loss': 0.8100597458260674}
2022-11-18 03:32:23,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:23,453 INFO:     Epoch: 99
2022-11-18 03:32:24,283 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8726029301231558, 'Total loss': 0.8726029301231558} | train loss {'Reaction outcome loss': 0.8116932853816017, 'Total loss': 0.8116932853816017}
2022-11-18 03:32:24,283 INFO:     Best model found after epoch 71 of 100.
2022-11-18 03:32:24,283 INFO:   Done with stage: TRAINING
2022-11-18 03:32:24,284 INFO:   Starting stage: EVALUATION
2022-11-18 03:32:24,402 INFO:   Done with stage: EVALUATION
2022-11-18 03:32:24,402 INFO:   Leaving out SEQ value Fold_8
2022-11-18 03:32:24,415 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:32:24,415 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:32:25,085 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:32:25,085 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:32:25,155 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:32:25,156 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:32:25,156 INFO:     No hyperparam tuning for this model
2022-11-18 03:32:25,156 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:32:25,156 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:32:25,157 INFO:     None feature selector for col prot
2022-11-18 03:32:25,157 INFO:     None feature selector for col prot
2022-11-18 03:32:25,157 INFO:     None feature selector for col prot
2022-11-18 03:32:25,157 INFO:     None feature selector for col chem
2022-11-18 03:32:25,158 INFO:     None feature selector for col chem
2022-11-18 03:32:25,158 INFO:     None feature selector for col chem
2022-11-18 03:32:25,158 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:32:25,158 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:32:25,159 INFO:     Number of params in model 168571
2022-11-18 03:32:25,162 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:32:25,163 INFO:   Starting stage: TRAINING
2022-11-18 03:32:25,221 INFO:     Val loss before train {'Reaction outcome loss': 1.0818377502939918, 'Total loss': 1.0818377502939918}
2022-11-18 03:32:25,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:25,221 INFO:     Epoch: 0
2022-11-18 03:32:26,012 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8600988652218472, 'Total loss': 0.8600988652218472} | train loss {'Reaction outcome loss': 0.8608257317168992, 'Total loss': 0.8608257317168992}
2022-11-18 03:32:26,013 INFO:     Found new best model at epoch 0
2022-11-18 03:32:26,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:26,014 INFO:     Epoch: 1
2022-11-18 03:32:26,800 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8639154766093601, 'Total loss': 0.8639154766093601} | train loss {'Reaction outcome loss': 0.8328576281003142, 'Total loss': 0.8328576281003142}
2022-11-18 03:32:26,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:26,800 INFO:     Epoch: 2
2022-11-18 03:32:27,641 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8582782826640389, 'Total loss': 0.8582782826640389} | train loss {'Reaction outcome loss': 0.831484383055073, 'Total loss': 0.831484383055073}
2022-11-18 03:32:27,641 INFO:     Found new best model at epoch 2
2022-11-18 03:32:27,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:27,642 INFO:     Epoch: 3
2022-11-18 03:32:28,501 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8675612563436682, 'Total loss': 0.8675612563436682} | train loss {'Reaction outcome loss': 0.8276263846740549, 'Total loss': 0.8276263846740549}
2022-11-18 03:32:28,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:28,501 INFO:     Epoch: 4
2022-11-18 03:32:29,344 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8735054365613244, 'Total loss': 0.8735054365613244} | train loss {'Reaction outcome loss': 0.8282097149715733, 'Total loss': 0.8282097149715733}
2022-11-18 03:32:29,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:29,344 INFO:     Epoch: 5
2022-11-18 03:32:30,174 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8428708423267711, 'Total loss': 0.8428708423267711} | train loss {'Reaction outcome loss': 0.824261180181735, 'Total loss': 0.824261180181735}
2022-11-18 03:32:30,175 INFO:     Found new best model at epoch 5
2022-11-18 03:32:30,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:30,176 INFO:     Epoch: 6
2022-11-18 03:32:31,006 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8568347462198951, 'Total loss': 0.8568347462198951} | train loss {'Reaction outcome loss': 0.8167517576140431, 'Total loss': 0.8167517576140431}
2022-11-18 03:32:31,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:31,006 INFO:     Epoch: 7
2022-11-18 03:32:31,795 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8462759588252414, 'Total loss': 0.8462759588252414} | train loss {'Reaction outcome loss': 0.8163040374454699, 'Total loss': 0.8163040374454699}
2022-11-18 03:32:31,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:31,795 INFO:     Epoch: 8
2022-11-18 03:32:32,620 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8590858456763354, 'Total loss': 0.8590858456763354} | train loss {'Reaction outcome loss': 0.8189019165058368, 'Total loss': 0.8189019165058368}
2022-11-18 03:32:32,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:32,620 INFO:     Epoch: 9
2022-11-18 03:32:33,454 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8835685090585188, 'Total loss': 0.8835685090585188} | train loss {'Reaction outcome loss': 0.8180676409107471, 'Total loss': 0.8180676409107471}
2022-11-18 03:32:33,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:33,455 INFO:     Epoch: 10
2022-11-18 03:32:34,250 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8742120042443275, 'Total loss': 0.8742120042443275} | train loss {'Reaction outcome loss': 0.8115525516541863, 'Total loss': 0.8115525516541863}
2022-11-18 03:32:34,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:34,250 INFO:     Epoch: 11
2022-11-18 03:32:35,068 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.853664056821303, 'Total loss': 0.853664056821303} | train loss {'Reaction outcome loss': 0.8113160616593805, 'Total loss': 0.8113160616593805}
2022-11-18 03:32:35,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:35,068 INFO:     Epoch: 12
2022-11-18 03:32:35,895 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8622813482176174, 'Total loss': 0.8622813482176174} | train loss {'Reaction outcome loss': 0.8118468325147744, 'Total loss': 0.8118468325147744}
2022-11-18 03:32:35,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:35,896 INFO:     Epoch: 13
2022-11-18 03:32:36,686 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8461333228783174, 'Total loss': 0.8461333228783174} | train loss {'Reaction outcome loss': 0.8171977434563733, 'Total loss': 0.8171977434563733}
2022-11-18 03:32:36,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:36,686 INFO:     Epoch: 14
2022-11-18 03:32:37,523 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8945524204861034, 'Total loss': 0.8945524204861034} | train loss {'Reaction outcome loss': 0.8076054343448477, 'Total loss': 0.8076054343448477}
2022-11-18 03:32:37,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:37,523 INFO:     Epoch: 15
2022-11-18 03:32:38,342 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8686727312478152, 'Total loss': 0.8686727312478152} | train loss {'Reaction outcome loss': 0.814346990061675, 'Total loss': 0.814346990061675}
2022-11-18 03:32:38,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:38,343 INFO:     Epoch: 16
2022-11-18 03:32:39,167 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8344813354990699, 'Total loss': 0.8344813354990699} | train loss {'Reaction outcome loss': 0.8058609779441526, 'Total loss': 0.8058609779441526}
2022-11-18 03:32:39,167 INFO:     Found new best model at epoch 16
2022-11-18 03:32:39,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:39,168 INFO:     Epoch: 17
2022-11-18 03:32:39,962 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8646144311536442, 'Total loss': 0.8646144311536442} | train loss {'Reaction outcome loss': 0.8079188765603521, 'Total loss': 0.8079188765603521}
2022-11-18 03:32:39,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:39,962 INFO:     Epoch: 18
2022-11-18 03:32:40,769 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8384687087752603, 'Total loss': 0.8384687087752603} | train loss {'Reaction outcome loss': 0.8066268611080974, 'Total loss': 0.8066268611080974}
2022-11-18 03:32:40,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:40,769 INFO:     Epoch: 19
2022-11-18 03:32:41,545 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8484823094172911, 'Total loss': 0.8484823094172911} | train loss {'Reaction outcome loss': 0.8053258401662232, 'Total loss': 0.8053258401662232}
2022-11-18 03:32:41,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:41,546 INFO:     Epoch: 20
2022-11-18 03:32:42,372 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8473673090338707, 'Total loss': 0.8473673090338707} | train loss {'Reaction outcome loss': 0.8160700915072129, 'Total loss': 0.8160700915072129}
2022-11-18 03:32:42,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:42,372 INFO:     Epoch: 21
2022-11-18 03:32:43,159 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8641871593215249, 'Total loss': 0.8641871593215249} | train loss {'Reaction outcome loss': 0.8106649994608844, 'Total loss': 0.8106649994608844}
2022-11-18 03:32:43,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:43,160 INFO:     Epoch: 22
2022-11-18 03:32:43,987 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8687824031168764, 'Total loss': 0.8687824031168764} | train loss {'Reaction outcome loss': 0.8037361532811694, 'Total loss': 0.8037361532811694}
2022-11-18 03:32:43,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:43,987 INFO:     Epoch: 23
2022-11-18 03:32:44,813 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8326081267812036, 'Total loss': 0.8326081267812036} | train loss {'Reaction outcome loss': 0.806872939532585, 'Total loss': 0.806872939532585}
2022-11-18 03:32:44,814 INFO:     Found new best model at epoch 23
2022-11-18 03:32:44,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:44,814 INFO:     Epoch: 24
2022-11-18 03:32:45,638 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8500447598370638, 'Total loss': 0.8500447598370638} | train loss {'Reaction outcome loss': 0.8145266009969749, 'Total loss': 0.8145266009969749}
2022-11-18 03:32:45,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:45,639 INFO:     Epoch: 25
2022-11-18 03:32:46,459 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8309965783899481, 'Total loss': 0.8309965783899481} | train loss {'Reaction outcome loss': 0.8187596281530404, 'Total loss': 0.8187596281530404}
2022-11-18 03:32:46,459 INFO:     Found new best model at epoch 25
2022-11-18 03:32:46,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:46,460 INFO:     Epoch: 26
2022-11-18 03:32:47,268 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8537644906477495, 'Total loss': 0.8537644906477495} | train loss {'Reaction outcome loss': 0.8051174264929073, 'Total loss': 0.8051174264929073}
2022-11-18 03:32:47,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:47,268 INFO:     Epoch: 27
2022-11-18 03:32:48,060 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8615967272357508, 'Total loss': 0.8615967272357508} | train loss {'Reaction outcome loss': 0.8089668815917814, 'Total loss': 0.8089668815917814}
2022-11-18 03:32:48,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:48,062 INFO:     Epoch: 28
2022-11-18 03:32:48,868 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8735718700018796, 'Total loss': 0.8735718700018796} | train loss {'Reaction outcome loss': 0.8343401272528568, 'Total loss': 0.8343401272528568}
2022-11-18 03:32:48,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:48,868 INFO:     Epoch: 29
2022-11-18 03:32:49,692 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8465338830243457, 'Total loss': 0.8465338830243457} | train loss {'Reaction outcome loss': 0.8204756426183801, 'Total loss': 0.8204756426183801}
2022-11-18 03:32:49,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:49,693 INFO:     Epoch: 30
2022-11-18 03:32:50,507 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.845131823962385, 'Total loss': 0.845131823962385} | train loss {'Reaction outcome loss': 0.816729772428752, 'Total loss': 0.816729772428752}
2022-11-18 03:32:50,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:50,507 INFO:     Epoch: 31
2022-11-18 03:32:51,333 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8717800270427357, 'Total loss': 0.8717800270427357} | train loss {'Reaction outcome loss': 0.8030788020083779, 'Total loss': 0.8030788020083779}
2022-11-18 03:32:51,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:51,334 INFO:     Epoch: 32
2022-11-18 03:32:52,119 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.870762858201157, 'Total loss': 0.870762858201157} | train loss {'Reaction outcome loss': 0.8076052368893797, 'Total loss': 0.8076052368893797}
2022-11-18 03:32:52,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:52,119 INFO:     Epoch: 33
2022-11-18 03:32:52,940 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8279135349121961, 'Total loss': 0.8279135349121961} | train loss {'Reaction outcome loss': 0.813434790261844, 'Total loss': 0.813434790261844}
2022-11-18 03:32:52,941 INFO:     Found new best model at epoch 33
2022-11-18 03:32:52,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:52,942 INFO:     Epoch: 34
2022-11-18 03:32:53,747 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8332037024877288, 'Total loss': 0.8332037024877288} | train loss {'Reaction outcome loss': 0.8077842575094478, 'Total loss': 0.8077842575094478}
2022-11-18 03:32:53,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:53,749 INFO:     Epoch: 35
2022-11-18 03:32:54,592 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8323316716335036, 'Total loss': 0.8323316716335036} | train loss {'Reaction outcome loss': 0.8132065950858931, 'Total loss': 0.8132065950858931}
2022-11-18 03:32:54,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:54,592 INFO:     Epoch: 36
2022-11-18 03:32:55,398 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8396819233894348, 'Total loss': 0.8396819233894348} | train loss {'Reaction outcome loss': 0.818737324794777, 'Total loss': 0.818737324794777}
2022-11-18 03:32:55,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:55,398 INFO:     Epoch: 37
2022-11-18 03:32:56,188 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8535885241898623, 'Total loss': 0.8535885241898623} | train loss {'Reaction outcome loss': 0.8147212624067237, 'Total loss': 0.8147212624067237}
2022-11-18 03:32:56,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:56,188 INFO:     Epoch: 38
2022-11-18 03:32:56,957 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8352082845839587, 'Total loss': 0.8352082845839587} | train loss {'Reaction outcome loss': 0.805234608741907, 'Total loss': 0.805234608741907}
2022-11-18 03:32:56,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:56,958 INFO:     Epoch: 39
2022-11-18 03:32:57,735 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.844975085421042, 'Total loss': 0.844975085421042} | train loss {'Reaction outcome loss': 0.808388928049489, 'Total loss': 0.808388928049489}
2022-11-18 03:32:57,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:57,735 INFO:     Epoch: 40
2022-11-18 03:32:58,553 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8317233195359056, 'Total loss': 0.8317233195359056} | train loss {'Reaction outcome loss': 0.8176422894966264, 'Total loss': 0.8176422894966264}
2022-11-18 03:32:58,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:58,553 INFO:     Epoch: 41
2022-11-18 03:32:59,346 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8487351543524049, 'Total loss': 0.8487351543524049} | train loss {'Reaction outcome loss': 0.808012233813282, 'Total loss': 0.808012233813282}
2022-11-18 03:32:59,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:32:59,347 INFO:     Epoch: 42
2022-11-18 03:33:00,189 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8606000203977932, 'Total loss': 0.8606000203977932} | train loss {'Reaction outcome loss': 0.8160446564919552, 'Total loss': 0.8160446564919552}
2022-11-18 03:33:00,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:00,189 INFO:     Epoch: 43
2022-11-18 03:33:00,956 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8370998759161342, 'Total loss': 0.8370998759161342} | train loss {'Reaction outcome loss': 0.8062362779489896, 'Total loss': 0.8062362779489896}
2022-11-18 03:33:00,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:00,957 INFO:     Epoch: 44
2022-11-18 03:33:01,783 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.877323105931282, 'Total loss': 0.877323105931282} | train loss {'Reaction outcome loss': 0.8022284767164393, 'Total loss': 0.8022284767164393}
2022-11-18 03:33:01,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:01,784 INFO:     Epoch: 45
2022-11-18 03:33:02,590 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8170060786333951, 'Total loss': 0.8170060786333951} | train loss {'Reaction outcome loss': 0.8103711588180017, 'Total loss': 0.8103711588180017}
2022-11-18 03:33:02,590 INFO:     Found new best model at epoch 45
2022-11-18 03:33:02,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:02,591 INFO:     Epoch: 46
2022-11-18 03:33:03,377 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8366656587882475, 'Total loss': 0.8366656587882475} | train loss {'Reaction outcome loss': 0.8002088005967468, 'Total loss': 0.8002088005967468}
2022-11-18 03:33:03,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:03,377 INFO:     Epoch: 47
2022-11-18 03:33:04,193 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8260832130908966, 'Total loss': 0.8260832130908966} | train loss {'Reaction outcome loss': 0.8026270806065455, 'Total loss': 0.8026270806065455}
2022-11-18 03:33:04,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:04,194 INFO:     Epoch: 48
2022-11-18 03:33:04,992 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8415542529387907, 'Total loss': 0.8415542529387907} | train loss {'Reaction outcome loss': 0.8042167697840856, 'Total loss': 0.8042167697840856}
2022-11-18 03:33:04,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:04,994 INFO:     Epoch: 49
2022-11-18 03:33:05,795 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8365131210197102, 'Total loss': 0.8365131210197102} | train loss {'Reaction outcome loss': 0.8072489765491563, 'Total loss': 0.8072489765491563}
2022-11-18 03:33:05,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:05,796 INFO:     Epoch: 50
2022-11-18 03:33:06,623 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8424260291186246, 'Total loss': 0.8424260291186246} | train loss {'Reaction outcome loss': 0.8082108953703753, 'Total loss': 0.8082108953703753}
2022-11-18 03:33:06,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:06,623 INFO:     Epoch: 51
2022-11-18 03:33:07,453 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8318968279795214, 'Total loss': 0.8318968279795214} | train loss {'Reaction outcome loss': 0.8002077012892194, 'Total loss': 0.8002077012892194}
2022-11-18 03:33:07,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:07,454 INFO:     Epoch: 52
2022-11-18 03:33:08,236 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8385503115979108, 'Total loss': 0.8385503115979108} | train loss {'Reaction outcome loss': 0.8019551623929367, 'Total loss': 0.8019551623929367}
2022-11-18 03:33:08,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:08,236 INFO:     Epoch: 53
2022-11-18 03:33:09,054 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8356058699163523, 'Total loss': 0.8356058699163523} | train loss {'Reaction outcome loss': 0.802516478879249, 'Total loss': 0.802516478879249}
2022-11-18 03:33:09,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:09,054 INFO:     Epoch: 54
2022-11-18 03:33:09,889 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8369302627715197, 'Total loss': 0.8369302627715197} | train loss {'Reaction outcome loss': 0.8018614515239894, 'Total loss': 0.8018614515239894}
2022-11-18 03:33:09,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:09,889 INFO:     Epoch: 55
2022-11-18 03:33:10,686 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8406434235247698, 'Total loss': 0.8406434235247698} | train loss {'Reaction outcome loss': 0.801428964625486, 'Total loss': 0.801428964625486}
2022-11-18 03:33:10,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:10,687 INFO:     Epoch: 56
2022-11-18 03:33:11,478 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8935983072627675, 'Total loss': 0.8935983072627675} | train loss {'Reaction outcome loss': 0.7997827181207989, 'Total loss': 0.7997827181207989}
2022-11-18 03:33:11,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:11,478 INFO:     Epoch: 57
2022-11-18 03:33:12,281 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8421924635767937, 'Total loss': 0.8421924635767937} | train loss {'Reaction outcome loss': 0.8015004964733896, 'Total loss': 0.8015004964733896}
2022-11-18 03:33:12,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:12,281 INFO:     Epoch: 58
2022-11-18 03:33:13,104 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.837442161007361, 'Total loss': 0.837442161007361} | train loss {'Reaction outcome loss': 0.805735061646473, 'Total loss': 0.805735061646473}
2022-11-18 03:33:13,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:13,104 INFO:     Epoch: 59
2022-11-18 03:33:13,923 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8705062026327307, 'Total loss': 0.8705062026327307} | train loss {'Reaction outcome loss': 0.7964986665739946, 'Total loss': 0.7964986665739946}
2022-11-18 03:33:13,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:13,923 INFO:     Epoch: 60
2022-11-18 03:33:14,732 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8422016623345289, 'Total loss': 0.8422016623345289} | train loss {'Reaction outcome loss': 0.8094364568772103, 'Total loss': 0.8094364568772103}
2022-11-18 03:33:14,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:14,732 INFO:     Epoch: 61
2022-11-18 03:33:15,554 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.847389511086724, 'Total loss': 0.847389511086724} | train loss {'Reaction outcome loss': 0.8008271069058522, 'Total loss': 0.8008271069058522}
2022-11-18 03:33:15,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:15,555 INFO:     Epoch: 62
2022-11-18 03:33:16,370 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8475757552818819, 'Total loss': 0.8475757552818819} | train loss {'Reaction outcome loss': 0.8027266277988189, 'Total loss': 0.8027266277988189}
2022-11-18 03:33:16,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:16,372 INFO:     Epoch: 63
2022-11-18 03:33:17,198 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8334208537231792, 'Total loss': 0.8334208537231792} | train loss {'Reaction outcome loss': 0.8006344145608817, 'Total loss': 0.8006344145608817}
2022-11-18 03:33:17,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:17,198 INFO:     Epoch: 64
2022-11-18 03:33:18,039 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8354217897761952, 'Total loss': 0.8354217897761952} | train loss {'Reaction outcome loss': 0.7978877632573307, 'Total loss': 0.7978877632573307}
2022-11-18 03:33:18,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:18,040 INFO:     Epoch: 65
2022-11-18 03:33:18,837 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.887675674801523, 'Total loss': 0.887675674801523} | train loss {'Reaction outcome loss': 0.8004427049082783, 'Total loss': 0.8004427049082783}
2022-11-18 03:33:18,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:18,838 INFO:     Epoch: 66
2022-11-18 03:33:19,665 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8631257082928311, 'Total loss': 0.8631257082928311} | train loss {'Reaction outcome loss': 0.8037797595385597, 'Total loss': 0.8037797595385597}
2022-11-18 03:33:19,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:19,665 INFO:     Epoch: 67
2022-11-18 03:33:20,446 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8445091802965511, 'Total loss': 0.8445091802965511} | train loss {'Reaction outcome loss': 0.8041582243886554, 'Total loss': 0.8041582243886554}
2022-11-18 03:33:20,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:20,446 INFO:     Epoch: 68
2022-11-18 03:33:21,237 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8379884362220764, 'Total loss': 0.8379884362220764} | train loss {'Reaction outcome loss': 0.8015975623055991, 'Total loss': 0.8015975623055991}
2022-11-18 03:33:21,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:21,238 INFO:     Epoch: 69
2022-11-18 03:33:22,032 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8436261970888485, 'Total loss': 0.8436261970888485} | train loss {'Reaction outcome loss': 0.8008433701055735, 'Total loss': 0.8008433701055735}
2022-11-18 03:33:22,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:22,033 INFO:     Epoch: 70
2022-11-18 03:33:22,807 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8431036763570525, 'Total loss': 0.8431036763570525} | train loss {'Reaction outcome loss': 0.8129505545262866, 'Total loss': 0.8129505545262866}
2022-11-18 03:33:22,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:22,808 INFO:     Epoch: 71
2022-11-18 03:33:23,606 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8327416093512015, 'Total loss': 0.8327416093512015} | train loss {'Reaction outcome loss': 0.8038632192833703, 'Total loss': 0.8038632192833703}
2022-11-18 03:33:23,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:23,606 INFO:     Epoch: 72
2022-11-18 03:33:24,387 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.842507775534283, 'Total loss': 0.842507775534283} | train loss {'Reaction outcome loss': 0.8019500864662139, 'Total loss': 0.8019500864662139}
2022-11-18 03:33:24,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:24,387 INFO:     Epoch: 73
2022-11-18 03:33:25,157 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8459713337096301, 'Total loss': 0.8459713337096301} | train loss {'Reaction outcome loss': 0.7959949603447547, 'Total loss': 0.7959949603447547}
2022-11-18 03:33:25,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:25,157 INFO:     Epoch: 74
2022-11-18 03:33:25,940 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8438970920714465, 'Total loss': 0.8438970920714465} | train loss {'Reaction outcome loss': 0.7989150035960472, 'Total loss': 0.7989150035960472}
2022-11-18 03:33:25,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:25,940 INFO:     Epoch: 75
2022-11-18 03:33:26,709 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8992485722357576, 'Total loss': 0.8992485722357576} | train loss {'Reaction outcome loss': 0.7975385839398573, 'Total loss': 0.7975385839398573}
2022-11-18 03:33:26,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:26,709 INFO:     Epoch: 76
2022-11-18 03:33:27,490 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8455217968333851, 'Total loss': 0.8455217968333851} | train loss {'Reaction outcome loss': 0.8082893478725603, 'Total loss': 0.8082893478725603}
2022-11-18 03:33:27,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:27,491 INFO:     Epoch: 77
2022-11-18 03:33:28,234 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8388094048608433, 'Total loss': 0.8388094048608433} | train loss {'Reaction outcome loss': 0.8041298511298561, 'Total loss': 0.8041298511298561}
2022-11-18 03:33:28,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:28,235 INFO:     Epoch: 78
2022-11-18 03:33:29,000 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8269318159330975, 'Total loss': 0.8269318159330975} | train loss {'Reaction outcome loss': 0.8036879607540394, 'Total loss': 0.8036879607540394}
2022-11-18 03:33:29,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:29,000 INFO:     Epoch: 79
2022-11-18 03:33:29,787 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8310194943438877, 'Total loss': 0.8310194943438877} | train loss {'Reaction outcome loss': 0.8096142883001551, 'Total loss': 0.8096142883001551}
2022-11-18 03:33:29,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:29,788 INFO:     Epoch: 80
2022-11-18 03:33:30,565 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8275660913098942, 'Total loss': 0.8275660913098942} | train loss {'Reaction outcome loss': 0.8042751504824712, 'Total loss': 0.8042751504824712}
2022-11-18 03:33:30,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:30,565 INFO:     Epoch: 81
2022-11-18 03:33:31,338 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8424287885427475, 'Total loss': 0.8424287885427475} | train loss {'Reaction outcome loss': 0.804351182239741, 'Total loss': 0.804351182239741}
2022-11-18 03:33:31,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:31,339 INFO:     Epoch: 82
2022-11-18 03:33:32,142 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.835309655151584, 'Total loss': 0.835309655151584} | train loss {'Reaction outcome loss': 0.8019450201920653, 'Total loss': 0.8019450201920653}
2022-11-18 03:33:32,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:32,142 INFO:     Epoch: 83
2022-11-18 03:33:32,947 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8389174762097272, 'Total loss': 0.8389174762097272} | train loss {'Reaction outcome loss': 0.803305808349177, 'Total loss': 0.803305808349177}
2022-11-18 03:33:32,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:32,949 INFO:     Epoch: 84
2022-11-18 03:33:33,739 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8346711776473306, 'Total loss': 0.8346711776473306} | train loss {'Reaction outcome loss': 0.8093667862868985, 'Total loss': 0.8093667862868985}
2022-11-18 03:33:33,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:33,739 INFO:     Epoch: 85
2022-11-18 03:33:34,532 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8351407680999149, 'Total loss': 0.8351407680999149} | train loss {'Reaction outcome loss': 0.7992311725656875, 'Total loss': 0.7992311725656875}
2022-11-18 03:33:34,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:34,532 INFO:     Epoch: 86
2022-11-18 03:33:35,328 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8319564841010354, 'Total loss': 0.8319564841010354} | train loss {'Reaction outcome loss': 0.7995234187692404, 'Total loss': 0.7995234187692404}
2022-11-18 03:33:35,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:35,328 INFO:     Epoch: 87
2022-11-18 03:33:36,113 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8442510705102574, 'Total loss': 0.8442510705102574} | train loss {'Reaction outcome loss': 0.8118560940389209, 'Total loss': 0.8118560940389209}
2022-11-18 03:33:36,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:36,114 INFO:     Epoch: 88
2022-11-18 03:33:36,903 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8379912003874779, 'Total loss': 0.8379912003874779} | train loss {'Reaction outcome loss': 0.805119822865073, 'Total loss': 0.805119822865073}
2022-11-18 03:33:36,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:36,903 INFO:     Epoch: 89
2022-11-18 03:33:37,654 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8374199975620616, 'Total loss': 0.8374199975620616} | train loss {'Reaction outcome loss': 0.7983999214915611, 'Total loss': 0.7983999214915611}
2022-11-18 03:33:37,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:37,654 INFO:     Epoch: 90
2022-11-18 03:33:38,410 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8250497715039686, 'Total loss': 0.8250497715039686} | train loss {'Reaction outcome loss': 0.799225348089388, 'Total loss': 0.799225348089388}
2022-11-18 03:33:38,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:38,411 INFO:     Epoch: 91
2022-11-18 03:33:39,208 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8208448405970227, 'Total loss': 0.8208448405970227} | train loss {'Reaction outcome loss': 0.8122813354136973, 'Total loss': 0.8122813354136973}
2022-11-18 03:33:39,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:39,209 INFO:     Epoch: 92
2022-11-18 03:33:39,977 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8507673374631188, 'Total loss': 0.8507673374631188} | train loss {'Reaction outcome loss': 0.8049571953321758, 'Total loss': 0.8049571953321758}
2022-11-18 03:33:39,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:39,977 INFO:     Epoch: 93
2022-11-18 03:33:40,757 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.861375012181022, 'Total loss': 0.861375012181022} | train loss {'Reaction outcome loss': 0.8076435637015563, 'Total loss': 0.8076435637015563}
2022-11-18 03:33:40,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:40,757 INFO:     Epoch: 94
2022-11-18 03:33:41,523 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8367401347918944, 'Total loss': 0.8367401347918944} | train loss {'Reaction outcome loss': 0.80106559282674, 'Total loss': 0.80106559282674}
2022-11-18 03:33:41,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:41,524 INFO:     Epoch: 95
2022-11-18 03:33:42,323 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8401880386200818, 'Total loss': 0.8401880386200818} | train loss {'Reaction outcome loss': 0.7978187580460961, 'Total loss': 0.7978187580460961}
2022-11-18 03:33:42,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:42,323 INFO:     Epoch: 96
2022-11-18 03:33:43,121 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.834854432805018, 'Total loss': 0.834854432805018} | train loss {'Reaction outcome loss': 0.8018597838457538, 'Total loss': 0.8018597838457538}
2022-11-18 03:33:43,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:43,121 INFO:     Epoch: 97
2022-11-18 03:33:43,899 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.854695203629407, 'Total loss': 0.854695203629407} | train loss {'Reaction outcome loss': 0.8023558611329268, 'Total loss': 0.8023558611329268}
2022-11-18 03:33:43,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:43,905 INFO:     Epoch: 98
2022-11-18 03:33:44,689 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8398589248006995, 'Total loss': 0.8398589248006995} | train loss {'Reaction outcome loss': 0.8186369527448044, 'Total loss': 0.8186369527448044}
2022-11-18 03:33:44,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:44,689 INFO:     Epoch: 99
2022-11-18 03:33:45,446 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8397687917405908, 'Total loss': 0.8397687917405908} | train loss {'Reaction outcome loss': 0.7996888437010499, 'Total loss': 0.7996888437010499}
2022-11-18 03:33:45,446 INFO:     Best model found after epoch 46 of 100.
2022-11-18 03:33:45,446 INFO:   Done with stage: TRAINING
2022-11-18 03:33:45,446 INFO:   Starting stage: EVALUATION
2022-11-18 03:33:45,570 INFO:   Done with stage: EVALUATION
2022-11-18 03:33:45,570 INFO:   Leaving out SEQ value Fold_9
2022-11-18 03:33:45,583 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:33:45,583 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:33:46,260 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:33:46,260 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:33:46,330 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:33:46,330 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:33:46,330 INFO:     No hyperparam tuning for this model
2022-11-18 03:33:46,330 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:33:46,330 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:33:46,331 INFO:     None feature selector for col prot
2022-11-18 03:33:46,331 INFO:     None feature selector for col prot
2022-11-18 03:33:46,331 INFO:     None feature selector for col prot
2022-11-18 03:33:46,331 INFO:     None feature selector for col chem
2022-11-18 03:33:46,332 INFO:     None feature selector for col chem
2022-11-18 03:33:46,332 INFO:     None feature selector for col chem
2022-11-18 03:33:46,332 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:33:46,332 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:33:46,333 INFO:     Number of params in model 168571
2022-11-18 03:33:46,337 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:33:46,337 INFO:   Starting stage: TRAINING
2022-11-18 03:33:46,394 INFO:     Val loss before train {'Reaction outcome loss': 0.9789818349209699, 'Total loss': 0.9789818349209699}
2022-11-18 03:33:46,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:46,395 INFO:     Epoch: 0
2022-11-18 03:33:47,149 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8329805562442, 'Total loss': 0.8329805562442} | train loss {'Reaction outcome loss': 0.8766557683627452, 'Total loss': 0.8766557683627452}
2022-11-18 03:33:47,149 INFO:     Found new best model at epoch 0
2022-11-18 03:33:47,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:47,150 INFO:     Epoch: 1
2022-11-18 03:33:47,918 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8696396486325697, 'Total loss': 0.8696396486325697} | train loss {'Reaction outcome loss': 0.8468367315588459, 'Total loss': 0.8468367315588459}
2022-11-18 03:33:47,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:47,918 INFO:     Epoch: 2
2022-11-18 03:33:48,725 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8175115219571374, 'Total loss': 0.8175115219571374} | train loss {'Reaction outcome loss': 0.8440588540848224, 'Total loss': 0.8440588540848224}
2022-11-18 03:33:48,726 INFO:     Found new best model at epoch 2
2022-11-18 03:33:48,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:48,726 INFO:     Epoch: 3
2022-11-18 03:33:49,507 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8254077238115397, 'Total loss': 0.8254077238115397} | train loss {'Reaction outcome loss': 0.8412534414279845, 'Total loss': 0.8412534414279845}
2022-11-18 03:33:49,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:49,509 INFO:     Epoch: 4
2022-11-18 03:33:50,283 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8284697708758441, 'Total loss': 0.8284697708758441} | train loss {'Reaction outcome loss': 0.8314987428246006, 'Total loss': 0.8314987428246006}
2022-11-18 03:33:50,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:50,283 INFO:     Epoch: 5
2022-11-18 03:33:51,056 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8167099112814123, 'Total loss': 0.8167099112814123} | train loss {'Reaction outcome loss': 0.8278692898250395, 'Total loss': 0.8278692898250395}
2022-11-18 03:33:51,056 INFO:     Found new best model at epoch 5
2022-11-18 03:33:51,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:51,057 INFO:     Epoch: 6
2022-11-18 03:33:51,847 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8105090009895238, 'Total loss': 0.8105090009895238} | train loss {'Reaction outcome loss': 0.8259752104359288, 'Total loss': 0.8259752104359288}
2022-11-18 03:33:51,847 INFO:     Found new best model at epoch 6
2022-11-18 03:33:51,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:51,848 INFO:     Epoch: 7
2022-11-18 03:33:52,603 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8065053874796088, 'Total loss': 0.8065053874796088} | train loss {'Reaction outcome loss': 0.8288000492799666, 'Total loss': 0.8288000492799666}
2022-11-18 03:33:52,603 INFO:     Found new best model at epoch 7
2022-11-18 03:33:52,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:52,604 INFO:     Epoch: 8
2022-11-18 03:33:53,399 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8124924383380197, 'Total loss': 0.8124924383380197} | train loss {'Reaction outcome loss': 0.8262070770705899, 'Total loss': 0.8262070770705899}
2022-11-18 03:33:53,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:53,399 INFO:     Epoch: 9
2022-11-18 03:33:54,171 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.81398625604131, 'Total loss': 0.81398625604131} | train loss {'Reaction outcome loss': 0.8207255735272362, 'Total loss': 0.8207255735272362}
2022-11-18 03:33:54,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:54,171 INFO:     Epoch: 10
2022-11-18 03:33:54,959 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8321780088272962, 'Total loss': 0.8321780088272962} | train loss {'Reaction outcome loss': 0.8215651883473319, 'Total loss': 0.8215651883473319}
2022-11-18 03:33:54,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:54,961 INFO:     Epoch: 11
2022-11-18 03:33:55,762 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8341035626151345, 'Total loss': 0.8341035626151345} | train loss {'Reaction outcome loss': 0.8267115552819544, 'Total loss': 0.8267115552819544}
2022-11-18 03:33:55,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:55,762 INFO:     Epoch: 12
2022-11-18 03:33:56,545 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8104813119227235, 'Total loss': 0.8104813119227235} | train loss {'Reaction outcome loss': 0.8203230348806227, 'Total loss': 0.8203230348806227}
2022-11-18 03:33:56,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:56,545 INFO:     Epoch: 13
2022-11-18 03:33:57,311 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8129010119221427, 'Total loss': 0.8129010119221427} | train loss {'Reaction outcome loss': 0.8169626415737213, 'Total loss': 0.8169626415737213}
2022-11-18 03:33:57,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:57,311 INFO:     Epoch: 14
2022-11-18 03:33:58,112 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8052198934284124, 'Total loss': 0.8052198934284124} | train loss {'Reaction outcome loss': 0.8187562733167603, 'Total loss': 0.8187562733167603}
2022-11-18 03:33:58,112 INFO:     Found new best model at epoch 14
2022-11-18 03:33:58,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:58,113 INFO:     Epoch: 15
2022-11-18 03:33:58,877 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8393584002148021, 'Total loss': 0.8393584002148021} | train loss {'Reaction outcome loss': 0.8186471512120578, 'Total loss': 0.8186471512120578}
2022-11-18 03:33:58,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:58,877 INFO:     Epoch: 16
2022-11-18 03:33:59,648 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.814290923151103, 'Total loss': 0.814290923151103} | train loss {'Reaction outcome loss': 0.821196035872544, 'Total loss': 0.821196035872544}
2022-11-18 03:33:59,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:33:59,649 INFO:     Epoch: 17
2022-11-18 03:34:00,441 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.813683420419693, 'Total loss': 0.813683420419693} | train loss {'Reaction outcome loss': 0.8211930162243305, 'Total loss': 0.8211930162243305}
2022-11-18 03:34:00,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:00,442 INFO:     Epoch: 18
2022-11-18 03:34:01,242 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8126146481795744, 'Total loss': 0.8126146481795744} | train loss {'Reaction outcome loss': 0.820553669886243, 'Total loss': 0.820553669886243}
2022-11-18 03:34:01,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:01,242 INFO:     Epoch: 19
2022-11-18 03:34:02,012 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.805302460085262, 'Total loss': 0.805302460085262} | train loss {'Reaction outcome loss': 0.8211738908242795, 'Total loss': 0.8211738908242795}
2022-11-18 03:34:02,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:02,013 INFO:     Epoch: 20
2022-11-18 03:34:02,794 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8116227930242365, 'Total loss': 0.8116227930242365} | train loss {'Reaction outcome loss': 0.8187079851425463, 'Total loss': 0.8187079851425463}
2022-11-18 03:34:02,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:02,794 INFO:     Epoch: 21
2022-11-18 03:34:03,597 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8093350448391654, 'Total loss': 0.8093350448391654} | train loss {'Reaction outcome loss': 0.8173632792407467, 'Total loss': 0.8173632792407467}
2022-11-18 03:34:03,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:03,597 INFO:     Epoch: 22
2022-11-18 03:34:04,379 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8352750729430806, 'Total loss': 0.8352750729430806} | train loss {'Reaction outcome loss': 0.8177153269850439, 'Total loss': 0.8177153269850439}
2022-11-18 03:34:04,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:04,379 INFO:     Epoch: 23
2022-11-18 03:34:05,185 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8189772821285508, 'Total loss': 0.8189772821285508} | train loss {'Reaction outcome loss': 0.8168885706653518, 'Total loss': 0.8168885706653518}
2022-11-18 03:34:05,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:05,186 INFO:     Epoch: 24
2022-11-18 03:34:05,984 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8077679764140736, 'Total loss': 0.8077679764140736} | train loss {'Reaction outcome loss': 0.8205451566365457, 'Total loss': 0.8205451566365457}
2022-11-18 03:34:05,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:05,986 INFO:     Epoch: 25
2022-11-18 03:34:06,764 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8047810671004382, 'Total loss': 0.8047810671004382} | train loss {'Reaction outcome loss': 0.8146206243864952, 'Total loss': 0.8146206243864952}
2022-11-18 03:34:06,764 INFO:     Found new best model at epoch 25
2022-11-18 03:34:06,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:06,765 INFO:     Epoch: 26
2022-11-18 03:34:07,567 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8199133751067248, 'Total loss': 0.8199133751067248} | train loss {'Reaction outcome loss': 0.8180814288075893, 'Total loss': 0.8180814288075893}
2022-11-18 03:34:07,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:07,568 INFO:     Epoch: 27
2022-11-18 03:34:08,344 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8684768405827609, 'Total loss': 0.8684768405827609} | train loss {'Reaction outcome loss': 0.8216961595800615, 'Total loss': 0.8216961595800615}
2022-11-18 03:34:08,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:08,344 INFO:     Epoch: 28
2022-11-18 03:34:09,128 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8207381706346165, 'Total loss': 0.8207381706346165} | train loss {'Reaction outcome loss': 0.8146314494792493, 'Total loss': 0.8146314494792493}
2022-11-18 03:34:09,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:09,129 INFO:     Epoch: 29
2022-11-18 03:34:09,910 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8224280320785262, 'Total loss': 0.8224280320785262} | train loss {'Reaction outcome loss': 0.8190126068169071, 'Total loss': 0.8190126068169071}
2022-11-18 03:34:09,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:09,910 INFO:     Epoch: 30
2022-11-18 03:34:10,699 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8140464743429964, 'Total loss': 0.8140464743429964} | train loss {'Reaction outcome loss': 0.8156097179218647, 'Total loss': 0.8156097179218647}
2022-11-18 03:34:10,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:10,699 INFO:     Epoch: 31
2022-11-18 03:34:11,472 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8143444677645509, 'Total loss': 0.8143444677645509} | train loss {'Reaction outcome loss': 0.8125830281886363, 'Total loss': 0.8125830281886363}
2022-11-18 03:34:11,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:11,474 INFO:     Epoch: 32
2022-11-18 03:34:12,247 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8091967918656089, 'Total loss': 0.8091967918656089} | train loss {'Reaction outcome loss': 0.8159026567253375, 'Total loss': 0.8159026567253375}
2022-11-18 03:34:12,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:12,247 INFO:     Epoch: 33
2022-11-18 03:34:13,044 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8125060031359846, 'Total loss': 0.8125060031359846} | train loss {'Reaction outcome loss': 0.8137924947565601, 'Total loss': 0.8137924947565601}
2022-11-18 03:34:13,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:13,044 INFO:     Epoch: 34
2022-11-18 03:34:13,839 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.827207469127395, 'Total loss': 0.827207469127395} | train loss {'Reaction outcome loss': 0.8148071678175081, 'Total loss': 0.8148071678175081}
2022-11-18 03:34:13,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:13,839 INFO:     Epoch: 35
2022-11-18 03:34:14,615 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.811871043660424, 'Total loss': 0.811871043660424} | train loss {'Reaction outcome loss': 0.8186026851256047, 'Total loss': 0.8186026851256047}
2022-11-18 03:34:14,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:14,616 INFO:     Epoch: 36
2022-11-18 03:34:15,391 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8113142631270669, 'Total loss': 0.8113142631270669} | train loss {'Reaction outcome loss': 0.8163577527288468, 'Total loss': 0.8163577527288468}
2022-11-18 03:34:15,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:15,391 INFO:     Epoch: 37
2022-11-18 03:34:16,168 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8168694295666434, 'Total loss': 0.8168694295666434} | train loss {'Reaction outcome loss': 0.8147134722601022, 'Total loss': 0.8147134722601022}
2022-11-18 03:34:16,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:16,168 INFO:     Epoch: 38
2022-11-18 03:34:16,961 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8052297789942134, 'Total loss': 0.8052297789942134} | train loss {'Reaction outcome loss': 0.8182979438814425, 'Total loss': 0.8182979438814425}
2022-11-18 03:34:16,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:16,963 INFO:     Epoch: 39
2022-11-18 03:34:17,772 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8116092885082419, 'Total loss': 0.8116092885082419} | train loss {'Reaction outcome loss': 0.8131335615631072, 'Total loss': 0.8131335615631072}
2022-11-18 03:34:17,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:17,773 INFO:     Epoch: 40
2022-11-18 03:34:18,558 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7986111187122085, 'Total loss': 0.7986111187122085} | train loss {'Reaction outcome loss': 0.8149862246167275, 'Total loss': 0.8149862246167275}
2022-11-18 03:34:18,559 INFO:     Found new best model at epoch 40
2022-11-18 03:34:18,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:18,560 INFO:     Epoch: 41
2022-11-18 03:34:19,351 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.800041301683946, 'Total loss': 0.800041301683946} | train loss {'Reaction outcome loss': 0.8132337352200862, 'Total loss': 0.8132337352200862}
2022-11-18 03:34:19,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:19,351 INFO:     Epoch: 42
2022-11-18 03:34:20,141 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8333952975544062, 'Total loss': 0.8333952975544062} | train loss {'Reaction outcome loss': 0.8137130632756218, 'Total loss': 0.8137130632756218}
2022-11-18 03:34:20,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:20,141 INFO:     Epoch: 43
2022-11-18 03:34:20,903 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8118236383253877, 'Total loss': 0.8118236383253877} | train loss {'Reaction outcome loss': 0.8145500231654413, 'Total loss': 0.8145500231654413}
2022-11-18 03:34:20,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:20,903 INFO:     Epoch: 44
2022-11-18 03:34:21,702 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8255938278003172, 'Total loss': 0.8255938278003172} | train loss {'Reaction outcome loss': 0.8143689465378562, 'Total loss': 0.8143689465378562}
2022-11-18 03:34:21,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:21,702 INFO:     Epoch: 45
2022-11-18 03:34:22,491 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8152465522289276, 'Total loss': 0.8152465522289276} | train loss {'Reaction outcome loss': 0.8126357575097392, 'Total loss': 0.8126357575097392}
2022-11-18 03:34:22,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:22,492 INFO:     Epoch: 46
2022-11-18 03:34:23,258 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.805535883388736, 'Total loss': 0.805535883388736} | train loss {'Reaction outcome loss': 0.8215512340107272, 'Total loss': 0.8215512340107272}
2022-11-18 03:34:23,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:23,258 INFO:     Epoch: 47
2022-11-18 03:34:24,027 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8157279504971071, 'Total loss': 0.8157279504971071} | train loss {'Reaction outcome loss': 0.8109965881993694, 'Total loss': 0.8109965881993694}
2022-11-18 03:34:24,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:24,027 INFO:     Epoch: 48
2022-11-18 03:34:24,820 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8005235628648237, 'Total loss': 0.8005235628648237} | train loss {'Reaction outcome loss': 0.8101824702274415, 'Total loss': 0.8101824702274415}
2022-11-18 03:34:24,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:24,820 INFO:     Epoch: 49
2022-11-18 03:34:25,609 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7961122989654541, 'Total loss': 0.7961122989654541} | train loss {'Reaction outcome loss': 0.8154711545475067, 'Total loss': 0.8154711545475067}
2022-11-18 03:34:25,609 INFO:     Found new best model at epoch 49
2022-11-18 03:34:25,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:25,610 INFO:     Epoch: 50
2022-11-18 03:34:26,390 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8281486677852544, 'Total loss': 0.8281486677852544} | train loss {'Reaction outcome loss': 0.8168617589098792, 'Total loss': 0.8168617589098792}
2022-11-18 03:34:26,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:26,391 INFO:     Epoch: 51
2022-11-18 03:34:27,160 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8234772140329535, 'Total loss': 0.8234772140329535} | train loss {'Reaction outcome loss': 0.814232281499332, 'Total loss': 0.814232281499332}
2022-11-18 03:34:27,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:27,160 INFO:     Epoch: 52
2022-11-18 03:34:27,947 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8099602494727481, 'Total loss': 0.8099602494727481} | train loss {'Reaction outcome loss': 0.8167970425659611, 'Total loss': 0.8167970425659611}
2022-11-18 03:34:27,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:27,949 INFO:     Epoch: 53
2022-11-18 03:34:28,742 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8245432688431307, 'Total loss': 0.8245432688431307} | train loss {'Reaction outcome loss': 0.8090278195036996, 'Total loss': 0.8090278195036996}
2022-11-18 03:34:28,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:28,742 INFO:     Epoch: 54
2022-11-18 03:34:29,525 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8113219555128705, 'Total loss': 0.8113219555128705} | train loss {'Reaction outcome loss': 0.812955034836646, 'Total loss': 0.812955034836646}
2022-11-18 03:34:29,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:29,525 INFO:     Epoch: 55
2022-11-18 03:34:30,286 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8202953799204393, 'Total loss': 0.8202953799204393} | train loss {'Reaction outcome loss': 0.812634959696762, 'Total loss': 0.812634959696762}
2022-11-18 03:34:30,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:30,287 INFO:     Epoch: 56
2022-11-18 03:34:31,086 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8081371655518358, 'Total loss': 0.8081371655518358} | train loss {'Reaction outcome loss': 0.8146195034346273, 'Total loss': 0.8146195034346273}
2022-11-18 03:34:31,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:31,086 INFO:     Epoch: 57
2022-11-18 03:34:31,856 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8184389986775138, 'Total loss': 0.8184389986775138} | train loss {'Reaction outcome loss': 0.814063836249613, 'Total loss': 0.814063836249613}
2022-11-18 03:34:31,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:31,856 INFO:     Epoch: 58
2022-11-18 03:34:32,653 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8179909871383146, 'Total loss': 0.8179909871383146} | train loss {'Reaction outcome loss': 0.8166580316760848, 'Total loss': 0.8166580316760848}
2022-11-18 03:34:32,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:32,653 INFO:     Epoch: 59
2022-11-18 03:34:33,433 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8145278319716454, 'Total loss': 0.8145278319716454} | train loss {'Reaction outcome loss': 0.8165942569894176, 'Total loss': 0.8165942569894176}
2022-11-18 03:34:33,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:33,434 INFO:     Epoch: 60
2022-11-18 03:34:34,231 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8076944899829951, 'Total loss': 0.8076944899829951} | train loss {'Reaction outcome loss': 0.8135574629470226, 'Total loss': 0.8135574629470226}
2022-11-18 03:34:34,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:34,231 INFO:     Epoch: 61
2022-11-18 03:34:35,000 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8024310584772717, 'Total loss': 0.8024310584772717} | train loss {'Reaction outcome loss': 0.8092126116877602, 'Total loss': 0.8092126116877602}
2022-11-18 03:34:35,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:35,001 INFO:     Epoch: 62
2022-11-18 03:34:35,787 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7953992526639592, 'Total loss': 0.7953992526639592} | train loss {'Reaction outcome loss': 0.8141535991622556, 'Total loss': 0.8141535991622556}
2022-11-18 03:34:35,788 INFO:     Found new best model at epoch 62
2022-11-18 03:34:35,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:35,788 INFO:     Epoch: 63
2022-11-18 03:34:36,581 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8002547933296724, 'Total loss': 0.8002547933296724} | train loss {'Reaction outcome loss': 0.8126352590418631, 'Total loss': 0.8126352590418631}
2022-11-18 03:34:36,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:36,582 INFO:     Epoch: 64
2022-11-18 03:34:37,376 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8093804378401149, 'Total loss': 0.8093804378401149} | train loss {'Reaction outcome loss': 0.8154837302863598, 'Total loss': 0.8154837302863598}
2022-11-18 03:34:37,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:37,377 INFO:     Epoch: 65
2022-11-18 03:34:38,180 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8055850687352094, 'Total loss': 0.8055850687352094} | train loss {'Reaction outcome loss': 0.8148434979300345, 'Total loss': 0.8148434979300345}
2022-11-18 03:34:38,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:38,180 INFO:     Epoch: 66
2022-11-18 03:34:38,963 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8224205483089794, 'Total loss': 0.8224205483089794} | train loss {'Reaction outcome loss': 0.8172304756458728, 'Total loss': 0.8172304756458728}
2022-11-18 03:34:38,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:38,964 INFO:     Epoch: 67
2022-11-18 03:34:39,747 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8139409693804655, 'Total loss': 0.8139409693804655} | train loss {'Reaction outcome loss': 0.8161545549669573, 'Total loss': 0.8161545549669573}
2022-11-18 03:34:39,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:39,748 INFO:     Epoch: 68
2022-11-18 03:34:40,523 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8009095632217147, 'Total loss': 0.8009095632217147} | train loss {'Reaction outcome loss': 0.8103095976816069, 'Total loss': 0.8103095976816069}
2022-11-18 03:34:40,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:40,524 INFO:     Epoch: 69
2022-11-18 03:34:41,328 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.804717019200325, 'Total loss': 0.804717019200325} | train loss {'Reaction outcome loss': 0.8154534097881087, 'Total loss': 0.8154534097881087}
2022-11-18 03:34:41,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:41,328 INFO:     Epoch: 70
2022-11-18 03:34:42,111 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8263344737616453, 'Total loss': 0.8263344737616453} | train loss {'Reaction outcome loss': 0.8175926186865375, 'Total loss': 0.8175926186865375}
2022-11-18 03:34:42,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:42,111 INFO:     Epoch: 71
2022-11-18 03:34:42,896 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8146460171450268, 'Total loss': 0.8146460171450268} | train loss {'Reaction outcome loss': 0.8128948784883945, 'Total loss': 0.8128948784883945}
2022-11-18 03:34:42,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:42,896 INFO:     Epoch: 72
2022-11-18 03:34:43,674 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7989628592675383, 'Total loss': 0.7989628592675383} | train loss {'Reaction outcome loss': 0.8179810453326471, 'Total loss': 0.8179810453326471}
2022-11-18 03:34:43,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:43,675 INFO:     Epoch: 73
2022-11-18 03:34:44,464 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8147792558778416, 'Total loss': 0.8147792558778416} | train loss {'Reaction outcome loss': 0.819467460316035, 'Total loss': 0.819467460316035}
2022-11-18 03:34:44,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:44,466 INFO:     Epoch: 74
2022-11-18 03:34:45,259 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8042758615179495, 'Total loss': 0.8042758615179495} | train loss {'Reaction outcome loss': 0.815997383647388, 'Total loss': 0.815997383647388}
2022-11-18 03:34:45,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:45,259 INFO:     Epoch: 75
2022-11-18 03:34:46,047 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8105959269133481, 'Total loss': 0.8105959269133481} | train loss {'Reaction outcome loss': 0.808953611480613, 'Total loss': 0.808953611480613}
2022-11-18 03:34:46,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:46,047 INFO:     Epoch: 76
2022-11-18 03:34:46,827 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8032659881494262, 'Total loss': 0.8032659881494262} | train loss {'Reaction outcome loss': 0.8156846206515066, 'Total loss': 0.8156846206515066}
2022-11-18 03:34:46,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:46,828 INFO:     Epoch: 77
2022-11-18 03:34:47,607 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.813115419311957, 'Total loss': 0.813115419311957} | train loss {'Reaction outcome loss': 0.8132543790965311, 'Total loss': 0.8132543790965311}
2022-11-18 03:34:47,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:47,607 INFO:     Epoch: 78
2022-11-18 03:34:48,412 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8030641329559413, 'Total loss': 0.8030641329559413} | train loss {'Reaction outcome loss': 0.8169105994485079, 'Total loss': 0.8169105994485079}
2022-11-18 03:34:48,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:48,412 INFO:     Epoch: 79
2022-11-18 03:34:49,218 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8187649500640956, 'Total loss': 0.8187649500640956} | train loss {'Reaction outcome loss': 0.8148740822028729, 'Total loss': 0.8148740822028729}
2022-11-18 03:34:49,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:49,218 INFO:     Epoch: 80
2022-11-18 03:34:50,014 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8201920566233721, 'Total loss': 0.8201920566233721} | train loss {'Reaction outcome loss': 0.8130170444567357, 'Total loss': 0.8130170444567357}
2022-11-18 03:34:50,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:50,016 INFO:     Epoch: 81
2022-11-18 03:34:50,805 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.801330181685361, 'Total loss': 0.801330181685361} | train loss {'Reaction outcome loss': 0.8164982012202663, 'Total loss': 0.8164982012202663}
2022-11-18 03:34:50,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:50,805 INFO:     Epoch: 82
2022-11-18 03:34:51,566 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8056415935808962, 'Total loss': 0.8056415935808962} | train loss {'Reaction outcome loss': 0.812563732626938, 'Total loss': 0.812563732626938}
2022-11-18 03:34:51,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:51,567 INFO:     Epoch: 83
2022-11-18 03:34:52,347 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8022892759604887, 'Total loss': 0.8022892759604887} | train loss {'Reaction outcome loss': 0.8124528679876558, 'Total loss': 0.8124528679876558}
2022-11-18 03:34:52,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:52,347 INFO:     Epoch: 84
2022-11-18 03:34:53,155 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8080333410338922, 'Total loss': 0.8080333410338922} | train loss {'Reaction outcome loss': 0.814289704686211, 'Total loss': 0.814289704686211}
2022-11-18 03:34:53,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:53,156 INFO:     Epoch: 85
2022-11-18 03:34:53,949 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7991938895799897, 'Total loss': 0.7991938895799897} | train loss {'Reaction outcome loss': 0.8156413581342467, 'Total loss': 0.8156413581342467}
2022-11-18 03:34:53,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:53,949 INFO:     Epoch: 86
2022-11-18 03:34:54,743 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8337847299196504, 'Total loss': 0.8337847299196504} | train loss {'Reaction outcome loss': 0.8131341705879858, 'Total loss': 0.8131341705879858}
2022-11-18 03:34:54,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:54,743 INFO:     Epoch: 87
2022-11-18 03:34:55,519 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8154098960486326, 'Total loss': 0.8154098960486326} | train loss {'Reaction outcome loss': 0.8122650747818332, 'Total loss': 0.8122650747818332}
2022-11-18 03:34:55,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:55,521 INFO:     Epoch: 88
2022-11-18 03:34:56,322 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8013793101364916, 'Total loss': 0.8013793101364916} | train loss {'Reaction outcome loss': 0.8178444838812274, 'Total loss': 0.8178444838812274}
2022-11-18 03:34:56,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:56,322 INFO:     Epoch: 89
2022-11-18 03:34:57,108 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8191103271462701, 'Total loss': 0.8191103271462701} | train loss {'Reaction outcome loss': 0.8118217802576481, 'Total loss': 0.8118217802576481}
2022-11-18 03:34:57,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:57,109 INFO:     Epoch: 90
2022-11-18 03:34:57,908 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7977110120383176, 'Total loss': 0.7977110120383176} | train loss {'Reaction outcome loss': 0.8140580560411176, 'Total loss': 0.8140580560411176}
2022-11-18 03:34:57,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:57,909 INFO:     Epoch: 91
2022-11-18 03:34:58,700 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8416049046949907, 'Total loss': 0.8416049046949907} | train loss {'Reaction outcome loss': 0.8151925637597038, 'Total loss': 0.8151925637597038}
2022-11-18 03:34:58,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:58,700 INFO:     Epoch: 92
2022-11-18 03:34:59,506 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8331143199042841, 'Total loss': 0.8331143199042841} | train loss {'Reaction outcome loss': 0.814431459432648, 'Total loss': 0.814431459432648}
2022-11-18 03:34:59,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:34:59,507 INFO:     Epoch: 93
2022-11-18 03:35:00,304 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8200548738241196, 'Total loss': 0.8200548738241196} | train loss {'Reaction outcome loss': 0.8152345805879562, 'Total loss': 0.8152345805879562}
2022-11-18 03:35:00,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:00,305 INFO:     Epoch: 94
2022-11-18 03:35:01,075 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8131081570278514, 'Total loss': 0.8131081570278514} | train loss {'Reaction outcome loss': 0.8175189037236475, 'Total loss': 0.8175189037236475}
2022-11-18 03:35:01,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:01,077 INFO:     Epoch: 95
2022-11-18 03:35:01,882 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8120226893912662, 'Total loss': 0.8120226893912662} | train loss {'Reaction outcome loss': 0.8126626872727948, 'Total loss': 0.8126626872727948}
2022-11-18 03:35:01,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:01,882 INFO:     Epoch: 96
2022-11-18 03:35:02,673 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8031529093330557, 'Total loss': 0.8031529093330557} | train loss {'Reaction outcome loss': 0.8133916942582976, 'Total loss': 0.8133916942582976}
2022-11-18 03:35:02,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:02,674 INFO:     Epoch: 97
2022-11-18 03:35:03,477 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8241529024460099, 'Total loss': 0.8241529024460099} | train loss {'Reaction outcome loss': 0.8140827446214615, 'Total loss': 0.8140827446214615}
2022-11-18 03:35:03,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:03,477 INFO:     Epoch: 98
2022-11-18 03:35:04,277 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8158856454220685, 'Total loss': 0.8158856454220685} | train loss {'Reaction outcome loss': 0.8140059449980336, 'Total loss': 0.8140059449980336}
2022-11-18 03:35:04,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:04,277 INFO:     Epoch: 99
2022-11-18 03:35:05,057 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8092680092562329, 'Total loss': 0.8092680092562329} | train loss {'Reaction outcome loss': 0.8152213609747349, 'Total loss': 0.8152213609747349}
2022-11-18 03:35:05,057 INFO:     Best model found after epoch 63 of 100.
2022-11-18 03:35:05,057 INFO:   Done with stage: TRAINING
2022-11-18 03:35:05,057 INFO:   Starting stage: EVALUATION
2022-11-18 03:35:05,174 INFO:   Done with stage: EVALUATION
2022-11-18 03:35:05,183 INFO:   Leaving out SEQ value Fold_0
2022-11-18 03:35:05,196 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:35:05,196 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:35:05,871 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:35:05,872 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:35:05,941 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:35:05,941 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:35:05,941 INFO:     No hyperparam tuning for this model
2022-11-18 03:35:05,941 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:35:05,941 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:35:05,942 INFO:     None feature selector for col prot
2022-11-18 03:35:05,942 INFO:     None feature selector for col prot
2022-11-18 03:35:05,942 INFO:     None feature selector for col prot
2022-11-18 03:35:05,943 INFO:     None feature selector for col chem
2022-11-18 03:35:05,943 INFO:     None feature selector for col chem
2022-11-18 03:35:05,943 INFO:     None feature selector for col chem
2022-11-18 03:35:05,943 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:35:05,943 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:35:05,945 INFO:     Number of params in model 168571
2022-11-18 03:35:05,948 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:35:05,948 INFO:   Starting stage: TRAINING
2022-11-18 03:35:06,006 INFO:     Val loss before train {'Reaction outcome loss': 1.0116798010739414, 'Total loss': 1.0116798010739414}
2022-11-18 03:35:06,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:06,006 INFO:     Epoch: 0
2022-11-18 03:35:06,791 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9024751376021992, 'Total loss': 0.9024751376021992} | train loss {'Reaction outcome loss': 0.8966881924795236, 'Total loss': 0.8966881924795236}
2022-11-18 03:35:06,792 INFO:     Found new best model at epoch 0
2022-11-18 03:35:06,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:06,793 INFO:     Epoch: 1
2022-11-18 03:35:07,562 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8839903487400576, 'Total loss': 0.8839903487400576} | train loss {'Reaction outcome loss': 0.8648603243323473, 'Total loss': 0.8648603243323473}
2022-11-18 03:35:07,562 INFO:     Found new best model at epoch 1
2022-11-18 03:35:07,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:07,563 INFO:     Epoch: 2
2022-11-18 03:35:08,375 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8614673709327524, 'Total loss': 0.8614673709327524} | train loss {'Reaction outcome loss': 0.8580565342777654, 'Total loss': 0.8580565342777654}
2022-11-18 03:35:08,375 INFO:     Found new best model at epoch 2
2022-11-18 03:35:08,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:08,376 INFO:     Epoch: 3
2022-11-18 03:35:09,184 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8785859915343198, 'Total loss': 0.8785859915343198} | train loss {'Reaction outcome loss': 0.8625539029658083, 'Total loss': 0.8625539029658083}
2022-11-18 03:35:09,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:09,184 INFO:     Epoch: 4
2022-11-18 03:35:10,009 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8772414543411948, 'Total loss': 0.8772414543411948} | train loss {'Reaction outcome loss': 0.8590837946304908, 'Total loss': 0.8590837946304908}
2022-11-18 03:35:10,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:10,009 INFO:     Epoch: 5
2022-11-18 03:35:10,812 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8820490308783271, 'Total loss': 0.8820490308783271} | train loss {'Reaction outcome loss': 0.8525278719089292, 'Total loss': 0.8525278719089292}
2022-11-18 03:35:10,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:10,812 INFO:     Epoch: 6
2022-11-18 03:35:11,601 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8690538772127845, 'Total loss': 0.8690538772127845} | train loss {'Reaction outcome loss': 0.8506160906934546, 'Total loss': 0.8506160906934546}
2022-11-18 03:35:11,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:11,603 INFO:     Epoch: 7
2022-11-18 03:35:12,382 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8721570880575613, 'Total loss': 0.8721570880575613} | train loss {'Reaction outcome loss': 0.8482342118676375, 'Total loss': 0.8482342118676375}
2022-11-18 03:35:12,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:12,382 INFO:     Epoch: 8
2022-11-18 03:35:13,155 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8878170786933466, 'Total loss': 0.8878170786933466} | train loss {'Reaction outcome loss': 0.8442491422659955, 'Total loss': 0.8442491422659955}
2022-11-18 03:35:13,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:13,156 INFO:     Epoch: 9
2022-11-18 03:35:13,941 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8496759283271703, 'Total loss': 0.8496759283271703} | train loss {'Reaction outcome loss': 0.8455145076098229, 'Total loss': 0.8455145076098229}
2022-11-18 03:35:13,941 INFO:     Found new best model at epoch 9
2022-11-18 03:35:13,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:13,942 INFO:     Epoch: 10
2022-11-18 03:35:14,728 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8577495047991927, 'Total loss': 0.8577495047991927} | train loss {'Reaction outcome loss': 0.8362235271255014, 'Total loss': 0.8362235271255014}
2022-11-18 03:35:14,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:14,728 INFO:     Epoch: 11
2022-11-18 03:35:15,512 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8625774735754187, 'Total loss': 0.8625774735754187} | train loss {'Reaction outcome loss': 0.844276870431205, 'Total loss': 0.844276870431205}
2022-11-18 03:35:15,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:15,512 INFO:     Epoch: 12
2022-11-18 03:35:16,291 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8570708198980852, 'Total loss': 0.8570708198980852} | train loss {'Reaction outcome loss': 0.8450465871978868, 'Total loss': 0.8450465871978868}
2022-11-18 03:35:16,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:16,291 INFO:     Epoch: 13
2022-11-18 03:35:17,070 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8566741069609468, 'Total loss': 0.8566741069609468} | train loss {'Reaction outcome loss': 0.8421916038340885, 'Total loss': 0.8421916038340885}
2022-11-18 03:35:17,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:17,070 INFO:     Epoch: 14
2022-11-18 03:35:17,860 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.9098320914940401, 'Total loss': 0.9098320914940401} | train loss {'Reaction outcome loss': 0.8404422536311362, 'Total loss': 0.8404422536311362}
2022-11-18 03:35:17,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:17,862 INFO:     Epoch: 15
2022-11-18 03:35:18,630 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8607098947871815, 'Total loss': 0.8607098947871815} | train loss {'Reaction outcome loss': 0.8379047474397822, 'Total loss': 0.8379047474397822}
2022-11-18 03:35:18,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:18,630 INFO:     Epoch: 16
2022-11-18 03:35:19,411 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8646793081001802, 'Total loss': 0.8646793081001802} | train loss {'Reaction outcome loss': 0.8305545152440245, 'Total loss': 0.8305545152440245}
2022-11-18 03:35:19,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:19,411 INFO:     Epoch: 17
2022-11-18 03:35:20,207 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8584775362502445, 'Total loss': 0.8584775362502445} | train loss {'Reaction outcome loss': 0.8361821099814133, 'Total loss': 0.8361821099814133}
2022-11-18 03:35:20,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:20,207 INFO:     Epoch: 18
2022-11-18 03:35:21,000 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8569116172465411, 'Total loss': 0.8569116172465411} | train loss {'Reaction outcome loss': 0.8321105440859853, 'Total loss': 0.8321105440859853}
2022-11-18 03:35:21,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:21,001 INFO:     Epoch: 19
2022-11-18 03:35:21,784 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8501329252665694, 'Total loss': 0.8501329252665694} | train loss {'Reaction outcome loss': 0.8375667276894033, 'Total loss': 0.8375667276894033}
2022-11-18 03:35:21,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:21,785 INFO:     Epoch: 20
2022-11-18 03:35:22,572 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8555605587634173, 'Total loss': 0.8555605587634173} | train loss {'Reaction outcome loss': 0.8301896263471982, 'Total loss': 0.8301896263471982}
2022-11-18 03:35:22,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:22,572 INFO:     Epoch: 21
2022-11-18 03:35:23,355 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8601140901446342, 'Total loss': 0.8601140901446342} | train loss {'Reaction outcome loss': 0.8334224160142273, 'Total loss': 0.8334224160142273}
2022-11-18 03:35:23,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:23,357 INFO:     Epoch: 22
2022-11-18 03:35:24,133 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8473574322733012, 'Total loss': 0.8473574322733012} | train loss {'Reaction outcome loss': 0.8317778092707216, 'Total loss': 0.8317778092707216}
2022-11-18 03:35:24,133 INFO:     Found new best model at epoch 22
2022-11-18 03:35:24,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:24,134 INFO:     Epoch: 23
2022-11-18 03:35:24,926 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8763672492720864, 'Total loss': 0.8763672492720864} | train loss {'Reaction outcome loss': 0.8287758221510451, 'Total loss': 0.8287758221510451}
2022-11-18 03:35:24,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:24,926 INFO:     Epoch: 24
2022-11-18 03:35:25,691 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8475262305953286, 'Total loss': 0.8475262305953286} | train loss {'Reaction outcome loss': 0.8352836324618413, 'Total loss': 0.8352836324618413}
2022-11-18 03:35:25,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:25,691 INFO:     Epoch: 25
2022-11-18 03:35:26,477 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.86375554041429, 'Total loss': 0.86375554041429} | train loss {'Reaction outcome loss': 0.8284350412818584, 'Total loss': 0.8284350412818584}
2022-11-18 03:35:26,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:26,477 INFO:     Epoch: 26
2022-11-18 03:35:27,277 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8501644974405115, 'Total loss': 0.8501644974405115} | train loss {'Reaction outcome loss': 0.8291173988749624, 'Total loss': 0.8291173988749624}
2022-11-18 03:35:27,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:27,277 INFO:     Epoch: 27
2022-11-18 03:35:28,075 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8659307299689813, 'Total loss': 0.8659307299689813} | train loss {'Reaction outcome loss': 0.8327252060054284, 'Total loss': 0.8327252060054284}
2022-11-18 03:35:28,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:28,075 INFO:     Epoch: 28
2022-11-18 03:35:28,850 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8617678921331059, 'Total loss': 0.8617678921331059} | train loss {'Reaction outcome loss': 0.8336688620358826, 'Total loss': 0.8336688620358826}
2022-11-18 03:35:28,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:28,852 INFO:     Epoch: 29
2022-11-18 03:35:29,635 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8740063648332249, 'Total loss': 0.8740063648332249} | train loss {'Reaction outcome loss': 0.831120905243916, 'Total loss': 0.831120905243916}
2022-11-18 03:35:29,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:29,635 INFO:     Epoch: 30
2022-11-18 03:35:30,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8608220476995815, 'Total loss': 0.8608220476995815} | train loss {'Reaction outcome loss': 0.8345849086881166, 'Total loss': 0.8345849086881166}
2022-11-18 03:35:30,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:30,415 INFO:     Epoch: 31
2022-11-18 03:35:31,205 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8558348349549554, 'Total loss': 0.8558348349549554} | train loss {'Reaction outcome loss': 0.8375616470570506, 'Total loss': 0.8375616470570506}
2022-11-18 03:35:31,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:31,205 INFO:     Epoch: 32
2022-11-18 03:35:31,969 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8501347161152146, 'Total loss': 0.8501347161152146} | train loss {'Reaction outcome loss': 0.8388328777875013, 'Total loss': 0.8388328777875013}
2022-11-18 03:35:31,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:31,969 INFO:     Epoch: 33
2022-11-18 03:35:32,736 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.855556917461482, 'Total loss': 0.855556917461482} | train loss {'Reaction outcome loss': 0.8361430629062266, 'Total loss': 0.8361430629062266}
2022-11-18 03:35:32,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:32,736 INFO:     Epoch: 34
2022-11-18 03:35:33,498 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.861524646255103, 'Total loss': 0.861524646255103} | train loss {'Reaction outcome loss': 0.834095076752095, 'Total loss': 0.834095076752095}
2022-11-18 03:35:33,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:33,498 INFO:     Epoch: 35
2022-11-18 03:35:34,298 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8679829307577827, 'Total loss': 0.8679829307577827} | train loss {'Reaction outcome loss': 0.8282750330955876, 'Total loss': 0.8282750330955876}
2022-11-18 03:35:34,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:34,300 INFO:     Epoch: 36
2022-11-18 03:35:35,071 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8572398999875243, 'Total loss': 0.8572398999875243} | train loss {'Reaction outcome loss': 0.8282695179767454, 'Total loss': 0.8282695179767454}
2022-11-18 03:35:35,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:35,072 INFO:     Epoch: 37
2022-11-18 03:35:35,844 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8657574518160387, 'Total loss': 0.8657574518160387} | train loss {'Reaction outcome loss': 0.8354336048668696, 'Total loss': 0.8354336048668696}
2022-11-18 03:35:35,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:35,845 INFO:     Epoch: 38
2022-11-18 03:35:36,654 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.850516635585915, 'Total loss': 0.850516635585915} | train loss {'Reaction outcome loss': 0.8328979093777505, 'Total loss': 0.8328979093777505}
2022-11-18 03:35:36,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:36,655 INFO:     Epoch: 39
2022-11-18 03:35:37,441 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8628324879841371, 'Total loss': 0.8628324879841371} | train loss {'Reaction outcome loss': 0.8281882881876911, 'Total loss': 0.8281882881876911}
2022-11-18 03:35:37,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:37,441 INFO:     Epoch: 40
2022-11-18 03:35:38,242 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8820466006344015, 'Total loss': 0.8820466006344015} | train loss {'Reaction outcome loss': 0.8379280868812129, 'Total loss': 0.8379280868812129}
2022-11-18 03:35:38,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:38,243 INFO:     Epoch: 41
2022-11-18 03:35:39,061 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8549739305268634, 'Total loss': 0.8549739305268634} | train loss {'Reaction outcome loss': 0.8356697403708933, 'Total loss': 0.8356697403708933}
2022-11-18 03:35:39,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:39,061 INFO:     Epoch: 42
2022-11-18 03:35:39,837 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8553845259276304, 'Total loss': 0.8553845259276304} | train loss {'Reaction outcome loss': 0.8232872607978249, 'Total loss': 0.8232872607978249}
2022-11-18 03:35:39,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:39,838 INFO:     Epoch: 43
2022-11-18 03:35:40,647 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8492420891469176, 'Total loss': 0.8492420891469176} | train loss {'Reaction outcome loss': 0.8338056065534291, 'Total loss': 0.8338056065534291}
2022-11-18 03:35:40,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:40,647 INFO:     Epoch: 44
2022-11-18 03:35:41,445 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.85719053379514, 'Total loss': 0.85719053379514} | train loss {'Reaction outcome loss': 0.8322778748355897, 'Total loss': 0.8322778748355897}
2022-11-18 03:35:41,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:41,445 INFO:     Epoch: 45
2022-11-18 03:35:42,290 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8600887615572322, 'Total loss': 0.8600887615572322} | train loss {'Reaction outcome loss': 0.8324890524028283, 'Total loss': 0.8324890524028283}
2022-11-18 03:35:42,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:42,290 INFO:     Epoch: 46
2022-11-18 03:35:43,089 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8500395796515725, 'Total loss': 0.8500395796515725} | train loss {'Reaction outcome loss': 0.8279481344377464, 'Total loss': 0.8279481344377464}
2022-11-18 03:35:43,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:43,089 INFO:     Epoch: 47
2022-11-18 03:35:43,891 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.849915244362571, 'Total loss': 0.849915244362571} | train loss {'Reaction outcome loss': 0.8283932287442056, 'Total loss': 0.8283932287442056}
2022-11-18 03:35:43,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:43,892 INFO:     Epoch: 48
2022-11-18 03:35:44,681 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.859067442742261, 'Total loss': 0.859067442742261} | train loss {'Reaction outcome loss': 0.8230919549279367, 'Total loss': 0.8230919549279367}
2022-11-18 03:35:44,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:44,681 INFO:     Epoch: 49
2022-11-18 03:35:45,451 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8636311130090193, 'Total loss': 0.8636311130090193} | train loss {'Reaction outcome loss': 0.8265766949064819, 'Total loss': 0.8265766949064819}
2022-11-18 03:35:45,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:45,453 INFO:     Epoch: 50
2022-11-18 03:35:46,310 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8526621677658774, 'Total loss': 0.8526621677658774} | train loss {'Reaction outcome loss': 0.8259484565209764, 'Total loss': 0.8259484565209764}
2022-11-18 03:35:46,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:46,310 INFO:     Epoch: 51
2022-11-18 03:35:47,120 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8471544107252901, 'Total loss': 0.8471544107252901} | train loss {'Reaction outcome loss': 0.8286355007515263, 'Total loss': 0.8286355007515263}
2022-11-18 03:35:47,120 INFO:     Found new best model at epoch 51
2022-11-18 03:35:47,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:47,121 INFO:     Epoch: 52
2022-11-18 03:35:47,927 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8615272085775029, 'Total loss': 0.8615272085775029} | train loss {'Reaction outcome loss': 0.8253068892579329, 'Total loss': 0.8253068892579329}
2022-11-18 03:35:47,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:47,927 INFO:     Epoch: 53
2022-11-18 03:35:48,770 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.854689777574756, 'Total loss': 0.854689777574756} | train loss {'Reaction outcome loss': 0.8360728339145058, 'Total loss': 0.8360728339145058}
2022-11-18 03:35:48,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:48,770 INFO:     Epoch: 54
2022-11-18 03:35:49,569 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8614118112759157, 'Total loss': 0.8614118112759157} | train loss {'Reaction outcome loss': 0.8254393713194349, 'Total loss': 0.8254393713194349}
2022-11-18 03:35:49,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:49,569 INFO:     Epoch: 55
2022-11-18 03:35:50,382 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8584959344430403, 'Total loss': 0.8584959344430403} | train loss {'Reaction outcome loss': 0.8291321780781454, 'Total loss': 0.8291321780781454}
2022-11-18 03:35:50,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:50,382 INFO:     Epoch: 56
2022-11-18 03:35:51,176 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8364817527207461, 'Total loss': 0.8364817527207461} | train loss {'Reaction outcome loss': 0.8283586496042337, 'Total loss': 0.8283586496042337}
2022-11-18 03:35:51,177 INFO:     Found new best model at epoch 56
2022-11-18 03:35:51,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:51,178 INFO:     Epoch: 57
2022-11-18 03:35:51,970 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8561478744853627, 'Total loss': 0.8561478744853627} | train loss {'Reaction outcome loss': 0.8218925556069926, 'Total loss': 0.8218925556069926}
2022-11-18 03:35:51,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:51,970 INFO:     Epoch: 58
2022-11-18 03:35:52,814 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8536241386424411, 'Total loss': 0.8536241386424411} | train loss {'Reaction outcome loss': 0.8255223345901319, 'Total loss': 0.8255223345901319}
2022-11-18 03:35:52,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:52,815 INFO:     Epoch: 59
2022-11-18 03:35:53,644 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8665555620735342, 'Total loss': 0.8665555620735342} | train loss {'Reaction outcome loss': 0.8242282130216297, 'Total loss': 0.8242282130216297}
2022-11-18 03:35:53,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:53,645 INFO:     Epoch: 60
2022-11-18 03:35:54,456 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8511279089884325, 'Total loss': 0.8511279089884325} | train loss {'Reaction outcome loss': 0.8303069116374259, 'Total loss': 0.8303069116374259}
2022-11-18 03:35:54,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:54,456 INFO:     Epoch: 61
2022-11-18 03:35:55,278 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8509021997451782, 'Total loss': 0.8509021997451782} | train loss {'Reaction outcome loss': 0.8297476144394411, 'Total loss': 0.8297476144394411}
2022-11-18 03:35:55,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:55,278 INFO:     Epoch: 62
2022-11-18 03:35:56,065 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8744222548874941, 'Total loss': 0.8744222548874941} | train loss {'Reaction outcome loss': 0.828135029869041, 'Total loss': 0.828135029869041}
2022-11-18 03:35:56,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:56,066 INFO:     Epoch: 63
2022-11-18 03:35:56,841 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8607893586158752, 'Total loss': 0.8607893586158752} | train loss {'Reaction outcome loss': 0.8398564503139813, 'Total loss': 0.8398564503139813}
2022-11-18 03:35:56,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:56,842 INFO:     Epoch: 64
2022-11-18 03:35:57,657 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8674710562283342, 'Total loss': 0.8674710562283342} | train loss {'Reaction outcome loss': 0.830994437459992, 'Total loss': 0.830994437459992}
2022-11-18 03:35:57,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:57,658 INFO:     Epoch: 65
2022-11-18 03:35:58,484 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.854975241151723, 'Total loss': 0.854975241151723} | train loss {'Reaction outcome loss': 0.8380527148845225, 'Total loss': 0.8380527148845225}
2022-11-18 03:35:58,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:58,484 INFO:     Epoch: 66
2022-11-18 03:35:59,295 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8453011526302858, 'Total loss': 0.8453011526302858} | train loss {'Reaction outcome loss': 0.8355418121525151, 'Total loss': 0.8355418121525151}
2022-11-18 03:35:59,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:35:59,295 INFO:     Epoch: 67
2022-11-18 03:36:00,124 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8516897809776393, 'Total loss': 0.8516897809776393} | train loss {'Reaction outcome loss': 0.8271957357764727, 'Total loss': 0.8271957357764727}
2022-11-18 03:36:00,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:00,125 INFO:     Epoch: 68
2022-11-18 03:36:00,886 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8509904904799028, 'Total loss': 0.8509904904799028} | train loss {'Reaction outcome loss': 0.8334822815198165, 'Total loss': 0.8334822815198165}
2022-11-18 03:36:00,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:00,887 INFO:     Epoch: 69
2022-11-18 03:36:01,750 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8647675974802538, 'Total loss': 0.8647675974802538} | train loss {'Reaction outcome loss': 0.8305537033418895, 'Total loss': 0.8305537033418895}
2022-11-18 03:36:01,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:01,752 INFO:     Epoch: 70
2022-11-18 03:36:02,559 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8544229628010229, 'Total loss': 0.8544229628010229} | train loss {'Reaction outcome loss': 0.8342137308979807, 'Total loss': 0.8342137308979807}
2022-11-18 03:36:02,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:02,559 INFO:     Epoch: 71
2022-11-18 03:36:03,350 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8487742136825215, 'Total loss': 0.8487742136825215} | train loss {'Reaction outcome loss': 0.8359168438534987, 'Total loss': 0.8359168438534987}
2022-11-18 03:36:03,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:03,351 INFO:     Epoch: 72
2022-11-18 03:36:04,152 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8604798567566004, 'Total loss': 0.8604798567566004} | train loss {'Reaction outcome loss': 0.8293129934473076, 'Total loss': 0.8293129934473076}
2022-11-18 03:36:04,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:04,152 INFO:     Epoch: 73
2022-11-18 03:36:04,965 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8487383181398566, 'Total loss': 0.8487383181398566} | train loss {'Reaction outcome loss': 0.8238173386888948, 'Total loss': 0.8238173386888948}
2022-11-18 03:36:04,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:04,966 INFO:     Epoch: 74
2022-11-18 03:36:05,787 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8651929111643271, 'Total loss': 0.8651929111643271} | train loss {'Reaction outcome loss': 0.8318774869084841, 'Total loss': 0.8318774869084841}
2022-11-18 03:36:05,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:05,787 INFO:     Epoch: 75
2022-11-18 03:36:06,589 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.870517713779753, 'Total loss': 0.870517713779753} | train loss {'Reaction outcome loss': 0.8310350420986593, 'Total loss': 0.8310350420986593}
2022-11-18 03:36:06,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:06,589 INFO:     Epoch: 76
2022-11-18 03:36:07,414 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8506970276886766, 'Total loss': 0.8506970276886766} | train loss {'Reaction outcome loss': 0.8341461818227883, 'Total loss': 0.8341461818227883}
2022-11-18 03:36:07,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:07,415 INFO:     Epoch: 77
2022-11-18 03:36:08,209 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8665268475359137, 'Total loss': 0.8665268475359137} | train loss {'Reaction outcome loss': 0.8358635649024716, 'Total loss': 0.8358635649024716}
2022-11-18 03:36:08,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:08,210 INFO:     Epoch: 78
2022-11-18 03:36:09,024 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8445650366219607, 'Total loss': 0.8445650366219607} | train loss {'Reaction outcome loss': 0.8310354020190143, 'Total loss': 0.8310354020190143}
2022-11-18 03:36:09,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:09,025 INFO:     Epoch: 79
2022-11-18 03:36:09,811 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8630819273265925, 'Total loss': 0.8630819273265925} | train loss {'Reaction outcome loss': 0.8363815962303023, 'Total loss': 0.8363815962303023}
2022-11-18 03:36:09,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:09,811 INFO:     Epoch: 80
2022-11-18 03:36:10,612 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8593326183882627, 'Total loss': 0.8593326183882627} | train loss {'Reaction outcome loss': 0.8344557063299635, 'Total loss': 0.8344557063299635}
2022-11-18 03:36:10,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:10,612 INFO:     Epoch: 81
2022-11-18 03:36:11,391 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8515430810776624, 'Total loss': 0.8515430810776624} | train loss {'Reaction outcome loss': 0.8317809582721849, 'Total loss': 0.8317809582721849}
2022-11-18 03:36:11,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:11,391 INFO:     Epoch: 82
2022-11-18 03:36:12,171 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8583053011785854, 'Total loss': 0.8583053011785854} | train loss {'Reaction outcome loss': 0.8292972561318864, 'Total loss': 0.8292972561318864}
2022-11-18 03:36:12,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:12,171 INFO:     Epoch: 83
2022-11-18 03:36:12,972 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.870545320212841, 'Total loss': 0.870545320212841} | train loss {'Reaction outcome loss': 0.829430312159573, 'Total loss': 0.829430312159573}
2022-11-18 03:36:12,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:12,972 INFO:     Epoch: 84
2022-11-18 03:36:13,728 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8529633053324439, 'Total loss': 0.8529633053324439} | train loss {'Reaction outcome loss': 0.8341257602338367, 'Total loss': 0.8341257602338367}
2022-11-18 03:36:13,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:13,729 INFO:     Epoch: 85
2022-11-18 03:36:14,482 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8611460829322989, 'Total loss': 0.8611460829322989} | train loss {'Reaction outcome loss': 0.8364369942833055, 'Total loss': 0.8364369942833055}
2022-11-18 03:36:14,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:14,482 INFO:     Epoch: 86
2022-11-18 03:36:15,266 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.853009047833356, 'Total loss': 0.853009047833356} | train loss {'Reaction outcome loss': 0.828117204882838, 'Total loss': 0.828117204882838}
2022-11-18 03:36:15,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:15,266 INFO:     Epoch: 87
2022-11-18 03:36:16,049 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8392799483104185, 'Total loss': 0.8392799483104185} | train loss {'Reaction outcome loss': 0.8323090159699984, 'Total loss': 0.8323090159699984}
2022-11-18 03:36:16,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:16,049 INFO:     Epoch: 88
2022-11-18 03:36:16,850 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.868010625243187, 'Total loss': 0.868010625243187} | train loss {'Reaction outcome loss': 0.8274423164213717, 'Total loss': 0.8274423164213717}
2022-11-18 03:36:16,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:16,850 INFO:     Epoch: 89
2022-11-18 03:36:17,635 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8590931411493908, 'Total loss': 0.8590931411493908} | train loss {'Reaction outcome loss': 0.8304209559552582, 'Total loss': 0.8304209559552582}
2022-11-18 03:36:17,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:17,636 INFO:     Epoch: 90
2022-11-18 03:36:18,412 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8495393977923826, 'Total loss': 0.8495393977923826} | train loss {'Reaction outcome loss': 0.8304501952912643, 'Total loss': 0.8304501952912643}
2022-11-18 03:36:18,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:18,412 INFO:     Epoch: 91
2022-11-18 03:36:19,182 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8558431172912772, 'Total loss': 0.8558431172912772} | train loss {'Reaction outcome loss': 0.8293360703990527, 'Total loss': 0.8293360703990527}
2022-11-18 03:36:19,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:19,184 INFO:     Epoch: 92
2022-11-18 03:36:19,968 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8524429232559421, 'Total loss': 0.8524429232559421} | train loss {'Reaction outcome loss': 0.823418084577269, 'Total loss': 0.823418084577269}
2022-11-18 03:36:19,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:19,968 INFO:     Epoch: 93
2022-11-18 03:36:20,750 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8414239869876341, 'Total loss': 0.8414239869876341} | train loss {'Reaction outcome loss': 0.8367387010500982, 'Total loss': 0.8367387010500982}
2022-11-18 03:36:20,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:20,750 INFO:     Epoch: 94
2022-11-18 03:36:21,515 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8729506107893857, 'Total loss': 0.8729506107893857} | train loss {'Reaction outcome loss': 0.826974463486961, 'Total loss': 0.826974463486961}
2022-11-18 03:36:21,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:21,515 INFO:     Epoch: 95
2022-11-18 03:36:22,277 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8620213784954764, 'Total loss': 0.8620213784954764} | train loss {'Reaction outcome loss': 0.8308907270672833, 'Total loss': 0.8308907270672833}
2022-11-18 03:36:22,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:22,277 INFO:     Epoch: 96
2022-11-18 03:36:23,068 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8441879640926014, 'Total loss': 0.8441879640926014} | train loss {'Reaction outcome loss': 0.8287423829197401, 'Total loss': 0.8287423829197401}
2022-11-18 03:36:23,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:23,068 INFO:     Epoch: 97
2022-11-18 03:36:23,848 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8625880059870806, 'Total loss': 0.8625880059870806} | train loss {'Reaction outcome loss': 0.8323546310185421, 'Total loss': 0.8323546310185421}
2022-11-18 03:36:23,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:23,848 INFO:     Epoch: 98
2022-11-18 03:36:24,631 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.849211489612406, 'Total loss': 0.849211489612406} | train loss {'Reaction outcome loss': 0.8367489181790757, 'Total loss': 0.8367489181790757}
2022-11-18 03:36:24,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:24,633 INFO:     Epoch: 99
2022-11-18 03:36:25,414 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8575821776281704, 'Total loss': 0.8575821776281704} | train loss {'Reaction outcome loss': 0.835181924933002, 'Total loss': 0.835181924933002}
2022-11-18 03:36:25,415 INFO:     Best model found after epoch 57 of 100.
2022-11-18 03:36:25,415 INFO:   Done with stage: TRAINING
2022-11-18 03:36:25,415 INFO:   Starting stage: EVALUATION
2022-11-18 03:36:25,538 INFO:   Done with stage: EVALUATION
2022-11-18 03:36:25,538 INFO:   Leaving out SEQ value Fold_1
2022-11-18 03:36:25,551 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 03:36:25,551 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:36:26,221 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:36:26,221 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:36:26,290 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:36:26,290 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:36:26,290 INFO:     No hyperparam tuning for this model
2022-11-18 03:36:26,291 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:36:26,291 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:36:26,291 INFO:     None feature selector for col prot
2022-11-18 03:36:26,292 INFO:     None feature selector for col prot
2022-11-18 03:36:26,292 INFO:     None feature selector for col prot
2022-11-18 03:36:26,292 INFO:     None feature selector for col chem
2022-11-18 03:36:26,292 INFO:     None feature selector for col chem
2022-11-18 03:36:26,293 INFO:     None feature selector for col chem
2022-11-18 03:36:26,293 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:36:26,293 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:36:26,294 INFO:     Number of params in model 168571
2022-11-18 03:36:26,298 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:36:26,298 INFO:   Starting stage: TRAINING
2022-11-18 03:36:26,355 INFO:     Val loss before train {'Reaction outcome loss': 1.007564428177747, 'Total loss': 1.007564428177747}
2022-11-18 03:36:26,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:26,355 INFO:     Epoch: 0
2022-11-18 03:36:27,141 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8717044700275768, 'Total loss': 0.8717044700275768} | train loss {'Reaction outcome loss': 0.8733191457595902, 'Total loss': 0.8733191457595902}
2022-11-18 03:36:27,141 INFO:     Found new best model at epoch 0
2022-11-18 03:36:27,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:27,142 INFO:     Epoch: 1
2022-11-18 03:36:27,909 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8401694649999792, 'Total loss': 0.8401694649999792} | train loss {'Reaction outcome loss': 0.8483660367095036, 'Total loss': 0.8483660367095036}
2022-11-18 03:36:27,909 INFO:     Found new best model at epoch 1
2022-11-18 03:36:27,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:27,910 INFO:     Epoch: 2
2022-11-18 03:36:28,706 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8074061023918065, 'Total loss': 0.8074061023918065} | train loss {'Reaction outcome loss': 0.8389036216233906, 'Total loss': 0.8389036216233906}
2022-11-18 03:36:28,706 INFO:     Found new best model at epoch 2
2022-11-18 03:36:28,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:28,707 INFO:     Epoch: 3
2022-11-18 03:36:29,465 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.841999003155665, 'Total loss': 0.841999003155665} | train loss {'Reaction outcome loss': 0.8350129021324126, 'Total loss': 0.8350129021324126}
2022-11-18 03:36:29,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:29,465 INFO:     Epoch: 4
2022-11-18 03:36:30,236 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8214561248367483, 'Total loss': 0.8214561248367483} | train loss {'Reaction outcome loss': 0.8522757273695247, 'Total loss': 0.8522757273695247}
2022-11-18 03:36:30,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:30,238 INFO:     Epoch: 5
2022-11-18 03:36:31,024 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8321500528942455, 'Total loss': 0.8321500528942455} | train loss {'Reaction outcome loss': 0.8270219795571768, 'Total loss': 0.8270219795571768}
2022-11-18 03:36:31,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:31,025 INFO:     Epoch: 6
2022-11-18 03:36:31,798 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7998923693190921, 'Total loss': 0.7998923693190921} | train loss {'Reaction outcome loss': 0.8305115580317463, 'Total loss': 0.8305115580317463}
2022-11-18 03:36:31,798 INFO:     Found new best model at epoch 6
2022-11-18 03:36:31,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:31,799 INFO:     Epoch: 7
2022-11-18 03:36:32,586 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8081754561175, 'Total loss': 0.8081754561175} | train loss {'Reaction outcome loss': 0.8275174322096925, 'Total loss': 0.8275174322096925}
2022-11-18 03:36:32,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:32,586 INFO:     Epoch: 8
2022-11-18 03:36:33,371 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8094306215643883, 'Total loss': 0.8094306215643883} | train loss {'Reaction outcome loss': 0.827816276935491, 'Total loss': 0.827816276935491}
2022-11-18 03:36:33,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:33,371 INFO:     Epoch: 9
2022-11-18 03:36:34,162 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8159152892502871, 'Total loss': 0.8159152892502871} | train loss {'Reaction outcome loss': 0.8227006620482394, 'Total loss': 0.8227006620482394}
2022-11-18 03:36:34,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:34,163 INFO:     Epoch: 10
2022-11-18 03:36:34,957 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8276019252159379, 'Total loss': 0.8276019252159379} | train loss {'Reaction outcome loss': 0.8193501891636172, 'Total loss': 0.8193501891636172}
2022-11-18 03:36:34,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:34,957 INFO:     Epoch: 11
2022-11-18 03:36:35,707 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.797984239729968, 'Total loss': 0.797984239729968} | train loss {'Reaction outcome loss': 0.8301826008418312, 'Total loss': 0.8301826008418312}
2022-11-18 03:36:35,708 INFO:     Found new best model at epoch 11
2022-11-18 03:36:35,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:35,709 INFO:     Epoch: 12
2022-11-18 03:36:36,481 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8166810897263613, 'Total loss': 0.8166810897263613} | train loss {'Reaction outcome loss': 0.8203549321122497, 'Total loss': 0.8203549321122497}
2022-11-18 03:36:36,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:36,481 INFO:     Epoch: 13
2022-11-18 03:36:37,270 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7971925423903898, 'Total loss': 0.7971925423903898} | train loss {'Reaction outcome loss': 0.8161671145966178, 'Total loss': 0.8161671145966178}
2022-11-18 03:36:37,271 INFO:     Found new best model at epoch 13
2022-11-18 03:36:37,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:37,271 INFO:     Epoch: 14
2022-11-18 03:36:38,063 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8112676760012453, 'Total loss': 0.8112676760012453} | train loss {'Reaction outcome loss': 0.8185149104247692, 'Total loss': 0.8185149104247692}
2022-11-18 03:36:38,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:38,063 INFO:     Epoch: 15
2022-11-18 03:36:38,887 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8153719854625788, 'Total loss': 0.8153719854625788} | train loss {'Reaction outcome loss': 0.8194957242803536, 'Total loss': 0.8194957242803536}
2022-11-18 03:36:38,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:38,888 INFO:     Epoch: 16
2022-11-18 03:36:39,665 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8340754590251229, 'Total loss': 0.8340754590251229} | train loss {'Reaction outcome loss': 0.8195552327613599, 'Total loss': 0.8195552327613599}
2022-11-18 03:36:39,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:39,665 INFO:     Epoch: 17
2022-11-18 03:36:40,451 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8069630658084695, 'Total loss': 0.8069630658084695} | train loss {'Reaction outcome loss': 0.8182370690440359, 'Total loss': 0.8182370690440359}
2022-11-18 03:36:40,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:40,452 INFO:     Epoch: 18
2022-11-18 03:36:41,249 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8130541348999197, 'Total loss': 0.8130541348999197} | train loss {'Reaction outcome loss': 0.816025117872215, 'Total loss': 0.816025117872215}
2022-11-18 03:36:41,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:41,250 INFO:     Epoch: 19
2022-11-18 03:36:42,021 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7945658307183873, 'Total loss': 0.7945658307183873} | train loss {'Reaction outcome loss': 0.8240549197563758, 'Total loss': 0.8240549197563758}
2022-11-18 03:36:42,022 INFO:     Found new best model at epoch 19
2022-11-18 03:36:42,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:42,022 INFO:     Epoch: 20
2022-11-18 03:36:42,783 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8122457022016699, 'Total loss': 0.8122457022016699} | train loss {'Reaction outcome loss': 0.8129572631255818, 'Total loss': 0.8129572631255818}
2022-11-18 03:36:42,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:42,783 INFO:     Epoch: 21
2022-11-18 03:36:43,566 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8216627355326306, 'Total loss': 0.8216627355326306} | train loss {'Reaction outcome loss': 0.8133071655867553, 'Total loss': 0.8133071655867553}
2022-11-18 03:36:43,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:43,567 INFO:     Epoch: 22
2022-11-18 03:36:44,333 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8016542020169172, 'Total loss': 0.8016542020169172} | train loss {'Reaction outcome loss': 0.8118689150704064, 'Total loss': 0.8118689150704064}
2022-11-18 03:36:44,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:44,333 INFO:     Epoch: 23
2022-11-18 03:36:45,129 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8405186425555836, 'Total loss': 0.8405186425555836} | train loss {'Reaction outcome loss': 0.813697301665781, 'Total loss': 0.813697301665781}
2022-11-18 03:36:45,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:45,130 INFO:     Epoch: 24
2022-11-18 03:36:45,897 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8108379475095056, 'Total loss': 0.8108379475095056} | train loss {'Reaction outcome loss': 0.8186192008165213, 'Total loss': 0.8186192008165213}
2022-11-18 03:36:45,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:45,897 INFO:     Epoch: 25
2022-11-18 03:36:46,687 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.795211367986419, 'Total loss': 0.795211367986419} | train loss {'Reaction outcome loss': 0.8133016704970043, 'Total loss': 0.8133016704970043}
2022-11-18 03:36:46,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:46,689 INFO:     Epoch: 26
2022-11-18 03:36:47,454 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8061796304854479, 'Total loss': 0.8061796304854479} | train loss {'Reaction outcome loss': 0.8208447751487314, 'Total loss': 0.8208447751487314}
2022-11-18 03:36:47,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:47,454 INFO:     Epoch: 27
2022-11-18 03:36:48,242 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8222194862636653, 'Total loss': 0.8222194862636653} | train loss {'Reaction outcome loss': 0.8127450502594473, 'Total loss': 0.8127450502594473}
2022-11-18 03:36:48,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:48,242 INFO:     Epoch: 28
2022-11-18 03:36:49,016 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8027508177540519, 'Total loss': 0.8027508177540519} | train loss {'Reaction outcome loss': 0.8132564956963304, 'Total loss': 0.8132564956963304}
2022-11-18 03:36:49,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:49,016 INFO:     Epoch: 29
2022-11-18 03:36:49,808 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7945357791402123, 'Total loss': 0.7945357791402123} | train loss {'Reaction outcome loss': 0.8134265383969435, 'Total loss': 0.8134265383969435}
2022-11-18 03:36:49,808 INFO:     Found new best model at epoch 29
2022-11-18 03:36:49,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:49,809 INFO:     Epoch: 30
2022-11-18 03:36:50,585 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8148505586114797, 'Total loss': 0.8148505586114797} | train loss {'Reaction outcome loss': 0.8141666253809987, 'Total loss': 0.8141666253809987}
2022-11-18 03:36:50,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:50,586 INFO:     Epoch: 31
2022-11-18 03:36:51,361 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8135648274963553, 'Total loss': 0.8135648274963553} | train loss {'Reaction outcome loss': 0.8123585477260201, 'Total loss': 0.8123585477260201}
2022-11-18 03:36:51,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:51,361 INFO:     Epoch: 32
2022-11-18 03:36:52,153 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8018224401907488, 'Total loss': 0.8018224401907488} | train loss {'Reaction outcome loss': 0.8122508372613776, 'Total loss': 0.8122508372613776}
2022-11-18 03:36:52,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:52,155 INFO:     Epoch: 33
2022-11-18 03:36:52,946 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8236117159778421, 'Total loss': 0.8236117159778421} | train loss {'Reaction outcome loss': 0.8143915331315416, 'Total loss': 0.8143915331315416}
2022-11-18 03:36:52,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:52,946 INFO:     Epoch: 34
2022-11-18 03:36:53,727 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8042599274353548, 'Total loss': 0.8042599274353548} | train loss {'Reaction outcome loss': 0.8278818760323621, 'Total loss': 0.8278818760323621}
2022-11-18 03:36:53,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:53,727 INFO:     Epoch: 35
2022-11-18 03:36:54,513 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8392366008325056, 'Total loss': 0.8392366008325056} | train loss {'Reaction outcome loss': 0.8217809305258608, 'Total loss': 0.8217809305258608}
2022-11-18 03:36:54,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:54,513 INFO:     Epoch: 36
2022-11-18 03:36:55,331 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8189510188319467, 'Total loss': 0.8189510188319467} | train loss {'Reaction outcome loss': 0.8144883095976795, 'Total loss': 0.8144883095976795}
2022-11-18 03:36:55,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:55,332 INFO:     Epoch: 37
2022-11-18 03:36:56,134 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8087940026413311, 'Total loss': 0.8087940026413311} | train loss {'Reaction outcome loss': 0.8074981409468149, 'Total loss': 0.8074981409468149}
2022-11-18 03:36:56,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:56,135 INFO:     Epoch: 38
2022-11-18 03:36:56,917 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7992004054513845, 'Total loss': 0.7992004054513845} | train loss {'Reaction outcome loss': 0.8121626628072638, 'Total loss': 0.8121626628072638}
2022-11-18 03:36:56,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:56,918 INFO:     Epoch: 39
2022-11-18 03:36:57,686 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8383419628847729, 'Total loss': 0.8383419628847729} | train loss {'Reaction outcome loss': 0.8106813455520854, 'Total loss': 0.8106813455520854}
2022-11-18 03:36:57,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:57,687 INFO:     Epoch: 40
2022-11-18 03:36:58,471 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7907356362451207, 'Total loss': 0.7907356362451207} | train loss {'Reaction outcome loss': 0.8098520668381862, 'Total loss': 0.8098520668381862}
2022-11-18 03:36:58,471 INFO:     Found new best model at epoch 40
2022-11-18 03:36:58,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:58,472 INFO:     Epoch: 41
2022-11-18 03:36:59,248 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8097875531424176, 'Total loss': 0.8097875531424176} | train loss {'Reaction outcome loss': 0.8199993986108525, 'Total loss': 0.8199993986108525}
2022-11-18 03:36:59,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:36:59,248 INFO:     Epoch: 42
2022-11-18 03:37:00,041 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8052464899691668, 'Total loss': 0.8052464899691668} | train loss {'Reaction outcome loss': 0.8295673232088204, 'Total loss': 0.8295673232088204}
2022-11-18 03:37:00,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:00,042 INFO:     Epoch: 43
2022-11-18 03:37:00,780 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8061420165679671, 'Total loss': 0.8061420165679671} | train loss {'Reaction outcome loss': 0.8183028278080559, 'Total loss': 0.8183028278080559}
2022-11-18 03:37:00,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:00,780 INFO:     Epoch: 44
2022-11-18 03:37:01,578 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.788461790166118, 'Total loss': 0.788461790166118} | train loss {'Reaction outcome loss': 0.8129537822490158, 'Total loss': 0.8129537822490158}
2022-11-18 03:37:01,579 INFO:     Found new best model at epoch 44
2022-11-18 03:37:01,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:01,579 INFO:     Epoch: 45
2022-11-18 03:37:02,371 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8167141384699128, 'Total loss': 0.8167141384699128} | train loss {'Reaction outcome loss': 0.8094678486467373, 'Total loss': 0.8094678486467373}
2022-11-18 03:37:02,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:02,371 INFO:     Epoch: 46
2022-11-18 03:37:03,155 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8047928180206906, 'Total loss': 0.8047928180206906} | train loss {'Reaction outcome loss': 0.813561467204982, 'Total loss': 0.813561467204982}
2022-11-18 03:37:03,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:03,157 INFO:     Epoch: 47
2022-11-18 03:37:03,903 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7886702350594781, 'Total loss': 0.7886702350594781} | train loss {'Reaction outcome loss': 0.8139139030143799, 'Total loss': 0.8139139030143799}
2022-11-18 03:37:03,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:03,904 INFO:     Epoch: 48
2022-11-18 03:37:04,734 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8337237970395521, 'Total loss': 0.8337237970395521} | train loss {'Reaction outcome loss': 0.8069946483561867, 'Total loss': 0.8069946483561867}
2022-11-18 03:37:04,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:04,734 INFO:     Epoch: 49
2022-11-18 03:37:05,550 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.796216800131581, 'Total loss': 0.796216800131581} | train loss {'Reaction outcome loss': 0.8148667408145873, 'Total loss': 0.8148667408145873}
2022-11-18 03:37:05,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:05,550 INFO:     Epoch: 50
2022-11-18 03:37:06,350 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8061347461559556, 'Total loss': 0.8061347461559556} | train loss {'Reaction outcome loss': 0.8123360611649177, 'Total loss': 0.8123360611649177}
2022-11-18 03:37:06,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:06,350 INFO:     Epoch: 51
2022-11-18 03:37:07,192 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8188864182342183, 'Total loss': 0.8188864182342183} | train loss {'Reaction outcome loss': 0.8127185676985906, 'Total loss': 0.8127185676985906}
2022-11-18 03:37:07,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:07,192 INFO:     Epoch: 52
2022-11-18 03:37:08,002 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8035071776671843, 'Total loss': 0.8035071776671843} | train loss {'Reaction outcome loss': 0.814543325288093, 'Total loss': 0.814543325288093}
2022-11-18 03:37:08,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:08,002 INFO:     Epoch: 53
2022-11-18 03:37:08,791 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7998005233027718, 'Total loss': 0.7998005233027718} | train loss {'Reaction outcome loss': 0.8162556675522916, 'Total loss': 0.8162556675522916}
2022-11-18 03:37:08,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:08,793 INFO:     Epoch: 54
2022-11-18 03:37:09,635 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8098524578592994, 'Total loss': 0.8098524578592994} | train loss {'Reaction outcome loss': 0.8110231221446141, 'Total loss': 0.8110231221446141}
2022-11-18 03:37:09,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:09,635 INFO:     Epoch: 55
2022-11-18 03:37:10,426 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8074366416443478, 'Total loss': 0.8074366416443478} | train loss {'Reaction outcome loss': 0.8107369238065805, 'Total loss': 0.8107369238065805}
2022-11-18 03:37:10,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:10,426 INFO:     Epoch: 56
2022-11-18 03:37:11,226 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8157086568799886, 'Total loss': 0.8157086568799886} | train loss {'Reaction outcome loss': 0.8203734172741893, 'Total loss': 0.8203734172741893}
2022-11-18 03:37:11,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:11,227 INFO:     Epoch: 57
2022-11-18 03:37:12,049 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8064949404109608, 'Total loss': 0.8064949404109608} | train loss {'Reaction outcome loss': 0.8156662420463948, 'Total loss': 0.8156662420463948}
2022-11-18 03:37:12,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:12,049 INFO:     Epoch: 58
2022-11-18 03:37:12,829 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8050080978057601, 'Total loss': 0.8050080978057601} | train loss {'Reaction outcome loss': 0.8195419146223106, 'Total loss': 0.8195419146223106}
2022-11-18 03:37:12,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:12,829 INFO:     Epoch: 59
2022-11-18 03:37:13,644 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.834753579036756, 'Total loss': 0.834753579036756} | train loss {'Reaction outcome loss': 0.8091234985497678, 'Total loss': 0.8091234985497678}
2022-11-18 03:37:13,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:13,645 INFO:     Epoch: 60
2022-11-18 03:37:14,448 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.797267077321356, 'Total loss': 0.797267077321356} | train loss {'Reaction outcome loss': 0.8129080197724857, 'Total loss': 0.8129080197724857}
2022-11-18 03:37:14,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:14,448 INFO:     Epoch: 61
2022-11-18 03:37:15,272 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8121489137411118, 'Total loss': 0.8121489137411118} | train loss {'Reaction outcome loss': 0.8104132442821858, 'Total loss': 0.8104132442821858}
2022-11-18 03:37:15,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:15,272 INFO:     Epoch: 62
2022-11-18 03:37:16,093 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8007315356623043, 'Total loss': 0.8007315356623043} | train loss {'Reaction outcome loss': 0.8090181278313703, 'Total loss': 0.8090181278313703}
2022-11-18 03:37:16,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:16,093 INFO:     Epoch: 63
2022-11-18 03:37:16,930 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.794661901213906, 'Total loss': 0.794661901213906} | train loss {'Reaction outcome loss': 0.8169229752139041, 'Total loss': 0.8169229752139041}
2022-11-18 03:37:16,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:16,930 INFO:     Epoch: 64
2022-11-18 03:37:17,773 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8004362271590666, 'Total loss': 0.8004362271590666} | train loss {'Reaction outcome loss': 0.8115817563012544, 'Total loss': 0.8115817563012544}
2022-11-18 03:37:17,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:17,773 INFO:     Epoch: 65
2022-11-18 03:37:18,600 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.826829310845245, 'Total loss': 0.826829310845245} | train loss {'Reaction outcome loss': 0.8084476348238918, 'Total loss': 0.8084476348238918}
2022-11-18 03:37:18,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:18,601 INFO:     Epoch: 66
2022-11-18 03:37:19,424 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8061001097614114, 'Total loss': 0.8061001097614114} | train loss {'Reaction outcome loss': 0.8079600738369019, 'Total loss': 0.8079600738369019}
2022-11-18 03:37:19,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:19,426 INFO:     Epoch: 67
2022-11-18 03:37:20,227 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8057168532501567, 'Total loss': 0.8057168532501567} | train loss {'Reaction outcome loss': 0.8188427299381751, 'Total loss': 0.8188427299381751}
2022-11-18 03:37:20,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:20,228 INFO:     Epoch: 68
2022-11-18 03:37:21,053 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7897598255764354, 'Total loss': 0.7897598255764354} | train loss {'Reaction outcome loss': 0.8171895819636974, 'Total loss': 0.8171895819636974}
2022-11-18 03:37:21,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:21,053 INFO:     Epoch: 69
2022-11-18 03:37:21,916 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8064917935566469, 'Total loss': 0.8064917935566469} | train loss {'Reaction outcome loss': 0.8230943543466962, 'Total loss': 0.8230943543466962}
2022-11-18 03:37:21,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:21,916 INFO:     Epoch: 70
2022-11-18 03:37:22,724 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8146301697600972, 'Total loss': 0.8146301697600972} | train loss {'Reaction outcome loss': 0.8123480821186714, 'Total loss': 0.8123480821186714}
2022-11-18 03:37:22,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:22,724 INFO:     Epoch: 71
2022-11-18 03:37:23,561 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8261229334907099, 'Total loss': 0.8261229334907099} | train loss {'Reaction outcome loss': 0.8123323620572264, 'Total loss': 0.8123323620572264}
2022-11-18 03:37:23,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:23,561 INFO:     Epoch: 72
2022-11-18 03:37:24,378 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7981238697062839, 'Total loss': 0.7981238697062839} | train loss {'Reaction outcome loss': 0.8151651310172641, 'Total loss': 0.8151651310172641}
2022-11-18 03:37:24,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:24,379 INFO:     Epoch: 73
2022-11-18 03:37:25,196 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8044656257737767, 'Total loss': 0.8044656257737767} | train loss {'Reaction outcome loss': 0.8053787717226184, 'Total loss': 0.8053787717226184}
2022-11-18 03:37:25,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:25,197 INFO:     Epoch: 74
2022-11-18 03:37:25,976 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8248318352482535, 'Total loss': 0.8248318352482535} | train loss {'Reaction outcome loss': 0.8098104815734061, 'Total loss': 0.8098104815734061}
2022-11-18 03:37:25,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:25,977 INFO:     Epoch: 75
2022-11-18 03:37:26,784 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7948815497485074, 'Total loss': 0.7948815497485074} | train loss {'Reaction outcome loss': 0.8082148929839192, 'Total loss': 0.8082148929839192}
2022-11-18 03:37:26,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:26,784 INFO:     Epoch: 76
2022-11-18 03:37:27,609 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8002637827938254, 'Total loss': 0.8002637827938254} | train loss {'Reaction outcome loss': 0.823098698125677, 'Total loss': 0.823098698125677}
2022-11-18 03:37:27,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:27,610 INFO:     Epoch: 77
2022-11-18 03:37:28,425 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8012929233637723, 'Total loss': 0.8012929233637723} | train loss {'Reaction outcome loss': 0.810469161643673, 'Total loss': 0.810469161643673}
2022-11-18 03:37:28,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:28,425 INFO:     Epoch: 78
2022-11-18 03:37:29,230 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7855264795097437, 'Total loss': 0.7855264795097437} | train loss {'Reaction outcome loss': 0.8152725795502604, 'Total loss': 0.8152725795502604}
2022-11-18 03:37:29,230 INFO:     Found new best model at epoch 78
2022-11-18 03:37:29,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:29,231 INFO:     Epoch: 79
2022-11-18 03:37:30,009 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7932564799081195, 'Total loss': 0.7932564799081195} | train loss {'Reaction outcome loss': 0.8069196871900366, 'Total loss': 0.8069196871900366}
2022-11-18 03:37:30,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:30,010 INFO:     Epoch: 80
2022-11-18 03:37:30,783 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.806747746061195, 'Total loss': 0.806747746061195} | train loss {'Reaction outcome loss': 0.8082670346656551, 'Total loss': 0.8082670346656551}
2022-11-18 03:37:30,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:30,784 INFO:     Epoch: 81
2022-11-18 03:37:31,597 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8300553187727928, 'Total loss': 0.8300553187727928} | train loss {'Reaction outcome loss': 0.8049660053270066, 'Total loss': 0.8049660053270066}
2022-11-18 03:37:31,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:31,598 INFO:     Epoch: 82
2022-11-18 03:37:32,393 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8107402595606717, 'Total loss': 0.8107402595606717} | train loss {'Reaction outcome loss': 0.8129929697465318, 'Total loss': 0.8129929697465318}
2022-11-18 03:37:32,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:32,394 INFO:     Epoch: 83
2022-11-18 03:37:33,165 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8054321983998473, 'Total loss': 0.8054321983998473} | train loss {'Reaction outcome loss': 0.8227756349181357, 'Total loss': 0.8227756349181357}
2022-11-18 03:37:33,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:33,166 INFO:     Epoch: 84
2022-11-18 03:37:33,976 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7932677445086566, 'Total loss': 0.7932677445086566} | train loss {'Reaction outcome loss': 0.8223598406382417, 'Total loss': 0.8223598406382417}
2022-11-18 03:37:33,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:33,976 INFO:     Epoch: 85
2022-11-18 03:37:34,729 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8021870634772561, 'Total loss': 0.8021870634772561} | train loss {'Reaction outcome loss': 0.8118086534473095, 'Total loss': 0.8118086534473095}
2022-11-18 03:37:34,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:34,729 INFO:     Epoch: 86
2022-11-18 03:37:35,541 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7959612797607075, 'Total loss': 0.7959612797607075} | train loss {'Reaction outcome loss': 0.8107742393306392, 'Total loss': 0.8107742393306392}
2022-11-18 03:37:35,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:35,541 INFO:     Epoch: 87
2022-11-18 03:37:36,376 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7993179315870459, 'Total loss': 0.7993179315870459} | train loss {'Reaction outcome loss': 0.8143000200933773, 'Total loss': 0.8143000200933773}
2022-11-18 03:37:36,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:36,376 INFO:     Epoch: 88
2022-11-18 03:37:37,180 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7883744212714109, 'Total loss': 0.7883744212714109} | train loss {'Reaction outcome loss': 0.8134412300972803, 'Total loss': 0.8134412300972803}
2022-11-18 03:37:37,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:37,181 INFO:     Epoch: 89
2022-11-18 03:37:38,009 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7962795001539317, 'Total loss': 0.7962795001539317} | train loss {'Reaction outcome loss': 0.8145294406636041, 'Total loss': 0.8145294406636041}
2022-11-18 03:37:38,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:38,009 INFO:     Epoch: 90
2022-11-18 03:37:38,841 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8015909479423002, 'Total loss': 0.8015909479423002} | train loss {'Reaction outcome loss': 0.8109055032976243, 'Total loss': 0.8109055032976243}
2022-11-18 03:37:38,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:38,842 INFO:     Epoch: 91
2022-11-18 03:37:39,655 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8129395889964971, 'Total loss': 0.8129395889964971} | train loss {'Reaction outcome loss': 0.814016695929925, 'Total loss': 0.814016695929925}
2022-11-18 03:37:39,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:39,655 INFO:     Epoch: 92
2022-11-18 03:37:40,491 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7983273498036645, 'Total loss': 0.7983273498036645} | train loss {'Reaction outcome loss': 0.8114500728695981, 'Total loss': 0.8114500728695981}
2022-11-18 03:37:40,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:40,491 INFO:     Epoch: 93
2022-11-18 03:37:41,325 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8329049782319502, 'Total loss': 0.8329049782319502} | train loss {'Reaction outcome loss': 0.8100744407427939, 'Total loss': 0.8100744407427939}
2022-11-18 03:37:41,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:41,326 INFO:     Epoch: 94
2022-11-18 03:37:42,116 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8172137256373059, 'Total loss': 0.8172137256373059} | train loss {'Reaction outcome loss': 0.8082609414179557, 'Total loss': 0.8082609414179557}
2022-11-18 03:37:42,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:42,118 INFO:     Epoch: 95
2022-11-18 03:37:42,909 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.803315284577283, 'Total loss': 0.803315284577283} | train loss {'Reaction outcome loss': 0.8108767309652166, 'Total loss': 0.8108767309652166}
2022-11-18 03:37:42,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:42,910 INFO:     Epoch: 96
2022-11-18 03:37:43,727 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8028495535254478, 'Total loss': 0.8028495535254478} | train loss {'Reaction outcome loss': 0.8160694406824074, 'Total loss': 0.8160694406824074}
2022-11-18 03:37:43,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:43,727 INFO:     Epoch: 97
2022-11-18 03:37:44,548 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7986641803925688, 'Total loss': 0.7986641803925688} | train loss {'Reaction outcome loss': 0.8132842064869066, 'Total loss': 0.8132842064869066}
2022-11-18 03:37:44,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:44,548 INFO:     Epoch: 98
2022-11-18 03:37:45,328 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8015231469815428, 'Total loss': 0.8015231469815428} | train loss {'Reaction outcome loss': 0.8134313077337829, 'Total loss': 0.8134313077337829}
2022-11-18 03:37:45,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:45,328 INFO:     Epoch: 99
2022-11-18 03:37:46,126 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7934999811378393, 'Total loss': 0.7934999811378393} | train loss {'Reaction outcome loss': 0.8079586114719329, 'Total loss': 0.8079586114719329}
2022-11-18 03:37:46,126 INFO:     Best model found after epoch 79 of 100.
2022-11-18 03:37:46,126 INFO:   Done with stage: TRAINING
2022-11-18 03:37:46,126 INFO:   Starting stage: EVALUATION
2022-11-18 03:37:46,250 INFO:   Done with stage: EVALUATION
2022-11-18 03:37:46,250 INFO:   Leaving out SEQ value Fold_2
2022-11-18 03:37:46,263 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 03:37:46,264 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:37:46,926 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:37:46,926 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:37:46,995 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:37:46,995 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:37:46,995 INFO:     No hyperparam tuning for this model
2022-11-18 03:37:46,995 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:37:46,995 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:37:46,996 INFO:     None feature selector for col prot
2022-11-18 03:37:46,996 INFO:     None feature selector for col prot
2022-11-18 03:37:46,996 INFO:     None feature selector for col prot
2022-11-18 03:37:46,997 INFO:     None feature selector for col chem
2022-11-18 03:37:46,997 INFO:     None feature selector for col chem
2022-11-18 03:37:46,997 INFO:     None feature selector for col chem
2022-11-18 03:37:46,997 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:37:46,997 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:37:46,999 INFO:     Number of params in model 168571
2022-11-18 03:37:47,002 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:37:47,002 INFO:   Starting stage: TRAINING
2022-11-18 03:37:47,059 INFO:     Val loss before train {'Reaction outcome loss': 1.01311051984166, 'Total loss': 1.01311051984166}
2022-11-18 03:37:47,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:47,059 INFO:     Epoch: 0
2022-11-18 03:37:47,827 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8291785384333411, 'Total loss': 0.8291785384333411} | train loss {'Reaction outcome loss': 0.8786221302340551, 'Total loss': 0.8786221302340551}
2022-11-18 03:37:47,828 INFO:     Found new best model at epoch 0
2022-11-18 03:37:47,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:47,829 INFO:     Epoch: 1
2022-11-18 03:37:48,643 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.863152027130127, 'Total loss': 0.863152027130127} | train loss {'Reaction outcome loss': 0.8529977458739968, 'Total loss': 0.8529977458739968}
2022-11-18 03:37:48,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:48,643 INFO:     Epoch: 2
2022-11-18 03:37:49,413 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8124658409939256, 'Total loss': 0.8124658409939256} | train loss {'Reaction outcome loss': 0.8392457054475698, 'Total loss': 0.8392457054475698}
2022-11-18 03:37:49,413 INFO:     Found new best model at epoch 2
2022-11-18 03:37:49,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:49,414 INFO:     Epoch: 3
2022-11-18 03:37:50,232 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8280136051566102, 'Total loss': 0.8280136051566102} | train loss {'Reaction outcome loss': 0.8354163827228939, 'Total loss': 0.8354163827228939}
2022-11-18 03:37:50,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:50,232 INFO:     Epoch: 4
2022-11-18 03:37:51,022 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8283737315688022, 'Total loss': 0.8283737315688022} | train loss {'Reaction outcome loss': 0.8334220921306453, 'Total loss': 0.8334220921306453}
2022-11-18 03:37:51,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:51,023 INFO:     Epoch: 5
2022-11-18 03:37:51,797 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8234425353449445, 'Total loss': 0.8234425353449445} | train loss {'Reaction outcome loss': 0.8256804657325824, 'Total loss': 0.8256804657325824}
2022-11-18 03:37:51,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:51,797 INFO:     Epoch: 6
2022-11-18 03:37:52,622 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.800664411034695, 'Total loss': 0.800664411034695} | train loss {'Reaction outcome loss': 0.8264400637689441, 'Total loss': 0.8264400637689441}
2022-11-18 03:37:52,622 INFO:     Found new best model at epoch 6
2022-11-18 03:37:52,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:52,623 INFO:     Epoch: 7
2022-11-18 03:37:53,391 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8222189268400503, 'Total loss': 0.8222189268400503} | train loss {'Reaction outcome loss': 0.8232263516742016, 'Total loss': 0.8232263516742016}
2022-11-18 03:37:53,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:53,392 INFO:     Epoch: 8
2022-11-18 03:37:54,172 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8003568191860997, 'Total loss': 0.8003568191860997} | train loss {'Reaction outcome loss': 0.8222616583476832, 'Total loss': 0.8222616583476832}
2022-11-18 03:37:54,173 INFO:     Found new best model at epoch 8
2022-11-18 03:37:54,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:54,174 INFO:     Epoch: 9
2022-11-18 03:37:54,935 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.804467965004056, 'Total loss': 0.804467965004056} | train loss {'Reaction outcome loss': 0.8253846185688128, 'Total loss': 0.8253846185688128}
2022-11-18 03:37:54,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:54,935 INFO:     Epoch: 10
2022-11-18 03:37:55,738 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8341153132361036, 'Total loss': 0.8341153132361036} | train loss {'Reaction outcome loss': 0.8176299442724927, 'Total loss': 0.8176299442724927}
2022-11-18 03:37:55,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:55,738 INFO:     Epoch: 11
2022-11-18 03:37:56,588 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8101714378179505, 'Total loss': 0.8101714378179505} | train loss {'Reaction outcome loss': 0.8184891276889377, 'Total loss': 0.8184891276889377}
2022-11-18 03:37:56,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:56,588 INFO:     Epoch: 12
2022-11-18 03:37:57,369 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8012302032736844, 'Total loss': 0.8012302032736844} | train loss {'Reaction outcome loss': 0.8142737662841263, 'Total loss': 0.8142737662841263}
2022-11-18 03:37:57,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:57,369 INFO:     Epoch: 13
2022-11-18 03:37:58,171 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8226897259091221, 'Total loss': 0.8226897259091221} | train loss {'Reaction outcome loss': 0.8115466395278036, 'Total loss': 0.8115466395278036}
2022-11-18 03:37:58,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:58,172 INFO:     Epoch: 14
2022-11-18 03:37:58,952 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8006504538447358, 'Total loss': 0.8006504538447358} | train loss {'Reaction outcome loss': 0.8204479982823502, 'Total loss': 0.8204479982823502}
2022-11-18 03:37:58,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:58,952 INFO:     Epoch: 15
2022-11-18 03:37:59,761 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8012662453706875, 'Total loss': 0.8012662453706875} | train loss {'Reaction outcome loss': 0.8128376281801074, 'Total loss': 0.8128376281801074}
2022-11-18 03:37:59,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:37:59,762 INFO:     Epoch: 16
2022-11-18 03:38:00,577 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8313354309215102, 'Total loss': 0.8313354309215102} | train loss {'Reaction outcome loss': 0.8148842105649626, 'Total loss': 0.8148842105649626}
2022-11-18 03:38:00,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:00,577 INFO:     Epoch: 17
2022-11-18 03:38:01,381 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.839385449886322, 'Total loss': 0.839385449886322} | train loss {'Reaction outcome loss': 0.8139097704073038, 'Total loss': 0.8139097704073038}
2022-11-18 03:38:01,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:01,381 INFO:     Epoch: 18
2022-11-18 03:38:02,160 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8225037621897321, 'Total loss': 0.8225037621897321} | train loss {'Reaction outcome loss': 0.8129491716500663, 'Total loss': 0.8129491716500663}
2022-11-18 03:38:02,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:02,160 INFO:     Epoch: 19
2022-11-18 03:38:02,932 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.803110426248506, 'Total loss': 0.803110426248506} | train loss {'Reaction outcome loss': 0.8185932807961609, 'Total loss': 0.8185932807961609}
2022-11-18 03:38:02,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:02,932 INFO:     Epoch: 20
2022-11-18 03:38:03,737 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7975488062514815, 'Total loss': 0.7975488062514815} | train loss {'Reaction outcome loss': 0.8168149052088153, 'Total loss': 0.8168149052088153}
2022-11-18 03:38:03,737 INFO:     Found new best model at epoch 20
2022-11-18 03:38:03,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:03,738 INFO:     Epoch: 21
2022-11-18 03:38:04,510 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.788444668747658, 'Total loss': 0.788444668747658} | train loss {'Reaction outcome loss': 0.8107268533098354, 'Total loss': 0.8107268533098354}
2022-11-18 03:38:04,510 INFO:     Found new best model at epoch 21
2022-11-18 03:38:04,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:04,511 INFO:     Epoch: 22
2022-11-18 03:38:05,326 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8006447512050008, 'Total loss': 0.8006447512050008} | train loss {'Reaction outcome loss': 0.816359847661399, 'Total loss': 0.816359847661399}
2022-11-18 03:38:05,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:05,328 INFO:     Epoch: 23
2022-11-18 03:38:06,138 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7861693875734196, 'Total loss': 0.7861693875734196} | train loss {'Reaction outcome loss': 0.8103452961385986, 'Total loss': 0.8103452961385986}
2022-11-18 03:38:06,138 INFO:     Found new best model at epoch 23
2022-11-18 03:38:06,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:06,139 INFO:     Epoch: 24
2022-11-18 03:38:06,959 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.824153121820716, 'Total loss': 0.824153121820716} | train loss {'Reaction outcome loss': 0.8115239142145149, 'Total loss': 0.8115239142145149}
2022-11-18 03:38:06,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:06,960 INFO:     Epoch: 25
2022-11-18 03:38:07,736 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8049143913180329, 'Total loss': 0.8049143913180329} | train loss {'Reaction outcome loss': 0.813060584750195, 'Total loss': 0.813060584750195}
2022-11-18 03:38:07,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:07,737 INFO:     Epoch: 26
2022-11-18 03:38:08,507 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7916061961373617, 'Total loss': 0.7916061961373617} | train loss {'Reaction outcome loss': 0.816608896348702, 'Total loss': 0.816608896348702}
2022-11-18 03:38:08,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:08,507 INFO:     Epoch: 27
2022-11-18 03:38:09,268 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8127870670584745, 'Total loss': 0.8127870670584745} | train loss {'Reaction outcome loss': 0.8166562409557924, 'Total loss': 0.8166562409557924}
2022-11-18 03:38:09,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:09,268 INFO:     Epoch: 28
2022-11-18 03:38:10,100 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7839652674142704, 'Total loss': 0.7839652674142704} | train loss {'Reaction outcome loss': 0.8098063403932155, 'Total loss': 0.8098063403932155}
2022-11-18 03:38:10,100 INFO:     Found new best model at epoch 28
2022-11-18 03:38:10,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:10,101 INFO:     Epoch: 29
2022-11-18 03:38:10,910 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8047361519447592, 'Total loss': 0.8047361519447592} | train loss {'Reaction outcome loss': 0.8120439913537767, 'Total loss': 0.8120439913537767}
2022-11-18 03:38:10,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:10,912 INFO:     Epoch: 30
2022-11-18 03:38:11,739 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8065778897252194, 'Total loss': 0.8065778897252194} | train loss {'Reaction outcome loss': 0.8132463114742389, 'Total loss': 0.8132463114742389}
2022-11-18 03:38:11,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:11,739 INFO:     Epoch: 31
2022-11-18 03:38:12,531 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7989428528519564, 'Total loss': 0.7989428528519564} | train loss {'Reaction outcome loss': 0.8124379801406781, 'Total loss': 0.8124379801406781}
2022-11-18 03:38:12,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:12,531 INFO:     Epoch: 32
2022-11-18 03:38:13,282 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7980507307274397, 'Total loss': 0.7980507307274397} | train loss {'Reaction outcome loss': 0.8081085578281693, 'Total loss': 0.8081085578281693}
2022-11-18 03:38:13,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:13,282 INFO:     Epoch: 33
2022-11-18 03:38:14,080 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7940192714680073, 'Total loss': 0.7940192714680073} | train loss {'Reaction outcome loss': 0.8131590086982083, 'Total loss': 0.8131590086982083}
2022-11-18 03:38:14,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:14,080 INFO:     Epoch: 34
2022-11-18 03:38:14,899 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8512052089668983, 'Total loss': 0.8512052089668983} | train loss {'Reaction outcome loss': 0.8118542009665642, 'Total loss': 0.8118542009665642}
2022-11-18 03:38:14,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:14,899 INFO:     Epoch: 35
2022-11-18 03:38:15,646 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7986995619396831, 'Total loss': 0.7986995619396831} | train loss {'Reaction outcome loss': 0.8104431629180908, 'Total loss': 0.8104431629180908}
2022-11-18 03:38:15,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:15,646 INFO:     Epoch: 36
2022-11-18 03:38:16,430 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.813347858051921, 'Total loss': 0.813347858051921} | train loss {'Reaction outcome loss': 0.8119043515297611, 'Total loss': 0.8119043515297611}
2022-11-18 03:38:16,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:16,431 INFO:     Epoch: 37
2022-11-18 03:38:17,268 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8015425323053847, 'Total loss': 0.8015425323053847} | train loss {'Reaction outcome loss': 0.8104548050788204, 'Total loss': 0.8104548050788204}
2022-11-18 03:38:17,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:17,268 INFO:     Epoch: 38
2022-11-18 03:38:18,065 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8178626520689144, 'Total loss': 0.8178626520689144} | train loss {'Reaction outcome loss': 0.8086953114089652, 'Total loss': 0.8086953114089652}
2022-11-18 03:38:18,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:18,065 INFO:     Epoch: 39
2022-11-18 03:38:18,904 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7952730600223985, 'Total loss': 0.7952730600223985} | train loss {'Reaction outcome loss': 0.8193401101930642, 'Total loss': 0.8193401101930642}
2022-11-18 03:38:18,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:18,905 INFO:     Epoch: 40
2022-11-18 03:38:19,744 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.795711150003034, 'Total loss': 0.795711150003034} | train loss {'Reaction outcome loss': 0.8100991478427447, 'Total loss': 0.8100991478427447}
2022-11-18 03:38:19,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:19,744 INFO:     Epoch: 41
2022-11-18 03:38:20,563 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7840802627940511, 'Total loss': 0.7840802627940511} | train loss {'Reaction outcome loss': 0.8096977352114861, 'Total loss': 0.8096977352114861}
2022-11-18 03:38:20,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:20,564 INFO:     Epoch: 42
2022-11-18 03:38:21,342 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8220543889112251, 'Total loss': 0.8220543889112251} | train loss {'Reaction outcome loss': 0.8055799667236736, 'Total loss': 0.8055799667236736}
2022-11-18 03:38:21,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:21,343 INFO:     Epoch: 43
2022-11-18 03:38:22,121 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7877648639124494, 'Total loss': 0.7877648639124494} | train loss {'Reaction outcome loss': 0.8081156095114265, 'Total loss': 0.8081156095114265}
2022-11-18 03:38:22,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:22,123 INFO:     Epoch: 44
2022-11-18 03:38:22,943 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.783187443433806, 'Total loss': 0.783187443433806} | train loss {'Reaction outcome loss': 0.8043082563720122, 'Total loss': 0.8043082563720122}
2022-11-18 03:38:22,943 INFO:     Found new best model at epoch 44
2022-11-18 03:38:22,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:22,943 INFO:     Epoch: 45
2022-11-18 03:38:23,722 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7948994691981826, 'Total loss': 0.7948994691981826} | train loss {'Reaction outcome loss': 0.8139744243994662, 'Total loss': 0.8139744243994662}
2022-11-18 03:38:23,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:23,722 INFO:     Epoch: 46
2022-11-18 03:38:24,486 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8140365190284197, 'Total loss': 0.8140365190284197} | train loss {'Reaction outcome loss': 0.8067138430512981, 'Total loss': 0.8067138430512981}
2022-11-18 03:38:24,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:24,486 INFO:     Epoch: 47
2022-11-18 03:38:25,290 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8090503188066704, 'Total loss': 0.8090503188066704} | train loss {'Reaction outcome loss': 0.8139935545469998, 'Total loss': 0.8139935545469998}
2022-11-18 03:38:25,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:25,291 INFO:     Epoch: 48
2022-11-18 03:38:26,124 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7948758567488471, 'Total loss': 0.7948758567488471} | train loss {'Reaction outcome loss': 0.8152270436654856, 'Total loss': 0.8152270436654856}
2022-11-18 03:38:26,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:26,124 INFO:     Epoch: 49
2022-11-18 03:38:26,997 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8147429220898207, 'Total loss': 0.8147429220898207} | train loss {'Reaction outcome loss': 0.8109581021615017, 'Total loss': 0.8109581021615017}
2022-11-18 03:38:26,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:26,997 INFO:     Epoch: 50
2022-11-18 03:38:27,814 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.787493036236874, 'Total loss': 0.787493036236874} | train loss {'Reaction outcome loss': 0.8176081445482042, 'Total loss': 0.8176081445482042}
2022-11-18 03:38:27,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:27,815 INFO:     Epoch: 51
2022-11-18 03:38:28,596 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7913621553154879, 'Total loss': 0.7913621553154879} | train loss {'Reaction outcome loss': 0.8111103529056894, 'Total loss': 0.8111103529056894}
2022-11-18 03:38:28,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:28,596 INFO:     Epoch: 52
2022-11-18 03:38:29,394 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7902049519294916, 'Total loss': 0.7902049519294916} | train loss {'Reaction outcome loss': 0.8064184201107104, 'Total loss': 0.8064184201107104}
2022-11-18 03:38:29,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:29,395 INFO:     Epoch: 53
2022-11-18 03:38:30,165 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8022593460803809, 'Total loss': 0.8022593460803809} | train loss {'Reaction outcome loss': 0.8150901034045122, 'Total loss': 0.8150901034045122}
2022-11-18 03:38:30,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:30,166 INFO:     Epoch: 54
2022-11-18 03:38:30,963 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7958432013212249, 'Total loss': 0.7958432013212249} | train loss {'Reaction outcome loss': 0.8131707118126591, 'Total loss': 0.8131707118126591}
2022-11-18 03:38:30,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:30,964 INFO:     Epoch: 55
2022-11-18 03:38:31,768 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8172625026037527, 'Total loss': 0.8172625026037527} | train loss {'Reaction outcome loss': 0.8062670131524404, 'Total loss': 0.8062670131524404}
2022-11-18 03:38:31,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:31,768 INFO:     Epoch: 56
2022-11-18 03:38:32,562 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8200068744116051, 'Total loss': 0.8200068744116051} | train loss {'Reaction outcome loss': 0.8091736093715385, 'Total loss': 0.8091736093715385}
2022-11-18 03:38:32,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:32,562 INFO:     Epoch: 57
2022-11-18 03:38:33,396 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7938625133314798, 'Total loss': 0.7938625133314798} | train loss {'Reaction outcome loss': 0.8116704751679926, 'Total loss': 0.8116704751679926}
2022-11-18 03:38:33,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:33,397 INFO:     Epoch: 58
2022-11-18 03:38:34,191 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8390015294385511, 'Total loss': 0.8390015294385511} | train loss {'Reaction outcome loss': 0.8088055254255303, 'Total loss': 0.8088055254255303}
2022-11-18 03:38:34,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:34,191 INFO:     Epoch: 59
2022-11-18 03:38:34,978 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7891792973806692, 'Total loss': 0.7891792973806692} | train loss {'Reaction outcome loss': 0.8138058815963964, 'Total loss': 0.8138058815963964}
2022-11-18 03:38:34,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:34,978 INFO:     Epoch: 60
2022-11-18 03:38:35,778 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8106410891510719, 'Total loss': 0.8106410891510719} | train loss {'Reaction outcome loss': 0.8081679200684583, 'Total loss': 0.8081679200684583}
2022-11-18 03:38:35,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:35,778 INFO:     Epoch: 61
2022-11-18 03:38:36,587 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7918200811674428, 'Total loss': 0.7918200811674428} | train loss {'Reaction outcome loss': 0.8089530535440876, 'Total loss': 0.8089530535440876}
2022-11-18 03:38:36,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:36,587 INFO:     Epoch: 62
2022-11-18 03:38:37,415 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8079008473906406, 'Total loss': 0.8079008473906406} | train loss {'Reaction outcome loss': 0.8139492451163476, 'Total loss': 0.8139492451163476}
2022-11-18 03:38:37,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:37,415 INFO:     Epoch: 63
2022-11-18 03:38:38,224 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7908204572145329, 'Total loss': 0.7908204572145329} | train loss {'Reaction outcome loss': 0.8076820816277477, 'Total loss': 0.8076820816277477}
2022-11-18 03:38:38,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:38,225 INFO:     Epoch: 64
2022-11-18 03:38:38,994 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8072811836420104, 'Total loss': 0.8072811836420104} | train loss {'Reaction outcome loss': 0.8136182312121607, 'Total loss': 0.8136182312121607}
2022-11-18 03:38:38,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:38,995 INFO:     Epoch: 65
2022-11-18 03:38:39,778 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7917822391487831, 'Total loss': 0.7917822391487831} | train loss {'Reaction outcome loss': 0.8124716400854872, 'Total loss': 0.8124716400854872}
2022-11-18 03:38:39,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:39,779 INFO:     Epoch: 66
2022-11-18 03:38:40,540 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8033271404199822, 'Total loss': 0.8033271404199822} | train loss {'Reaction outcome loss': 0.8141489369879044, 'Total loss': 0.8141489369879044}
2022-11-18 03:38:40,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:40,541 INFO:     Epoch: 67
2022-11-18 03:38:41,347 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7910493591497111, 'Total loss': 0.7910493591497111} | train loss {'Reaction outcome loss': 0.811600789121149, 'Total loss': 0.811600789121149}
2022-11-18 03:38:41,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:41,347 INFO:     Epoch: 68
2022-11-18 03:38:42,149 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.790212411520093, 'Total loss': 0.790212411520093} | train loss {'Reaction outcome loss': 0.8096442362408579, 'Total loss': 0.8096442362408579}
2022-11-18 03:38:42,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:42,149 INFO:     Epoch: 69
2022-11-18 03:38:42,931 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8116869344267734, 'Total loss': 0.8116869344267734} | train loss {'Reaction outcome loss': 0.8117358163305761, 'Total loss': 0.8117358163305761}
2022-11-18 03:38:42,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:42,931 INFO:     Epoch: 70
2022-11-18 03:38:43,721 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7906973479792129, 'Total loss': 0.7906973479792129} | train loss {'Reaction outcome loss': 0.8129635437280552, 'Total loss': 0.8129635437280552}
2022-11-18 03:38:43,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:43,721 INFO:     Epoch: 71
2022-11-18 03:38:44,529 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8131547064282173, 'Total loss': 0.8131547064282173} | train loss {'Reaction outcome loss': 0.8117299186594692, 'Total loss': 0.8117299186594692}
2022-11-18 03:38:44,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:44,530 INFO:     Epoch: 72
2022-11-18 03:38:45,269 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8201122166112412, 'Total loss': 0.8201122166112412} | train loss {'Reaction outcome loss': 0.8075522692115219, 'Total loss': 0.8075522692115219}
2022-11-18 03:38:45,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:45,270 INFO:     Epoch: 73
2022-11-18 03:38:46,040 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8063160375107167, 'Total loss': 0.8063160375107167} | train loss {'Reaction outcome loss': 0.8103741045596669, 'Total loss': 0.8103741045596669}
2022-11-18 03:38:46,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:46,040 INFO:     Epoch: 74
2022-11-18 03:38:46,814 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8089994815892951, 'Total loss': 0.8089994815892951} | train loss {'Reaction outcome loss': 0.8037354354995759, 'Total loss': 0.8037354354995759}
2022-11-18 03:38:46,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:46,815 INFO:     Epoch: 75
2022-11-18 03:38:47,633 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8200445535571076, 'Total loss': 0.8200445535571076} | train loss {'Reaction outcome loss': 0.8073496285044117, 'Total loss': 0.8073496285044117}
2022-11-18 03:38:47,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:47,633 INFO:     Epoch: 76
2022-11-18 03:38:48,460 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7963803098645321, 'Total loss': 0.7963803098645321} | train loss {'Reaction outcome loss': 0.8054031880549443, 'Total loss': 0.8054031880549443}
2022-11-18 03:38:48,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:48,460 INFO:     Epoch: 77
2022-11-18 03:38:49,283 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8061659495497859, 'Total loss': 0.8061659495497859} | train loss {'Reaction outcome loss': 0.808329876435637, 'Total loss': 0.808329876435637}
2022-11-18 03:38:49,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:49,283 INFO:     Epoch: 78
2022-11-18 03:38:50,088 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7895191949467326, 'Total loss': 0.7895191949467326} | train loss {'Reaction outcome loss': 0.8122641888174991, 'Total loss': 0.8122641888174991}
2022-11-18 03:38:50,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:50,088 INFO:     Epoch: 79
2022-11-18 03:38:50,876 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7993434695310371, 'Total loss': 0.7993434695310371} | train loss {'Reaction outcome loss': 0.8105538325545228, 'Total loss': 0.8105538325545228}
2022-11-18 03:38:50,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:50,876 INFO:     Epoch: 80
2022-11-18 03:38:51,649 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.795998616274013, 'Total loss': 0.795998616274013} | train loss {'Reaction outcome loss': 0.8094024694996116, 'Total loss': 0.8094024694996116}
2022-11-18 03:38:51,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:51,650 INFO:     Epoch: 81
2022-11-18 03:38:52,440 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7920805957428244, 'Total loss': 0.7920805957428244} | train loss {'Reaction outcome loss': 0.8076010345186225, 'Total loss': 0.8076010345186225}
2022-11-18 03:38:52,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:52,440 INFO:     Epoch: 82
2022-11-18 03:38:53,229 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7875438020672909, 'Total loss': 0.7875438020672909} | train loss {'Reaction outcome loss': 0.8064722521805469, 'Total loss': 0.8064722521805469}
2022-11-18 03:38:53,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:53,230 INFO:     Epoch: 83
2022-11-18 03:38:54,024 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.832422291816667, 'Total loss': 0.832422291816667} | train loss {'Reaction outcome loss': 0.8096696532066957, 'Total loss': 0.8096696532066957}
2022-11-18 03:38:54,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:54,024 INFO:     Epoch: 84
2022-11-18 03:38:54,785 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7908344310383464, 'Total loss': 0.7908344310383464} | train loss {'Reaction outcome loss': 0.8129727003996264, 'Total loss': 0.8129727003996264}
2022-11-18 03:38:54,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:54,785 INFO:     Epoch: 85
2022-11-18 03:38:55,561 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8023908138275146, 'Total loss': 0.8023908138275146} | train loss {'Reaction outcome loss': 0.8050230342910123, 'Total loss': 0.8050230342910123}
2022-11-18 03:38:55,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:55,561 INFO:     Epoch: 86
2022-11-18 03:38:56,371 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7920530743377153, 'Total loss': 0.7920530743377153} | train loss {'Reaction outcome loss': 0.8018724312507567, 'Total loss': 0.8018724312507567}
2022-11-18 03:38:56,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:56,371 INFO:     Epoch: 87
2022-11-18 03:38:57,167 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8075619755789291, 'Total loss': 0.8075619755789291} | train loss {'Reaction outcome loss': 0.810289719835721, 'Total loss': 0.810289719835721}
2022-11-18 03:38:57,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:57,167 INFO:     Epoch: 88
2022-11-18 03:38:57,992 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8076925735140956, 'Total loss': 0.8076925735140956} | train loss {'Reaction outcome loss': 0.807557623204871, 'Total loss': 0.807557623204871}
2022-11-18 03:38:57,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:57,993 INFO:     Epoch: 89
2022-11-18 03:38:58,777 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.78688070663186, 'Total loss': 0.78688070663186} | train loss {'Reaction outcome loss': 0.8130237587685447, 'Total loss': 0.8130237587685447}
2022-11-18 03:38:58,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:58,777 INFO:     Epoch: 90
2022-11-18 03:38:59,541 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8209421703981798, 'Total loss': 0.8209421703981798} | train loss {'Reaction outcome loss': 0.8050618702124176, 'Total loss': 0.8050618702124176}
2022-11-18 03:38:59,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:38:59,542 INFO:     Epoch: 91
2022-11-18 03:39:00,351 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7964699302994928, 'Total loss': 0.7964699302994928} | train loss {'Reaction outcome loss': 0.8079127577045326, 'Total loss': 0.8079127577045326}
2022-11-18 03:39:00,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:00,352 INFO:     Epoch: 92
2022-11-18 03:39:01,172 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7929614525894786, 'Total loss': 0.7929614525894786} | train loss {'Reaction outcome loss': 0.8078035087987719, 'Total loss': 0.8078035087987719}
2022-11-18 03:39:01,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:01,173 INFO:     Epoch: 93
2022-11-18 03:39:01,963 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.79257676629133, 'Total loss': 0.79257676629133} | train loss {'Reaction outcome loss': 0.8082008648801733, 'Total loss': 0.8082008648801733}
2022-11-18 03:39:01,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:01,963 INFO:     Epoch: 94
2022-11-18 03:39:02,816 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7966703328975412, 'Total loss': 0.7966703328975412} | train loss {'Reaction outcome loss': 0.8084611123726692, 'Total loss': 0.8084611123726692}
2022-11-18 03:39:02,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:02,817 INFO:     Epoch: 95
2022-11-18 03:39:03,726 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7962849957998409, 'Total loss': 0.7962849957998409} | train loss {'Reaction outcome loss': 0.8090899611206211, 'Total loss': 0.8090899611206211}
2022-11-18 03:39:03,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:03,727 INFO:     Epoch: 96
2022-11-18 03:39:04,492 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8088861246441685, 'Total loss': 0.8088861246441685} | train loss {'Reaction outcome loss': 0.8018577983104643, 'Total loss': 0.8018577983104643}
2022-11-18 03:39:04,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:04,493 INFO:     Epoch: 97
2022-11-18 03:39:05,260 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8032191534375035, 'Total loss': 0.8032191534375035} | train loss {'Reaction outcome loss': 0.806173321764165, 'Total loss': 0.806173321764165}
2022-11-18 03:39:05,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:05,260 INFO:     Epoch: 98
2022-11-18 03:39:06,027 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8030549412549928, 'Total loss': 0.8030549412549928} | train loss {'Reaction outcome loss': 0.8072296558829491, 'Total loss': 0.8072296558829491}
2022-11-18 03:39:06,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:06,027 INFO:     Epoch: 99
2022-11-18 03:39:06,805 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.789418567058652, 'Total loss': 0.789418567058652} | train loss {'Reaction outcome loss': 0.806506597210841, 'Total loss': 0.806506597210841}
2022-11-18 03:39:06,806 INFO:     Best model found after epoch 45 of 100.
2022-11-18 03:39:06,806 INFO:   Done with stage: TRAINING
2022-11-18 03:39:06,806 INFO:   Starting stage: EVALUATION
2022-11-18 03:39:06,946 INFO:   Done with stage: EVALUATION
2022-11-18 03:39:06,946 INFO:   Leaving out SEQ value Fold_3
2022-11-18 03:39:06,959 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 03:39:06,959 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:39:07,617 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:39:07,617 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:39:07,685 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:39:07,685 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:39:07,685 INFO:     No hyperparam tuning for this model
2022-11-18 03:39:07,685 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:39:07,685 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:39:07,686 INFO:     None feature selector for col prot
2022-11-18 03:39:07,686 INFO:     None feature selector for col prot
2022-11-18 03:39:07,686 INFO:     None feature selector for col prot
2022-11-18 03:39:07,687 INFO:     None feature selector for col chem
2022-11-18 03:39:07,687 INFO:     None feature selector for col chem
2022-11-18 03:39:07,687 INFO:     None feature selector for col chem
2022-11-18 03:39:07,687 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:39:07,687 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:39:07,689 INFO:     Number of params in model 168571
2022-11-18 03:39:07,692 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:39:07,692 INFO:   Starting stage: TRAINING
2022-11-18 03:39:07,748 INFO:     Val loss before train {'Reaction outcome loss': 1.0544664845910183, 'Total loss': 1.0544664845910183}
2022-11-18 03:39:07,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:07,749 INFO:     Epoch: 0
2022-11-18 03:39:08,519 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9152386133060899, 'Total loss': 0.9152386133060899} | train loss {'Reaction outcome loss': 0.8656093397258241, 'Total loss': 0.8656093397258241}
2022-11-18 03:39:08,519 INFO:     Found new best model at epoch 0
2022-11-18 03:39:08,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:08,520 INFO:     Epoch: 1
2022-11-18 03:39:09,287 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8800572808398757, 'Total loss': 0.8800572808398757} | train loss {'Reaction outcome loss': 0.8309653476187231, 'Total loss': 0.8309653476187231}
2022-11-18 03:39:09,288 INFO:     Found new best model at epoch 1
2022-11-18 03:39:09,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:09,288 INFO:     Epoch: 2
2022-11-18 03:39:10,047 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8810623302016147, 'Total loss': 0.8810623302016147} | train loss {'Reaction outcome loss': 0.8295419783994494, 'Total loss': 0.8295419783994494}
2022-11-18 03:39:10,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:10,048 INFO:     Epoch: 3
2022-11-18 03:39:10,852 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8793546321780182, 'Total loss': 0.8793546321780182} | train loss {'Reaction outcome loss': 0.8196185887350467, 'Total loss': 0.8196185887350467}
2022-11-18 03:39:10,852 INFO:     Found new best model at epoch 3
2022-11-18 03:39:10,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:10,853 INFO:     Epoch: 4
2022-11-18 03:39:11,612 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8561634989671929, 'Total loss': 0.8561634989671929} | train loss {'Reaction outcome loss': 0.8187140689955817, 'Total loss': 0.8187140689955817}
2022-11-18 03:39:11,612 INFO:     Found new best model at epoch 4
2022-11-18 03:39:11,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:11,613 INFO:     Epoch: 5
2022-11-18 03:39:12,366 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.844912494337836, 'Total loss': 0.844912494337836} | train loss {'Reaction outcome loss': 0.8135859030509682, 'Total loss': 0.8135859030509682}
2022-11-18 03:39:12,366 INFO:     Found new best model at epoch 5
2022-11-18 03:39:12,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:12,367 INFO:     Epoch: 6
2022-11-18 03:39:13,164 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8551932635695435, 'Total loss': 0.8551932635695435} | train loss {'Reaction outcome loss': 0.8095308025923286, 'Total loss': 0.8095308025923286}
2022-11-18 03:39:13,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:13,164 INFO:     Epoch: 7
2022-11-18 03:39:13,944 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8557839774808218, 'Total loss': 0.8557839774808218} | train loss {'Reaction outcome loss': 0.8117547291541787, 'Total loss': 0.8117547291541787}
2022-11-18 03:39:13,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:13,944 INFO:     Epoch: 8
2022-11-18 03:39:14,726 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8578170420125474, 'Total loss': 0.8578170420125474} | train loss {'Reaction outcome loss': 0.8119956743079448, 'Total loss': 0.8119956743079448}
2022-11-18 03:39:14,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:14,726 INFO:     Epoch: 9
2022-11-18 03:39:15,487 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8428181569243587, 'Total loss': 0.8428181569243587} | train loss {'Reaction outcome loss': 0.8108517048044951, 'Total loss': 0.8108517048044951}
2022-11-18 03:39:15,487 INFO:     Found new best model at epoch 9
2022-11-18 03:39:15,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:15,488 INFO:     Epoch: 10
2022-11-18 03:39:16,244 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8483530359212742, 'Total loss': 0.8483530359212742} | train loss {'Reaction outcome loss': 0.8021627023141571, 'Total loss': 0.8021627023141571}
2022-11-18 03:39:16,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:16,245 INFO:     Epoch: 11
2022-11-18 03:39:16,990 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8403830964897954, 'Total loss': 0.8403830964897954} | train loss {'Reaction outcome loss': 0.8096579459223727, 'Total loss': 0.8096579459223727}
2022-11-18 03:39:16,990 INFO:     Found new best model at epoch 11
2022-11-18 03:39:16,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:16,991 INFO:     Epoch: 12
2022-11-18 03:39:17,760 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8746102570101272, 'Total loss': 0.8746102570101272} | train loss {'Reaction outcome loss': 0.809054844050741, 'Total loss': 0.809054844050741}
2022-11-18 03:39:17,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:17,760 INFO:     Epoch: 13
2022-11-18 03:39:18,529 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8436032485130222, 'Total loss': 0.8436032485130222} | train loss {'Reaction outcome loss': 0.8054725814748693, 'Total loss': 0.8054725814748693}
2022-11-18 03:39:18,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:18,530 INFO:     Epoch: 14
2022-11-18 03:39:19,313 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.834918724243031, 'Total loss': 0.834918724243031} | train loss {'Reaction outcome loss': 0.8051896974628354, 'Total loss': 0.8051896974628354}
2022-11-18 03:39:19,313 INFO:     Found new best model at epoch 14
2022-11-18 03:39:19,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:19,314 INFO:     Epoch: 15
2022-11-18 03:39:20,090 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8604502345240393, 'Total loss': 0.8604502345240393} | train loss {'Reaction outcome loss': 0.803673534972187, 'Total loss': 0.803673534972187}
2022-11-18 03:39:20,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:20,090 INFO:     Epoch: 16
2022-11-18 03:39:20,871 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8448508035304935, 'Total loss': 0.8448508035304935} | train loss {'Reaction outcome loss': 0.8040986178833761, 'Total loss': 0.8040986178833761}
2022-11-18 03:39:20,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:20,871 INFO:     Epoch: 17
2022-11-18 03:39:21,640 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8512231388757395, 'Total loss': 0.8512231388757395} | train loss {'Reaction outcome loss': 0.8029438902321175, 'Total loss': 0.8029438902321175}
2022-11-18 03:39:21,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:21,641 INFO:     Epoch: 18
2022-11-18 03:39:22,393 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8504350781440735, 'Total loss': 0.8504350781440735} | train loss {'Reaction outcome loss': 0.8047084271171947, 'Total loss': 0.8047084271171947}
2022-11-18 03:39:22,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:22,393 INFO:     Epoch: 19
2022-11-18 03:39:23,145 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8402870921201484, 'Total loss': 0.8402870921201484} | train loss {'Reaction outcome loss': 0.8009509387820837, 'Total loss': 0.8009509387820837}
2022-11-18 03:39:23,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:23,145 INFO:     Epoch: 20
2022-11-18 03:39:23,910 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8428992393404938, 'Total loss': 0.8428992393404938} | train loss {'Reaction outcome loss': 0.8014250131546224, 'Total loss': 0.8014250131546224}
2022-11-18 03:39:23,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:23,910 INFO:     Epoch: 21
2022-11-18 03:39:24,689 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8470581915489462, 'Total loss': 0.8470581915489462} | train loss {'Reaction outcome loss': 0.801047091866717, 'Total loss': 0.801047091866717}
2022-11-18 03:39:24,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:24,690 INFO:     Epoch: 22
2022-11-18 03:39:25,460 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8532733958820964, 'Total loss': 0.8532733958820964} | train loss {'Reaction outcome loss': 0.8061459225146368, 'Total loss': 0.8061459225146368}
2022-11-18 03:39:25,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:25,460 INFO:     Epoch: 23
2022-11-18 03:39:26,232 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8330745114836582, 'Total loss': 0.8330745114836582} | train loss {'Reaction outcome loss': 0.8037790170422306, 'Total loss': 0.8037790170422306}
2022-11-18 03:39:26,232 INFO:     Found new best model at epoch 23
2022-11-18 03:39:26,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:26,233 INFO:     Epoch: 24
2022-11-18 03:39:27,010 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8860088032345439, 'Total loss': 0.8860088032345439} | train loss {'Reaction outcome loss': 0.794971411978757, 'Total loss': 0.794971411978757}
2022-11-18 03:39:27,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:27,010 INFO:     Epoch: 25
2022-11-18 03:39:27,764 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.847624005273331, 'Total loss': 0.847624005273331} | train loss {'Reaction outcome loss': 0.8008568510106562, 'Total loss': 0.8008568510106562}
2022-11-18 03:39:27,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:27,764 INFO:     Epoch: 26
2022-11-18 03:39:28,568 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.829740911029106, 'Total loss': 0.829740911029106} | train loss {'Reaction outcome loss': 0.7985140995233638, 'Total loss': 0.7985140995233638}
2022-11-18 03:39:28,569 INFO:     Found new best model at epoch 26
2022-11-18 03:39:28,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:28,570 INFO:     Epoch: 27
2022-11-18 03:39:29,332 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8440162040466486, 'Total loss': 0.8440162040466486} | train loss {'Reaction outcome loss': 0.7997965523244913, 'Total loss': 0.7997965523244913}
2022-11-18 03:39:29,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:29,332 INFO:     Epoch: 28
2022-11-18 03:39:30,116 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8473857689735501, 'Total loss': 0.8473857689735501} | train loss {'Reaction outcome loss': 0.799175546370416, 'Total loss': 0.799175546370416}
2022-11-18 03:39:30,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:30,116 INFO:     Epoch: 29
2022-11-18 03:39:30,871 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8356305714263472, 'Total loss': 0.8356305714263472} | train loss {'Reaction outcome loss': 0.7962469124990236, 'Total loss': 0.7962469124990236}
2022-11-18 03:39:30,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:30,872 INFO:     Epoch: 30
2022-11-18 03:39:31,647 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8277576669704082, 'Total loss': 0.8277576669704082} | train loss {'Reaction outcome loss': 0.8023970174936601, 'Total loss': 0.8023970174936601}
2022-11-18 03:39:31,647 INFO:     Found new best model at epoch 30
2022-11-18 03:39:31,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:31,648 INFO:     Epoch: 31
2022-11-18 03:39:32,400 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.834396107252254, 'Total loss': 0.834396107252254} | train loss {'Reaction outcome loss': 0.795227348436544, 'Total loss': 0.795227348436544}
2022-11-18 03:39:32,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:32,400 INFO:     Epoch: 32
2022-11-18 03:39:33,185 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8391521878020708, 'Total loss': 0.8391521878020708} | train loss {'Reaction outcome loss': 0.7994507395436243, 'Total loss': 0.7994507395436243}
2022-11-18 03:39:33,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:33,186 INFO:     Epoch: 33
2022-11-18 03:39:33,985 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8367571830749512, 'Total loss': 0.8367571830749512} | train loss {'Reaction outcome loss': 0.7980140127517559, 'Total loss': 0.7980140127517559}
2022-11-18 03:39:33,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:33,986 INFO:     Epoch: 34
2022-11-18 03:39:34,757 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8313116091628407, 'Total loss': 0.8313116091628407} | train loss {'Reaction outcome loss': 0.7983141069304306, 'Total loss': 0.7983141069304306}
2022-11-18 03:39:34,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:34,758 INFO:     Epoch: 35
2022-11-18 03:39:35,520 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8425671382005825, 'Total loss': 0.8425671382005825} | train loss {'Reaction outcome loss': 0.7949331015225791, 'Total loss': 0.7949331015225791}
2022-11-18 03:39:35,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:35,521 INFO:     Epoch: 36
2022-11-18 03:39:36,309 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8350009162758671, 'Total loss': 0.8350009162758671} | train loss {'Reaction outcome loss': 0.7982442192579984, 'Total loss': 0.7982442192579984}
2022-11-18 03:39:36,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:36,309 INFO:     Epoch: 37
2022-11-18 03:39:37,088 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8403616755507713, 'Total loss': 0.8403616755507713} | train loss {'Reaction outcome loss': 0.7975384650652301, 'Total loss': 0.7975384650652301}
2022-11-18 03:39:37,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:37,088 INFO:     Epoch: 38
2022-11-18 03:39:37,851 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8512847603753556, 'Total loss': 0.8512847603753556} | train loss {'Reaction outcome loss': 0.795088164109752, 'Total loss': 0.795088164109752}
2022-11-18 03:39:37,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:37,852 INFO:     Epoch: 39
2022-11-18 03:39:38,624 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.839700389740079, 'Total loss': 0.839700389740079} | train loss {'Reaction outcome loss': 0.799628083597976, 'Total loss': 0.799628083597976}
2022-11-18 03:39:38,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:38,624 INFO:     Epoch: 40
2022-11-18 03:39:39,383 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8511631246223006, 'Total loss': 0.8511631246223006} | train loss {'Reaction outcome loss': 0.8006252434273315, 'Total loss': 0.8006252434273315}
2022-11-18 03:39:39,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:39,384 INFO:     Epoch: 41
2022-11-18 03:39:40,167 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8363318997760152, 'Total loss': 0.8363318997760152} | train loss {'Reaction outcome loss': 0.8007684927663685, 'Total loss': 0.8007684927663685}
2022-11-18 03:39:40,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:40,168 INFO:     Epoch: 42
2022-11-18 03:39:40,932 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8547522193470667, 'Total loss': 0.8547522193470667} | train loss {'Reaction outcome loss': 0.8016108576162362, 'Total loss': 0.8016108576162362}
2022-11-18 03:39:40,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:40,934 INFO:     Epoch: 43
2022-11-18 03:39:41,722 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.84259056767752, 'Total loss': 0.84259056767752} | train loss {'Reaction outcome loss': 0.7956202412828987, 'Total loss': 0.7956202412828987}
2022-11-18 03:39:41,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:41,722 INFO:     Epoch: 44
2022-11-18 03:39:42,485 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8442593306996101, 'Total loss': 0.8442593306996101} | train loss {'Reaction outcome loss': 0.7938683440165265, 'Total loss': 0.7938683440165265}
2022-11-18 03:39:42,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:42,486 INFO:     Epoch: 45
2022-11-18 03:39:43,255 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8425743240256642, 'Total loss': 0.8425743240256642} | train loss {'Reaction outcome loss': 0.7991834414103394, 'Total loss': 0.7991834414103394}
2022-11-18 03:39:43,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:43,256 INFO:     Epoch: 46
2022-11-18 03:39:44,010 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8438302819118944, 'Total loss': 0.8438302819118944} | train loss {'Reaction outcome loss': 0.7967731414263141, 'Total loss': 0.7967731414263141}
2022-11-18 03:39:44,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:44,011 INFO:     Epoch: 47
2022-11-18 03:39:44,779 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8326401738233344, 'Total loss': 0.8326401738233344} | train loss {'Reaction outcome loss': 0.804126617410546, 'Total loss': 0.804126617410546}
2022-11-18 03:39:44,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:44,779 INFO:     Epoch: 48
2022-11-18 03:39:45,530 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8482545669688735, 'Total loss': 0.8482545669688735} | train loss {'Reaction outcome loss': 0.7982500947306677, 'Total loss': 0.7982500947306677}
2022-11-18 03:39:45,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:45,531 INFO:     Epoch: 49
2022-11-18 03:39:46,314 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8406858471936958, 'Total loss': 0.8406858471936958} | train loss {'Reaction outcome loss': 0.7978391711113384, 'Total loss': 0.7978391711113384}
2022-11-18 03:39:46,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:46,314 INFO:     Epoch: 50
2022-11-18 03:39:47,068 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8482255395068679, 'Total loss': 0.8482255395068679} | train loss {'Reaction outcome loss': 0.7982577128420151, 'Total loss': 0.7982577128420151}
2022-11-18 03:39:47,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:47,069 INFO:     Epoch: 51
2022-11-18 03:39:47,872 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8504698415135228, 'Total loss': 0.8504698415135228} | train loss {'Reaction outcome loss': 0.7980990658816978, 'Total loss': 0.7980990658816978}
2022-11-18 03:39:47,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:47,873 INFO:     Epoch: 52
2022-11-18 03:39:48,672 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.848242003557294, 'Total loss': 0.848242003557294} | train loss {'Reaction outcome loss': 0.796706896873168, 'Total loss': 0.796706896873168}
2022-11-18 03:39:48,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:48,672 INFO:     Epoch: 53
2022-11-18 03:39:49,455 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8366828325182892, 'Total loss': 0.8366828325182892} | train loss {'Reaction outcome loss': 0.7946288474057437, 'Total loss': 0.7946288474057437}
2022-11-18 03:39:49,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:49,455 INFO:     Epoch: 54
2022-11-18 03:39:50,211 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8364103464193122, 'Total loss': 0.8364103464193122} | train loss {'Reaction outcome loss': 0.7989227524019563, 'Total loss': 0.7989227524019563}
2022-11-18 03:39:50,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:50,212 INFO:     Epoch: 55
2022-11-18 03:39:51,007 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8400563070940417, 'Total loss': 0.8400563070940417} | train loss {'Reaction outcome loss': 0.8001403889538329, 'Total loss': 0.8001403889538329}
2022-11-18 03:39:51,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:51,007 INFO:     Epoch: 56
2022-11-18 03:39:51,751 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8462875658689544, 'Total loss': 0.8462875658689544} | train loss {'Reaction outcome loss': 0.7977529814459169, 'Total loss': 0.7977529814459169}
2022-11-18 03:39:51,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:51,751 INFO:     Epoch: 57
2022-11-18 03:39:52,503 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8390785379465237, 'Total loss': 0.8390785379465237} | train loss {'Reaction outcome loss': 0.7957932555381163, 'Total loss': 0.7957932555381163}
2022-11-18 03:39:52,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:52,503 INFO:     Epoch: 58
2022-11-18 03:39:53,257 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.837187786434972, 'Total loss': 0.837187786434972} | train loss {'Reaction outcome loss': 0.8013175458574491, 'Total loss': 0.8013175458574491}
2022-11-18 03:39:53,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:53,257 INFO:     Epoch: 59
2022-11-18 03:39:54,020 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8276623355787854, 'Total loss': 0.8276623355787854} | train loss {'Reaction outcome loss': 0.7960139353579454, 'Total loss': 0.7960139353579454}
2022-11-18 03:39:54,020 INFO:     Found new best model at epoch 59
2022-11-18 03:39:54,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:54,021 INFO:     Epoch: 60
2022-11-18 03:39:54,795 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.868765230788741, 'Total loss': 0.868765230788741} | train loss {'Reaction outcome loss': 0.7956726073973464, 'Total loss': 0.7956726073973464}
2022-11-18 03:39:54,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:54,796 INFO:     Epoch: 61
2022-11-18 03:39:55,568 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8442400153293166, 'Total loss': 0.8442400153293166} | train loss {'Reaction outcome loss': 0.8009520312886179, 'Total loss': 0.8009520312886179}
2022-11-18 03:39:55,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:55,569 INFO:     Epoch: 62
2022-11-18 03:39:56,348 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8320451739222504, 'Total loss': 0.8320451739222504} | train loss {'Reaction outcome loss': 0.7941282152393718, 'Total loss': 0.7941282152393718}
2022-11-18 03:39:56,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:56,349 INFO:     Epoch: 63
2022-11-18 03:39:57,122 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8389580582463464, 'Total loss': 0.8389580582463464} | train loss {'Reaction outcome loss': 0.8019715585581069, 'Total loss': 0.8019715585581069}
2022-11-18 03:39:57,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:57,122 INFO:     Epoch: 64
2022-11-18 03:39:57,890 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8337216301019802, 'Total loss': 0.8337216301019802} | train loss {'Reaction outcome loss': 0.8001523653175605, 'Total loss': 0.8001523653175605}
2022-11-18 03:39:57,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:57,890 INFO:     Epoch: 65
2022-11-18 03:39:58,665 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.875563076762266, 'Total loss': 0.875563076762266} | train loss {'Reaction outcome loss': 0.7928979676446797, 'Total loss': 0.7928979676446797}
2022-11-18 03:39:58,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:58,666 INFO:     Epoch: 66
2022-11-18 03:39:59,434 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8236920098925746, 'Total loss': 0.8236920098925746} | train loss {'Reaction outcome loss': 0.7986931767728593, 'Total loss': 0.7986931767728593}
2022-11-18 03:39:59,435 INFO:     Found new best model at epoch 66
2022-11-18 03:39:59,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:39:59,436 INFO:     Epoch: 67
2022-11-18 03:40:00,197 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8439679443836212, 'Total loss': 0.8439679443836212} | train loss {'Reaction outcome loss': 0.7965075420254052, 'Total loss': 0.7965075420254052}
2022-11-18 03:40:00,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:00,197 INFO:     Epoch: 68
2022-11-18 03:40:00,968 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8340291367020718, 'Total loss': 0.8340291367020718} | train loss {'Reaction outcome loss': 0.798324096227379, 'Total loss': 0.798324096227379}
2022-11-18 03:40:00,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:00,968 INFO:     Epoch: 69
2022-11-18 03:40:01,742 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8622659604216731, 'Total loss': 0.8622659604216731} | train loss {'Reaction outcome loss': 0.7956903292931647, 'Total loss': 0.7956903292931647}
2022-11-18 03:40:01,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:01,742 INFO:     Epoch: 70
2022-11-18 03:40:02,497 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8284116872521334, 'Total loss': 0.8284116872521334} | train loss {'Reaction outcome loss': 0.7979282400735612, 'Total loss': 0.7979282400735612}
2022-11-18 03:40:02,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:02,498 INFO:     Epoch: 71
2022-11-18 03:40:03,284 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8654096195864123, 'Total loss': 0.8654096195864123} | train loss {'Reaction outcome loss': 0.7982294503062841, 'Total loss': 0.7982294503062841}
2022-11-18 03:40:03,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:03,284 INFO:     Epoch: 72
2022-11-18 03:40:04,073 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8396034926869148, 'Total loss': 0.8396034926869148} | train loss {'Reaction outcome loss': 0.7942852720066353, 'Total loss': 0.7942852720066353}
2022-11-18 03:40:04,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:04,073 INFO:     Epoch: 73
2022-11-18 03:40:04,843 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8329987428909125, 'Total loss': 0.8329987428909125} | train loss {'Reaction outcome loss': 0.7969833937446766, 'Total loss': 0.7969833937446766}
2022-11-18 03:40:04,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:04,844 INFO:     Epoch: 74
2022-11-18 03:40:05,607 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8535548947578253, 'Total loss': 0.8535548947578253} | train loss {'Reaction outcome loss': 0.8025554533848547, 'Total loss': 0.8025554533848547}
2022-11-18 03:40:05,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:05,607 INFO:     Epoch: 75
2022-11-18 03:40:06,373 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8488421412401421, 'Total loss': 0.8488421412401421} | train loss {'Reaction outcome loss': 0.794737058657187, 'Total loss': 0.794737058657187}
2022-11-18 03:40:06,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:06,373 INFO:     Epoch: 76
2022-11-18 03:40:07,134 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8310346631116645, 'Total loss': 0.8310346631116645} | train loss {'Reaction outcome loss': 0.792588074020888, 'Total loss': 0.792588074020888}
2022-11-18 03:40:07,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:07,135 INFO:     Epoch: 77
2022-11-18 03:40:07,920 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.857389583144077, 'Total loss': 0.857389583144077} | train loss {'Reaction outcome loss': 0.7937873324739589, 'Total loss': 0.7937873324739589}
2022-11-18 03:40:07,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:07,920 INFO:     Epoch: 78
2022-11-18 03:40:08,691 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.836114240940227, 'Total loss': 0.836114240940227} | train loss {'Reaction outcome loss': 0.7986947668432699, 'Total loss': 0.7986947668432699}
2022-11-18 03:40:08,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:08,691 INFO:     Epoch: 79
2022-11-18 03:40:09,455 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8286613329898479, 'Total loss': 0.8286613329898479} | train loss {'Reaction outcome loss': 0.7943246868657478, 'Total loss': 0.7943246868657478}
2022-11-18 03:40:09,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:09,455 INFO:     Epoch: 80
2022-11-18 03:40:10,247 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.829991414103397, 'Total loss': 0.829991414103397} | train loss {'Reaction outcome loss': 0.798890107207828, 'Total loss': 0.798890107207828}
2022-11-18 03:40:10,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:10,247 INFO:     Epoch: 81
2022-11-18 03:40:11,014 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8343300486719886, 'Total loss': 0.8343300486719886} | train loss {'Reaction outcome loss': 0.7960677222950469, 'Total loss': 0.7960677222950469}
2022-11-18 03:40:11,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:11,014 INFO:     Epoch: 82
2022-11-18 03:40:11,830 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8268677100192668, 'Total loss': 0.8268677100192668} | train loss {'Reaction outcome loss': 0.7962390379405316, 'Total loss': 0.7962390379405316}
2022-11-18 03:40:11,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:11,831 INFO:     Epoch: 83
2022-11-18 03:40:12,620 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8391110994095026, 'Total loss': 0.8391110994095026} | train loss {'Reaction outcome loss': 0.7983948408085623, 'Total loss': 0.7983948408085623}
2022-11-18 03:40:12,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:12,620 INFO:     Epoch: 84
2022-11-18 03:40:13,434 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8486635144366774, 'Total loss': 0.8486635144366774} | train loss {'Reaction outcome loss': 0.7964796746463932, 'Total loss': 0.7964796746463932}
2022-11-18 03:40:13,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:13,434 INFO:     Epoch: 85
2022-11-18 03:40:14,241 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8592627769292787, 'Total loss': 0.8592627769292787} | train loss {'Reaction outcome loss': 0.797412320603559, 'Total loss': 0.797412320603559}
2022-11-18 03:40:14,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:14,242 INFO:     Epoch: 86
2022-11-18 03:40:15,035 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.847747805506684, 'Total loss': 0.847747805506684} | train loss {'Reaction outcome loss': 0.7920312312404805, 'Total loss': 0.7920312312404805}
2022-11-18 03:40:15,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:15,035 INFO:     Epoch: 87
2022-11-18 03:40:15,843 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8438171078992445, 'Total loss': 0.8438171078992445} | train loss {'Reaction outcome loss': 0.7993850391588093, 'Total loss': 0.7993850391588093}
2022-11-18 03:40:15,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:15,843 INFO:     Epoch: 88
2022-11-18 03:40:16,631 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8355927869331005, 'Total loss': 0.8355927869331005} | train loss {'Reaction outcome loss': 0.7957583929530878, 'Total loss': 0.7957583929530878}
2022-11-18 03:40:16,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:16,631 INFO:     Epoch: 89
2022-11-18 03:40:17,420 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8884203531021295, 'Total loss': 0.8884203531021295} | train loss {'Reaction outcome loss': 0.7915242898734018, 'Total loss': 0.7915242898734018}
2022-11-18 03:40:17,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:17,420 INFO:     Epoch: 90
2022-11-18 03:40:18,184 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.851829225933829, 'Total loss': 0.851829225933829} | train loss {'Reaction outcome loss': 0.7966680656735299, 'Total loss': 0.7966680656735299}
2022-11-18 03:40:18,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:18,186 INFO:     Epoch: 91
2022-11-18 03:40:18,950 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8619076477926831, 'Total loss': 0.8619076477926831} | train loss {'Reaction outcome loss': 0.7970370985107658, 'Total loss': 0.7970370985107658}
2022-11-18 03:40:18,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:18,950 INFO:     Epoch: 92
2022-11-18 03:40:19,723 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8363269110058629, 'Total loss': 0.8363269110058629} | train loss {'Reaction outcome loss': 0.7973782264401392, 'Total loss': 0.7973782264401392}
2022-11-18 03:40:19,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:19,724 INFO:     Epoch: 93
2022-11-18 03:40:20,511 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8453766745190288, 'Total loss': 0.8453766745190288} | train loss {'Reaction outcome loss': 0.7934530159082923, 'Total loss': 0.7934530159082923}
2022-11-18 03:40:20,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:20,512 INFO:     Epoch: 94
2022-11-18 03:40:21,277 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8303159461464993, 'Total loss': 0.8303159461464993} | train loss {'Reaction outcome loss': 0.7932004006924452, 'Total loss': 0.7932004006924452}
2022-11-18 03:40:21,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:21,277 INFO:     Epoch: 95
2022-11-18 03:40:22,059 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8268108936243279, 'Total loss': 0.8268108936243279} | train loss {'Reaction outcome loss': 0.7948641295050397, 'Total loss': 0.7948641295050397}
2022-11-18 03:40:22,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:22,059 INFO:     Epoch: 96
2022-11-18 03:40:22,806 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8566351844820865, 'Total loss': 0.8566351844820865} | train loss {'Reaction outcome loss': 0.7942955825063918, 'Total loss': 0.7942955825063918}
2022-11-18 03:40:22,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:22,806 INFO:     Epoch: 97
2022-11-18 03:40:23,558 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8285404984341112, 'Total loss': 0.8285404984341112} | train loss {'Reaction outcome loss': 0.7981316479145254, 'Total loss': 0.7981316479145254}
2022-11-18 03:40:23,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:23,558 INFO:     Epoch: 98
2022-11-18 03:40:24,320 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8264208269673724, 'Total loss': 0.8264208269673724} | train loss {'Reaction outcome loss': 0.7940920840320274, 'Total loss': 0.7940920840320274}
2022-11-18 03:40:24,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:24,321 INFO:     Epoch: 99
2022-11-18 03:40:25,106 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8344733216041742, 'Total loss': 0.8344733216041742} | train loss {'Reaction outcome loss': 0.7959830924071403, 'Total loss': 0.7959830924071403}
2022-11-18 03:40:25,107 INFO:     Best model found after epoch 67 of 100.
2022-11-18 03:40:25,107 INFO:   Done with stage: TRAINING
2022-11-18 03:40:25,107 INFO:   Starting stage: EVALUATION
2022-11-18 03:40:25,248 INFO:   Done with stage: EVALUATION
2022-11-18 03:40:25,248 INFO:   Leaving out SEQ value Fold_4
2022-11-18 03:40:25,262 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:40:25,262 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:40:25,938 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:40:25,938 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:40:26,009 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:40:26,009 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:40:26,009 INFO:     No hyperparam tuning for this model
2022-11-18 03:40:26,009 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:40:26,009 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:40:26,010 INFO:     None feature selector for col prot
2022-11-18 03:40:26,010 INFO:     None feature selector for col prot
2022-11-18 03:40:26,010 INFO:     None feature selector for col prot
2022-11-18 03:40:26,011 INFO:     None feature selector for col chem
2022-11-18 03:40:26,011 INFO:     None feature selector for col chem
2022-11-18 03:40:26,011 INFO:     None feature selector for col chem
2022-11-18 03:40:26,011 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:40:26,011 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:40:26,013 INFO:     Number of params in model 168571
2022-11-18 03:40:26,016 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:40:26,016 INFO:   Starting stage: TRAINING
2022-11-18 03:40:26,074 INFO:     Val loss before train {'Reaction outcome loss': 0.9962000765583732, 'Total loss': 0.9962000765583732}
2022-11-18 03:40:26,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:26,075 INFO:     Epoch: 0
2022-11-18 03:40:26,877 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7900463755835186, 'Total loss': 0.7900463755835186} | train loss {'Reaction outcome loss': 0.8817772945809749, 'Total loss': 0.8817772945809749}
2022-11-18 03:40:26,877 INFO:     Found new best model at epoch 0
2022-11-18 03:40:26,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:26,878 INFO:     Epoch: 1
2022-11-18 03:40:27,649 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8029907176440413, 'Total loss': 0.8029907176440413} | train loss {'Reaction outcome loss': 0.8510122919274915, 'Total loss': 0.8510122919274915}
2022-11-18 03:40:27,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:27,649 INFO:     Epoch: 2
2022-11-18 03:40:28,463 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7931249344890768, 'Total loss': 0.7931249344890768} | train loss {'Reaction outcome loss': 0.8434319509373557, 'Total loss': 0.8434319509373557}
2022-11-18 03:40:28,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:28,463 INFO:     Epoch: 3
2022-11-18 03:40:29,264 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7827191779559309, 'Total loss': 0.7827191779559309} | train loss {'Reaction outcome loss': 0.8357961354476791, 'Total loss': 0.8357961354476791}
2022-11-18 03:40:29,264 INFO:     Found new best model at epoch 3
2022-11-18 03:40:29,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:29,265 INFO:     Epoch: 4
2022-11-18 03:40:30,057 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7836120115085081, 'Total loss': 0.7836120115085081} | train loss {'Reaction outcome loss': 0.8329082445031212, 'Total loss': 0.8329082445031212}
2022-11-18 03:40:30,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:30,057 INFO:     Epoch: 5
2022-11-18 03:40:30,834 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7987064976583828, 'Total loss': 0.7987064976583828} | train loss {'Reaction outcome loss': 0.8278494399161108, 'Total loss': 0.8278494399161108}
2022-11-18 03:40:30,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:30,835 INFO:     Epoch: 6
2022-11-18 03:40:31,637 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7903810725970701, 'Total loss': 0.7903810725970701} | train loss {'Reaction outcome loss': 0.8232654764527275, 'Total loss': 0.8232654764527275}
2022-11-18 03:40:31,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:31,637 INFO:     Epoch: 7
2022-11-18 03:40:32,428 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7783805240284313, 'Total loss': 0.7783805240284313} | train loss {'Reaction outcome loss': 0.8228248240005586, 'Total loss': 0.8228248240005586}
2022-11-18 03:40:32,428 INFO:     Found new best model at epoch 7
2022-11-18 03:40:32,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:32,429 INFO:     Epoch: 8
2022-11-18 03:40:33,200 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7712424356829036, 'Total loss': 0.7712424356829036} | train loss {'Reaction outcome loss': 0.8251747637386283, 'Total loss': 0.8251747637386283}
2022-11-18 03:40:33,200 INFO:     Found new best model at epoch 8
2022-11-18 03:40:33,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:33,201 INFO:     Epoch: 9
2022-11-18 03:40:33,991 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7786807160485875, 'Total loss': 0.7786807160485875} | train loss {'Reaction outcome loss': 0.8183894228310354, 'Total loss': 0.8183894228310354}
2022-11-18 03:40:33,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:33,992 INFO:     Epoch: 10
2022-11-18 03:40:34,791 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7767799347639084, 'Total loss': 0.7767799347639084} | train loss {'Reaction outcome loss': 0.8217239113103959, 'Total loss': 0.8217239113103959}
2022-11-18 03:40:34,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:34,791 INFO:     Epoch: 11
2022-11-18 03:40:35,577 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7802409550005739, 'Total loss': 0.7802409550005739} | train loss {'Reaction outcome loss': 0.821248133336344, 'Total loss': 0.821248133336344}
2022-11-18 03:40:35,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:35,577 INFO:     Epoch: 12
2022-11-18 03:40:36,389 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7925855205817656, 'Total loss': 0.7925855205817656} | train loss {'Reaction outcome loss': 0.8165684419894411, 'Total loss': 0.8165684419894411}
2022-11-18 03:40:36,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:36,390 INFO:     Epoch: 13
2022-11-18 03:40:37,170 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7703197815201499, 'Total loss': 0.7703197815201499} | train loss {'Reaction outcome loss': 0.8186841261002326, 'Total loss': 0.8186841261002326}
2022-11-18 03:40:37,170 INFO:     Found new best model at epoch 13
2022-11-18 03:40:37,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:37,171 INFO:     Epoch: 14
2022-11-18 03:40:37,972 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7804941548542543, 'Total loss': 0.7804941548542543} | train loss {'Reaction outcome loss': 0.8188359885206146, 'Total loss': 0.8188359885206146}
2022-11-18 03:40:37,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:37,972 INFO:     Epoch: 15
2022-11-18 03:40:38,771 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7702702846039425, 'Total loss': 0.7702702846039425} | train loss {'Reaction outcome loss': 0.8186931513970898, 'Total loss': 0.8186931513970898}
2022-11-18 03:40:38,771 INFO:     Found new best model at epoch 15
2022-11-18 03:40:38,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:38,772 INFO:     Epoch: 16
2022-11-18 03:40:39,529 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7898260869763114, 'Total loss': 0.7898260869763114} | train loss {'Reaction outcome loss': 0.8202436316397882, 'Total loss': 0.8202436316397882}
2022-11-18 03:40:39,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:39,529 INFO:     Epoch: 17
2022-11-18 03:40:40,317 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7746012386950579, 'Total loss': 0.7746012386950579} | train loss {'Reaction outcome loss': 0.8210191356558953, 'Total loss': 0.8210191356558953}
2022-11-18 03:40:40,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:40,318 INFO:     Epoch: 18
2022-11-18 03:40:41,099 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7821075117046182, 'Total loss': 0.7821075117046182} | train loss {'Reaction outcome loss': 0.8187624639080416, 'Total loss': 0.8187624639080416}
2022-11-18 03:40:41,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:41,100 INFO:     Epoch: 19
2022-11-18 03:40:41,877 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7688856632872061, 'Total loss': 0.7688856632872061} | train loss {'Reaction outcome loss': 0.8168800902222434, 'Total loss': 0.8168800902222434}
2022-11-18 03:40:41,877 INFO:     Found new best model at epoch 19
2022-11-18 03:40:41,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:41,878 INFO:     Epoch: 20
2022-11-18 03:40:42,658 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7856689589944753, 'Total loss': 0.7856689589944753} | train loss {'Reaction outcome loss': 0.8101818455803779, 'Total loss': 0.8101818455803779}
2022-11-18 03:40:42,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:42,659 INFO:     Epoch: 21
2022-11-18 03:40:43,458 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7714673646471717, 'Total loss': 0.7714673646471717} | train loss {'Reaction outcome loss': 0.8173903992339489, 'Total loss': 0.8173903992339489}
2022-11-18 03:40:43,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:43,459 INFO:     Epoch: 22
2022-11-18 03:40:44,241 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7733533138578589, 'Total loss': 0.7733533138578589} | train loss {'Reaction outcome loss': 0.8182494975626469, 'Total loss': 0.8182494975626469}
2022-11-18 03:40:44,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:44,241 INFO:     Epoch: 23
2022-11-18 03:40:45,034 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7757457867264748, 'Total loss': 0.7757457867264748} | train loss {'Reaction outcome loss': 0.8168991820946816, 'Total loss': 0.8168991820946816}
2022-11-18 03:40:45,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:45,035 INFO:     Epoch: 24
2022-11-18 03:40:45,840 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7685706276785244, 'Total loss': 0.7685706276785244} | train loss {'Reaction outcome loss': 0.812761209424465, 'Total loss': 0.812761209424465}
2022-11-18 03:40:45,840 INFO:     Found new best model at epoch 24
2022-11-18 03:40:45,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:45,841 INFO:     Epoch: 25
2022-11-18 03:40:46,604 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7718425799499858, 'Total loss': 0.7718425799499858} | train loss {'Reaction outcome loss': 0.8134844597549208, 'Total loss': 0.8134844597549208}
2022-11-18 03:40:46,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:46,604 INFO:     Epoch: 26
2022-11-18 03:40:47,374 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7700394243001938, 'Total loss': 0.7700394243001938} | train loss {'Reaction outcome loss': 0.8162109449265464, 'Total loss': 0.8162109449265464}
2022-11-18 03:40:47,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:47,375 INFO:     Epoch: 27
2022-11-18 03:40:48,140 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7670007117769935, 'Total loss': 0.7670007117769935} | train loss {'Reaction outcome loss': 0.8189435500291086, 'Total loss': 0.8189435500291086}
2022-11-18 03:40:48,140 INFO:     Found new best model at epoch 27
2022-11-18 03:40:48,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:48,141 INFO:     Epoch: 28
2022-11-18 03:40:48,955 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7835985679518093, 'Total loss': 0.7835985679518093} | train loss {'Reaction outcome loss': 0.8161634679042524, 'Total loss': 0.8161634679042524}
2022-11-18 03:40:48,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:48,956 INFO:     Epoch: 29
2022-11-18 03:40:49,746 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7674190334298394, 'Total loss': 0.7674190334298394} | train loss {'Reaction outcome loss': 0.8157084550588362, 'Total loss': 0.8157084550588362}
2022-11-18 03:40:49,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:49,747 INFO:     Epoch: 30
2022-11-18 03:40:50,524 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.767466009340503, 'Total loss': 0.767466009340503} | train loss {'Reaction outcome loss': 0.8177878283444913, 'Total loss': 0.8177878283444913}
2022-11-18 03:40:50,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:50,525 INFO:     Epoch: 31
2022-11-18 03:40:51,303 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.772234134376049, 'Total loss': 0.772234134376049} | train loss {'Reaction outcome loss': 0.8129060205913359, 'Total loss': 0.8129060205913359}
2022-11-18 03:40:51,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:51,303 INFO:     Epoch: 32
2022-11-18 03:40:52,071 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7679405124350027, 'Total loss': 0.7679405124350027} | train loss {'Reaction outcome loss': 0.8147655155870223, 'Total loss': 0.8147655155870223}
2022-11-18 03:40:52,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:52,072 INFO:     Epoch: 33
2022-11-18 03:40:52,865 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7926183600317348, 'Total loss': 0.7926183600317348} | train loss {'Reaction outcome loss': 0.8143793012826673, 'Total loss': 0.8143793012826673}
2022-11-18 03:40:52,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:52,866 INFO:     Epoch: 34
2022-11-18 03:40:53,633 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7663622918454084, 'Total loss': 0.7663622918454084} | train loss {'Reaction outcome loss': 0.8195831178417129, 'Total loss': 0.8195831178417129}
2022-11-18 03:40:53,633 INFO:     Found new best model at epoch 34
2022-11-18 03:40:53,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:53,634 INFO:     Epoch: 35
2022-11-18 03:40:54,425 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.770117998123169, 'Total loss': 0.770117998123169} | train loss {'Reaction outcome loss': 0.8146711887130814, 'Total loss': 0.8146711887130814}
2022-11-18 03:40:54,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:54,425 INFO:     Epoch: 36
2022-11-18 03:40:55,217 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7778516831723127, 'Total loss': 0.7778516831723127} | train loss {'Reaction outcome loss': 0.8149512419777531, 'Total loss': 0.8149512419777531}
2022-11-18 03:40:55,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:55,217 INFO:     Epoch: 37
2022-11-18 03:40:55,983 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7750267190012065, 'Total loss': 0.7750267190012065} | train loss {'Reaction outcome loss': 0.815568508039559, 'Total loss': 0.815568508039559}
2022-11-18 03:40:55,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:55,984 INFO:     Epoch: 38
2022-11-18 03:40:56,786 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7625609534707937, 'Total loss': 0.7625609534707937} | train loss {'Reaction outcome loss': 0.8167312170468992, 'Total loss': 0.8167312170468992}
2022-11-18 03:40:56,786 INFO:     Found new best model at epoch 38
2022-11-18 03:40:56,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:56,787 INFO:     Epoch: 39
2022-11-18 03:40:57,574 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7853008021007885, 'Total loss': 0.7853008021007885} | train loss {'Reaction outcome loss': 0.8172394781103057, 'Total loss': 0.8172394781103057}
2022-11-18 03:40:57,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:57,574 INFO:     Epoch: 40
2022-11-18 03:40:58,327 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7775420499118891, 'Total loss': 0.7775420499118891} | train loss {'Reaction outcome loss': 0.8134641074124844, 'Total loss': 0.8134641074124844}
2022-11-18 03:40:58,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:58,327 INFO:     Epoch: 41
2022-11-18 03:40:59,128 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7991815812208436, 'Total loss': 0.7991815812208436} | train loss {'Reaction outcome loss': 0.8118146391164872, 'Total loss': 0.8118146391164872}
2022-11-18 03:40:59,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:59,129 INFO:     Epoch: 42
2022-11-18 03:40:59,921 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7761902809143066, 'Total loss': 0.7761902809143066} | train loss {'Reaction outcome loss': 0.8136905250289748, 'Total loss': 0.8136905250289748}
2022-11-18 03:40:59,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:40:59,921 INFO:     Epoch: 43
2022-11-18 03:41:00,718 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7611946341666308, 'Total loss': 0.7611946341666308} | train loss {'Reaction outcome loss': 0.8181851122888827, 'Total loss': 0.8181851122888827}
2022-11-18 03:41:00,718 INFO:     Found new best model at epoch 43
2022-11-18 03:41:00,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:00,719 INFO:     Epoch: 44
2022-11-18 03:41:01,503 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7779242917895317, 'Total loss': 0.7779242917895317} | train loss {'Reaction outcome loss': 0.8152200071321379, 'Total loss': 0.8152200071321379}
2022-11-18 03:41:01,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:01,504 INFO:     Epoch: 45
2022-11-18 03:41:02,275 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7638029645789753, 'Total loss': 0.7638029645789753} | train loss {'Reaction outcome loss': 0.8124680557558613, 'Total loss': 0.8124680557558613}
2022-11-18 03:41:02,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:02,275 INFO:     Epoch: 46
2022-11-18 03:41:03,061 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7636904188177802, 'Total loss': 0.7636904188177802} | train loss {'Reaction outcome loss': 0.8145468415271852, 'Total loss': 0.8145468415271852}
2022-11-18 03:41:03,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:03,061 INFO:     Epoch: 47
2022-11-18 03:41:03,852 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7660504667596384, 'Total loss': 0.7660504667596384} | train loss {'Reaction outcome loss': 0.813205631509904, 'Total loss': 0.813205631509904}
2022-11-18 03:41:03,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:03,853 INFO:     Epoch: 48
2022-11-18 03:41:04,632 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7832783284512433, 'Total loss': 0.7832783284512433} | train loss {'Reaction outcome loss': 0.814540707896794, 'Total loss': 0.814540707896794}
2022-11-18 03:41:04,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:04,632 INFO:     Epoch: 49
2022-11-18 03:41:05,426 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7696139446713708, 'Total loss': 0.7696139446713708} | train loss {'Reaction outcome loss': 0.813055751905326, 'Total loss': 0.813055751905326}
2022-11-18 03:41:05,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:05,426 INFO:     Epoch: 50
2022-11-18 03:41:06,197 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7719705131920901, 'Total loss': 0.7719705131920901} | train loss {'Reaction outcome loss': 0.8067486681524785, 'Total loss': 0.8067486681524785}
2022-11-18 03:41:06,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:06,197 INFO:     Epoch: 51
2022-11-18 03:41:06,978 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7746453569693998, 'Total loss': 0.7746453569693998} | train loss {'Reaction outcome loss': 0.8167019824106847, 'Total loss': 0.8167019824106847}
2022-11-18 03:41:06,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:06,978 INFO:     Epoch: 52
2022-11-18 03:41:07,778 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7682858664881099, 'Total loss': 0.7682858664881099} | train loss {'Reaction outcome loss': 0.8161258101463318, 'Total loss': 0.8161258101463318}
2022-11-18 03:41:07,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:07,779 INFO:     Epoch: 53
2022-11-18 03:41:08,547 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7914626368067481, 'Total loss': 0.7914626368067481} | train loss {'Reaction outcome loss': 0.8162410590917833, 'Total loss': 0.8162410590917833}
2022-11-18 03:41:08,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:08,548 INFO:     Epoch: 54
2022-11-18 03:41:09,359 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7709038067947734, 'Total loss': 0.7709038067947734} | train loss {'Reaction outcome loss': 0.8133813740024644, 'Total loss': 0.8133813740024644}
2022-11-18 03:41:09,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:09,359 INFO:     Epoch: 55
2022-11-18 03:41:10,169 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7703701217066158, 'Total loss': 0.7703701217066158} | train loss {'Reaction outcome loss': 0.8165622376386197, 'Total loss': 0.8165622376386197}
2022-11-18 03:41:10,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:10,169 INFO:     Epoch: 56
2022-11-18 03:41:10,950 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7896580303257162, 'Total loss': 0.7896580303257162} | train loss {'Reaction outcome loss': 0.8142568104930462, 'Total loss': 0.8142568104930462}
2022-11-18 03:41:10,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:10,951 INFO:     Epoch: 57
2022-11-18 03:41:11,741 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7696137258952315, 'Total loss': 0.7696137258952315} | train loss {'Reaction outcome loss': 0.8153123144180544, 'Total loss': 0.8153123144180544}
2022-11-18 03:41:11,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:11,742 INFO:     Epoch: 58
2022-11-18 03:41:12,534 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7569927173581991, 'Total loss': 0.7569927173581991} | train loss {'Reaction outcome loss': 0.8094639469298625, 'Total loss': 0.8094639469298625}
2022-11-18 03:41:12,534 INFO:     Found new best model at epoch 58
2022-11-18 03:41:12,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:12,535 INFO:     Epoch: 59
2022-11-18 03:41:13,347 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7700850381092592, 'Total loss': 0.7700850381092592} | train loss {'Reaction outcome loss': 0.8163794229828543, 'Total loss': 0.8163794229828543}
2022-11-18 03:41:13,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:13,348 INFO:     Epoch: 60
2022-11-18 03:41:14,141 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7806636460802772, 'Total loss': 0.7806636460802772} | train loss {'Reaction outcome loss': 0.8109471301638311, 'Total loss': 0.8109471301638311}
2022-11-18 03:41:14,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:14,142 INFO:     Epoch: 61
2022-11-18 03:41:14,904 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7750221382487904, 'Total loss': 0.7750221382487904} | train loss {'Reaction outcome loss': 0.8154443049382779, 'Total loss': 0.8154443049382779}
2022-11-18 03:41:14,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:14,904 INFO:     Epoch: 62
2022-11-18 03:41:15,701 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7621746307069605, 'Total loss': 0.7621746307069605} | train loss {'Reaction outcome loss': 0.8135291721912161, 'Total loss': 0.8135291721912161}
2022-11-18 03:41:15,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:15,701 INFO:     Epoch: 63
2022-11-18 03:41:16,467 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7814583683555777, 'Total loss': 0.7814583683555777} | train loss {'Reaction outcome loss': 0.8112364609635645, 'Total loss': 0.8112364609635645}
2022-11-18 03:41:16,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:16,467 INFO:     Epoch: 64
2022-11-18 03:41:17,269 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7554061643101952, 'Total loss': 0.7554061643101952} | train loss {'Reaction outcome loss': 0.8134049275709737, 'Total loss': 0.8134049275709737}
2022-11-18 03:41:17,269 INFO:     Found new best model at epoch 64
2022-11-18 03:41:17,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:17,270 INFO:     Epoch: 65
2022-11-18 03:41:18,068 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7600514909083192, 'Total loss': 0.7600514909083192} | train loss {'Reaction outcome loss': 0.8095763412214094, 'Total loss': 0.8095763412214094}
2022-11-18 03:41:18,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:18,068 INFO:     Epoch: 66
2022-11-18 03:41:18,855 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7574164528738369, 'Total loss': 0.7574164528738369} | train loss {'Reaction outcome loss': 0.8165874083436304, 'Total loss': 0.8165874083436304}
2022-11-18 03:41:18,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:18,855 INFO:     Epoch: 67
2022-11-18 03:41:19,648 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.767422344874252, 'Total loss': 0.767422344874252} | train loss {'Reaction outcome loss': 0.8113702082585904, 'Total loss': 0.8113702082585904}
2022-11-18 03:41:19,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:19,648 INFO:     Epoch: 68
2022-11-18 03:41:20,437 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7663793347098611, 'Total loss': 0.7663793347098611} | train loss {'Reaction outcome loss': 0.8105195406223497, 'Total loss': 0.8105195406223497}
2022-11-18 03:41:20,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:20,438 INFO:     Epoch: 69
2022-11-18 03:41:21,241 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7663904706185515, 'Total loss': 0.7663904706185515} | train loss {'Reaction outcome loss': 0.8153788610812156, 'Total loss': 0.8153788610812156}
2022-11-18 03:41:21,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:21,241 INFO:     Epoch: 70
2022-11-18 03:41:22,017 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7818634686144915, 'Total loss': 0.7818634686144915} | train loss {'Reaction outcome loss': 0.8120337009670273, 'Total loss': 0.8120337009670273}
2022-11-18 03:41:22,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:22,018 INFO:     Epoch: 71
2022-11-18 03:41:22,784 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7742860771038316, 'Total loss': 0.7742860771038316} | train loss {'Reaction outcome loss': 0.814274221899048, 'Total loss': 0.814274221899048}
2022-11-18 03:41:22,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:22,784 INFO:     Epoch: 72
2022-11-18 03:41:23,552 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.767414504154162, 'Total loss': 0.767414504154162} | train loss {'Reaction outcome loss': 0.8159652812586676, 'Total loss': 0.8159652812586676}
2022-11-18 03:41:23,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:23,552 INFO:     Epoch: 73
2022-11-18 03:41:24,342 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7565405355258421, 'Total loss': 0.7565405355258421} | train loss {'Reaction outcome loss': 0.8137705815174887, 'Total loss': 0.8137705815174887}
2022-11-18 03:41:24,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:24,342 INFO:     Epoch: 74
2022-11-18 03:41:25,116 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7641593278809027, 'Total loss': 0.7641593278809027} | train loss {'Reaction outcome loss': 0.8149018484738565, 'Total loss': 0.8149018484738565}
2022-11-18 03:41:25,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:25,116 INFO:     Epoch: 75
2022-11-18 03:41:25,879 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7638595842502334, 'Total loss': 0.7638595842502334} | train loss {'Reaction outcome loss': 0.8115031367107746, 'Total loss': 0.8115031367107746}
2022-11-18 03:41:25,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:25,879 INFO:     Epoch: 76
2022-11-18 03:41:26,667 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7656247893517668, 'Total loss': 0.7656247893517668} | train loss {'Reaction outcome loss': 0.8215646005926593, 'Total loss': 0.8215646005926593}
2022-11-18 03:41:26,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:26,667 INFO:     Epoch: 77
2022-11-18 03:41:27,444 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7603739574551582, 'Total loss': 0.7603739574551582} | train loss {'Reaction outcome loss': 0.8160461669246997, 'Total loss': 0.8160461669246997}
2022-11-18 03:41:27,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:27,444 INFO:     Epoch: 78
2022-11-18 03:41:28,223 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.766577617011287, 'Total loss': 0.766577617011287} | train loss {'Reaction outcome loss': 0.8151829927679031, 'Total loss': 0.8151829927679031}
2022-11-18 03:41:28,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:28,223 INFO:     Epoch: 79
2022-11-18 03:41:29,021 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7669204128059474, 'Total loss': 0.7669204128059474} | train loss {'Reaction outcome loss': 0.8158040337504879, 'Total loss': 0.8158040337504879}
2022-11-18 03:41:29,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:29,021 INFO:     Epoch: 80
2022-11-18 03:41:29,802 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7714858481829817, 'Total loss': 0.7714858481829817} | train loss {'Reaction outcome loss': 0.81134522117434, 'Total loss': 0.81134522117434}
2022-11-18 03:41:29,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:29,802 INFO:     Epoch: 81
2022-11-18 03:41:30,572 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7663972865451466, 'Total loss': 0.7663972865451466} | train loss {'Reaction outcome loss': 0.8157578426743707, 'Total loss': 0.8157578426743707}
2022-11-18 03:41:30,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:30,572 INFO:     Epoch: 82
2022-11-18 03:41:31,363 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7884836014021527, 'Total loss': 0.7884836014021527} | train loss {'Reaction outcome loss': 0.8133048528144436, 'Total loss': 0.8133048528144436}
2022-11-18 03:41:31,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:31,363 INFO:     Epoch: 83
2022-11-18 03:41:32,155 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7759241366928274, 'Total loss': 0.7759241366928274} | train loss {'Reaction outcome loss': 0.8093036505724153, 'Total loss': 0.8093036505724153}
2022-11-18 03:41:32,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:32,156 INFO:     Epoch: 84
2022-11-18 03:41:32,913 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7673833614045923, 'Total loss': 0.7673833614045923} | train loss {'Reaction outcome loss': 0.8130085202715089, 'Total loss': 0.8130085202715089}
2022-11-18 03:41:32,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:32,914 INFO:     Epoch: 85
2022-11-18 03:41:33,709 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7883602035316554, 'Total loss': 0.7883602035316554} | train loss {'Reaction outcome loss': 0.8140275129868139, 'Total loss': 0.8140275129868139}
2022-11-18 03:41:33,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:33,709 INFO:     Epoch: 86
2022-11-18 03:41:34,484 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7732762552120469, 'Total loss': 0.7732762552120469} | train loss {'Reaction outcome loss': 0.8136176590717608, 'Total loss': 0.8136176590717608}
2022-11-18 03:41:34,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:34,485 INFO:     Epoch: 87
2022-11-18 03:41:35,259 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7655084627595815, 'Total loss': 0.7655084627595815} | train loss {'Reaction outcome loss': 0.8151821057883001, 'Total loss': 0.8151821057883001}
2022-11-18 03:41:35,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:35,259 INFO:     Epoch: 88
2022-11-18 03:41:36,058 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7835861214182593, 'Total loss': 0.7835861214182593} | train loss {'Reaction outcome loss': 0.8118468337962704, 'Total loss': 0.8118468337962704}
2022-11-18 03:41:36,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:36,058 INFO:     Epoch: 89
2022-11-18 03:41:36,823 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7742798660289157, 'Total loss': 0.7742798660289157} | train loss {'Reaction outcome loss': 0.8117670549019691, 'Total loss': 0.8117670549019691}
2022-11-18 03:41:36,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:36,823 INFO:     Epoch: 90
2022-11-18 03:41:37,622 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7687161998315291, 'Total loss': 0.7687161998315291} | train loss {'Reaction outcome loss': 0.8125279641920521, 'Total loss': 0.8125279641920521}
2022-11-18 03:41:37,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:37,623 INFO:     Epoch: 91
2022-11-18 03:41:38,415 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7627698149193417, 'Total loss': 0.7627698149193417} | train loss {'Reaction outcome loss': 0.8164242554095483, 'Total loss': 0.8164242554095483}
2022-11-18 03:41:38,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:38,415 INFO:     Epoch: 92
2022-11-18 03:41:39,191 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7638561813668772, 'Total loss': 0.7638561813668772} | train loss {'Reaction outcome loss': 0.8079992235908585, 'Total loss': 0.8079992235908585}
2022-11-18 03:41:39,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:39,191 INFO:     Epoch: 93
2022-11-18 03:41:39,992 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7840232828801329, 'Total loss': 0.7840232828801329} | train loss {'Reaction outcome loss': 0.8085060352759976, 'Total loss': 0.8085060352759976}
2022-11-18 03:41:39,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:39,992 INFO:     Epoch: 94
2022-11-18 03:41:40,747 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7757591103965585, 'Total loss': 0.7757591103965585} | train loss {'Reaction outcome loss': 0.8067934154983489, 'Total loss': 0.8067934154983489}
2022-11-18 03:41:40,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:40,747 INFO:     Epoch: 95
2022-11-18 03:41:41,513 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7526658570224588, 'Total loss': 0.7526658570224588} | train loss {'Reaction outcome loss': 0.8146116465570465, 'Total loss': 0.8146116465570465}
2022-11-18 03:41:41,514 INFO:     Found new best model at epoch 95
2022-11-18 03:41:41,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:41,514 INFO:     Epoch: 96
2022-11-18 03:41:42,292 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7808639407157898, 'Total loss': 0.7808639407157898} | train loss {'Reaction outcome loss': 0.8110615395970883, 'Total loss': 0.8110615395970883}
2022-11-18 03:41:42,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:42,292 INFO:     Epoch: 97
2022-11-18 03:41:43,052 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7960365841334517, 'Total loss': 0.7960365841334517} | train loss {'Reaction outcome loss': 0.8107550514321173, 'Total loss': 0.8107550514321173}
2022-11-18 03:41:43,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:43,052 INFO:     Epoch: 98
2022-11-18 03:41:43,834 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7812206257473339, 'Total loss': 0.7812206257473339} | train loss {'Reaction outcome loss': 0.8182838339238397, 'Total loss': 0.8182838339238397}
2022-11-18 03:41:43,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:43,835 INFO:     Epoch: 99
2022-11-18 03:41:44,640 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7776035673239015, 'Total loss': 0.7776035673239015} | train loss {'Reaction outcome loss': 0.8096665625851001, 'Total loss': 0.8096665625851001}
2022-11-18 03:41:44,641 INFO:     Best model found after epoch 96 of 100.
2022-11-18 03:41:44,641 INFO:   Done with stage: TRAINING
2022-11-18 03:41:44,641 INFO:   Starting stage: EVALUATION
2022-11-18 03:41:44,758 INFO:   Done with stage: EVALUATION
2022-11-18 03:41:44,759 INFO:   Leaving out SEQ value Fold_5
2022-11-18 03:41:44,771 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 03:41:44,772 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:41:45,435 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:41:45,435 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:41:45,504 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:41:45,504 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:41:45,504 INFO:     No hyperparam tuning for this model
2022-11-18 03:41:45,505 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:41:45,505 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:41:45,505 INFO:     None feature selector for col prot
2022-11-18 03:41:45,506 INFO:     None feature selector for col prot
2022-11-18 03:41:45,506 INFO:     None feature selector for col prot
2022-11-18 03:41:45,506 INFO:     None feature selector for col chem
2022-11-18 03:41:45,507 INFO:     None feature selector for col chem
2022-11-18 03:41:45,507 INFO:     None feature selector for col chem
2022-11-18 03:41:45,507 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:41:45,507 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:41:45,508 INFO:     Number of params in model 168571
2022-11-18 03:41:45,512 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:41:45,512 INFO:   Starting stage: TRAINING
2022-11-18 03:41:45,570 INFO:     Val loss before train {'Reaction outcome loss': 1.0634990551254966, 'Total loss': 1.0634990551254966}
2022-11-18 03:41:45,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:45,571 INFO:     Epoch: 0
2022-11-18 03:41:46,350 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8740206950090148, 'Total loss': 0.8740206950090148} | train loss {'Reaction outcome loss': 0.8866892141955239, 'Total loss': 0.8866892141955239}
2022-11-18 03:41:46,350 INFO:     Found new best model at epoch 0
2022-11-18 03:41:46,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:46,351 INFO:     Epoch: 1
2022-11-18 03:41:47,119 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8621769283305515, 'Total loss': 0.8621769283305515} | train loss {'Reaction outcome loss': 0.8547460979344893, 'Total loss': 0.8547460979344893}
2022-11-18 03:41:47,119 INFO:     Found new best model at epoch 1
2022-11-18 03:41:47,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:47,120 INFO:     Epoch: 2
2022-11-18 03:41:47,895 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8808495077219877, 'Total loss': 0.8808495077219877} | train loss {'Reaction outcome loss': 0.8482151106912262, 'Total loss': 0.8482151106912262}
2022-11-18 03:41:47,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:47,895 INFO:     Epoch: 3
2022-11-18 03:41:48,685 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8559500886635347, 'Total loss': 0.8559500886635347} | train loss {'Reaction outcome loss': 0.8433884977077951, 'Total loss': 0.8433884977077951}
2022-11-18 03:41:48,686 INFO:     Found new best model at epoch 3
2022-11-18 03:41:48,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:48,687 INFO:     Epoch: 4
2022-11-18 03:41:49,473 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.852793116461147, 'Total loss': 0.852793116461147} | train loss {'Reaction outcome loss': 0.8420327512585387, 'Total loss': 0.8420327512585387}
2022-11-18 03:41:49,473 INFO:     Found new best model at epoch 4
2022-11-18 03:41:49,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:49,474 INFO:     Epoch: 5
2022-11-18 03:41:50,228 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8551255268129435, 'Total loss': 0.8551255268129435} | train loss {'Reaction outcome loss': 0.836074055700886, 'Total loss': 0.836074055700886}
2022-11-18 03:41:50,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:50,229 INFO:     Epoch: 6
2022-11-18 03:41:50,997 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8537039553577249, 'Total loss': 0.8537039553577249} | train loss {'Reaction outcome loss': 0.8330270392554147, 'Total loss': 0.8330270392554147}
2022-11-18 03:41:50,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:50,998 INFO:     Epoch: 7
2022-11-18 03:41:51,757 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8852495510469783, 'Total loss': 0.8852495510469783} | train loss {'Reaction outcome loss': 0.838286637651677, 'Total loss': 0.838286637651677}
2022-11-18 03:41:51,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:51,757 INFO:     Epoch: 8
2022-11-18 03:41:52,530 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.852238111875274, 'Total loss': 0.852238111875274} | train loss {'Reaction outcome loss': 0.8375994387938052, 'Total loss': 0.8375994387938052}
2022-11-18 03:41:52,530 INFO:     Found new best model at epoch 8
2022-11-18 03:41:52,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:52,531 INFO:     Epoch: 9
2022-11-18 03:41:53,308 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8574175197969783, 'Total loss': 0.8574175197969783} | train loss {'Reaction outcome loss': 0.8330520642047026, 'Total loss': 0.8330520642047026}
2022-11-18 03:41:53,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:53,308 INFO:     Epoch: 10
2022-11-18 03:41:54,084 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8662542341784998, 'Total loss': 0.8662542341784998} | train loss {'Reaction outcome loss': 0.8305126019886562, 'Total loss': 0.8305126019886562}
2022-11-18 03:41:54,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:54,084 INFO:     Epoch: 11
2022-11-18 03:41:54,863 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8671827844598077, 'Total loss': 0.8671827844598077} | train loss {'Reaction outcome loss': 0.8356214507501952, 'Total loss': 0.8356214507501952}
2022-11-18 03:41:54,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:54,864 INFO:     Epoch: 12
2022-11-18 03:41:55,649 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8886043842543255, 'Total loss': 0.8886043842543255} | train loss {'Reaction outcome loss': 0.8323423666613442, 'Total loss': 0.8323423666613442}
2022-11-18 03:41:55,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:55,650 INFO:     Epoch: 13
2022-11-18 03:41:56,410 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8614635034040972, 'Total loss': 0.8614635034040972} | train loss {'Reaction outcome loss': 0.8299000572185127, 'Total loss': 0.8299000572185127}
2022-11-18 03:41:56,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:56,410 INFO:     Epoch: 14
2022-11-18 03:41:57,186 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8579027679833499, 'Total loss': 0.8579027679833499} | train loss {'Reaction outcome loss': 0.8325417264383667, 'Total loss': 0.8325417264383667}
2022-11-18 03:41:57,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:57,187 INFO:     Epoch: 15
2022-11-18 03:41:57,968 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8530257012356411, 'Total loss': 0.8530257012356411} | train loss {'Reaction outcome loss': 0.8270983775051273, 'Total loss': 0.8270983775051273}
2022-11-18 03:41:57,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:57,969 INFO:     Epoch: 16
2022-11-18 03:41:58,746 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8775178288871591, 'Total loss': 0.8775178288871591} | train loss {'Reaction outcome loss': 0.8282654179602253, 'Total loss': 0.8282654179602253}
2022-11-18 03:41:58,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:58,746 INFO:     Epoch: 17
2022-11-18 03:41:59,507 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8603006628426638, 'Total loss': 0.8603006628426638} | train loss {'Reaction outcome loss': 0.8261725553444453, 'Total loss': 0.8261725553444453}
2022-11-18 03:41:59,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:41:59,507 INFO:     Epoch: 18
2022-11-18 03:42:00,289 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8574905476786874, 'Total loss': 0.8574905476786874} | train loss {'Reaction outcome loss': 0.8263013147577948, 'Total loss': 0.8263013147577948}
2022-11-18 03:42:00,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:00,290 INFO:     Epoch: 19
2022-11-18 03:42:01,068 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8605061661113392, 'Total loss': 0.8605061661113392} | train loss {'Reaction outcome loss': 0.8258567679901512, 'Total loss': 0.8258567679901512}
2022-11-18 03:42:01,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:01,069 INFO:     Epoch: 20
2022-11-18 03:42:01,847 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8623047552325509, 'Total loss': 0.8623047552325509} | train loss {'Reaction outcome loss': 0.8240895856399926, 'Total loss': 0.8240895856399926}
2022-11-18 03:42:01,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:01,847 INFO:     Epoch: 21
2022-11-18 03:42:02,620 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8657161092216318, 'Total loss': 0.8657161092216318} | train loss {'Reaction outcome loss': 0.828522597162091, 'Total loss': 0.828522597162091}
2022-11-18 03:42:02,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:02,620 INFO:     Epoch: 22
2022-11-18 03:42:03,389 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8652602881193161, 'Total loss': 0.8652602881193161} | train loss {'Reaction outcome loss': 0.827396825624972, 'Total loss': 0.827396825624972}
2022-11-18 03:42:03,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:03,390 INFO:     Epoch: 23
2022-11-18 03:42:04,152 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8632412065159191, 'Total loss': 0.8632412065159191} | train loss {'Reaction outcome loss': 0.8251474510650245, 'Total loss': 0.8251474510650245}
2022-11-18 03:42:04,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:04,152 INFO:     Epoch: 24
2022-11-18 03:42:04,952 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8696001429449428, 'Total loss': 0.8696001429449428} | train loss {'Reaction outcome loss': 0.8259515246566461, 'Total loss': 0.8259515246566461}
2022-11-18 03:42:04,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:04,953 INFO:     Epoch: 25
2022-11-18 03:42:05,733 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8602637499570847, 'Total loss': 0.8602637499570847} | train loss {'Reaction outcome loss': 0.8248783720999348, 'Total loss': 0.8248783720999348}
2022-11-18 03:42:05,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:05,733 INFO:     Epoch: 26
2022-11-18 03:42:06,489 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8525191111998125, 'Total loss': 0.8525191111998125} | train loss {'Reaction outcome loss': 0.8312550225428172, 'Total loss': 0.8312550225428172}
2022-11-18 03:42:06,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:06,490 INFO:     Epoch: 27
2022-11-18 03:42:07,266 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8402882624756206, 'Total loss': 0.8402882624756206} | train loss {'Reaction outcome loss': 0.8292887466294425, 'Total loss': 0.8292887466294425}
2022-11-18 03:42:07,267 INFO:     Found new best model at epoch 27
2022-11-18 03:42:07,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:07,268 INFO:     Epoch: 28
2022-11-18 03:42:08,035 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8630749556151304, 'Total loss': 0.8630749556151304} | train loss {'Reaction outcome loss': 0.8206722685268947, 'Total loss': 0.8206722685268947}
2022-11-18 03:42:08,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:08,035 INFO:     Epoch: 29
2022-11-18 03:42:08,813 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8502832027998838, 'Total loss': 0.8502832027998838} | train loss {'Reaction outcome loss': 0.8233332987950772, 'Total loss': 0.8233332987950772}
2022-11-18 03:42:08,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:08,813 INFO:     Epoch: 30
2022-11-18 03:42:09,588 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8438100496476347, 'Total loss': 0.8438100496476347} | train loss {'Reaction outcome loss': 0.8269278319514528, 'Total loss': 0.8269278319514528}
2022-11-18 03:42:09,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:09,589 INFO:     Epoch: 31
2022-11-18 03:42:10,372 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8481738838282499, 'Total loss': 0.8481738838282499} | train loss {'Reaction outcome loss': 0.8227464751321443, 'Total loss': 0.8227464751321443}
2022-11-18 03:42:10,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:10,372 INFO:     Epoch: 32
2022-11-18 03:42:11,155 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8546766361052339, 'Total loss': 0.8546766361052339} | train loss {'Reaction outcome loss': 0.8206906315015287, 'Total loss': 0.8206906315015287}
2022-11-18 03:42:11,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:11,156 INFO:     Epoch: 33
2022-11-18 03:42:11,919 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8384768268601461, 'Total loss': 0.8384768268601461} | train loss {'Reaction outcome loss': 0.8218123789344515, 'Total loss': 0.8218123789344515}
2022-11-18 03:42:11,919 INFO:     Found new best model at epoch 33
2022-11-18 03:42:11,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:11,920 INFO:     Epoch: 34
2022-11-18 03:42:12,677 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8541231534697793, 'Total loss': 0.8541231534697793} | train loss {'Reaction outcome loss': 0.8214321567087758, 'Total loss': 0.8214321567087758}
2022-11-18 03:42:12,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:12,678 INFO:     Epoch: 35
2022-11-18 03:42:13,449 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8523329909552227, 'Total loss': 0.8523329909552227} | train loss {'Reaction outcome loss': 0.822115698274301, 'Total loss': 0.822115698274301}
2022-11-18 03:42:13,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:13,450 INFO:     Epoch: 36
2022-11-18 03:42:14,222 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8421558846126903, 'Total loss': 0.8421558846126903} | train loss {'Reaction outcome loss': 0.8233399908153378, 'Total loss': 0.8233399908153378}
2022-11-18 03:42:14,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:14,222 INFO:     Epoch: 37
2022-11-18 03:42:15,007 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8515517142685977, 'Total loss': 0.8515517142685977} | train loss {'Reaction outcome loss': 0.8211923364473849, 'Total loss': 0.8211923364473849}
2022-11-18 03:42:15,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:15,007 INFO:     Epoch: 38
2022-11-18 03:42:15,759 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8378890414129604, 'Total loss': 0.8378890414129604} | train loss {'Reaction outcome loss': 0.8228475646096833, 'Total loss': 0.8228475646096833}
2022-11-18 03:42:15,760 INFO:     Found new best model at epoch 38
2022-11-18 03:42:15,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:15,760 INFO:     Epoch: 39
2022-11-18 03:42:16,555 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8647624213587154, 'Total loss': 0.8647624213587154} | train loss {'Reaction outcome loss': 0.825032418723009, 'Total loss': 0.825032418723009}
2022-11-18 03:42:16,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:16,555 INFO:     Epoch: 40
2022-11-18 03:42:17,325 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8436000150713053, 'Total loss': 0.8436000150713053} | train loss {'Reaction outcome loss': 0.8224099575865026, 'Total loss': 0.8224099575865026}
2022-11-18 03:42:17,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:17,327 INFO:     Epoch: 41
2022-11-18 03:42:18,128 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8388598662885752, 'Total loss': 0.8388598662885752} | train loss {'Reaction outcome loss': 0.8217024005189234, 'Total loss': 0.8217024005189234}
2022-11-18 03:42:18,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:18,129 INFO:     Epoch: 42
2022-11-18 03:42:18,892 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8417006920684468, 'Total loss': 0.8417006920684468} | train loss {'Reaction outcome loss': 0.8198613137614971, 'Total loss': 0.8198613137614971}
2022-11-18 03:42:18,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:18,892 INFO:     Epoch: 43
2022-11-18 03:42:19,676 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.853793625804511, 'Total loss': 0.853793625804511} | train loss {'Reaction outcome loss': 0.8193369993141719, 'Total loss': 0.8193369993141719}
2022-11-18 03:42:19,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:19,676 INFO:     Epoch: 44
2022-11-18 03:42:20,464 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8443889306350187, 'Total loss': 0.8443889306350187} | train loss {'Reaction outcome loss': 0.8212091426460111, 'Total loss': 0.8212091426460111}
2022-11-18 03:42:20,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:20,464 INFO:     Epoch: 45
2022-11-18 03:42:21,233 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8474370864304629, 'Total loss': 0.8474370864304629} | train loss {'Reaction outcome loss': 0.8193014916108579, 'Total loss': 0.8193014916108579}
2022-11-18 03:42:21,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:21,233 INFO:     Epoch: 46
2022-11-18 03:42:22,032 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8278796235946092, 'Total loss': 0.8278796235946092} | train loss {'Reaction outcome loss': 0.8179104944881128, 'Total loss': 0.8179104944881128}
2022-11-18 03:42:22,032 INFO:     Found new best model at epoch 46
2022-11-18 03:42:22,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:22,033 INFO:     Epoch: 47
2022-11-18 03:42:22,793 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8584211834452369, 'Total loss': 0.8584211834452369} | train loss {'Reaction outcome loss': 0.8198597823478737, 'Total loss': 0.8198597823478737}
2022-11-18 03:42:22,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:22,793 INFO:     Epoch: 48
2022-11-18 03:42:23,562 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8413760350509123, 'Total loss': 0.8413760350509123} | train loss {'Reaction outcome loss': 0.8242606137480054, 'Total loss': 0.8242606137480054}
2022-11-18 03:42:23,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:23,563 INFO:     Epoch: 49
2022-11-18 03:42:24,319 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.835180021145127, 'Total loss': 0.835180021145127} | train loss {'Reaction outcome loss': 0.8190765602248056, 'Total loss': 0.8190765602248056}
2022-11-18 03:42:24,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:24,319 INFO:     Epoch: 50
2022-11-18 03:42:25,088 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8506319976665757, 'Total loss': 0.8506319976665757} | train loss {'Reaction outcome loss': 0.8155277271660006, 'Total loss': 0.8155277271660006}
2022-11-18 03:42:25,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:25,089 INFO:     Epoch: 51
2022-11-18 03:42:25,876 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8610795072533868, 'Total loss': 0.8610795072533868} | train loss {'Reaction outcome loss': 0.8189226657760387, 'Total loss': 0.8189226657760387}
2022-11-18 03:42:25,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:25,876 INFO:     Epoch: 52
2022-11-18 03:42:26,656 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8351764665408568, 'Total loss': 0.8351764665408568} | train loss {'Reaction outcome loss': 0.8179323001783722, 'Total loss': 0.8179323001783722}
2022-11-18 03:42:26,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:26,656 INFO:     Epoch: 53
2022-11-18 03:42:27,426 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8444989763877608, 'Total loss': 0.8444989763877608} | train loss {'Reaction outcome loss': 0.8206527328004642, 'Total loss': 0.8206527328004642}
2022-11-18 03:42:27,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:27,426 INFO:     Epoch: 54
2022-11-18 03:42:28,200 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8620938062667847, 'Total loss': 0.8620938062667847} | train loss {'Reaction outcome loss': 0.8202716036718719, 'Total loss': 0.8202716036718719}
2022-11-18 03:42:28,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:28,200 INFO:     Epoch: 55
2022-11-18 03:42:28,988 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8363039046525955, 'Total loss': 0.8363039046525955} | train loss {'Reaction outcome loss': 0.8196164789248486, 'Total loss': 0.8196164789248486}
2022-11-18 03:42:28,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:28,988 INFO:     Epoch: 56
2022-11-18 03:42:29,775 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8603271259502931, 'Total loss': 0.8603271259502931} | train loss {'Reaction outcome loss': 0.8191760019380219, 'Total loss': 0.8191760019380219}
2022-11-18 03:42:29,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:29,776 INFO:     Epoch: 57
2022-11-18 03:42:30,545 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.854110177945007, 'Total loss': 0.854110177945007} | train loss {'Reaction outcome loss': 0.8179316863721731, 'Total loss': 0.8179316863721731}
2022-11-18 03:42:30,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:30,545 INFO:     Epoch: 58
2022-11-18 03:42:31,319 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.843512390147556, 'Total loss': 0.843512390147556} | train loss {'Reaction outcome loss': 0.8162045626007781, 'Total loss': 0.8162045626007781}
2022-11-18 03:42:31,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:31,319 INFO:     Epoch: 59
2022-11-18 03:42:32,101 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8466450680385936, 'Total loss': 0.8466450680385936} | train loss {'Reaction outcome loss': 0.8178902476417775, 'Total loss': 0.8178902476417775}
2022-11-18 03:42:32,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:32,102 INFO:     Epoch: 60
2022-11-18 03:42:32,846 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.842240421609445, 'Total loss': 0.842240421609445} | train loss {'Reaction outcome loss': 0.8180391688736117, 'Total loss': 0.8180391688736117}
2022-11-18 03:42:32,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:32,846 INFO:     Epoch: 61
2022-11-18 03:42:33,604 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8530618751590903, 'Total loss': 0.8530618751590903} | train loss {'Reaction outcome loss': 0.8242334270963864, 'Total loss': 0.8242334270963864}
2022-11-18 03:42:33,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:33,604 INFO:     Epoch: 62
2022-11-18 03:42:34,357 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.851913636380976, 'Total loss': 0.851913636380976} | train loss {'Reaction outcome loss': 0.8209594710749023, 'Total loss': 0.8209594710749023}
2022-11-18 03:42:34,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:34,358 INFO:     Epoch: 63
2022-11-18 03:42:35,131 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8324689262292602, 'Total loss': 0.8324689262292602} | train loss {'Reaction outcome loss': 0.8215011082133469, 'Total loss': 0.8215011082133469}
2022-11-18 03:42:35,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:35,132 INFO:     Epoch: 64
2022-11-18 03:42:35,894 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8274774768135764, 'Total loss': 0.8274774768135764} | train loss {'Reaction outcome loss': 0.8186667911860408, 'Total loss': 0.8186667911860408}
2022-11-18 03:42:35,895 INFO:     Found new best model at epoch 64
2022-11-18 03:42:35,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:35,895 INFO:     Epoch: 65
2022-11-18 03:42:36,692 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8449028811671517, 'Total loss': 0.8449028811671517} | train loss {'Reaction outcome loss': 0.8190536012454909, 'Total loss': 0.8190536012454909}
2022-11-18 03:42:36,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:36,693 INFO:     Epoch: 66
2022-11-18 03:42:37,436 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8314246169545434, 'Total loss': 0.8314246169545434} | train loss {'Reaction outcome loss': 0.8186974170256635, 'Total loss': 0.8186974170256635}
2022-11-18 03:42:37,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:37,436 INFO:     Epoch: 67
2022-11-18 03:42:38,204 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8482592349702661, 'Total loss': 0.8482592349702661} | train loss {'Reaction outcome loss': 0.8264671048339532, 'Total loss': 0.8264671048339532}
2022-11-18 03:42:38,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:38,204 INFO:     Epoch: 68
2022-11-18 03:42:38,955 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8562010337005962, 'Total loss': 0.8562010337005962} | train loss {'Reaction outcome loss': 0.8185516375668195, 'Total loss': 0.8185516375668195}
2022-11-18 03:42:38,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:38,955 INFO:     Epoch: 69
2022-11-18 03:42:39,753 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8598477217284116, 'Total loss': 0.8598477217284116} | train loss {'Reaction outcome loss': 0.8184169378815865, 'Total loss': 0.8184169378815865}
2022-11-18 03:42:39,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:39,754 INFO:     Epoch: 70
2022-11-18 03:42:40,536 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.9003742757168683, 'Total loss': 0.9003742757168683} | train loss {'Reaction outcome loss': 0.817669985914717, 'Total loss': 0.817669985914717}
2022-11-18 03:42:40,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:40,536 INFO:     Epoch: 71
2022-11-18 03:42:41,327 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8547620719129388, 'Total loss': 0.8547620719129388} | train loss {'Reaction outcome loss': 0.8214175461506357, 'Total loss': 0.8214175461506357}
2022-11-18 03:42:41,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:41,327 INFO:     Epoch: 72
2022-11-18 03:42:42,163 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8632337017492815, 'Total loss': 0.8632337017492815} | train loss {'Reaction outcome loss': 0.8163836796672976, 'Total loss': 0.8163836796672976}
2022-11-18 03:42:42,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:42,163 INFO:     Epoch: 73
2022-11-18 03:42:42,937 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.839672633192756, 'Total loss': 0.839672633192756} | train loss {'Reaction outcome loss': 0.8248624197074346, 'Total loss': 0.8248624197074346}
2022-11-18 03:42:42,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:42,938 INFO:     Epoch: 74
2022-11-18 03:42:43,727 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8558297990397974, 'Total loss': 0.8558297990397974} | train loss {'Reaction outcome loss': 0.8230052002230469, 'Total loss': 0.8230052002230469}
2022-11-18 03:42:43,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:43,727 INFO:     Epoch: 75
2022-11-18 03:42:44,531 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8397017107768492, 'Total loss': 0.8397017107768492} | train loss {'Reaction outcome loss': 0.8204616944400631, 'Total loss': 0.8204616944400631}
2022-11-18 03:42:44,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:44,531 INFO:     Epoch: 76
2022-11-18 03:42:45,356 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8470086821100928, 'Total loss': 0.8470086821100928} | train loss {'Reaction outcome loss': 0.8165014232907977, 'Total loss': 0.8165014232907977}
2022-11-18 03:42:45,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:45,356 INFO:     Epoch: 77
2022-11-18 03:42:46,167 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8820596770806746, 'Total loss': 0.8820596770806746} | train loss {'Reaction outcome loss': 0.8149097440194111, 'Total loss': 0.8149097440194111}
2022-11-18 03:42:46,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:46,167 INFO:     Epoch: 78
2022-11-18 03:42:46,941 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8458958559415557, 'Total loss': 0.8458958559415557} | train loss {'Reaction outcome loss': 0.8194533022082582, 'Total loss': 0.8194533022082582}
2022-11-18 03:42:46,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:46,941 INFO:     Epoch: 79
2022-11-18 03:42:47,786 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8505172878503799, 'Total loss': 0.8505172878503799} | train loss {'Reaction outcome loss': 0.8188284697581311, 'Total loss': 0.8188284697581311}
2022-11-18 03:42:47,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:47,786 INFO:     Epoch: 80
2022-11-18 03:42:48,608 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8410112417557023, 'Total loss': 0.8410112417557023} | train loss {'Reaction outcome loss': 0.8155064296965696, 'Total loss': 0.8155064296965696}
2022-11-18 03:42:48,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:48,610 INFO:     Epoch: 81
2022-11-18 03:42:49,424 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8371399275281213, 'Total loss': 0.8371399275281213} | train loss {'Reaction outcome loss': 0.8181310608678934, 'Total loss': 0.8181310608678934}
2022-11-18 03:42:49,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:49,424 INFO:     Epoch: 82
2022-11-18 03:42:50,269 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8415620144117962, 'Total loss': 0.8415620144117962} | train loss {'Reaction outcome loss': 0.8164126898561205, 'Total loss': 0.8164126898561205}
2022-11-18 03:42:50,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:50,270 INFO:     Epoch: 83
2022-11-18 03:42:51,059 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8331505385312167, 'Total loss': 0.8331505385312167} | train loss {'Reaction outcome loss': 0.8221279860759269, 'Total loss': 0.8221279860759269}
2022-11-18 03:42:51,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:51,059 INFO:     Epoch: 84
2022-11-18 03:42:51,851 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.841083285483447, 'Total loss': 0.841083285483447} | train loss {'Reaction outcome loss': 0.8204041523592812, 'Total loss': 0.8204041523592812}
2022-11-18 03:42:51,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:51,852 INFO:     Epoch: 85
2022-11-18 03:42:52,669 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8732532418586991, 'Total loss': 0.8732532418586991} | train loss {'Reaction outcome loss': 0.8138670634250251, 'Total loss': 0.8138670634250251}
2022-11-18 03:42:52,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:52,669 INFO:     Epoch: 86
2022-11-18 03:42:53,481 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8350505158305168, 'Total loss': 0.8350505158305168} | train loss {'Reaction outcome loss': 0.8174310184254938, 'Total loss': 0.8174310184254938}
2022-11-18 03:42:53,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:53,482 INFO:     Epoch: 87
2022-11-18 03:42:54,286 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8402788964184847, 'Total loss': 0.8402788964184847} | train loss {'Reaction outcome loss': 0.818646908292965, 'Total loss': 0.818646908292965}
2022-11-18 03:42:54,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:54,286 INFO:     Epoch: 88
2022-11-18 03:42:55,097 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8426591916517778, 'Total loss': 0.8426591916517778} | train loss {'Reaction outcome loss': 0.8176840450082506, 'Total loss': 0.8176840450082506}
2022-11-18 03:42:55,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:55,098 INFO:     Epoch: 89
2022-11-18 03:42:55,897 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8326156125827269, 'Total loss': 0.8326156125827269} | train loss {'Reaction outcome loss': 0.8173466046245731, 'Total loss': 0.8173466046245731}
2022-11-18 03:42:55,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:55,898 INFO:     Epoch: 90
2022-11-18 03:42:56,724 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8419118103655902, 'Total loss': 0.8419118103655902} | train loss {'Reaction outcome loss': 0.8161648992373018, 'Total loss': 0.8161648992373018}
2022-11-18 03:42:56,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:56,724 INFO:     Epoch: 91
2022-11-18 03:42:57,567 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8572412417693571, 'Total loss': 0.8572412417693571} | train loss {'Reaction outcome loss': 0.8167654598245815, 'Total loss': 0.8167654598245815}
2022-11-18 03:42:57,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:57,568 INFO:     Epoch: 92
2022-11-18 03:42:58,368 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8341284062374722, 'Total loss': 0.8341284062374722} | train loss {'Reaction outcome loss': 0.8131158023464437, 'Total loss': 0.8131158023464437}
2022-11-18 03:42:58,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:58,368 INFO:     Epoch: 93
2022-11-18 03:42:59,167 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8467274416576732, 'Total loss': 0.8467274416576732} | train loss {'Reaction outcome loss': 0.8192048334345525, 'Total loss': 0.8192048334345525}
2022-11-18 03:42:59,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:59,167 INFO:     Epoch: 94
2022-11-18 03:42:59,963 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8643875460733067, 'Total loss': 0.8643875460733067} | train loss {'Reaction outcome loss': 0.813349964910624, 'Total loss': 0.813349964910624}
2022-11-18 03:42:59,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:42:59,964 INFO:     Epoch: 95
2022-11-18 03:43:00,787 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8588067997585643, 'Total loss': 0.8588067997585643} | train loss {'Reaction outcome loss': 0.8171319253590642, 'Total loss': 0.8171319253590642}
2022-11-18 03:43:00,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:00,787 INFO:     Epoch: 96
2022-11-18 03:43:01,578 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8611768782138824, 'Total loss': 0.8611768782138824} | train loss {'Reaction outcome loss': 0.8170976715428488, 'Total loss': 0.8170976715428488}
2022-11-18 03:43:01,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:01,578 INFO:     Epoch: 97
2022-11-18 03:43:02,389 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8368539945645765, 'Total loss': 0.8368539945645765} | train loss {'Reaction outcome loss': 0.8206551338945116, 'Total loss': 0.8206551338945116}
2022-11-18 03:43:02,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:02,389 INFO:     Epoch: 98
2022-11-18 03:43:03,200 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.858429070900787, 'Total loss': 0.858429070900787} | train loss {'Reaction outcome loss': 0.8124464308728977, 'Total loss': 0.8124464308728977}
2022-11-18 03:43:03,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:03,201 INFO:     Epoch: 99
2022-11-18 03:43:04,018 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8458342531865294, 'Total loss': 0.8458342531865294} | train loss {'Reaction outcome loss': 0.8143349742402836, 'Total loss': 0.8143349742402836}
2022-11-18 03:43:04,018 INFO:     Best model found after epoch 65 of 100.
2022-11-18 03:43:04,019 INFO:   Done with stage: TRAINING
2022-11-18 03:43:04,019 INFO:   Starting stage: EVALUATION
2022-11-18 03:43:04,147 INFO:   Done with stage: EVALUATION
2022-11-18 03:43:04,148 INFO:   Leaving out SEQ value Fold_6
2022-11-18 03:43:04,160 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:43:04,161 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:43:04,838 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:43:04,838 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:43:04,912 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:43:04,912 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:43:04,912 INFO:     No hyperparam tuning for this model
2022-11-18 03:43:04,912 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:43:04,912 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:43:04,913 INFO:     None feature selector for col prot
2022-11-18 03:43:04,914 INFO:     None feature selector for col prot
2022-11-18 03:43:04,914 INFO:     None feature selector for col prot
2022-11-18 03:43:04,914 INFO:     None feature selector for col chem
2022-11-18 03:43:04,914 INFO:     None feature selector for col chem
2022-11-18 03:43:04,915 INFO:     None feature selector for col chem
2022-11-18 03:43:04,915 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:43:04,915 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:43:04,916 INFO:     Number of params in model 168571
2022-11-18 03:43:04,920 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:43:04,920 INFO:   Starting stage: TRAINING
2022-11-18 03:43:04,978 INFO:     Val loss before train {'Reaction outcome loss': 1.0090875882994046, 'Total loss': 1.0090875882994046}
2022-11-18 03:43:04,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:04,978 INFO:     Epoch: 0
2022-11-18 03:43:05,763 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8790667409246619, 'Total loss': 0.8790667409246619} | train loss {'Reaction outcome loss': 0.8876144142160493, 'Total loss': 0.8876144142160493}
2022-11-18 03:43:05,763 INFO:     Found new best model at epoch 0
2022-11-18 03:43:05,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:05,764 INFO:     Epoch: 1
2022-11-18 03:43:06,589 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8112230497327718, 'Total loss': 0.8112230497327718} | train loss {'Reaction outcome loss': 0.8545042799124795, 'Total loss': 0.8545042799124795}
2022-11-18 03:43:06,589 INFO:     Found new best model at epoch 1
2022-11-18 03:43:06,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:06,590 INFO:     Epoch: 2
2022-11-18 03:43:07,337 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8192086314613168, 'Total loss': 0.8192086314613168} | train loss {'Reaction outcome loss': 0.8425790208481974, 'Total loss': 0.8425790208481974}
2022-11-18 03:43:07,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:07,339 INFO:     Epoch: 3
2022-11-18 03:43:08,139 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8236860456791791, 'Total loss': 0.8236860456791791} | train loss {'Reaction outcome loss': 0.8470266183778163, 'Total loss': 0.8470266183778163}
2022-11-18 03:43:08,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:08,139 INFO:     Epoch: 4
2022-11-18 03:43:08,935 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8101789626208219, 'Total loss': 0.8101789626208219} | train loss {'Reaction outcome loss': 0.8402598985741215, 'Total loss': 0.8402598985741215}
2022-11-18 03:43:08,935 INFO:     Found new best model at epoch 4
2022-11-18 03:43:08,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:08,936 INFO:     Epoch: 5
2022-11-18 03:43:09,741 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8056219301440499, 'Total loss': 0.8056219301440499} | train loss {'Reaction outcome loss': 0.8324840345209644, 'Total loss': 0.8324840345209644}
2022-11-18 03:43:09,741 INFO:     Found new best model at epoch 5
2022-11-18 03:43:09,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:09,742 INFO:     Epoch: 6
2022-11-18 03:43:10,543 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.795136879790913, 'Total loss': 0.795136879790913} | train loss {'Reaction outcome loss': 0.8318724483251572, 'Total loss': 0.8318724483251572}
2022-11-18 03:43:10,543 INFO:     Found new best model at epoch 6
2022-11-18 03:43:10,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:10,544 INFO:     Epoch: 7
2022-11-18 03:43:11,350 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8083917234431613, 'Total loss': 0.8083917234431613} | train loss {'Reaction outcome loss': 0.8289966369348187, 'Total loss': 0.8289966369348187}
2022-11-18 03:43:11,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:11,350 INFO:     Epoch: 8
2022-11-18 03:43:12,165 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7940979559313167, 'Total loss': 0.7940979559313167} | train loss {'Reaction outcome loss': 0.8249465525150299, 'Total loss': 0.8249465525150299}
2022-11-18 03:43:12,165 INFO:     Found new best model at epoch 8
2022-11-18 03:43:12,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:12,166 INFO:     Epoch: 9
2022-11-18 03:43:12,996 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7968838634816083, 'Total loss': 0.7968838634816083} | train loss {'Reaction outcome loss': 0.831105437129736, 'Total loss': 0.831105437129736}
2022-11-18 03:43:12,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:12,996 INFO:     Epoch: 10
2022-11-18 03:43:13,824 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8020911006764933, 'Total loss': 0.8020911006764933} | train loss {'Reaction outcome loss': 0.8256451276040846, 'Total loss': 0.8256451276040846}
2022-11-18 03:43:13,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:13,824 INFO:     Epoch: 11
2022-11-18 03:43:14,654 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8007803891192783, 'Total loss': 0.8007803891192783} | train loss {'Reaction outcome loss': 0.8257601620449174, 'Total loss': 0.8257601620449174}
2022-11-18 03:43:14,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:14,655 INFO:     Epoch: 12
2022-11-18 03:43:15,471 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8105170103636655, 'Total loss': 0.8105170103636655} | train loss {'Reaction outcome loss': 0.8251252649051528, 'Total loss': 0.8251252649051528}
2022-11-18 03:43:15,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:15,471 INFO:     Epoch: 13
2022-11-18 03:43:16,305 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7934114851734855, 'Total loss': 0.7934114851734855} | train loss {'Reaction outcome loss': 0.8210108865412974, 'Total loss': 0.8210108865412974}
2022-11-18 03:43:16,305 INFO:     Found new best model at epoch 13
2022-11-18 03:43:16,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:16,306 INFO:     Epoch: 14
2022-11-18 03:43:17,119 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8053872111168775, 'Total loss': 0.8053872111168775} | train loss {'Reaction outcome loss': 0.8214676559211747, 'Total loss': 0.8214676559211747}
2022-11-18 03:43:17,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:17,119 INFO:     Epoch: 15
2022-11-18 03:43:17,913 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8098929822444916, 'Total loss': 0.8098929822444916} | train loss {'Reaction outcome loss': 0.8237902436765933, 'Total loss': 0.8237902436765933}
2022-11-18 03:43:17,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:17,913 INFO:     Epoch: 16
2022-11-18 03:43:18,713 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.81379714675925, 'Total loss': 0.81379714675925} | train loss {'Reaction outcome loss': 0.8243514379907039, 'Total loss': 0.8243514379907039}
2022-11-18 03:43:18,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:18,713 INFO:     Epoch: 17
2022-11-18 03:43:19,571 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7941865257241509, 'Total loss': 0.7941865257241509} | train loss {'Reaction outcome loss': 0.8251271344000294, 'Total loss': 0.8251271344000294}
2022-11-18 03:43:19,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:19,573 INFO:     Epoch: 18
2022-11-18 03:43:20,410 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7884527858008038, 'Total loss': 0.7884527858008038} | train loss {'Reaction outcome loss': 0.8213583621526918, 'Total loss': 0.8213583621526918}
2022-11-18 03:43:20,410 INFO:     Found new best model at epoch 18
2022-11-18 03:43:20,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:20,411 INFO:     Epoch: 19
2022-11-18 03:43:21,210 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8114085739309137, 'Total loss': 0.8114085739309137} | train loss {'Reaction outcome loss': 0.8228143852564597, 'Total loss': 0.8228143852564597}
2022-11-18 03:43:21,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:21,210 INFO:     Epoch: 20
2022-11-18 03:43:22,005 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.801244743168354, 'Total loss': 0.801244743168354} | train loss {'Reaction outcome loss': 0.8212701363428947, 'Total loss': 0.8212701363428947}
2022-11-18 03:43:22,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:22,006 INFO:     Epoch: 21
2022-11-18 03:43:22,823 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7889938185160811, 'Total loss': 0.7889938185160811} | train loss {'Reaction outcome loss': 0.8191974896096414, 'Total loss': 0.8191974896096414}
2022-11-18 03:43:22,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:22,823 INFO:     Epoch: 22
2022-11-18 03:43:23,624 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8142593970352953, 'Total loss': 0.8142593970352953} | train loss {'Reaction outcome loss': 0.8199766745730754, 'Total loss': 0.8199766745730754}
2022-11-18 03:43:23,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:23,624 INFO:     Epoch: 23
2022-11-18 03:43:24,396 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8096675276756287, 'Total loss': 0.8096675276756287} | train loss {'Reaction outcome loss': 0.8221562778757464, 'Total loss': 0.8221562778757464}
2022-11-18 03:43:24,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:24,396 INFO:     Epoch: 24
2022-11-18 03:43:25,204 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7969805964014747, 'Total loss': 0.7969805964014747} | train loss {'Reaction outcome loss': 0.8221045660395776, 'Total loss': 0.8221045660395776}
2022-11-18 03:43:25,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:25,205 INFO:     Epoch: 25
2022-11-18 03:43:25,980 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7885217754678293, 'Total loss': 0.7885217754678293} | train loss {'Reaction outcome loss': 0.8194841803802598, 'Total loss': 0.8194841803802598}
2022-11-18 03:43:25,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:25,982 INFO:     Epoch: 26
2022-11-18 03:43:26,798 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7838892130689188, 'Total loss': 0.7838892130689188} | train loss {'Reaction outcome loss': 0.8177261233570114, 'Total loss': 0.8177261233570114}
2022-11-18 03:43:26,798 INFO:     Found new best model at epoch 26
2022-11-18 03:43:26,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:26,799 INFO:     Epoch: 27
2022-11-18 03:43:27,617 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7855637242848222, 'Total loss': 0.7855637242848222} | train loss {'Reaction outcome loss': 0.8227945754845296, 'Total loss': 0.8227945754845296}
2022-11-18 03:43:27,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:27,617 INFO:     Epoch: 28
2022-11-18 03:43:28,450 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8130482543598522, 'Total loss': 0.8130482543598522} | train loss {'Reaction outcome loss': 0.8193471936448928, 'Total loss': 0.8193471936448928}
2022-11-18 03:43:28,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:28,450 INFO:     Epoch: 29
2022-11-18 03:43:29,280 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7795734276825731, 'Total loss': 0.7795734276825731} | train loss {'Reaction outcome loss': 0.8217328453977262, 'Total loss': 0.8217328453977262}
2022-11-18 03:43:29,280 INFO:     Found new best model at epoch 29
2022-11-18 03:43:29,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:29,281 INFO:     Epoch: 30
2022-11-18 03:43:30,086 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7999457540837202, 'Total loss': 0.7999457540837202} | train loss {'Reaction outcome loss': 0.8168137015834931, 'Total loss': 0.8168137015834931}
2022-11-18 03:43:30,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:30,086 INFO:     Epoch: 31
2022-11-18 03:43:30,939 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.809721328318119, 'Total loss': 0.809721328318119} | train loss {'Reaction outcome loss': 0.8181886657351448, 'Total loss': 0.8181886657351448}
2022-11-18 03:43:30,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:30,940 INFO:     Epoch: 32
2022-11-18 03:43:31,754 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7920702689073302, 'Total loss': 0.7920702689073302} | train loss {'Reaction outcome loss': 0.8179434260293361, 'Total loss': 0.8179434260293361}
2022-11-18 03:43:31,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:31,754 INFO:     Epoch: 33
2022-11-18 03:43:32,560 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7873748960820112, 'Total loss': 0.7873748960820112} | train loss {'Reaction outcome loss': 0.8184107236804501, 'Total loss': 0.8184107236804501}
2022-11-18 03:43:32,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:32,560 INFO:     Epoch: 34
2022-11-18 03:43:33,345 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7772893031889742, 'Total loss': 0.7772893031889742} | train loss {'Reaction outcome loss': 0.8188837158583826, 'Total loss': 0.8188837158583826}
2022-11-18 03:43:33,346 INFO:     Found new best model at epoch 34
2022-11-18 03:43:33,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:33,346 INFO:     Epoch: 35
2022-11-18 03:43:34,131 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7863097502426668, 'Total loss': 0.7863097502426668} | train loss {'Reaction outcome loss': 0.8206975591038504, 'Total loss': 0.8206975591038504}
2022-11-18 03:43:34,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:34,132 INFO:     Epoch: 36
2022-11-18 03:43:34,919 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8073885616931048, 'Total loss': 0.8073885616931048} | train loss {'Reaction outcome loss': 0.8161212947339781, 'Total loss': 0.8161212947339781}
2022-11-18 03:43:34,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:34,919 INFO:     Epoch: 37
2022-11-18 03:43:35,733 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7883853370493109, 'Total loss': 0.7883853370493109} | train loss {'Reaction outcome loss': 0.8191646843427612, 'Total loss': 0.8191646843427612}
2022-11-18 03:43:35,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:35,733 INFO:     Epoch: 38
2022-11-18 03:43:36,534 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.796835335818204, 'Total loss': 0.796835335818204} | train loss {'Reaction outcome loss': 0.8174682832773654, 'Total loss': 0.8174682832773654}
2022-11-18 03:43:36,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:36,534 INFO:     Epoch: 39
2022-11-18 03:43:37,354 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7864011038433422, 'Total loss': 0.7864011038433422} | train loss {'Reaction outcome loss': 0.8185870824081283, 'Total loss': 0.8185870824081283}
2022-11-18 03:43:37,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:37,354 INFO:     Epoch: 40
2022-11-18 03:43:38,119 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8049443384463136, 'Total loss': 0.8049443384463136} | train loss {'Reaction outcome loss': 0.8187873499287713, 'Total loss': 0.8187873499287713}
2022-11-18 03:43:38,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:38,120 INFO:     Epoch: 41
2022-11-18 03:43:38,957 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7912383296272971, 'Total loss': 0.7912383296272971} | train loss {'Reaction outcome loss': 0.8159019131093256, 'Total loss': 0.8159019131093256}
2022-11-18 03:43:38,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:38,957 INFO:     Epoch: 42
2022-11-18 03:43:39,775 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.777856972407211, 'Total loss': 0.777856972407211} | train loss {'Reaction outcome loss': 0.8196540092748981, 'Total loss': 0.8196540092748981}
2022-11-18 03:43:39,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:39,775 INFO:     Epoch: 43
2022-11-18 03:43:40,554 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7883578010580756, 'Total loss': 0.7883578010580756} | train loss {'Reaction outcome loss': 0.8129755593836308, 'Total loss': 0.8129755593836308}
2022-11-18 03:43:40,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:40,554 INFO:     Epoch: 44
2022-11-18 03:43:41,333 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8863861283118074, 'Total loss': 0.8863861283118074} | train loss {'Reaction outcome loss': 0.8215030497841297, 'Total loss': 0.8215030497841297}
2022-11-18 03:43:41,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:41,333 INFO:     Epoch: 45
2022-11-18 03:43:42,118 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7832633554935455, 'Total loss': 0.7832633554935455} | train loss {'Reaction outcome loss': 0.8185811694110593, 'Total loss': 0.8185811694110593}
2022-11-18 03:43:42,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:42,119 INFO:     Epoch: 46
2022-11-18 03:43:42,903 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8010106296701864, 'Total loss': 0.8010106296701864} | train loss {'Reaction outcome loss': 0.8171636453799663, 'Total loss': 0.8171636453799663}
2022-11-18 03:43:42,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:42,903 INFO:     Epoch: 47
2022-11-18 03:43:43,678 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8113014894452962, 'Total loss': 0.8113014894452962} | train loss {'Reaction outcome loss': 0.8150504382867967, 'Total loss': 0.8150504382867967}
2022-11-18 03:43:43,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:43,678 INFO:     Epoch: 48
2022-11-18 03:43:44,465 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7833462899381464, 'Total loss': 0.7833462899381464} | train loss {'Reaction outcome loss': 0.8142555652847213, 'Total loss': 0.8142555652847213}
2022-11-18 03:43:44,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:44,466 INFO:     Epoch: 49
2022-11-18 03:43:45,257 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.780326509340243, 'Total loss': 0.780326509340243} | train loss {'Reaction outcome loss': 0.8174829583975577, 'Total loss': 0.8174829583975577}
2022-11-18 03:43:45,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:45,258 INFO:     Epoch: 50
2022-11-18 03:43:46,055 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7842268219048326, 'Total loss': 0.7842268219048326} | train loss {'Reaction outcome loss': 0.8209707412508226, 'Total loss': 0.8209707412508226}
2022-11-18 03:43:46,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:46,055 INFO:     Epoch: 51
2022-11-18 03:43:46,862 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7881163731217384, 'Total loss': 0.7881163731217384} | train loss {'Reaction outcome loss': 0.8163842024101365, 'Total loss': 0.8163842024101365}
2022-11-18 03:43:46,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:46,862 INFO:     Epoch: 52
2022-11-18 03:43:47,657 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7889547713778235, 'Total loss': 0.7889547713778235} | train loss {'Reaction outcome loss': 0.8168866543039199, 'Total loss': 0.8168866543039199}
2022-11-18 03:43:47,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:47,657 INFO:     Epoch: 53
2022-11-18 03:43:48,460 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7955919822508638, 'Total loss': 0.7955919822508638} | train loss {'Reaction outcome loss': 0.8134289754013861, 'Total loss': 0.8134289754013861}
2022-11-18 03:43:48,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:48,461 INFO:     Epoch: 54
2022-11-18 03:43:49,245 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7820400893688202, 'Total loss': 0.7820400893688202} | train loss {'Reaction outcome loss': 0.8190956661297429, 'Total loss': 0.8190956661297429}
2022-11-18 03:43:49,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:49,246 INFO:     Epoch: 55
2022-11-18 03:43:50,050 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8000876727429304, 'Total loss': 0.8000876727429304} | train loss {'Reaction outcome loss': 0.8147327515386766, 'Total loss': 0.8147327515386766}
2022-11-18 03:43:50,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:50,052 INFO:     Epoch: 56
2022-11-18 03:43:50,850 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8067728484218771, 'Total loss': 0.8067728484218771} | train loss {'Reaction outcome loss': 0.816650353732609, 'Total loss': 0.816650353732609}
2022-11-18 03:43:50,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:50,850 INFO:     Epoch: 57
2022-11-18 03:43:51,634 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7844995348290964, 'Total loss': 0.7844995348290964} | train loss {'Reaction outcome loss': 0.8144740660584742, 'Total loss': 0.8144740660584742}
2022-11-18 03:43:51,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:51,634 INFO:     Epoch: 58
2022-11-18 03:43:52,423 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7801350714130835, 'Total loss': 0.7801350714130835} | train loss {'Reaction outcome loss': 0.8206869845669116, 'Total loss': 0.8206869845669116}
2022-11-18 03:43:52,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:52,423 INFO:     Epoch: 59
2022-11-18 03:43:53,180 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.779276692731814, 'Total loss': 0.779276692731814} | train loss {'Reaction outcome loss': 0.8118373641083317, 'Total loss': 0.8118373641083317}
2022-11-18 03:43:53,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:53,180 INFO:     Epoch: 60
2022-11-18 03:43:53,968 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7985805455933918, 'Total loss': 0.7985805455933918} | train loss {'Reaction outcome loss': 0.8141924640344035, 'Total loss': 0.8141924640344035}
2022-11-18 03:43:53,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:53,969 INFO:     Epoch: 61
2022-11-18 03:43:54,743 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.787986006249081, 'Total loss': 0.787986006249081} | train loss {'Reaction outcome loss': 0.820934469661405, 'Total loss': 0.820934469661405}
2022-11-18 03:43:54,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:54,743 INFO:     Epoch: 62
2022-11-18 03:43:55,548 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.783675567670302, 'Total loss': 0.783675567670302} | train loss {'Reaction outcome loss': 0.8147264937719991, 'Total loss': 0.8147264937719991}
2022-11-18 03:43:55,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:55,548 INFO:     Epoch: 63
2022-11-18 03:43:56,338 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7735426649451256, 'Total loss': 0.7735426649451256} | train loss {'Reaction outcome loss': 0.8129607187884469, 'Total loss': 0.8129607187884469}
2022-11-18 03:43:56,338 INFO:     Found new best model at epoch 63
2022-11-18 03:43:56,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:56,339 INFO:     Epoch: 64
2022-11-18 03:43:57,102 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7812362624840303, 'Total loss': 0.7812362624840303} | train loss {'Reaction outcome loss': 0.8176051550094159, 'Total loss': 0.8176051550094159}
2022-11-18 03:43:57,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:57,102 INFO:     Epoch: 65
2022-11-18 03:43:57,903 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.785729895261201, 'Total loss': 0.785729895261201} | train loss {'Reaction outcome loss': 0.8110389077375012, 'Total loss': 0.8110389077375012}
2022-11-18 03:43:57,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:57,903 INFO:     Epoch: 66
2022-11-18 03:43:58,692 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7896107353947379, 'Total loss': 0.7896107353947379} | train loss {'Reaction outcome loss': 0.8154808185513942, 'Total loss': 0.8154808185513942}
2022-11-18 03:43:58,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:58,692 INFO:     Epoch: 67
2022-11-18 03:43:59,458 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7835396866906773, 'Total loss': 0.7835396866906773} | train loss {'Reaction outcome loss': 0.8078167770178087, 'Total loss': 0.8078167770178087}
2022-11-18 03:43:59,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:43:59,458 INFO:     Epoch: 68
2022-11-18 03:44:00,285 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7768105275251649, 'Total loss': 0.7768105275251649} | train loss {'Reaction outcome loss': 0.8177823651461832, 'Total loss': 0.8177823651461832}
2022-11-18 03:44:00,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:00,285 INFO:     Epoch: 69
2022-11-18 03:44:01,082 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7868491092866118, 'Total loss': 0.7868491092866118} | train loss {'Reaction outcome loss': 0.8160973590227866, 'Total loss': 0.8160973590227866}
2022-11-18 03:44:01,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:01,083 INFO:     Epoch: 70
2022-11-18 03:44:01,897 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7714406265453859, 'Total loss': 0.7714406265453859} | train loss {'Reaction outcome loss': 0.8111852685049656, 'Total loss': 0.8111852685049656}
2022-11-18 03:44:01,897 INFO:     Found new best model at epoch 70
2022-11-18 03:44:01,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:01,898 INFO:     Epoch: 71
2022-11-18 03:44:02,704 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7905294461683794, 'Total loss': 0.7905294461683794} | train loss {'Reaction outcome loss': 0.812445139211993, 'Total loss': 0.812445139211993}
2022-11-18 03:44:02,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:02,704 INFO:     Epoch: 72
2022-11-18 03:44:03,468 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7829016961834647, 'Total loss': 0.7829016961834647} | train loss {'Reaction outcome loss': 0.8156284363039078, 'Total loss': 0.8156284363039078}
2022-11-18 03:44:03,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:03,469 INFO:     Epoch: 73
2022-11-18 03:44:04,241 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.784438050606034, 'Total loss': 0.784438050606034} | train loss {'Reaction outcome loss': 0.8139919096664074, 'Total loss': 0.8139919096664074}
2022-11-18 03:44:04,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:04,241 INFO:     Epoch: 74
2022-11-18 03:44:05,024 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7863528369502588, 'Total loss': 0.7863528369502588} | train loss {'Reaction outcome loss': 0.8117732584716812, 'Total loss': 0.8117732584716812}
2022-11-18 03:44:05,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:05,025 INFO:     Epoch: 75
2022-11-18 03:44:05,790 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7883754433556036, 'Total loss': 0.7883754433556036} | train loss {'Reaction outcome loss': 0.8144532400033166, 'Total loss': 0.8144532400033166}
2022-11-18 03:44:05,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:05,791 INFO:     Epoch: 76
2022-11-18 03:44:06,583 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7939999310130422, 'Total loss': 0.7939999310130422} | train loss {'Reaction outcome loss': 0.8116766721490891, 'Total loss': 0.8116766721490891}
2022-11-18 03:44:06,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:06,583 INFO:     Epoch: 77
2022-11-18 03:44:07,368 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7981335100802508, 'Total loss': 0.7981335100802508} | train loss {'Reaction outcome loss': 0.8155473220732904, 'Total loss': 0.8155473220732904}
2022-11-18 03:44:07,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:07,369 INFO:     Epoch: 78
2022-11-18 03:44:08,130 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7880345711653883, 'Total loss': 0.7880345711653883} | train loss {'Reaction outcome loss': 0.8121016150520693, 'Total loss': 0.8121016150520693}
2022-11-18 03:44:08,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:08,130 INFO:     Epoch: 79
2022-11-18 03:44:08,914 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7877751622687686, 'Total loss': 0.7877751622687686} | train loss {'Reaction outcome loss': 0.8155378591149084, 'Total loss': 0.8155378591149084}
2022-11-18 03:44:08,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:08,915 INFO:     Epoch: 80
2022-11-18 03:44:09,689 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7995467795567079, 'Total loss': 0.7995467795567079} | train loss {'Reaction outcome loss': 0.8095149538449703, 'Total loss': 0.8095149538449703}
2022-11-18 03:44:09,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:09,690 INFO:     Epoch: 81
2022-11-18 03:44:10,472 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8113753572106361, 'Total loss': 0.8113753572106361} | train loss {'Reaction outcome loss': 0.8065345900794191, 'Total loss': 0.8065345900794191}
2022-11-18 03:44:10,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:10,472 INFO:     Epoch: 82
2022-11-18 03:44:11,249 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8043146932666952, 'Total loss': 0.8043146932666952} | train loss {'Reaction outcome loss': 0.8113709953763792, 'Total loss': 0.8113709953763792}
2022-11-18 03:44:11,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:11,249 INFO:     Epoch: 83
2022-11-18 03:44:12,045 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7764868512749672, 'Total loss': 0.7764868512749672} | train loss {'Reaction outcome loss': 0.8120886943633517, 'Total loss': 0.8120886943633517}
2022-11-18 03:44:12,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:12,045 INFO:     Epoch: 84
2022-11-18 03:44:12,845 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7779824672774835, 'Total loss': 0.7779824672774835} | train loss {'Reaction outcome loss': 0.8075629352561889, 'Total loss': 0.8075629352561889}
2022-11-18 03:44:12,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:12,845 INFO:     Epoch: 85
2022-11-18 03:44:13,600 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7931311787529425, 'Total loss': 0.7931311787529425} | train loss {'Reaction outcome loss': 0.812222164965445, 'Total loss': 0.812222164965445}
2022-11-18 03:44:13,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:13,600 INFO:     Epoch: 86
2022-11-18 03:44:14,403 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7787083238363266, 'Total loss': 0.7787083238363266} | train loss {'Reaction outcome loss': 0.8138513948407865, 'Total loss': 0.8138513948407865}
2022-11-18 03:44:14,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:14,403 INFO:     Epoch: 87
2022-11-18 03:44:15,200 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7741192233833399, 'Total loss': 0.7741192233833399} | train loss {'Reaction outcome loss': 0.8099814350566557, 'Total loss': 0.8099814350566557}
2022-11-18 03:44:15,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:15,200 INFO:     Epoch: 88
2022-11-18 03:44:15,984 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7763569761406292, 'Total loss': 0.7763569761406292} | train loss {'Reaction outcome loss': 0.8079409986253707, 'Total loss': 0.8079409986253707}
2022-11-18 03:44:15,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:15,984 INFO:     Epoch: 89
2022-11-18 03:44:16,769 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7829382006417621, 'Total loss': 0.7829382006417621} | train loss {'Reaction outcome loss': 0.8076770436619559, 'Total loss': 0.8076770436619559}
2022-11-18 03:44:16,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:16,769 INFO:     Epoch: 90
2022-11-18 03:44:17,572 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8100812008435075, 'Total loss': 0.8100812008435075} | train loss {'Reaction outcome loss': 0.8096831765987219, 'Total loss': 0.8096831765987219}
2022-11-18 03:44:17,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:17,572 INFO:     Epoch: 91
2022-11-18 03:44:18,372 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7801607975905592, 'Total loss': 0.7801607975905592} | train loss {'Reaction outcome loss': 0.8098731492796252, 'Total loss': 0.8098731492796252}
2022-11-18 03:44:18,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:18,372 INFO:     Epoch: 92
2022-11-18 03:44:19,143 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7861901860345494, 'Total loss': 0.7861901860345494} | train loss {'Reaction outcome loss': 0.8064724641942209, 'Total loss': 0.8064724641942209}
2022-11-18 03:44:19,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:19,143 INFO:     Epoch: 93
2022-11-18 03:44:19,906 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7788146903569048, 'Total loss': 0.7788146903569048} | train loss {'Reaction outcome loss': 0.8076779854393774, 'Total loss': 0.8076779854393774}
2022-11-18 03:44:19,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:19,907 INFO:     Epoch: 94
2022-11-18 03:44:20,689 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7785498269579627, 'Total loss': 0.7785498269579627} | train loss {'Reaction outcome loss': 0.8088589319058003, 'Total loss': 0.8088589319058003}
2022-11-18 03:44:20,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:20,690 INFO:     Epoch: 95
2022-11-18 03:44:21,452 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7726158899339762, 'Total loss': 0.7726158899339762} | train loss {'Reaction outcome loss': 0.8154278159622224, 'Total loss': 0.8154278159622224}
2022-11-18 03:44:21,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:21,454 INFO:     Epoch: 96
2022-11-18 03:44:22,216 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7882343449375846, 'Total loss': 0.7882343449375846} | train loss {'Reaction outcome loss': 0.8136138736360496, 'Total loss': 0.8136138736360496}
2022-11-18 03:44:22,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:22,216 INFO:     Epoch: 97
2022-11-18 03:44:23,041 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7820243151350454, 'Total loss': 0.7820243151350454} | train loss {'Reaction outcome loss': 0.8094504855332836, 'Total loss': 0.8094504855332836}
2022-11-18 03:44:23,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:23,041 INFO:     Epoch: 98
2022-11-18 03:44:23,866 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7860029095953162, 'Total loss': 0.7860029095953162} | train loss {'Reaction outcome loss': 0.8068863946583963, 'Total loss': 0.8068863946583963}
2022-11-18 03:44:23,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:23,867 INFO:     Epoch: 99
2022-11-18 03:44:24,666 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7794570882212032, 'Total loss': 0.7794570882212032} | train loss {'Reaction outcome loss': 0.809599929158726, 'Total loss': 0.809599929158726}
2022-11-18 03:44:24,666 INFO:     Best model found after epoch 71 of 100.
2022-11-18 03:44:24,667 INFO:   Done with stage: TRAINING
2022-11-18 03:44:24,667 INFO:   Starting stage: EVALUATION
2022-11-18 03:44:24,787 INFO:   Done with stage: EVALUATION
2022-11-18 03:44:24,788 INFO:   Leaving out SEQ value Fold_7
2022-11-18 03:44:24,801 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:44:24,801 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:44:25,469 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:44:25,469 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:44:25,539 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:44:25,539 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:44:25,539 INFO:     No hyperparam tuning for this model
2022-11-18 03:44:25,539 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:44:25,539 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:44:25,540 INFO:     None feature selector for col prot
2022-11-18 03:44:25,540 INFO:     None feature selector for col prot
2022-11-18 03:44:25,540 INFO:     None feature selector for col prot
2022-11-18 03:44:25,541 INFO:     None feature selector for col chem
2022-11-18 03:44:25,541 INFO:     None feature selector for col chem
2022-11-18 03:44:25,541 INFO:     None feature selector for col chem
2022-11-18 03:44:25,541 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:44:25,541 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:44:25,543 INFO:     Number of params in model 168571
2022-11-18 03:44:25,546 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:44:25,546 INFO:   Starting stage: TRAINING
2022-11-18 03:44:25,604 INFO:     Val loss before train {'Reaction outcome loss': 1.0237496481700377, 'Total loss': 1.0237496481700377}
2022-11-18 03:44:25,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:25,605 INFO:     Epoch: 0
2022-11-18 03:44:26,416 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.870130408893932, 'Total loss': 0.870130408893932} | train loss {'Reaction outcome loss': 0.8723718110592135, 'Total loss': 0.8723718110592135}
2022-11-18 03:44:26,416 INFO:     Found new best model at epoch 0
2022-11-18 03:44:26,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:26,418 INFO:     Epoch: 1
2022-11-18 03:44:27,211 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8447037406943061, 'Total loss': 0.8447037406943061} | train loss {'Reaction outcome loss': 0.8386296581837439, 'Total loss': 0.8386296581837439}
2022-11-18 03:44:27,212 INFO:     Found new best model at epoch 1
2022-11-18 03:44:27,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:27,212 INFO:     Epoch: 2
2022-11-18 03:44:28,064 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8284838382493366, 'Total loss': 0.8284838382493366} | train loss {'Reaction outcome loss': 0.8370543008129443, 'Total loss': 0.8370543008129443}
2022-11-18 03:44:28,065 INFO:     Found new best model at epoch 2
2022-11-18 03:44:28,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:28,066 INFO:     Epoch: 3
2022-11-18 03:44:28,847 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8528493026440794, 'Total loss': 0.8528493026440794} | train loss {'Reaction outcome loss': 0.831965709645902, 'Total loss': 0.831965709645902}
2022-11-18 03:44:28,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:28,847 INFO:     Epoch: 4
2022-11-18 03:44:29,673 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8516090634194288, 'Total loss': 0.8516090634194288} | train loss {'Reaction outcome loss': 0.8281154534629276, 'Total loss': 0.8281154534629276}
2022-11-18 03:44:29,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:29,673 INFO:     Epoch: 5
2022-11-18 03:44:30,524 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8496313298290427, 'Total loss': 0.8496313298290427} | train loss {'Reaction outcome loss': 0.8241213010924477, 'Total loss': 0.8241213010924477}
2022-11-18 03:44:30,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:30,524 INFO:     Epoch: 6
2022-11-18 03:44:31,323 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.881072145971385, 'Total loss': 0.881072145971385} | train loss {'Reaction outcome loss': 0.8237162698661128, 'Total loss': 0.8237162698661128}
2022-11-18 03:44:31,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:31,324 INFO:     Epoch: 7
2022-11-18 03:44:32,120 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8473919047550722, 'Total loss': 0.8473919047550722} | train loss {'Reaction outcome loss': 0.8210188728426734, 'Total loss': 0.8210188728426734}
2022-11-18 03:44:32,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:32,120 INFO:     Epoch: 8
2022-11-18 03:44:32,924 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8311733264814724, 'Total loss': 0.8311733264814724} | train loss {'Reaction outcome loss': 0.8199965105422081, 'Total loss': 0.8199965105422081}
2022-11-18 03:44:32,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:32,924 INFO:     Epoch: 9
2022-11-18 03:44:33,769 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8344413949684664, 'Total loss': 0.8344413949684664} | train loss {'Reaction outcome loss': 0.8181947295463854, 'Total loss': 0.8181947295463854}
2022-11-18 03:44:33,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:33,770 INFO:     Epoch: 10
2022-11-18 03:44:34,582 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8413844216953624, 'Total loss': 0.8413844216953624} | train loss {'Reaction outcome loss': 0.8117336432539648, 'Total loss': 0.8117336432539648}
2022-11-18 03:44:34,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:34,582 INFO:     Epoch: 11
2022-11-18 03:44:35,415 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8325787755576047, 'Total loss': 0.8325787755576047} | train loss {'Reaction outcome loss': 0.8138571278222145, 'Total loss': 0.8138571278222145}
2022-11-18 03:44:35,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:35,415 INFO:     Epoch: 12
2022-11-18 03:44:36,216 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8167175894433801, 'Total loss': 0.8167175894433801} | train loss {'Reaction outcome loss': 0.812557241128337, 'Total loss': 0.812557241128337}
2022-11-18 03:44:36,216 INFO:     Found new best model at epoch 12
2022-11-18 03:44:36,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:36,217 INFO:     Epoch: 13
2022-11-18 03:44:37,014 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.834431148388169, 'Total loss': 0.834431148388169} | train loss {'Reaction outcome loss': 0.809497503263335, 'Total loss': 0.809497503263335}
2022-11-18 03:44:37,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:37,014 INFO:     Epoch: 14
2022-11-18 03:44:37,784 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8141125704754483, 'Total loss': 0.8141125704754483} | train loss {'Reaction outcome loss': 0.8111595239850783, 'Total loss': 0.8111595239850783}
2022-11-18 03:44:37,785 INFO:     Found new best model at epoch 14
2022-11-18 03:44:37,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:37,786 INFO:     Epoch: 15
2022-11-18 03:44:38,618 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8237226117740978, 'Total loss': 0.8237226117740978} | train loss {'Reaction outcome loss': 0.8090036255457709, 'Total loss': 0.8090036255457709}
2022-11-18 03:44:38,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:38,619 INFO:     Epoch: 16
2022-11-18 03:44:39,426 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8116743131117388, 'Total loss': 0.8116743131117388} | train loss {'Reaction outcome loss': 0.8081050045307605, 'Total loss': 0.8081050045307605}
2022-11-18 03:44:39,426 INFO:     Found new best model at epoch 16
2022-11-18 03:44:39,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:39,427 INFO:     Epoch: 17
2022-11-18 03:44:40,228 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8294961520216682, 'Total loss': 0.8294961520216682} | train loss {'Reaction outcome loss': 0.810509935862595, 'Total loss': 0.810509935862595}
2022-11-18 03:44:40,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:40,229 INFO:     Epoch: 18
2022-11-18 03:44:41,014 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8242619444023479, 'Total loss': 0.8242619444023479} | train loss {'Reaction outcome loss': 0.813315229430314, 'Total loss': 0.813315229430314}
2022-11-18 03:44:41,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:41,015 INFO:     Epoch: 19
2022-11-18 03:44:41,806 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8157210769978437, 'Total loss': 0.8157210769978437} | train loss {'Reaction outcome loss': 0.8072773530598609, 'Total loss': 0.8072773530598609}
2022-11-18 03:44:41,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:41,807 INFO:     Epoch: 20
2022-11-18 03:44:42,614 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8309765769676729, 'Total loss': 0.8309765769676729} | train loss {'Reaction outcome loss': 0.8109106562070308, 'Total loss': 0.8109106562070308}
2022-11-18 03:44:42,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:42,614 INFO:     Epoch: 21
2022-11-18 03:44:43,423 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8229492848569696, 'Total loss': 0.8229492848569696} | train loss {'Reaction outcome loss': 0.8111315645998524, 'Total loss': 0.8111315645998524}
2022-11-18 03:44:43,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:43,424 INFO:     Epoch: 22
2022-11-18 03:44:44,209 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8221832947297529, 'Total loss': 0.8221832947297529} | train loss {'Reaction outcome loss': 0.8055209606405227, 'Total loss': 0.8055209606405227}
2022-11-18 03:44:44,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:44,210 INFO:     Epoch: 23
2022-11-18 03:44:45,023 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8215879384766925, 'Total loss': 0.8215879384766925} | train loss {'Reaction outcome loss': 0.8087543997793428, 'Total loss': 0.8087543997793428}
2022-11-18 03:44:45,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:45,023 INFO:     Epoch: 24
2022-11-18 03:44:45,819 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8350823386148973, 'Total loss': 0.8350823386148973} | train loss {'Reaction outcome loss': 0.8089694986420293, 'Total loss': 0.8089694986420293}
2022-11-18 03:44:45,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:45,819 INFO:     Epoch: 25
2022-11-18 03:44:46,620 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8182214620438489, 'Total loss': 0.8182214620438489} | train loss {'Reaction outcome loss': 0.8067544995536727, 'Total loss': 0.8067544995536727}
2022-11-18 03:44:46,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:46,620 INFO:     Epoch: 26
2022-11-18 03:44:47,439 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8334637636488135, 'Total loss': 0.8334637636488135} | train loss {'Reaction outcome loss': 0.8081655950555878, 'Total loss': 0.8081655950555878}
2022-11-18 03:44:47,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:47,439 INFO:     Epoch: 27
2022-11-18 03:44:48,254 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8260857408696954, 'Total loss': 0.8260857408696954} | train loss {'Reaction outcome loss': 0.8154486786694296, 'Total loss': 0.8154486786694296}
2022-11-18 03:44:48,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:48,254 INFO:     Epoch: 28
2022-11-18 03:44:49,060 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.827800143848766, 'Total loss': 0.827800143848766} | train loss {'Reaction outcome loss': 0.8051425668020402, 'Total loss': 0.8051425668020402}
2022-11-18 03:44:49,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:49,060 INFO:     Epoch: 29
2022-11-18 03:44:49,878 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8287915140390396, 'Total loss': 0.8287915140390396} | train loss {'Reaction outcome loss': 0.8103832471514901, 'Total loss': 0.8103832471514901}
2022-11-18 03:44:49,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:49,878 INFO:     Epoch: 30
2022-11-18 03:44:50,709 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8176315440372988, 'Total loss': 0.8176315440372988} | train loss {'Reaction outcome loss': 0.8062349090412739, 'Total loss': 0.8062349090412739}
2022-11-18 03:44:50,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:50,709 INFO:     Epoch: 31
2022-11-18 03:44:51,527 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8649236329577186, 'Total loss': 0.8649236329577186} | train loss {'Reaction outcome loss': 0.8053811099981109, 'Total loss': 0.8053811099981109}
2022-11-18 03:44:51,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:51,527 INFO:     Epoch: 32
2022-11-18 03:44:52,317 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8325234651565552, 'Total loss': 0.8325234651565552} | train loss {'Reaction outcome loss': 0.8082555019326748, 'Total loss': 0.8082555019326748}
2022-11-18 03:44:52,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:52,317 INFO:     Epoch: 33
2022-11-18 03:44:53,104 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8210486783222719, 'Total loss': 0.8210486783222719} | train loss {'Reaction outcome loss': 0.8044742455165232, 'Total loss': 0.8044742455165232}
2022-11-18 03:44:53,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:53,106 INFO:     Epoch: 34
2022-11-18 03:44:53,893 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.829241163351319, 'Total loss': 0.829241163351319} | train loss {'Reaction outcome loss': 0.8027443028986454, 'Total loss': 0.8027443028986454}
2022-11-18 03:44:53,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:53,893 INFO:     Epoch: 35
2022-11-18 03:44:54,699 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8155355968258597, 'Total loss': 0.8155355968258597} | train loss {'Reaction outcome loss': 0.8079238149427599, 'Total loss': 0.8079238149427599}
2022-11-18 03:44:54,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:54,699 INFO:     Epoch: 36
2022-11-18 03:44:55,518 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.813804142177105, 'Total loss': 0.813804142177105} | train loss {'Reaction outcome loss': 0.8086719859030939, 'Total loss': 0.8086719859030939}
2022-11-18 03:44:55,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:55,519 INFO:     Epoch: 37
2022-11-18 03:44:56,337 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8221697062253952, 'Total loss': 0.8221697062253952} | train loss {'Reaction outcome loss': 0.807705485051678, 'Total loss': 0.807705485051678}
2022-11-18 03:44:56,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:56,337 INFO:     Epoch: 38
2022-11-18 03:44:57,115 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8312598514285955, 'Total loss': 0.8312598514285955} | train loss {'Reaction outcome loss': 0.8133974572823893, 'Total loss': 0.8133974572823893}
2022-11-18 03:44:57,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:57,116 INFO:     Epoch: 39
2022-11-18 03:44:57,902 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8421293036504225, 'Total loss': 0.8421293036504225} | train loss {'Reaction outcome loss': 0.8021987414648456, 'Total loss': 0.8021987414648456}
2022-11-18 03:44:57,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:57,903 INFO:     Epoch: 40
2022-11-18 03:44:58,714 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8467202105305411, 'Total loss': 0.8467202105305411} | train loss {'Reaction outcome loss': 0.809386306472363, 'Total loss': 0.809386306472363}
2022-11-18 03:44:58,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:58,714 INFO:     Epoch: 41
2022-11-18 03:44:59,576 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8294026919386603, 'Total loss': 0.8294026919386603} | train loss {'Reaction outcome loss': 0.8045476833658833, 'Total loss': 0.8045476833658833}
2022-11-18 03:44:59,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:44:59,577 INFO:     Epoch: 42
2022-11-18 03:45:00,394 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8278712169690565, 'Total loss': 0.8278712169690565} | train loss {'Reaction outcome loss': 0.8132780367929128, 'Total loss': 0.8132780367929128}
2022-11-18 03:45:00,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:00,394 INFO:     Epoch: 43
2022-11-18 03:45:01,241 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.815016271038489, 'Total loss': 0.815016271038489} | train loss {'Reaction outcome loss': 0.807670478979426, 'Total loss': 0.807670478979426}
2022-11-18 03:45:01,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:01,241 INFO:     Epoch: 44
2022-11-18 03:45:02,050 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8654036670923233, 'Total loss': 0.8654036670923233} | train loss {'Reaction outcome loss': 0.8081530337372134, 'Total loss': 0.8081530337372134}
2022-11-18 03:45:02,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:02,051 INFO:     Epoch: 45
2022-11-18 03:45:02,891 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.826070795005018, 'Total loss': 0.826070795005018} | train loss {'Reaction outcome loss': 0.8126927909831847, 'Total loss': 0.8126927909831847}
2022-11-18 03:45:02,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:02,892 INFO:     Epoch: 46
2022-11-18 03:45:03,718 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8198163956403732, 'Total loss': 0.8198163956403732} | train loss {'Reaction outcome loss': 0.8069491547442251, 'Total loss': 0.8069491547442251}
2022-11-18 03:45:03,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:03,719 INFO:     Epoch: 47
2022-11-18 03:45:04,519 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8262314444238489, 'Total loss': 0.8262314444238489} | train loss {'Reaction outcome loss': 0.8123465674298425, 'Total loss': 0.8123465674298425}
2022-11-18 03:45:04,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:04,520 INFO:     Epoch: 48
2022-11-18 03:45:05,362 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8075039007446982, 'Total loss': 0.8075039007446982} | train loss {'Reaction outcome loss': 0.8041840255741151, 'Total loss': 0.8041840255741151}
2022-11-18 03:45:05,362 INFO:     Found new best model at epoch 48
2022-11-18 03:45:05,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:05,363 INFO:     Epoch: 49
2022-11-18 03:45:06,211 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8197186047380621, 'Total loss': 0.8197186047380621} | train loss {'Reaction outcome loss': 0.8061603938619937, 'Total loss': 0.8061603938619937}
2022-11-18 03:45:06,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:06,211 INFO:     Epoch: 50
2022-11-18 03:45:07,021 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8215936557813124, 'Total loss': 0.8215936557813124} | train loss {'Reaction outcome loss': 0.8065050833167569, 'Total loss': 0.8065050833167569}
2022-11-18 03:45:07,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:07,021 INFO:     Epoch: 51
2022-11-18 03:45:07,826 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8309849432923577, 'Total loss': 0.8309849432923577} | train loss {'Reaction outcome loss': 0.8077503812889899, 'Total loss': 0.8077503812889899}
2022-11-18 03:45:07,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:07,826 INFO:     Epoch: 52
2022-11-18 03:45:08,690 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8270725072784857, 'Total loss': 0.8270725072784857} | train loss {'Reaction outcome loss': 0.8041988367274884, 'Total loss': 0.8041988367274884}
2022-11-18 03:45:08,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:08,690 INFO:     Epoch: 53
2022-11-18 03:45:09,483 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8180956271561709, 'Total loss': 0.8180956271561709} | train loss {'Reaction outcome loss': 0.8034405685480563, 'Total loss': 0.8034405685480563}
2022-11-18 03:45:09,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:09,484 INFO:     Epoch: 54
2022-11-18 03:45:10,296 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8157444806261496, 'Total loss': 0.8157444806261496} | train loss {'Reaction outcome loss': 0.808958285157719, 'Total loss': 0.808958285157719}
2022-11-18 03:45:10,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:10,296 INFO:     Epoch: 55
2022-11-18 03:45:11,121 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.818192604590546, 'Total loss': 0.818192604590546} | train loss {'Reaction outcome loss': 0.8044492502606684, 'Total loss': 0.8044492502606684}
2022-11-18 03:45:11,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:11,121 INFO:     Epoch: 56
2022-11-18 03:45:11,926 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8176561756567522, 'Total loss': 0.8176561756567522} | train loss {'Reaction outcome loss': 0.804775050210376, 'Total loss': 0.804775050210376}
2022-11-18 03:45:11,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:11,927 INFO:     Epoch: 57
2022-11-18 03:45:12,752 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8265599513595755, 'Total loss': 0.8265599513595755} | train loss {'Reaction outcome loss': 0.8085689467167662, 'Total loss': 0.8085689467167662}
2022-11-18 03:45:12,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:12,753 INFO:     Epoch: 58
2022-11-18 03:45:13,564 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8178816207430579, 'Total loss': 0.8178816207430579} | train loss {'Reaction outcome loss': 0.8076974642613242, 'Total loss': 0.8076974642613242}
2022-11-18 03:45:13,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:13,564 INFO:     Epoch: 59
2022-11-18 03:45:14,378 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8271307613361966, 'Total loss': 0.8271307613361966} | train loss {'Reaction outcome loss': 0.8072899672533235, 'Total loss': 0.8072899672533235}
2022-11-18 03:45:14,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:14,378 INFO:     Epoch: 60
2022-11-18 03:45:15,176 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8186036118052222, 'Total loss': 0.8186036118052222} | train loss {'Reaction outcome loss': 0.8039355988223706, 'Total loss': 0.8039355988223706}
2022-11-18 03:45:15,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:15,176 INFO:     Epoch: 61
2022-11-18 03:45:15,977 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.81863149729642, 'Total loss': 0.81863149729642} | train loss {'Reaction outcome loss': 0.8061185346976403, 'Total loss': 0.8061185346976403}
2022-11-18 03:45:15,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:15,977 INFO:     Epoch: 62
2022-11-18 03:45:16,853 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8382776128974828, 'Total loss': 0.8382776128974828} | train loss {'Reaction outcome loss': 0.8009196245862592, 'Total loss': 0.8009196245862592}
2022-11-18 03:45:16,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:16,853 INFO:     Epoch: 63
2022-11-18 03:45:17,678 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8192174895243212, 'Total loss': 0.8192174895243212} | train loss {'Reaction outcome loss': 0.8064500279724598, 'Total loss': 0.8064500279724598}
2022-11-18 03:45:17,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:17,678 INFO:     Epoch: 64
2022-11-18 03:45:18,504 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8232378505847671, 'Total loss': 0.8232378505847671} | train loss {'Reaction outcome loss': 0.8068472017203608, 'Total loss': 0.8068472017203608}
2022-11-18 03:45:18,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:18,505 INFO:     Epoch: 65
2022-11-18 03:45:19,342 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8360804373567755, 'Total loss': 0.8360804373567755} | train loss {'Reaction outcome loss': 0.8078781083947227, 'Total loss': 0.8078781083947227}
2022-11-18 03:45:19,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:19,343 INFO:     Epoch: 66
2022-11-18 03:45:20,151 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8218504271724008, 'Total loss': 0.8218504271724008} | train loss {'Reaction outcome loss': 0.8096704549126087, 'Total loss': 0.8096704549126087}
2022-11-18 03:45:20,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:20,151 INFO:     Epoch: 67
2022-11-18 03:45:20,965 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.815449617464434, 'Total loss': 0.815449617464434} | train loss {'Reaction outcome loss': 0.8029075918659088, 'Total loss': 0.8029075918659088}
2022-11-18 03:45:20,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:20,965 INFO:     Epoch: 68
2022-11-18 03:45:21,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8378009450706568, 'Total loss': 0.8378009450706568} | train loss {'Reaction outcome loss': 0.8112350832070073, 'Total loss': 0.8112350832070073}
2022-11-18 03:45:21,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:21,740 INFO:     Epoch: 69
2022-11-18 03:45:22,558 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8314758281816136, 'Total loss': 0.8314758281816136} | train loss {'Reaction outcome loss': 0.8071626733628011, 'Total loss': 0.8071626733628011}
2022-11-18 03:45:22,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:22,559 INFO:     Epoch: 70
2022-11-18 03:45:23,399 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8189828748052771, 'Total loss': 0.8189828748052771} | train loss {'Reaction outcome loss': 0.8034389220899151, 'Total loss': 0.8034389220899151}
2022-11-18 03:45:23,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:23,399 INFO:     Epoch: 71
2022-11-18 03:45:24,251 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8353821283037012, 'Total loss': 0.8353821283037012} | train loss {'Reaction outcome loss': 0.8012271534291006, 'Total loss': 0.8012271534291006}
2022-11-18 03:45:24,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:24,251 INFO:     Epoch: 72
2022-11-18 03:45:25,078 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8223768743601713, 'Total loss': 0.8223768743601713} | train loss {'Reaction outcome loss': 0.8068832984614757, 'Total loss': 0.8068832984614757}
2022-11-18 03:45:25,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:25,079 INFO:     Epoch: 73
2022-11-18 03:45:25,903 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8285973092371767, 'Total loss': 0.8285973092371767} | train loss {'Reaction outcome loss': 0.8060733524541701, 'Total loss': 0.8060733524541701}
2022-11-18 03:45:25,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:25,904 INFO:     Epoch: 74
2022-11-18 03:45:26,651 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8111017021265897, 'Total loss': 0.8111017021265897} | train loss {'Reaction outcome loss': 0.8090817430807699, 'Total loss': 0.8090817430807699}
2022-11-18 03:45:26,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:26,651 INFO:     Epoch: 75
2022-11-18 03:45:27,485 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.825646232474934, 'Total loss': 0.825646232474934} | train loss {'Reaction outcome loss': 0.8075851068621681, 'Total loss': 0.8075851068621681}
2022-11-18 03:45:27,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:27,485 INFO:     Epoch: 76
2022-11-18 03:45:28,286 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8289526043967768, 'Total loss': 0.8289526043967768} | train loss {'Reaction outcome loss': 0.8038921193970788, 'Total loss': 0.8038921193970788}
2022-11-18 03:45:28,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:28,286 INFO:     Epoch: 77
2022-11-18 03:45:29,060 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8293811584060843, 'Total loss': 0.8293811584060843} | train loss {'Reaction outcome loss': 0.8095911392761815, 'Total loss': 0.8095911392761815}
2022-11-18 03:45:29,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:29,060 INFO:     Epoch: 78
2022-11-18 03:45:29,901 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8299128602851521, 'Total loss': 0.8299128602851521} | train loss {'Reaction outcome loss': 0.811781876990872, 'Total loss': 0.811781876990872}
2022-11-18 03:45:29,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:29,901 INFO:     Epoch: 79
2022-11-18 03:45:30,746 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.827989785508676, 'Total loss': 0.827989785508676} | train loss {'Reaction outcome loss': 0.8068438167533567, 'Total loss': 0.8068438167533567}
2022-11-18 03:45:30,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:30,747 INFO:     Epoch: 80
2022-11-18 03:45:31,546 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8367350467226722, 'Total loss': 0.8367350467226722} | train loss {'Reaction outcome loss': 0.8034762998502101, 'Total loss': 0.8034762998502101}
2022-11-18 03:45:31,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:31,547 INFO:     Epoch: 81
2022-11-18 03:45:32,365 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8341728408228267, 'Total loss': 0.8341728408228267} | train loss {'Reaction outcome loss': 0.8107073767290961, 'Total loss': 0.8107073767290961}
2022-11-18 03:45:32,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:32,365 INFO:     Epoch: 82
2022-11-18 03:45:33,143 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8201816840605303, 'Total loss': 0.8201816840605303} | train loss {'Reaction outcome loss': 0.8085809792241743, 'Total loss': 0.8085809792241743}
2022-11-18 03:45:33,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:33,143 INFO:     Epoch: 83
2022-11-18 03:45:33,981 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8288600011305376, 'Total loss': 0.8288600011305376} | train loss {'Reaction outcome loss': 0.809097285712919, 'Total loss': 0.809097285712919}
2022-11-18 03:45:33,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:33,982 INFO:     Epoch: 84
2022-11-18 03:45:34,784 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8235536122863943, 'Total loss': 0.8235536122863943} | train loss {'Reaction outcome loss': 0.8033607965034824, 'Total loss': 0.8033607965034824}
2022-11-18 03:45:34,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:34,784 INFO:     Epoch: 85
2022-11-18 03:45:35,624 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8328368494456465, 'Total loss': 0.8328368494456465} | train loss {'Reaction outcome loss': 0.8087964434056513, 'Total loss': 0.8087964434056513}
2022-11-18 03:45:35,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:35,624 INFO:     Epoch: 86
2022-11-18 03:45:36,437 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8352467234839093, 'Total loss': 0.8352467234839093} | train loss {'Reaction outcome loss': 0.8075936828409472, 'Total loss': 0.8075936828409472}
2022-11-18 03:45:36,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:36,438 INFO:     Epoch: 87
2022-11-18 03:45:37,263 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8127684972502969, 'Total loss': 0.8127684972502969} | train loss {'Reaction outcome loss': 0.8038860059553578, 'Total loss': 0.8038860059553578}
2022-11-18 03:45:37,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:37,263 INFO:     Epoch: 88
2022-11-18 03:45:38,063 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8133158507672223, 'Total loss': 0.8133158507672223} | train loss {'Reaction outcome loss': 0.8075919719713349, 'Total loss': 0.8075919719713349}
2022-11-18 03:45:38,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:38,064 INFO:     Epoch: 89
2022-11-18 03:45:38,877 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.822710545225577, 'Total loss': 0.822710545225577} | train loss {'Reaction outcome loss': 0.8086194897130612, 'Total loss': 0.8086194897130612}
2022-11-18 03:45:38,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:38,877 INFO:     Epoch: 90
2022-11-18 03:45:39,706 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.818271510980346, 'Total loss': 0.818271510980346} | train loss {'Reaction outcome loss': 0.8045228791813697, 'Total loss': 0.8045228791813697}
2022-11-18 03:45:39,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:39,706 INFO:     Epoch: 91
2022-11-18 03:45:40,494 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8322831947695125, 'Total loss': 0.8322831947695125} | train loss {'Reaction outcome loss': 0.8015533774610488, 'Total loss': 0.8015533774610488}
2022-11-18 03:45:40,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:40,495 INFO:     Epoch: 92
2022-11-18 03:45:41,288 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8176142302426425, 'Total loss': 0.8176142302426425} | train loss {'Reaction outcome loss': 0.8093951172646014, 'Total loss': 0.8093951172646014}
2022-11-18 03:45:41,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:41,289 INFO:     Epoch: 93
2022-11-18 03:45:42,084 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.822540357708931, 'Total loss': 0.822540357708931} | train loss {'Reaction outcome loss': 0.8053298606987922, 'Total loss': 0.8053298606987922}
2022-11-18 03:45:42,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:42,084 INFO:     Epoch: 94
2022-11-18 03:45:42,872 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8292580903931097, 'Total loss': 0.8292580903931097} | train loss {'Reaction outcome loss': 0.802863841215449, 'Total loss': 0.802863841215449}
2022-11-18 03:45:42,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:42,873 INFO:     Epoch: 95
2022-11-18 03:45:43,663 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8227790810845115, 'Total loss': 0.8227790810845115} | train loss {'Reaction outcome loss': 0.8036636628450886, 'Total loss': 0.8036636628450886}
2022-11-18 03:45:43,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:43,664 INFO:     Epoch: 96
2022-11-18 03:45:44,458 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8324084593491121, 'Total loss': 0.8324084593491121} | train loss {'Reaction outcome loss': 0.800227883722513, 'Total loss': 0.800227883722513}
2022-11-18 03:45:44,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:44,458 INFO:     Epoch: 97
2022-11-18 03:45:45,244 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8144377754493193, 'Total loss': 0.8144377754493193} | train loss {'Reaction outcome loss': 0.805612518181724, 'Total loss': 0.805612518181724}
2022-11-18 03:45:45,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:45,244 INFO:     Epoch: 98
2022-11-18 03:45:46,024 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8261570381847295, 'Total loss': 0.8261570381847295} | train loss {'Reaction outcome loss': 0.8043010430710931, 'Total loss': 0.8043010430710931}
2022-11-18 03:45:46,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:46,024 INFO:     Epoch: 99
2022-11-18 03:45:46,826 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8343465585600246, 'Total loss': 0.8343465585600246} | train loss {'Reaction outcome loss': 0.8037817242645449, 'Total loss': 0.8037817242645449}
2022-11-18 03:45:46,826 INFO:     Best model found after epoch 49 of 100.
2022-11-18 03:45:46,826 INFO:   Done with stage: TRAINING
2022-11-18 03:45:46,826 INFO:   Starting stage: EVALUATION
2022-11-18 03:45:46,944 INFO:   Done with stage: EVALUATION
2022-11-18 03:45:46,944 INFO:   Leaving out SEQ value Fold_8
2022-11-18 03:45:46,957 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 03:45:46,957 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:45:47,623 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:45:47,623 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:45:47,692 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:45:47,692 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:45:47,692 INFO:     No hyperparam tuning for this model
2022-11-18 03:45:47,692 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:45:47,692 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:45:47,693 INFO:     None feature selector for col prot
2022-11-18 03:45:47,693 INFO:     None feature selector for col prot
2022-11-18 03:45:47,693 INFO:     None feature selector for col prot
2022-11-18 03:45:47,694 INFO:     None feature selector for col chem
2022-11-18 03:45:47,694 INFO:     None feature selector for col chem
2022-11-18 03:45:47,694 INFO:     None feature selector for col chem
2022-11-18 03:45:47,694 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:45:47,694 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:45:47,696 INFO:     Number of params in model 168571
2022-11-18 03:45:47,699 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:45:47,699 INFO:   Starting stage: TRAINING
2022-11-18 03:45:47,757 INFO:     Val loss before train {'Reaction outcome loss': 0.9844559647820212, 'Total loss': 0.9844559647820212}
2022-11-18 03:45:47,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:47,757 INFO:     Epoch: 0
2022-11-18 03:45:48,601 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8127521919933233, 'Total loss': 0.8127521919933233} | train loss {'Reaction outcome loss': 0.8692112597883964, 'Total loss': 0.8692112597883964}
2022-11-18 03:45:48,601 INFO:     Found new best model at epoch 0
2022-11-18 03:45:48,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:48,602 INFO:     Epoch: 1
2022-11-18 03:45:49,383 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8412904366850853, 'Total loss': 0.8412904366850853} | train loss {'Reaction outcome loss': 0.8347199716130081, 'Total loss': 0.8347199716130081}
2022-11-18 03:45:49,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:49,383 INFO:     Epoch: 2
2022-11-18 03:45:50,197 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8363494317639958, 'Total loss': 0.8363494317639958} | train loss {'Reaction outcome loss': 0.8349399095895339, 'Total loss': 0.8349399095895339}
2022-11-18 03:45:50,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:50,197 INFO:     Epoch: 3
2022-11-18 03:45:50,972 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8308078700845892, 'Total loss': 0.8308078700845892} | train loss {'Reaction outcome loss': 0.8282137710220959, 'Total loss': 0.8282137710220959}
2022-11-18 03:45:50,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:50,972 INFO:     Epoch: 4
2022-11-18 03:45:51,781 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7883379879322919, 'Total loss': 0.7883379879322919} | train loss {'Reaction outcome loss': 0.823634331688589, 'Total loss': 0.823634331688589}
2022-11-18 03:45:51,781 INFO:     Found new best model at epoch 4
2022-11-18 03:45:51,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:51,782 INFO:     Epoch: 5
2022-11-18 03:45:52,538 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8208993984894319, 'Total loss': 0.8208993984894319} | train loss {'Reaction outcome loss': 0.8210506448940355, 'Total loss': 0.8210506448940355}
2022-11-18 03:45:52,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:52,538 INFO:     Epoch: 6
2022-11-18 03:45:53,311 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7832230898466978, 'Total loss': 0.7832230898466978} | train loss {'Reaction outcome loss': 0.8138952823317781, 'Total loss': 0.8138952823317781}
2022-11-18 03:45:53,311 INFO:     Found new best model at epoch 6
2022-11-18 03:45:53,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:53,312 INFO:     Epoch: 7
2022-11-18 03:45:54,082 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8217012889005921, 'Total loss': 0.8217012889005921} | train loss {'Reaction outcome loss': 0.8199751914763937, 'Total loss': 0.8199751914763937}
2022-11-18 03:45:54,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:54,082 INFO:     Epoch: 8
2022-11-18 03:45:54,872 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8017856133255091, 'Total loss': 0.8017856133255091} | train loss {'Reaction outcome loss': 0.8144954681396485, 'Total loss': 0.8144954681396485}
2022-11-18 03:45:54,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:54,872 INFO:     Epoch: 9
2022-11-18 03:45:55,661 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7877675531940027, 'Total loss': 0.7877675531940027} | train loss {'Reaction outcome loss': 0.8140431384651028, 'Total loss': 0.8140431384651028}
2022-11-18 03:45:55,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:55,662 INFO:     Epoch: 10
2022-11-18 03:45:56,472 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8102633113210852, 'Total loss': 0.8102633113210852} | train loss {'Reaction outcome loss': 0.8180137827688334, 'Total loss': 0.8180137827688334}
2022-11-18 03:45:56,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:56,473 INFO:     Epoch: 11
2022-11-18 03:45:57,277 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7813120199875399, 'Total loss': 0.7813120199875399} | train loss {'Reaction outcome loss': 0.811025757570656, 'Total loss': 0.811025757570656}
2022-11-18 03:45:57,277 INFO:     Found new best model at epoch 11
2022-11-18 03:45:57,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:57,278 INFO:     Epoch: 12
2022-11-18 03:45:58,049 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7791920568455349, 'Total loss': 0.7791920568455349} | train loss {'Reaction outcome loss': 0.8141234497634732, 'Total loss': 0.8141234497634732}
2022-11-18 03:45:58,049 INFO:     Found new best model at epoch 12
2022-11-18 03:45:58,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:58,050 INFO:     Epoch: 13
2022-11-18 03:45:58,848 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7944079518995502, 'Total loss': 0.7944079518995502} | train loss {'Reaction outcome loss': 0.8126681983470917, 'Total loss': 0.8126681983470917}
2022-11-18 03:45:58,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:58,849 INFO:     Epoch: 14
2022-11-18 03:45:59,630 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8000228967178952, 'Total loss': 0.8000228967178952} | train loss {'Reaction outcome loss': 0.81694313117436, 'Total loss': 0.81694313117436}
2022-11-18 03:45:59,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:45:59,631 INFO:     Epoch: 15
2022-11-18 03:46:00,415 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8025419908491048, 'Total loss': 0.8025419908491048} | train loss {'Reaction outcome loss': 0.8097728129552335, 'Total loss': 0.8097728129552335}
2022-11-18 03:46:00,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:00,415 INFO:     Epoch: 16
2022-11-18 03:46:01,195 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8005517741495912, 'Total loss': 0.8005517741495912} | train loss {'Reaction outcome loss': 0.8133033375959007, 'Total loss': 0.8133033375959007}
2022-11-18 03:46:01,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:01,195 INFO:     Epoch: 17
2022-11-18 03:46:01,971 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8419820320877162, 'Total loss': 0.8419820320877162} | train loss {'Reaction outcome loss': 0.8080581335388884, 'Total loss': 0.8080581335388884}
2022-11-18 03:46:01,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:01,973 INFO:     Epoch: 18
2022-11-18 03:46:02,753 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7940425290302797, 'Total loss': 0.7940425290302797} | train loss {'Reaction outcome loss': 0.8067677950372502, 'Total loss': 0.8067677950372502}
2022-11-18 03:46:02,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:02,754 INFO:     Epoch: 19
2022-11-18 03:46:03,561 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8109071742404591, 'Total loss': 0.8109071742404591} | train loss {'Reaction outcome loss': 0.8102190166103597, 'Total loss': 0.8102190166103597}
2022-11-18 03:46:03,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:03,561 INFO:     Epoch: 20
2022-11-18 03:46:04,336 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8165602880445394, 'Total loss': 0.8165602880445394} | train loss {'Reaction outcome loss': 0.8115018950433147, 'Total loss': 0.8115018950433147}
2022-11-18 03:46:04,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:04,336 INFO:     Epoch: 21
2022-11-18 03:46:05,137 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8039936375888911, 'Total loss': 0.8039936375888911} | train loss {'Reaction outcome loss': 0.8082947967003803, 'Total loss': 0.8082947967003803}
2022-11-18 03:46:05,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:05,137 INFO:     Epoch: 22
2022-11-18 03:46:05,944 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7596165172078393, 'Total loss': 0.7596165172078393} | train loss {'Reaction outcome loss': 0.8044063414846148, 'Total loss': 0.8044063414846148}
2022-11-18 03:46:05,944 INFO:     Found new best model at epoch 22
2022-11-18 03:46:05,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:05,945 INFO:     Epoch: 23
2022-11-18 03:46:06,704 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8008451746268705, 'Total loss': 0.8008451746268705} | train loss {'Reaction outcome loss': 0.8077378307070051, 'Total loss': 0.8077378307070051}
2022-11-18 03:46:06,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:06,704 INFO:     Epoch: 24
2022-11-18 03:46:07,485 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7805908498438922, 'Total loss': 0.7805908498438922} | train loss {'Reaction outcome loss': 0.8076235852679428, 'Total loss': 0.8076235852679428}
2022-11-18 03:46:07,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:07,485 INFO:     Epoch: 25
2022-11-18 03:46:08,271 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7808082704855637, 'Total loss': 0.7808082704855637} | train loss {'Reaction outcome loss': 0.8052644086127378, 'Total loss': 0.8052644086127378}
2022-11-18 03:46:08,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:08,271 INFO:     Epoch: 26
2022-11-18 03:46:09,023 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7921885468743064, 'Total loss': 0.7921885468743064} | train loss {'Reaction outcome loss': 0.8086794202425042, 'Total loss': 0.8086794202425042}
2022-11-18 03:46:09,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:09,023 INFO:     Epoch: 27
2022-11-18 03:46:09,813 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7887747978622263, 'Total loss': 0.7887747978622263} | train loss {'Reaction outcome loss': 0.804583291131623, 'Total loss': 0.804583291131623}
2022-11-18 03:46:09,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:09,813 INFO:     Epoch: 28
2022-11-18 03:46:10,646 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7922483310103416, 'Total loss': 0.7922483310103416} | train loss {'Reaction outcome loss': 0.8062829354587866, 'Total loss': 0.8062829354587866}
2022-11-18 03:46:10,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:10,646 INFO:     Epoch: 29
2022-11-18 03:46:11,482 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7726029983975671, 'Total loss': 0.7726029983975671} | train loss {'Reaction outcome loss': 0.8061312440706759, 'Total loss': 0.8061312440706759}
2022-11-18 03:46:11,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:11,482 INFO:     Epoch: 30
2022-11-18 03:46:12,253 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7732458961280909, 'Total loss': 0.7732458961280909} | train loss {'Reaction outcome loss': 0.8088754084645485, 'Total loss': 0.8088754084645485}
2022-11-18 03:46:12,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:12,254 INFO:     Epoch: 31
2022-11-18 03:46:13,049 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7784618769179691, 'Total loss': 0.7784618769179691} | train loss {'Reaction outcome loss': 0.8064009442621348, 'Total loss': 0.8064009442621348}
2022-11-18 03:46:13,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:13,049 INFO:     Epoch: 32
2022-11-18 03:46:13,851 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7823218567804857, 'Total loss': 0.7823218567804857} | train loss {'Reaction outcome loss': 0.8048175390885801, 'Total loss': 0.8048175390885801}
2022-11-18 03:46:13,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:13,852 INFO:     Epoch: 33
2022-11-18 03:46:14,680 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7870755696838553, 'Total loss': 0.7870755696838553} | train loss {'Reaction outcome loss': 0.8011867340730161, 'Total loss': 0.8011867340730161}
2022-11-18 03:46:14,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:14,681 INFO:     Epoch: 34
2022-11-18 03:46:15,487 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7719254988161001, 'Total loss': 0.7719254988161001} | train loss {'Reaction outcome loss': 0.8060617502854794, 'Total loss': 0.8060617502854794}
2022-11-18 03:46:15,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:15,488 INFO:     Epoch: 35
2022-11-18 03:46:16,291 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7773487926884131, 'Total loss': 0.7773487926884131} | train loss {'Reaction outcome loss': 0.8053777307880168, 'Total loss': 0.8053777307880168}
2022-11-18 03:46:16,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:16,291 INFO:     Epoch: 36
2022-11-18 03:46:17,078 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7838601090691306, 'Total loss': 0.7838601090691306} | train loss {'Reaction outcome loss': 0.8035501250198909, 'Total loss': 0.8035501250198909}
2022-11-18 03:46:17,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:17,078 INFO:     Epoch: 37
2022-11-18 03:46:17,921 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7936485121873292, 'Total loss': 0.7936485121873292} | train loss {'Reaction outcome loss': 0.799623875958579, 'Total loss': 0.799623875958579}
2022-11-18 03:46:17,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:17,922 INFO:     Epoch: 38
2022-11-18 03:46:18,741 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7928148677403276, 'Total loss': 0.7928148677403276} | train loss {'Reaction outcome loss': 0.8024474005309903, 'Total loss': 0.8024474005309903}
2022-11-18 03:46:18,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:18,741 INFO:     Epoch: 39
2022-11-18 03:46:19,509 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7790715613148429, 'Total loss': 0.7790715613148429} | train loss {'Reaction outcome loss': 0.7977759024318384, 'Total loss': 0.7977759024318384}
2022-11-18 03:46:19,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:19,510 INFO:     Epoch: 40
2022-11-18 03:46:20,292 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7897945507006212, 'Total loss': 0.7897945507006212} | train loss {'Reaction outcome loss': 0.8040583080174971, 'Total loss': 0.8040583080174971}
2022-11-18 03:46:20,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:20,293 INFO:     Epoch: 41
2022-11-18 03:46:21,081 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7826807647943497, 'Total loss': 0.7826807647943497} | train loss {'Reaction outcome loss': 0.7999206370236922, 'Total loss': 0.7999206370236922}
2022-11-18 03:46:21,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:21,081 INFO:     Epoch: 42
2022-11-18 03:46:21,864 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7846103716980327, 'Total loss': 0.7846103716980327} | train loss {'Reaction outcome loss': 0.8005766699508745, 'Total loss': 0.8005766699508745}
2022-11-18 03:46:21,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:21,864 INFO:     Epoch: 43
2022-11-18 03:46:22,695 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7850991636514664, 'Total loss': 0.7850991636514664} | train loss {'Reaction outcome loss': 0.797510102330422, 'Total loss': 0.797510102330422}
2022-11-18 03:46:22,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:22,696 INFO:     Epoch: 44
2022-11-18 03:46:23,474 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7790672643618151, 'Total loss': 0.7790672643618151} | train loss {'Reaction outcome loss': 0.8016781682870826, 'Total loss': 0.8016781682870826}
2022-11-18 03:46:23,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:23,474 INFO:     Epoch: 45
2022-11-18 03:46:24,280 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7850556624206629, 'Total loss': 0.7850556624206629} | train loss {'Reaction outcome loss': 0.8051597392072483, 'Total loss': 0.8051597392072483}
2022-11-18 03:46:24,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:24,281 INFO:     Epoch: 46
2022-11-18 03:46:25,126 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8107636252587492, 'Total loss': 0.8107636252587492} | train loss {'Reaction outcome loss': 0.7964625469275883, 'Total loss': 0.7964625469275883}
2022-11-18 03:46:25,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:25,126 INFO:     Epoch: 47
2022-11-18 03:46:25,941 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7870203608816321, 'Total loss': 0.7870203608816321} | train loss {'Reaction outcome loss': 0.7950608679226466, 'Total loss': 0.7950608679226466}
2022-11-18 03:46:25,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:25,941 INFO:     Epoch: 48
2022-11-18 03:46:26,719 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7872838377952576, 'Total loss': 0.7872838377952576} | train loss {'Reaction outcome loss': 0.7992525739329202, 'Total loss': 0.7992525739329202}
2022-11-18 03:46:26,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:26,721 INFO:     Epoch: 49
2022-11-18 03:46:27,495 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7879670323296026, 'Total loss': 0.7879670323296026} | train loss {'Reaction outcome loss': 0.7956889834939217, 'Total loss': 0.7956889834939217}
2022-11-18 03:46:27,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:27,495 INFO:     Epoch: 50
2022-11-18 03:46:28,313 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7775034796107899, 'Total loss': 0.7775034796107899} | train loss {'Reaction outcome loss': 0.7981445194507132, 'Total loss': 0.7981445194507132}
2022-11-18 03:46:28,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:28,314 INFO:     Epoch: 51
2022-11-18 03:46:29,105 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7782889171080156, 'Total loss': 0.7782889171080156} | train loss {'Reaction outcome loss': 0.7945383633886065, 'Total loss': 0.7945383633886065}
2022-11-18 03:46:29,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:29,105 INFO:     Epoch: 52
2022-11-18 03:46:29,977 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7759154486385259, 'Total loss': 0.7759154486385259} | train loss {'Reaction outcome loss': 0.7974583872726986, 'Total loss': 0.7974583872726986}
2022-11-18 03:46:29,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:29,977 INFO:     Epoch: 53
2022-11-18 03:46:30,782 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.799973726272583, 'Total loss': 0.799973726272583} | train loss {'Reaction outcome loss': 0.7918226621588882, 'Total loss': 0.7918226621588882}
2022-11-18 03:46:30,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:30,782 INFO:     Epoch: 54
2022-11-18 03:46:31,616 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.771836443380876, 'Total loss': 0.771836443380876} | train loss {'Reaction outcome loss': 0.7981626334239026, 'Total loss': 0.7981626334239026}
2022-11-18 03:46:31,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:31,617 INFO:     Epoch: 55
2022-11-18 03:46:32,410 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8046795644543387, 'Total loss': 0.8046795644543387} | train loss {'Reaction outcome loss': 0.7934013316825944, 'Total loss': 0.7934013316825944}
2022-11-18 03:46:32,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:32,410 INFO:     Epoch: 56
2022-11-18 03:46:33,213 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7839984155514024, 'Total loss': 0.7839984155514024} | train loss {'Reaction outcome loss': 0.7945859140279342, 'Total loss': 0.7945859140279342}
2022-11-18 03:46:33,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:33,215 INFO:     Epoch: 57
2022-11-18 03:46:34,003 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7957949089733037, 'Total loss': 0.7957949089733037} | train loss {'Reaction outcome loss': 0.7958304721481946, 'Total loss': 0.7958304721481946}
2022-11-18 03:46:34,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:34,003 INFO:     Epoch: 58
2022-11-18 03:46:34,792 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8150976516983726, 'Total loss': 0.8150976516983726} | train loss {'Reaction outcome loss': 0.7912031286833238, 'Total loss': 0.7912031286833238}
2022-11-18 03:46:34,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:34,793 INFO:     Epoch: 59
2022-11-18 03:46:35,635 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8154375742782246, 'Total loss': 0.8154375742782246} | train loss {'Reaction outcome loss': 0.7959428922254213, 'Total loss': 0.7959428922254213}
2022-11-18 03:46:35,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:35,635 INFO:     Epoch: 60
2022-11-18 03:46:36,419 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8015665357763117, 'Total loss': 0.8015665357763117} | train loss {'Reaction outcome loss': 0.7908657114116513, 'Total loss': 0.7908657114116513}
2022-11-18 03:46:36,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:36,420 INFO:     Epoch: 61
2022-11-18 03:46:37,231 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7690911767157641, 'Total loss': 0.7690911767157641} | train loss {'Reaction outcome loss': 0.7922248188330203, 'Total loss': 0.7922248188330203}
2022-11-18 03:46:37,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:37,232 INFO:     Epoch: 62
2022-11-18 03:46:38,031 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7885320924899795, 'Total loss': 0.7885320924899795} | train loss {'Reaction outcome loss': 0.7906311459687292, 'Total loss': 0.7906311459687292}
2022-11-18 03:46:38,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:38,031 INFO:     Epoch: 63
2022-11-18 03:46:38,832 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7778507931665941, 'Total loss': 0.7778507931665941} | train loss {'Reaction outcome loss': 0.7934208980628422, 'Total loss': 0.7934208980628422}
2022-11-18 03:46:38,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:38,832 INFO:     Epoch: 64
2022-11-18 03:46:39,630 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7588018504056063, 'Total loss': 0.7588018504056063} | train loss {'Reaction outcome loss': 0.7898461312663798, 'Total loss': 0.7898461312663798}
2022-11-18 03:46:39,630 INFO:     Found new best model at epoch 64
2022-11-18 03:46:39,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:39,631 INFO:     Epoch: 65
2022-11-18 03:46:40,431 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.78580818799409, 'Total loss': 0.78580818799409} | train loss {'Reaction outcome loss': 0.7934660740044652, 'Total loss': 0.7934660740044652}
2022-11-18 03:46:40,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:40,431 INFO:     Epoch: 66
2022-11-18 03:46:41,266 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7663115242665465, 'Total loss': 0.7663115242665465} | train loss {'Reaction outcome loss': 0.7873043981133675, 'Total loss': 0.7873043981133675}
2022-11-18 03:46:41,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:41,266 INFO:     Epoch: 67
2022-11-18 03:46:42,040 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7596008974042806, 'Total loss': 0.7596008974042806} | train loss {'Reaction outcome loss': 0.7830729744872268, 'Total loss': 0.7830729744872268}
2022-11-18 03:46:42,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:42,040 INFO:     Epoch: 68
2022-11-18 03:46:42,834 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7728258046236905, 'Total loss': 0.7728258046236905} | train loss {'Reaction outcome loss': 0.7921197528741798, 'Total loss': 0.7921197528741798}
2022-11-18 03:46:42,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:42,834 INFO:     Epoch: 69
2022-11-18 03:46:43,663 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7699559642509981, 'Total loss': 0.7699559642509981} | train loss {'Reaction outcome loss': 0.7806350242118446, 'Total loss': 0.7806350242118446}
2022-11-18 03:46:43,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:43,663 INFO:     Epoch: 70
2022-11-18 03:46:44,449 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7644848498431119, 'Total loss': 0.7644848498431119} | train loss {'Reaction outcome loss': 0.7824640865228614, 'Total loss': 0.7824640865228614}
2022-11-18 03:46:44,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:44,449 INFO:     Epoch: 71
2022-11-18 03:46:45,282 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7684880467978391, 'Total loss': 0.7684880467978391} | train loss {'Reaction outcome loss': 0.7847321518829891, 'Total loss': 0.7847321518829891}
2022-11-18 03:46:45,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:45,283 INFO:     Epoch: 72
2022-11-18 03:46:46,071 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7838431386785074, 'Total loss': 0.7838431386785074} | train loss {'Reaction outcome loss': 0.7820577763781256, 'Total loss': 0.7820577763781256}
2022-11-18 03:46:46,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:46,071 INFO:     Epoch: 73
2022-11-18 03:46:46,838 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7803971056233753, 'Total loss': 0.7803971056233753} | train loss {'Reaction outcome loss': 0.7817640119669389, 'Total loss': 0.7817640119669389}
2022-11-18 03:46:46,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:46,838 INFO:     Epoch: 74
2022-11-18 03:46:47,637 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.777479266578501, 'Total loss': 0.777479266578501} | train loss {'Reaction outcome loss': 0.7829563873154777, 'Total loss': 0.7829563873154777}
2022-11-18 03:46:47,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:47,637 INFO:     Epoch: 75
2022-11-18 03:46:48,458 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7524901567534967, 'Total loss': 0.7524901567534967} | train loss {'Reaction outcome loss': 0.7774566213695371, 'Total loss': 0.7774566213695371}
2022-11-18 03:46:48,458 INFO:     Found new best model at epoch 75
2022-11-18 03:46:48,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:48,459 INFO:     Epoch: 76
2022-11-18 03:46:49,251 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7710087949579413, 'Total loss': 0.7710087949579413} | train loss {'Reaction outcome loss': 0.7806361785956791, 'Total loss': 0.7806361785956791}
2022-11-18 03:46:49,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:49,251 INFO:     Epoch: 77
2022-11-18 03:46:50,058 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7566073895855383, 'Total loss': 0.7566073895855383} | train loss {'Reaction outcome loss': 0.7771942001216265, 'Total loss': 0.7771942001216265}
2022-11-18 03:46:50,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:50,059 INFO:     Epoch: 78
2022-11-18 03:46:50,806 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7575218413363803, 'Total loss': 0.7575218413363803} | train loss {'Reaction outcome loss': 0.7783628124363569, 'Total loss': 0.7783628124363569}
2022-11-18 03:46:50,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:50,806 INFO:     Epoch: 79
2022-11-18 03:46:51,602 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7784864055839452, 'Total loss': 0.7784864055839452} | train loss {'Reaction outcome loss': 0.7785265343529838, 'Total loss': 0.7785265343529838}
2022-11-18 03:46:51,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:51,602 INFO:     Epoch: 80
2022-11-18 03:46:52,381 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7758642333475027, 'Total loss': 0.7758642333475027} | train loss {'Reaction outcome loss': 0.7714420645820851, 'Total loss': 0.7714420645820851}
2022-11-18 03:46:52,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:52,381 INFO:     Epoch: 81
2022-11-18 03:46:53,155 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7464419786225666, 'Total loss': 0.7464419786225666} | train loss {'Reaction outcome loss': 0.7752009880786039, 'Total loss': 0.7752009880786039}
2022-11-18 03:46:53,155 INFO:     Found new best model at epoch 81
2022-11-18 03:46:53,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:53,156 INFO:     Epoch: 82
2022-11-18 03:46:53,979 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7798148779706522, 'Total loss': 0.7798148779706522} | train loss {'Reaction outcome loss': 0.7663656577772023, 'Total loss': 0.7663656577772023}
2022-11-18 03:46:53,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:53,979 INFO:     Epoch: 83
2022-11-18 03:46:54,761 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7603727193041281, 'Total loss': 0.7603727193041281} | train loss {'Reaction outcome loss': 0.7746579667743372, 'Total loss': 0.7746579667743372}
2022-11-18 03:46:54,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:54,762 INFO:     Epoch: 84
2022-11-18 03:46:55,616 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.746182423423637, 'Total loss': 0.746182423423637} | train loss {'Reaction outcome loss': 0.7672834454750528, 'Total loss': 0.7672834454750528}
2022-11-18 03:46:55,617 INFO:     Found new best model at epoch 84
2022-11-18 03:46:55,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:55,617 INFO:     Epoch: 85
2022-11-18 03:46:56,399 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7370510616085746, 'Total loss': 0.7370510616085746} | train loss {'Reaction outcome loss': 0.7592944780174566, 'Total loss': 0.7592944780174566}
2022-11-18 03:46:56,399 INFO:     Found new best model at epoch 85
2022-11-18 03:46:56,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:56,400 INFO:     Epoch: 86
2022-11-18 03:46:57,182 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7673604122617028, 'Total loss': 0.7673604122617028} | train loss {'Reaction outcome loss': 0.7659500433474171, 'Total loss': 0.7659500433474171}
2022-11-18 03:46:57,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:57,182 INFO:     Epoch: 87
2022-11-18 03:46:58,021 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7521400952881033, 'Total loss': 0.7521400952881033} | train loss {'Reaction outcome loss': 0.7628666880179424, 'Total loss': 0.7628666880179424}
2022-11-18 03:46:58,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:58,023 INFO:     Epoch: 88
2022-11-18 03:46:58,819 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7372725429860029, 'Total loss': 0.7372725429860029} | train loss {'Reaction outcome loss': 0.7495510016168867, 'Total loss': 0.7495510016168867}
2022-11-18 03:46:58,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:58,820 INFO:     Epoch: 89
2022-11-18 03:46:59,631 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7419724457643249, 'Total loss': 0.7419724457643249} | train loss {'Reaction outcome loss': 0.7539824534435662, 'Total loss': 0.7539824534435662}
2022-11-18 03:46:59,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:46:59,632 INFO:     Epoch: 90
2022-11-18 03:47:00,441 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7033094303174452, 'Total loss': 0.7033094303174452} | train loss {'Reaction outcome loss': 0.7439950385872198, 'Total loss': 0.7439950385872198}
2022-11-18 03:47:00,441 INFO:     Found new best model at epoch 90
2022-11-18 03:47:00,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:00,442 INFO:     Epoch: 91
2022-11-18 03:47:01,215 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7288505644960837, 'Total loss': 0.7288505644960837} | train loss {'Reaction outcome loss': 0.7350330827187519, 'Total loss': 0.7350330827187519}
2022-11-18 03:47:01,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:01,215 INFO:     Epoch: 92
2022-11-18 03:47:02,008 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7683591537854888, 'Total loss': 0.7683591537854888} | train loss {'Reaction outcome loss': 0.7311451054349237, 'Total loss': 0.7311451054349237}
2022-11-18 03:47:02,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:02,008 INFO:     Epoch: 93
2022-11-18 03:47:02,793 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7131246660243381, 'Total loss': 0.7131246660243381} | train loss {'Reaction outcome loss': 0.7207120858893102, 'Total loss': 0.7207120858893102}
2022-11-18 03:47:02,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:02,794 INFO:     Epoch: 94
2022-11-18 03:47:03,575 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6729766350578178, 'Total loss': 0.6729766350578178} | train loss {'Reaction outcome loss': 0.7119813313289565, 'Total loss': 0.7119813313289565}
2022-11-18 03:47:03,576 INFO:     Found new best model at epoch 94
2022-11-18 03:47:03,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:03,576 INFO:     Epoch: 95
2022-11-18 03:47:04,351 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6973157342184674, 'Total loss': 0.6973157342184674} | train loss {'Reaction outcome loss': 0.7041484156433417, 'Total loss': 0.7041484156433417}
2022-11-18 03:47:04,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:04,352 INFO:     Epoch: 96
2022-11-18 03:47:05,127 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6778296272863041, 'Total loss': 0.6778296272863041} | train loss {'Reaction outcome loss': 0.6851753661827166, 'Total loss': 0.6851753661827166}
2022-11-18 03:47:05,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:05,127 INFO:     Epoch: 97
2022-11-18 03:47:05,919 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6743186752904545, 'Total loss': 0.6743186752904545} | train loss {'Reaction outcome loss': 0.6725326603772689, 'Total loss': 0.6725326603772689}
2022-11-18 03:47:05,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:05,919 INFO:     Epoch: 98
2022-11-18 03:47:06,733 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7045874771746722, 'Total loss': 0.7045874771746722} | train loss {'Reaction outcome loss': 0.6501916859222918, 'Total loss': 0.6501916859222918}
2022-11-18 03:47:06,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:06,733 INFO:     Epoch: 99
2022-11-18 03:47:07,520 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6266091885891828, 'Total loss': 0.6266091885891828} | train loss {'Reaction outcome loss': 0.6505262058608386, 'Total loss': 0.6505262058608386}
2022-11-18 03:47:07,520 INFO:     Found new best model at epoch 99
2022-11-18 03:47:07,521 INFO:     Best model found after epoch 100 of 100.
2022-11-18 03:47:07,521 INFO:   Done with stage: TRAINING
2022-11-18 03:47:07,521 INFO:   Starting stage: EVALUATION
2022-11-18 03:47:07,650 INFO:   Done with stage: EVALUATION
2022-11-18 03:47:07,651 INFO:   Leaving out SEQ value Fold_9
2022-11-18 03:47:07,663 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 03:47:07,663 INFO:   Starting stage: FEATURE SCALING
2022-11-18 03:47:08,338 INFO:   Done with stage: FEATURE SCALING
2022-11-18 03:47:08,338 INFO:   Starting stage: SCALING TARGETS
2022-11-18 03:47:08,408 INFO:   Done with stage: SCALING TARGETS
2022-11-18 03:47:08,408 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:47:08,409 INFO:     No hyperparam tuning for this model
2022-11-18 03:47:08,409 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 03:47:08,409 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 03:47:08,409 INFO:     None feature selector for col prot
2022-11-18 03:47:08,410 INFO:     None feature selector for col prot
2022-11-18 03:47:08,410 INFO:     None feature selector for col prot
2022-11-18 03:47:08,410 INFO:     None feature selector for col chem
2022-11-18 03:47:08,410 INFO:     None feature selector for col chem
2022-11-18 03:47:08,410 INFO:     None feature selector for col chem
2022-11-18 03:47:08,410 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 03:47:08,411 INFO:   Starting stage: BUILD MODEL
2022-11-18 03:47:08,412 INFO:     Number of params in model 168571
2022-11-18 03:47:08,415 INFO:   Done with stage: BUILD MODEL
2022-11-18 03:47:08,415 INFO:   Starting stage: TRAINING
2022-11-18 03:47:08,473 INFO:     Val loss before train {'Reaction outcome loss': 0.9504107142036612, 'Total loss': 0.9504107142036612}
2022-11-18 03:47:08,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:08,474 INFO:     Epoch: 0
2022-11-18 03:47:09,252 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.823642759160562, 'Total loss': 0.823642759160562} | train loss {'Reaction outcome loss': 0.8849627207363805, 'Total loss': 0.8849627207363805}
2022-11-18 03:47:09,252 INFO:     Found new best model at epoch 0
2022-11-18 03:47:09,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:09,253 INFO:     Epoch: 1
2022-11-18 03:47:10,061 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8213480710983276, 'Total loss': 0.8213480710983276} | train loss {'Reaction outcome loss': 0.8606937592548709, 'Total loss': 0.8606937592548709}
2022-11-18 03:47:10,061 INFO:     Found new best model at epoch 1
2022-11-18 03:47:10,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:10,062 INFO:     Epoch: 2
2022-11-18 03:47:10,884 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8335752798752352, 'Total loss': 0.8335752798752352} | train loss {'Reaction outcome loss': 0.8529877473990763, 'Total loss': 0.8529877473990763}
2022-11-18 03:47:10,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:10,885 INFO:     Epoch: 3
2022-11-18 03:47:11,697 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8164859143170443, 'Total loss': 0.8164859143170443} | train loss {'Reaction outcome loss': 0.8422743220242762, 'Total loss': 0.8422743220242762}
2022-11-18 03:47:11,697 INFO:     Found new best model at epoch 3
2022-11-18 03:47:11,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:11,698 INFO:     Epoch: 4
2022-11-18 03:47:12,505 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8129775916988199, 'Total loss': 0.8129775916988199} | train loss {'Reaction outcome loss': 0.8399677229744773, 'Total loss': 0.8399677229744773}
2022-11-18 03:47:12,505 INFO:     Found new best model at epoch 4
2022-11-18 03:47:12,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:12,506 INFO:     Epoch: 5
2022-11-18 03:47:13,348 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.832595398480242, 'Total loss': 0.832595398480242} | train loss {'Reaction outcome loss': 0.8342210387270297, 'Total loss': 0.8342210387270297}
2022-11-18 03:47:13,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:13,348 INFO:     Epoch: 6
2022-11-18 03:47:14,182 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.823553058234128, 'Total loss': 0.823553058234128} | train loss {'Reaction outcome loss': 0.8319043276771423, 'Total loss': 0.8319043276771423}
2022-11-18 03:47:14,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:14,182 INFO:     Epoch: 7
2022-11-18 03:47:15,037 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.797385420311581, 'Total loss': 0.797385420311581} | train loss {'Reaction outcome loss': 0.8302827922086562, 'Total loss': 0.8302827922086562}
2022-11-18 03:47:15,037 INFO:     Found new best model at epoch 7
2022-11-18 03:47:15,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:15,038 INFO:     Epoch: 8
2022-11-18 03:47:15,884 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8311361203139479, 'Total loss': 0.8311361203139479} | train loss {'Reaction outcome loss': 0.8316370149052912, 'Total loss': 0.8316370149052912}
2022-11-18 03:47:15,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:15,885 INFO:     Epoch: 9
2022-11-18 03:47:16,656 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.808032785626975, 'Total loss': 0.808032785626975} | train loss {'Reaction outcome loss': 0.8299532705737699, 'Total loss': 0.8299532705737699}
2022-11-18 03:47:16,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:16,657 INFO:     Epoch: 10
2022-11-18 03:47:17,471 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7863904603502967, 'Total loss': 0.7863904603502967} | train loss {'Reaction outcome loss': 0.8271733909364669, 'Total loss': 0.8271733909364669}
2022-11-18 03:47:17,471 INFO:     Found new best model at epoch 10
2022-11-18 03:47:17,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:17,472 INFO:     Epoch: 11
2022-11-18 03:47:18,252 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8018190318887884, 'Total loss': 0.8018190318887884} | train loss {'Reaction outcome loss': 0.8211909278986915, 'Total loss': 0.8211909278986915}
2022-11-18 03:47:18,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:18,252 INFO:     Epoch: 12
2022-11-18 03:47:19,085 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8033808808435093, 'Total loss': 0.8033808808435093} | train loss {'Reaction outcome loss': 0.8242827507276689, 'Total loss': 0.8242827507276689}
2022-11-18 03:47:19,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:19,086 INFO:     Epoch: 13
2022-11-18 03:47:19,893 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.809248262508349, 'Total loss': 0.809248262508349} | train loss {'Reaction outcome loss': 0.8236723860665676, 'Total loss': 0.8236723860665676}
2022-11-18 03:47:19,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:19,894 INFO:     Epoch: 14
2022-11-18 03:47:20,695 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8031820492310957, 'Total loss': 0.8031820492310957} | train loss {'Reaction outcome loss': 0.8219803337368273, 'Total loss': 0.8219803337368273}
2022-11-18 03:47:20,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:20,696 INFO:     Epoch: 15
2022-11-18 03:47:21,476 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8048305254090916, 'Total loss': 0.8048305254090916} | train loss {'Reaction outcome loss': 0.8222127728644879, 'Total loss': 0.8222127728644879}
2022-11-18 03:47:21,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:21,476 INFO:     Epoch: 16
2022-11-18 03:47:22,267 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7976270534775474, 'Total loss': 0.7976270534775474} | train loss {'Reaction outcome loss': 0.823716280200789, 'Total loss': 0.823716280200789}
2022-11-18 03:47:22,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:22,267 INFO:     Epoch: 17
2022-11-18 03:47:23,058 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8246566152030771, 'Total loss': 0.8246566152030771} | train loss {'Reaction outcome loss': 0.8232550439575026, 'Total loss': 0.8232550439575026}
2022-11-18 03:47:23,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:23,058 INFO:     Epoch: 18
2022-11-18 03:47:23,870 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7991916991092942, 'Total loss': 0.7991916991092942} | train loss {'Reaction outcome loss': 0.8265814264455149, 'Total loss': 0.8265814264455149}
2022-11-18 03:47:23,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:23,870 INFO:     Epoch: 19
2022-11-18 03:47:24,669 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8166301670399579, 'Total loss': 0.8166301670399579} | train loss {'Reaction outcome loss': 0.8182703677204347, 'Total loss': 0.8182703677204347}
2022-11-18 03:47:24,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:24,669 INFO:     Epoch: 20
2022-11-18 03:47:25,459 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7920953150499951, 'Total loss': 0.7920953150499951} | train loss {'Reaction outcome loss': 0.8209122456610203, 'Total loss': 0.8209122456610203}
2022-11-18 03:47:25,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:25,459 INFO:     Epoch: 21
2022-11-18 03:47:26,266 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7953106693246148, 'Total loss': 0.7953106693246148} | train loss {'Reaction outcome loss': 0.8214398406205639, 'Total loss': 0.8214398406205639}
2022-11-18 03:47:26,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:26,266 INFO:     Epoch: 22
2022-11-18 03:47:27,057 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8042289763689041, 'Total loss': 0.8042289763689041} | train loss {'Reaction outcome loss': 0.8122892700616391, 'Total loss': 0.8122892700616391}
2022-11-18 03:47:27,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:27,057 INFO:     Epoch: 23
2022-11-18 03:47:27,866 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7977727678689089, 'Total loss': 0.7977727678689089} | train loss {'Reaction outcome loss': 0.8238426368803747, 'Total loss': 0.8238426368803747}
2022-11-18 03:47:27,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:27,867 INFO:     Epoch: 24
2022-11-18 03:47:28,680 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8246810646219687, 'Total loss': 0.8246810646219687} | train loss {'Reaction outcome loss': 0.8199992318066859, 'Total loss': 0.8199992318066859}
2022-11-18 03:47:28,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:28,682 INFO:     Epoch: 25
2022-11-18 03:47:29,482 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8071833103895187, 'Total loss': 0.8071833103895187} | train loss {'Reaction outcome loss': 0.8191427533184329, 'Total loss': 0.8191427533184329}
2022-11-18 03:47:29,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:29,483 INFO:     Epoch: 26
2022-11-18 03:47:30,304 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.793613004413518, 'Total loss': 0.793613004413518} | train loss {'Reaction outcome loss': 0.8184457899582002, 'Total loss': 0.8184457899582002}
2022-11-18 03:47:30,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:30,304 INFO:     Epoch: 27
2022-11-18 03:47:31,115 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8034758737141435, 'Total loss': 0.8034758737141435} | train loss {'Reaction outcome loss': 0.8177840400847697, 'Total loss': 0.8177840400847697}
2022-11-18 03:47:31,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:31,115 INFO:     Epoch: 28
2022-11-18 03:47:31,965 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8066326840357347, 'Total loss': 0.8066326840357347} | train loss {'Reaction outcome loss': 0.817483325518908, 'Total loss': 0.817483325518908}
2022-11-18 03:47:31,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:31,965 INFO:     Epoch: 29
2022-11-18 03:47:32,770 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8134772222150456, 'Total loss': 0.8134772222150456} | train loss {'Reaction outcome loss': 0.8194576232664047, 'Total loss': 0.8194576232664047}
2022-11-18 03:47:32,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:32,770 INFO:     Epoch: 30
2022-11-18 03:47:33,556 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8028773306445642, 'Total loss': 0.8028773306445642} | train loss {'Reaction outcome loss': 0.8147095242334951, 'Total loss': 0.8147095242334951}
2022-11-18 03:47:33,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:33,556 INFO:     Epoch: 31
2022-11-18 03:47:34,411 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7934131872924891, 'Total loss': 0.7934131872924891} | train loss {'Reaction outcome loss': 0.81347640832105, 'Total loss': 0.81347640832105}
2022-11-18 03:47:34,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:34,412 INFO:     Epoch: 32
2022-11-18 03:47:35,253 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7961632487448779, 'Total loss': 0.7961632487448779} | train loss {'Reaction outcome loss': 0.8202201967998859, 'Total loss': 0.8202201967998859}
2022-11-18 03:47:35,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:35,254 INFO:     Epoch: 33
2022-11-18 03:47:36,067 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.821657198396596, 'Total loss': 0.821657198396596} | train loss {'Reaction outcome loss': 0.8126829289380582, 'Total loss': 0.8126829289380582}
2022-11-18 03:47:36,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:36,067 INFO:     Epoch: 34
2022-11-18 03:47:36,894 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7988995415243235, 'Total loss': 0.7988995415243235} | train loss {'Reaction outcome loss': 0.8167225124855195, 'Total loss': 0.8167225124855195}
2022-11-18 03:47:36,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:36,894 INFO:     Epoch: 35
2022-11-18 03:47:37,701 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7956996194340966, 'Total loss': 0.7956996194340966} | train loss {'Reaction outcome loss': 0.8164659689270681, 'Total loss': 0.8164659689270681}
2022-11-18 03:47:37,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:37,701 INFO:     Epoch: 36
2022-11-18 03:47:38,533 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7915806892243299, 'Total loss': 0.7915806892243299} | train loss {'Reaction outcome loss': 0.8220374371495939, 'Total loss': 0.8220374371495939}
2022-11-18 03:47:38,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:38,533 INFO:     Epoch: 37
2022-11-18 03:47:39,310 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7920054718852043, 'Total loss': 0.7920054718852043} | train loss {'Reaction outcome loss': 0.8166645166854705, 'Total loss': 0.8166645166854705}
2022-11-18 03:47:39,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:39,310 INFO:     Epoch: 38
2022-11-18 03:47:40,104 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7819296812469309, 'Total loss': 0.7819296812469309} | train loss {'Reaction outcome loss': 0.815829478324421, 'Total loss': 0.815829478324421}
2022-11-18 03:47:40,104 INFO:     Found new best model at epoch 38
2022-11-18 03:47:40,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:40,105 INFO:     Epoch: 39
2022-11-18 03:47:40,916 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.81168582290411, 'Total loss': 0.81168582290411} | train loss {'Reaction outcome loss': 0.816121461170335, 'Total loss': 0.816121461170335}
2022-11-18 03:47:40,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:40,916 INFO:     Epoch: 40
2022-11-18 03:47:41,739 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8163643343882128, 'Total loss': 0.8163643343882128} | train loss {'Reaction outcome loss': 0.8199673587035748, 'Total loss': 0.8199673587035748}
2022-11-18 03:47:41,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:41,739 INFO:     Epoch: 41
2022-11-18 03:47:42,530 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7921000095930967, 'Total loss': 0.7921000095930967} | train loss {'Reaction outcome loss': 0.8186997464827953, 'Total loss': 0.8186997464827953}
2022-11-18 03:47:42,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:42,530 INFO:     Epoch: 42
2022-11-18 03:47:43,316 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8091932860287753, 'Total loss': 0.8091932860287753} | train loss {'Reaction outcome loss': 0.821132606436168, 'Total loss': 0.821132606436168}
2022-11-18 03:47:43,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:43,317 INFO:     Epoch: 43
2022-11-18 03:47:44,145 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8049142943187193, 'Total loss': 0.8049142943187193} | train loss {'Reaction outcome loss': 0.8162665718024776, 'Total loss': 0.8162665718024776}
2022-11-18 03:47:44,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:44,146 INFO:     Epoch: 44
2022-11-18 03:47:45,010 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8011740703474391, 'Total loss': 0.8011740703474391} | train loss {'Reaction outcome loss': 0.8152093377805525, 'Total loss': 0.8152093377805525}
2022-11-18 03:47:45,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:45,011 INFO:     Epoch: 45
2022-11-18 03:47:45,825 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7822900698943571, 'Total loss': 0.7822900698943571} | train loss {'Reaction outcome loss': 0.8140740925746579, 'Total loss': 0.8140740925746579}
2022-11-18 03:47:45,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:45,825 INFO:     Epoch: 46
2022-11-18 03:47:46,595 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8084198195825923, 'Total loss': 0.8084198195825923} | train loss {'Reaction outcome loss': 0.8161949861434198, 'Total loss': 0.8161949861434198}
2022-11-18 03:47:46,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:46,595 INFO:     Epoch: 47
2022-11-18 03:47:47,377 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7842335321686484, 'Total loss': 0.7842335321686484} | train loss {'Reaction outcome loss': 0.8169175125658512, 'Total loss': 0.8169175125658512}
2022-11-18 03:47:47,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:47,379 INFO:     Epoch: 48
2022-11-18 03:47:48,221 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7972855046391487, 'Total loss': 0.7972855046391487} | train loss {'Reaction outcome loss': 0.8178063155181946, 'Total loss': 0.8178063155181946}
2022-11-18 03:47:48,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:48,222 INFO:     Epoch: 49
2022-11-18 03:47:49,018 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7947206321087751, 'Total loss': 0.7947206321087751} | train loss {'Reaction outcome loss': 0.8218032893153929, 'Total loss': 0.8218032893153929}
2022-11-18 03:47:49,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:49,019 INFO:     Epoch: 50
2022-11-18 03:47:49,812 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8079865087162365, 'Total loss': 0.8079865087162365} | train loss {'Reaction outcome loss': 0.8156283124079627, 'Total loss': 0.8156283124079627}
2022-11-18 03:47:49,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:49,812 INFO:     Epoch: 51
2022-11-18 03:47:50,666 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7864378189498727, 'Total loss': 0.7864378189498727} | train loss {'Reaction outcome loss': 0.8155048258842961, 'Total loss': 0.8155048258842961}
2022-11-18 03:47:50,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:50,667 INFO:     Epoch: 52
2022-11-18 03:47:51,439 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7889885658567602, 'Total loss': 0.7889885658567602} | train loss {'Reaction outcome loss': 0.8174039425869142, 'Total loss': 0.8174039425869142}
2022-11-18 03:47:51,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:51,439 INFO:     Epoch: 53
2022-11-18 03:47:52,245 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.788643282245506, 'Total loss': 0.788643282245506} | train loss {'Reaction outcome loss': 0.8157610633680897, 'Total loss': 0.8157610633680897}
2022-11-18 03:47:52,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:52,246 INFO:     Epoch: 54
2022-11-18 03:47:53,030 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8066425391218879, 'Total loss': 0.8066425391218879} | train loss {'Reaction outcome loss': 0.8143958689705018, 'Total loss': 0.8143958689705018}
2022-11-18 03:47:53,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:53,030 INFO:     Epoch: 55
2022-11-18 03:47:53,862 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8186667412519455, 'Total loss': 0.8186667412519455} | train loss {'Reaction outcome loss': 0.8168731908644399, 'Total loss': 0.8168731908644399}
2022-11-18 03:47:53,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:53,862 INFO:     Epoch: 56
2022-11-18 03:47:54,672 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7886381447315216, 'Total loss': 0.7886381447315216} | train loss {'Reaction outcome loss': 0.8148467001174727, 'Total loss': 0.8148467001174727}
2022-11-18 03:47:54,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:54,672 INFO:     Epoch: 57
2022-11-18 03:47:55,483 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7833892987533049, 'Total loss': 0.7833892987533049} | train loss {'Reaction outcome loss': 0.8148505221451482, 'Total loss': 0.8148505221451482}
2022-11-18 03:47:55,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:55,483 INFO:     Epoch: 58
2022-11-18 03:47:56,317 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7825108976526693, 'Total loss': 0.7825108976526693} | train loss {'Reaction outcome loss': 0.8150251782949893, 'Total loss': 0.8150251782949893}
2022-11-18 03:47:56,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:56,317 INFO:     Epoch: 59
2022-11-18 03:47:57,127 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7892283316362988, 'Total loss': 0.7892283316362988} | train loss {'Reaction outcome loss': 0.8136607086466204, 'Total loss': 0.8136607086466204}
2022-11-18 03:47:57,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:57,127 INFO:     Epoch: 60
2022-11-18 03:47:57,932 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7997030480341478, 'Total loss': 0.7997030480341478} | train loss {'Reaction outcome loss': 0.8132664323333771, 'Total loss': 0.8132664323333771}
2022-11-18 03:47:57,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:57,932 INFO:     Epoch: 61
2022-11-18 03:47:58,728 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7864247817884792, 'Total loss': 0.7864247817884792} | train loss {'Reaction outcome loss': 0.8193124094076695, 'Total loss': 0.8193124094076695}
2022-11-18 03:47:58,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:58,728 INFO:     Epoch: 62
2022-11-18 03:47:59,513 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7990202165462754, 'Total loss': 0.7990202165462754} | train loss {'Reaction outcome loss': 0.8150664622024182, 'Total loss': 0.8150664622024182}
2022-11-18 03:47:59,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:47:59,513 INFO:     Epoch: 63
2022-11-18 03:48:00,344 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7913754866881804, 'Total loss': 0.7913754866881804} | train loss {'Reaction outcome loss': 0.8175404491203446, 'Total loss': 0.8175404491203446}
2022-11-18 03:48:00,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:00,346 INFO:     Epoch: 64
2022-11-18 03:48:01,166 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8170911358161406, 'Total loss': 0.8170911358161406} | train loss {'Reaction outcome loss': 0.8134235073962519, 'Total loss': 0.8134235073962519}
2022-11-18 03:48:01,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:01,166 INFO:     Epoch: 65
2022-11-18 03:48:01,962 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7997618608854034, 'Total loss': 0.7997618608854034} | train loss {'Reaction outcome loss': 0.8140194810205891, 'Total loss': 0.8140194810205891}
2022-11-18 03:48:01,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:01,963 INFO:     Epoch: 66
2022-11-18 03:48:02,737 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7960574518550526, 'Total loss': 0.7960574518550526} | train loss {'Reaction outcome loss': 0.8149843518772433, 'Total loss': 0.8149843518772433}
2022-11-18 03:48:02,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:02,737 INFO:     Epoch: 67
2022-11-18 03:48:03,508 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7882284291765906, 'Total loss': 0.7882284291765906} | train loss {'Reaction outcome loss': 0.8162970506856518, 'Total loss': 0.8162970506856518}
2022-11-18 03:48:03,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:03,509 INFO:     Epoch: 68
2022-11-18 03:48:04,311 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7844511798836968, 'Total loss': 0.7844511798836968} | train loss {'Reaction outcome loss': 0.8129201239395526, 'Total loss': 0.8129201239395526}
2022-11-18 03:48:04,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:04,311 INFO:     Epoch: 69
2022-11-18 03:48:05,120 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7930058924989267, 'Total loss': 0.7930058924989267} | train loss {'Reaction outcome loss': 0.8145365477088959, 'Total loss': 0.8145365477088959}
2022-11-18 03:48:05,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:05,120 INFO:     Epoch: 70
2022-11-18 03:48:05,869 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8027755645188418, 'Total loss': 0.8027755645188418} | train loss {'Reaction outcome loss': 0.8155438650038934, 'Total loss': 0.8155438650038934}
2022-11-18 03:48:05,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:05,869 INFO:     Epoch: 71
2022-11-18 03:48:06,680 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7851144508882002, 'Total loss': 0.7851144508882002} | train loss {'Reaction outcome loss': 0.8127656682364403, 'Total loss': 0.8127656682364403}
2022-11-18 03:48:06,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:06,681 INFO:     Epoch: 72
2022-11-18 03:48:07,496 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7845255170356144, 'Total loss': 0.7845255170356144} | train loss {'Reaction outcome loss': 0.8143679280915568, 'Total loss': 0.8143679280915568}
2022-11-18 03:48:07,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:07,496 INFO:     Epoch: 73
2022-11-18 03:48:08,284 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8182753771543503, 'Total loss': 0.8182753771543503} | train loss {'Reaction outcome loss': 0.810720800872772, 'Total loss': 0.810720800872772}
2022-11-18 03:48:08,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:08,284 INFO:     Epoch: 74
2022-11-18 03:48:09,057 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7927077846093611, 'Total loss': 0.7927077846093611} | train loss {'Reaction outcome loss': 0.8169828487500068, 'Total loss': 0.8169828487500068}
2022-11-18 03:48:09,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:09,058 INFO:     Epoch: 75
2022-11-18 03:48:09,854 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7876064330339432, 'Total loss': 0.7876064330339432} | train loss {'Reaction outcome loss': 0.8148683834700815, 'Total loss': 0.8148683834700815}
2022-11-18 03:48:09,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:09,855 INFO:     Epoch: 76
2022-11-18 03:48:10,659 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8408988558433272, 'Total loss': 0.8408988558433272} | train loss {'Reaction outcome loss': 0.8160618604911912, 'Total loss': 0.8160618604911912}
2022-11-18 03:48:10,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:10,659 INFO:     Epoch: 77
2022-11-18 03:48:11,429 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7817435576157137, 'Total loss': 0.7817435576157137} | train loss {'Reaction outcome loss': 0.819239359469183, 'Total loss': 0.819239359469183}
2022-11-18 03:48:11,430 INFO:     Found new best model at epoch 77
2022-11-18 03:48:11,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:11,430 INFO:     Epoch: 78
2022-11-18 03:48:12,207 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7947714694521644, 'Total loss': 0.7947714694521644} | train loss {'Reaction outcome loss': 0.8169261278404344, 'Total loss': 0.8169261278404344}
2022-11-18 03:48:12,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:12,207 INFO:     Epoch: 79
2022-11-18 03:48:13,014 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7940006459301169, 'Total loss': 0.7940006459301169} | train loss {'Reaction outcome loss': 0.8151492856202587, 'Total loss': 0.8151492856202587}
2022-11-18 03:48:13,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:13,015 INFO:     Epoch: 80
2022-11-18 03:48:13,796 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.811557446691123, 'Total loss': 0.811557446691123} | train loss {'Reaction outcome loss': 0.8118803837606984, 'Total loss': 0.8118803837606984}
2022-11-18 03:48:13,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:13,796 INFO:     Epoch: 81
2022-11-18 03:48:14,573 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7912100594152104, 'Total loss': 0.7912100594152104} | train loss {'Reaction outcome loss': 0.8167630027859442, 'Total loss': 0.8167630027859442}
2022-11-18 03:48:14,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:14,574 INFO:     Epoch: 82
2022-11-18 03:48:15,367 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8177428082986311, 'Total loss': 0.8177428082986311} | train loss {'Reaction outcome loss': 0.8121626487662715, 'Total loss': 0.8121626487662715}
2022-11-18 03:48:15,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:15,367 INFO:     Epoch: 83
2022-11-18 03:48:16,171 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7924936833706769, 'Total loss': 0.7924936833706769} | train loss {'Reaction outcome loss': 0.8160145985743692, 'Total loss': 0.8160145985743692}
2022-11-18 03:48:16,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:16,171 INFO:     Epoch: 84
2022-11-18 03:48:17,000 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7941706573421304, 'Total loss': 0.7941706573421304} | train loss {'Reaction outcome loss': 0.8148233781178151, 'Total loss': 0.8148233781178151}
2022-11-18 03:48:17,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:17,001 INFO:     Epoch: 85
2022-11-18 03:48:17,792 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7883957407691262, 'Total loss': 0.7883957407691262} | train loss {'Reaction outcome loss': 0.8143485962383209, 'Total loss': 0.8143485962383209}
2022-11-18 03:48:17,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:17,792 INFO:     Epoch: 86
2022-11-18 03:48:18,577 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7961273308504712, 'Total loss': 0.7961273308504712} | train loss {'Reaction outcome loss': 0.8205495912942194, 'Total loss': 0.8205495912942194}
2022-11-18 03:48:18,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:18,578 INFO:     Epoch: 87
2022-11-18 03:48:19,412 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7869355251843279, 'Total loss': 0.7869355251843279} | train loss {'Reaction outcome loss': 0.8123213225795377, 'Total loss': 0.8123213225795377}
2022-11-18 03:48:19,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:19,413 INFO:     Epoch: 88
2022-11-18 03:48:20,219 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7998632463541898, 'Total loss': 0.7998632463541898} | train loss {'Reaction outcome loss': 0.8208045886168557, 'Total loss': 0.8208045886168557}
2022-11-18 03:48:20,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:20,219 INFO:     Epoch: 89
2022-11-18 03:48:21,027 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7954246252775192, 'Total loss': 0.7954246252775192} | train loss {'Reaction outcome loss': 0.8141695681598878, 'Total loss': 0.8141695681598878}
2022-11-18 03:48:21,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:21,028 INFO:     Epoch: 90
2022-11-18 03:48:21,806 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7816433222456411, 'Total loss': 0.7816433222456411} | train loss {'Reaction outcome loss': 0.8151894161297429, 'Total loss': 0.8151894161297429}
2022-11-18 03:48:21,806 INFO:     Found new best model at epoch 90
2022-11-18 03:48:21,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:21,807 INFO:     Epoch: 91
2022-11-18 03:48:22,640 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7780312651937659, 'Total loss': 0.7780312651937659} | train loss {'Reaction outcome loss': 0.8163009851930603, 'Total loss': 0.8163009851930603}
2022-11-18 03:48:22,640 INFO:     Found new best model at epoch 91
2022-11-18 03:48:22,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:22,641 INFO:     Epoch: 92
2022-11-18 03:48:23,431 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7927054532549598, 'Total loss': 0.7927054532549598} | train loss {'Reaction outcome loss': 0.8138200042228545, 'Total loss': 0.8138200042228545}
2022-11-18 03:48:23,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:23,431 INFO:     Epoch: 93
2022-11-18 03:48:24,257 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.796298319643194, 'Total loss': 0.796298319643194} | train loss {'Reaction outcome loss': 0.8148959835450496, 'Total loss': 0.8148959835450496}
2022-11-18 03:48:24,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:24,258 INFO:     Epoch: 94
2022-11-18 03:48:25,031 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7960365218195048, 'Total loss': 0.7960365218195048} | train loss {'Reaction outcome loss': 0.8131267654318963, 'Total loss': 0.8131267654318963}
2022-11-18 03:48:25,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:25,032 INFO:     Epoch: 95
2022-11-18 03:48:25,858 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.789196798747236, 'Total loss': 0.789196798747236} | train loss {'Reaction outcome loss': 0.8211846904408547, 'Total loss': 0.8211846904408547}
2022-11-18 03:48:25,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:25,858 INFO:     Epoch: 96
2022-11-18 03:48:26,712 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7874047600410201, 'Total loss': 0.7874047600410201} | train loss {'Reaction outcome loss': 0.8151516963637644, 'Total loss': 0.8151516963637644}
2022-11-18 03:48:26,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:26,712 INFO:     Epoch: 97
2022-11-18 03:48:27,545 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7863574769686569, 'Total loss': 0.7863574769686569} | train loss {'Reaction outcome loss': 0.8119782462956444, 'Total loss': 0.8119782462956444}
2022-11-18 03:48:27,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:27,545 INFO:     Epoch: 98
2022-11-18 03:48:28,371 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8110972873189233, 'Total loss': 0.8110972873189233} | train loss {'Reaction outcome loss': 0.8131523604594892, 'Total loss': 0.8131523604594892}
2022-11-18 03:48:28,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 03:48:28,371 INFO:     Epoch: 99
2022-11-18 03:48:29,249 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.79490907557986, 'Total loss': 0.79490907557986} | train loss {'Reaction outcome loss': 0.8125125057995319, 'Total loss': 0.8125125057995319}
2022-11-18 03:48:29,250 INFO:     Best model found after epoch 92 of 100.
2022-11-18 03:48:29,250 INFO:   Done with stage: TRAINING
2022-11-18 03:48:29,250 INFO:   Starting stage: EVALUATION
2022-11-18 03:48:29,371 INFO:   Done with stage: EVALUATION
2022-11-18 03:48:29,371 INFO: Done with stage: RUNNING SPLITS
2022-11-18 03:48:29,371 INFO: Starting stage: COMPUTE METRICS
2022-11-18 03:48:30,570 INFO: Done with stage: COMPUTE METRICS
2022-11-18 03:48:30,570 INFO: Starting stage: EXPORT RESULTS
2022-11-18 03:48:30,587 INFO:   Final results averaged over 50 folds: 
2022-11-18 03:48:30,591 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.251902           NaN  0.342766       NaN
2022-11-18 03:48:32,272 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-18 03:48:32,280 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-18 03:48:32,281 DEBUG:   interactive is False
2022-11-18 03:48:32,281 DEBUG:   platform is linux
2022-11-18 03:48:32,281 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-18 03:48:32,467 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-18 03:48:32,470 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-18 03:48:32,917 DEBUG:   Loaded backend agg version unknown.
2022-11-18 03:48:32,919 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-18 03:48:32,919 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,919 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,919 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,920 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,921 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 03:48:32,922 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,922 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 03:48:32,960 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,964 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,964 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 03:48:32,964 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,964 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 03:48:32,972 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-18 03:48:32,972 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,973 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,974 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 03:48:32,975 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 03:48:32,975 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 03:48:33,436 INFO: Done with stage: EXPORT RESULTS
2022-11-18 03:48:33,436 INFO: Starting stage: SAVE MODEL
2022-11-18 03:48:33,505 INFO: Done with stage: SAVE MODEL
2022-11-18 03:48:33,506 INFO: Wall time for program:  4024.75 seconds
