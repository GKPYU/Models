2023-01-04 07:46:41,554 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/49a4ce39930b950120bbf9460d9f51e9/2023_01_03-225551",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-04 07:46:41,572 INFO: Starting stage: BUILD FEATURIZERS
2023-01-04 07:46:41,579 INFO:   Creating esm representation model
2023-01-04 07:46:41,579 INFO:   Done esm representation model
2023-01-04 07:46:41,579 INFO: Done with stage: BUILD FEATURIZERS
2023-01-04 07:46:41,579 INFO: Starting stage: BUILDING DATASET
2023-01-04 07:46:41,638 INFO: Done with stage: BUILDING DATASET
2023-01-04 07:46:41,638 INFO: Starting stage: FEATURIZING DATA
2023-01-04 07:46:41,638 INFO:   Featurizing proteins
2023-01-04 07:46:41,642 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-04 07:46:41,679 INFO:   Loaded feature cache of size 489
2023-01-04 07:46:41,680 INFO:   Starting to pool ESM Embeddings
2023-01-04 07:46:41,804 INFO:   Featurizing molecules
2023-01-04 07:46:41,807 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-04 07:46:41,810 INFO:   Loaded feature cache of size 498
2023-01-04 07:46:43,167 INFO: Done with stage: FEATURIZING DATA
2023-01-04 07:46:43,167 INFO: Starting stage: RUNNING SPLITS
2023-01-04 07:46:43,176 INFO:   Leaving out SEQ value Fold_0
2023-01-04 07:46:43,189 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 07:46:43,190 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:46:43,848 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:46:43,848 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:46:43,915 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:46:43,915 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:46:43,915 INFO:     No hyperparam tuning for this model
2023-01-04 07:46:43,915 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:46:43,915 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:46:43,916 INFO:     None feature selector for col prot
2023-01-04 07:46:43,916 INFO:     None feature selector for col prot
2023-01-04 07:46:43,916 INFO:     None feature selector for col prot
2023-01-04 07:46:43,917 INFO:     None feature selector for col chem
2023-01-04 07:46:43,917 INFO:     None feature selector for col chem
2023-01-04 07:46:43,917 INFO:     None feature selector for col chem
2023-01-04 07:46:43,917 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:46:43,917 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:46:43,918 INFO:     Number of params in model 70111
2023-01-04 07:46:43,918 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:46:43,918 INFO:   Starting stage: TRAINING
2023-01-04 07:46:45,547 INFO:     Val loss before train {'Reaction outcome loss': 1.167160431543986, 'Total loss': 1.167160431543986}
2023-01-04 07:46:45,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:45,548 INFO:     Epoch: 0
2023-01-04 07:46:47,052 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8702100177605947, 'Total loss': 0.8702100177605947} | train loss {'Reaction outcome loss': 0.8662309024360154, 'Total loss': 0.8662309024360154}
2023-01-04 07:46:47,053 INFO:     Found new best model at epoch 0
2023-01-04 07:46:47,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:47,053 INFO:     Epoch: 1
2023-01-04 07:46:48,555 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7234278241793315, 'Total loss': 0.7234278241793315} | train loss {'Reaction outcome loss': 0.7119122000185998, 'Total loss': 0.7119122000185998}
2023-01-04 07:46:48,555 INFO:     Found new best model at epoch 1
2023-01-04 07:46:48,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:48,556 INFO:     Epoch: 2
2023-01-04 07:46:50,106 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6412530501683553, 'Total loss': 0.6412530501683553} | train loss {'Reaction outcome loss': 0.6158720200315063, 'Total loss': 0.6158720200315063}
2023-01-04 07:46:50,106 INFO:     Found new best model at epoch 2
2023-01-04 07:46:50,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:50,107 INFO:     Epoch: 3
2023-01-04 07:46:51,649 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5610973368088404, 'Total loss': 0.5610973368088404} | train loss {'Reaction outcome loss': 0.5672733257541727, 'Total loss': 0.5672733257541727}
2023-01-04 07:46:51,649 INFO:     Found new best model at epoch 3
2023-01-04 07:46:51,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:51,650 INFO:     Epoch: 4
2023-01-04 07:46:53,196 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5693328181902567, 'Total loss': 0.5693328181902567} | train loss {'Reaction outcome loss': 0.5453215983761099, 'Total loss': 0.5453215983761099}
2023-01-04 07:46:53,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:53,196 INFO:     Epoch: 5
2023-01-04 07:46:54,743 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5807976504166921, 'Total loss': 0.5807976504166921} | train loss {'Reaction outcome loss': 0.5237087481842809, 'Total loss': 0.5237087481842809}
2023-01-04 07:46:54,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:54,743 INFO:     Epoch: 6
2023-01-04 07:46:56,258 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5332121054331461, 'Total loss': 0.5332121054331461} | train loss {'Reaction outcome loss': 0.5106529418802087, 'Total loss': 0.5106529418802087}
2023-01-04 07:46:56,258 INFO:     Found new best model at epoch 6
2023-01-04 07:46:56,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:56,259 INFO:     Epoch: 7
2023-01-04 07:46:57,773 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.544077064593633, 'Total loss': 0.544077064593633} | train loss {'Reaction outcome loss': 0.5019173399978505, 'Total loss': 0.5019173399978505}
2023-01-04 07:46:57,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:57,773 INFO:     Epoch: 8
2023-01-04 07:46:59,310 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.527939103047053, 'Total loss': 0.527939103047053} | train loss {'Reaction outcome loss': 0.48955229776246206, 'Total loss': 0.48955229776246206}
2023-01-04 07:46:59,310 INFO:     Found new best model at epoch 8
2023-01-04 07:46:59,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:59,311 INFO:     Epoch: 9
2023-01-04 07:47:00,844 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49920972585678103, 'Total loss': 0.49920972585678103} | train loss {'Reaction outcome loss': 0.4854188500852375, 'Total loss': 0.4854188500852375}
2023-01-04 07:47:00,844 INFO:     Found new best model at epoch 9
2023-01-04 07:47:00,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:00,845 INFO:     Epoch: 10
2023-01-04 07:47:02,374 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5046531945466995, 'Total loss': 0.5046531945466995} | train loss {'Reaction outcome loss': 0.48017649063260565, 'Total loss': 0.48017649063260565}
2023-01-04 07:47:02,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:02,374 INFO:     Epoch: 11
2023-01-04 07:47:03,911 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49890093008677167, 'Total loss': 0.49890093008677167} | train loss {'Reaction outcome loss': 0.47270599744477115, 'Total loss': 0.47270599744477115}
2023-01-04 07:47:03,912 INFO:     Found new best model at epoch 11
2023-01-04 07:47:03,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:03,912 INFO:     Epoch: 12
2023-01-04 07:47:05,413 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5482087383667628, 'Total loss': 0.5482087383667628} | train loss {'Reaction outcome loss': 0.4670969471062496, 'Total loss': 0.4670969471062496}
2023-01-04 07:47:05,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:05,414 INFO:     Epoch: 13
2023-01-04 07:47:06,914 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5001345992088317, 'Total loss': 0.5001345992088317} | train loss {'Reaction outcome loss': 0.45888084664449585, 'Total loss': 0.45888084664449585}
2023-01-04 07:47:06,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:06,914 INFO:     Epoch: 14
2023-01-04 07:47:08,465 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4941052973270416, 'Total loss': 0.4941052973270416} | train loss {'Reaction outcome loss': 0.45716921308320085, 'Total loss': 0.45716921308320085}
2023-01-04 07:47:08,465 INFO:     Found new best model at epoch 14
2023-01-04 07:47:08,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:08,466 INFO:     Epoch: 15
2023-01-04 07:47:10,023 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5240928292274475, 'Total loss': 0.5240928292274475} | train loss {'Reaction outcome loss': 0.44689459929536113, 'Total loss': 0.44689459929536113}
2023-01-04 07:47:10,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:10,023 INFO:     Epoch: 16
2023-01-04 07:47:11,573 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5217534124851226, 'Total loss': 0.5217534124851226} | train loss {'Reaction outcome loss': 0.44390413880129875, 'Total loss': 0.44390413880129875}
2023-01-04 07:47:11,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:11,573 INFO:     Epoch: 17
2023-01-04 07:47:13,130 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49505786299705506, 'Total loss': 0.49505786299705506} | train loss {'Reaction outcome loss': 0.43556563996952097, 'Total loss': 0.43556563996952097}
2023-01-04 07:47:13,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:13,130 INFO:     Epoch: 18
2023-01-04 07:47:14,627 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49388787647088367, 'Total loss': 0.49388787647088367} | train loss {'Reaction outcome loss': 0.43304251554684764, 'Total loss': 0.43304251554684764}
2023-01-04 07:47:14,627 INFO:     Found new best model at epoch 18
2023-01-04 07:47:14,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:14,628 INFO:     Epoch: 19
2023-01-04 07:47:16,137 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46521132489045464, 'Total loss': 0.46521132489045464} | train loss {'Reaction outcome loss': 0.43132816072239544, 'Total loss': 0.43132816072239544}
2023-01-04 07:47:16,137 INFO:     Found new best model at epoch 19
2023-01-04 07:47:16,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:16,138 INFO:     Epoch: 20
2023-01-04 07:47:17,671 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5012058039506276, 'Total loss': 0.5012058039506276} | train loss {'Reaction outcome loss': 0.4291665384566391, 'Total loss': 0.4291665384566391}
2023-01-04 07:47:17,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:17,671 INFO:     Epoch: 21
2023-01-04 07:47:19,217 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49328310092290245, 'Total loss': 0.49328310092290245} | train loss {'Reaction outcome loss': 0.42387437121772065, 'Total loss': 0.42387437121772065}
2023-01-04 07:47:19,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:19,218 INFO:     Epoch: 22
2023-01-04 07:47:20,771 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49812681674957277, 'Total loss': 0.49812681674957277} | train loss {'Reaction outcome loss': 0.4211458960077265, 'Total loss': 0.4211458960077265}
2023-01-04 07:47:20,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:20,772 INFO:     Epoch: 23
2023-01-04 07:47:22,346 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46744648019472756, 'Total loss': 0.46744648019472756} | train loss {'Reaction outcome loss': 0.4157348389808948, 'Total loss': 0.4157348389808948}
2023-01-04 07:47:22,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:22,346 INFO:     Epoch: 24
2023-01-04 07:47:23,893 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4914698898792267, 'Total loss': 0.4914698898792267} | train loss {'Reaction outcome loss': 0.4109304582788831, 'Total loss': 0.4109304582788831}
2023-01-04 07:47:23,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:23,893 INFO:     Epoch: 25
2023-01-04 07:47:25,423 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.501218581199646, 'Total loss': 0.501218581199646} | train loss {'Reaction outcome loss': 0.41181649300423295, 'Total loss': 0.41181649300423295}
2023-01-04 07:47:25,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:25,423 INFO:     Epoch: 26
2023-01-04 07:47:26,948 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4672275384267171, 'Total loss': 0.4672275384267171} | train loss {'Reaction outcome loss': 0.40580359218648937, 'Total loss': 0.40580359218648937}
2023-01-04 07:47:26,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:26,949 INFO:     Epoch: 27
2023-01-04 07:47:28,470 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4641050656636556, 'Total loss': 0.4641050656636556} | train loss {'Reaction outcome loss': 0.39887054428294466, 'Total loss': 0.39887054428294466}
2023-01-04 07:47:28,470 INFO:     Found new best model at epoch 27
2023-01-04 07:47:28,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:28,471 INFO:     Epoch: 28
2023-01-04 07:47:30,008 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46909340023994445, 'Total loss': 0.46909340023994445} | train loss {'Reaction outcome loss': 0.396813381313186, 'Total loss': 0.396813381313186}
2023-01-04 07:47:30,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:30,008 INFO:     Epoch: 29
2023-01-04 07:47:31,534 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46163338820139566, 'Total loss': 0.46163338820139566} | train loss {'Reaction outcome loss': 0.39377642163645216, 'Total loss': 0.39377642163645216}
2023-01-04 07:47:31,534 INFO:     Found new best model at epoch 29
2023-01-04 07:47:31,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:31,535 INFO:     Epoch: 30
2023-01-04 07:47:33,042 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4690227806568146, 'Total loss': 0.4690227806568146} | train loss {'Reaction outcome loss': 0.3913865762424993, 'Total loss': 0.3913865762424993}
2023-01-04 07:47:33,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:33,042 INFO:     Epoch: 31
2023-01-04 07:47:34,573 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4684420883655548, 'Total loss': 0.4684420883655548} | train loss {'Reaction outcome loss': 0.38782879087951155, 'Total loss': 0.38782879087951155}
2023-01-04 07:47:34,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:34,573 INFO:     Epoch: 32
2023-01-04 07:47:36,140 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4712986866633097, 'Total loss': 0.4712986866633097} | train loss {'Reaction outcome loss': 0.38085718308285477, 'Total loss': 0.38085718308285477}
2023-01-04 07:47:36,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:36,140 INFO:     Epoch: 33
2023-01-04 07:47:37,683 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48715698917706807, 'Total loss': 0.48715698917706807} | train loss {'Reaction outcome loss': 0.38149284822491064, 'Total loss': 0.38149284822491064}
2023-01-04 07:47:37,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:37,684 INFO:     Epoch: 34
2023-01-04 07:47:39,222 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4683649023373922, 'Total loss': 0.4683649023373922} | train loss {'Reaction outcome loss': 0.3759393827928292, 'Total loss': 0.3759393827928292}
2023-01-04 07:47:39,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:39,223 INFO:     Epoch: 35
2023-01-04 07:47:40,769 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4570817252000173, 'Total loss': 0.4570817252000173} | train loss {'Reaction outcome loss': 0.37331332705723935, 'Total loss': 0.37331332705723935}
2023-01-04 07:47:40,769 INFO:     Found new best model at epoch 35
2023-01-04 07:47:40,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:40,770 INFO:     Epoch: 36
2023-01-04 07:47:42,281 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.496928862730662, 'Total loss': 0.496928862730662} | train loss {'Reaction outcome loss': 0.3694739891113816, 'Total loss': 0.3694739891113816}
2023-01-04 07:47:42,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:42,281 INFO:     Epoch: 37
2023-01-04 07:47:43,799 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4675515671571096, 'Total loss': 0.4675515671571096} | train loss {'Reaction outcome loss': 0.36271031703049444, 'Total loss': 0.36271031703049444}
2023-01-04 07:47:43,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:43,799 INFO:     Epoch: 38
2023-01-04 07:47:45,333 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4595402851700783, 'Total loss': 0.4595402851700783} | train loss {'Reaction outcome loss': 0.3656162319930045, 'Total loss': 0.3656162319930045}
2023-01-04 07:47:45,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:45,333 INFO:     Epoch: 39
2023-01-04 07:47:46,879 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44583873425920806, 'Total loss': 0.44583873425920806} | train loss {'Reaction outcome loss': 0.36162868529667347, 'Total loss': 0.36162868529667347}
2023-01-04 07:47:46,879 INFO:     Found new best model at epoch 39
2023-01-04 07:47:46,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:46,880 INFO:     Epoch: 40
2023-01-04 07:47:48,420 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49987886746724447, 'Total loss': 0.49987886746724447} | train loss {'Reaction outcome loss': 0.35746800632048875, 'Total loss': 0.35746800632048875}
2023-01-04 07:47:48,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:48,420 INFO:     Epoch: 41
2023-01-04 07:47:49,958 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5149031281471252, 'Total loss': 0.5149031281471252} | train loss {'Reaction outcome loss': 0.35607370835193347, 'Total loss': 0.35607370835193347}
2023-01-04 07:47:49,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:49,959 INFO:     Epoch: 42
2023-01-04 07:47:51,483 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48257826964060463, 'Total loss': 0.48257826964060463} | train loss {'Reaction outcome loss': 0.3556085311886155, 'Total loss': 0.3556085311886155}
2023-01-04 07:47:51,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:51,484 INFO:     Epoch: 43
2023-01-04 07:47:53,015 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5255674461523692, 'Total loss': 0.5255674461523692} | train loss {'Reaction outcome loss': 0.35239054328137703, 'Total loss': 0.35239054328137703}
2023-01-04 07:47:53,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:53,015 INFO:     Epoch: 44
2023-01-04 07:47:54,572 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4866634418567022, 'Total loss': 0.4866634418567022} | train loss {'Reaction outcome loss': 0.3475700993459303, 'Total loss': 0.3475700993459303}
2023-01-04 07:47:54,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:54,572 INFO:     Epoch: 45
2023-01-04 07:47:56,110 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4947327792644501, 'Total loss': 0.4947327792644501} | train loss {'Reaction outcome loss': 0.34343798690553984, 'Total loss': 0.34343798690553984}
2023-01-04 07:47:56,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:56,112 INFO:     Epoch: 46
2023-01-04 07:47:57,652 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4718580663204193, 'Total loss': 0.4718580663204193} | train loss {'Reaction outcome loss': 0.3399407284491228, 'Total loss': 0.3399407284491228}
2023-01-04 07:47:57,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:57,652 INFO:     Epoch: 47
2023-01-04 07:47:59,175 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47950581312179563, 'Total loss': 0.47950581312179563} | train loss {'Reaction outcome loss': 0.337816643736738, 'Total loss': 0.337816643736738}
2023-01-04 07:47:59,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:47:59,175 INFO:     Epoch: 48
2023-01-04 07:48:00,698 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.468786883354187, 'Total loss': 0.468786883354187} | train loss {'Reaction outcome loss': 0.33515444755445034, 'Total loss': 0.33515444755445034}
2023-01-04 07:48:00,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:00,698 INFO:     Epoch: 49
2023-01-04 07:48:02,250 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5234019875526428, 'Total loss': 0.5234019875526428} | train loss {'Reaction outcome loss': 0.3372131978526657, 'Total loss': 0.3372131978526657}
2023-01-04 07:48:02,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:02,251 INFO:     Epoch: 50
2023-01-04 07:48:03,788 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45683866838614146, 'Total loss': 0.45683866838614146} | train loss {'Reaction outcome loss': 0.33684509968037135, 'Total loss': 0.33684509968037135}
2023-01-04 07:48:03,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:03,788 INFO:     Epoch: 51
2023-01-04 07:48:05,335 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4929944574832916, 'Total loss': 0.4929944574832916} | train loss {'Reaction outcome loss': 0.33368369000844467, 'Total loss': 0.33368369000844467}
2023-01-04 07:48:05,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:05,335 INFO:     Epoch: 52
2023-01-04 07:48:06,872 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4587535192569097, 'Total loss': 0.4587535192569097} | train loss {'Reaction outcome loss': 0.33268210471986415, 'Total loss': 0.33268210471986415}
2023-01-04 07:48:06,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:06,872 INFO:     Epoch: 53
2023-01-04 07:48:08,383 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48470352490743, 'Total loss': 0.48470352490743} | train loss {'Reaction outcome loss': 0.32781180417363026, 'Total loss': 0.32781180417363026}
2023-01-04 07:48:08,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:08,383 INFO:     Epoch: 54
2023-01-04 07:48:09,889 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49292958080768584, 'Total loss': 0.49292958080768584} | train loss {'Reaction outcome loss': 0.32608802963198324, 'Total loss': 0.32608802963198324}
2023-01-04 07:48:09,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:09,889 INFO:     Epoch: 55
2023-01-04 07:48:11,431 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4769706110159556, 'Total loss': 0.4769706110159556} | train loss {'Reaction outcome loss': 0.324749126238919, 'Total loss': 0.324749126238919}
2023-01-04 07:48:11,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:11,431 INFO:     Epoch: 56
2023-01-04 07:48:12,990 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4987245976924896, 'Total loss': 0.4987245976924896} | train loss {'Reaction outcome loss': 0.3210498353828004, 'Total loss': 0.3210498353828004}
2023-01-04 07:48:12,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:12,990 INFO:     Epoch: 57
2023-01-04 07:48:14,536 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4851624091466268, 'Total loss': 0.4851624091466268} | train loss {'Reaction outcome loss': 0.32030398027473317, 'Total loss': 0.32030398027473317}
2023-01-04 07:48:14,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:14,537 INFO:     Epoch: 58
2023-01-04 07:48:16,067 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45084909001986184, 'Total loss': 0.45084909001986184} | train loss {'Reaction outcome loss': 0.3201309988623137, 'Total loss': 0.3201309988623137}
2023-01-04 07:48:16,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:16,068 INFO:     Epoch: 59
2023-01-04 07:48:17,571 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49621493617693585, 'Total loss': 0.49621493617693585} | train loss {'Reaction outcome loss': 0.31577299813647847, 'Total loss': 0.31577299813647847}
2023-01-04 07:48:17,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:17,571 INFO:     Epoch: 60
2023-01-04 07:48:19,073 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4867567638556162, 'Total loss': 0.4867567638556162} | train loss {'Reaction outcome loss': 0.31284243504315506, 'Total loss': 0.31284243504315506}
2023-01-04 07:48:19,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:19,073 INFO:     Epoch: 61
2023-01-04 07:48:20,613 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4651394685109456, 'Total loss': 0.4651394685109456} | train loss {'Reaction outcome loss': 0.31420414815673897, 'Total loss': 0.31420414815673897}
2023-01-04 07:48:20,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:20,613 INFO:     Epoch: 62
2023-01-04 07:48:22,154 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45580432812372845, 'Total loss': 0.45580432812372845} | train loss {'Reaction outcome loss': 0.31033301956596826, 'Total loss': 0.31033301956596826}
2023-01-04 07:48:22,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:22,154 INFO:     Epoch: 63
2023-01-04 07:48:23,688 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4982835054397583, 'Total loss': 0.4982835054397583} | train loss {'Reaction outcome loss': 0.30694534806978135, 'Total loss': 0.30694534806978135}
2023-01-04 07:48:23,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:23,688 INFO:     Epoch: 64
2023-01-04 07:48:25,225 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.485686324040095, 'Total loss': 0.485686324040095} | train loss {'Reaction outcome loss': 0.3040508537556662, 'Total loss': 0.3040508537556662}
2023-01-04 07:48:25,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:25,225 INFO:     Epoch: 65
2023-01-04 07:48:26,718 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48016082843144736, 'Total loss': 0.48016082843144736} | train loss {'Reaction outcome loss': 0.3085157072969845, 'Total loss': 0.3085157072969845}
2023-01-04 07:48:26,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:26,720 INFO:     Epoch: 66
2023-01-04 07:48:28,225 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5123428086439769, 'Total loss': 0.5123428086439769} | train loss {'Reaction outcome loss': 0.3031049594556019, 'Total loss': 0.3031049594556019}
2023-01-04 07:48:28,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:28,225 INFO:     Epoch: 67
2023-01-04 07:48:29,753 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5282493968804677, 'Total loss': 0.5282493968804677} | train loss {'Reaction outcome loss': 0.3075129289193686, 'Total loss': 0.3075129289193686}
2023-01-04 07:48:29,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:29,753 INFO:     Epoch: 68
2023-01-04 07:48:31,289 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4879174202680588, 'Total loss': 0.4879174202680588} | train loss {'Reaction outcome loss': 0.3000922654192526, 'Total loss': 0.3000922654192526}
2023-01-04 07:48:31,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:31,289 INFO:     Epoch: 69
2023-01-04 07:48:32,820 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4670237272977829, 'Total loss': 0.4670237272977829} | train loss {'Reaction outcome loss': 0.3027204087092763, 'Total loss': 0.3027204087092763}
2023-01-04 07:48:32,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:32,821 INFO:     Epoch: 70
2023-01-04 07:48:34,357 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4948565989732742, 'Total loss': 0.4948565989732742} | train loss {'Reaction outcome loss': 0.2998664579166597, 'Total loss': 0.2998664579166597}
2023-01-04 07:48:34,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:34,358 INFO:     Epoch: 71
2023-01-04 07:48:35,863 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48505143423875174, 'Total loss': 0.48505143423875174} | train loss {'Reaction outcome loss': 0.29512014267317976, 'Total loss': 0.29512014267317976}
2023-01-04 07:48:35,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:35,863 INFO:     Epoch: 72
2023-01-04 07:48:37,362 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4742322919269403, 'Total loss': 0.4742322919269403} | train loss {'Reaction outcome loss': 0.29277710817181146, 'Total loss': 0.29277710817181146}
2023-01-04 07:48:37,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:37,362 INFO:     Epoch: 73
2023-01-04 07:48:38,913 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47604017953077954, 'Total loss': 0.47604017953077954} | train loss {'Reaction outcome loss': 0.29504101131206906, 'Total loss': 0.29504101131206906}
2023-01-04 07:48:38,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:38,913 INFO:     Epoch: 74
2023-01-04 07:48:40,445 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4834656298160553, 'Total loss': 0.4834656298160553} | train loss {'Reaction outcome loss': 0.2939112516386168, 'Total loss': 0.2939112516386168}
2023-01-04 07:48:40,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:40,445 INFO:     Epoch: 75
2023-01-04 07:48:41,983 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47009596625963845, 'Total loss': 0.47009596625963845} | train loss {'Reaction outcome loss': 0.2901482335377089, 'Total loss': 0.2901482335377089}
2023-01-04 07:48:41,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:41,983 INFO:     Epoch: 76
2023-01-04 07:48:43,533 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4718538373708725, 'Total loss': 0.4718538373708725} | train loss {'Reaction outcome loss': 0.2882771253749564, 'Total loss': 0.2882771253749564}
2023-01-04 07:48:43,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:43,533 INFO:     Epoch: 77
2023-01-04 07:48:45,047 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47616230249404906, 'Total loss': 0.47616230249404906} | train loss {'Reaction outcome loss': 0.2945047920985973, 'Total loss': 0.2945047920985973}
2023-01-04 07:48:45,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:45,048 INFO:     Epoch: 78
2023-01-04 07:48:46,550 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48548395236333214, 'Total loss': 0.48548395236333214} | train loss {'Reaction outcome loss': 0.28849634012350667, 'Total loss': 0.28849634012350667}
2023-01-04 07:48:46,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:46,550 INFO:     Epoch: 79
2023-01-04 07:48:48,088 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47802050511042277, 'Total loss': 0.47802050511042277} | train loss {'Reaction outcome loss': 0.2859326121516717, 'Total loss': 0.2859326121516717}
2023-01-04 07:48:48,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:48,088 INFO:     Epoch: 80
2023-01-04 07:48:49,607 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4566916843255361, 'Total loss': 0.4566916843255361} | train loss {'Reaction outcome loss': 0.28506246542100944, 'Total loss': 0.28506246542100944}
2023-01-04 07:48:49,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:49,607 INFO:     Epoch: 81
2023-01-04 07:48:51,140 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5213381946086884, 'Total loss': 0.5213381946086884} | train loss {'Reaction outcome loss': 0.27788056378617826, 'Total loss': 0.27788056378617826}
2023-01-04 07:48:51,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:51,140 INFO:     Epoch: 82
2023-01-04 07:48:52,665 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.494502188762029, 'Total loss': 0.494502188762029} | train loss {'Reaction outcome loss': 0.2840738152955478, 'Total loss': 0.2840738152955478}
2023-01-04 07:48:52,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:52,665 INFO:     Epoch: 83
2023-01-04 07:48:54,163 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5174309929211934, 'Total loss': 0.5174309929211934} | train loss {'Reaction outcome loss': 0.28495716820760963, 'Total loss': 0.28495716820760963}
2023-01-04 07:48:54,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:54,164 INFO:     Epoch: 84
2023-01-04 07:48:55,648 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4714629093805949, 'Total loss': 0.4714629093805949} | train loss {'Reaction outcome loss': 0.27921912693606193, 'Total loss': 0.27921912693606193}
2023-01-04 07:48:55,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:55,648 INFO:     Epoch: 85
2023-01-04 07:48:57,179 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5031154553095499, 'Total loss': 0.5031154553095499} | train loss {'Reaction outcome loss': 0.2781079996909414, 'Total loss': 0.2781079996909414}
2023-01-04 07:48:57,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:57,181 INFO:     Epoch: 86
2023-01-04 07:48:58,703 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.517453690369924, 'Total loss': 0.517453690369924} | train loss {'Reaction outcome loss': 0.2796764681900377, 'Total loss': 0.2796764681900377}
2023-01-04 07:48:58,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:48:58,703 INFO:     Epoch: 87
2023-01-04 07:49:00,225 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4857815315326055, 'Total loss': 0.4857815315326055} | train loss {'Reaction outcome loss': 0.2725035628447166, 'Total loss': 0.2725035628447166}
2023-01-04 07:49:00,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:00,225 INFO:     Epoch: 88
2023-01-04 07:49:01,767 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45490694642066953, 'Total loss': 0.45490694642066953} | train loss {'Reaction outcome loss': 0.2725832057987159, 'Total loss': 0.2725832057987159}
2023-01-04 07:49:01,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:01,767 INFO:     Epoch: 89
2023-01-04 07:49:03,264 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48601322770118716, 'Total loss': 0.48601322770118716} | train loss {'Reaction outcome loss': 0.27158393091334526, 'Total loss': 0.27158393091334526}
2023-01-04 07:49:03,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:03,265 INFO:     Epoch: 90
2023-01-04 07:49:04,767 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47533965706825254, 'Total loss': 0.47533965706825254} | train loss {'Reaction outcome loss': 0.27357832607113836, 'Total loss': 0.27357832607113836}
2023-01-04 07:49:04,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:04,768 INFO:     Epoch: 91
2023-01-04 07:49:06,309 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4609261304140091, 'Total loss': 0.4609261304140091} | train loss {'Reaction outcome loss': 0.2684919012116862, 'Total loss': 0.2684919012116862}
2023-01-04 07:49:06,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:06,309 INFO:     Epoch: 92
2023-01-04 07:49:07,852 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5218695739905039, 'Total loss': 0.5218695739905039} | train loss {'Reaction outcome loss': 0.2702433245031388, 'Total loss': 0.2702433245031388}
2023-01-04 07:49:07,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:07,853 INFO:     Epoch: 93
2023-01-04 07:49:09,390 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5109251270691554, 'Total loss': 0.5109251270691554} | train loss {'Reaction outcome loss': 0.26972743563162976, 'Total loss': 0.26972743563162976}
2023-01-04 07:49:09,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:09,391 INFO:     Epoch: 94
2023-01-04 07:49:10,931 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4789007753133774, 'Total loss': 0.4789007753133774} | train loss {'Reaction outcome loss': 0.2701946627143975, 'Total loss': 0.2701946627143975}
2023-01-04 07:49:10,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:10,932 INFO:     Epoch: 95
2023-01-04 07:49:12,424 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48856528401374816, 'Total loss': 0.48856528401374816} | train loss {'Reaction outcome loss': 0.2691363187390806, 'Total loss': 0.2691363187390806}
2023-01-04 07:49:12,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:12,424 INFO:     Epoch: 96
2023-01-04 07:49:13,915 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4756607542435328, 'Total loss': 0.4756607542435328} | train loss {'Reaction outcome loss': 0.2689401882499347, 'Total loss': 0.2689401882499347}
2023-01-04 07:49:13,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:13,916 INFO:     Epoch: 97
2023-01-04 07:49:15,442 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5014091908931733, 'Total loss': 0.5014091908931733} | train loss {'Reaction outcome loss': 0.2637113774870778, 'Total loss': 0.2637113774870778}
2023-01-04 07:49:15,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:15,443 INFO:     Epoch: 98
2023-01-04 07:49:16,979 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4754254053036372, 'Total loss': 0.4754254053036372} | train loss {'Reaction outcome loss': 0.26739803050736805, 'Total loss': 0.26739803050736805}
2023-01-04 07:49:16,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:16,980 INFO:     Epoch: 99
2023-01-04 07:49:18,527 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46771111389001213, 'Total loss': 0.46771111389001213} | train loss {'Reaction outcome loss': 0.2697634290317039, 'Total loss': 0.2697634290317039}
2023-01-04 07:49:18,527 INFO:     Best model found after epoch 40 of 100.
2023-01-04 07:49:18,528 INFO:   Done with stage: TRAINING
2023-01-04 07:49:18,528 INFO:   Starting stage: EVALUATION
2023-01-04 07:49:18,668 INFO:   Done with stage: EVALUATION
2023-01-04 07:49:18,668 INFO:   Leaving out SEQ value Fold_1
2023-01-04 07:49:18,681 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:49:18,681 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:49:19,337 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:49:19,337 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:49:19,406 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:49:19,406 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:49:19,406 INFO:     No hyperparam tuning for this model
2023-01-04 07:49:19,406 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:49:19,406 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:49:19,407 INFO:     None feature selector for col prot
2023-01-04 07:49:19,407 INFO:     None feature selector for col prot
2023-01-04 07:49:19,407 INFO:     None feature selector for col prot
2023-01-04 07:49:19,408 INFO:     None feature selector for col chem
2023-01-04 07:49:19,408 INFO:     None feature selector for col chem
2023-01-04 07:49:19,408 INFO:     None feature selector for col chem
2023-01-04 07:49:19,408 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:49:19,408 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:49:19,409 INFO:     Number of params in model 70111
2023-01-04 07:49:19,413 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:49:19,413 INFO:   Starting stage: TRAINING
2023-01-04 07:49:19,455 INFO:     Val loss before train {'Reaction outcome loss': 1.111202323436737, 'Total loss': 1.111202323436737}
2023-01-04 07:49:19,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:19,456 INFO:     Epoch: 0
2023-01-04 07:49:20,974 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7917659362157186, 'Total loss': 0.7917659362157186} | train loss {'Reaction outcome loss': 0.8224144823093346, 'Total loss': 0.8224144823093346}
2023-01-04 07:49:20,974 INFO:     Found new best model at epoch 0
2023-01-04 07:49:20,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:20,975 INFO:     Epoch: 1
2023-01-04 07:49:22,493 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7104996879895528, 'Total loss': 0.7104996879895528} | train loss {'Reaction outcome loss': 0.6567565605476282, 'Total loss': 0.6567565605476282}
2023-01-04 07:49:22,493 INFO:     Found new best model at epoch 1
2023-01-04 07:49:22,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:22,494 INFO:     Epoch: 2
2023-01-04 07:49:24,029 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6204131444295248, 'Total loss': 0.6204131444295248} | train loss {'Reaction outcome loss': 0.5823875188395597, 'Total loss': 0.5823875188395597}
2023-01-04 07:49:24,029 INFO:     Found new best model at epoch 2
2023-01-04 07:49:24,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:24,030 INFO:     Epoch: 3
2023-01-04 07:49:25,584 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5812074144681295, 'Total loss': 0.5812074144681295} | train loss {'Reaction outcome loss': 0.5471950313751248, 'Total loss': 0.5471950313751248}
2023-01-04 07:49:25,585 INFO:     Found new best model at epoch 3
2023-01-04 07:49:25,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:25,585 INFO:     Epoch: 4
2023-01-04 07:49:27,140 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5986429045597712, 'Total loss': 0.5986429045597712} | train loss {'Reaction outcome loss': 0.5351563077689945, 'Total loss': 0.5351563077689945}
2023-01-04 07:49:27,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:27,141 INFO:     Epoch: 5
2023-01-04 07:49:28,693 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5785203516483307, 'Total loss': 0.5785203516483307} | train loss {'Reaction outcome loss': 0.5282149593467298, 'Total loss': 0.5282149593467298}
2023-01-04 07:49:28,694 INFO:     Found new best model at epoch 5
2023-01-04 07:49:28,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:28,695 INFO:     Epoch: 6
2023-01-04 07:49:30,216 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.543809590737025, 'Total loss': 0.543809590737025} | train loss {'Reaction outcome loss': 0.49654433434530487, 'Total loss': 0.49654433434530487}
2023-01-04 07:49:30,216 INFO:     Found new best model at epoch 6
2023-01-04 07:49:30,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:30,217 INFO:     Epoch: 7
2023-01-04 07:49:31,742 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5473321239153545, 'Total loss': 0.5473321239153545} | train loss {'Reaction outcome loss': 0.5005144036334493, 'Total loss': 0.5005144036334493}
2023-01-04 07:49:31,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:31,742 INFO:     Epoch: 8
2023-01-04 07:49:33,297 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5473632872104645, 'Total loss': 0.5473632872104645} | train loss {'Reaction outcome loss': 0.4926606320600579, 'Total loss': 0.4926606320600579}
2023-01-04 07:49:33,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:33,297 INFO:     Epoch: 9
2023-01-04 07:49:34,852 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5283787260452907, 'Total loss': 0.5283787260452907} | train loss {'Reaction outcome loss': 0.4804741095049658, 'Total loss': 0.4804741095049658}
2023-01-04 07:49:34,853 INFO:     Found new best model at epoch 9
2023-01-04 07:49:34,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:34,854 INFO:     Epoch: 10
2023-01-04 07:49:36,403 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5549003700415294, 'Total loss': 0.5549003700415294} | train loss {'Reaction outcome loss': 0.4941646846524183, 'Total loss': 0.4941646846524183}
2023-01-04 07:49:36,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:36,403 INFO:     Epoch: 11
2023-01-04 07:49:37,956 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5248782376448313, 'Total loss': 0.5248782376448313} | train loss {'Reaction outcome loss': 0.5007710598874837, 'Total loss': 0.5007710598874837}
2023-01-04 07:49:37,956 INFO:     Found new best model at epoch 11
2023-01-04 07:49:37,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:37,957 INFO:     Epoch: 12
2023-01-04 07:49:39,487 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5186023950576782, 'Total loss': 0.5186023950576782} | train loss {'Reaction outcome loss': 0.46648607273464615, 'Total loss': 0.46648607273464615}
2023-01-04 07:49:39,487 INFO:     Found new best model at epoch 12
2023-01-04 07:49:39,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:39,487 INFO:     Epoch: 13
2023-01-04 07:49:41,014 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4920270403226217, 'Total loss': 0.4920270403226217} | train loss {'Reaction outcome loss': 0.4589497106338757, 'Total loss': 0.4589497106338757}
2023-01-04 07:49:41,014 INFO:     Found new best model at epoch 13
2023-01-04 07:49:41,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:41,015 INFO:     Epoch: 14
2023-01-04 07:49:42,565 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5445024073123932, 'Total loss': 0.5445024073123932} | train loss {'Reaction outcome loss': 0.45926876044899656, 'Total loss': 0.45926876044899656}
2023-01-04 07:49:42,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:42,565 INFO:     Epoch: 15
2023-01-04 07:49:44,130 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5486007849375407, 'Total loss': 0.5486007849375407} | train loss {'Reaction outcome loss': 0.44707871610644623, 'Total loss': 0.44707871610644623}
2023-01-04 07:49:44,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:44,130 INFO:     Epoch: 16
2023-01-04 07:49:45,684 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4918713867664337, 'Total loss': 0.4918713867664337} | train loss {'Reaction outcome loss': 0.4401493264139508, 'Total loss': 0.4401493264139508}
2023-01-04 07:49:45,684 INFO:     Found new best model at epoch 16
2023-01-04 07:49:45,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:45,685 INFO:     Epoch: 17
2023-01-04 07:49:47,245 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49369173248608905, 'Total loss': 0.49369173248608905} | train loss {'Reaction outcome loss': 0.4380900031773954, 'Total loss': 0.4380900031773954}
2023-01-04 07:49:47,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:47,246 INFO:     Epoch: 18
2023-01-04 07:49:48,788 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48546407123406726, 'Total loss': 0.48546407123406726} | train loss {'Reaction outcome loss': 0.4329981357939001, 'Total loss': 0.4329981357939001}
2023-01-04 07:49:48,788 INFO:     Found new best model at epoch 18
2023-01-04 07:49:48,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:48,789 INFO:     Epoch: 19
2023-01-04 07:49:50,313 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5216817637284596, 'Total loss': 0.5216817637284596} | train loss {'Reaction outcome loss': 0.43628035646701313, 'Total loss': 0.43628035646701313}
2023-01-04 07:49:50,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:50,313 INFO:     Epoch: 20
2023-01-04 07:49:51,872 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.489506251613299, 'Total loss': 0.489506251613299} | train loss {'Reaction outcome loss': 0.4267070929965247, 'Total loss': 0.4267070929965247}
2023-01-04 07:49:51,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:51,872 INFO:     Epoch: 21
2023-01-04 07:49:53,427 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4834160029888153, 'Total loss': 0.4834160029888153} | train loss {'Reaction outcome loss': 0.4257091171242317, 'Total loss': 0.4257091171242317}
2023-01-04 07:49:53,428 INFO:     Found new best model at epoch 21
2023-01-04 07:49:53,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:53,428 INFO:     Epoch: 22
2023-01-04 07:49:54,994 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5169988205035527, 'Total loss': 0.5169988205035527} | train loss {'Reaction outcome loss': 0.41856439522319083, 'Total loss': 0.41856439522319083}
2023-01-04 07:49:54,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:54,995 INFO:     Epoch: 23
2023-01-04 07:49:56,557 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.492986387014389, 'Total loss': 0.492986387014389} | train loss {'Reaction outcome loss': 0.4263519560032443, 'Total loss': 0.4263519560032443}
2023-01-04 07:49:56,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:56,557 INFO:     Epoch: 24
2023-01-04 07:49:58,085 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49130580921967826, 'Total loss': 0.49130580921967826} | train loss {'Reaction outcome loss': 0.4140449808235618, 'Total loss': 0.4140449808235618}
2023-01-04 07:49:58,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:58,085 INFO:     Epoch: 25
2023-01-04 07:49:59,600 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5005483110745748, 'Total loss': 0.5005483110745748} | train loss {'Reaction outcome loss': 0.409151302056684, 'Total loss': 0.409151302056684}
2023-01-04 07:49:59,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:49:59,601 INFO:     Epoch: 26
2023-01-04 07:50:01,158 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48912428319454193, 'Total loss': 0.48912428319454193} | train loss {'Reaction outcome loss': 0.4013228638880495, 'Total loss': 0.4013228638880495}
2023-01-04 07:50:01,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:01,158 INFO:     Epoch: 27
2023-01-04 07:50:02,715 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4857712606588999, 'Total loss': 0.4857712606588999} | train loss {'Reaction outcome loss': 0.398121393436022, 'Total loss': 0.398121393436022}
2023-01-04 07:50:02,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:02,715 INFO:     Epoch: 28
2023-01-04 07:50:04,280 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46192007660865786, 'Total loss': 0.46192007660865786} | train loss {'Reaction outcome loss': 0.3951714396804902, 'Total loss': 0.3951714396804902}
2023-01-04 07:50:04,281 INFO:     Found new best model at epoch 28
2023-01-04 07:50:04,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:04,282 INFO:     Epoch: 29
2023-01-04 07:50:05,823 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4861294448375702, 'Total loss': 0.4861294448375702} | train loss {'Reaction outcome loss': 0.3891304237768054, 'Total loss': 0.3891304237768054}
2023-01-04 07:50:05,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:05,823 INFO:     Epoch: 30
2023-01-04 07:50:07,347 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47493315239747363, 'Total loss': 0.47493315239747363} | train loss {'Reaction outcome loss': 0.3902601146314671, 'Total loss': 0.3902601146314671}
2023-01-04 07:50:07,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:07,348 INFO:     Epoch: 31
2023-01-04 07:50:08,875 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46070986489454907, 'Total loss': 0.46070986489454907} | train loss {'Reaction outcome loss': 0.3818219232312201, 'Total loss': 0.3818219232312201}
2023-01-04 07:50:08,875 INFO:     Found new best model at epoch 31
2023-01-04 07:50:08,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:08,876 INFO:     Epoch: 32
2023-01-04 07:50:10,428 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4885519176721573, 'Total loss': 0.4885519176721573} | train loss {'Reaction outcome loss': 0.38128225620080164, 'Total loss': 0.38128225620080164}
2023-01-04 07:50:10,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:10,429 INFO:     Epoch: 33
2023-01-04 07:50:11,993 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4689183314641317, 'Total loss': 0.4689183314641317} | train loss {'Reaction outcome loss': 0.3822374522847974, 'Total loss': 0.3822374522847974}
2023-01-04 07:50:11,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:11,994 INFO:     Epoch: 34
2023-01-04 07:50:13,543 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4502278407414754, 'Total loss': 0.4502278407414754} | train loss {'Reaction outcome loss': 0.39669760733343445, 'Total loss': 0.39669760733343445}
2023-01-04 07:50:13,543 INFO:     Found new best model at epoch 34
2023-01-04 07:50:13,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:13,544 INFO:     Epoch: 35
2023-01-04 07:50:15,080 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45503732562065125, 'Total loss': 0.45503732562065125} | train loss {'Reaction outcome loss': 0.37108540394599887, 'Total loss': 0.37108540394599887}
2023-01-04 07:50:15,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:15,080 INFO:     Epoch: 36
2023-01-04 07:50:16,611 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4602899730205536, 'Total loss': 0.4602899730205536} | train loss {'Reaction outcome loss': 0.3895957174886396, 'Total loss': 0.3895957174886396}
2023-01-04 07:50:16,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:16,612 INFO:     Epoch: 37
2023-01-04 07:50:18,154 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4727299650510152, 'Total loss': 0.4727299650510152} | train loss {'Reaction outcome loss': 0.3888413561103137, 'Total loss': 0.3888413561103137}
2023-01-04 07:50:18,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:18,154 INFO:     Epoch: 38
2023-01-04 07:50:19,706 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4377021084229151, 'Total loss': 0.4377021084229151} | train loss {'Reaction outcome loss': 0.36938023901935935, 'Total loss': 0.36938023901935935}
2023-01-04 07:50:19,706 INFO:     Found new best model at epoch 38
2023-01-04 07:50:19,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:19,707 INFO:     Epoch: 39
2023-01-04 07:50:21,264 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47148759762446085, 'Total loss': 0.47148759762446085} | train loss {'Reaction outcome loss': 0.3568228198760746, 'Total loss': 0.3568228198760746}
2023-01-04 07:50:21,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:21,264 INFO:     Epoch: 40
2023-01-04 07:50:22,810 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4702455043792725, 'Total loss': 0.4702455043792725} | train loss {'Reaction outcome loss': 0.35225334145344683, 'Total loss': 0.35225334145344683}
2023-01-04 07:50:22,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:22,811 INFO:     Epoch: 41
2023-01-04 07:50:24,322 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48257975876331327, 'Total loss': 0.48257975876331327} | train loss {'Reaction outcome loss': 0.3700749312082063, 'Total loss': 0.3700749312082063}
2023-01-04 07:50:24,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:24,322 INFO:     Epoch: 42
2023-01-04 07:50:25,855 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4440378606319427, 'Total loss': 0.4440378606319427} | train loss {'Reaction outcome loss': 0.35370456518575194, 'Total loss': 0.35370456518575194}
2023-01-04 07:50:25,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:25,856 INFO:     Epoch: 43
2023-01-04 07:50:27,418 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4520449678103129, 'Total loss': 0.4520449678103129} | train loss {'Reaction outcome loss': 0.34585447409947356, 'Total loss': 0.34585447409947356}
2023-01-04 07:50:27,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:27,419 INFO:     Epoch: 44
2023-01-04 07:50:28,991 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4833556274573008, 'Total loss': 0.4833556274573008} | train loss {'Reaction outcome loss': 0.3449819656021461, 'Total loss': 0.3449819656021461}
2023-01-04 07:50:28,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:28,991 INFO:     Epoch: 45
2023-01-04 07:50:30,563 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49287496507167816, 'Total loss': 0.49287496507167816} | train loss {'Reaction outcome loss': 0.34608255351043266, 'Total loss': 0.34608255351043266}
2023-01-04 07:50:30,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:30,563 INFO:     Epoch: 46
2023-01-04 07:50:32,157 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43647756377855934, 'Total loss': 0.43647756377855934} | train loss {'Reaction outcome loss': 0.35480364910272066, 'Total loss': 0.35480364910272066}
2023-01-04 07:50:32,157 INFO:     Found new best model at epoch 46
2023-01-04 07:50:32,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:32,158 INFO:     Epoch: 47
2023-01-04 07:50:33,689 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4614637136459351, 'Total loss': 0.4614637136459351} | train loss {'Reaction outcome loss': 0.3340600372393833, 'Total loss': 0.3340600372393833}
2023-01-04 07:50:33,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:33,690 INFO:     Epoch: 48
2023-01-04 07:50:35,220 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42513650258382163, 'Total loss': 0.42513650258382163} | train loss {'Reaction outcome loss': 0.3329362505591353, 'Total loss': 0.3329362505591353}
2023-01-04 07:50:35,222 INFO:     Found new best model at epoch 48
2023-01-04 07:50:35,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:35,222 INFO:     Epoch: 49
2023-01-04 07:50:36,790 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4259999687472979, 'Total loss': 0.4259999687472979} | train loss {'Reaction outcome loss': 0.33912627644620946, 'Total loss': 0.33912627644620946}
2023-01-04 07:50:36,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:36,790 INFO:     Epoch: 50
2023-01-04 07:50:38,349 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45496077140172325, 'Total loss': 0.45496077140172325} | train loss {'Reaction outcome loss': 0.35511056987055833, 'Total loss': 0.35511056987055833}
2023-01-04 07:50:38,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:38,349 INFO:     Epoch: 51
2023-01-04 07:50:39,904 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42210271060466764, 'Total loss': 0.42210271060466764} | train loss {'Reaction outcome loss': 0.3493258635769936, 'Total loss': 0.3493258635769936}
2023-01-04 07:50:39,904 INFO:     Found new best model at epoch 51
2023-01-04 07:50:39,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:39,905 INFO:     Epoch: 52
2023-01-04 07:50:41,482 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4205678145090739, 'Total loss': 0.4205678145090739} | train loss {'Reaction outcome loss': 0.32348254851354874, 'Total loss': 0.32348254851354874}
2023-01-04 07:50:41,482 INFO:     Found new best model at epoch 52
2023-01-04 07:50:41,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:41,483 INFO:     Epoch: 53
2023-01-04 07:50:43,018 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46872628132502236, 'Total loss': 0.46872628132502236} | train loss {'Reaction outcome loss': 0.3215331886527743, 'Total loss': 0.3215331886527743}
2023-01-04 07:50:43,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:43,019 INFO:     Epoch: 54
2023-01-04 07:50:44,599 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.443085116147995, 'Total loss': 0.443085116147995} | train loss {'Reaction outcome loss': 0.3210747469668248, 'Total loss': 0.3210747469668248}
2023-01-04 07:50:44,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:44,599 INFO:     Epoch: 55
2023-01-04 07:50:46,227 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42418181101481117, 'Total loss': 0.42418181101481117} | train loss {'Reaction outcome loss': 0.31982868936522235, 'Total loss': 0.31982868936522235}
2023-01-04 07:50:46,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:46,227 INFO:     Epoch: 56
2023-01-04 07:50:47,822 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4267292519410451, 'Total loss': 0.4267292519410451} | train loss {'Reaction outcome loss': 0.3168075952300991, 'Total loss': 0.3168075952300991}
2023-01-04 07:50:47,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:47,823 INFO:     Epoch: 57
2023-01-04 07:50:49,382 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42579323252042134, 'Total loss': 0.42579323252042134} | train loss {'Reaction outcome loss': 0.3391783203021961, 'Total loss': 0.3391783203021961}
2023-01-04 07:50:49,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:49,382 INFO:     Epoch: 58
2023-01-04 07:50:50,940 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4497607111930847, 'Total loss': 0.4497607111930847} | train loss {'Reaction outcome loss': 0.3119427151033196, 'Total loss': 0.3119427151033196}
2023-01-04 07:50:50,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:50,940 INFO:     Epoch: 59
2023-01-04 07:50:52,511 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44695420066515607, 'Total loss': 0.44695420066515607} | train loss {'Reaction outcome loss': 0.3093462711164015, 'Total loss': 0.3093462711164015}
2023-01-04 07:50:52,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:52,512 INFO:     Epoch: 60
2023-01-04 07:50:53,701 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4302074581384659, 'Total loss': 0.4302074581384659} | train loss {'Reaction outcome loss': 0.30804981922783947, 'Total loss': 0.30804981922783947}
2023-01-04 07:50:53,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:53,702 INFO:     Epoch: 61
2023-01-04 07:50:54,725 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43310445348421733, 'Total loss': 0.43310445348421733} | train loss {'Reaction outcome loss': 0.30620095352692855, 'Total loss': 0.30620095352692855}
2023-01-04 07:50:54,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:54,725 INFO:     Epoch: 62
2023-01-04 07:50:55,744 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4587131271759669, 'Total loss': 0.4587131271759669} | train loss {'Reaction outcome loss': 0.3013164205071719, 'Total loss': 0.3013164205071719}
2023-01-04 07:50:55,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:55,745 INFO:     Epoch: 63
2023-01-04 07:50:56,765 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4223183423280716, 'Total loss': 0.4223183423280716} | train loss {'Reaction outcome loss': 0.3074125519859186, 'Total loss': 0.3074125519859186}
2023-01-04 07:50:56,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:56,765 INFO:     Epoch: 64
2023-01-04 07:50:57,800 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.434440611799558, 'Total loss': 0.434440611799558} | train loss {'Reaction outcome loss': 0.3191349776866643, 'Total loss': 0.3191349776866643}
2023-01-04 07:50:57,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:57,801 INFO:     Epoch: 65
2023-01-04 07:50:59,367 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4427577128012975, 'Total loss': 0.4427577128012975} | train loss {'Reaction outcome loss': 0.33026752700064116, 'Total loss': 0.33026752700064116}
2023-01-04 07:50:59,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:50:59,368 INFO:     Epoch: 66
2023-01-04 07:51:00,947 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4315772414207458, 'Total loss': 0.4315772414207458} | train loss {'Reaction outcome loss': 0.3030959251539215, 'Total loss': 0.3030959251539215}
2023-01-04 07:51:00,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:00,947 INFO:     Epoch: 67
2023-01-04 07:51:02,525 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4252183258533478, 'Total loss': 0.4252183258533478} | train loss {'Reaction outcome loss': 0.3012012482014551, 'Total loss': 0.3012012482014551}
2023-01-04 07:51:02,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:02,525 INFO:     Epoch: 68
2023-01-04 07:51:04,095 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43576060732205707, 'Total loss': 0.43576060732205707} | train loss {'Reaction outcome loss': 0.29759675599200197, 'Total loss': 0.29759675599200197}
2023-01-04 07:51:04,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:04,096 INFO:     Epoch: 69
2023-01-04 07:51:05,671 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4299977620442708, 'Total loss': 0.4299977620442708} | train loss {'Reaction outcome loss': 0.2966770005692163, 'Total loss': 0.2966770005692163}
2023-01-04 07:51:05,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:05,671 INFO:     Epoch: 70
2023-01-04 07:51:07,088 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43287118474642433, 'Total loss': 0.43287118474642433} | train loss {'Reaction outcome loss': 0.29453408135020215, 'Total loss': 0.29453408135020215}
2023-01-04 07:51:07,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:07,088 INFO:     Epoch: 71
2023-01-04 07:51:08,652 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45032075643539426, 'Total loss': 0.45032075643539426} | train loss {'Reaction outcome loss': 0.3003851827354505, 'Total loss': 0.3003851827354505}
2023-01-04 07:51:08,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:08,652 INFO:     Epoch: 72
2023-01-04 07:51:10,215 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40744997262954713, 'Total loss': 0.40744997262954713} | train loss {'Reaction outcome loss': 0.29394947103751096, 'Total loss': 0.29394947103751096}
2023-01-04 07:51:10,216 INFO:     Found new best model at epoch 72
2023-01-04 07:51:10,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:10,217 INFO:     Epoch: 73
2023-01-04 07:51:11,772 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.409259025255839, 'Total loss': 0.409259025255839} | train loss {'Reaction outcome loss': 0.2952410788477763, 'Total loss': 0.2952410788477763}
2023-01-04 07:51:11,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:11,772 INFO:     Epoch: 74
2023-01-04 07:51:13,321 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45320775707562766, 'Total loss': 0.45320775707562766} | train loss {'Reaction outcome loss': 0.33303945071900776, 'Total loss': 0.33303945071900776}
2023-01-04 07:51:13,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:13,321 INFO:     Epoch: 75
2023-01-04 07:51:14,876 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4073933402697245, 'Total loss': 0.4073933402697245} | train loss {'Reaction outcome loss': 0.2965033587029936, 'Total loss': 0.2965033587029936}
2023-01-04 07:51:14,876 INFO:     Found new best model at epoch 75
2023-01-04 07:51:14,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:14,877 INFO:     Epoch: 76
2023-01-04 07:51:16,273 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44504157900810243, 'Total loss': 0.44504157900810243} | train loss {'Reaction outcome loss': 0.2899479228949201, 'Total loss': 0.2899479228949201}
2023-01-04 07:51:16,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:16,274 INFO:     Epoch: 77
2023-01-04 07:51:17,858 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4365715980529785, 'Total loss': 0.4365715980529785} | train loss {'Reaction outcome loss': 0.28947358346656826, 'Total loss': 0.28947358346656826}
2023-01-04 07:51:17,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:17,858 INFO:     Epoch: 78
2023-01-04 07:51:19,466 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4036809245745341, 'Total loss': 0.4036809245745341} | train loss {'Reaction outcome loss': 0.2847233431447757, 'Total loss': 0.2847233431447757}
2023-01-04 07:51:19,466 INFO:     Found new best model at epoch 78
2023-01-04 07:51:19,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:19,467 INFO:     Epoch: 79
2023-01-04 07:51:21,058 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41159706314404804, 'Total loss': 0.41159706314404804} | train loss {'Reaction outcome loss': 0.28100487818027026, 'Total loss': 0.28100487818027026}
2023-01-04 07:51:21,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:21,058 INFO:     Epoch: 80
2023-01-04 07:51:22,668 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41813842753569286, 'Total loss': 0.41813842753569286} | train loss {'Reaction outcome loss': 0.28138503969471523, 'Total loss': 0.28138503969471523}
2023-01-04 07:51:22,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:22,669 INFO:     Epoch: 81
2023-01-04 07:51:24,285 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4042739907900492, 'Total loss': 0.4042739907900492} | train loss {'Reaction outcome loss': 0.2875500806367727, 'Total loss': 0.2875500806367727}
2023-01-04 07:51:24,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:24,285 INFO:     Epoch: 82
2023-01-04 07:51:25,754 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4402053435643514, 'Total loss': 0.4402053435643514} | train loss {'Reaction outcome loss': 0.2829706258413827, 'Total loss': 0.2829706258413827}
2023-01-04 07:51:25,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:25,754 INFO:     Epoch: 83
2023-01-04 07:51:27,362 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4169142623742422, 'Total loss': 0.4169142623742422} | train loss {'Reaction outcome loss': 0.27757869671902724, 'Total loss': 0.27757869671902724}
2023-01-04 07:51:27,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:27,362 INFO:     Epoch: 84
2023-01-04 07:51:28,972 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4324787815411886, 'Total loss': 0.4324787815411886} | train loss {'Reaction outcome loss': 0.2736018549581733, 'Total loss': 0.2736018549581733}
2023-01-04 07:51:28,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:28,973 INFO:     Epoch: 85
2023-01-04 07:51:30,576 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4471341828505198, 'Total loss': 0.4471341828505198} | train loss {'Reaction outcome loss': 0.2729359799745051, 'Total loss': 0.2729359799745051}
2023-01-04 07:51:30,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:30,576 INFO:     Epoch: 86
2023-01-04 07:51:32,161 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3987251967191696, 'Total loss': 0.3987251967191696} | train loss {'Reaction outcome loss': 0.2745789170747731, 'Total loss': 0.2745789170747731}
2023-01-04 07:51:32,161 INFO:     Found new best model at epoch 86
2023-01-04 07:51:32,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:32,162 INFO:     Epoch: 87
2023-01-04 07:51:33,765 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42386167248090106, 'Total loss': 0.42386167248090106} | train loss {'Reaction outcome loss': 0.2767362174759198, 'Total loss': 0.2767362174759198}
2023-01-04 07:51:33,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:33,765 INFO:     Epoch: 88
2023-01-04 07:51:35,231 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.429644242922465, 'Total loss': 0.429644242922465} | train loss {'Reaction outcome loss': 0.2713777146114887, 'Total loss': 0.2713777146114887}
2023-01-04 07:51:35,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:35,231 INFO:     Epoch: 89
2023-01-04 07:51:36,831 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.431929079691569, 'Total loss': 0.431929079691569} | train loss {'Reaction outcome loss': 0.27038781021693087, 'Total loss': 0.27038781021693087}
2023-01-04 07:51:36,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:36,832 INFO:     Epoch: 90
2023-01-04 07:51:38,435 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4368438124656677, 'Total loss': 0.4368438124656677} | train loss {'Reaction outcome loss': 0.27008503698406444, 'Total loss': 0.27008503698406444}
2023-01-04 07:51:38,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:38,435 INFO:     Epoch: 91
2023-01-04 07:51:40,038 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4287185788154602, 'Total loss': 0.4287185788154602} | train loss {'Reaction outcome loss': 0.2717961028498341, 'Total loss': 0.2717961028498341}
2023-01-04 07:51:40,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:40,039 INFO:     Epoch: 92
2023-01-04 07:51:41,651 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4341254154841105, 'Total loss': 0.4341254154841105} | train loss {'Reaction outcome loss': 0.2707597633226491, 'Total loss': 0.2707597633226491}
2023-01-04 07:51:41,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:41,652 INFO:     Epoch: 93
2023-01-04 07:51:43,202 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3976545423269272, 'Total loss': 0.3976545423269272} | train loss {'Reaction outcome loss': 0.2662211184383984, 'Total loss': 0.2662211184383984}
2023-01-04 07:51:43,202 INFO:     Found new best model at epoch 93
2023-01-04 07:51:43,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:43,203 INFO:     Epoch: 94
2023-01-04 07:51:44,765 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4655655632416407, 'Total loss': 0.4655655632416407} | train loss {'Reaction outcome loss': 0.268715508106718, 'Total loss': 0.268715508106718}
2023-01-04 07:51:44,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:44,766 INFO:     Epoch: 95
2023-01-04 07:51:46,356 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4232010285059611, 'Total loss': 0.4232010285059611} | train loss {'Reaction outcome loss': 0.2650821015248885, 'Total loss': 0.2650821015248885}
2023-01-04 07:51:46,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:46,356 INFO:     Epoch: 96
2023-01-04 07:51:47,949 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4313861762483915, 'Total loss': 0.4313861762483915} | train loss {'Reaction outcome loss': 0.266540714232521, 'Total loss': 0.266540714232521}
2023-01-04 07:51:47,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:47,950 INFO:     Epoch: 97
2023-01-04 07:51:49,570 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41457406381766, 'Total loss': 0.41457406381766} | train loss {'Reaction outcome loss': 0.26104194122076413, 'Total loss': 0.26104194122076413}
2023-01-04 07:51:49,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:49,570 INFO:     Epoch: 98
2023-01-04 07:51:51,195 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4343570709228516, 'Total loss': 0.4343570709228516} | train loss {'Reaction outcome loss': 0.2621861817282532, 'Total loss': 0.2621861817282532}
2023-01-04 07:51:51,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:51,195 INFO:     Epoch: 99
2023-01-04 07:51:52,670 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4610121130943298, 'Total loss': 0.4610121130943298} | train loss {'Reaction outcome loss': 0.2645944742676954, 'Total loss': 0.2645944742676954}
2023-01-04 07:51:52,671 INFO:     Best model found after epoch 94 of 100.
2023-01-04 07:51:52,671 INFO:   Done with stage: TRAINING
2023-01-04 07:51:52,671 INFO:   Starting stage: EVALUATION
2023-01-04 07:51:52,799 INFO:   Done with stage: EVALUATION
2023-01-04 07:51:52,799 INFO:   Leaving out SEQ value Fold_2
2023-01-04 07:51:52,811 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 07:51:52,812 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:51:53,462 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:51:53,462 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:51:53,531 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:51:53,531 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:51:53,531 INFO:     No hyperparam tuning for this model
2023-01-04 07:51:53,531 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:51:53,531 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:51:53,532 INFO:     None feature selector for col prot
2023-01-04 07:51:53,532 INFO:     None feature selector for col prot
2023-01-04 07:51:53,532 INFO:     None feature selector for col prot
2023-01-04 07:51:53,533 INFO:     None feature selector for col chem
2023-01-04 07:51:53,533 INFO:     None feature selector for col chem
2023-01-04 07:51:53,533 INFO:     None feature selector for col chem
2023-01-04 07:51:53,533 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:51:53,533 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:51:53,534 INFO:     Number of params in model 70111
2023-01-04 07:51:53,537 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:51:53,537 INFO:   Starting stage: TRAINING
2023-01-04 07:51:53,580 INFO:     Val loss before train {'Reaction outcome loss': 0.8487650434176127, 'Total loss': 0.8487650434176127}
2023-01-04 07:51:53,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:53,580 INFO:     Epoch: 0
2023-01-04 07:51:55,185 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6772592763106028, 'Total loss': 0.6772592763106028} | train loss {'Reaction outcome loss': 0.8371232569652752, 'Total loss': 0.8371232569652752}
2023-01-04 07:51:55,185 INFO:     Found new best model at epoch 0
2023-01-04 07:51:55,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:55,186 INFO:     Epoch: 1
2023-01-04 07:51:56,778 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6006055533885956, 'Total loss': 0.6006055533885956} | train loss {'Reaction outcome loss': 0.6762239819895612, 'Total loss': 0.6762239819895612}
2023-01-04 07:51:56,778 INFO:     Found new best model at epoch 1
2023-01-04 07:51:56,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:56,779 INFO:     Epoch: 2
2023-01-04 07:51:58,322 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5134878396987915, 'Total loss': 0.5134878396987915} | train loss {'Reaction outcome loss': 0.5873923711206791, 'Total loss': 0.5873923711206791}
2023-01-04 07:51:58,322 INFO:     Found new best model at epoch 2
2023-01-04 07:51:58,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:58,323 INFO:     Epoch: 3
2023-01-04 07:51:59,861 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5159200727939606, 'Total loss': 0.5159200727939606} | train loss {'Reaction outcome loss': 0.5428174779797993, 'Total loss': 0.5428174779797993}
2023-01-04 07:51:59,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:51:59,862 INFO:     Epoch: 4
2023-01-04 07:52:01,230 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5101072609424591, 'Total loss': 0.5101072609424591} | train loss {'Reaction outcome loss': 0.518525184070977, 'Total loss': 0.518525184070977}
2023-01-04 07:52:01,231 INFO:     Found new best model at epoch 4
2023-01-04 07:52:01,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:01,232 INFO:     Epoch: 5
2023-01-04 07:52:02,778 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48462578654289246, 'Total loss': 0.48462578654289246} | train loss {'Reaction outcome loss': 0.5048696942573047, 'Total loss': 0.5048696942573047}
2023-01-04 07:52:02,778 INFO:     Found new best model at epoch 5
2023-01-04 07:52:02,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:02,779 INFO:     Epoch: 6
2023-01-04 07:52:04,321 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46297412713368735, 'Total loss': 0.46297412713368735} | train loss {'Reaction outcome loss': 0.49060770358047345, 'Total loss': 0.49060770358047345}
2023-01-04 07:52:04,321 INFO:     Found new best model at epoch 6
2023-01-04 07:52:04,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:04,322 INFO:     Epoch: 7
2023-01-04 07:52:05,865 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5131433765093486, 'Total loss': 0.5131433765093486} | train loss {'Reaction outcome loss': 0.4824585911348788, 'Total loss': 0.4824585911348788}
2023-01-04 07:52:05,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:05,865 INFO:     Epoch: 8
2023-01-04 07:52:07,428 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46002713590860367, 'Total loss': 0.46002713590860367} | train loss {'Reaction outcome loss': 0.4748607773306596, 'Total loss': 0.4748607773306596}
2023-01-04 07:52:07,429 INFO:     Found new best model at epoch 8
2023-01-04 07:52:07,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:07,429 INFO:     Epoch: 9
2023-01-04 07:52:08,993 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4371807465950648, 'Total loss': 0.4371807465950648} | train loss {'Reaction outcome loss': 0.46927402201142626, 'Total loss': 0.46927402201142626}
2023-01-04 07:52:08,993 INFO:     Found new best model at epoch 9
2023-01-04 07:52:08,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:08,994 INFO:     Epoch: 10
2023-01-04 07:52:10,382 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43798767725626625, 'Total loss': 0.43798767725626625} | train loss {'Reaction outcome loss': 0.4615685990365752, 'Total loss': 0.4615685990365752}
2023-01-04 07:52:10,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:10,382 INFO:     Epoch: 11
2023-01-04 07:52:11,962 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4506587594747543, 'Total loss': 0.4506587594747543} | train loss {'Reaction outcome loss': 0.45216183108787467, 'Total loss': 0.45216183108787467}
2023-01-04 07:52:11,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:11,963 INFO:     Epoch: 12
2023-01-04 07:52:13,511 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4444059809048971, 'Total loss': 0.4444059809048971} | train loss {'Reaction outcome loss': 0.4480062053151374, 'Total loss': 0.4480062053151374}
2023-01-04 07:52:13,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:13,511 INFO:     Epoch: 13
2023-01-04 07:52:15,053 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45791070063908895, 'Total loss': 0.45791070063908895} | train loss {'Reaction outcome loss': 0.4455675460996419, 'Total loss': 0.4455675460996419}
2023-01-04 07:52:15,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:15,054 INFO:     Epoch: 14
2023-01-04 07:52:16,614 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4403642555077871, 'Total loss': 0.4403642555077871} | train loss {'Reaction outcome loss': 0.43763598701814665, 'Total loss': 0.43763598701814665}
2023-01-04 07:52:16,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:16,614 INFO:     Epoch: 15
2023-01-04 07:52:18,221 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4354205866654714, 'Total loss': 0.4354205866654714} | train loss {'Reaction outcome loss': 0.43708247647885856, 'Total loss': 0.43708247647885856}
2023-01-04 07:52:18,222 INFO:     Found new best model at epoch 15
2023-01-04 07:52:18,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:18,223 INFO:     Epoch: 16
2023-01-04 07:52:19,670 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41875764230887097, 'Total loss': 0.41875764230887097} | train loss {'Reaction outcome loss': 0.4324973315870675, 'Total loss': 0.4324973315870675}
2023-01-04 07:52:19,671 INFO:     Found new best model at epoch 16
2023-01-04 07:52:19,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:19,671 INFO:     Epoch: 17
2023-01-04 07:52:21,268 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42027767896652224, 'Total loss': 0.42027767896652224} | train loss {'Reaction outcome loss': 0.4307209656838953, 'Total loss': 0.4307209656838953}
2023-01-04 07:52:21,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:21,268 INFO:     Epoch: 18
2023-01-04 07:52:22,885 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43865060011545814, 'Total loss': 0.43865060011545814} | train loss {'Reaction outcome loss': 0.4245457214704395, 'Total loss': 0.4245457214704395}
2023-01-04 07:52:22,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:22,885 INFO:     Epoch: 19
2023-01-04 07:52:24,497 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4463967978954315, 'Total loss': 0.4463967978954315} | train loss {'Reaction outcome loss': 0.4199637113696467, 'Total loss': 0.4199637113696467}
2023-01-04 07:52:24,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:24,497 INFO:     Epoch: 20
2023-01-04 07:52:26,102 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42611606121063234, 'Total loss': 0.42611606121063234} | train loss {'Reaction outcome loss': 0.4178622384032194, 'Total loss': 0.4178622384032194}
2023-01-04 07:52:26,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:26,103 INFO:     Epoch: 21
2023-01-04 07:52:27,681 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46443335165580113, 'Total loss': 0.46443335165580113} | train loss {'Reaction outcome loss': 0.41160913306648717, 'Total loss': 0.41160913306648717}
2023-01-04 07:52:27,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:27,681 INFO:     Epoch: 22
2023-01-04 07:52:29,128 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4699493875106176, 'Total loss': 0.4699493875106176} | train loss {'Reaction outcome loss': 0.4126608669214005, 'Total loss': 0.4126608669214005}
2023-01-04 07:52:29,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:29,128 INFO:     Epoch: 23
2023-01-04 07:52:30,721 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40772659381230675, 'Total loss': 0.40772659381230675} | train loss {'Reaction outcome loss': 0.4060317288785085, 'Total loss': 0.4060317288785085}
2023-01-04 07:52:30,722 INFO:     Found new best model at epoch 23
2023-01-04 07:52:30,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:30,722 INFO:     Epoch: 24
2023-01-04 07:52:32,317 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4216836988925934, 'Total loss': 0.4216836988925934} | train loss {'Reaction outcome loss': 0.39705607547920985, 'Total loss': 0.39705607547920985}
2023-01-04 07:52:32,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:32,317 INFO:     Epoch: 25
2023-01-04 07:52:33,897 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39925583004951476, 'Total loss': 0.39925583004951476} | train loss {'Reaction outcome loss': 0.3979721680881768, 'Total loss': 0.3979721680881768}
2023-01-04 07:52:33,897 INFO:     Found new best model at epoch 25
2023-01-04 07:52:33,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:33,897 INFO:     Epoch: 26
2023-01-04 07:52:35,506 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4248459905385971, 'Total loss': 0.4248459905385971} | train loss {'Reaction outcome loss': 0.3898337803182811, 'Total loss': 0.3898337803182811}
2023-01-04 07:52:35,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:35,506 INFO:     Epoch: 27
2023-01-04 07:52:37,096 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4285146683454514, 'Total loss': 0.4285146683454514} | train loss {'Reaction outcome loss': 0.3910673384683846, 'Total loss': 0.3910673384683846}
2023-01-04 07:52:37,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:37,096 INFO:     Epoch: 28
2023-01-04 07:52:38,554 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41183380981286366, 'Total loss': 0.41183380981286366} | train loss {'Reaction outcome loss': 0.38633864432790854, 'Total loss': 0.38633864432790854}
2023-01-04 07:52:38,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:38,554 INFO:     Epoch: 29
2023-01-04 07:52:40,161 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3952195833126704, 'Total loss': 0.3952195833126704} | train loss {'Reaction outcome loss': 0.38049377677758245, 'Total loss': 0.38049377677758245}
2023-01-04 07:52:40,161 INFO:     Found new best model at epoch 29
2023-01-04 07:52:40,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:40,162 INFO:     Epoch: 30
2023-01-04 07:52:41,756 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4102612023552259, 'Total loss': 0.4102612023552259} | train loss {'Reaction outcome loss': 0.37916019107521015, 'Total loss': 0.37916019107521015}
2023-01-04 07:52:41,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:41,756 INFO:     Epoch: 31
2023-01-04 07:52:43,349 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42699317385752994, 'Total loss': 0.42699317385752994} | train loss {'Reaction outcome loss': 0.37323957238427913, 'Total loss': 0.37323957238427913}
2023-01-04 07:52:43,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:43,351 INFO:     Epoch: 32
2023-01-04 07:52:44,947 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3825512230396271, 'Total loss': 0.3825512230396271} | train loss {'Reaction outcome loss': 0.36975454560814114, 'Total loss': 0.36975454560814114}
2023-01-04 07:52:44,947 INFO:     Found new best model at epoch 32
2023-01-04 07:52:44,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:44,948 INFO:     Epoch: 33
2023-01-04 07:52:46,541 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36408336609601977, 'Total loss': 0.36408336609601977} | train loss {'Reaction outcome loss': 0.36979549647356474, 'Total loss': 0.36979549647356474}
2023-01-04 07:52:46,542 INFO:     Found new best model at epoch 33
2023-01-04 07:52:46,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:46,542 INFO:     Epoch: 34
2023-01-04 07:52:48,008 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38073982993761696, 'Total loss': 0.38073982993761696} | train loss {'Reaction outcome loss': 0.36461140112067664, 'Total loss': 0.36461140112067664}
2023-01-04 07:52:48,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:48,008 INFO:     Epoch: 35
2023-01-04 07:52:49,620 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4074275533358256, 'Total loss': 0.4074275533358256} | train loss {'Reaction outcome loss': 0.3615758971576273, 'Total loss': 0.3615758971576273}
2023-01-04 07:52:49,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:49,621 INFO:     Epoch: 36
2023-01-04 07:52:51,205 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4131463756163915, 'Total loss': 0.4131463756163915} | train loss {'Reaction outcome loss': 0.3573225298284614, 'Total loss': 0.3573225298284614}
2023-01-04 07:52:51,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:51,205 INFO:     Epoch: 37
2023-01-04 07:52:52,818 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40311158299446104, 'Total loss': 0.40311158299446104} | train loss {'Reaction outcome loss': 0.35543543432098235, 'Total loss': 0.35543543432098235}
2023-01-04 07:52:52,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:52,818 INFO:     Epoch: 38
2023-01-04 07:52:54,419 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41389267295598986, 'Total loss': 0.41389267295598986} | train loss {'Reaction outcome loss': 0.3483022269215027, 'Total loss': 0.3483022269215027}
2023-01-04 07:52:54,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:54,419 INFO:     Epoch: 39
2023-01-04 07:52:55,915 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4043400188287099, 'Total loss': 0.4043400188287099} | train loss {'Reaction outcome loss': 0.3514622112967237, 'Total loss': 0.3514622112967237}
2023-01-04 07:52:55,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:55,915 INFO:     Epoch: 40
2023-01-04 07:52:57,509 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39026076197624204, 'Total loss': 0.39026076197624204} | train loss {'Reaction outcome loss': 0.34317220029604695, 'Total loss': 0.34317220029604695}
2023-01-04 07:52:57,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:57,509 INFO:     Epoch: 41
2023-01-04 07:52:59,098 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.418735733628273, 'Total loss': 0.418735733628273} | train loss {'Reaction outcome loss': 0.3461461653457071, 'Total loss': 0.3461461653457071}
2023-01-04 07:52:59,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:52:59,098 INFO:     Epoch: 42
2023-01-04 07:53:00,700 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3892297983169556, 'Total loss': 0.3892297983169556} | train loss {'Reaction outcome loss': 0.3371831684434501, 'Total loss': 0.3371831684434501}
2023-01-04 07:53:00,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:00,700 INFO:     Epoch: 43
2023-01-04 07:53:02,311 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36041320537527405, 'Total loss': 0.36041320537527405} | train loss {'Reaction outcome loss': 0.33817265310535466, 'Total loss': 0.33817265310535466}
2023-01-04 07:53:02,312 INFO:     Found new best model at epoch 43
2023-01-04 07:53:02,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:02,313 INFO:     Epoch: 44
2023-01-04 07:53:03,920 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3851136118173599, 'Total loss': 0.3851136118173599} | train loss {'Reaction outcome loss': 0.3376658686103612, 'Total loss': 0.3376658686103612}
2023-01-04 07:53:03,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:03,921 INFO:     Epoch: 45
2023-01-04 07:53:05,397 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35843138297398885, 'Total loss': 0.35843138297398885} | train loss {'Reaction outcome loss': 0.3323796939131987, 'Total loss': 0.3323796939131987}
2023-01-04 07:53:05,397 INFO:     Found new best model at epoch 45
2023-01-04 07:53:05,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:05,398 INFO:     Epoch: 46
2023-01-04 07:53:06,993 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3599995940923691, 'Total loss': 0.3599995940923691} | train loss {'Reaction outcome loss': 0.3337317166754799, 'Total loss': 0.3337317166754799}
2023-01-04 07:53:06,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:06,993 INFO:     Epoch: 47
2023-01-04 07:53:08,583 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40523628393809, 'Total loss': 0.40523628393809} | train loss {'Reaction outcome loss': 0.3262314190612222, 'Total loss': 0.3262314190612222}
2023-01-04 07:53:08,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:08,583 INFO:     Epoch: 48
2023-01-04 07:53:10,184 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39343614081541695, 'Total loss': 0.39343614081541695} | train loss {'Reaction outcome loss': 0.325071833538313, 'Total loss': 0.325071833538313}
2023-01-04 07:53:10,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:10,185 INFO:     Epoch: 49
2023-01-04 07:53:11,784 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37330188949902854, 'Total loss': 0.37330188949902854} | train loss {'Reaction outcome loss': 0.3257289103293506, 'Total loss': 0.3257289103293506}
2023-01-04 07:53:11,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:11,784 INFO:     Epoch: 50
2023-01-04 07:53:13,323 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36856825749079386, 'Total loss': 0.36856825749079386} | train loss {'Reaction outcome loss': 0.32107360196048323, 'Total loss': 0.32107360196048323}
2023-01-04 07:53:13,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:13,323 INFO:     Epoch: 51
2023-01-04 07:53:14,697 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3569108724594116, 'Total loss': 0.3569108724594116} | train loss {'Reaction outcome loss': 0.317198477005654, 'Total loss': 0.317198477005654}
2023-01-04 07:53:14,697 INFO:     Found new best model at epoch 51
2023-01-04 07:53:14,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:14,698 INFO:     Epoch: 52
2023-01-04 07:53:16,235 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3808199187119802, 'Total loss': 0.3808199187119802} | train loss {'Reaction outcome loss': 0.31538554036269223, 'Total loss': 0.31538554036269223}
2023-01-04 07:53:16,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:16,235 INFO:     Epoch: 53
2023-01-04 07:53:17,763 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3532357503970464, 'Total loss': 0.3532357503970464} | train loss {'Reaction outcome loss': 0.31929078700877456, 'Total loss': 0.31929078700877456}
2023-01-04 07:53:17,763 INFO:     Found new best model at epoch 53
2023-01-04 07:53:17,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:17,764 INFO:     Epoch: 54
2023-01-04 07:53:19,301 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36268987754980725, 'Total loss': 0.36268987754980725} | train loss {'Reaction outcome loss': 0.3098595414283502, 'Total loss': 0.3098595414283502}
2023-01-04 07:53:19,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:19,302 INFO:     Epoch: 55
2023-01-04 07:53:20,853 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3380332330862681, 'Total loss': 0.3380332330862681} | train loss {'Reaction outcome loss': 0.3066606480002838, 'Total loss': 0.3066606480002838}
2023-01-04 07:53:20,853 INFO:     Found new best model at epoch 55
2023-01-04 07:53:20,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:20,854 INFO:     Epoch: 56
2023-01-04 07:53:22,390 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39935266474882763, 'Total loss': 0.39935266474882763} | train loss {'Reaction outcome loss': 0.30781444613515896, 'Total loss': 0.30781444613515896}
2023-01-04 07:53:22,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:22,391 INFO:     Epoch: 57
2023-01-04 07:53:23,768 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35635479936997094, 'Total loss': 0.35635479936997094} | train loss {'Reaction outcome loss': 0.30198615378815763, 'Total loss': 0.30198615378815763}
2023-01-04 07:53:23,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:23,768 INFO:     Epoch: 58
2023-01-04 07:53:25,312 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38374677002429963, 'Total loss': 0.38374677002429963} | train loss {'Reaction outcome loss': 0.30153701862279514, 'Total loss': 0.30153701862279514}
2023-01-04 07:53:25,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:25,313 INFO:     Epoch: 59
2023-01-04 07:53:26,853 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3608378887176514, 'Total loss': 0.3608378887176514} | train loss {'Reaction outcome loss': 0.30211251348692136, 'Total loss': 0.30211251348692136}
2023-01-04 07:53:26,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:26,854 INFO:     Epoch: 60
2023-01-04 07:53:28,401 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3708371827999751, 'Total loss': 0.3708371827999751} | train loss {'Reaction outcome loss': 0.2995889125949275, 'Total loss': 0.2995889125949275}
2023-01-04 07:53:28,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:28,401 INFO:     Epoch: 61
2023-01-04 07:53:29,946 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4203551153341929, 'Total loss': 0.4203551153341929} | train loss {'Reaction outcome loss': 0.29517289071622554, 'Total loss': 0.29517289071622554}
2023-01-04 07:53:29,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:29,947 INFO:     Epoch: 62
2023-01-04 07:53:31,489 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3382231285174688, 'Total loss': 0.3382231285174688} | train loss {'Reaction outcome loss': 0.2941155427672567, 'Total loss': 0.2941155427672567}
2023-01-04 07:53:31,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:31,490 INFO:     Epoch: 63
2023-01-04 07:53:32,871 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3423893650372823, 'Total loss': 0.3423893650372823} | train loss {'Reaction outcome loss': 0.2892111635148308, 'Total loss': 0.2892111635148308}
2023-01-04 07:53:32,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:32,872 INFO:     Epoch: 64
2023-01-04 07:53:34,415 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38269821802775067, 'Total loss': 0.38269821802775067} | train loss {'Reaction outcome loss': 0.290836169894268, 'Total loss': 0.290836169894268}
2023-01-04 07:53:34,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:34,415 INFO:     Epoch: 65
2023-01-04 07:53:35,959 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34475265940030414, 'Total loss': 0.34475265940030414} | train loss {'Reaction outcome loss': 0.2914031535169504, 'Total loss': 0.2914031535169504}
2023-01-04 07:53:35,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:35,960 INFO:     Epoch: 66
2023-01-04 07:53:37,512 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39505003293355306, 'Total loss': 0.39505003293355306} | train loss {'Reaction outcome loss': 0.2910781223190962, 'Total loss': 0.2910781223190962}
2023-01-04 07:53:37,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:37,513 INFO:     Epoch: 67
2023-01-04 07:53:39,046 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35987645586331685, 'Total loss': 0.35987645586331685} | train loss {'Reaction outcome loss': 0.2922881013258313, 'Total loss': 0.2922881013258313}
2023-01-04 07:53:39,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:39,046 INFO:     Epoch: 68
2023-01-04 07:53:40,586 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.33488044838110603, 'Total loss': 0.33488044838110603} | train loss {'Reaction outcome loss': 0.28300103055734704, 'Total loss': 0.28300103055734704}
2023-01-04 07:53:40,587 INFO:     Found new best model at epoch 68
2023-01-04 07:53:40,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:40,587 INFO:     Epoch: 69
2023-01-04 07:53:41,986 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3967768008510272, 'Total loss': 0.3967768008510272} | train loss {'Reaction outcome loss': 0.28905968289196926, 'Total loss': 0.28905968289196926}
2023-01-04 07:53:41,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:41,986 INFO:     Epoch: 70
2023-01-04 07:53:43,536 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3489969859520594, 'Total loss': 0.3489969859520594} | train loss {'Reaction outcome loss': 0.27984383767538695, 'Total loss': 0.27984383767538695}
2023-01-04 07:53:43,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:43,537 INFO:     Epoch: 71
2023-01-04 07:53:45,080 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3515310021738211, 'Total loss': 0.3515310021738211} | train loss {'Reaction outcome loss': 0.28542596289384975, 'Total loss': 0.28542596289384975}
2023-01-04 07:53:45,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:45,080 INFO:     Epoch: 72
2023-01-04 07:53:46,628 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35954207678635913, 'Total loss': 0.35954207678635913} | train loss {'Reaction outcome loss': 0.28168051222162527, 'Total loss': 0.28168051222162527}
2023-01-04 07:53:46,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:46,629 INFO:     Epoch: 73
2023-01-04 07:53:48,184 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3521367331345876, 'Total loss': 0.3521367331345876} | train loss {'Reaction outcome loss': 0.2754003033041954, 'Total loss': 0.2754003033041954}
2023-01-04 07:53:48,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:48,184 INFO:     Epoch: 74
2023-01-04 07:53:49,725 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3656214271982511, 'Total loss': 0.3656214271982511} | train loss {'Reaction outcome loss': 0.2784232550783314, 'Total loss': 0.2784232550783314}
2023-01-04 07:53:49,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:49,725 INFO:     Epoch: 75
2023-01-04 07:53:51,106 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35962536235650383, 'Total loss': 0.35962536235650383} | train loss {'Reaction outcome loss': 0.2760930292199563, 'Total loss': 0.2760930292199563}
2023-01-04 07:53:51,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:51,107 INFO:     Epoch: 76
2023-01-04 07:53:52,658 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3742611343661944, 'Total loss': 0.3742611343661944} | train loss {'Reaction outcome loss': 0.2729716959552173, 'Total loss': 0.2729716959552173}
2023-01-04 07:53:52,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:52,658 INFO:     Epoch: 77
2023-01-04 07:53:54,207 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3616869166493416, 'Total loss': 0.3616869166493416} | train loss {'Reaction outcome loss': 0.275386292188272, 'Total loss': 0.275386292188272}
2023-01-04 07:53:54,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:54,208 INFO:     Epoch: 78
2023-01-04 07:53:55,760 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37643684695164364, 'Total loss': 0.37643684695164364} | train loss {'Reaction outcome loss': 0.27684228264991817, 'Total loss': 0.27684228264991817}
2023-01-04 07:53:55,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:55,761 INFO:     Epoch: 79
2023-01-04 07:53:57,305 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3909703572591146, 'Total loss': 0.3909703572591146} | train loss {'Reaction outcome loss': 0.27144598049947816, 'Total loss': 0.27144598049947816}
2023-01-04 07:53:57,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:57,306 INFO:     Epoch: 80
2023-01-04 07:53:58,851 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3488638093074163, 'Total loss': 0.3488638093074163} | train loss {'Reaction outcome loss': 0.26903319124975345, 'Total loss': 0.26903319124975345}
2023-01-04 07:53:58,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:53:58,851 INFO:     Epoch: 81
2023-01-04 07:54:00,251 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35893743137518563, 'Total loss': 0.35893743137518563} | train loss {'Reaction outcome loss': 0.27039215294984137, 'Total loss': 0.27039215294984137}
2023-01-04 07:54:00,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:00,252 INFO:     Epoch: 82
2023-01-04 07:54:01,808 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3522433618704478, 'Total loss': 0.3522433618704478} | train loss {'Reaction outcome loss': 0.2736435241752515, 'Total loss': 0.2736435241752515}
2023-01-04 07:54:01,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:01,808 INFO:     Epoch: 83
2023-01-04 07:54:03,353 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36540370086828866, 'Total loss': 0.36540370086828866} | train loss {'Reaction outcome loss': 0.2657136764023861, 'Total loss': 0.2657136764023861}
2023-01-04 07:54:03,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:03,353 INFO:     Epoch: 84
2023-01-04 07:54:04,891 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3702328950166702, 'Total loss': 0.3702328950166702} | train loss {'Reaction outcome loss': 0.26566286768465147, 'Total loss': 0.26566286768465147}
2023-01-04 07:54:04,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:04,891 INFO:     Epoch: 85
2023-01-04 07:54:06,439 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3407234251499176, 'Total loss': 0.3407234251499176} | train loss {'Reaction outcome loss': 0.26429955307802144, 'Total loss': 0.26429955307802144}
2023-01-04 07:54:06,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:06,439 INFO:     Epoch: 86
2023-01-04 07:54:08,029 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33239376321434977, 'Total loss': 0.33239376321434977} | train loss {'Reaction outcome loss': 0.2688016402025292, 'Total loss': 0.2688016402025292}
2023-01-04 07:54:08,029 INFO:     Found new best model at epoch 86
2023-01-04 07:54:08,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:08,030 INFO:     Epoch: 87
2023-01-04 07:54:09,541 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3481199751297633, 'Total loss': 0.3481199751297633} | train loss {'Reaction outcome loss': 0.2619944796455603, 'Total loss': 0.2619944796455603}
2023-01-04 07:54:09,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:09,541 INFO:     Epoch: 88
2023-01-04 07:54:11,122 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35081888536612194, 'Total loss': 0.35081888536612194} | train loss {'Reaction outcome loss': 0.25773956353375077, 'Total loss': 0.25773956353375077}
2023-01-04 07:54:11,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:11,122 INFO:     Epoch: 89
2023-01-04 07:54:12,711 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35282257695992786, 'Total loss': 0.35282257695992786} | train loss {'Reaction outcome loss': 0.25864565392860966, 'Total loss': 0.25864565392860966}
2023-01-04 07:54:12,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:12,712 INFO:     Epoch: 90
2023-01-04 07:54:14,303 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.35416104992230735, 'Total loss': 0.35416104992230735} | train loss {'Reaction outcome loss': 0.2603173459587741, 'Total loss': 0.2603173459587741}
2023-01-04 07:54:14,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:14,303 INFO:     Epoch: 91
2023-01-04 07:54:15,889 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34848008925716084, 'Total loss': 0.34848008925716084} | train loss {'Reaction outcome loss': 0.25846519285853764, 'Total loss': 0.25846519285853764}
2023-01-04 07:54:15,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:15,890 INFO:     Epoch: 92
2023-01-04 07:54:17,474 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3441861540079117, 'Total loss': 0.3441861540079117} | train loss {'Reaction outcome loss': 0.25869589351987754, 'Total loss': 0.25869589351987754}
2023-01-04 07:54:17,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:17,474 INFO:     Epoch: 93
2023-01-04 07:54:18,994 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3512100487947464, 'Total loss': 0.3512100487947464} | train loss {'Reaction outcome loss': 0.25931483344004974, 'Total loss': 0.25931483344004974}
2023-01-04 07:54:18,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:18,994 INFO:     Epoch: 94
2023-01-04 07:54:20,534 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3819876323143641, 'Total loss': 0.3819876323143641} | train loss {'Reaction outcome loss': 0.2517458324993614, 'Total loss': 0.2517458324993614}
2023-01-04 07:54:20,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:20,534 INFO:     Epoch: 95
2023-01-04 07:54:22,065 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3762607475121816, 'Total loss': 0.3762607475121816} | train loss {'Reaction outcome loss': 0.25830246713420335, 'Total loss': 0.25830246713420335}
2023-01-04 07:54:22,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:22,065 INFO:     Epoch: 96
2023-01-04 07:54:23,591 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.33290158907572426, 'Total loss': 0.33290158907572426} | train loss {'Reaction outcome loss': 0.2578007558319908, 'Total loss': 0.2578007558319908}
2023-01-04 07:54:23,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:23,592 INFO:     Epoch: 97
2023-01-04 07:54:25,126 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3807506799697876, 'Total loss': 0.3807506799697876} | train loss {'Reaction outcome loss': 0.25647829921684995, 'Total loss': 0.25647829921684995}
2023-01-04 07:54:25,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:25,128 INFO:     Epoch: 98
2023-01-04 07:54:26,660 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3825770338376363, 'Total loss': 0.3825770338376363} | train loss {'Reaction outcome loss': 0.2549102311532428, 'Total loss': 0.2549102311532428}
2023-01-04 07:54:26,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:26,660 INFO:     Epoch: 99
2023-01-04 07:54:28,136 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3640673518180847, 'Total loss': 0.3640673518180847} | train loss {'Reaction outcome loss': 0.2564674799133391, 'Total loss': 0.2564674799133391}
2023-01-04 07:54:28,136 INFO:     Best model found after epoch 87 of 100.
2023-01-04 07:54:28,136 INFO:   Done with stage: TRAINING
2023-01-04 07:54:28,136 INFO:   Starting stage: EVALUATION
2023-01-04 07:54:28,272 INFO:   Done with stage: EVALUATION
2023-01-04 07:54:28,272 INFO:   Leaving out SEQ value Fold_3
2023-01-04 07:54:28,285 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 07:54:28,285 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:54:28,939 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:54:28,939 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:54:29,007 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:54:29,007 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:54:29,007 INFO:     No hyperparam tuning for this model
2023-01-04 07:54:29,007 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:54:29,007 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:54:29,008 INFO:     None feature selector for col prot
2023-01-04 07:54:29,008 INFO:     None feature selector for col prot
2023-01-04 07:54:29,008 INFO:     None feature selector for col prot
2023-01-04 07:54:29,009 INFO:     None feature selector for col chem
2023-01-04 07:54:29,009 INFO:     None feature selector for col chem
2023-01-04 07:54:29,009 INFO:     None feature selector for col chem
2023-01-04 07:54:29,009 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:54:29,009 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:54:29,010 INFO:     Number of params in model 70111
2023-01-04 07:54:29,013 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:54:29,013 INFO:   Starting stage: TRAINING
2023-01-04 07:54:29,056 INFO:     Val loss before train {'Reaction outcome loss': 0.9850326657295227, 'Total loss': 0.9850326657295227}
2023-01-04 07:54:29,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:29,056 INFO:     Epoch: 0
2023-01-04 07:54:30,586 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7709364573160807, 'Total loss': 0.7709364573160807} | train loss {'Reaction outcome loss': 0.853315016179731, 'Total loss': 0.853315016179731}
2023-01-04 07:54:30,586 INFO:     Found new best model at epoch 0
2023-01-04 07:54:30,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:30,587 INFO:     Epoch: 1
2023-01-04 07:54:32,113 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6061616698900859, 'Total loss': 0.6061616698900859} | train loss {'Reaction outcome loss': 0.7013410788315994, 'Total loss': 0.7013410788315994}
2023-01-04 07:54:32,114 INFO:     Found new best model at epoch 1
2023-01-04 07:54:32,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:32,115 INFO:     Epoch: 2
2023-01-04 07:54:33,657 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5074123720328013, 'Total loss': 0.5074123720328013} | train loss {'Reaction outcome loss': 0.590832722274375, 'Total loss': 0.590832722274375}
2023-01-04 07:54:33,657 INFO:     Found new best model at epoch 2
2023-01-04 07:54:33,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:33,658 INFO:     Epoch: 3
2023-01-04 07:54:35,177 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48710986574490867, 'Total loss': 0.48710986574490867} | train loss {'Reaction outcome loss': 0.5483906242873643, 'Total loss': 0.5483906242873643}
2023-01-04 07:54:35,177 INFO:     Found new best model at epoch 3
2023-01-04 07:54:35,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:35,178 INFO:     Epoch: 4
2023-01-04 07:54:36,648 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4719264398018519, 'Total loss': 0.4719264398018519} | train loss {'Reaction outcome loss': 0.5273587430789793, 'Total loss': 0.5273587430789793}
2023-01-04 07:54:36,648 INFO:     Found new best model at epoch 4
2023-01-04 07:54:36,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:36,649 INFO:     Epoch: 5
2023-01-04 07:54:38,194 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46169337034225466, 'Total loss': 0.46169337034225466} | train loss {'Reaction outcome loss': 0.5114823645833648, 'Total loss': 0.5114823645833648}
2023-01-04 07:54:38,194 INFO:     Found new best model at epoch 5
2023-01-04 07:54:38,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:38,195 INFO:     Epoch: 6
2023-01-04 07:54:39,727 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4757318377494812, 'Total loss': 0.4757318377494812} | train loss {'Reaction outcome loss': 0.4994062603939147, 'Total loss': 0.4994062603939147}
2023-01-04 07:54:39,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:39,728 INFO:     Epoch: 7
2023-01-04 07:54:41,264 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46120331486066185, 'Total loss': 0.46120331486066185} | train loss {'Reaction outcome loss': 0.4872758791341886, 'Total loss': 0.4872758791341886}
2023-01-04 07:54:41,264 INFO:     Found new best model at epoch 7
2023-01-04 07:54:41,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:41,265 INFO:     Epoch: 8
2023-01-04 07:54:42,812 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46656595468521117, 'Total loss': 0.46656595468521117} | train loss {'Reaction outcome loss': 0.47667963278817604, 'Total loss': 0.47667963278817604}
2023-01-04 07:54:42,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:42,812 INFO:     Epoch: 9
2023-01-04 07:54:44,348 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45261775652567543, 'Total loss': 0.45261775652567543} | train loss {'Reaction outcome loss': 0.47316949173207684, 'Total loss': 0.47316949173207684}
2023-01-04 07:54:44,349 INFO:     Found new best model at epoch 9
2023-01-04 07:54:44,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:44,350 INFO:     Epoch: 10
2023-01-04 07:54:45,821 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45497106611728666, 'Total loss': 0.45497106611728666} | train loss {'Reaction outcome loss': 0.4684340701107577, 'Total loss': 0.4684340701107577}
2023-01-04 07:54:45,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:45,821 INFO:     Epoch: 11
2023-01-04 07:54:47,371 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.447355721394221, 'Total loss': 0.447355721394221} | train loss {'Reaction outcome loss': 0.4593675159832169, 'Total loss': 0.4593675159832169}
2023-01-04 07:54:47,371 INFO:     Found new best model at epoch 11
2023-01-04 07:54:47,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:47,372 INFO:     Epoch: 12
2023-01-04 07:54:48,908 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4155117154121399, 'Total loss': 0.4155117154121399} | train loss {'Reaction outcome loss': 0.4537309250170058, 'Total loss': 0.4537309250170058}
2023-01-04 07:54:48,908 INFO:     Found new best model at epoch 12
2023-01-04 07:54:48,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:48,909 INFO:     Epoch: 13
2023-01-04 07:54:50,461 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42758469581604003, 'Total loss': 0.42758469581604003} | train loss {'Reaction outcome loss': 0.44833460256402746, 'Total loss': 0.44833460256402746}
2023-01-04 07:54:50,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:50,461 INFO:     Epoch: 14
2023-01-04 07:54:52,015 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4190134942531586, 'Total loss': 0.4190134942531586} | train loss {'Reaction outcome loss': 0.44690105466397256, 'Total loss': 0.44690105466397256}
2023-01-04 07:54:52,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:52,016 INFO:     Epoch: 15
2023-01-04 07:54:53,541 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4641720453898112, 'Total loss': 0.4641720453898112} | train loss {'Reaction outcome loss': 0.44119818121085674, 'Total loss': 0.44119818121085674}
2023-01-04 07:54:53,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:53,541 INFO:     Epoch: 16
2023-01-04 07:54:55,019 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4248359555999438, 'Total loss': 0.4248359555999438} | train loss {'Reaction outcome loss': 0.4384563602370657, 'Total loss': 0.4384563602370657}
2023-01-04 07:54:55,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:55,019 INFO:     Epoch: 17
2023-01-04 07:54:56,540 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4336055388053258, 'Total loss': 0.4336055388053258} | train loss {'Reaction outcome loss': 0.431767415814784, 'Total loss': 0.431767415814784}
2023-01-04 07:54:56,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:56,541 INFO:     Epoch: 18
2023-01-04 07:54:58,097 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3940060744682948, 'Total loss': 0.3940060744682948} | train loss {'Reaction outcome loss': 0.43133840363322595, 'Total loss': 0.43133840363322595}
2023-01-04 07:54:58,097 INFO:     Found new best model at epoch 18
2023-01-04 07:54:58,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:58,097 INFO:     Epoch: 19
2023-01-04 07:54:59,645 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.413316465417544, 'Total loss': 0.413316465417544} | train loss {'Reaction outcome loss': 0.42079155960362474, 'Total loss': 0.42079155960362474}
2023-01-04 07:54:59,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:54:59,645 INFO:     Epoch: 20
2023-01-04 07:55:01,190 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4018452102939288, 'Total loss': 0.4018452102939288} | train loss {'Reaction outcome loss': 0.4211310775397898, 'Total loss': 0.4211310775397898}
2023-01-04 07:55:01,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:01,190 INFO:     Epoch: 21
2023-01-04 07:55:02,746 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4098020027081172, 'Total loss': 0.4098020027081172} | train loss {'Reaction outcome loss': 0.4148407159816651, 'Total loss': 0.4148407159816651}
2023-01-04 07:55:02,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:02,747 INFO:     Epoch: 22
2023-01-04 07:55:04,233 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40179913739363354, 'Total loss': 0.40179913739363354} | train loss {'Reaction outcome loss': 0.4062506754101414, 'Total loss': 0.4062506754101414}
2023-01-04 07:55:04,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:04,234 INFO:     Epoch: 23
2023-01-04 07:55:05,766 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4087104896704356, 'Total loss': 0.4087104896704356} | train loss {'Reaction outcome loss': 0.4048188408707088, 'Total loss': 0.4048188408707088}
2023-01-04 07:55:05,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:05,766 INFO:     Epoch: 24
2023-01-04 07:55:07,297 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4460796038309733, 'Total loss': 0.4460796038309733} | train loss {'Reaction outcome loss': 0.4061115747078871, 'Total loss': 0.4061115747078871}
2023-01-04 07:55:07,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:07,297 INFO:     Epoch: 25
2023-01-04 07:55:08,830 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39824272990226744, 'Total loss': 0.39824272990226744} | train loss {'Reaction outcome loss': 0.4017397334915159, 'Total loss': 0.4017397334915159}
2023-01-04 07:55:08,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:08,830 INFO:     Epoch: 26
2023-01-04 07:55:10,370 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40759642521540324, 'Total loss': 0.40759642521540324} | train loss {'Reaction outcome loss': 0.39450726764542715, 'Total loss': 0.39450726764542715}
2023-01-04 07:55:10,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:10,371 INFO:     Epoch: 27
2023-01-04 07:55:11,906 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3827661861975988, 'Total loss': 0.3827661861975988} | train loss {'Reaction outcome loss': 0.39448705075424667, 'Total loss': 0.39448705075424667}
2023-01-04 07:55:11,906 INFO:     Found new best model at epoch 27
2023-01-04 07:55:11,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:11,907 INFO:     Epoch: 28
2023-01-04 07:55:13,398 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42089101672172546, 'Total loss': 0.42089101672172546} | train loss {'Reaction outcome loss': 0.3937204070252813, 'Total loss': 0.3937204070252813}
2023-01-04 07:55:13,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:13,398 INFO:     Epoch: 29
2023-01-04 07:55:14,934 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3982416649659475, 'Total loss': 0.3982416649659475} | train loss {'Reaction outcome loss': 0.3876583889235944, 'Total loss': 0.3876583889235944}
2023-01-04 07:55:14,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:14,934 INFO:     Epoch: 30
2023-01-04 07:55:16,470 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4179932703574499, 'Total loss': 0.4179932703574499} | train loss {'Reaction outcome loss': 0.3816689235216259, 'Total loss': 0.3816689235216259}
2023-01-04 07:55:16,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:16,471 INFO:     Epoch: 31
2023-01-04 07:55:18,008 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3890092064936956, 'Total loss': 0.3890092064936956} | train loss {'Reaction outcome loss': 0.3789140410694011, 'Total loss': 0.3789140410694011}
2023-01-04 07:55:18,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:18,009 INFO:     Epoch: 32
2023-01-04 07:55:19,546 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38083967864513396, 'Total loss': 0.38083967864513396} | train loss {'Reaction outcome loss': 0.3732220069829361, 'Total loss': 0.3732220069829361}
2023-01-04 07:55:19,546 INFO:     Found new best model at epoch 32
2023-01-04 07:55:19,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:19,547 INFO:     Epoch: 33
2023-01-04 07:55:21,056 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3859848399957021, 'Total loss': 0.3859848399957021} | train loss {'Reaction outcome loss': 0.36885076239978, 'Total loss': 0.36885076239978}
2023-01-04 07:55:21,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:21,056 INFO:     Epoch: 34
2023-01-04 07:55:22,553 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38128405809402466, 'Total loss': 0.38128405809402466} | train loss {'Reaction outcome loss': 0.37039660263956686, 'Total loss': 0.37039660263956686}
2023-01-04 07:55:22,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:22,554 INFO:     Epoch: 35
2023-01-04 07:55:24,097 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3781684954961141, 'Total loss': 0.3781684954961141} | train loss {'Reaction outcome loss': 0.3658217734251267, 'Total loss': 0.3658217734251267}
2023-01-04 07:55:24,097 INFO:     Found new best model at epoch 35
2023-01-04 07:55:24,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:24,098 INFO:     Epoch: 36
2023-01-04 07:55:25,643 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37647505700588224, 'Total loss': 0.37647505700588224} | train loss {'Reaction outcome loss': 0.36042206300483953, 'Total loss': 0.36042206300483953}
2023-01-04 07:55:25,643 INFO:     Found new best model at epoch 36
2023-01-04 07:55:25,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:25,644 INFO:     Epoch: 37
2023-01-04 07:55:27,179 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4170141836007436, 'Total loss': 0.4170141836007436} | train loss {'Reaction outcome loss': 0.36246191884899315, 'Total loss': 0.36246191884899315}
2023-01-04 07:55:27,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:27,179 INFO:     Epoch: 38
2023-01-04 07:55:28,724 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4042134592930476, 'Total loss': 0.4042134592930476} | train loss {'Reaction outcome loss': 0.35805573426323495, 'Total loss': 0.35805573426323495}
2023-01-04 07:55:28,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:28,724 INFO:     Epoch: 39
2023-01-04 07:55:30,222 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3791380743185679, 'Total loss': 0.3791380743185679} | train loss {'Reaction outcome loss': 0.3539832619192836, 'Total loss': 0.3539832619192836}
2023-01-04 07:55:30,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:30,222 INFO:     Epoch: 40
2023-01-04 07:55:31,734 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3739904388785362, 'Total loss': 0.3739904388785362} | train loss {'Reaction outcome loss': 0.3508330220049554, 'Total loss': 0.3508330220049554}
2023-01-04 07:55:31,735 INFO:     Found new best model at epoch 40
2023-01-04 07:55:31,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:31,736 INFO:     Epoch: 41
2023-01-04 07:55:33,280 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3746750737229983, 'Total loss': 0.3746750737229983} | train loss {'Reaction outcome loss': 0.3481898359654151, 'Total loss': 0.3481898359654151}
2023-01-04 07:55:33,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:33,280 INFO:     Epoch: 42
2023-01-04 07:55:34,833 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3919359008471171, 'Total loss': 0.3919359008471171} | train loss {'Reaction outcome loss': 0.3448204491492156, 'Total loss': 0.3448204491492156}
2023-01-04 07:55:34,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:34,834 INFO:     Epoch: 43
2023-01-04 07:55:36,392 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4259495516618093, 'Total loss': 0.4259495516618093} | train loss {'Reaction outcome loss': 0.34290168207179716, 'Total loss': 0.34290168207179716}
2023-01-04 07:55:36,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:36,392 INFO:     Epoch: 44
2023-01-04 07:55:37,946 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40018630425135293, 'Total loss': 0.40018630425135293} | train loss {'Reaction outcome loss': 0.344839042086741, 'Total loss': 0.344839042086741}
2023-01-04 07:55:37,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:37,948 INFO:     Epoch: 45
2023-01-04 07:55:39,456 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3986536830663681, 'Total loss': 0.3986536830663681} | train loss {'Reaction outcome loss': 0.3398402980886973, 'Total loss': 0.3398402980886973}
2023-01-04 07:55:39,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:39,456 INFO:     Epoch: 46
2023-01-04 07:55:40,972 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4093194882074992, 'Total loss': 0.4093194882074992} | train loss {'Reaction outcome loss': 0.3374323131782668, 'Total loss': 0.3374323131782668}
2023-01-04 07:55:40,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:40,972 INFO:     Epoch: 47
2023-01-04 07:55:42,528 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40010950167973836, 'Total loss': 0.40010950167973836} | train loss {'Reaction outcome loss': 0.3351625294967012, 'Total loss': 0.3351625294967012}
2023-01-04 07:55:42,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:42,528 INFO:     Epoch: 48
2023-01-04 07:55:44,079 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3721021523078283, 'Total loss': 0.3721021523078283} | train loss {'Reaction outcome loss': 0.3292463093231886, 'Total loss': 0.3292463093231886}
2023-01-04 07:55:44,079 INFO:     Found new best model at epoch 48
2023-01-04 07:55:44,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:44,080 INFO:     Epoch: 49
2023-01-04 07:55:45,629 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39348139067490895, 'Total loss': 0.39348139067490895} | train loss {'Reaction outcome loss': 0.32720877661373154, 'Total loss': 0.32720877661373154}
2023-01-04 07:55:45,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:45,629 INFO:     Epoch: 50
2023-01-04 07:55:47,181 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39245545566082, 'Total loss': 0.39245545566082} | train loss {'Reaction outcome loss': 0.3266490827768277, 'Total loss': 0.3266490827768277}
2023-01-04 07:55:47,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:47,182 INFO:     Epoch: 51
2023-01-04 07:55:48,708 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37041130860646565, 'Total loss': 0.37041130860646565} | train loss {'Reaction outcome loss': 0.3297090839608248, 'Total loss': 0.3297090839608248}
2023-01-04 07:55:48,708 INFO:     Found new best model at epoch 51
2023-01-04 07:55:48,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:48,709 INFO:     Epoch: 52
2023-01-04 07:55:50,230 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37716349760691326, 'Total loss': 0.37716349760691326} | train loss {'Reaction outcome loss': 0.32142675198587306, 'Total loss': 0.32142675198587306}
2023-01-04 07:55:50,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:50,230 INFO:     Epoch: 53
2023-01-04 07:55:51,765 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40649991979201633, 'Total loss': 0.40649991979201633} | train loss {'Reaction outcome loss': 0.3240128341966715, 'Total loss': 0.3240128341966715}
2023-01-04 07:55:51,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:51,765 INFO:     Epoch: 54
2023-01-04 07:55:53,290 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38807342847188314, 'Total loss': 0.38807342847188314} | train loss {'Reaction outcome loss': 0.31793019245122817, 'Total loss': 0.31793019245122817}
2023-01-04 07:55:53,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:53,290 INFO:     Epoch: 55
2023-01-04 07:55:54,839 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3789061268170675, 'Total loss': 0.3789061268170675} | train loss {'Reaction outcome loss': 0.32012194378690406, 'Total loss': 0.32012194378690406}
2023-01-04 07:55:54,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:54,840 INFO:     Epoch: 56
2023-01-04 07:55:56,368 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3971925775210063, 'Total loss': 0.3971925775210063} | train loss {'Reaction outcome loss': 0.31323510628098095, 'Total loss': 0.31323510628098095}
2023-01-04 07:55:56,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:56,368 INFO:     Epoch: 57
2023-01-04 07:55:57,880 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40079517364501954, 'Total loss': 0.40079517364501954} | train loss {'Reaction outcome loss': 0.3179571343783712, 'Total loss': 0.3179571343783712}
2023-01-04 07:55:57,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:57,881 INFO:     Epoch: 58
2023-01-04 07:55:59,385 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4020939230918884, 'Total loss': 0.4020939230918884} | train loss {'Reaction outcome loss': 0.3135833618514267, 'Total loss': 0.3135833618514267}
2023-01-04 07:55:59,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:55:59,385 INFO:     Epoch: 59
2023-01-04 07:56:00,925 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42801390290260316, 'Total loss': 0.42801390290260316} | train loss {'Reaction outcome loss': 0.3134159317492565, 'Total loss': 0.3134159317492565}
2023-01-04 07:56:00,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:00,925 INFO:     Epoch: 60
2023-01-04 07:56:02,455 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40989863773187, 'Total loss': 0.40989863773187} | train loss {'Reaction outcome loss': 0.3036577087236848, 'Total loss': 0.3036577087236848}
2023-01-04 07:56:02,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:02,456 INFO:     Epoch: 61
2023-01-04 07:56:03,990 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3836885650952657, 'Total loss': 0.3836885650952657} | train loss {'Reaction outcome loss': 0.308246044421589, 'Total loss': 0.308246044421589}
2023-01-04 07:56:03,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:03,991 INFO:     Epoch: 62
2023-01-04 07:56:05,520 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44044578075408936, 'Total loss': 0.44044578075408936} | train loss {'Reaction outcome loss': 0.3119977213742532, 'Total loss': 0.3119977213742532}
2023-01-04 07:56:05,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:05,520 INFO:     Epoch: 63
2023-01-04 07:56:07,018 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3856256643931071, 'Total loss': 0.3856256643931071} | train loss {'Reaction outcome loss': 0.3077215050985088, 'Total loss': 0.3077215050985088}
2023-01-04 07:56:07,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:07,018 INFO:     Epoch: 64
2023-01-04 07:56:08,534 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37440840105215706, 'Total loss': 0.37440840105215706} | train loss {'Reaction outcome loss': 0.3012376131537633, 'Total loss': 0.3012376131537633}
2023-01-04 07:56:08,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:08,535 INFO:     Epoch: 65
2023-01-04 07:56:10,070 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40913253227869667, 'Total loss': 0.40913253227869667} | train loss {'Reaction outcome loss': 0.2990635254662552, 'Total loss': 0.2990635254662552}
2023-01-04 07:56:10,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:10,071 INFO:     Epoch: 66
2023-01-04 07:56:11,610 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37890154321988423, 'Total loss': 0.37890154321988423} | train loss {'Reaction outcome loss': 0.2983871464218412, 'Total loss': 0.2983871464218412}
2023-01-04 07:56:11,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:11,611 INFO:     Epoch: 67
2023-01-04 07:56:13,150 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36923964420954386, 'Total loss': 0.36923964420954386} | train loss {'Reaction outcome loss': 0.2940767328271936, 'Total loss': 0.2940767328271936}
2023-01-04 07:56:13,150 INFO:     Found new best model at epoch 67
2023-01-04 07:56:13,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:13,151 INFO:     Epoch: 68
2023-01-04 07:56:14,699 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37138063708941144, 'Total loss': 0.37138063708941144} | train loss {'Reaction outcome loss': 0.2929167244105767, 'Total loss': 0.2929167244105767}
2023-01-04 07:56:14,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:14,700 INFO:     Epoch: 69
2023-01-04 07:56:16,186 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36416860992709793, 'Total loss': 0.36416860992709793} | train loss {'Reaction outcome loss': 0.2940161551379568, 'Total loss': 0.2940161551379568}
2023-01-04 07:56:16,186 INFO:     Found new best model at epoch 69
2023-01-04 07:56:16,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:16,187 INFO:     Epoch: 70
2023-01-04 07:56:17,208 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37109133700529734, 'Total loss': 0.37109133700529734} | train loss {'Reaction outcome loss': 0.295847128981199, 'Total loss': 0.295847128981199}
2023-01-04 07:56:17,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:17,208 INFO:     Epoch: 71
2023-01-04 07:56:18,218 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40180805027484895, 'Total loss': 0.40180805027484895} | train loss {'Reaction outcome loss': 0.2905930881780801, 'Total loss': 0.2905930881780801}
2023-01-04 07:56:18,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:18,218 INFO:     Epoch: 72
2023-01-04 07:56:19,228 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38374770283699033, 'Total loss': 0.38374770283699033} | train loss {'Reaction outcome loss': 0.28949952092799514, 'Total loss': 0.28949952092799514}
2023-01-04 07:56:19,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:19,228 INFO:     Epoch: 73
2023-01-04 07:56:20,236 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3842665284872055, 'Total loss': 0.3842665284872055} | train loss {'Reaction outcome loss': 0.28920916538862956, 'Total loss': 0.28920916538862956}
2023-01-04 07:56:20,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:20,236 INFO:     Epoch: 74
2023-01-04 07:56:21,710 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35524478256702424, 'Total loss': 0.35524478256702424} | train loss {'Reaction outcome loss': 0.28781735779710743, 'Total loss': 0.28781735779710743}
2023-01-04 07:56:21,711 INFO:     Found new best model at epoch 74
2023-01-04 07:56:21,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:21,712 INFO:     Epoch: 75
2023-01-04 07:56:23,209 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41640154321988426, 'Total loss': 0.41640154321988426} | train loss {'Reaction outcome loss': 0.2864341003472333, 'Total loss': 0.2864341003472333}
2023-01-04 07:56:23,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:23,209 INFO:     Epoch: 76
2023-01-04 07:56:24,735 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41010320285956064, 'Total loss': 0.41010320285956064} | train loss {'Reaction outcome loss': 0.28463017506586324, 'Total loss': 0.28463017506586324}
2023-01-04 07:56:24,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:24,735 INFO:     Epoch: 77
2023-01-04 07:56:26,270 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37794640362262727, 'Total loss': 0.37794640362262727} | train loss {'Reaction outcome loss': 0.28085917231691626, 'Total loss': 0.28085917231691626}
2023-01-04 07:56:26,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:26,270 INFO:     Epoch: 78
2023-01-04 07:56:27,793 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3822198142608007, 'Total loss': 0.3822198142608007} | train loss {'Reaction outcome loss': 0.2840869107689613, 'Total loss': 0.2840869107689613}
2023-01-04 07:56:27,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:27,794 INFO:     Epoch: 79
2023-01-04 07:56:29,314 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3928392966588338, 'Total loss': 0.3928392966588338} | train loss {'Reaction outcome loss': 0.2791605517814011, 'Total loss': 0.2791605517814011}
2023-01-04 07:56:29,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:29,314 INFO:     Epoch: 80
2023-01-04 07:56:30,832 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36290719111760456, 'Total loss': 0.36290719111760456} | train loss {'Reaction outcome loss': 0.28213715609231277, 'Total loss': 0.28213715609231277}
2023-01-04 07:56:30,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:30,832 INFO:     Epoch: 81
2023-01-04 07:56:32,340 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38680340846379596, 'Total loss': 0.38680340846379596} | train loss {'Reaction outcome loss': 0.27649596147921496, 'Total loss': 0.27649596147921496}
2023-01-04 07:56:32,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:32,340 INFO:     Epoch: 82
2023-01-04 07:56:33,871 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3767752836147944, 'Total loss': 0.3767752836147944} | train loss {'Reaction outcome loss': 0.2778491970601973, 'Total loss': 0.2778491970601973}
2023-01-04 07:56:33,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:33,873 INFO:     Epoch: 83
2023-01-04 07:56:35,410 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38342031836509705, 'Total loss': 0.38342031836509705} | train loss {'Reaction outcome loss': 0.27866996303473635, 'Total loss': 0.27866996303473635}
2023-01-04 07:56:35,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:35,410 INFO:     Epoch: 84
2023-01-04 07:56:36,963 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40316761533419293, 'Total loss': 0.40316761533419293} | train loss {'Reaction outcome loss': 0.2766749400086019, 'Total loss': 0.2766749400086019}
2023-01-04 07:56:36,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:36,963 INFO:     Epoch: 85
2023-01-04 07:56:38,485 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37641655206680297, 'Total loss': 0.37641655206680297} | train loss {'Reaction outcome loss': 0.27666797325178816, 'Total loss': 0.27666797325178816}
2023-01-04 07:56:38,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:38,485 INFO:     Epoch: 86
2023-01-04 07:56:39,997 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40355661114056907, 'Total loss': 0.40355661114056907} | train loss {'Reaction outcome loss': 0.27567853277801596, 'Total loss': 0.27567853277801596}
2023-01-04 07:56:39,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:39,998 INFO:     Epoch: 87
2023-01-04 07:56:41,528 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3925783778230349, 'Total loss': 0.3925783778230349} | train loss {'Reaction outcome loss': 0.27520446411091765, 'Total loss': 0.27520446411091765}
2023-01-04 07:56:41,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:41,528 INFO:     Epoch: 88
2023-01-04 07:56:43,074 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4165883382161458, 'Total loss': 0.4165883382161458} | train loss {'Reaction outcome loss': 0.2750664794674286, 'Total loss': 0.2750664794674286}
2023-01-04 07:56:43,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:43,074 INFO:     Epoch: 89
2023-01-04 07:56:44,641 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37932899991671243, 'Total loss': 0.37932899991671243} | train loss {'Reaction outcome loss': 0.27678160467645624, 'Total loss': 0.27678160467645624}
2023-01-04 07:56:44,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:44,641 INFO:     Epoch: 90
2023-01-04 07:56:46,208 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39815410375595095, 'Total loss': 0.39815410375595095} | train loss {'Reaction outcome loss': 0.27371411729644946, 'Total loss': 0.27371411729644946}
2023-01-04 07:56:46,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:46,208 INFO:     Epoch: 91
2023-01-04 07:56:47,730 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40200188954671223, 'Total loss': 0.40200188954671223} | train loss {'Reaction outcome loss': 0.271680645194355, 'Total loss': 0.271680645194355}
2023-01-04 07:56:47,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:47,731 INFO:     Epoch: 92
2023-01-04 07:56:49,267 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35876818795998894, 'Total loss': 0.35876818795998894} | train loss {'Reaction outcome loss': 0.2699726880306289, 'Total loss': 0.2699726880306289}
2023-01-04 07:56:49,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:49,268 INFO:     Epoch: 93
2023-01-04 07:56:50,817 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3770208021004995, 'Total loss': 0.3770208021004995} | train loss {'Reaction outcome loss': 0.2684063503157088, 'Total loss': 0.2684063503157088}
2023-01-04 07:56:50,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:50,818 INFO:     Epoch: 94
2023-01-04 07:56:52,371 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3812594930330912, 'Total loss': 0.3812594930330912} | train loss {'Reaction outcome loss': 0.26646544896202645, 'Total loss': 0.26646544896202645}
2023-01-04 07:56:52,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:52,372 INFO:     Epoch: 95
2023-01-04 07:56:53,915 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3632407397031784, 'Total loss': 0.3632407397031784} | train loss {'Reaction outcome loss': 0.2684046612581709, 'Total loss': 0.2684046612581709}
2023-01-04 07:56:53,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:53,915 INFO:     Epoch: 96
2023-01-04 07:56:55,474 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37918043732643125, 'Total loss': 0.37918043732643125} | train loss {'Reaction outcome loss': 0.26750663070233316, 'Total loss': 0.26750663070233316}
2023-01-04 07:56:55,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:55,475 INFO:     Epoch: 97
2023-01-04 07:56:56,989 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3566786309083303, 'Total loss': 0.3566786309083303} | train loss {'Reaction outcome loss': 0.260815244727519, 'Total loss': 0.260815244727519}
2023-01-04 07:56:56,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:56,990 INFO:     Epoch: 98
2023-01-04 07:56:58,501 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39762311379114784, 'Total loss': 0.39762311379114784} | train loss {'Reaction outcome loss': 0.26594514200538943, 'Total loss': 0.26594514200538943}
2023-01-04 07:56:58,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:56:58,501 INFO:     Epoch: 99
2023-01-04 07:57:00,043 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4263089964787165, 'Total loss': 0.4263089964787165} | train loss {'Reaction outcome loss': 0.2659341520169279, 'Total loss': 0.2659341520169279}
2023-01-04 07:57:00,043 INFO:     Best model found after epoch 75 of 100.
2023-01-04 07:57:00,043 INFO:   Done with stage: TRAINING
2023-01-04 07:57:00,044 INFO:   Starting stage: EVALUATION
2023-01-04 07:57:00,185 INFO:   Done with stage: EVALUATION
2023-01-04 07:57:00,185 INFO:   Leaving out SEQ value Fold_4
2023-01-04 07:57:00,197 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 07:57:00,197 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:57:00,850 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:57:00,851 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:57:00,920 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:57:00,920 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:57:00,920 INFO:     No hyperparam tuning for this model
2023-01-04 07:57:00,920 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:57:00,920 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:57:00,921 INFO:     None feature selector for col prot
2023-01-04 07:57:00,921 INFO:     None feature selector for col prot
2023-01-04 07:57:00,921 INFO:     None feature selector for col prot
2023-01-04 07:57:00,921 INFO:     None feature selector for col chem
2023-01-04 07:57:00,921 INFO:     None feature selector for col chem
2023-01-04 07:57:00,922 INFO:     None feature selector for col chem
2023-01-04 07:57:00,922 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:57:00,922 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:57:00,923 INFO:     Number of params in model 70111
2023-01-04 07:57:00,926 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:57:00,926 INFO:   Starting stage: TRAINING
2023-01-04 07:57:00,969 INFO:     Val loss before train {'Reaction outcome loss': 1.0011984586715699, 'Total loss': 1.0011984586715699}
2023-01-04 07:57:00,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:00,969 INFO:     Epoch: 0
2023-01-04 07:57:02,535 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7303583184878032, 'Total loss': 0.7303583184878032} | train loss {'Reaction outcome loss': 0.8368820610459531, 'Total loss': 0.8368820610459531}
2023-01-04 07:57:02,536 INFO:     Found new best model at epoch 0
2023-01-04 07:57:02,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:02,536 INFO:     Epoch: 1
2023-01-04 07:57:04,099 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6558076898256938, 'Total loss': 0.6558076898256938} | train loss {'Reaction outcome loss': 0.6811926158326628, 'Total loss': 0.6811926158326628}
2023-01-04 07:57:04,099 INFO:     Found new best model at epoch 1
2023-01-04 07:57:04,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:04,100 INFO:     Epoch: 2
2023-01-04 07:57:05,620 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5836375375588735, 'Total loss': 0.5836375375588735} | train loss {'Reaction outcome loss': 0.6013997046525728, 'Total loss': 0.6013997046525728}
2023-01-04 07:57:05,620 INFO:     Found new best model at epoch 2
2023-01-04 07:57:05,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:05,621 INFO:     Epoch: 3
2023-01-04 07:57:07,147 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5545103589693705, 'Total loss': 0.5545103589693705} | train loss {'Reaction outcome loss': 0.5574541176914738, 'Total loss': 0.5574541176914738}
2023-01-04 07:57:07,148 INFO:     Found new best model at epoch 3
2023-01-04 07:57:07,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:07,148 INFO:     Epoch: 4
2023-01-04 07:57:08,721 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5358005642890931, 'Total loss': 0.5358005642890931} | train loss {'Reaction outcome loss': 0.5315497985062616, 'Total loss': 0.5315497985062616}
2023-01-04 07:57:08,723 INFO:     Found new best model at epoch 4
2023-01-04 07:57:08,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:08,723 INFO:     Epoch: 5
2023-01-04 07:57:10,296 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5267906824747721, 'Total loss': 0.5267906824747721} | train loss {'Reaction outcome loss': 0.5102039463145638, 'Total loss': 0.5102039463145638}
2023-01-04 07:57:10,296 INFO:     Found new best model at epoch 5
2023-01-04 07:57:10,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:10,297 INFO:     Epoch: 6
2023-01-04 07:57:11,856 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5063105066617329, 'Total loss': 0.5063105066617329} | train loss {'Reaction outcome loss': 0.49807036218875583, 'Total loss': 0.49807036218875583}
2023-01-04 07:57:11,857 INFO:     Found new best model at epoch 6
2023-01-04 07:57:11,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:11,857 INFO:     Epoch: 7
2023-01-04 07:57:13,445 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5153856416543324, 'Total loss': 0.5153856416543324} | train loss {'Reaction outcome loss': 0.487552408976245, 'Total loss': 0.487552408976245}
2023-01-04 07:57:13,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:13,445 INFO:     Epoch: 8
2023-01-04 07:57:14,984 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5257643620173137, 'Total loss': 0.5257643620173137} | train loss {'Reaction outcome loss': 0.47806254933026726, 'Total loss': 0.47806254933026726}
2023-01-04 07:57:14,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:14,984 INFO:     Epoch: 9
2023-01-04 07:57:16,520 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49359727601210274, 'Total loss': 0.49359727601210274} | train loss {'Reaction outcome loss': 0.4716894950462162, 'Total loss': 0.4716894950462162}
2023-01-04 07:57:16,520 INFO:     Found new best model at epoch 9
2023-01-04 07:57:16,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:16,521 INFO:     Epoch: 10
2023-01-04 07:57:18,078 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4999691108862559, 'Total loss': 0.4999691108862559} | train loss {'Reaction outcome loss': 0.4653141138140475, 'Total loss': 0.4653141138140475}
2023-01-04 07:57:18,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:18,079 INFO:     Epoch: 11
2023-01-04 07:57:19,662 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49238697489102684, 'Total loss': 0.49238697489102684} | train loss {'Reaction outcome loss': 0.4590978535826886, 'Total loss': 0.4590978535826886}
2023-01-04 07:57:19,662 INFO:     Found new best model at epoch 11
2023-01-04 07:57:19,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:19,663 INFO:     Epoch: 12
2023-01-04 07:57:21,221 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48409085869789126, 'Total loss': 0.48409085869789126} | train loss {'Reaction outcome loss': 0.44819489998292406, 'Total loss': 0.44819489998292406}
2023-01-04 07:57:21,221 INFO:     Found new best model at epoch 12
2023-01-04 07:57:21,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:21,221 INFO:     Epoch: 13
2023-01-04 07:57:22,801 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49037476579348244, 'Total loss': 0.49037476579348244} | train loss {'Reaction outcome loss': 0.44909722624272647, 'Total loss': 0.44909722624272647}
2023-01-04 07:57:22,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:22,801 INFO:     Epoch: 14
2023-01-04 07:57:24,332 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48350725173950193, 'Total loss': 0.48350725173950193} | train loss {'Reaction outcome loss': 0.44499076728033243, 'Total loss': 0.44499076728033243}
2023-01-04 07:57:24,332 INFO:     Found new best model at epoch 14
2023-01-04 07:57:24,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:24,333 INFO:     Epoch: 15
2023-01-04 07:57:25,863 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4925700694322586, 'Total loss': 0.4925700694322586} | train loss {'Reaction outcome loss': 0.43993500445293604, 'Total loss': 0.43993500445293604}
2023-01-04 07:57:25,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:25,863 INFO:     Epoch: 16
2023-01-04 07:57:27,432 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46270676255226134, 'Total loss': 0.46270676255226134} | train loss {'Reaction outcome loss': 0.4341953096084216, 'Total loss': 0.4341953096084216}
2023-01-04 07:57:27,432 INFO:     Found new best model at epoch 16
2023-01-04 07:57:27,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:27,433 INFO:     Epoch: 17
2023-01-04 07:57:28,990 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46388577024141947, 'Total loss': 0.46388577024141947} | train loss {'Reaction outcome loss': 0.427458525403312, 'Total loss': 0.427458525403312}
2023-01-04 07:57:28,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:28,990 INFO:     Epoch: 18
2023-01-04 07:57:30,541 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4716199696063995, 'Total loss': 0.4716199696063995} | train loss {'Reaction outcome loss': 0.42310878898047366, 'Total loss': 0.42310878898047366}
2023-01-04 07:57:30,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:30,542 INFO:     Epoch: 19
2023-01-04 07:57:32,095 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4498075822989146, 'Total loss': 0.4498075822989146} | train loss {'Reaction outcome loss': 0.4223839597581526, 'Total loss': 0.4223839597581526}
2023-01-04 07:57:32,095 INFO:     Found new best model at epoch 19
2023-01-04 07:57:32,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:32,096 INFO:     Epoch: 20
2023-01-04 07:57:33,621 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48497813642024995, 'Total loss': 0.48497813642024995} | train loss {'Reaction outcome loss': 0.4165028794147478, 'Total loss': 0.4165028794147478}
2023-01-04 07:57:33,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:33,621 INFO:     Epoch: 21
2023-01-04 07:57:35,144 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4557296613852183, 'Total loss': 0.4557296613852183} | train loss {'Reaction outcome loss': 0.41454079693405205, 'Total loss': 0.41454079693405205}
2023-01-04 07:57:35,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:35,144 INFO:     Epoch: 22
2023-01-04 07:57:36,696 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47187832991282147, 'Total loss': 0.47187832991282147} | train loss {'Reaction outcome loss': 0.40725766888917136, 'Total loss': 0.40725766888917136}
2023-01-04 07:57:36,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:36,696 INFO:     Epoch: 23
2023-01-04 07:57:38,237 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4530133585135142, 'Total loss': 0.4530133585135142} | train loss {'Reaction outcome loss': 0.4061449977034696, 'Total loss': 0.4061449977034696}
2023-01-04 07:57:38,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:38,237 INFO:     Epoch: 24
2023-01-04 07:57:39,787 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.461078409353892, 'Total loss': 0.461078409353892} | train loss {'Reaction outcome loss': 0.40555063551728904, 'Total loss': 0.40555063551728904}
2023-01-04 07:57:39,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:39,789 INFO:     Epoch: 25
2023-01-04 07:57:41,342 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4443992922703425, 'Total loss': 0.4443992922703425} | train loss {'Reaction outcome loss': 0.39871800091077275, 'Total loss': 0.39871800091077275}
2023-01-04 07:57:41,342 INFO:     Found new best model at epoch 25
2023-01-04 07:57:41,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:41,343 INFO:     Epoch: 26
2023-01-04 07:57:42,862 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46053979992866517, 'Total loss': 0.46053979992866517} | train loss {'Reaction outcome loss': 0.3945100186964235, 'Total loss': 0.3945100186964235}
2023-01-04 07:57:42,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:42,863 INFO:     Epoch: 27
2023-01-04 07:57:44,387 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44480774899323783, 'Total loss': 0.44480774899323783} | train loss {'Reaction outcome loss': 0.3858276532714117, 'Total loss': 0.3858276532714117}
2023-01-04 07:57:44,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:44,387 INFO:     Epoch: 28
2023-01-04 07:57:45,958 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4362666577100754, 'Total loss': 0.4362666577100754} | train loss {'Reaction outcome loss': 0.38695101014973887, 'Total loss': 0.38695101014973887}
2023-01-04 07:57:45,959 INFO:     Found new best model at epoch 28
2023-01-04 07:57:45,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:45,960 INFO:     Epoch: 29
2023-01-04 07:57:47,572 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4399893303712209, 'Total loss': 0.4399893303712209} | train loss {'Reaction outcome loss': 0.3816184150290403, 'Total loss': 0.3816184150290403}
2023-01-04 07:57:47,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:47,572 INFO:     Epoch: 30
2023-01-04 07:57:49,160 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46516676545143126, 'Total loss': 0.46516676545143126} | train loss {'Reaction outcome loss': 0.3784680579005596, 'Total loss': 0.3784680579005596}
2023-01-04 07:57:49,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:49,160 INFO:     Epoch: 31
2023-01-04 07:57:50,732 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43674452404181163, 'Total loss': 0.43674452404181163} | train loss {'Reaction outcome loss': 0.37471378570429253, 'Total loss': 0.37471378570429253}
2023-01-04 07:57:50,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:50,732 INFO:     Epoch: 32
2023-01-04 07:57:52,314 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43009634415308634, 'Total loss': 0.43009634415308634} | train loss {'Reaction outcome loss': 0.371429991017395, 'Total loss': 0.371429991017395}
2023-01-04 07:57:52,314 INFO:     Found new best model at epoch 32
2023-01-04 07:57:52,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:52,315 INFO:     Epoch: 33
2023-01-04 07:57:53,885 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43731680810451506, 'Total loss': 0.43731680810451506} | train loss {'Reaction outcome loss': 0.3651604258088859, 'Total loss': 0.3651604258088859}
2023-01-04 07:57:53,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:53,885 INFO:     Epoch: 34
2023-01-04 07:57:55,487 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4164877692858378, 'Total loss': 0.4164877692858378} | train loss {'Reaction outcome loss': 0.3643297497922763, 'Total loss': 0.3643297497922763}
2023-01-04 07:57:55,487 INFO:     Found new best model at epoch 34
2023-01-04 07:57:55,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:55,488 INFO:     Epoch: 35
2023-01-04 07:57:57,086 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.421480659643809, 'Total loss': 0.421480659643809} | train loss {'Reaction outcome loss': 0.3583107505679561, 'Total loss': 0.3583107505679561}
2023-01-04 07:57:57,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:57,086 INFO:     Epoch: 36
2023-01-04 07:57:58,682 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42269534468650816, 'Total loss': 0.42269534468650816} | train loss {'Reaction outcome loss': 0.3551001597182415, 'Total loss': 0.3551001597182415}
2023-01-04 07:57:58,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:57:58,683 INFO:     Epoch: 37
2023-01-04 07:58:00,242 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4639663457870483, 'Total loss': 0.4639663457870483} | train loss {'Reaction outcome loss': 0.3531743844143966, 'Total loss': 0.3531743844143966}
2023-01-04 07:58:00,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:00,242 INFO:     Epoch: 38
2023-01-04 07:58:01,798 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4119746208190918, 'Total loss': 0.4119746208190918} | train loss {'Reaction outcome loss': 0.35245487459730157, 'Total loss': 0.35245487459730157}
2023-01-04 07:58:01,799 INFO:     Found new best model at epoch 38
2023-01-04 07:58:01,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:01,799 INFO:     Epoch: 39
2023-01-04 07:58:03,413 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42216572860876717, 'Total loss': 0.42216572860876717} | train loss {'Reaction outcome loss': 0.34624667710453166, 'Total loss': 0.34624667710453166}
2023-01-04 07:58:03,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:03,413 INFO:     Epoch: 40
2023-01-04 07:58:05,030 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44615259766578674, 'Total loss': 0.44615259766578674} | train loss {'Reaction outcome loss': 0.3417450188783532, 'Total loss': 0.3417450188783532}
2023-01-04 07:58:05,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:05,031 INFO:     Epoch: 41
2023-01-04 07:58:06,652 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41498055855433147, 'Total loss': 0.41498055855433147} | train loss {'Reaction outcome loss': 0.34205412937308044, 'Total loss': 0.34205412937308044}
2023-01-04 07:58:06,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:06,652 INFO:     Epoch: 42
2023-01-04 07:58:08,252 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4461574991544088, 'Total loss': 0.4461574991544088} | train loss {'Reaction outcome loss': 0.3378278812131296, 'Total loss': 0.3378278812131296}
2023-01-04 07:58:08,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:08,252 INFO:     Epoch: 43
2023-01-04 07:58:09,830 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43108090162277224, 'Total loss': 0.43108090162277224} | train loss {'Reaction outcome loss': 0.339311987672687, 'Total loss': 0.339311987672687}
2023-01-04 07:58:09,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:09,831 INFO:     Epoch: 44
2023-01-04 07:58:11,406 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4359571814537048, 'Total loss': 0.4359571814537048} | train loss {'Reaction outcome loss': 0.33109051036221454, 'Total loss': 0.33109051036221454}
2023-01-04 07:58:11,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:11,408 INFO:     Epoch: 45
2023-01-04 07:58:13,020 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4307125310103099, 'Total loss': 0.4307125310103099} | train loss {'Reaction outcome loss': 0.32689975059527354, 'Total loss': 0.32689975059527354}
2023-01-04 07:58:13,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:13,020 INFO:     Epoch: 46
2023-01-04 07:58:14,634 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4587061862150828, 'Total loss': 0.4587061862150828} | train loss {'Reaction outcome loss': 0.3302058590717264, 'Total loss': 0.3302058590717264}
2023-01-04 07:58:14,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:14,635 INFO:     Epoch: 47
2023-01-04 07:58:16,252 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4263564666112264, 'Total loss': 0.4263564666112264} | train loss {'Reaction outcome loss': 0.3265549444227012, 'Total loss': 0.3265549444227012}
2023-01-04 07:58:16,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:16,252 INFO:     Epoch: 48
2023-01-04 07:58:17,779 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4226873219013214, 'Total loss': 0.4226873219013214} | train loss {'Reaction outcome loss': 0.32391944317826293, 'Total loss': 0.32391944317826293}
2023-01-04 07:58:17,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:17,780 INFO:     Epoch: 49
2023-01-04 07:58:19,299 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4199084728956223, 'Total loss': 0.4199084728956223} | train loss {'Reaction outcome loss': 0.32121899589519637, 'Total loss': 0.32121899589519637}
2023-01-04 07:58:19,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:19,299 INFO:     Epoch: 50
2023-01-04 07:58:20,817 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40074268778165184, 'Total loss': 0.40074268778165184} | train loss {'Reaction outcome loss': 0.317335525978128, 'Total loss': 0.317335525978128}
2023-01-04 07:58:20,817 INFO:     Found new best model at epoch 50
2023-01-04 07:58:20,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:20,818 INFO:     Epoch: 51
2023-01-04 07:58:22,380 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40381651123364765, 'Total loss': 0.40381651123364765} | train loss {'Reaction outcome loss': 0.31815775233700816, 'Total loss': 0.31815775233700816}
2023-01-04 07:58:22,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:22,380 INFO:     Epoch: 52
2023-01-04 07:58:23,929 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42754046817620595, 'Total loss': 0.42754046817620595} | train loss {'Reaction outcome loss': 0.31525108920215267, 'Total loss': 0.31525108920215267}
2023-01-04 07:58:23,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:23,929 INFO:     Epoch: 53
2023-01-04 07:58:25,481 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4519336332877477, 'Total loss': 0.4519336332877477} | train loss {'Reaction outcome loss': 0.3161438230142697, 'Total loss': 0.3161438230142697}
2023-01-04 07:58:25,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:25,481 INFO:     Epoch: 54
2023-01-04 07:58:27,038 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41633420387903847, 'Total loss': 0.41633420387903847} | train loss {'Reaction outcome loss': 0.3134830618539442, 'Total loss': 0.3134830618539442}
2023-01-04 07:58:27,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:27,038 INFO:     Epoch: 55
2023-01-04 07:58:28,598 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41862743298212685, 'Total loss': 0.41862743298212685} | train loss {'Reaction outcome loss': 0.31016105281639617, 'Total loss': 0.31016105281639617}
2023-01-04 07:58:28,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:28,598 INFO:     Epoch: 56
2023-01-04 07:58:30,138 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44263751109441124, 'Total loss': 0.44263751109441124} | train loss {'Reaction outcome loss': 0.30500464792286014, 'Total loss': 0.30500464792286014}
2023-01-04 07:58:30,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:30,139 INFO:     Epoch: 57
2023-01-04 07:58:31,710 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42816076179345447, 'Total loss': 0.42816076179345447} | train loss {'Reaction outcome loss': 0.30406339840445706, 'Total loss': 0.30406339840445706}
2023-01-04 07:58:31,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:31,711 INFO:     Epoch: 58
2023-01-04 07:58:33,297 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4147306477030118, 'Total loss': 0.4147306477030118} | train loss {'Reaction outcome loss': 0.30062680201947906, 'Total loss': 0.30062680201947906}
2023-01-04 07:58:33,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:33,297 INFO:     Epoch: 59
2023-01-04 07:58:34,872 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41988859275976814, 'Total loss': 0.41988859275976814} | train loss {'Reaction outcome loss': 0.30085323651452356, 'Total loss': 0.30085323651452356}
2023-01-04 07:58:34,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:34,873 INFO:     Epoch: 60
2023-01-04 07:58:36,402 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42339007556438446, 'Total loss': 0.42339007556438446} | train loss {'Reaction outcome loss': 0.2980645993717741, 'Total loss': 0.2980645993717741}
2023-01-04 07:58:36,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:36,403 INFO:     Epoch: 61
2023-01-04 07:58:37,961 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4434390830496947, 'Total loss': 0.4434390830496947} | train loss {'Reaction outcome loss': 0.29507482595176904, 'Total loss': 0.29507482595176904}
2023-01-04 07:58:37,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:37,961 INFO:     Epoch: 62
2023-01-04 07:58:39,526 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42034885883331297, 'Total loss': 0.42034885883331297} | train loss {'Reaction outcome loss': 0.2946010214757403, 'Total loss': 0.2946010214757403}
2023-01-04 07:58:39,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:39,527 INFO:     Epoch: 63
2023-01-04 07:58:41,102 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42963479657967885, 'Total loss': 0.42963479657967885} | train loss {'Reaction outcome loss': 0.2922115098779167, 'Total loss': 0.2922115098779167}
2023-01-04 07:58:41,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:41,102 INFO:     Epoch: 64
2023-01-04 07:58:42,679 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42264748613039654, 'Total loss': 0.42264748613039654} | train loss {'Reaction outcome loss': 0.29196685081892493, 'Total loss': 0.29196685081892493}
2023-01-04 07:58:42,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:42,679 INFO:     Epoch: 65
2023-01-04 07:58:44,266 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4289402941862742, 'Total loss': 0.4289402941862742} | train loss {'Reaction outcome loss': 0.28794997615827117, 'Total loss': 0.28794997615827117}
2023-01-04 07:58:44,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:44,266 INFO:     Epoch: 66
2023-01-04 07:58:45,808 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42607208887736003, 'Total loss': 0.42607208887736003} | train loss {'Reaction outcome loss': 0.28824938134381056, 'Total loss': 0.28824938134381056}
2023-01-04 07:58:45,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:45,809 INFO:     Epoch: 67
2023-01-04 07:58:47,341 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4049712618192037, 'Total loss': 0.4049712618192037} | train loss {'Reaction outcome loss': 0.2831193619686774, 'Total loss': 0.2831193619686774}
2023-01-04 07:58:47,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:47,342 INFO:     Epoch: 68
2023-01-04 07:58:48,913 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41960225204626717, 'Total loss': 0.41960225204626717} | train loss {'Reaction outcome loss': 0.28817255141395093, 'Total loss': 0.28817255141395093}
2023-01-04 07:58:48,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:48,913 INFO:     Epoch: 69
2023-01-04 07:58:50,490 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4250655551751455, 'Total loss': 0.4250655551751455} | train loss {'Reaction outcome loss': 0.29088509236109383, 'Total loss': 0.29088509236109383}
2023-01-04 07:58:50,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:50,491 INFO:     Epoch: 70
2023-01-04 07:58:52,079 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42777805030345917, 'Total loss': 0.42777805030345917} | train loss {'Reaction outcome loss': 0.281898526158789, 'Total loss': 0.281898526158789}
2023-01-04 07:58:52,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:52,080 INFO:     Epoch: 71
2023-01-04 07:58:53,658 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.400504602988561, 'Total loss': 0.400504602988561} | train loss {'Reaction outcome loss': 0.2827800944824081, 'Total loss': 0.2827800944824081}
2023-01-04 07:58:53,658 INFO:     Found new best model at epoch 71
2023-01-04 07:58:53,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:53,659 INFO:     Epoch: 72
2023-01-04 07:58:55,200 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.423092649380366, 'Total loss': 0.423092649380366} | train loss {'Reaction outcome loss': 0.2785950024689578, 'Total loss': 0.2785950024689578}
2023-01-04 07:58:55,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:55,200 INFO:     Epoch: 73
2023-01-04 07:58:56,750 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.394065859913826, 'Total loss': 0.394065859913826} | train loss {'Reaction outcome loss': 0.2779604614265129, 'Total loss': 0.2779604614265129}
2023-01-04 07:58:56,750 INFO:     Found new best model at epoch 73
2023-01-04 07:58:56,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:56,751 INFO:     Epoch: 74
2023-01-04 07:58:58,336 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40731747845808663, 'Total loss': 0.40731747845808663} | train loss {'Reaction outcome loss': 0.2767616300053545, 'Total loss': 0.2767616300053545}
2023-01-04 07:58:58,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:58,336 INFO:     Epoch: 75
2023-01-04 07:58:59,917 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4293327440818151, 'Total loss': 0.4293327440818151} | train loss {'Reaction outcome loss': 0.27545918376329576, 'Total loss': 0.27545918376329576}
2023-01-04 07:58:59,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:58:59,917 INFO:     Epoch: 76
2023-01-04 07:59:01,502 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4230250279108683, 'Total loss': 0.4230250279108683} | train loss {'Reaction outcome loss': 0.276109455899749, 'Total loss': 0.276109455899749}
2023-01-04 07:59:01,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:01,503 INFO:     Epoch: 77
2023-01-04 07:59:03,068 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40116287072499596, 'Total loss': 0.40116287072499596} | train loss {'Reaction outcome loss': 0.27831860779640044, 'Total loss': 0.27831860779640044}
2023-01-04 07:59:03,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:03,069 INFO:     Epoch: 78
2023-01-04 07:59:04,594 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4262147625287374, 'Total loss': 0.4262147625287374} | train loss {'Reaction outcome loss': 0.27246997223003677, 'Total loss': 0.27246997223003677}
2023-01-04 07:59:04,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:04,595 INFO:     Epoch: 79
2023-01-04 07:59:06,120 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4108133643865585, 'Total loss': 0.4108133643865585} | train loss {'Reaction outcome loss': 0.2724761467978412, 'Total loss': 0.2724761467978412}
2023-01-04 07:59:06,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:06,120 INFO:     Epoch: 80
2023-01-04 07:59:07,689 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40522734920183817, 'Total loss': 0.40522734920183817} | train loss {'Reaction outcome loss': 0.2664277344296555, 'Total loss': 0.2664277344296555}
2023-01-04 07:59:07,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:07,689 INFO:     Epoch: 81
2023-01-04 07:59:09,239 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39615371574958164, 'Total loss': 0.39615371574958164} | train loss {'Reaction outcome loss': 0.26456417958336187, 'Total loss': 0.26456417958336187}
2023-01-04 07:59:09,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:09,239 INFO:     Epoch: 82
2023-01-04 07:59:10,803 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3964815298716227, 'Total loss': 0.3964815298716227} | train loss {'Reaction outcome loss': 0.27064822173075553, 'Total loss': 0.27064822173075553}
2023-01-04 07:59:10,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:10,803 INFO:     Epoch: 83
2023-01-04 07:59:12,371 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3932098885377248, 'Total loss': 0.3932098885377248} | train loss {'Reaction outcome loss': 0.26539780799339824, 'Total loss': 0.26539780799339824}
2023-01-04 07:59:12,371 INFO:     Found new best model at epoch 83
2023-01-04 07:59:12,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:12,372 INFO:     Epoch: 84
2023-01-04 07:59:13,915 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3840385655562083, 'Total loss': 0.3840385655562083} | train loss {'Reaction outcome loss': 0.26510559299469855, 'Total loss': 0.26510559299469855}
2023-01-04 07:59:13,915 INFO:     Found new best model at epoch 84
2023-01-04 07:59:13,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:13,916 INFO:     Epoch: 85
2023-01-04 07:59:15,456 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3986369530359904, 'Total loss': 0.3986369530359904} | train loss {'Reaction outcome loss': 0.266733574872628, 'Total loss': 0.266733574872628}
2023-01-04 07:59:15,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:15,457 INFO:     Epoch: 86
2023-01-04 07:59:17,027 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4075705587863922, 'Total loss': 0.4075705587863922} | train loss {'Reaction outcome loss': 0.2665071844489781, 'Total loss': 0.2665071844489781}
2023-01-04 07:59:17,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:17,027 INFO:     Epoch: 87
2023-01-04 07:59:18,593 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40018916726112364, 'Total loss': 0.40018916726112364} | train loss {'Reaction outcome loss': 0.2624362888426557, 'Total loss': 0.2624362888426557}
2023-01-04 07:59:18,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:18,593 INFO:     Epoch: 88
2023-01-04 07:59:20,163 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4164911617835363, 'Total loss': 0.4164911617835363} | train loss {'Reaction outcome loss': 0.26375878064318253, 'Total loss': 0.26375878064318253}
2023-01-04 07:59:20,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:20,163 INFO:     Epoch: 89
2023-01-04 07:59:21,691 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39869231084982554, 'Total loss': 0.39869231084982554} | train loss {'Reaction outcome loss': 0.2591809390469148, 'Total loss': 0.2591809390469148}
2023-01-04 07:59:21,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:21,692 INFO:     Epoch: 90
2023-01-04 07:59:23,216 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.368292302886645, 'Total loss': 0.368292302886645} | train loss {'Reaction outcome loss': 0.2576055726581102, 'Total loss': 0.2576055726581102}
2023-01-04 07:59:23,217 INFO:     Found new best model at epoch 90
2023-01-04 07:59:23,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:23,217 INFO:     Epoch: 91
2023-01-04 07:59:24,773 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4073448618253072, 'Total loss': 0.4073448618253072} | train loss {'Reaction outcome loss': 0.2581248909826743, 'Total loss': 0.2581248909826743}
2023-01-04 07:59:24,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:24,773 INFO:     Epoch: 92
2023-01-04 07:59:26,334 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37668960889180503, 'Total loss': 0.37668960889180503} | train loss {'Reaction outcome loss': 0.25573117082891483, 'Total loss': 0.25573117082891483}
2023-01-04 07:59:26,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:26,335 INFO:     Epoch: 93
2023-01-04 07:59:27,896 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38642660329739253, 'Total loss': 0.38642660329739253} | train loss {'Reaction outcome loss': 0.25432513829065145, 'Total loss': 0.25432513829065145}
2023-01-04 07:59:27,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:27,897 INFO:     Epoch: 94
2023-01-04 07:59:29,475 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38478737100958826, 'Total loss': 0.38478737100958826} | train loss {'Reaction outcome loss': 0.25447908568360744, 'Total loss': 0.25447908568360744}
2023-01-04 07:59:29,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:29,476 INFO:     Epoch: 95
2023-01-04 07:59:31,006 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40519341031710304, 'Total loss': 0.40519341031710304} | train loss {'Reaction outcome loss': 0.25562091737931814, 'Total loss': 0.25562091737931814}
2023-01-04 07:59:31,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:31,006 INFO:     Epoch: 96
2023-01-04 07:59:32,532 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40381150345007577, 'Total loss': 0.40381150345007577} | train loss {'Reaction outcome loss': 0.25236593547280517, 'Total loss': 0.25236593547280517}
2023-01-04 07:59:32,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:32,533 INFO:     Epoch: 97
2023-01-04 07:59:34,076 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40233555634816487, 'Total loss': 0.40233555634816487} | train loss {'Reaction outcome loss': 0.253509921663935, 'Total loss': 0.253509921663935}
2023-01-04 07:59:34,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:34,076 INFO:     Epoch: 98
2023-01-04 07:59:35,653 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3978899449110031, 'Total loss': 0.3978899449110031} | train loss {'Reaction outcome loss': 0.2539598928892225, 'Total loss': 0.2539598928892225}
2023-01-04 07:59:35,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:35,653 INFO:     Epoch: 99
2023-01-04 07:59:37,218 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4193825433651606, 'Total loss': 0.4193825433651606} | train loss {'Reaction outcome loss': 0.25080504502415224, 'Total loss': 0.25080504502415224}
2023-01-04 07:59:37,218 INFO:     Best model found after epoch 91 of 100.
2023-01-04 07:59:37,218 INFO:   Done with stage: TRAINING
2023-01-04 07:59:37,218 INFO:   Starting stage: EVALUATION
2023-01-04 07:59:37,339 INFO:   Done with stage: EVALUATION
2023-01-04 07:59:37,339 INFO:   Leaving out SEQ value Fold_5
2023-01-04 07:59:37,352 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 07:59:37,352 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:59:38,000 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:59:38,000 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:59:38,069 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:59:38,069 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:59:38,070 INFO:     No hyperparam tuning for this model
2023-01-04 07:59:38,070 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:59:38,070 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:59:38,070 INFO:     None feature selector for col prot
2023-01-04 07:59:38,071 INFO:     None feature selector for col prot
2023-01-04 07:59:38,071 INFO:     None feature selector for col prot
2023-01-04 07:59:38,071 INFO:     None feature selector for col chem
2023-01-04 07:59:38,071 INFO:     None feature selector for col chem
2023-01-04 07:59:38,071 INFO:     None feature selector for col chem
2023-01-04 07:59:38,071 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:59:38,071 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:59:38,072 INFO:     Number of params in model 70111
2023-01-04 07:59:38,076 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:59:38,076 INFO:   Starting stage: TRAINING
2023-01-04 07:59:38,117 INFO:     Val loss before train {'Reaction outcome loss': 0.9957435488700866, 'Total loss': 0.9957435488700866}
2023-01-04 07:59:38,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:38,118 INFO:     Epoch: 0
2023-01-04 07:59:39,653 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6819933116436004, 'Total loss': 0.6819933116436004} | train loss {'Reaction outcome loss': 0.8416191680551867, 'Total loss': 0.8416191680551867}
2023-01-04 07:59:39,653 INFO:     Found new best model at epoch 0
2023-01-04 07:59:39,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:39,654 INFO:     Epoch: 1
2023-01-04 07:59:41,179 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5621198892593384, 'Total loss': 0.5621198892593384} | train loss {'Reaction outcome loss': 0.661031937071993, 'Total loss': 0.661031937071993}
2023-01-04 07:59:41,180 INFO:     Found new best model at epoch 1
2023-01-04 07:59:41,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:41,181 INFO:     Epoch: 2
2023-01-04 07:59:42,745 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5049263815085093, 'Total loss': 0.5049263815085093} | train loss {'Reaction outcome loss': 0.5768137097573883, 'Total loss': 0.5768137097573883}
2023-01-04 07:59:42,745 INFO:     Found new best model at epoch 2
2023-01-04 07:59:42,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:42,746 INFO:     Epoch: 3
2023-01-04 07:59:44,308 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47212114234765373, 'Total loss': 0.47212114234765373} | train loss {'Reaction outcome loss': 0.540085488708441, 'Total loss': 0.540085488708441}
2023-01-04 07:59:44,308 INFO:     Found new best model at epoch 3
2023-01-04 07:59:44,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:44,308 INFO:     Epoch: 4
2023-01-04 07:59:45,856 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48267699480056764, 'Total loss': 0.48267699480056764} | train loss {'Reaction outcome loss': 0.5167931160126352, 'Total loss': 0.5167931160126352}
2023-01-04 07:59:45,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:45,856 INFO:     Epoch: 5
2023-01-04 07:59:47,421 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4684947460889816, 'Total loss': 0.4684947460889816} | train loss {'Reaction outcome loss': 0.5028636216149003, 'Total loss': 0.5028636216149003}
2023-01-04 07:59:47,421 INFO:     Found new best model at epoch 5
2023-01-04 07:59:47,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:47,422 INFO:     Epoch: 6
2023-01-04 07:59:48,963 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47351588010787965, 'Total loss': 0.47351588010787965} | train loss {'Reaction outcome loss': 0.4913708026981526, 'Total loss': 0.4913708026981526}
2023-01-04 07:59:48,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:48,963 INFO:     Epoch: 7
2023-01-04 07:59:50,493 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4574533621470133, 'Total loss': 0.4574533621470133} | train loss {'Reaction outcome loss': 0.4853142696812695, 'Total loss': 0.4853142696812695}
2023-01-04 07:59:50,493 INFO:     Found new best model at epoch 7
2023-01-04 07:59:50,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:50,494 INFO:     Epoch: 8
2023-01-04 07:59:52,038 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4747455050547918, 'Total loss': 0.4747455050547918} | train loss {'Reaction outcome loss': 0.4745328906210751, 'Total loss': 0.4745328906210751}
2023-01-04 07:59:52,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:52,039 INFO:     Epoch: 9
2023-01-04 07:59:53,584 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45018967787424724, 'Total loss': 0.45018967787424724} | train loss {'Reaction outcome loss': 0.46607493316008297, 'Total loss': 0.46607493316008297}
2023-01-04 07:59:53,585 INFO:     Found new best model at epoch 9
2023-01-04 07:59:53,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:53,585 INFO:     Epoch: 10
2023-01-04 07:59:55,150 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4672115574280421, 'Total loss': 0.4672115574280421} | train loss {'Reaction outcome loss': 0.46185849106699123, 'Total loss': 0.46185849106699123}
2023-01-04 07:59:55,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:55,150 INFO:     Epoch: 11
2023-01-04 07:59:56,705 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44347801208496096, 'Total loss': 0.44347801208496096} | train loss {'Reaction outcome loss': 0.456673122431397, 'Total loss': 0.456673122431397}
2023-01-04 07:59:56,705 INFO:     Found new best model at epoch 11
2023-01-04 07:59:56,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:56,706 INFO:     Epoch: 12
2023-01-04 07:59:58,232 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4550137241681417, 'Total loss': 0.4550137241681417} | train loss {'Reaction outcome loss': 0.44598662272257067, 'Total loss': 0.44598662272257067}
2023-01-04 07:59:58,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:58,232 INFO:     Epoch: 13
2023-01-04 07:59:59,770 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43822916944821677, 'Total loss': 0.43822916944821677} | train loss {'Reaction outcome loss': 0.4424999669355606, 'Total loss': 0.4424999669355606}
2023-01-04 07:59:59,771 INFO:     Found new best model at epoch 13
2023-01-04 07:59:59,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:59:59,771 INFO:     Epoch: 14
2023-01-04 08:00:01,315 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.452699879805247, 'Total loss': 0.452699879805247} | train loss {'Reaction outcome loss': 0.4397780493654929, 'Total loss': 0.4397780493654929}
2023-01-04 08:00:01,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:01,315 INFO:     Epoch: 15
2023-01-04 08:00:02,877 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4462825745344162, 'Total loss': 0.4462825745344162} | train loss {'Reaction outcome loss': 0.43375648800216426, 'Total loss': 0.43375648800216426}
2023-01-04 08:00:02,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:02,877 INFO:     Epoch: 16
2023-01-04 08:00:04,422 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44532140493392947, 'Total loss': 0.44532140493392947} | train loss {'Reaction outcome loss': 0.42545552783064033, 'Total loss': 0.42545552783064033}
2023-01-04 08:00:04,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:04,423 INFO:     Epoch: 17
2023-01-04 08:00:05,971 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4452838162581126, 'Total loss': 0.4452838162581126} | train loss {'Reaction outcome loss': 0.42318954617322996, 'Total loss': 0.42318954617322996}
2023-01-04 08:00:05,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:05,972 INFO:     Epoch: 18
2023-01-04 08:00:07,492 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43916732470194497, 'Total loss': 0.43916732470194497} | train loss {'Reaction outcome loss': 0.41888753596410855, 'Total loss': 0.41888753596410855}
2023-01-04 08:00:07,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:07,493 INFO:     Epoch: 19
2023-01-04 08:00:09,002 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4241540680329005, 'Total loss': 0.4241540680329005} | train loss {'Reaction outcome loss': 0.41568460172909694, 'Total loss': 0.41568460172909694}
2023-01-04 08:00:09,002 INFO:     Found new best model at epoch 19
2023-01-04 08:00:09,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:09,003 INFO:     Epoch: 20
2023-01-04 08:00:10,553 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42386840681234994, 'Total loss': 0.42386840681234994} | train loss {'Reaction outcome loss': 0.4141344741417182, 'Total loss': 0.4141344741417182}
2023-01-04 08:00:10,553 INFO:     Found new best model at epoch 20
2023-01-04 08:00:10,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:10,554 INFO:     Epoch: 21
2023-01-04 08:00:12,107 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4284325838088989, 'Total loss': 0.4284325838088989} | train loss {'Reaction outcome loss': 0.40544553601354466, 'Total loss': 0.40544553601354466}
2023-01-04 08:00:12,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:12,108 INFO:     Epoch: 22
2023-01-04 08:00:13,660 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42174574037392937, 'Total loss': 0.42174574037392937} | train loss {'Reaction outcome loss': 0.4015395450624318, 'Total loss': 0.4015395450624318}
2023-01-04 08:00:13,660 INFO:     Found new best model at epoch 22
2023-01-04 08:00:13,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:13,661 INFO:     Epoch: 23
2023-01-04 08:00:15,216 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4001286933819453, 'Total loss': 0.4001286933819453} | train loss {'Reaction outcome loss': 0.39643763167117907, 'Total loss': 0.39643763167117907}
2023-01-04 08:00:15,216 INFO:     Found new best model at epoch 23
2023-01-04 08:00:15,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:15,217 INFO:     Epoch: 24
2023-01-04 08:00:16,730 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4176029205322266, 'Total loss': 0.4176029205322266} | train loss {'Reaction outcome loss': 0.3901156046115104, 'Total loss': 0.3901156046115104}
2023-01-04 08:00:16,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:16,730 INFO:     Epoch: 25
2023-01-04 08:00:18,255 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4078021804491679, 'Total loss': 0.4078021804491679} | train loss {'Reaction outcome loss': 0.388322113142332, 'Total loss': 0.388322113142332}
2023-01-04 08:00:18,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:18,256 INFO:     Epoch: 26
2023-01-04 08:00:19,793 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4115398695071538, 'Total loss': 0.4115398695071538} | train loss {'Reaction outcome loss': 0.38788205239962154, 'Total loss': 0.38788205239962154}
2023-01-04 08:00:19,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:19,793 INFO:     Epoch: 27
2023-01-04 08:00:21,347 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.425067275762558, 'Total loss': 0.425067275762558} | train loss {'Reaction outcome loss': 0.37666320375802287, 'Total loss': 0.37666320375802287}
2023-01-04 08:00:21,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:21,347 INFO:     Epoch: 28
2023-01-04 08:00:22,888 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4068368931611379, 'Total loss': 0.4068368931611379} | train loss {'Reaction outcome loss': 0.37513138316168254, 'Total loss': 0.37513138316168254}
2023-01-04 08:00:22,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:22,889 INFO:     Epoch: 29
2023-01-04 08:00:24,428 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4129334976275762, 'Total loss': 0.4129334976275762} | train loss {'Reaction outcome loss': 0.37246659532565934, 'Total loss': 0.37246659532565934}
2023-01-04 08:00:24,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:24,428 INFO:     Epoch: 30
2023-01-04 08:00:25,949 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41395531098047894, 'Total loss': 0.41395531098047894} | train loss {'Reaction outcome loss': 0.3698160392551646, 'Total loss': 0.3698160392551646}
2023-01-04 08:00:25,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:25,949 INFO:     Epoch: 31
2023-01-04 08:00:27,531 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39477829734484354, 'Total loss': 0.39477829734484354} | train loss {'Reaction outcome loss': 0.3645807976434377, 'Total loss': 0.3645807976434377}
2023-01-04 08:00:27,531 INFO:     Found new best model at epoch 31
2023-01-04 08:00:27,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:27,532 INFO:     Epoch: 32
2023-01-04 08:00:29,165 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4222869396209717, 'Total loss': 0.4222869396209717} | train loss {'Reaction outcome loss': 0.3585675562923566, 'Total loss': 0.3585675562923566}
2023-01-04 08:00:29,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:29,167 INFO:     Epoch: 33
2023-01-04 08:00:30,797 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40036293417215346, 'Total loss': 0.40036293417215346} | train loss {'Reaction outcome loss': 0.3595774031987259, 'Total loss': 0.3595774031987259}
2023-01-04 08:00:30,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:30,797 INFO:     Epoch: 34
2023-01-04 08:00:32,424 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39185303648312886, 'Total loss': 0.39185303648312886} | train loss {'Reaction outcome loss': 0.35117180868714293, 'Total loss': 0.35117180868714293}
2023-01-04 08:00:32,424 INFO:     Found new best model at epoch 34
2023-01-04 08:00:32,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:32,425 INFO:     Epoch: 35
2023-01-04 08:00:34,004 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3968549301226934, 'Total loss': 0.3968549301226934} | train loss {'Reaction outcome loss': 0.3506962576820532, 'Total loss': 0.3506962576820532}
2023-01-04 08:00:34,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:34,005 INFO:     Epoch: 36
2023-01-04 08:00:35,592 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3911222020785014, 'Total loss': 0.3911222020785014} | train loss {'Reaction outcome loss': 0.34309557583250294, 'Total loss': 0.34309557583250294}
2023-01-04 08:00:35,592 INFO:     Found new best model at epoch 36
2023-01-04 08:00:35,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:35,593 INFO:     Epoch: 37
2023-01-04 08:00:37,228 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40185744166374204, 'Total loss': 0.40185744166374204} | train loss {'Reaction outcome loss': 0.3403310454332872, 'Total loss': 0.3403310454332872}
2023-01-04 08:00:37,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:37,228 INFO:     Epoch: 38
2023-01-04 08:00:38,866 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3886667708555857, 'Total loss': 0.3886667708555857} | train loss {'Reaction outcome loss': 0.3424933068319779, 'Total loss': 0.3424933068319779}
2023-01-04 08:00:38,866 INFO:     Found new best model at epoch 38
2023-01-04 08:00:38,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:38,867 INFO:     Epoch: 39
2023-01-04 08:00:40,494 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38690366546312965, 'Total loss': 0.38690366546312965} | train loss {'Reaction outcome loss': 0.33539063260228197, 'Total loss': 0.33539063260228197}
2023-01-04 08:00:40,494 INFO:     Found new best model at epoch 39
2023-01-04 08:00:40,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:40,495 INFO:     Epoch: 40
2023-01-04 08:00:42,121 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4053196956713994, 'Total loss': 0.4053196956713994} | train loss {'Reaction outcome loss': 0.33708669202207225, 'Total loss': 0.33708669202207225}
2023-01-04 08:00:42,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:42,121 INFO:     Epoch: 41
2023-01-04 08:00:43,701 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3868610918521881, 'Total loss': 0.3868610918521881} | train loss {'Reaction outcome loss': 0.32805823125886574, 'Total loss': 0.32805823125886574}
2023-01-04 08:00:43,701 INFO:     Found new best model at epoch 41
2023-01-04 08:00:43,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:43,702 INFO:     Epoch: 42
2023-01-04 08:00:45,280 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4002732346455256, 'Total loss': 0.4002732346455256} | train loss {'Reaction outcome loss': 0.3338354152731517, 'Total loss': 0.3338354152731517}
2023-01-04 08:00:45,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:45,280 INFO:     Epoch: 43
2023-01-04 08:00:46,912 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39408489167690275, 'Total loss': 0.39408489167690275} | train loss {'Reaction outcome loss': 0.3284628138430282, 'Total loss': 0.3284628138430282}
2023-01-04 08:00:46,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:46,913 INFO:     Epoch: 44
2023-01-04 08:00:48,532 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4020504782597224, 'Total loss': 0.4020504782597224} | train loss {'Reaction outcome loss': 0.32702676516147294, 'Total loss': 0.32702676516147294}
2023-01-04 08:00:48,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:48,533 INFO:     Epoch: 45
2023-01-04 08:00:50,157 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38847331355015435, 'Total loss': 0.38847331355015435} | train loss {'Reaction outcome loss': 0.323371944471602, 'Total loss': 0.323371944471602}
2023-01-04 08:00:50,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:50,157 INFO:     Epoch: 46
2023-01-04 08:00:51,774 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3859363506237666, 'Total loss': 0.3859363506237666} | train loss {'Reaction outcome loss': 0.3165237924843919, 'Total loss': 0.3165237924843919}
2023-01-04 08:00:51,774 INFO:     Found new best model at epoch 46
2023-01-04 08:00:51,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:51,775 INFO:     Epoch: 47
2023-01-04 08:00:53,381 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.399469780921936, 'Total loss': 0.399469780921936} | train loss {'Reaction outcome loss': 0.3156490949140559, 'Total loss': 0.3156490949140559}
2023-01-04 08:00:53,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:53,381 INFO:     Epoch: 48
2023-01-04 08:00:54,965 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3942001432180405, 'Total loss': 0.3942001432180405} | train loss {'Reaction outcome loss': 0.3154993545976787, 'Total loss': 0.3154993545976787}
2023-01-04 08:00:54,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:54,965 INFO:     Epoch: 49
2023-01-04 08:00:56,595 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40834647218386333, 'Total loss': 0.40834647218386333} | train loss {'Reaction outcome loss': 0.30769245536318757, 'Total loss': 0.30769245536318757}
2023-01-04 08:00:56,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:56,595 INFO:     Epoch: 50
2023-01-04 08:00:58,234 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3819606065750122, 'Total loss': 0.3819606065750122} | train loss {'Reaction outcome loss': 0.31488556463257933, 'Total loss': 0.31488556463257933}
2023-01-04 08:00:58,234 INFO:     Found new best model at epoch 50
2023-01-04 08:00:58,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:58,235 INFO:     Epoch: 51
2023-01-04 08:00:59,866 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3843079557021459, 'Total loss': 0.3843079557021459} | train loss {'Reaction outcome loss': 0.30781164219340695, 'Total loss': 0.30781164219340695}
2023-01-04 08:00:59,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:00:59,866 INFO:     Epoch: 52
2023-01-04 08:01:01,456 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3781032830476761, 'Total loss': 0.3781032830476761} | train loss {'Reaction outcome loss': 0.30808282062572695, 'Total loss': 0.30808282062572695}
2023-01-04 08:01:01,456 INFO:     Found new best model at epoch 52
2023-01-04 08:01:01,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:01,457 INFO:     Epoch: 53
2023-01-04 08:01:02,987 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38005411848425863, 'Total loss': 0.38005411848425863} | train loss {'Reaction outcome loss': 0.3057978775634662, 'Total loss': 0.3057978775634662}
2023-01-04 08:01:02,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:02,987 INFO:     Epoch: 54
2023-01-04 08:01:04,550 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3709067751963933, 'Total loss': 0.3709067751963933} | train loss {'Reaction outcome loss': 0.3030988849188447, 'Total loss': 0.3030988849188447}
2023-01-04 08:01:04,551 INFO:     Found new best model at epoch 54
2023-01-04 08:01:04,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:04,552 INFO:     Epoch: 55
2023-01-04 08:01:06,115 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.379296933611234, 'Total loss': 0.379296933611234} | train loss {'Reaction outcome loss': 0.30318570801389777, 'Total loss': 0.30318570801389777}
2023-01-04 08:01:06,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:06,116 INFO:     Epoch: 56
2023-01-04 08:01:07,675 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40814310212930044, 'Total loss': 0.40814310212930044} | train loss {'Reaction outcome loss': 0.3010867340523844, 'Total loss': 0.3010867340523844}
2023-01-04 08:01:07,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:07,675 INFO:     Epoch: 57
2023-01-04 08:01:09,240 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4233713279167811, 'Total loss': 0.4233713279167811} | train loss {'Reaction outcome loss': 0.29785242431968556, 'Total loss': 0.29785242431968556}
2023-01-04 08:01:09,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:09,240 INFO:     Epoch: 58
2023-01-04 08:01:10,777 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4178693731625875, 'Total loss': 0.4178693731625875} | train loss {'Reaction outcome loss': 0.2961017765131668, 'Total loss': 0.2961017765131668}
2023-01-04 08:01:10,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:10,778 INFO:     Epoch: 59
2023-01-04 08:01:12,308 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40670007864634194, 'Total loss': 0.40670007864634194} | train loss {'Reaction outcome loss': 0.29803758192578805, 'Total loss': 0.29803758192578805}
2023-01-04 08:01:12,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:12,308 INFO:     Epoch: 60
2023-01-04 08:01:13,864 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3753118058045705, 'Total loss': 0.3753118058045705} | train loss {'Reaction outcome loss': 0.29309496184010797, 'Total loss': 0.29309496184010797}
2023-01-04 08:01:13,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:13,865 INFO:     Epoch: 61
2023-01-04 08:01:15,426 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3863389963905017, 'Total loss': 0.3863389963905017} | train loss {'Reaction outcome loss': 0.2913554031603603, 'Total loss': 0.2913554031603603}
2023-01-04 08:01:15,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:15,426 INFO:     Epoch: 62
2023-01-04 08:01:16,987 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39269682168960574, 'Total loss': 0.39269682168960574} | train loss {'Reaction outcome loss': 0.28736239792745466, 'Total loss': 0.28736239792745466}
2023-01-04 08:01:16,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:16,987 INFO:     Epoch: 63
2023-01-04 08:01:18,560 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38485302329063414, 'Total loss': 0.38485302329063414} | train loss {'Reaction outcome loss': 0.28877586621239726, 'Total loss': 0.28877586621239726}
2023-01-04 08:01:18,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:18,560 INFO:     Epoch: 64
2023-01-04 08:01:20,108 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38544382750988004, 'Total loss': 0.38544382750988004} | train loss {'Reaction outcome loss': 0.28994168407058457, 'Total loss': 0.28994168407058457}
2023-01-04 08:01:20,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:20,108 INFO:     Epoch: 65
2023-01-04 08:01:21,646 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39367456336816153, 'Total loss': 0.39367456336816153} | train loss {'Reaction outcome loss': 0.2845580702116343, 'Total loss': 0.2845580702116343}
2023-01-04 08:01:21,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:21,646 INFO:     Epoch: 66
2023-01-04 08:01:23,220 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4002104938030243, 'Total loss': 0.4002104938030243} | train loss {'Reaction outcome loss': 0.28457573295607896, 'Total loss': 0.28457573295607896}
2023-01-04 08:01:23,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:23,221 INFO:     Epoch: 67
2023-01-04 08:01:24,790 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38548871378103894, 'Total loss': 0.38548871378103894} | train loss {'Reaction outcome loss': 0.2849133910093497, 'Total loss': 0.2849133910093497}
2023-01-04 08:01:24,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:24,791 INFO:     Epoch: 68
2023-01-04 08:01:26,370 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41699793537457785, 'Total loss': 0.41699793537457785} | train loss {'Reaction outcome loss': 0.2797087911207108, 'Total loss': 0.2797087911207108}
2023-01-04 08:01:26,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:26,370 INFO:     Epoch: 69
2023-01-04 08:01:27,934 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3953600505987803, 'Total loss': 0.3953600505987803} | train loss {'Reaction outcome loss': 0.27679068690656755, 'Total loss': 0.27679068690656755}
2023-01-04 08:01:27,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:27,935 INFO:     Epoch: 70
2023-01-04 08:01:29,493 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38131629625956215, 'Total loss': 0.38131629625956215} | train loss {'Reaction outcome loss': 0.27469203110098406, 'Total loss': 0.27469203110098406}
2023-01-04 08:01:29,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:29,493 INFO:     Epoch: 71
2023-01-04 08:01:31,038 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40209235846996305, 'Total loss': 0.40209235846996305} | train loss {'Reaction outcome loss': 0.2779815076490602, 'Total loss': 0.2779815076490602}
2023-01-04 08:01:31,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:31,039 INFO:     Epoch: 72
2023-01-04 08:01:32,633 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3803156981865565, 'Total loss': 0.3803156981865565} | train loss {'Reaction outcome loss': 0.276136201453338, 'Total loss': 0.276136201453338}
2023-01-04 08:01:32,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:32,633 INFO:     Epoch: 73
2023-01-04 08:01:34,226 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3986912737290064, 'Total loss': 0.3986912737290064} | train loss {'Reaction outcome loss': 0.270335450486048, 'Total loss': 0.270335450486048}
2023-01-04 08:01:34,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:34,227 INFO:     Epoch: 74
2023-01-04 08:01:35,825 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3755969971418381, 'Total loss': 0.3755969971418381} | train loss {'Reaction outcome loss': 0.27286058213790404, 'Total loss': 0.27286058213790404}
2023-01-04 08:01:35,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:35,827 INFO:     Epoch: 75
2023-01-04 08:01:37,377 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40603478749593097, 'Total loss': 0.40603478749593097} | train loss {'Reaction outcome loss': 0.26446341513403915, 'Total loss': 0.26446341513403915}
2023-01-04 08:01:37,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:37,378 INFO:     Epoch: 76
2023-01-04 08:01:38,956 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3648793801665306, 'Total loss': 0.3648793801665306} | train loss {'Reaction outcome loss': 0.2707816768531765, 'Total loss': 0.2707816768531765}
2023-01-04 08:01:38,956 INFO:     Found new best model at epoch 76
2023-01-04 08:01:38,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:38,957 INFO:     Epoch: 77
2023-01-04 08:01:40,526 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39222181737422945, 'Total loss': 0.39222181737422945} | train loss {'Reaction outcome loss': 0.27592307781054226, 'Total loss': 0.27592307781054226}
2023-01-04 08:01:40,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:40,526 INFO:     Epoch: 78
2023-01-04 08:01:42,101 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38958589831988016, 'Total loss': 0.38958589831988016} | train loss {'Reaction outcome loss': 0.26957743561117226, 'Total loss': 0.26957743561117226}
2023-01-04 08:01:42,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:42,102 INFO:     Epoch: 79
2023-01-04 08:01:43,676 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.373465496301651, 'Total loss': 0.373465496301651} | train loss {'Reaction outcome loss': 0.26162299806998524, 'Total loss': 0.26162299806998524}
2023-01-04 08:01:43,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:43,676 INFO:     Epoch: 80
2023-01-04 08:01:45,252 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37036302338043847, 'Total loss': 0.37036302338043847} | train loss {'Reaction outcome loss': 0.26323727687773724, 'Total loss': 0.26323727687773724}
2023-01-04 08:01:45,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:45,252 INFO:     Epoch: 81
2023-01-04 08:01:46,790 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39442108273506166, 'Total loss': 0.39442108273506166} | train loss {'Reaction outcome loss': 0.264284185164134, 'Total loss': 0.264284185164134}
2023-01-04 08:01:46,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:46,790 INFO:     Epoch: 82
2023-01-04 08:01:48,345 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39069544076919555, 'Total loss': 0.39069544076919555} | train loss {'Reaction outcome loss': 0.2607609551494087, 'Total loss': 0.2607609551494087}
2023-01-04 08:01:48,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:48,345 INFO:     Epoch: 83
2023-01-04 08:01:49,956 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36289118280013405, 'Total loss': 0.36289118280013405} | train loss {'Reaction outcome loss': 0.25896275928412105, 'Total loss': 0.25896275928412105}
2023-01-04 08:01:49,956 INFO:     Found new best model at epoch 83
2023-01-04 08:01:49,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:49,957 INFO:     Epoch: 84
2023-01-04 08:01:51,533 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39924137393633524, 'Total loss': 0.39924137393633524} | train loss {'Reaction outcome loss': 0.2614144036001677, 'Total loss': 0.2614144036001677}
2023-01-04 08:01:51,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:51,534 INFO:     Epoch: 85
2023-01-04 08:01:53,107 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40827524811029436, 'Total loss': 0.40827524811029436} | train loss {'Reaction outcome loss': 0.2599382666124549, 'Total loss': 0.2599382666124549}
2023-01-04 08:01:53,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:53,107 INFO:     Epoch: 86
2023-01-04 08:01:54,669 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3699717444678148, 'Total loss': 0.3699717444678148} | train loss {'Reaction outcome loss': 0.25684388377283457, 'Total loss': 0.25684388377283457}
2023-01-04 08:01:54,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:54,670 INFO:     Epoch: 87
2023-01-04 08:01:56,208 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3824150790770849, 'Total loss': 0.3824150790770849} | train loss {'Reaction outcome loss': 0.258655073867593, 'Total loss': 0.258655073867593}
2023-01-04 08:01:56,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:56,209 INFO:     Epoch: 88
2023-01-04 08:01:57,731 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3825969224174817, 'Total loss': 0.3825969224174817} | train loss {'Reaction outcome loss': 0.25714753546654534, 'Total loss': 0.25714753546654534}
2023-01-04 08:01:57,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:57,731 INFO:     Epoch: 89
2023-01-04 08:01:59,304 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38605531950791677, 'Total loss': 0.38605531950791677} | train loss {'Reaction outcome loss': 0.25262174674642646, 'Total loss': 0.25262174674642646}
2023-01-04 08:01:59,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:01:59,304 INFO:     Epoch: 90
2023-01-04 08:02:00,871 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3752246558666229, 'Total loss': 0.3752246558666229} | train loss {'Reaction outcome loss': 0.256482397807957, 'Total loss': 0.256482397807957}
2023-01-04 08:02:00,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:00,871 INFO:     Epoch: 91
2023-01-04 08:02:02,438 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39208482404549916, 'Total loss': 0.39208482404549916} | train loss {'Reaction outcome loss': 0.25602752297094583, 'Total loss': 0.25602752297094583}
2023-01-04 08:02:02,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:02,438 INFO:     Epoch: 92
2023-01-04 08:02:04,003 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3822700391213099, 'Total loss': 0.3822700391213099} | train loss {'Reaction outcome loss': 0.2504082267518939, 'Total loss': 0.2504082267518939}
2023-01-04 08:02:04,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:04,003 INFO:     Epoch: 93
2023-01-04 08:02:05,537 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36952799956003823, 'Total loss': 0.36952799956003823} | train loss {'Reaction outcome loss': 0.24808777913128427, 'Total loss': 0.24808777913128427}
2023-01-04 08:02:05,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:05,537 INFO:     Epoch: 94
2023-01-04 08:02:07,080 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38872153460979464, 'Total loss': 0.38872153460979464} | train loss {'Reaction outcome loss': 0.25276835203601133, 'Total loss': 0.25276835203601133}
2023-01-04 08:02:07,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:07,080 INFO:     Epoch: 95
2023-01-04 08:02:08,655 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38582901855309804, 'Total loss': 0.38582901855309804} | train loss {'Reaction outcome loss': 0.2500652395027424, 'Total loss': 0.2500652395027424}
2023-01-04 08:02:08,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:08,655 INFO:     Epoch: 96
2023-01-04 08:02:10,217 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38780019879341127, 'Total loss': 0.38780019879341127} | train loss {'Reaction outcome loss': 0.2464962348960582, 'Total loss': 0.2464962348960582}
2023-01-04 08:02:10,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:10,217 INFO:     Epoch: 97
2023-01-04 08:02:11,790 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3793869336446126, 'Total loss': 0.3793869336446126} | train loss {'Reaction outcome loss': 0.2473546499487295, 'Total loss': 0.2473546499487295}
2023-01-04 08:02:11,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:11,791 INFO:     Epoch: 98
2023-01-04 08:02:13,363 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3980581457416216, 'Total loss': 0.3980581457416216} | train loss {'Reaction outcome loss': 0.2522849827897247, 'Total loss': 0.2522849827897247}
2023-01-04 08:02:13,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:13,363 INFO:     Epoch: 99
2023-01-04 08:02:14,894 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36149006684621177, 'Total loss': 0.36149006684621177} | train loss {'Reaction outcome loss': 0.24642255709973915, 'Total loss': 0.24642255709973915}
2023-01-04 08:02:14,894 INFO:     Found new best model at epoch 99
2023-01-04 08:02:14,895 INFO:     Best model found after epoch 100 of 100.
2023-01-04 08:02:14,895 INFO:   Done with stage: TRAINING
2023-01-04 08:02:14,895 INFO:   Starting stage: EVALUATION
2023-01-04 08:02:15,017 INFO:   Done with stage: EVALUATION
2023-01-04 08:02:15,017 INFO:   Leaving out SEQ value Fold_6
2023-01-04 08:02:15,030 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 08:02:15,030 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:02:15,684 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:02:15,684 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:02:15,753 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:02:15,753 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:02:15,753 INFO:     No hyperparam tuning for this model
2023-01-04 08:02:15,754 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:02:15,754 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:02:15,754 INFO:     None feature selector for col prot
2023-01-04 08:02:15,754 INFO:     None feature selector for col prot
2023-01-04 08:02:15,755 INFO:     None feature selector for col prot
2023-01-04 08:02:15,755 INFO:     None feature selector for col chem
2023-01-04 08:02:15,755 INFO:     None feature selector for col chem
2023-01-04 08:02:15,755 INFO:     None feature selector for col chem
2023-01-04 08:02:15,755 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:02:15,755 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:02:15,756 INFO:     Number of params in model 70111
2023-01-04 08:02:15,759 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:02:15,760 INFO:   Starting stage: TRAINING
2023-01-04 08:02:15,802 INFO:     Val loss before train {'Reaction outcome loss': 1.0109145363171896, 'Total loss': 1.0109145363171896}
2023-01-04 08:02:15,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:15,802 INFO:     Epoch: 0
2023-01-04 08:02:17,375 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.70062349041303, 'Total loss': 0.70062349041303} | train loss {'Reaction outcome loss': 0.8451628920618808, 'Total loss': 0.8451628920618808}
2023-01-04 08:02:17,375 INFO:     Found new best model at epoch 0
2023-01-04 08:02:17,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:17,376 INFO:     Epoch: 1
2023-01-04 08:02:18,964 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5958001395066579, 'Total loss': 0.5958001395066579} | train loss {'Reaction outcome loss': 0.6700208290389299, 'Total loss': 0.6700208290389299}
2023-01-04 08:02:18,965 INFO:     Found new best model at epoch 1
2023-01-04 08:02:18,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:18,966 INFO:     Epoch: 2
2023-01-04 08:02:20,545 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5284199933211009, 'Total loss': 0.5284199933211009} | train loss {'Reaction outcome loss': 0.5756835556632776, 'Total loss': 0.5756835556632776}
2023-01-04 08:02:20,545 INFO:     Found new best model at epoch 2
2023-01-04 08:02:20,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:20,546 INFO:     Epoch: 3
2023-01-04 08:02:22,110 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5254816591739655, 'Total loss': 0.5254816591739655} | train loss {'Reaction outcome loss': 0.5354222202344061, 'Total loss': 0.5354222202344061}
2023-01-04 08:02:22,110 INFO:     Found new best model at epoch 3
2023-01-04 08:02:22,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:22,111 INFO:     Epoch: 4
2023-01-04 08:02:23,664 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4539269387722015, 'Total loss': 0.4539269387722015} | train loss {'Reaction outcome loss': 0.5202124740134938, 'Total loss': 0.5202124740134938}
2023-01-04 08:02:23,664 INFO:     Found new best model at epoch 4
2023-01-04 08:02:23,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:23,665 INFO:     Epoch: 5
2023-01-04 08:02:25,201 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4717412173748016, 'Total loss': 0.4717412173748016} | train loss {'Reaction outcome loss': 0.5026187721357449, 'Total loss': 0.5026187721357449}
2023-01-04 08:02:25,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:25,202 INFO:     Epoch: 6
2023-01-04 08:02:26,774 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4486346572637558, 'Total loss': 0.4486346572637558} | train loss {'Reaction outcome loss': 0.48888761665846897, 'Total loss': 0.48888761665846897}
2023-01-04 08:02:26,774 INFO:     Found new best model at epoch 6
2023-01-04 08:02:26,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:26,775 INFO:     Epoch: 7
2023-01-04 08:02:28,346 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47127748529116315, 'Total loss': 0.47127748529116315} | train loss {'Reaction outcome loss': 0.48080710937615334, 'Total loss': 0.48080710937615334}
2023-01-04 08:02:28,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:28,346 INFO:     Epoch: 8
2023-01-04 08:02:29,936 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4552536795536677, 'Total loss': 0.4552536795536677} | train loss {'Reaction outcome loss': 0.47242952070941996, 'Total loss': 0.47242952070941996}
2023-01-04 08:02:29,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:29,936 INFO:     Epoch: 9
2023-01-04 08:02:31,474 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4582663079102834, 'Total loss': 0.4582663079102834} | train loss {'Reaction outcome loss': 0.467604002421083, 'Total loss': 0.467604002421083}
2023-01-04 08:02:31,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:31,475 INFO:     Epoch: 10
2023-01-04 08:02:33,037 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44755054314931236, 'Total loss': 0.44755054314931236} | train loss {'Reaction outcome loss': 0.45980714853274696, 'Total loss': 0.45980714853274696}
2023-01-04 08:02:33,038 INFO:     Found new best model at epoch 10
2023-01-04 08:02:33,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:33,038 INFO:     Epoch: 11
2023-01-04 08:02:34,619 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4433325111865997, 'Total loss': 0.4433325111865997} | train loss {'Reaction outcome loss': 0.4559931932588777, 'Total loss': 0.4559931932588777}
2023-01-04 08:02:34,619 INFO:     Found new best model at epoch 11
2023-01-04 08:02:34,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:34,620 INFO:     Epoch: 12
2023-01-04 08:02:36,211 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.428075518210729, 'Total loss': 0.428075518210729} | train loss {'Reaction outcome loss': 0.44875876183221486, 'Total loss': 0.44875876183221486}
2023-01-04 08:02:36,212 INFO:     Found new best model at epoch 12
2023-01-04 08:02:36,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:36,212 INFO:     Epoch: 13
2023-01-04 08:02:37,733 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42740014344453814, 'Total loss': 0.42740014344453814} | train loss {'Reaction outcome loss': 0.44222176290160914, 'Total loss': 0.44222176290160914}
2023-01-04 08:02:37,733 INFO:     Found new best model at epoch 13
2023-01-04 08:02:37,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:37,734 INFO:     Epoch: 14
2023-01-04 08:02:39,262 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4296511193116506, 'Total loss': 0.4296511193116506} | train loss {'Reaction outcome loss': 0.43890152296004314, 'Total loss': 0.43890152296004314}
2023-01-04 08:02:39,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:39,262 INFO:     Epoch: 15
2023-01-04 08:02:40,769 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43941518664360046, 'Total loss': 0.43941518664360046} | train loss {'Reaction outcome loss': 0.4343095814224185, 'Total loss': 0.4343095814224185}
2023-01-04 08:02:40,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:40,769 INFO:     Epoch: 16
2023-01-04 08:02:42,334 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43266358474890393, 'Total loss': 0.43266358474890393} | train loss {'Reaction outcome loss': 0.42788883511124964, 'Total loss': 0.42788883511124964}
2023-01-04 08:02:42,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:42,334 INFO:     Epoch: 17
2023-01-04 08:02:43,888 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4397712141275406, 'Total loss': 0.4397712141275406} | train loss {'Reaction outcome loss': 0.42322627914941696, 'Total loss': 0.42322627914941696}
2023-01-04 08:02:43,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:43,888 INFO:     Epoch: 18
2023-01-04 08:02:45,471 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.420916340748469, 'Total loss': 0.420916340748469} | train loss {'Reaction outcome loss': 0.41999855277125153, 'Total loss': 0.41999855277125153}
2023-01-04 08:02:45,471 INFO:     Found new best model at epoch 18
2023-01-04 08:02:45,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:45,472 INFO:     Epoch: 19
2023-01-04 08:02:47,048 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42077096303304035, 'Total loss': 0.42077096303304035} | train loss {'Reaction outcome loss': 0.4163072382768999, 'Total loss': 0.4163072382768999}
2023-01-04 08:02:47,049 INFO:     Found new best model at epoch 19
2023-01-04 08:02:47,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:47,050 INFO:     Epoch: 20
2023-01-04 08:02:48,619 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41791139245033265, 'Total loss': 0.41791139245033265} | train loss {'Reaction outcome loss': 0.4116504774412093, 'Total loss': 0.4116504774412093}
2023-01-04 08:02:48,619 INFO:     Found new best model at epoch 20
2023-01-04 08:02:48,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:48,620 INFO:     Epoch: 21
2023-01-04 08:02:50,154 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.410107746720314, 'Total loss': 0.410107746720314} | train loss {'Reaction outcome loss': 0.4086725023248996, 'Total loss': 0.4086725023248996}
2023-01-04 08:02:50,154 INFO:     Found new best model at epoch 21
2023-01-04 08:02:50,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:50,155 INFO:     Epoch: 22
2023-01-04 08:02:51,685 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4039385149876277, 'Total loss': 0.4039385149876277} | train loss {'Reaction outcome loss': 0.40201220914237334, 'Total loss': 0.40201220914237334}
2023-01-04 08:02:51,685 INFO:     Found new best model at epoch 22
2023-01-04 08:02:51,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:51,686 INFO:     Epoch: 23
2023-01-04 08:02:53,248 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.402589072783788, 'Total loss': 0.402589072783788} | train loss {'Reaction outcome loss': 0.4015593374087492, 'Total loss': 0.4015593374087492}
2023-01-04 08:02:53,249 INFO:     Found new best model at epoch 23
2023-01-04 08:02:53,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:53,250 INFO:     Epoch: 24
2023-01-04 08:02:54,802 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4198027551174164, 'Total loss': 0.4198027551174164} | train loss {'Reaction outcome loss': 0.39235838873829654, 'Total loss': 0.39235838873829654}
2023-01-04 08:02:54,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:54,802 INFO:     Epoch: 25
2023-01-04 08:02:56,354 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40026766856511437, 'Total loss': 0.40026766856511437} | train loss {'Reaction outcome loss': 0.39017379770748023, 'Total loss': 0.39017379770748023}
2023-01-04 08:02:56,354 INFO:     Found new best model at epoch 25
2023-01-04 08:02:56,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:56,355 INFO:     Epoch: 26
2023-01-04 08:02:57,913 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39886955817540487, 'Total loss': 0.39886955817540487} | train loss {'Reaction outcome loss': 0.38617502335822107, 'Total loss': 0.38617502335822107}
2023-01-04 08:02:57,914 INFO:     Found new best model at epoch 26
2023-01-04 08:02:57,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:57,914 INFO:     Epoch: 27
2023-01-04 08:02:59,449 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4168344686428706, 'Total loss': 0.4168344686428706} | train loss {'Reaction outcome loss': 0.3857169839341718, 'Total loss': 0.3857169839341718}
2023-01-04 08:02:59,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:02:59,449 INFO:     Epoch: 28
2023-01-04 08:03:00,997 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3858429342508316, 'Total loss': 0.3858429342508316} | train loss {'Reaction outcome loss': 0.3822515112774897, 'Total loss': 0.3822515112774897}
2023-01-04 08:03:00,997 INFO:     Found new best model at epoch 28
2023-01-04 08:03:00,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:00,998 INFO:     Epoch: 29
2023-01-04 08:03:02,572 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38779943784077964, 'Total loss': 0.38779943784077964} | train loss {'Reaction outcome loss': 0.37665652292730145, 'Total loss': 0.37665652292730145}
2023-01-04 08:03:02,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:02,572 INFO:     Epoch: 30
2023-01-04 08:03:04,138 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3994453211625417, 'Total loss': 0.3994453211625417} | train loss {'Reaction outcome loss': 0.3751313687177772, 'Total loss': 0.3751313687177772}
2023-01-04 08:03:04,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:04,138 INFO:     Epoch: 31
2023-01-04 08:03:05,721 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3883464445670446, 'Total loss': 0.3883464445670446} | train loss {'Reaction outcome loss': 0.3730139631226605, 'Total loss': 0.3730139631226605}
2023-01-04 08:03:05,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:05,722 INFO:     Epoch: 32
2023-01-04 08:03:07,358 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.381552055478096, 'Total loss': 0.381552055478096} | train loss {'Reaction outcome loss': 0.37078197047598527, 'Total loss': 0.37078197047598527}
2023-01-04 08:03:07,358 INFO:     Found new best model at epoch 32
2023-01-04 08:03:07,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:07,359 INFO:     Epoch: 33
2023-01-04 08:03:08,952 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39857004086176556, 'Total loss': 0.39857004086176556} | train loss {'Reaction outcome loss': 0.36432579339949234, 'Total loss': 0.36432579339949234}
2023-01-04 08:03:08,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:08,952 INFO:     Epoch: 34
2023-01-04 08:03:10,545 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40188238620758054, 'Total loss': 0.40188238620758054} | train loss {'Reaction outcome loss': 0.3588690788414504, 'Total loss': 0.3588690788414504}
2023-01-04 08:03:10,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:10,545 INFO:     Epoch: 35
2023-01-04 08:03:12,172 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39128092924753827, 'Total loss': 0.39128092924753827} | train loss {'Reaction outcome loss': 0.3546383209418949, 'Total loss': 0.3546383209418949}
2023-01-04 08:03:12,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:12,172 INFO:     Epoch: 36
2023-01-04 08:03:13,812 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3889369656642278, 'Total loss': 0.3889369656642278} | train loss {'Reaction outcome loss': 0.3549568518619675, 'Total loss': 0.3549568518619675}
2023-01-04 08:03:13,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:13,812 INFO:     Epoch: 37
2023-01-04 08:03:15,448 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4016972482204437, 'Total loss': 0.4016972482204437} | train loss {'Reaction outcome loss': 0.35605856380845663, 'Total loss': 0.35605856380845663}
2023-01-04 08:03:15,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:15,448 INFO:     Epoch: 38
2023-01-04 08:03:17,054 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4042112638552984, 'Total loss': 0.4042112638552984} | train loss {'Reaction outcome loss': 0.34974828921930884, 'Total loss': 0.34974828921930884}
2023-01-04 08:03:17,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:17,054 INFO:     Epoch: 39
2023-01-04 08:03:18,685 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3901882986227671, 'Total loss': 0.3901882986227671} | train loss {'Reaction outcome loss': 0.34602379546053574, 'Total loss': 0.34602379546053574}
2023-01-04 08:03:18,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:18,686 INFO:     Epoch: 40
2023-01-04 08:03:20,269 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38766963382562003, 'Total loss': 0.38766963382562003} | train loss {'Reaction outcome loss': 0.3432671238638003, 'Total loss': 0.3432671238638003}
2023-01-04 08:03:20,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:20,270 INFO:     Epoch: 41
2023-01-04 08:03:21,840 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42246519128481547, 'Total loss': 0.42246519128481547} | train loss {'Reaction outcome loss': 0.34204659586779046, 'Total loss': 0.34204659586779046}
2023-01-04 08:03:21,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:21,840 INFO:     Epoch: 42
2023-01-04 08:03:23,386 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3976656347513199, 'Total loss': 0.3976656347513199} | train loss {'Reaction outcome loss': 0.339444961170212, 'Total loss': 0.339444961170212}
2023-01-04 08:03:23,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:23,386 INFO:     Epoch: 43
2023-01-04 08:03:24,946 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3777856489022573, 'Total loss': 0.3777856489022573} | train loss {'Reaction outcome loss': 0.3361050070730788, 'Total loss': 0.3361050070730788}
2023-01-04 08:03:24,946 INFO:     Found new best model at epoch 43
2023-01-04 08:03:24,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:24,947 INFO:     Epoch: 44
2023-01-04 08:03:26,473 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3822481334209442, 'Total loss': 0.3822481334209442} | train loss {'Reaction outcome loss': 0.33525367094614017, 'Total loss': 0.33525367094614017}
2023-01-04 08:03:26,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:26,474 INFO:     Epoch: 45
2023-01-04 08:03:28,035 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3736221154530843, 'Total loss': 0.3736221154530843} | train loss {'Reaction outcome loss': 0.332072872789543, 'Total loss': 0.332072872789543}
2023-01-04 08:03:28,035 INFO:     Found new best model at epoch 45
2023-01-04 08:03:28,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:28,036 INFO:     Epoch: 46
2023-01-04 08:03:29,612 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3834769537051519, 'Total loss': 0.3834769537051519} | train loss {'Reaction outcome loss': 0.33081705717618715, 'Total loss': 0.33081705717618715}
2023-01-04 08:03:29,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:29,612 INFO:     Epoch: 47
2023-01-04 08:03:31,181 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.397868608434995, 'Total loss': 0.397868608434995} | train loss {'Reaction outcome loss': 0.3317903704161248, 'Total loss': 0.3317903704161248}
2023-01-04 08:03:31,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:31,181 INFO:     Epoch: 48
2023-01-04 08:03:32,729 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3920809805393219, 'Total loss': 0.3920809805393219} | train loss {'Reaction outcome loss': 0.3228110074459, 'Total loss': 0.3228110074459}
2023-01-04 08:03:32,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:32,729 INFO:     Epoch: 49
2023-01-04 08:03:34,277 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36639511287212373, 'Total loss': 0.36639511287212373} | train loss {'Reaction outcome loss': 0.3246489747121446, 'Total loss': 0.3246489747121446}
2023-01-04 08:03:34,277 INFO:     Found new best model at epoch 49
2023-01-04 08:03:34,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:34,278 INFO:     Epoch: 50
2023-01-04 08:03:35,797 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37384946743647257, 'Total loss': 0.37384946743647257} | train loss {'Reaction outcome loss': 0.3192676920914478, 'Total loss': 0.3192676920914478}
2023-01-04 08:03:35,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:35,797 INFO:     Epoch: 51
2023-01-04 08:03:37,355 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3816696465015411, 'Total loss': 0.3816696465015411} | train loss {'Reaction outcome loss': 0.3213977134830254, 'Total loss': 0.3213977134830254}
2023-01-04 08:03:37,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:37,356 INFO:     Epoch: 52
2023-01-04 08:03:38,930 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3712479084730148, 'Total loss': 0.3712479084730148} | train loss {'Reaction outcome loss': 0.3195895477053491, 'Total loss': 0.3195895477053491}
2023-01-04 08:03:38,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:38,930 INFO:     Epoch: 53
2023-01-04 08:03:40,482 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3889681398868561, 'Total loss': 0.3889681398868561} | train loss {'Reaction outcome loss': 0.31435232527473345, 'Total loss': 0.31435232527473345}
2023-01-04 08:03:40,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:40,482 INFO:     Epoch: 54
2023-01-04 08:03:42,049 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37017161548137667, 'Total loss': 0.37017161548137667} | train loss {'Reaction outcome loss': 0.31345000454234734, 'Total loss': 0.31345000454234734}
2023-01-04 08:03:42,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:42,049 INFO:     Epoch: 55
2023-01-04 08:03:43,607 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35524637003739673, 'Total loss': 0.35524637003739673} | train loss {'Reaction outcome loss': 0.30862958854340045, 'Total loss': 0.30862958854340045}
2023-01-04 08:03:43,607 INFO:     Found new best model at epoch 55
2023-01-04 08:03:43,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:43,608 INFO:     Epoch: 56
2023-01-04 08:03:45,140 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38127299547195437, 'Total loss': 0.38127299547195437} | train loss {'Reaction outcome loss': 0.3044214057416692, 'Total loss': 0.3044214057416692}
2023-01-04 08:03:45,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:45,140 INFO:     Epoch: 57
2023-01-04 08:03:46,674 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38739010294278464, 'Total loss': 0.38739010294278464} | train loss {'Reaction outcome loss': 0.3094777326613987, 'Total loss': 0.3094777326613987}
2023-01-04 08:03:46,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:46,674 INFO:     Epoch: 58
2023-01-04 08:03:48,252 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3672241727511088, 'Total loss': 0.3672241727511088} | train loss {'Reaction outcome loss': 0.30774993312272786, 'Total loss': 0.30774993312272786}
2023-01-04 08:03:48,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:48,252 INFO:     Epoch: 59
2023-01-04 08:03:49,813 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.363189305861791, 'Total loss': 0.363189305861791} | train loss {'Reaction outcome loss': 0.3049617825002016, 'Total loss': 0.3049617825002016}
2023-01-04 08:03:49,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:49,813 INFO:     Epoch: 60
2023-01-04 08:03:51,364 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3727179268995921, 'Total loss': 0.3727179268995921} | train loss {'Reaction outcome loss': 0.2998478535818279, 'Total loss': 0.2998478535818279}
2023-01-04 08:03:51,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:51,364 INFO:     Epoch: 61
2023-01-04 08:03:52,919 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38837607006231945, 'Total loss': 0.38837607006231945} | train loss {'Reaction outcome loss': 0.304252589410608, 'Total loss': 0.304252589410608}
2023-01-04 08:03:52,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:52,920 INFO:     Epoch: 62
2023-01-04 08:03:54,489 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37012197176615397, 'Total loss': 0.37012197176615397} | train loss {'Reaction outcome loss': 0.2939836930228054, 'Total loss': 0.2939836930228054}
2023-01-04 08:03:54,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:54,489 INFO:     Epoch: 63
2023-01-04 08:03:56,030 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3681565622488658, 'Total loss': 0.3681565622488658} | train loss {'Reaction outcome loss': 0.29303219120962953, 'Total loss': 0.29303219120962953}
2023-01-04 08:03:56,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:56,031 INFO:     Epoch: 64
2023-01-04 08:03:57,631 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36139632066090904, 'Total loss': 0.36139632066090904} | train loss {'Reaction outcome loss': 0.2963553962939913, 'Total loss': 0.2963553962939913}
2023-01-04 08:03:57,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:57,631 INFO:     Epoch: 65
2023-01-04 08:03:59,221 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3506620739897092, 'Total loss': 0.3506620739897092} | train loss {'Reaction outcome loss': 0.2926690937809996, 'Total loss': 0.2926690937809996}
2023-01-04 08:03:59,221 INFO:     Found new best model at epoch 65
2023-01-04 08:03:59,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:03:59,222 INFO:     Epoch: 66
2023-01-04 08:04:00,802 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3634615550438563, 'Total loss': 0.3634615550438563} | train loss {'Reaction outcome loss': 0.29243753398583683, 'Total loss': 0.29243753398583683}
2023-01-04 08:04:00,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:00,802 INFO:     Epoch: 67
2023-01-04 08:04:02,414 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3671307325363159, 'Total loss': 0.3671307325363159} | train loss {'Reaction outcome loss': 0.2890201812670549, 'Total loss': 0.2890201812670549}
2023-01-04 08:04:02,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:02,415 INFO:     Epoch: 68
2023-01-04 08:04:03,988 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39997575879096986, 'Total loss': 0.39997575879096986} | train loss {'Reaction outcome loss': 0.2891045851962446, 'Total loss': 0.2891045851962446}
2023-01-04 08:04:03,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:03,988 INFO:     Epoch: 69
2023-01-04 08:04:05,543 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39067463874816893, 'Total loss': 0.39067463874816893} | train loss {'Reaction outcome loss': 0.2837008414016734, 'Total loss': 0.2837008414016734}
2023-01-04 08:04:05,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:05,543 INFO:     Epoch: 70
2023-01-04 08:04:07,103 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37088195284207665, 'Total loss': 0.37088195284207665} | train loss {'Reaction outcome loss': 0.28206135933741333, 'Total loss': 0.28206135933741333}
2023-01-04 08:04:07,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:07,103 INFO:     Epoch: 71
2023-01-04 08:04:08,682 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36654503146807355, 'Total loss': 0.36654503146807355} | train loss {'Reaction outcome loss': 0.28570991700737053, 'Total loss': 0.28570991700737053}
2023-01-04 08:04:08,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:08,682 INFO:     Epoch: 72
2023-01-04 08:04:10,248 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39227298895517987, 'Total loss': 0.39227298895517987} | train loss {'Reaction outcome loss': 0.27867622302327344, 'Total loss': 0.27867622302327344}
2023-01-04 08:04:10,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:10,248 INFO:     Epoch: 73
2023-01-04 08:04:11,771 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3866590996583303, 'Total loss': 0.3866590996583303} | train loss {'Reaction outcome loss': 0.27847838050783325, 'Total loss': 0.27847838050783325}
2023-01-04 08:04:11,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:11,772 INFO:     Epoch: 74
2023-01-04 08:04:13,342 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3571096986532211, 'Total loss': 0.3571096986532211} | train loss {'Reaction outcome loss': 0.2763141899332673, 'Total loss': 0.2763141899332673}
2023-01-04 08:04:13,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:13,342 INFO:     Epoch: 75
2023-01-04 08:04:14,867 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3691663751999537, 'Total loss': 0.3691663751999537} | train loss {'Reaction outcome loss': 0.2720990867928908, 'Total loss': 0.2720990867928908}
2023-01-04 08:04:14,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:14,868 INFO:     Epoch: 76
2023-01-04 08:04:16,440 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36790330906709034, 'Total loss': 0.36790330906709034} | train loss {'Reaction outcome loss': 0.27756544572405434, 'Total loss': 0.27756544572405434}
2023-01-04 08:04:16,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:16,441 INFO:     Epoch: 77
2023-01-04 08:04:17,994 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38012016415596006, 'Total loss': 0.38012016415596006} | train loss {'Reaction outcome loss': 0.2753411630161833, 'Total loss': 0.2753411630161833}
2023-01-04 08:04:17,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:17,994 INFO:     Epoch: 78
2023-01-04 08:04:19,576 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3750368187824885, 'Total loss': 0.3750368187824885} | train loss {'Reaction outcome loss': 0.27899910727455296, 'Total loss': 0.27899910727455296}
2023-01-04 08:04:19,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:19,576 INFO:     Epoch: 79
2023-01-04 08:04:21,102 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37553373773892723, 'Total loss': 0.37553373773892723} | train loss {'Reaction outcome loss': 0.2731113868230947, 'Total loss': 0.2731113868230947}
2023-01-04 08:04:21,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:21,102 INFO:     Epoch: 80
2023-01-04 08:04:22,652 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3938721795876821, 'Total loss': 0.3938721795876821} | train loss {'Reaction outcome loss': 0.27186397745505997, 'Total loss': 0.27186397745505997}
2023-01-04 08:04:22,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:22,653 INFO:     Epoch: 81
2023-01-04 08:04:24,227 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.408055849870046, 'Total loss': 0.408055849870046} | train loss {'Reaction outcome loss': 0.2733827085378798, 'Total loss': 0.2733827085378798}
2023-01-04 08:04:24,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:24,227 INFO:     Epoch: 82
2023-01-04 08:04:25,791 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36318287551403045, 'Total loss': 0.36318287551403045} | train loss {'Reaction outcome loss': 0.2679318985515123, 'Total loss': 0.2679318985515123}
2023-01-04 08:04:25,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:25,791 INFO:     Epoch: 83
2023-01-04 08:04:27,376 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35971762041250865, 'Total loss': 0.35971762041250865} | train loss {'Reaction outcome loss': 0.2711819761335204, 'Total loss': 0.2711819761335204}
2023-01-04 08:04:27,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:27,377 INFO:     Epoch: 84
2023-01-04 08:04:28,942 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3800842632850011, 'Total loss': 0.3800842632850011} | train loss {'Reaction outcome loss': 0.2627127517001293, 'Total loss': 0.2627127517001293}
2023-01-04 08:04:28,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:28,943 INFO:     Epoch: 85
2023-01-04 08:04:30,477 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39769879579544065, 'Total loss': 0.39769879579544065} | train loss {'Reaction outcome loss': 0.2599085625731773, 'Total loss': 0.2599085625731773}
2023-01-04 08:04:30,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:30,478 INFO:     Epoch: 86
2023-01-04 08:04:32,026 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40497796833515165, 'Total loss': 0.40497796833515165} | train loss {'Reaction outcome loss': 0.2638639119127597, 'Total loss': 0.2638639119127597}
2023-01-04 08:04:32,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:32,026 INFO:     Epoch: 87
2023-01-04 08:04:33,608 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38499272167682647, 'Total loss': 0.38499272167682647} | train loss {'Reaction outcome loss': 0.26387047625082927, 'Total loss': 0.26387047625082927}
2023-01-04 08:04:33,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:33,608 INFO:     Epoch: 88
2023-01-04 08:04:35,173 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38035557270050047, 'Total loss': 0.38035557270050047} | train loss {'Reaction outcome loss': 0.2647918354087788, 'Total loss': 0.2647918354087788}
2023-01-04 08:04:35,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:35,174 INFO:     Epoch: 89
2023-01-04 08:04:36,761 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36155495047569275, 'Total loss': 0.36155495047569275} | train loss {'Reaction outcome loss': 0.26301101030317886, 'Total loss': 0.26301101030317886}
2023-01-04 08:04:36,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:36,761 INFO:     Epoch: 90
2023-01-04 08:04:38,330 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37486263513565066, 'Total loss': 0.37486263513565066} | train loss {'Reaction outcome loss': 0.2607637380488513, 'Total loss': 0.2607637380488513}
2023-01-04 08:04:38,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:38,330 INFO:     Epoch: 91
2023-01-04 08:04:39,861 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3819518804550171, 'Total loss': 0.3819518804550171} | train loss {'Reaction outcome loss': 0.2605450043205965, 'Total loss': 0.2605450043205965}
2023-01-04 08:04:39,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:39,861 INFO:     Epoch: 92
2023-01-04 08:04:41,400 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35362373292446136, 'Total loss': 0.35362373292446136} | train loss {'Reaction outcome loss': 0.2570825731549883, 'Total loss': 0.2570825731549883}
2023-01-04 08:04:41,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:41,400 INFO:     Epoch: 93
2023-01-04 08:04:42,959 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36967456539471943, 'Total loss': 0.36967456539471943} | train loss {'Reaction outcome loss': 0.2581047300881427, 'Total loss': 0.2581047300881427}
2023-01-04 08:04:42,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:42,960 INFO:     Epoch: 94
2023-01-04 08:04:44,528 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3645841141541799, 'Total loss': 0.3645841141541799} | train loss {'Reaction outcome loss': 0.2576822363889174, 'Total loss': 0.2576822363889174}
2023-01-04 08:04:44,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:44,528 INFO:     Epoch: 95
2023-01-04 08:04:46,096 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3531610975662867, 'Total loss': 0.3531610975662867} | train loss {'Reaction outcome loss': 0.25829398373834495, 'Total loss': 0.25829398373834495}
2023-01-04 08:04:46,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:46,096 INFO:     Epoch: 96
2023-01-04 08:04:47,668 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36348529358704884, 'Total loss': 0.36348529358704884} | train loss {'Reaction outcome loss': 0.2528787606701739, 'Total loss': 0.2528787606701739}
2023-01-04 08:04:47,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:47,669 INFO:     Epoch: 97
2023-01-04 08:04:49,206 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36679595708847046, 'Total loss': 0.36679595708847046} | train loss {'Reaction outcome loss': 0.252632459840781, 'Total loss': 0.252632459840781}
2023-01-04 08:04:49,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:49,206 INFO:     Epoch: 98
2023-01-04 08:04:50,727 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3899834285179774, 'Total loss': 0.3899834285179774} | train loss {'Reaction outcome loss': 0.2513745388668367, 'Total loss': 0.2513745388668367}
2023-01-04 08:04:50,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:50,727 INFO:     Epoch: 99
2023-01-04 08:04:52,298 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36702209810415903, 'Total loss': 0.36702209810415903} | train loss {'Reaction outcome loss': 0.25016145525157235, 'Total loss': 0.25016145525157235}
2023-01-04 08:04:52,298 INFO:     Best model found after epoch 66 of 100.
2023-01-04 08:04:52,298 INFO:   Done with stage: TRAINING
2023-01-04 08:04:52,298 INFO:   Starting stage: EVALUATION
2023-01-04 08:04:52,421 INFO:   Done with stage: EVALUATION
2023-01-04 08:04:52,421 INFO:   Leaving out SEQ value Fold_7
2023-01-04 08:04:52,433 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 08:04:52,434 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:04:53,079 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:04:53,080 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:04:53,147 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:04:53,147 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:04:53,147 INFO:     No hyperparam tuning for this model
2023-01-04 08:04:53,147 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:04:53,147 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:04:53,148 INFO:     None feature selector for col prot
2023-01-04 08:04:53,148 INFO:     None feature selector for col prot
2023-01-04 08:04:53,148 INFO:     None feature selector for col prot
2023-01-04 08:04:53,149 INFO:     None feature selector for col chem
2023-01-04 08:04:53,149 INFO:     None feature selector for col chem
2023-01-04 08:04:53,149 INFO:     None feature selector for col chem
2023-01-04 08:04:53,149 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:04:53,149 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:04:53,151 INFO:     Number of params in model 70111
2023-01-04 08:04:53,154 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:04:53,154 INFO:   Starting stage: TRAINING
2023-01-04 08:04:53,196 INFO:     Val loss before train {'Reaction outcome loss': 1.107362937927246, 'Total loss': 1.107362937927246}
2023-01-04 08:04:53,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:53,197 INFO:     Epoch: 0
2023-01-04 08:04:54,776 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7664491931597391, 'Total loss': 0.7664491931597391} | train loss {'Reaction outcome loss': 0.8433943657211331, 'Total loss': 0.8433943657211331}
2023-01-04 08:04:54,776 INFO:     Found new best model at epoch 0
2023-01-04 08:04:54,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:54,777 INFO:     Epoch: 1
2023-01-04 08:04:56,330 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6479499340057373, 'Total loss': 0.6479499340057373} | train loss {'Reaction outcome loss': 0.6782208589407114, 'Total loss': 0.6782208589407114}
2023-01-04 08:04:56,330 INFO:     Found new best model at epoch 1
2023-01-04 08:04:56,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:56,330 INFO:     Epoch: 2
2023-01-04 08:04:57,861 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5647157371044159, 'Total loss': 0.5647157371044159} | train loss {'Reaction outcome loss': 0.5842120009355056, 'Total loss': 0.5842120009355056}
2023-01-04 08:04:57,861 INFO:     Found new best model at epoch 2
2023-01-04 08:04:57,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:57,862 INFO:     Epoch: 3
2023-01-04 08:04:59,380 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5932311654090882, 'Total loss': 0.5932311654090882} | train loss {'Reaction outcome loss': 0.5355775012965605, 'Total loss': 0.5355775012965605}
2023-01-04 08:04:59,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:04:59,380 INFO:     Epoch: 4
2023-01-04 08:05:00,941 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5287510752677917, 'Total loss': 0.5287510752677917} | train loss {'Reaction outcome loss': 0.5146314379496452, 'Total loss': 0.5146314379496452}
2023-01-04 08:05:00,942 INFO:     Found new best model at epoch 4
2023-01-04 08:05:00,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:00,943 INFO:     Epoch: 5
2023-01-04 08:05:02,493 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5323492785294851, 'Total loss': 0.5323492785294851} | train loss {'Reaction outcome loss': 0.4949579580240088, 'Total loss': 0.4949579580240088}
2023-01-04 08:05:02,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:02,493 INFO:     Epoch: 6
2023-01-04 08:05:04,052 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48963516354560854, 'Total loss': 0.48963516354560854} | train loss {'Reaction outcome loss': 0.4868220772334944, 'Total loss': 0.4868220772334944}
2023-01-04 08:05:04,052 INFO:     Found new best model at epoch 6
2023-01-04 08:05:04,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:04,053 INFO:     Epoch: 7
2023-01-04 08:05:05,597 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.510830944776535, 'Total loss': 0.510830944776535} | train loss {'Reaction outcome loss': 0.47418050200511247, 'Total loss': 0.47418050200511247}
2023-01-04 08:05:05,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:05,598 INFO:     Epoch: 8
2023-01-04 08:05:07,111 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4961428562800089, 'Total loss': 0.4961428562800089} | train loss {'Reaction outcome loss': 0.4671014285349584, 'Total loss': 0.4671014285349584}
2023-01-04 08:05:07,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:07,112 INFO:     Epoch: 9
2023-01-04 08:05:08,624 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5044192711512248, 'Total loss': 0.5044192711512248} | train loss {'Reaction outcome loss': 0.46542193426754014, 'Total loss': 0.46542193426754014}
2023-01-04 08:05:08,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:08,624 INFO:     Epoch: 10
2023-01-04 08:05:10,183 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5057212869326274, 'Total loss': 0.5057212869326274} | train loss {'Reaction outcome loss': 0.4543372947490696, 'Total loss': 0.4543372947490696}
2023-01-04 08:05:10,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:10,183 INFO:     Epoch: 11
2023-01-04 08:05:11,743 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.560324756304423, 'Total loss': 0.560324756304423} | train loss {'Reaction outcome loss': 0.451645172504715, 'Total loss': 0.451645172504715}
2023-01-04 08:05:11,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:11,743 INFO:     Epoch: 12
2023-01-04 08:05:13,285 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49578483899434406, 'Total loss': 0.49578483899434406} | train loss {'Reaction outcome loss': 0.44625292006102235, 'Total loss': 0.44625292006102235}
2023-01-04 08:05:13,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:13,285 INFO:     Epoch: 13
2023-01-04 08:05:14,825 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4781166613101959, 'Total loss': 0.4781166613101959} | train loss {'Reaction outcome loss': 0.4417097454433476, 'Total loss': 0.4417097454433476}
2023-01-04 08:05:14,825 INFO:     Found new best model at epoch 13
2023-01-04 08:05:14,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:14,826 INFO:     Epoch: 14
2023-01-04 08:05:16,379 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49501577615737913, 'Total loss': 0.49501577615737913} | train loss {'Reaction outcome loss': 0.4331125497490495, 'Total loss': 0.4331125497490495}
2023-01-04 08:05:16,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:16,379 INFO:     Epoch: 15
2023-01-04 08:05:17,899 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49128024379412333, 'Total loss': 0.49128024379412333} | train loss {'Reaction outcome loss': 0.43270737172919754, 'Total loss': 0.43270737172919754}
2023-01-04 08:05:17,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:17,899 INFO:     Epoch: 16
2023-01-04 08:05:19,452 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4909431020418803, 'Total loss': 0.4909431020418803} | train loss {'Reaction outcome loss': 0.4243202326826124, 'Total loss': 0.4243202326826124}
2023-01-04 08:05:19,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:19,453 INFO:     Epoch: 17
2023-01-04 08:05:21,017 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4739238063494364, 'Total loss': 0.4739238063494364} | train loss {'Reaction outcome loss': 0.42463833197350903, 'Total loss': 0.42463833197350903}
2023-01-04 08:05:21,017 INFO:     Found new best model at epoch 17
2023-01-04 08:05:21,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:21,018 INFO:     Epoch: 18
2023-01-04 08:05:22,560 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5086697816848755, 'Total loss': 0.5086697816848755} | train loss {'Reaction outcome loss': 0.4157863294794446, 'Total loss': 0.4157863294794446}
2023-01-04 08:05:22,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:22,560 INFO:     Epoch: 19
2023-01-04 08:05:24,067 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49491557081540427, 'Total loss': 0.49491557081540427} | train loss {'Reaction outcome loss': 0.41412715945433787, 'Total loss': 0.41412715945433787}
2023-01-04 08:05:24,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:24,068 INFO:     Epoch: 20
2023-01-04 08:05:25,602 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47398521105448405, 'Total loss': 0.47398521105448405} | train loss {'Reaction outcome loss': 0.4070212720951318, 'Total loss': 0.4070212720951318}
2023-01-04 08:05:25,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:25,602 INFO:     Epoch: 21
2023-01-04 08:05:27,099 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46616854667663576, 'Total loss': 0.46616854667663576} | train loss {'Reaction outcome loss': 0.40752293229539754, 'Total loss': 0.40752293229539754}
2023-01-04 08:05:27,099 INFO:     Found new best model at epoch 21
2023-01-04 08:05:27,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:27,100 INFO:     Epoch: 22
2023-01-04 08:05:28,625 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5135743896166484, 'Total loss': 0.5135743896166484} | train loss {'Reaction outcome loss': 0.40067416211187623, 'Total loss': 0.40067416211187623}
2023-01-04 08:05:28,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:28,625 INFO:     Epoch: 23
2023-01-04 08:05:30,159 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48676744500796, 'Total loss': 0.48676744500796} | train loss {'Reaction outcome loss': 0.39760691227712036, 'Total loss': 0.39760691227712036}
2023-01-04 08:05:30,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:30,159 INFO:     Epoch: 24
2023-01-04 08:05:31,705 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4688893958926201, 'Total loss': 0.4688893958926201} | train loss {'Reaction outcome loss': 0.39603470500572263, 'Total loss': 0.39603470500572263}
2023-01-04 08:05:31,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:31,705 INFO:     Epoch: 25
2023-01-04 08:05:33,199 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48194716970125834, 'Total loss': 0.48194716970125834} | train loss {'Reaction outcome loss': 0.39158366740623235, 'Total loss': 0.39158366740623235}
2023-01-04 08:05:33,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:33,199 INFO:     Epoch: 26
2023-01-04 08:05:34,739 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47771912018458046, 'Total loss': 0.47771912018458046} | train loss {'Reaction outcome loss': 0.38614443722334535, 'Total loss': 0.38614443722334535}
2023-01-04 08:05:34,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:34,739 INFO:     Epoch: 27
2023-01-04 08:05:36,264 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45349060992399853, 'Total loss': 0.45349060992399853} | train loss {'Reaction outcome loss': 0.38402214640881116, 'Total loss': 0.38402214640881116}
2023-01-04 08:05:36,265 INFO:     Found new best model at epoch 27
2023-01-04 08:05:36,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:36,266 INFO:     Epoch: 28
2023-01-04 08:05:37,799 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4547823240359624, 'Total loss': 0.4547823240359624} | train loss {'Reaction outcome loss': 0.3835450622079137, 'Total loss': 0.3835450622079137}
2023-01-04 08:05:37,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:37,800 INFO:     Epoch: 29
2023-01-04 08:05:39,329 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48505959113438923, 'Total loss': 0.48505959113438923} | train loss {'Reaction outcome loss': 0.37709358642935314, 'Total loss': 0.37709358642935314}
2023-01-04 08:05:39,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:39,329 INFO:     Epoch: 30
2023-01-04 08:05:40,875 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47235161463419595, 'Total loss': 0.47235161463419595} | train loss {'Reaction outcome loss': 0.37501235871197103, 'Total loss': 0.37501235871197103}
2023-01-04 08:05:40,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:40,875 INFO:     Epoch: 31
2023-01-04 08:05:42,375 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4665662944316864, 'Total loss': 0.4665662944316864} | train loss {'Reaction outcome loss': 0.37420997487538027, 'Total loss': 0.37420997487538027}
2023-01-04 08:05:42,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:42,376 INFO:     Epoch: 32
2023-01-04 08:05:43,901 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4683019697666168, 'Total loss': 0.4683019697666168} | train loss {'Reaction outcome loss': 0.3675740301479405, 'Total loss': 0.3675740301479405}
2023-01-04 08:05:43,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:43,901 INFO:     Epoch: 33
2023-01-04 08:05:45,433 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47216908435026805, 'Total loss': 0.47216908435026805} | train loss {'Reaction outcome loss': 0.3663739465149768, 'Total loss': 0.3663739465149768}
2023-01-04 08:05:45,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:45,433 INFO:     Epoch: 34
2023-01-04 08:05:46,957 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4605527659257253, 'Total loss': 0.4605527659257253} | train loss {'Reaction outcome loss': 0.3586494287018811, 'Total loss': 0.3586494287018811}
2023-01-04 08:05:46,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:46,957 INFO:     Epoch: 35
2023-01-04 08:05:48,490 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46810871561368306, 'Total loss': 0.46810871561368306} | train loss {'Reaction outcome loss': 0.35757749776045483, 'Total loss': 0.35757749776045483}
2023-01-04 08:05:48,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:48,491 INFO:     Epoch: 36
2023-01-04 08:05:50,040 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4743202110131582, 'Total loss': 0.4743202110131582} | train loss {'Reaction outcome loss': 0.3601499155655012, 'Total loss': 0.3601499155655012}
2023-01-04 08:05:50,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:50,041 INFO:     Epoch: 37
2023-01-04 08:05:51,537 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4701440398891767, 'Total loss': 0.4701440398891767} | train loss {'Reaction outcome loss': 0.3531099646983348, 'Total loss': 0.3531099646983348}
2023-01-04 08:05:51,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:51,537 INFO:     Epoch: 38
2023-01-04 08:05:53,058 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4587236354748408, 'Total loss': 0.4587236354748408} | train loss {'Reaction outcome loss': 0.34673367323347065, 'Total loss': 0.34673367323347065}
2023-01-04 08:05:53,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:53,059 INFO:     Epoch: 39
2023-01-04 08:05:54,602 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45755523641904194, 'Total loss': 0.45755523641904194} | train loss {'Reaction outcome loss': 0.34478398306029184, 'Total loss': 0.34478398306029184}
2023-01-04 08:05:54,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:54,603 INFO:     Epoch: 40
2023-01-04 08:05:56,159 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4621524175008138, 'Total loss': 0.4621524175008138} | train loss {'Reaction outcome loss': 0.3410606603428121, 'Total loss': 0.3410606603428121}
2023-01-04 08:05:56,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:56,159 INFO:     Epoch: 41
2023-01-04 08:05:57,705 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4702709933121999, 'Total loss': 0.4702709933121999} | train loss {'Reaction outcome loss': 0.33968762584003337, 'Total loss': 0.33968762584003337}
2023-01-04 08:05:57,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:57,705 INFO:     Epoch: 42
2023-01-04 08:05:59,250 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45704826911290486, 'Total loss': 0.45704826911290486} | train loss {'Reaction outcome loss': 0.3370476381464319, 'Total loss': 0.3370476381464319}
2023-01-04 08:05:59,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:05:59,250 INFO:     Epoch: 43
2023-01-04 08:06:00,780 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46438283324241636, 'Total loss': 0.46438283324241636} | train loss {'Reaction outcome loss': 0.3370016779163818, 'Total loss': 0.3370016779163818}
2023-01-04 08:06:00,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:00,780 INFO:     Epoch: 44
2023-01-04 08:06:02,269 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4428745994965235, 'Total loss': 0.4428745994965235} | train loss {'Reaction outcome loss': 0.3304992126294108, 'Total loss': 0.3304992126294108}
2023-01-04 08:06:02,269 INFO:     Found new best model at epoch 44
2023-01-04 08:06:02,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:02,270 INFO:     Epoch: 45
2023-01-04 08:06:03,288 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4668857157230377, 'Total loss': 0.4668857157230377} | train loss {'Reaction outcome loss': 0.3300164007469193, 'Total loss': 0.3300164007469193}
2023-01-04 08:06:03,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:03,288 INFO:     Epoch: 46
2023-01-04 08:06:04,303 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5001691440741222, 'Total loss': 0.5001691440741222} | train loss {'Reaction outcome loss': 0.3261744004329701, 'Total loss': 0.3261744004329701}
2023-01-04 08:06:04,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:04,303 INFO:     Epoch: 47
2023-01-04 08:06:05,323 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.464300262928009, 'Total loss': 0.464300262928009} | train loss {'Reaction outcome loss': 0.33009350310751806, 'Total loss': 0.33009350310751806}
2023-01-04 08:06:05,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:05,323 INFO:     Epoch: 48
2023-01-04 08:06:06,336 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.440396918853124, 'Total loss': 0.440396918853124} | train loss {'Reaction outcome loss': 0.3223076261197909, 'Total loss': 0.3223076261197909}
2023-01-04 08:06:06,336 INFO:     Found new best model at epoch 48
2023-01-04 08:06:06,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:06,336 INFO:     Epoch: 49
2023-01-04 08:06:07,598 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47626165151596067, 'Total loss': 0.47626165151596067} | train loss {'Reaction outcome loss': 0.32455642911649885, 'Total loss': 0.32455642911649885}
2023-01-04 08:06:07,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:07,599 INFO:     Epoch: 50
2023-01-04 08:06:09,143 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44279833833376564, 'Total loss': 0.44279833833376564} | train loss {'Reaction outcome loss': 0.3206087276885361, 'Total loss': 0.3206087276885361}
2023-01-04 08:06:09,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:09,143 INFO:     Epoch: 51
2023-01-04 08:06:10,699 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4499234398206075, 'Total loss': 0.4499234398206075} | train loss {'Reaction outcome loss': 0.31703626677639535, 'Total loss': 0.31703626677639535}
2023-01-04 08:06:10,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:10,700 INFO:     Epoch: 52
2023-01-04 08:06:12,254 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4757031718889872, 'Total loss': 0.4757031718889872} | train loss {'Reaction outcome loss': 0.31140257781132674, 'Total loss': 0.31140257781132674}
2023-01-04 08:06:12,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:12,255 INFO:     Epoch: 53
2023-01-04 08:06:13,810 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4641610165437063, 'Total loss': 0.4641610165437063} | train loss {'Reaction outcome loss': 0.3135312864413628, 'Total loss': 0.3135312864413628}
2023-01-04 08:06:13,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:13,810 INFO:     Epoch: 54
2023-01-04 08:06:15,368 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45249676903088887, 'Total loss': 0.45249676903088887} | train loss {'Reaction outcome loss': 0.30832680677756286, 'Total loss': 0.30832680677756286}
2023-01-04 08:06:15,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:15,369 INFO:     Epoch: 55
2023-01-04 08:06:16,810 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47244468530019124, 'Total loss': 0.47244468530019124} | train loss {'Reaction outcome loss': 0.30823707853481447, 'Total loss': 0.30823707853481447}
2023-01-04 08:06:16,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:16,811 INFO:     Epoch: 56
2023-01-04 08:06:18,363 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4594974706570307, 'Total loss': 0.4594974706570307} | train loss {'Reaction outcome loss': 0.31121888478378673, 'Total loss': 0.31121888478378673}
2023-01-04 08:06:18,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:18,364 INFO:     Epoch: 57
2023-01-04 08:06:19,923 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44130252798398334, 'Total loss': 0.44130252798398334} | train loss {'Reaction outcome loss': 0.30450473925023724, 'Total loss': 0.30450473925023724}
2023-01-04 08:06:19,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:19,923 INFO:     Epoch: 58
2023-01-04 08:06:21,479 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.467270290851593, 'Total loss': 0.467270290851593} | train loss {'Reaction outcome loss': 0.3039781532553963, 'Total loss': 0.3039781532553963}
2023-01-04 08:06:21,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:21,479 INFO:     Epoch: 59
2023-01-04 08:06:23,035 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4411613335212072, 'Total loss': 0.4411613335212072} | train loss {'Reaction outcome loss': 0.303129337646149, 'Total loss': 0.303129337646149}
2023-01-04 08:06:23,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:23,035 INFO:     Epoch: 60
2023-01-04 08:06:24,584 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4309532900651296, 'Total loss': 0.4309532900651296} | train loss {'Reaction outcome loss': 0.3008255213771984, 'Total loss': 0.3008255213771984}
2023-01-04 08:06:24,584 INFO:     Found new best model at epoch 60
2023-01-04 08:06:24,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:24,585 INFO:     Epoch: 61
2023-01-04 08:06:26,010 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41415822406609853, 'Total loss': 0.41415822406609853} | train loss {'Reaction outcome loss': 0.29635988925020773, 'Total loss': 0.29635988925020773}
2023-01-04 08:06:26,010 INFO:     Found new best model at epoch 61
2023-01-04 08:06:26,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:26,011 INFO:     Epoch: 62
2023-01-04 08:06:27,543 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4511589070161184, 'Total loss': 0.4511589070161184} | train loss {'Reaction outcome loss': 0.2983947018700423, 'Total loss': 0.2983947018700423}
2023-01-04 08:06:27,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:27,543 INFO:     Epoch: 63
2023-01-04 08:06:29,082 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44555711845556895, 'Total loss': 0.44555711845556895} | train loss {'Reaction outcome loss': 0.2958760622875158, 'Total loss': 0.2958760622875158}
2023-01-04 08:06:29,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:29,083 INFO:     Epoch: 64
2023-01-04 08:06:30,647 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4575820545355479, 'Total loss': 0.4575820545355479} | train loss {'Reaction outcome loss': 0.2948026410935126, 'Total loss': 0.2948026410935126}
2023-01-04 08:06:30,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:30,648 INFO:     Epoch: 65
2023-01-04 08:06:32,206 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4343996286392212, 'Total loss': 0.4343996286392212} | train loss {'Reaction outcome loss': 0.29449140296860055, 'Total loss': 0.29449140296860055}
2023-01-04 08:06:32,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:32,206 INFO:     Epoch: 66
2023-01-04 08:06:33,761 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45077120264371234, 'Total loss': 0.45077120264371234} | train loss {'Reaction outcome loss': 0.2954868278687909, 'Total loss': 0.2954868278687909}
2023-01-04 08:06:33,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:33,761 INFO:     Epoch: 67
2023-01-04 08:06:35,194 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42991449534893034, 'Total loss': 0.42991449534893034} | train loss {'Reaction outcome loss': 0.2926548140553328, 'Total loss': 0.2926548140553328}
2023-01-04 08:06:35,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:35,194 INFO:     Epoch: 68
2023-01-04 08:06:36,735 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44366302688916526, 'Total loss': 0.44366302688916526} | train loss {'Reaction outcome loss': 0.289861145964909, 'Total loss': 0.289861145964909}
2023-01-04 08:06:36,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:36,735 INFO:     Epoch: 69
2023-01-04 08:06:38,290 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4305394728978475, 'Total loss': 0.4305394728978475} | train loss {'Reaction outcome loss': 0.2888519505223075, 'Total loss': 0.2888519505223075}
2023-01-04 08:06:38,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:38,290 INFO:     Epoch: 70
2023-01-04 08:06:39,860 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44403486847877505, 'Total loss': 0.44403486847877505} | train loss {'Reaction outcome loss': 0.28587383528550464, 'Total loss': 0.28587383528550464}
2023-01-04 08:06:39,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:39,860 INFO:     Epoch: 71
2023-01-04 08:06:41,419 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4309988300005595, 'Total loss': 0.4309988300005595} | train loss {'Reaction outcome loss': 0.2823790342106924, 'Total loss': 0.2823790342106924}
2023-01-04 08:06:41,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:41,419 INFO:     Epoch: 72
2023-01-04 08:06:42,980 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42835055192311605, 'Total loss': 0.42835055192311605} | train loss {'Reaction outcome loss': 0.2841929505978312, 'Total loss': 0.2841929505978312}
2023-01-04 08:06:42,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:42,980 INFO:     Epoch: 73
2023-01-04 08:06:44,446 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42612666885058087, 'Total loss': 0.42612666885058087} | train loss {'Reaction outcome loss': 0.2834013298617833, 'Total loss': 0.2834013298617833}
2023-01-04 08:06:44,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:44,446 INFO:     Epoch: 74
2023-01-04 08:06:46,001 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4099352866411209, 'Total loss': 0.4099352866411209} | train loss {'Reaction outcome loss': 0.2799836761785514, 'Total loss': 0.2799836761785514}
2023-01-04 08:06:46,002 INFO:     Found new best model at epoch 74
2023-01-04 08:06:46,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:46,003 INFO:     Epoch: 75
2023-01-04 08:06:47,552 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43095785280068716, 'Total loss': 0.43095785280068716} | train loss {'Reaction outcome loss': 0.27891700316370627, 'Total loss': 0.27891700316370627}
2023-01-04 08:06:47,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:47,553 INFO:     Epoch: 76
2023-01-04 08:06:49,104 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.446427458524704, 'Total loss': 0.446427458524704} | train loss {'Reaction outcome loss': 0.279061744364845, 'Total loss': 0.279061744364845}
2023-01-04 08:06:49,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:49,105 INFO:     Epoch: 77
2023-01-04 08:06:50,635 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45769565403461454, 'Total loss': 0.45769565403461454} | train loss {'Reaction outcome loss': 0.2775143320252607, 'Total loss': 0.2775143320252607}
2023-01-04 08:06:50,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:50,636 INFO:     Epoch: 78
2023-01-04 08:06:52,174 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41734083692232765, 'Total loss': 0.41734083692232765} | train loss {'Reaction outcome loss': 0.2785790067015987, 'Total loss': 0.2785790067015987}
2023-01-04 08:06:52,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:52,175 INFO:     Epoch: 79
2023-01-04 08:06:53,653 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45600131452083587, 'Total loss': 0.45600131452083587} | train loss {'Reaction outcome loss': 0.2765955447932303, 'Total loss': 0.2765955447932303}
2023-01-04 08:06:53,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:53,655 INFO:     Epoch: 80
2023-01-04 08:06:55,201 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.435777606566747, 'Total loss': 0.435777606566747} | train loss {'Reaction outcome loss': 0.28079624419465604, 'Total loss': 0.28079624419465604}
2023-01-04 08:06:55,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:55,201 INFO:     Epoch: 81
2023-01-04 08:06:56,759 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4283183544874191, 'Total loss': 0.4283183544874191} | train loss {'Reaction outcome loss': 0.27431482491475756, 'Total loss': 0.27431482491475756}
2023-01-04 08:06:56,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:56,759 INFO:     Epoch: 82
2023-01-04 08:06:58,306 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4211321145296097, 'Total loss': 0.4211321145296097} | train loss {'Reaction outcome loss': 0.2753069814253639, 'Total loss': 0.2753069814253639}
2023-01-04 08:06:58,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:58,306 INFO:     Epoch: 83
2023-01-04 08:06:59,847 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4385204198459784, 'Total loss': 0.4385204198459784} | train loss {'Reaction outcome loss': 0.2740063999025595, 'Total loss': 0.2740063999025595}
2023-01-04 08:06:59,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:06:59,847 INFO:     Epoch: 84
2023-01-04 08:07:01,360 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4581967492898305, 'Total loss': 0.4581967492898305} | train loss {'Reaction outcome loss': 0.2700067911392603, 'Total loss': 0.2700067911392603}
2023-01-04 08:07:01,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:01,361 INFO:     Epoch: 85
2023-01-04 08:07:02,875 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.415554024775823, 'Total loss': 0.415554024775823} | train loss {'Reaction outcome loss': 0.2664957563546333, 'Total loss': 0.2664957563546333}
2023-01-04 08:07:02,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:02,875 INFO:     Epoch: 86
2023-01-04 08:07:04,421 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4294882928331693, 'Total loss': 0.4294882928331693} | train loss {'Reaction outcome loss': 0.2687324105110361, 'Total loss': 0.2687324105110361}
2023-01-04 08:07:04,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:04,422 INFO:     Epoch: 87
2023-01-04 08:07:05,982 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4509856939315796, 'Total loss': 0.4509856939315796} | train loss {'Reaction outcome loss': 0.2661705130213128, 'Total loss': 0.2661705130213128}
2023-01-04 08:07:05,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:05,983 INFO:     Epoch: 88
2023-01-04 08:07:07,537 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4454734265804291, 'Total loss': 0.4454734265804291} | train loss {'Reaction outcome loss': 0.2637929144032272, 'Total loss': 0.2637929144032272}
2023-01-04 08:07:07,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:07,537 INFO:     Epoch: 89
2023-01-04 08:07:09,082 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43892515301704405, 'Total loss': 0.43892515301704405} | train loss {'Reaction outcome loss': 0.26616870199804343, 'Total loss': 0.26616870199804343}
2023-01-04 08:07:09,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:09,082 INFO:     Epoch: 90
2023-01-04 08:07:10,549 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40658876796563465, 'Total loss': 0.40658876796563465} | train loss {'Reaction outcome loss': 0.2716005661767044, 'Total loss': 0.2716005661767044}
2023-01-04 08:07:10,549 INFO:     Found new best model at epoch 90
2023-01-04 08:07:10,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:10,550 INFO:     Epoch: 91
2023-01-04 08:07:12,117 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43927324215571084, 'Total loss': 0.43927324215571084} | train loss {'Reaction outcome loss': 0.26190858891049584, 'Total loss': 0.26190858891049584}
2023-01-04 08:07:12,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:12,117 INFO:     Epoch: 92
2023-01-04 08:07:13,693 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45104647278785703, 'Total loss': 0.45104647278785703} | train loss {'Reaction outcome loss': 0.2635568687385255, 'Total loss': 0.2635568687385255}
2023-01-04 08:07:13,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:13,694 INFO:     Epoch: 93
2023-01-04 08:07:15,283 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4898915449778239, 'Total loss': 0.4898915449778239} | train loss {'Reaction outcome loss': 0.26521191050063125, 'Total loss': 0.26521191050063125}
2023-01-04 08:07:15,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:15,283 INFO:     Epoch: 94
2023-01-04 08:07:16,862 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42481516400973, 'Total loss': 0.42481516400973} | train loss {'Reaction outcome loss': 0.2639408630110842, 'Total loss': 0.2639408630110842}
2023-01-04 08:07:16,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:16,862 INFO:     Epoch: 95
2023-01-04 08:07:18,453 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3983552157878876, 'Total loss': 0.3983552157878876} | train loss {'Reaction outcome loss': 0.25934138823123204, 'Total loss': 0.25934138823123204}
2023-01-04 08:07:18,454 INFO:     Found new best model at epoch 95
2023-01-04 08:07:18,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:18,455 INFO:     Epoch: 96
2023-01-04 08:07:19,941 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46437093416849773, 'Total loss': 0.46437093416849773} | train loss {'Reaction outcome loss': 0.25661071578224937, 'Total loss': 0.25661071578224937}
2023-01-04 08:07:19,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:19,941 INFO:     Epoch: 97
2023-01-04 08:07:21,529 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4382580737272898, 'Total loss': 0.4382580737272898} | train loss {'Reaction outcome loss': 0.259930571548013, 'Total loss': 0.259930571548013}
2023-01-04 08:07:21,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:21,529 INFO:     Epoch: 98
2023-01-04 08:07:23,103 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4320496867100398, 'Total loss': 0.4320496867100398} | train loss {'Reaction outcome loss': 0.26296730762545445, 'Total loss': 0.26296730762545445}
2023-01-04 08:07:23,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:23,103 INFO:     Epoch: 99
2023-01-04 08:07:24,682 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4203723867734273, 'Total loss': 0.4203723867734273} | train loss {'Reaction outcome loss': 0.25323557004932956, 'Total loss': 0.25323557004932956}
2023-01-04 08:07:24,683 INFO:     Best model found after epoch 96 of 100.
2023-01-04 08:07:24,683 INFO:   Done with stage: TRAINING
2023-01-04 08:07:24,683 INFO:   Starting stage: EVALUATION
2023-01-04 08:07:24,824 INFO:   Done with stage: EVALUATION
2023-01-04 08:07:24,824 INFO:   Leaving out SEQ value Fold_8
2023-01-04 08:07:24,836 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 08:07:24,836 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:07:25,477 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:07:25,477 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:07:25,544 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:07:25,545 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:07:25,545 INFO:     No hyperparam tuning for this model
2023-01-04 08:07:25,545 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:07:25,545 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:07:25,545 INFO:     None feature selector for col prot
2023-01-04 08:07:25,546 INFO:     None feature selector for col prot
2023-01-04 08:07:25,546 INFO:     None feature selector for col prot
2023-01-04 08:07:25,546 INFO:     None feature selector for col chem
2023-01-04 08:07:25,546 INFO:     None feature selector for col chem
2023-01-04 08:07:25,546 INFO:     None feature selector for col chem
2023-01-04 08:07:25,546 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:07:25,546 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:07:25,547 INFO:     Number of params in model 70111
2023-01-04 08:07:25,551 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:07:25,551 INFO:   Starting stage: TRAINING
2023-01-04 08:07:25,594 INFO:     Val loss before train {'Reaction outcome loss': 0.93623392979304, 'Total loss': 0.93623392979304}
2023-01-04 08:07:25,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:25,594 INFO:     Epoch: 0
2023-01-04 08:07:27,176 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7035051584243774, 'Total loss': 0.7035051584243774} | train loss {'Reaction outcome loss': 0.837962426353192, 'Total loss': 0.837962426353192}
2023-01-04 08:07:27,176 INFO:     Found new best model at epoch 0
2023-01-04 08:07:27,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:27,177 INFO:     Epoch: 1
2023-01-04 08:07:28,632 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5578632831573487, 'Total loss': 0.5578632831573487} | train loss {'Reaction outcome loss': 0.6780873673657576, 'Total loss': 0.6780873673657576}
2023-01-04 08:07:28,633 INFO:     Found new best model at epoch 1
2023-01-04 08:07:28,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:28,633 INFO:     Epoch: 2
2023-01-04 08:07:30,173 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5551673591136932, 'Total loss': 0.5551673591136932} | train loss {'Reaction outcome loss': 0.5821180057482443, 'Total loss': 0.5821180057482443}
2023-01-04 08:07:30,173 INFO:     Found new best model at epoch 2
2023-01-04 08:07:30,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:30,174 INFO:     Epoch: 3
2023-01-04 08:07:31,727 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.515026773015658, 'Total loss': 0.515026773015658} | train loss {'Reaction outcome loss': 0.5446648393096267, 'Total loss': 0.5446648393096267}
2023-01-04 08:07:31,727 INFO:     Found new best model at epoch 3
2023-01-04 08:07:31,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:31,728 INFO:     Epoch: 4
2023-01-04 08:07:33,289 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.50689790447553, 'Total loss': 0.50689790447553} | train loss {'Reaction outcome loss': 0.5255251264442569, 'Total loss': 0.5255251264442569}
2023-01-04 08:07:33,289 INFO:     Found new best model at epoch 4
2023-01-04 08:07:33,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:33,290 INFO:     Epoch: 5
2023-01-04 08:07:34,852 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.515769116083781, 'Total loss': 0.515769116083781} | train loss {'Reaction outcome loss': 0.5050988205965015, 'Total loss': 0.5050988205965015}
2023-01-04 08:07:34,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:34,852 INFO:     Epoch: 6
2023-01-04 08:07:36,400 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4895630458990733, 'Total loss': 0.4895630458990733} | train loss {'Reaction outcome loss': 0.4941688162421021, 'Total loss': 0.4941688162421021}
2023-01-04 08:07:36,400 INFO:     Found new best model at epoch 6
2023-01-04 08:07:36,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:36,401 INFO:     Epoch: 7
2023-01-04 08:07:37,845 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48188085754712423, 'Total loss': 0.48188085754712423} | train loss {'Reaction outcome loss': 0.4840881458582336, 'Total loss': 0.4840881458582336}
2023-01-04 08:07:37,846 INFO:     Found new best model at epoch 7
2023-01-04 08:07:37,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:37,847 INFO:     Epoch: 8
2023-01-04 08:07:39,399 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48145428895950315, 'Total loss': 0.48145428895950315} | train loss {'Reaction outcome loss': 0.47465360133224194, 'Total loss': 0.47465360133224194}
2023-01-04 08:07:39,399 INFO:     Found new best model at epoch 8
2023-01-04 08:07:39,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:39,400 INFO:     Epoch: 9
2023-01-04 08:07:40,943 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4937075893084208, 'Total loss': 0.4937075893084208} | train loss {'Reaction outcome loss': 0.4745266268542711, 'Total loss': 0.4745266268542711}
2023-01-04 08:07:40,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:40,944 INFO:     Epoch: 10
2023-01-04 08:07:42,487 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4600844254096349, 'Total loss': 0.4600844254096349} | train loss {'Reaction outcome loss': 0.486319143972967, 'Total loss': 0.486319143972967}
2023-01-04 08:07:42,487 INFO:     Found new best model at epoch 10
2023-01-04 08:07:42,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:42,488 INFO:     Epoch: 11
2023-01-04 08:07:44,060 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48042127887407937, 'Total loss': 0.48042127887407937} | train loss {'Reaction outcome loss': 0.46673393292197335, 'Total loss': 0.46673393292197335}
2023-01-04 08:07:44,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:44,060 INFO:     Epoch: 12
2023-01-04 08:07:45,619 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49475815494855246, 'Total loss': 0.49475815494855246} | train loss {'Reaction outcome loss': 0.45596196311184345, 'Total loss': 0.45596196311184345}
2023-01-04 08:07:45,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:45,619 INFO:     Epoch: 13
2023-01-04 08:07:47,061 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4868190805117289, 'Total loss': 0.4868190805117289} | train loss {'Reaction outcome loss': 0.45415184538865433, 'Total loss': 0.45415184538865433}
2023-01-04 08:07:47,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:47,061 INFO:     Epoch: 14
2023-01-04 08:07:48,608 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4712382117907206, 'Total loss': 0.4712382117907206} | train loss {'Reaction outcome loss': 0.47118807010069164, 'Total loss': 0.47118807010069164}
2023-01-04 08:07:48,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:48,610 INFO:     Epoch: 15
2023-01-04 08:07:50,157 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46648964087168376, 'Total loss': 0.46648964087168376} | train loss {'Reaction outcome loss': 0.44060631130106637, 'Total loss': 0.44060631130106637}
2023-01-04 08:07:50,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:50,157 INFO:     Epoch: 16
2023-01-04 08:07:51,702 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4588822782039642, 'Total loss': 0.4588822782039642} | train loss {'Reaction outcome loss': 0.438003727140418, 'Total loss': 0.438003727140418}
2023-01-04 08:07:51,702 INFO:     Found new best model at epoch 16
2023-01-04 08:07:51,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:51,703 INFO:     Epoch: 17
2023-01-04 08:07:53,254 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4672160565853119, 'Total loss': 0.4672160565853119} | train loss {'Reaction outcome loss': 0.4343686093562755, 'Total loss': 0.4343686093562755}
2023-01-04 08:07:53,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:53,254 INFO:     Epoch: 18
2023-01-04 08:07:54,815 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4362374265988668, 'Total loss': 0.4362374265988668} | train loss {'Reaction outcome loss': 0.43144572342651477, 'Total loss': 0.43144572342651477}
2023-01-04 08:07:54,815 INFO:     Found new best model at epoch 18
2023-01-04 08:07:54,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:54,816 INFO:     Epoch: 19
2023-01-04 08:07:56,284 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4578798900047938, 'Total loss': 0.4578798900047938} | train loss {'Reaction outcome loss': 0.425648695235883, 'Total loss': 0.425648695235883}
2023-01-04 08:07:56,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:56,284 INFO:     Epoch: 20
2023-01-04 08:07:57,847 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4462865382432938, 'Total loss': 0.4462865382432938} | train loss {'Reaction outcome loss': 0.4372144096085559, 'Total loss': 0.4372144096085559}
2023-01-04 08:07:57,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:57,847 INFO:     Epoch: 21
2023-01-04 08:07:59,422 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4580199678738912, 'Total loss': 0.4580199678738912} | train loss {'Reaction outcome loss': 0.4391535991596976, 'Total loss': 0.4391535991596976}
2023-01-04 08:07:59,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:07:59,422 INFO:     Epoch: 22
2023-01-04 08:08:00,981 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44070864220460254, 'Total loss': 0.44070864220460254} | train loss {'Reaction outcome loss': 0.4125187873732353, 'Total loss': 0.4125187873732353}
2023-01-04 08:08:00,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:00,981 INFO:     Epoch: 23
2023-01-04 08:08:02,528 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43592362602551776, 'Total loss': 0.43592362602551776} | train loss {'Reaction outcome loss': 0.4153921020257732, 'Total loss': 0.4153921020257732}
2023-01-04 08:08:02,528 INFO:     Found new best model at epoch 23
2023-01-04 08:08:02,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:02,529 INFO:     Epoch: 24
2023-01-04 08:08:04,083 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43245321412881216, 'Total loss': 0.43245321412881216} | train loss {'Reaction outcome loss': 0.4170938369310191, 'Total loss': 0.4170938369310191}
2023-01-04 08:08:04,083 INFO:     Found new best model at epoch 24
2023-01-04 08:08:04,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:04,084 INFO:     Epoch: 25
2023-01-04 08:08:05,538 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4296232283115387, 'Total loss': 0.4296232283115387} | train loss {'Reaction outcome loss': 0.41126002884213475, 'Total loss': 0.41126002884213475}
2023-01-04 08:08:05,538 INFO:     Found new best model at epoch 25
2023-01-04 08:08:05,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:05,539 INFO:     Epoch: 26
2023-01-04 08:08:07,104 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41930943727493286, 'Total loss': 0.41930943727493286} | train loss {'Reaction outcome loss': 0.4187183384378643, 'Total loss': 0.4187183384378643}
2023-01-04 08:08:07,105 INFO:     Found new best model at epoch 26
2023-01-04 08:08:07,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:07,106 INFO:     Epoch: 27
2023-01-04 08:08:08,673 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4181334912776947, 'Total loss': 0.4181334912776947} | train loss {'Reaction outcome loss': 0.39797505370064545, 'Total loss': 0.39797505370064545}
2023-01-04 08:08:08,673 INFO:     Found new best model at epoch 27
2023-01-04 08:08:08,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:08,674 INFO:     Epoch: 28
2023-01-04 08:08:10,231 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4258529047171275, 'Total loss': 0.4258529047171275} | train loss {'Reaction outcome loss': 0.3880095675324454, 'Total loss': 0.3880095675324454}
2023-01-04 08:08:10,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:10,231 INFO:     Epoch: 29
2023-01-04 08:08:11,802 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.420247350136439, 'Total loss': 0.420247350136439} | train loss {'Reaction outcome loss': 0.39137974855712737, 'Total loss': 0.39137974855712737}
2023-01-04 08:08:11,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:11,802 INFO:     Epoch: 30
2023-01-04 08:08:13,372 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42102943460146586, 'Total loss': 0.42102943460146586} | train loss {'Reaction outcome loss': 0.387053854859677, 'Total loss': 0.387053854859677}
2023-01-04 08:08:13,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:13,373 INFO:     Epoch: 31
2023-01-04 08:08:14,849 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42403637369473773, 'Total loss': 0.42403637369473773} | train loss {'Reaction outcome loss': 0.38342858942063607, 'Total loss': 0.38342858942063607}
2023-01-04 08:08:14,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:14,849 INFO:     Epoch: 32
2023-01-04 08:08:16,408 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42670029203097026, 'Total loss': 0.42670029203097026} | train loss {'Reaction outcome loss': 0.38516225235914625, 'Total loss': 0.38516225235914625}
2023-01-04 08:08:16,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:16,408 INFO:     Epoch: 33
2023-01-04 08:08:17,960 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4217867344617844, 'Total loss': 0.4217867344617844} | train loss {'Reaction outcome loss': 0.38267657326429366, 'Total loss': 0.38267657326429366}
2023-01-04 08:08:17,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:17,961 INFO:     Epoch: 34
2023-01-04 08:08:19,508 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4250734895467758, 'Total loss': 0.4250734895467758} | train loss {'Reaction outcome loss': 0.3771370467932328, 'Total loss': 0.3771370467932328}
2023-01-04 08:08:19,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:19,509 INFO:     Epoch: 35
2023-01-04 08:08:21,061 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4309641460577647, 'Total loss': 0.4309641460577647} | train loss {'Reaction outcome loss': 0.38307415965971525, 'Total loss': 0.38307415965971525}
2023-01-04 08:08:21,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:21,061 INFO:     Epoch: 36
2023-01-04 08:08:22,617 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41053460141023, 'Total loss': 0.41053460141023} | train loss {'Reaction outcome loss': 0.37540162589562975, 'Total loss': 0.37540162589562975}
2023-01-04 08:08:22,617 INFO:     Found new best model at epoch 36
2023-01-04 08:08:22,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:22,618 INFO:     Epoch: 37
2023-01-04 08:08:24,101 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41299884716669716, 'Total loss': 0.41299884716669716} | train loss {'Reaction outcome loss': 0.39435836435228155, 'Total loss': 0.39435836435228155}
2023-01-04 08:08:24,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:24,101 INFO:     Epoch: 38
2023-01-04 08:08:25,662 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4074326554934184, 'Total loss': 0.4074326554934184} | train loss {'Reaction outcome loss': 0.3920005403249862, 'Total loss': 0.3920005403249862}
2023-01-04 08:08:25,663 INFO:     Found new best model at epoch 38
2023-01-04 08:08:25,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:25,664 INFO:     Epoch: 39
2023-01-04 08:08:27,213 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3967662443717321, 'Total loss': 0.3967662443717321} | train loss {'Reaction outcome loss': 0.36118158992220467, 'Total loss': 0.36118158992220467}
2023-01-04 08:08:27,214 INFO:     Found new best model at epoch 39
2023-01-04 08:08:27,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:27,214 INFO:     Epoch: 40
2023-01-04 08:08:28,778 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4001175860563914, 'Total loss': 0.4001175860563914} | train loss {'Reaction outcome loss': 0.3616442806964767, 'Total loss': 0.3616442806964767}
2023-01-04 08:08:28,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:28,779 INFO:     Epoch: 41
2023-01-04 08:08:30,335 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41469026207923887, 'Total loss': 0.41469026207923887} | train loss {'Reaction outcome loss': 0.3648107835577558, 'Total loss': 0.3648107835577558}
2023-01-04 08:08:30,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:30,335 INFO:     Epoch: 42
2023-01-04 08:08:31,863 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.398306675752004, 'Total loss': 0.398306675752004} | train loss {'Reaction outcome loss': 0.35482132310647535, 'Total loss': 0.35482132310647535}
2023-01-04 08:08:31,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:31,864 INFO:     Epoch: 43
2023-01-04 08:08:33,357 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38918908437093097, 'Total loss': 0.38918908437093097} | train loss {'Reaction outcome loss': 0.35111214919690636, 'Total loss': 0.35111214919690636}
2023-01-04 08:08:33,357 INFO:     Found new best model at epoch 43
2023-01-04 08:08:33,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:33,358 INFO:     Epoch: 44
2023-01-04 08:08:34,941 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4179137994845708, 'Total loss': 0.4179137994845708} | train loss {'Reaction outcome loss': 0.3476180436310655, 'Total loss': 0.3476180436310655}
2023-01-04 08:08:34,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:34,941 INFO:     Epoch: 45
2023-01-04 08:08:36,505 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40508330464363096, 'Total loss': 0.40508330464363096} | train loss {'Reaction outcome loss': 0.3474093811583125, 'Total loss': 0.3474093811583125}
2023-01-04 08:08:36,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:36,506 INFO:     Epoch: 46
2023-01-04 08:08:38,060 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41305604080359143, 'Total loss': 0.41305604080359143} | train loss {'Reaction outcome loss': 0.34990173562065413, 'Total loss': 0.34990173562065413}
2023-01-04 08:08:38,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:38,061 INFO:     Epoch: 47
2023-01-04 08:08:39,611 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3934755484263102, 'Total loss': 0.3934755484263102} | train loss {'Reaction outcome loss': 0.35913148137489403, 'Total loss': 0.35913148137489403}
2023-01-04 08:08:39,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:39,611 INFO:     Epoch: 48
2023-01-04 08:08:41,113 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41574832995732625, 'Total loss': 0.41574832995732625} | train loss {'Reaction outcome loss': 0.3427605809292931, 'Total loss': 0.3427605809292931}
2023-01-04 08:08:41,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:41,114 INFO:     Epoch: 49
2023-01-04 08:08:42,647 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39829098880290986, 'Total loss': 0.39829098880290986} | train loss {'Reaction outcome loss': 0.362620057283915, 'Total loss': 0.362620057283915}
2023-01-04 08:08:42,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:42,648 INFO:     Epoch: 50
2023-01-04 08:08:44,214 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39508983691533406, 'Total loss': 0.39508983691533406} | train loss {'Reaction outcome loss': 0.3392537837591616, 'Total loss': 0.3392537837591616}
2023-01-04 08:08:44,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:44,214 INFO:     Epoch: 51
2023-01-04 08:08:45,772 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3837406724691391, 'Total loss': 0.3837406724691391} | train loss {'Reaction outcome loss': 0.32981324983436777, 'Total loss': 0.32981324983436777}
2023-01-04 08:08:45,772 INFO:     Found new best model at epoch 51
2023-01-04 08:08:45,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:45,773 INFO:     Epoch: 52
2023-01-04 08:08:47,334 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4047549843788147, 'Total loss': 0.4047549843788147} | train loss {'Reaction outcome loss': 0.34048430740401364, 'Total loss': 0.34048430740401364}
2023-01-04 08:08:47,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:47,334 INFO:     Epoch: 53
2023-01-04 08:08:48,913 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40405110716819764, 'Total loss': 0.40405110716819764} | train loss {'Reaction outcome loss': 0.3774633392365987, 'Total loss': 0.3774633392365987}
2023-01-04 08:08:48,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:48,913 INFO:     Epoch: 54
2023-01-04 08:08:50,419 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41684105098247526, 'Total loss': 0.41684105098247526} | train loss {'Reaction outcome loss': 0.33437856675152655, 'Total loss': 0.33437856675152655}
2023-01-04 08:08:50,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:50,420 INFO:     Epoch: 55
2023-01-04 08:08:51,983 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3922664533058802, 'Total loss': 0.3922664533058802} | train loss {'Reaction outcome loss': 0.3301114446282778, 'Total loss': 0.3301114446282778}
2023-01-04 08:08:51,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:51,983 INFO:     Epoch: 56
2023-01-04 08:08:53,541 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4101794928312302, 'Total loss': 0.4101794928312302} | train loss {'Reaction outcome loss': 0.323474182355879, 'Total loss': 0.323474182355879}
2023-01-04 08:08:53,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:53,541 INFO:     Epoch: 57
2023-01-04 08:08:55,125 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3971053272485733, 'Total loss': 0.3971053272485733} | train loss {'Reaction outcome loss': 0.3247129218738258, 'Total loss': 0.3247129218738258}
2023-01-04 08:08:55,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:55,125 INFO:     Epoch: 58
2023-01-04 08:08:56,689 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40110849936803183, 'Total loss': 0.40110849936803183} | train loss {'Reaction outcome loss': 0.31710899278413557, 'Total loss': 0.31710899278413557}
2023-01-04 08:08:56,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:56,690 INFO:     Epoch: 59
2023-01-04 08:08:58,260 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38464712699254355, 'Total loss': 0.38464712699254355} | train loss {'Reaction outcome loss': 0.3191071987254174, 'Total loss': 0.3191071987254174}
2023-01-04 08:08:58,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:58,261 INFO:     Epoch: 60
2023-01-04 08:08:59,753 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40440205186605455, 'Total loss': 0.40440205186605455} | train loss {'Reaction outcome loss': 0.3139372550295261, 'Total loss': 0.3139372550295261}
2023-01-04 08:08:59,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:08:59,753 INFO:     Epoch: 61
2023-01-04 08:09:01,325 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4023768117030462, 'Total loss': 0.4023768117030462} | train loss {'Reaction outcome loss': 0.3116504275240004, 'Total loss': 0.3116504275240004}
2023-01-04 08:09:01,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:01,326 INFO:     Epoch: 62
2023-01-04 08:09:02,897 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3917239636182785, 'Total loss': 0.3917239636182785} | train loss {'Reaction outcome loss': 0.3107424849546404, 'Total loss': 0.3107424849546404}
2023-01-04 08:09:02,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:02,897 INFO:     Epoch: 63
2023-01-04 08:09:04,475 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36922842810551326, 'Total loss': 0.36922842810551326} | train loss {'Reaction outcome loss': 0.30866017712468835, 'Total loss': 0.30866017712468835}
2023-01-04 08:09:04,475 INFO:     Found new best model at epoch 63
2023-01-04 08:09:04,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:04,476 INFO:     Epoch: 64
2023-01-04 08:09:06,047 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3900026947259903, 'Total loss': 0.3900026947259903} | train loss {'Reaction outcome loss': 0.3081546576045778, 'Total loss': 0.3081546576045778}
2023-01-04 08:09:06,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:06,048 INFO:     Epoch: 65
2023-01-04 08:09:07,628 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4095097541809082, 'Total loss': 0.4095097541809082} | train loss {'Reaction outcome loss': 0.3138022013278543, 'Total loss': 0.3138022013278543}
2023-01-04 08:09:07,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:07,628 INFO:     Epoch: 66
2023-01-04 08:09:09,137 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40781103471914926, 'Total loss': 0.40781103471914926} | train loss {'Reaction outcome loss': 0.31263669708329106, 'Total loss': 0.31263669708329106}
2023-01-04 08:09:09,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:09,138 INFO:     Epoch: 67
2023-01-04 08:09:10,725 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3864863375822703, 'Total loss': 0.3864863375822703} | train loss {'Reaction outcome loss': 0.3028412886209401, 'Total loss': 0.3028412886209401}
2023-01-04 08:09:10,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:10,725 INFO:     Epoch: 68
2023-01-04 08:09:12,330 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39477306803067524, 'Total loss': 0.39477306803067524} | train loss {'Reaction outcome loss': 0.3043760341470656, 'Total loss': 0.3043760341470656}
2023-01-04 08:09:12,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:12,330 INFO:     Epoch: 69
2023-01-04 08:09:13,924 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3763158271710078, 'Total loss': 0.3763158271710078} | train loss {'Reaction outcome loss': 0.31102448706920055, 'Total loss': 0.31102448706920055}
2023-01-04 08:09:13,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:13,924 INFO:     Epoch: 70
2023-01-04 08:09:15,520 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3941822598377864, 'Total loss': 0.3941822598377864} | train loss {'Reaction outcome loss': 0.3064843602883427, 'Total loss': 0.3064843602883427}
2023-01-04 08:09:15,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:15,521 INFO:     Epoch: 71
2023-01-04 08:09:17,114 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39521170059839883, 'Total loss': 0.39521170059839883} | train loss {'Reaction outcome loss': 0.32173992963772186, 'Total loss': 0.32173992963772186}
2023-01-04 08:09:17,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:17,115 INFO:     Epoch: 72
2023-01-04 08:09:18,626 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4009889622529348, 'Total loss': 0.4009889622529348} | train loss {'Reaction outcome loss': 0.29657675378004333, 'Total loss': 0.29657675378004333}
2023-01-04 08:09:18,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:18,626 INFO:     Epoch: 73
2023-01-04 08:09:20,211 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40996334950129193, 'Total loss': 0.40996334950129193} | train loss {'Reaction outcome loss': 0.30094511896047904, 'Total loss': 0.30094511896047904}
2023-01-04 08:09:20,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:20,211 INFO:     Epoch: 74
2023-01-04 08:09:21,789 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40798929433027903, 'Total loss': 0.40798929433027903} | train loss {'Reaction outcome loss': 0.35205316844740475, 'Total loss': 0.35205316844740475}
2023-01-04 08:09:21,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:21,790 INFO:     Epoch: 75
2023-01-04 08:09:23,346 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4069656153519948, 'Total loss': 0.4069656153519948} | train loss {'Reaction outcome loss': 0.3034697486200721, 'Total loss': 0.3034697486200721}
2023-01-04 08:09:23,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:23,346 INFO:     Epoch: 76
2023-01-04 08:09:24,927 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38969113926092785, 'Total loss': 0.38969113926092785} | train loss {'Reaction outcome loss': 0.29092743365681206, 'Total loss': 0.29092743365681206}
2023-01-04 08:09:24,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:24,927 INFO:     Epoch: 77
2023-01-04 08:09:26,505 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3801523014903069, 'Total loss': 0.3801523014903069} | train loss {'Reaction outcome loss': 0.29829273453873134, 'Total loss': 0.29829273453873134}
2023-01-04 08:09:26,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:26,506 INFO:     Epoch: 78
2023-01-04 08:09:27,964 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39828849931557975, 'Total loss': 0.39828849931557975} | train loss {'Reaction outcome loss': 0.3061521651925168, 'Total loss': 0.3061521651925168}
2023-01-04 08:09:27,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:27,965 INFO:     Epoch: 79
2023-01-04 08:09:29,562 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41409237881501515, 'Total loss': 0.41409237881501515} | train loss {'Reaction outcome loss': 0.2871028047385693, 'Total loss': 0.2871028047385693}
2023-01-04 08:09:29,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:29,563 INFO:     Epoch: 80
2023-01-04 08:09:31,143 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41334143380324045, 'Total loss': 0.41334143380324045} | train loss {'Reaction outcome loss': 0.2905992009555516, 'Total loss': 0.2905992009555516}
2023-01-04 08:09:31,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:31,143 INFO:     Epoch: 81
2023-01-04 08:09:32,708 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40582749942938484, 'Total loss': 0.40582749942938484} | train loss {'Reaction outcome loss': 0.3244554626173762, 'Total loss': 0.3244554626173762}
2023-01-04 08:09:32,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:32,708 INFO:     Epoch: 82
2023-01-04 08:09:34,297 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4023573855559031, 'Total loss': 0.4023573855559031} | train loss {'Reaction outcome loss': 0.29089182043743794, 'Total loss': 0.29089182043743794}
2023-01-04 08:09:34,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:34,297 INFO:     Epoch: 83
2023-01-04 08:09:35,777 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3874917944272359, 'Total loss': 0.3874917944272359} | train loss {'Reaction outcome loss': 0.2826592079131776, 'Total loss': 0.2826592079131776}
2023-01-04 08:09:35,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:35,777 INFO:     Epoch: 84
2023-01-04 08:09:37,329 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38035327196121216, 'Total loss': 0.38035327196121216} | train loss {'Reaction outcome loss': 0.2842215258591012, 'Total loss': 0.2842215258591012}
2023-01-04 08:09:37,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:37,329 INFO:     Epoch: 85
2023-01-04 08:09:38,882 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4360673318306605, 'Total loss': 0.4360673318306605} | train loss {'Reaction outcome loss': 0.2993178521215484, 'Total loss': 0.2993178521215484}
2023-01-04 08:09:38,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:38,883 INFO:     Epoch: 86
2023-01-04 08:09:40,444 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3740146468083064, 'Total loss': 0.3740146468083064} | train loss {'Reaction outcome loss': 0.33565624260708044, 'Total loss': 0.33565624260708044}
2023-01-04 08:09:40,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:40,445 INFO:     Epoch: 87
2023-01-04 08:09:41,989 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4246402283509572, 'Total loss': 0.4246402283509572} | train loss {'Reaction outcome loss': 0.28183695839286066, 'Total loss': 0.28183695839286066}
2023-01-04 08:09:41,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:41,989 INFO:     Epoch: 88
2023-01-04 08:09:43,538 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38954168260097505, 'Total loss': 0.38954168260097505} | train loss {'Reaction outcome loss': 0.28038959895712795, 'Total loss': 0.28038959895712795}
2023-01-04 08:09:43,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:43,538 INFO:     Epoch: 89
2023-01-04 08:09:44,994 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40897983610630034, 'Total loss': 0.40897983610630034} | train loss {'Reaction outcome loss': 0.2829210816696328, 'Total loss': 0.2829210816696328}
2023-01-04 08:09:44,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:44,994 INFO:     Epoch: 90
2023-01-04 08:09:46,556 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4059537470340729, 'Total loss': 0.4059537470340729} | train loss {'Reaction outcome loss': 0.27902938980443415, 'Total loss': 0.27902938980443415}
2023-01-04 08:09:46,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:46,556 INFO:     Epoch: 91
2023-01-04 08:09:48,138 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4043503195047379, 'Total loss': 0.4043503195047379} | train loss {'Reaction outcome loss': 0.27583547086839605, 'Total loss': 0.27583547086839605}
2023-01-04 08:09:48,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:48,138 INFO:     Epoch: 92
2023-01-04 08:09:49,717 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3966471453507741, 'Total loss': 0.3966471453507741} | train loss {'Reaction outcome loss': 0.27693264861127187, 'Total loss': 0.27693264861127187}
2023-01-04 08:09:49,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:49,718 INFO:     Epoch: 93
2023-01-04 08:09:51,264 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40645288427670795, 'Total loss': 0.40645288427670795} | train loss {'Reaction outcome loss': 0.2907563470897899, 'Total loss': 0.2907563470897899}
2023-01-04 08:09:51,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:51,264 INFO:     Epoch: 94
2023-01-04 08:09:52,817 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4063548376162847, 'Total loss': 0.4063548376162847} | train loss {'Reaction outcome loss': 0.33232072003833624, 'Total loss': 0.33232072003833624}
2023-01-04 08:09:52,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:52,817 INFO:     Epoch: 95
2023-01-04 08:09:54,279 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43478105664253236, 'Total loss': 0.43478105664253236} | train loss {'Reaction outcome loss': 0.29798759278449893, 'Total loss': 0.29798759278449893}
2023-01-04 08:09:54,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:54,279 INFO:     Epoch: 96
2023-01-04 08:09:55,859 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3924428383509318, 'Total loss': 0.3924428383509318} | train loss {'Reaction outcome loss': 0.3093311953572624, 'Total loss': 0.3093311953572624}
2023-01-04 08:09:55,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:55,859 INFO:     Epoch: 97
2023-01-04 08:09:57,406 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41250634491443633, 'Total loss': 0.41250634491443633} | train loss {'Reaction outcome loss': 0.2803013017704791, 'Total loss': 0.2803013017704791}
2023-01-04 08:09:57,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:57,407 INFO:     Epoch: 98
2023-01-04 08:09:58,963 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40835130016009014, 'Total loss': 0.40835130016009014} | train loss {'Reaction outcome loss': 0.27977944574440305, 'Total loss': 0.27977944574440305}
2023-01-04 08:09:58,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:09:58,964 INFO:     Epoch: 99
2023-01-04 08:10:00,518 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38873616258303323, 'Total loss': 0.38873616258303323} | train loss {'Reaction outcome loss': 0.2722117475245202, 'Total loss': 0.2722117475245202}
2023-01-04 08:10:00,518 INFO:     Best model found after epoch 64 of 100.
2023-01-04 08:10:00,519 INFO:   Done with stage: TRAINING
2023-01-04 08:10:00,519 INFO:   Starting stage: EVALUATION
2023-01-04 08:10:00,647 INFO:   Done with stage: EVALUATION
2023-01-04 08:10:00,647 INFO:   Leaving out SEQ value Fold_9
2023-01-04 08:10:00,660 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 08:10:00,660 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:10:01,311 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:10:01,311 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:10:01,379 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:10:01,379 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:10:01,379 INFO:     No hyperparam tuning for this model
2023-01-04 08:10:01,379 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:10:01,379 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:10:01,380 INFO:     None feature selector for col prot
2023-01-04 08:10:01,380 INFO:     None feature selector for col prot
2023-01-04 08:10:01,380 INFO:     None feature selector for col prot
2023-01-04 08:10:01,380 INFO:     None feature selector for col chem
2023-01-04 08:10:01,380 INFO:     None feature selector for col chem
2023-01-04 08:10:01,380 INFO:     None feature selector for col chem
2023-01-04 08:10:01,381 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:10:01,381 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:10:01,382 INFO:     Number of params in model 70111
2023-01-04 08:10:01,385 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:10:01,385 INFO:   Starting stage: TRAINING
2023-01-04 08:10:01,427 INFO:     Val loss before train {'Reaction outcome loss': 1.041692809263865, 'Total loss': 1.041692809263865}
2023-01-04 08:10:01,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:01,428 INFO:     Epoch: 0
2023-01-04 08:10:02,866 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7607190291086833, 'Total loss': 0.7607190291086833} | train loss {'Reaction outcome loss': 0.854177081660516, 'Total loss': 0.854177081660516}
2023-01-04 08:10:02,867 INFO:     Found new best model at epoch 0
2023-01-04 08:10:02,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:02,867 INFO:     Epoch: 1
2023-01-04 08:10:04,407 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6481707831223805, 'Total loss': 0.6481707831223805} | train loss {'Reaction outcome loss': 0.727687767882278, 'Total loss': 0.727687767882278}
2023-01-04 08:10:04,408 INFO:     Found new best model at epoch 1
2023-01-04 08:10:04,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:04,409 INFO:     Epoch: 2
2023-01-04 08:10:05,956 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5939459085464478, 'Total loss': 0.5939459085464478} | train loss {'Reaction outcome loss': 0.6283375083475603, 'Total loss': 0.6283375083475603}
2023-01-04 08:10:05,956 INFO:     Found new best model at epoch 2
2023-01-04 08:10:05,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:05,957 INFO:     Epoch: 3
2023-01-04 08:10:07,505 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5349355558554332, 'Total loss': 0.5349355558554332} | train loss {'Reaction outcome loss': 0.5719097246942313, 'Total loss': 0.5719097246942313}
2023-01-04 08:10:07,506 INFO:     Found new best model at epoch 3
2023-01-04 08:10:07,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:07,506 INFO:     Epoch: 4
2023-01-04 08:10:09,065 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5670583168665568, 'Total loss': 0.5670583168665568} | train loss {'Reaction outcome loss': 0.538929329327969, 'Total loss': 0.538929329327969}
2023-01-04 08:10:09,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:09,065 INFO:     Epoch: 5
2023-01-04 08:10:10,622 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5204409023125967, 'Total loss': 0.5204409023125967} | train loss {'Reaction outcome loss': 0.5197390662911145, 'Total loss': 0.5197390662911145}
2023-01-04 08:10:10,622 INFO:     Found new best model at epoch 5
2023-01-04 08:10:10,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:10,623 INFO:     Epoch: 6
2023-01-04 08:10:12,052 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.499960865577062, 'Total loss': 0.499960865577062} | train loss {'Reaction outcome loss': 0.503841581400079, 'Total loss': 0.503841581400079}
2023-01-04 08:10:12,053 INFO:     Found new best model at epoch 6
2023-01-04 08:10:12,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:12,053 INFO:     Epoch: 7
2023-01-04 08:10:13,622 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4828793466091156, 'Total loss': 0.4828793466091156} | train loss {'Reaction outcome loss': 0.501092750147201, 'Total loss': 0.501092750147201}
2023-01-04 08:10:13,622 INFO:     Found new best model at epoch 7
2023-01-04 08:10:13,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:13,623 INFO:     Epoch: 8
2023-01-04 08:10:15,192 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47000281115372977, 'Total loss': 0.47000281115372977} | train loss {'Reaction outcome loss': 0.48995017241416633, 'Total loss': 0.48995017241416633}
2023-01-04 08:10:15,192 INFO:     Found new best model at epoch 8
2023-01-04 08:10:15,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:15,193 INFO:     Epoch: 9
2023-01-04 08:10:16,779 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46211810906728107, 'Total loss': 0.46211810906728107} | train loss {'Reaction outcome loss': 0.4733774311894524, 'Total loss': 0.4733774311894524}
2023-01-04 08:10:16,780 INFO:     Found new best model at epoch 9
2023-01-04 08:10:16,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:16,780 INFO:     Epoch: 10
2023-01-04 08:10:18,348 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4681156446536382, 'Total loss': 0.4681156446536382} | train loss {'Reaction outcome loss': 0.46523868938422075, 'Total loss': 0.46523868938422075}
2023-01-04 08:10:18,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:18,348 INFO:     Epoch: 11
2023-01-04 08:10:19,910 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4442102938890457, 'Total loss': 0.4442102938890457} | train loss {'Reaction outcome loss': 0.4595997141618484, 'Total loss': 0.4595997141618484}
2023-01-04 08:10:19,911 INFO:     Found new best model at epoch 11
2023-01-04 08:10:19,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:19,911 INFO:     Epoch: 12
2023-01-04 08:10:21,343 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44658779303232826, 'Total loss': 0.44658779303232826} | train loss {'Reaction outcome loss': 0.4544921065330593, 'Total loss': 0.4544921065330593}
2023-01-04 08:10:21,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:21,344 INFO:     Epoch: 13
2023-01-04 08:10:22,885 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4406314194202423, 'Total loss': 0.4406314194202423} | train loss {'Reaction outcome loss': 0.45286379476390537, 'Total loss': 0.45286379476390537}
2023-01-04 08:10:22,885 INFO:     Found new best model at epoch 13
2023-01-04 08:10:22,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:22,886 INFO:     Epoch: 14
2023-01-04 08:10:24,449 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4419166773557663, 'Total loss': 0.4419166773557663} | train loss {'Reaction outcome loss': 0.444556172804184, 'Total loss': 0.444556172804184}
2023-01-04 08:10:24,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:24,449 INFO:     Epoch: 15
2023-01-04 08:10:26,007 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4307656188805898, 'Total loss': 0.4307656188805898} | train loss {'Reaction outcome loss': 0.4418695710896366, 'Total loss': 0.4418695710896366}
2023-01-04 08:10:26,007 INFO:     Found new best model at epoch 15
2023-01-04 08:10:26,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:26,008 INFO:     Epoch: 16
2023-01-04 08:10:27,584 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4501083195209503, 'Total loss': 0.4501083195209503} | train loss {'Reaction outcome loss': 0.43851286984737153, 'Total loss': 0.43851286984737153}
2023-01-04 08:10:27,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:27,584 INFO:     Epoch: 17
2023-01-04 08:10:29,162 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4301841745773951, 'Total loss': 0.4301841745773951} | train loss {'Reaction outcome loss': 0.44039002120278886, 'Total loss': 0.44039002120278886}
2023-01-04 08:10:29,162 INFO:     Found new best model at epoch 17
2023-01-04 08:10:29,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:29,163 INFO:     Epoch: 18
2023-01-04 08:10:30,610 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4321395178635915, 'Total loss': 0.4321395178635915} | train loss {'Reaction outcome loss': 0.4334476739708064, 'Total loss': 0.4334476739708064}
2023-01-04 08:10:30,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:30,610 INFO:     Epoch: 19
2023-01-04 08:10:32,154 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4337552030881246, 'Total loss': 0.4337552030881246} | train loss {'Reaction outcome loss': 0.4297707766510438, 'Total loss': 0.4297707766510438}
2023-01-04 08:10:32,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:32,154 INFO:     Epoch: 20
2023-01-04 08:10:33,717 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42845490177472434, 'Total loss': 0.42845490177472434} | train loss {'Reaction outcome loss': 0.4311502569159358, 'Total loss': 0.4311502569159358}
2023-01-04 08:10:33,718 INFO:     Found new best model at epoch 20
2023-01-04 08:10:33,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:33,719 INFO:     Epoch: 21
2023-01-04 08:10:35,298 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.458959357937177, 'Total loss': 0.458959357937177} | train loss {'Reaction outcome loss': 0.42596948287193326, 'Total loss': 0.42596948287193326}
2023-01-04 08:10:35,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:35,298 INFO:     Epoch: 22
2023-01-04 08:10:36,863 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4375372141599655, 'Total loss': 0.4375372141599655} | train loss {'Reaction outcome loss': 0.4364675959830334, 'Total loss': 0.4364675959830334}
2023-01-04 08:10:36,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:36,863 INFO:     Epoch: 23
2023-01-04 08:10:38,417 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41360240081946054, 'Total loss': 0.41360240081946054} | train loss {'Reaction outcome loss': 0.413933050387168, 'Total loss': 0.413933050387168}
2023-01-04 08:10:38,418 INFO:     Found new best model at epoch 23
2023-01-04 08:10:38,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:38,418 INFO:     Epoch: 24
2023-01-04 08:10:39,838 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4046811272700628, 'Total loss': 0.4046811272700628} | train loss {'Reaction outcome loss': 0.4121105968243564, 'Total loss': 0.4121105968243564}
2023-01-04 08:10:39,839 INFO:     Found new best model at epoch 24
2023-01-04 08:10:39,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:39,840 INFO:     Epoch: 25
2023-01-04 08:10:41,389 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39366349081198376, 'Total loss': 0.39366349081198376} | train loss {'Reaction outcome loss': 0.40812116492032185, 'Total loss': 0.40812116492032185}
2023-01-04 08:10:41,389 INFO:     Found new best model at epoch 25
2023-01-04 08:10:41,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:41,390 INFO:     Epoch: 26
2023-01-04 08:10:42,950 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41237680514653524, 'Total loss': 0.41237680514653524} | train loss {'Reaction outcome loss': 0.4046926395022783, 'Total loss': 0.4046926395022783}
2023-01-04 08:10:42,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:42,950 INFO:     Epoch: 27
2023-01-04 08:10:44,500 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40126752654711406, 'Total loss': 0.40126752654711406} | train loss {'Reaction outcome loss': 0.39872098589936894, 'Total loss': 0.39872098589936894}
2023-01-04 08:10:44,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:44,500 INFO:     Epoch: 28
2023-01-04 08:10:46,069 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41228694121042886, 'Total loss': 0.41228694121042886} | train loss {'Reaction outcome loss': 0.399518914610161, 'Total loss': 0.399518914610161}
2023-01-04 08:10:46,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:46,070 INFO:     Epoch: 29
2023-01-04 08:10:47,614 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39467098663250605, 'Total loss': 0.39467098663250605} | train loss {'Reaction outcome loss': 0.3962861823459642, 'Total loss': 0.3962861823459642}
2023-01-04 08:10:47,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:47,615 INFO:     Epoch: 30
2023-01-04 08:10:49,035 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40830083688100177, 'Total loss': 0.40830083688100177} | train loss {'Reaction outcome loss': 0.3903043643960331, 'Total loss': 0.3903043643960331}
2023-01-04 08:10:49,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:49,035 INFO:     Epoch: 31
2023-01-04 08:10:50,615 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40580095648765563, 'Total loss': 0.40580095648765563} | train loss {'Reaction outcome loss': 0.3992008163283269, 'Total loss': 0.3992008163283269}
2023-01-04 08:10:50,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:50,615 INFO:     Epoch: 32
2023-01-04 08:10:52,164 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41085699399312336, 'Total loss': 0.41085699399312336} | train loss {'Reaction outcome loss': 0.4003605762145657, 'Total loss': 0.4003605762145657}
2023-01-04 08:10:52,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:52,165 INFO:     Epoch: 33
2023-01-04 08:10:53,709 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4208004117012024, 'Total loss': 0.4208004117012024} | train loss {'Reaction outcome loss': 0.3918062828428895, 'Total loss': 0.3918062828428895}
2023-01-04 08:10:53,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:53,710 INFO:     Epoch: 34
2023-01-04 08:10:55,268 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40082267820835116, 'Total loss': 0.40082267820835116} | train loss {'Reaction outcome loss': 0.3846878545912172, 'Total loss': 0.3846878545912172}
2023-01-04 08:10:55,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:55,268 INFO:     Epoch: 35
2023-01-04 08:10:56,822 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42733925183614097, 'Total loss': 0.42733925183614097} | train loss {'Reaction outcome loss': 0.3874323600228282, 'Total loss': 0.3874323600228282}
2023-01-04 08:10:56,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:56,822 INFO:     Epoch: 36
2023-01-04 08:10:58,323 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3985431998968124, 'Total loss': 0.3985431998968124} | train loss {'Reaction outcome loss': 0.39372456972689734, 'Total loss': 0.39372456972689734}
2023-01-04 08:10:58,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:58,323 INFO:     Epoch: 37
2023-01-04 08:10:59,879 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.404234183828036, 'Total loss': 0.404234183828036} | train loss {'Reaction outcome loss': 0.3730412440381242, 'Total loss': 0.3730412440381242}
2023-01-04 08:10:59,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:10:59,879 INFO:     Epoch: 38
2023-01-04 08:11:01,438 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4102621038754781, 'Total loss': 0.4102621038754781} | train loss {'Reaction outcome loss': 0.3709479556688904, 'Total loss': 0.3709479556688904}
2023-01-04 08:11:01,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:01,438 INFO:     Epoch: 39
2023-01-04 08:11:02,996 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3997391591469447, 'Total loss': 0.3997391591469447} | train loss {'Reaction outcome loss': 0.36539120056166186, 'Total loss': 0.36539120056166186}
2023-01-04 08:11:02,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:02,996 INFO:     Epoch: 40
2023-01-04 08:11:04,549 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3987292210261027, 'Total loss': 0.3987292210261027} | train loss {'Reaction outcome loss': 0.3663156564057251, 'Total loss': 0.3663156564057251}
2023-01-04 08:11:04,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:04,549 INFO:     Epoch: 41
2023-01-04 08:11:06,050 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4003365715344747, 'Total loss': 0.4003365715344747} | train loss {'Reaction outcome loss': 0.36614421506722766, 'Total loss': 0.36614421506722766}
2023-01-04 08:11:06,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:06,050 INFO:     Epoch: 42
2023-01-04 08:11:07,560 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3967520952224731, 'Total loss': 0.3967520952224731} | train loss {'Reaction outcome loss': 0.36766188569848623, 'Total loss': 0.36766188569848623}
2023-01-04 08:11:07,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:07,560 INFO:     Epoch: 43
2023-01-04 08:11:09,128 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.407741771141688, 'Total loss': 0.407741771141688} | train loss {'Reaction outcome loss': 0.3543428511553772, 'Total loss': 0.3543428511553772}
2023-01-04 08:11:09,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:09,129 INFO:     Epoch: 44
2023-01-04 08:11:10,708 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3804387390613556, 'Total loss': 0.3804387390613556} | train loss {'Reaction outcome loss': 0.35255014968756965, 'Total loss': 0.35255014968756965}
2023-01-04 08:11:10,708 INFO:     Found new best model at epoch 44
2023-01-04 08:11:10,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:10,709 INFO:     Epoch: 45
2023-01-04 08:11:12,289 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4003532667954763, 'Total loss': 0.4003532667954763} | train loss {'Reaction outcome loss': 0.3490359816747461, 'Total loss': 0.3490359816747461}
2023-01-04 08:11:12,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:12,289 INFO:     Epoch: 46
2023-01-04 08:11:13,844 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38936531444390615, 'Total loss': 0.38936531444390615} | train loss {'Reaction outcome loss': 0.3482211134126545, 'Total loss': 0.3482211134126545}
2023-01-04 08:11:13,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:13,845 INFO:     Epoch: 47
2023-01-04 08:11:15,256 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39162282248338065, 'Total loss': 0.39162282248338065} | train loss {'Reaction outcome loss': 0.3429390502810154, 'Total loss': 0.3429390502810154}
2023-01-04 08:11:15,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:15,257 INFO:     Epoch: 48
2023-01-04 08:11:16,824 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41334100166956583, 'Total loss': 0.41334100166956583} | train loss {'Reaction outcome loss': 0.33898227721236757, 'Total loss': 0.33898227721236757}
2023-01-04 08:11:16,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:16,824 INFO:     Epoch: 49
2023-01-04 08:11:18,377 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39929882089296975, 'Total loss': 0.39929882089296975} | train loss {'Reaction outcome loss': 0.33806695498229156, 'Total loss': 0.33806695498229156}
2023-01-04 08:11:18,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:18,377 INFO:     Epoch: 50
2023-01-04 08:11:19,884 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38999445736408234, 'Total loss': 0.38999445736408234} | train loss {'Reaction outcome loss': 0.3358029244141569, 'Total loss': 0.3358029244141569}
2023-01-04 08:11:19,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:19,885 INFO:     Epoch: 51
2023-01-04 08:11:21,436 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4043374389410019, 'Total loss': 0.4043374389410019} | train loss {'Reaction outcome loss': 0.3348591048810361, 'Total loss': 0.3348591048810361}
2023-01-04 08:11:21,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:21,437 INFO:     Epoch: 52
2023-01-04 08:11:22,981 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3805432985226313, 'Total loss': 0.3805432985226313} | train loss {'Reaction outcome loss': 0.33267619800956355, 'Total loss': 0.33267619800956355}
2023-01-04 08:11:22,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:22,981 INFO:     Epoch: 53
2023-01-04 08:11:24,419 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40673293073972067, 'Total loss': 0.40673293073972067} | train loss {'Reaction outcome loss': 0.3317387488272473, 'Total loss': 0.3317387488272473}
2023-01-04 08:11:24,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:24,420 INFO:     Epoch: 54
2023-01-04 08:11:25,443 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3602288694431384, 'Total loss': 0.3602288694431384} | train loss {'Reaction outcome loss': 0.3330553536829741, 'Total loss': 0.3330553536829741}
2023-01-04 08:11:25,443 INFO:     Found new best model at epoch 54
2023-01-04 08:11:25,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:25,444 INFO:     Epoch: 55
2023-01-04 08:11:26,460 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4211132874091466, 'Total loss': 0.4211132874091466} | train loss {'Reaction outcome loss': 0.3279997367317792, 'Total loss': 0.3279997367317792}
2023-01-04 08:11:26,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:26,460 INFO:     Epoch: 56
2023-01-04 08:11:27,477 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3979558984438578, 'Total loss': 0.3979558984438578} | train loss {'Reaction outcome loss': 0.32626784301322437, 'Total loss': 0.32626784301322437}
2023-01-04 08:11:27,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:27,478 INFO:     Epoch: 57
2023-01-04 08:11:28,488 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38831881086031594, 'Total loss': 0.38831881086031594} | train loss {'Reaction outcome loss': 0.3513593516595986, 'Total loss': 0.3513593516595986}
2023-01-04 08:11:28,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:28,488 INFO:     Epoch: 58
2023-01-04 08:11:29,970 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4021101156870524, 'Total loss': 0.4021101156870524} | train loss {'Reaction outcome loss': 0.32117341180834785, 'Total loss': 0.32117341180834785}
2023-01-04 08:11:29,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:29,970 INFO:     Epoch: 59
2023-01-04 08:11:31,483 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38820348580678304, 'Total loss': 0.38820348580678304} | train loss {'Reaction outcome loss': 0.3184130778139714, 'Total loss': 0.3184130778139714}
2023-01-04 08:11:31,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:31,484 INFO:     Epoch: 60
2023-01-04 08:11:33,049 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40176042914390564, 'Total loss': 0.40176042914390564} | train loss {'Reaction outcome loss': 0.316165952635619, 'Total loss': 0.316165952635619}
2023-01-04 08:11:33,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:33,049 INFO:     Epoch: 61
2023-01-04 08:11:34,611 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38364097078641257, 'Total loss': 0.38364097078641257} | train loss {'Reaction outcome loss': 0.3121757242883164, 'Total loss': 0.3121757242883164}
2023-01-04 08:11:34,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:34,611 INFO:     Epoch: 62
2023-01-04 08:11:36,177 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38372414112091063, 'Total loss': 0.38372414112091063} | train loss {'Reaction outcome loss': 0.30656722212080384, 'Total loss': 0.30656722212080384}
2023-01-04 08:11:36,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:36,177 INFO:     Epoch: 63
2023-01-04 08:11:37,759 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37901349862416583, 'Total loss': 0.37901349862416583} | train loss {'Reaction outcome loss': 0.3097138338000176, 'Total loss': 0.3097138338000176}
2023-01-04 08:11:37,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:37,759 INFO:     Epoch: 64
2023-01-04 08:11:39,325 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3881499916315079, 'Total loss': 0.3881499916315079} | train loss {'Reaction outcome loss': 0.3066577146123366, 'Total loss': 0.3066577146123366}
2023-01-04 08:11:39,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:39,325 INFO:     Epoch: 65
2023-01-04 08:11:40,870 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38746954103310904, 'Total loss': 0.38746954103310904} | train loss {'Reaction outcome loss': 0.30120026854632853, 'Total loss': 0.30120026854632853}
2023-01-04 08:11:40,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:40,871 INFO:     Epoch: 66
2023-01-04 08:11:42,442 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4677731434504191, 'Total loss': 0.4677731434504191} | train loss {'Reaction outcome loss': 0.3045562671470469, 'Total loss': 0.3045562671470469}
2023-01-04 08:11:42,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:42,443 INFO:     Epoch: 67
2023-01-04 08:11:44,024 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3722799946864446, 'Total loss': 0.3722799946864446} | train loss {'Reaction outcome loss': 0.3136991238380437, 'Total loss': 0.3136991238380437}
2023-01-04 08:11:44,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:44,026 INFO:     Epoch: 68
2023-01-04 08:11:45,588 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42119253873825074, 'Total loss': 0.42119253873825074} | train loss {'Reaction outcome loss': 0.2999140382946833, 'Total loss': 0.2999140382946833}
2023-01-04 08:11:45,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:45,589 INFO:     Epoch: 69
2023-01-04 08:11:47,122 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4058088550964991, 'Total loss': 0.4058088550964991} | train loss {'Reaction outcome loss': 0.31395637508841534, 'Total loss': 0.31395637508841534}
2023-01-04 08:11:47,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:47,122 INFO:     Epoch: 70
2023-01-04 08:11:48,677 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39434919456640877, 'Total loss': 0.39434919456640877} | train loss {'Reaction outcome loss': 0.2993233973781268, 'Total loss': 0.2993233973781268}
2023-01-04 08:11:48,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:48,677 INFO:     Epoch: 71
2023-01-04 08:11:50,203 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4169433315594991, 'Total loss': 0.4169433315594991} | train loss {'Reaction outcome loss': 0.34099332626531087, 'Total loss': 0.34099332626531087}
2023-01-04 08:11:50,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:50,204 INFO:     Epoch: 72
2023-01-04 08:11:51,758 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38406927784283956, 'Total loss': 0.38406927784283956} | train loss {'Reaction outcome loss': 0.3187410932648387, 'Total loss': 0.3187410932648387}
2023-01-04 08:11:51,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:51,758 INFO:     Epoch: 73
2023-01-04 08:11:53,324 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37429594695568086, 'Total loss': 0.37429594695568086} | train loss {'Reaction outcome loss': 0.302103013880011, 'Total loss': 0.302103013880011}
2023-01-04 08:11:53,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:53,324 INFO:     Epoch: 74
2023-01-04 08:11:54,888 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3795110811789831, 'Total loss': 0.3795110811789831} | train loss {'Reaction outcome loss': 0.2897653209917168, 'Total loss': 0.2897653209917168}
2023-01-04 08:11:54,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:54,889 INFO:     Epoch: 75
2023-01-04 08:11:56,404 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38664359350999195, 'Total loss': 0.38664359350999195} | train loss {'Reaction outcome loss': 0.28630302055482415, 'Total loss': 0.28630302055482415}
2023-01-04 08:11:56,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:56,404 INFO:     Epoch: 76
2023-01-04 08:11:57,974 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3784257253011068, 'Total loss': 0.3784257253011068} | train loss {'Reaction outcome loss': 0.29243449711129477, 'Total loss': 0.29243449711129477}
2023-01-04 08:11:57,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:57,974 INFO:     Epoch: 77
2023-01-04 08:11:59,539 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3913068224986394, 'Total loss': 0.3913068224986394} | train loss {'Reaction outcome loss': 0.285279435499578, 'Total loss': 0.285279435499578}
2023-01-04 08:11:59,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:11:59,539 INFO:     Epoch: 78
2023-01-04 08:12:01,129 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39457841714223224, 'Total loss': 0.39457841714223224} | train loss {'Reaction outcome loss': 0.2845184635101021, 'Total loss': 0.2845184635101021}
2023-01-04 08:12:01,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:01,130 INFO:     Epoch: 79
2023-01-04 08:12:02,726 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39820775091648103, 'Total loss': 0.39820775091648103} | train loss {'Reaction outcome loss': 0.28229415111591283, 'Total loss': 0.28229415111591283}
2023-01-04 08:12:02,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:02,727 INFO:     Epoch: 80
2023-01-04 08:12:04,318 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4093494748075803, 'Total loss': 0.4093494748075803} | train loss {'Reaction outcome loss': 0.2783991618941558, 'Total loss': 0.2783991618941558}
2023-01-04 08:12:04,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:04,318 INFO:     Epoch: 81
2023-01-04 08:12:05,868 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3809572607278824, 'Total loss': 0.3809572607278824} | train loss {'Reaction outcome loss': 0.28034285991621355, 'Total loss': 0.28034285991621355}
2023-01-04 08:12:05,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:05,868 INFO:     Epoch: 82
2023-01-04 08:12:07,423 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38358025848865507, 'Total loss': 0.38358025848865507} | train loss {'Reaction outcome loss': 0.2763780781769774, 'Total loss': 0.2763780781769774}
2023-01-04 08:12:07,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:07,423 INFO:     Epoch: 83
2023-01-04 08:12:09,014 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40736475586891174, 'Total loss': 0.40736475586891174} | train loss {'Reaction outcome loss': 0.2804661847745276, 'Total loss': 0.2804661847745276}
2023-01-04 08:12:09,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:09,015 INFO:     Epoch: 84
2023-01-04 08:12:10,611 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38426440755526226, 'Total loss': 0.38426440755526226} | train loss {'Reaction outcome loss': 0.2744171589700905, 'Total loss': 0.2744171589700905}
2023-01-04 08:12:10,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:10,611 INFO:     Epoch: 85
2023-01-04 08:12:12,189 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.395294530193011, 'Total loss': 0.395294530193011} | train loss {'Reaction outcome loss': 0.2744586975482441, 'Total loss': 0.2744586975482441}
2023-01-04 08:12:12,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:12,189 INFO:     Epoch: 86
2023-01-04 08:12:13,769 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43631222446759543, 'Total loss': 0.43631222446759543} | train loss {'Reaction outcome loss': 0.2737741045721518, 'Total loss': 0.2737741045721518}
2023-01-04 08:12:13,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:13,769 INFO:     Epoch: 87
2023-01-04 08:12:15,299 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39940370817979176, 'Total loss': 0.39940370817979176} | train loss {'Reaction outcome loss': 0.272302040258301, 'Total loss': 0.272302040258301}
2023-01-04 08:12:15,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:15,300 INFO:     Epoch: 88
2023-01-04 08:12:16,826 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3843830555677414, 'Total loss': 0.3843830555677414} | train loss {'Reaction outcome loss': 0.267593940014616, 'Total loss': 0.267593940014616}
2023-01-04 08:12:16,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:16,826 INFO:     Epoch: 89
2023-01-04 08:12:18,348 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3891326546669006, 'Total loss': 0.3891326546669006} | train loss {'Reaction outcome loss': 0.268243964604588, 'Total loss': 0.268243964604588}
2023-01-04 08:12:18,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:18,348 INFO:     Epoch: 90
2023-01-04 08:12:19,861 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3989579995473226, 'Total loss': 0.3989579995473226} | train loss {'Reaction outcome loss': 0.2696467963826802, 'Total loss': 0.2696467963826802}
2023-01-04 08:12:19,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:19,862 INFO:     Epoch: 91
2023-01-04 08:12:21,374 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42266859610875446, 'Total loss': 0.42266859610875446} | train loss {'Reaction outcome loss': 0.2869743762024935, 'Total loss': 0.2869743762024935}
2023-01-04 08:12:21,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:21,374 INFO:     Epoch: 92
2023-01-04 08:12:22,892 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3923872172832489, 'Total loss': 0.3923872172832489} | train loss {'Reaction outcome loss': 0.2772225713006396, 'Total loss': 0.2772225713006396}
2023-01-04 08:12:22,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:22,892 INFO:     Epoch: 93
2023-01-04 08:12:24,381 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37015111396710076, 'Total loss': 0.37015111396710076} | train loss {'Reaction outcome loss': 0.26421229955672787, 'Total loss': 0.26421229955672787}
2023-01-04 08:12:24,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:24,381 INFO:     Epoch: 94
2023-01-04 08:12:25,897 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37757333119710285, 'Total loss': 0.37757333119710285} | train loss {'Reaction outcome loss': 0.2659122252892804, 'Total loss': 0.2659122252892804}
2023-01-04 08:12:25,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:25,898 INFO:     Epoch: 95
2023-01-04 08:12:27,462 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42415364384651183, 'Total loss': 0.42415364384651183} | train loss {'Reaction outcome loss': 0.2616028982761302, 'Total loss': 0.2616028982761302}
2023-01-04 08:12:27,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:27,462 INFO:     Epoch: 96
2023-01-04 08:12:29,029 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40915735363960265, 'Total loss': 0.40915735363960265} | train loss {'Reaction outcome loss': 0.26021547620674, 'Total loss': 0.26021547620674}
2023-01-04 08:12:29,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:29,029 INFO:     Epoch: 97
2023-01-04 08:12:30,573 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4645199000835419, 'Total loss': 0.4645199000835419} | train loss {'Reaction outcome loss': 0.26199901494049077, 'Total loss': 0.26199901494049077}
2023-01-04 08:12:30,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:30,573 INFO:     Epoch: 98
2023-01-04 08:12:32,123 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39970347881317136, 'Total loss': 0.39970347881317136} | train loss {'Reaction outcome loss': 0.2701542406449216, 'Total loss': 0.2701542406449216}
2023-01-04 08:12:32,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:32,123 INFO:     Epoch: 99
2023-01-04 08:12:33,649 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43479044139385226, 'Total loss': 0.43479044139385226} | train loss {'Reaction outcome loss': 0.25676268778435135, 'Total loss': 0.25676268778435135}
2023-01-04 08:12:33,649 INFO:     Best model found after epoch 55 of 100.
2023-01-04 08:12:33,649 INFO:   Done with stage: TRAINING
2023-01-04 08:12:33,649 INFO:   Starting stage: EVALUATION
2023-01-04 08:12:33,780 INFO:   Done with stage: EVALUATION
2023-01-04 08:12:33,788 INFO:   Leaving out SEQ value Fold_0
2023-01-04 08:12:33,801 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 08:12:33,801 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:12:34,447 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:12:34,447 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:12:34,518 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:12:34,518 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:12:34,518 INFO:     No hyperparam tuning for this model
2023-01-04 08:12:34,518 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:12:34,518 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:12:34,519 INFO:     None feature selector for col prot
2023-01-04 08:12:34,519 INFO:     None feature selector for col prot
2023-01-04 08:12:34,519 INFO:     None feature selector for col prot
2023-01-04 08:12:34,519 INFO:     None feature selector for col chem
2023-01-04 08:12:34,520 INFO:     None feature selector for col chem
2023-01-04 08:12:34,520 INFO:     None feature selector for col chem
2023-01-04 08:12:34,520 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:12:34,520 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:12:34,521 INFO:     Number of params in model 70111
2023-01-04 08:12:34,524 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:12:34,524 INFO:   Starting stage: TRAINING
2023-01-04 08:12:34,569 INFO:     Val loss before train {'Reaction outcome loss': 1.0380966623624166, 'Total loss': 1.0380966623624166}
2023-01-04 08:12:34,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:34,569 INFO:     Epoch: 0
2023-01-04 08:12:36,125 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8021868348121644, 'Total loss': 0.8021868348121644} | train loss {'Reaction outcome loss': 0.8433883859762463, 'Total loss': 0.8433883859762463}
2023-01-04 08:12:36,125 INFO:     Found new best model at epoch 0
2023-01-04 08:12:36,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:36,126 INFO:     Epoch: 1
2023-01-04 08:12:37,671 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6342794895172119, 'Total loss': 0.6342794895172119} | train loss {'Reaction outcome loss': 0.6879761196888875, 'Total loss': 0.6879761196888875}
2023-01-04 08:12:37,671 INFO:     Found new best model at epoch 1
2023-01-04 08:12:37,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:37,672 INFO:     Epoch: 2
2023-01-04 08:12:39,220 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5841989283760388, 'Total loss': 0.5841989283760388} | train loss {'Reaction outcome loss': 0.6065258940924769, 'Total loss': 0.6065258940924769}
2023-01-04 08:12:39,221 INFO:     Found new best model at epoch 2
2023-01-04 08:12:39,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:39,222 INFO:     Epoch: 3
2023-01-04 08:12:40,781 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5440148413181305, 'Total loss': 0.5440148413181305} | train loss {'Reaction outcome loss': 0.569444193167315, 'Total loss': 0.569444193167315}
2023-01-04 08:12:40,781 INFO:     Found new best model at epoch 3
2023-01-04 08:12:40,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:40,782 INFO:     Epoch: 4
2023-01-04 08:12:42,324 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5040567447741826, 'Total loss': 0.5040567447741826} | train loss {'Reaction outcome loss': 0.5271315709350334, 'Total loss': 0.5271315709350334}
2023-01-04 08:12:42,325 INFO:     Found new best model at epoch 4
2023-01-04 08:12:42,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:42,325 INFO:     Epoch: 5
2023-01-04 08:12:43,848 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49597327013810477, 'Total loss': 0.49597327013810477} | train loss {'Reaction outcome loss': 0.5091726278163454, 'Total loss': 0.5091726278163454}
2023-01-04 08:12:43,848 INFO:     Found new best model at epoch 5
2023-01-04 08:12:43,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:43,849 INFO:     Epoch: 6
2023-01-04 08:12:45,411 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4712870538234711, 'Total loss': 0.4712870538234711} | train loss {'Reaction outcome loss': 0.4925682508670118, 'Total loss': 0.4925682508670118}
2023-01-04 08:12:45,411 INFO:     Found new best model at epoch 6
2023-01-04 08:12:45,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:45,412 INFO:     Epoch: 7
2023-01-04 08:12:46,973 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4586346447467804, 'Total loss': 0.4586346447467804} | train loss {'Reaction outcome loss': 0.4907338697517264, 'Total loss': 0.4907338697517264}
2023-01-04 08:12:46,973 INFO:     Found new best model at epoch 7
2023-01-04 08:12:46,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:46,974 INFO:     Epoch: 8
2023-01-04 08:12:48,524 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4590760151545207, 'Total loss': 0.4590760151545207} | train loss {'Reaction outcome loss': 0.4945884589432735, 'Total loss': 0.4945884589432735}
2023-01-04 08:12:48,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:48,525 INFO:     Epoch: 9
2023-01-04 08:12:50,090 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4530907988548279, 'Total loss': 0.4530907988548279} | train loss {'Reaction outcome loss': 0.4735659304736317, 'Total loss': 0.4735659304736317}
2023-01-04 08:12:50,090 INFO:     Found new best model at epoch 9
2023-01-04 08:12:50,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:50,091 INFO:     Epoch: 10
2023-01-04 08:12:51,619 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45782798727353413, 'Total loss': 0.45782798727353413} | train loss {'Reaction outcome loss': 0.46427158538953983, 'Total loss': 0.46427158538953983}
2023-01-04 08:12:51,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:51,620 INFO:     Epoch: 11
2023-01-04 08:12:53,147 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45659092466036477, 'Total loss': 0.45659092466036477} | train loss {'Reaction outcome loss': 0.4574290722156402, 'Total loss': 0.4574290722156402}
2023-01-04 08:12:53,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:53,147 INFO:     Epoch: 12
2023-01-04 08:12:54,709 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42664927591880164, 'Total loss': 0.42664927591880164} | train loss {'Reaction outcome loss': 0.4514757605401151, 'Total loss': 0.4514757605401151}
2023-01-04 08:12:54,709 INFO:     Found new best model at epoch 12
2023-01-04 08:12:54,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:54,709 INFO:     Epoch: 13
2023-01-04 08:12:56,256 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4464972406625748, 'Total loss': 0.4464972406625748} | train loss {'Reaction outcome loss': 0.44637710771158984, 'Total loss': 0.44637710771158984}
2023-01-04 08:12:56,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:56,257 INFO:     Epoch: 14
2023-01-04 08:12:57,817 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43047324419021604, 'Total loss': 0.43047324419021604} | train loss {'Reaction outcome loss': 0.44439849893872935, 'Total loss': 0.44439849893872935}
2023-01-04 08:12:57,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:57,817 INFO:     Epoch: 15
2023-01-04 08:12:59,366 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4514331062634786, 'Total loss': 0.4514331062634786} | train loss {'Reaction outcome loss': 0.4471503415185472, 'Total loss': 0.4471503415185472}
2023-01-04 08:12:59,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:12:59,366 INFO:     Epoch: 16
2023-01-04 08:13:00,892 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44641860127449035, 'Total loss': 0.44641860127449035} | train loss {'Reaction outcome loss': 0.45605249378781265, 'Total loss': 0.45605249378781265}
2023-01-04 08:13:00,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:00,893 INFO:     Epoch: 17
2023-01-04 08:13:02,390 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43258771697680154, 'Total loss': 0.43258771697680154} | train loss {'Reaction outcome loss': 0.4284582035540117, 'Total loss': 0.4284582035540117}
2023-01-04 08:13:02,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:02,390 INFO:     Epoch: 18
2023-01-04 08:13:03,929 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42423620919386545, 'Total loss': 0.42423620919386545} | train loss {'Reaction outcome loss': 0.4324136079977388, 'Total loss': 0.4324136079977388}
2023-01-04 08:13:03,929 INFO:     Found new best model at epoch 18
2023-01-04 08:13:03,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:03,930 INFO:     Epoch: 19
2023-01-04 08:13:05,469 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43146682580312096, 'Total loss': 0.43146682580312096} | train loss {'Reaction outcome loss': 0.4531404618983683, 'Total loss': 0.4531404618983683}
2023-01-04 08:13:05,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:05,469 INFO:     Epoch: 20
2023-01-04 08:13:07,005 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4194730192422867, 'Total loss': 0.4194730192422867} | train loss {'Reaction outcome loss': 0.42428340369593387, 'Total loss': 0.42428340369593387}
2023-01-04 08:13:07,005 INFO:     Found new best model at epoch 20
2023-01-04 08:13:07,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:07,006 INFO:     Epoch: 21
2023-01-04 08:13:08,525 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43395925760269166, 'Total loss': 0.43395925760269166} | train loss {'Reaction outcome loss': 0.41789508357212163, 'Total loss': 0.41789508357212163}
2023-01-04 08:13:08,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:08,525 INFO:     Epoch: 22
2023-01-04 08:13:10,069 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4046484440565109, 'Total loss': 0.4046484440565109} | train loss {'Reaction outcome loss': 0.4140399772322912, 'Total loss': 0.4140399772322912}
2023-01-04 08:13:10,069 INFO:     Found new best model at epoch 22
2023-01-04 08:13:10,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:10,070 INFO:     Epoch: 23
2023-01-04 08:13:11,574 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4247998615105947, 'Total loss': 0.4247998615105947} | train loss {'Reaction outcome loss': 0.4123164717701898, 'Total loss': 0.4123164717701898}
2023-01-04 08:13:11,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:11,575 INFO:     Epoch: 24
2023-01-04 08:13:13,091 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4199397335449854, 'Total loss': 0.4199397335449854} | train loss {'Reaction outcome loss': 0.40640967274742684, 'Total loss': 0.40640967274742684}
2023-01-04 08:13:13,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:13,091 INFO:     Epoch: 25
2023-01-04 08:13:14,642 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43200116654237114, 'Total loss': 0.43200116654237114} | train loss {'Reaction outcome loss': 0.4063085624408247, 'Total loss': 0.4063085624408247}
2023-01-04 08:13:14,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:14,643 INFO:     Epoch: 26
2023-01-04 08:13:16,191 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41792797644933066, 'Total loss': 0.41792797644933066} | train loss {'Reaction outcome loss': 0.42236439967393014, 'Total loss': 0.42236439967393014}
2023-01-04 08:13:16,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:16,192 INFO:     Epoch: 27
2023-01-04 08:13:17,717 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4223057389259338, 'Total loss': 0.4223057389259338} | train loss {'Reaction outcome loss': 0.4037278274587099, 'Total loss': 0.4037278274587099}
2023-01-04 08:13:17,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:17,718 INFO:     Epoch: 28
2023-01-04 08:13:19,246 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42953230341275533, 'Total loss': 0.42953230341275533} | train loss {'Reaction outcome loss': 0.4061142678821351, 'Total loss': 0.4061142678821351}
2023-01-04 08:13:19,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:19,246 INFO:     Epoch: 29
2023-01-04 08:13:20,768 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4438978264729182, 'Total loss': 0.4438978264729182} | train loss {'Reaction outcome loss': 0.393988325118013, 'Total loss': 0.393988325118013}
2023-01-04 08:13:20,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:20,769 INFO:     Epoch: 30
2023-01-04 08:13:22,329 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4196055183808009, 'Total loss': 0.4196055183808009} | train loss {'Reaction outcome loss': 0.3918402556244974, 'Total loss': 0.3918402556244974}
2023-01-04 08:13:22,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:22,330 INFO:     Epoch: 31
2023-01-04 08:13:23,948 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40235795776049293, 'Total loss': 0.40235795776049293} | train loss {'Reaction outcome loss': 0.38880403514654527, 'Total loss': 0.38880403514654527}
2023-01-04 08:13:23,948 INFO:     Found new best model at epoch 31
2023-01-04 08:13:23,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:23,949 INFO:     Epoch: 32
2023-01-04 08:13:25,556 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4142627716064453, 'Total loss': 0.4142627716064453} | train loss {'Reaction outcome loss': 0.3843162462142283, 'Total loss': 0.3843162462142283}
2023-01-04 08:13:25,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:25,557 INFO:     Epoch: 33
2023-01-04 08:13:27,128 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.390517994761467, 'Total loss': 0.390517994761467} | train loss {'Reaction outcome loss': 0.4098015274528576, 'Total loss': 0.4098015274528576}
2023-01-04 08:13:27,128 INFO:     Found new best model at epoch 33
2023-01-04 08:13:27,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:27,130 INFO:     Epoch: 34
2023-01-04 08:13:28,690 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3861005092660586, 'Total loss': 0.3861005092660586} | train loss {'Reaction outcome loss': 0.3839105690299682, 'Total loss': 0.3839105690299682}
2023-01-04 08:13:28,691 INFO:     Found new best model at epoch 34
2023-01-04 08:13:28,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:28,692 INFO:     Epoch: 35
2023-01-04 08:13:30,214 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4040834069252014, 'Total loss': 0.4040834069252014} | train loss {'Reaction outcome loss': 0.3766877231992903, 'Total loss': 0.3766877231992903}
2023-01-04 08:13:30,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:30,214 INFO:     Epoch: 36
2023-01-04 08:13:31,777 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4196034093697866, 'Total loss': 0.4196034093697866} | train loss {'Reaction outcome loss': 0.37186378653606644, 'Total loss': 0.37186378653606644}
2023-01-04 08:13:31,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:31,777 INFO:     Epoch: 37
2023-01-04 08:13:33,348 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3847925623257955, 'Total loss': 0.3847925623257955} | train loss {'Reaction outcome loss': 0.371409040281846, 'Total loss': 0.371409040281846}
2023-01-04 08:13:33,348 INFO:     Found new best model at epoch 37
2023-01-04 08:13:33,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:33,349 INFO:     Epoch: 38
2023-01-04 08:13:34,925 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39812612235546113, 'Total loss': 0.39812612235546113} | train loss {'Reaction outcome loss': 0.364325977065533, 'Total loss': 0.364325977065533}
2023-01-04 08:13:34,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:34,927 INFO:     Epoch: 39
2023-01-04 08:13:36,448 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4316380381584167, 'Total loss': 0.4316380381584167} | train loss {'Reaction outcome loss': 0.3626864226265014, 'Total loss': 0.3626864226265014}
2023-01-04 08:13:36,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:36,449 INFO:     Epoch: 40
2023-01-04 08:13:38,010 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38824899196624757, 'Total loss': 0.38824899196624757} | train loss {'Reaction outcome loss': 0.3612697417645351, 'Total loss': 0.3612697417645351}
2023-01-04 08:13:38,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:38,010 INFO:     Epoch: 41
2023-01-04 08:13:39,525 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39780625502268474, 'Total loss': 0.39780625502268474} | train loss {'Reaction outcome loss': 0.36280390582438826, 'Total loss': 0.36280390582438826}
2023-01-04 08:13:39,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:39,525 INFO:     Epoch: 42
2023-01-04 08:13:41,096 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3945239077011744, 'Total loss': 0.3945239077011744} | train loss {'Reaction outcome loss': 0.394250578854395, 'Total loss': 0.394250578854395}
2023-01-04 08:13:41,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:41,097 INFO:     Epoch: 43
2023-01-04 08:13:42,650 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3848255058129629, 'Total loss': 0.3848255058129629} | train loss {'Reaction outcome loss': 0.35792260713366186, 'Total loss': 0.35792260713366186}
2023-01-04 08:13:42,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:42,650 INFO:     Epoch: 44
2023-01-04 08:13:44,218 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38163474202156067, 'Total loss': 0.38163474202156067} | train loss {'Reaction outcome loss': 0.34332826026323915, 'Total loss': 0.34332826026323915}
2023-01-04 08:13:44,218 INFO:     Found new best model at epoch 44
2023-01-04 08:13:44,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:44,219 INFO:     Epoch: 45
2023-01-04 08:13:45,743 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37815260589122773, 'Total loss': 0.37815260589122773} | train loss {'Reaction outcome loss': 0.3434381112118886, 'Total loss': 0.3434381112118886}
2023-01-04 08:13:45,744 INFO:     Found new best model at epoch 45
2023-01-04 08:13:45,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:45,744 INFO:     Epoch: 46
2023-01-04 08:13:47,252 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37283021708329517, 'Total loss': 0.37283021708329517} | train loss {'Reaction outcome loss': 0.3394380602715672, 'Total loss': 0.3394380602715672}
2023-01-04 08:13:47,253 INFO:     Found new best model at epoch 46
2023-01-04 08:13:47,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:47,254 INFO:     Epoch: 47
2023-01-04 08:13:48,747 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4011569082736969, 'Total loss': 0.4011569082736969} | train loss {'Reaction outcome loss': 0.34573137660281383, 'Total loss': 0.34573137660281383}
2023-01-04 08:13:48,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:48,747 INFO:     Epoch: 48
2023-01-04 08:13:50,310 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38863805135091145, 'Total loss': 0.38863805135091145} | train loss {'Reaction outcome loss': 0.3680706393295069, 'Total loss': 0.3680706393295069}
2023-01-04 08:13:50,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:50,311 INFO:     Epoch: 49
2023-01-04 08:13:51,869 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.375118080774943, 'Total loss': 0.375118080774943} | train loss {'Reaction outcome loss': 0.33658694940796535, 'Total loss': 0.33658694940796535}
2023-01-04 08:13:51,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:51,870 INFO:     Epoch: 50
2023-01-04 08:13:53,440 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35821330199639, 'Total loss': 0.35821330199639} | train loss {'Reaction outcome loss': 0.33439402068978635, 'Total loss': 0.33439402068978635}
2023-01-04 08:13:53,441 INFO:     Found new best model at epoch 50
2023-01-04 08:13:53,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:53,442 INFO:     Epoch: 51
2023-01-04 08:13:54,967 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4078286836544673, 'Total loss': 0.4078286836544673} | train loss {'Reaction outcome loss': 0.32742494938598166, 'Total loss': 0.32742494938598166}
2023-01-04 08:13:54,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:54,967 INFO:     Epoch: 52
2023-01-04 08:13:56,537 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3879622668027878, 'Total loss': 0.3879622668027878} | train loss {'Reaction outcome loss': 0.33118306989722507, 'Total loss': 0.33118306989722507}
2023-01-04 08:13:56,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:56,537 INFO:     Epoch: 53
2023-01-04 08:13:58,061 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3853398233652115, 'Total loss': 0.3853398233652115} | train loss {'Reaction outcome loss': 0.3239686051518589, 'Total loss': 0.3239686051518589}
2023-01-04 08:13:58,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:58,062 INFO:     Epoch: 54
2023-01-04 08:13:59,624 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46513652602831523, 'Total loss': 0.46513652602831523} | train loss {'Reaction outcome loss': 0.3267002098424279, 'Total loss': 0.3267002098424279}
2023-01-04 08:13:59,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:13:59,626 INFO:     Epoch: 55
2023-01-04 08:14:01,207 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39774376451969146, 'Total loss': 0.39774376451969146} | train loss {'Reaction outcome loss': 0.3660784664756173, 'Total loss': 0.3660784664756173}
2023-01-04 08:14:01,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:01,208 INFO:     Epoch: 56
2023-01-04 08:14:02,770 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.369562063117822, 'Total loss': 0.369562063117822} | train loss {'Reaction outcome loss': 0.32222917408048024, 'Total loss': 0.32222917408048024}
2023-01-04 08:14:02,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:02,771 INFO:     Epoch: 57
2023-01-04 08:14:04,302 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4041056841611862, 'Total loss': 0.4041056841611862} | train loss {'Reaction outcome loss': 0.31630235880890023, 'Total loss': 0.31630235880890023}
2023-01-04 08:14:04,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:04,302 INFO:     Epoch: 58
2023-01-04 08:14:05,872 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3711464822292328, 'Total loss': 0.3711464822292328} | train loss {'Reaction outcome loss': 0.3134540043892744, 'Total loss': 0.3134540043892744}
2023-01-04 08:14:05,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:05,873 INFO:     Epoch: 59
2023-01-04 08:14:07,418 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.382912610967954, 'Total loss': 0.382912610967954} | train loss {'Reaction outcome loss': 0.323561761447269, 'Total loss': 0.323561761447269}
2023-01-04 08:14:07,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:07,418 INFO:     Epoch: 60
2023-01-04 08:14:08,998 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.380108114083608, 'Total loss': 0.380108114083608} | train loss {'Reaction outcome loss': 0.33353880687913706, 'Total loss': 0.33353880687913706}
2023-01-04 08:14:08,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:08,999 INFO:     Epoch: 61
2023-01-04 08:14:10,581 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39926712910334267, 'Total loss': 0.39926712910334267} | train loss {'Reaction outcome loss': 0.3070757889317052, 'Total loss': 0.3070757889317052}
2023-01-04 08:14:10,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:10,581 INFO:     Epoch: 62
2023-01-04 08:14:12,136 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3406459763646126, 'Total loss': 0.3406459763646126} | train loss {'Reaction outcome loss': 0.30587989485998085, 'Total loss': 0.30587989485998085}
2023-01-04 08:14:12,137 INFO:     Found new best model at epoch 62
2023-01-04 08:14:12,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:12,138 INFO:     Epoch: 63
2023-01-04 08:14:13,663 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37563408017158506, 'Total loss': 0.37563408017158506} | train loss {'Reaction outcome loss': 0.3116993475819797, 'Total loss': 0.3116993475819797}
2023-01-04 08:14:13,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:13,663 INFO:     Epoch: 64
2023-01-04 08:14:15,211 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36714874505996703, 'Total loss': 0.36714874505996703} | train loss {'Reaction outcome loss': 0.30105162382233835, 'Total loss': 0.30105162382233835}
2023-01-04 08:14:15,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:15,212 INFO:     Epoch: 65
2023-01-04 08:14:16,781 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3409854499002298, 'Total loss': 0.3409854499002298} | train loss {'Reaction outcome loss': 0.3259955280176971, 'Total loss': 0.3259955280176971}
2023-01-04 08:14:16,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:16,782 INFO:     Epoch: 66
2023-01-04 08:14:18,348 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35413407037655514, 'Total loss': 0.35413407037655514} | train loss {'Reaction outcome loss': 0.3179495810544577, 'Total loss': 0.3179495810544577}
2023-01-04 08:14:18,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:18,349 INFO:     Epoch: 67
2023-01-04 08:14:19,927 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40367671251297, 'Total loss': 0.40367671251297} | train loss {'Reaction outcome loss': 0.3247561895733942, 'Total loss': 0.3247561895733942}
2023-01-04 08:14:19,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:19,927 INFO:     Epoch: 68
2023-01-04 08:14:21,495 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3864021271467209, 'Total loss': 0.3864021271467209} | train loss {'Reaction outcome loss': 0.298325445961909, 'Total loss': 0.298325445961909}
2023-01-04 08:14:21,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:21,495 INFO:     Epoch: 69
2023-01-04 08:14:23,020 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36764374325672783, 'Total loss': 0.36764374325672783} | train loss {'Reaction outcome loss': 0.29270827004401706, 'Total loss': 0.29270827004401706}
2023-01-04 08:14:23,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:23,020 INFO:     Epoch: 70
2023-01-04 08:14:24,560 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3730344990889231, 'Total loss': 0.3730344990889231} | train loss {'Reaction outcome loss': 0.2935274674192719, 'Total loss': 0.2935274674192719}
2023-01-04 08:14:24,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:24,561 INFO:     Epoch: 71
2023-01-04 08:14:26,137 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40918203194936115, 'Total loss': 0.40918203194936115} | train loss {'Reaction outcome loss': 0.3054116240878036, 'Total loss': 0.3054116240878036}
2023-01-04 08:14:26,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:26,137 INFO:     Epoch: 72
2023-01-04 08:14:27,721 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3449132740497589, 'Total loss': 0.3449132740497589} | train loss {'Reaction outcome loss': 0.3134724088013172, 'Total loss': 0.3134724088013172}
2023-01-04 08:14:27,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:27,721 INFO:     Epoch: 73
2023-01-04 08:14:29,294 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35469858547051747, 'Total loss': 0.35469858547051747} | train loss {'Reaction outcome loss': 0.30048153843128367, 'Total loss': 0.30048153843128367}
2023-01-04 08:14:29,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:29,294 INFO:     Epoch: 74
2023-01-04 08:14:30,835 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3696616490681966, 'Total loss': 0.3696616490681966} | train loss {'Reaction outcome loss': 0.28895565111905447, 'Total loss': 0.28895565111905447}
2023-01-04 08:14:30,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:30,837 INFO:     Epoch: 75
2023-01-04 08:14:32,409 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3713827480872472, 'Total loss': 0.3713827480872472} | train loss {'Reaction outcome loss': 0.2874933995873384, 'Total loss': 0.2874933995873384}
2023-01-04 08:14:32,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:32,409 INFO:     Epoch: 76
2023-01-04 08:14:33,939 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40236729979515073, 'Total loss': 0.40236729979515073} | train loss {'Reaction outcome loss': 0.2873780720367812, 'Total loss': 0.2873780720367812}
2023-01-04 08:14:33,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:33,940 INFO:     Epoch: 77
2023-01-04 08:14:35,503 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3663105676571528, 'Total loss': 0.3663105676571528} | train loss {'Reaction outcome loss': 0.2886279399263794, 'Total loss': 0.2886279399263794}
2023-01-04 08:14:35,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:35,503 INFO:     Epoch: 78
2023-01-04 08:14:37,078 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.339985583225886, 'Total loss': 0.339985583225886} | train loss {'Reaction outcome loss': 0.2892307729499948, 'Total loss': 0.2892307729499948}
2023-01-04 08:14:37,079 INFO:     Found new best model at epoch 78
2023-01-04 08:14:37,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:37,080 INFO:     Epoch: 79
2023-01-04 08:14:38,657 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34938885072867076, 'Total loss': 0.34938885072867076} | train loss {'Reaction outcome loss': 0.28407827185372403, 'Total loss': 0.28407827185372403}
2023-01-04 08:14:38,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:38,657 INFO:     Epoch: 80
2023-01-04 08:14:40,212 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.33707991739114124, 'Total loss': 0.33707991739114124} | train loss {'Reaction outcome loss': 0.28740800439339614, 'Total loss': 0.28740800439339614}
2023-01-04 08:14:40,212 INFO:     Found new best model at epoch 80
2023-01-04 08:14:40,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:40,213 INFO:     Epoch: 81
2023-01-04 08:14:41,811 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3895517960190773, 'Total loss': 0.3895517960190773} | train loss {'Reaction outcome loss': 0.31345550472969597, 'Total loss': 0.31345550472969597}
2023-01-04 08:14:41,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:41,812 INFO:     Epoch: 82
2023-01-04 08:14:43,376 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3471571591993173, 'Total loss': 0.3471571591993173} | train loss {'Reaction outcome loss': 0.28583962263782386, 'Total loss': 0.28583962263782386}
2023-01-04 08:14:43,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:43,377 INFO:     Epoch: 83
2023-01-04 08:14:44,973 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37284648021062217, 'Total loss': 0.37284648021062217} | train loss {'Reaction outcome loss': 0.2969437008858591, 'Total loss': 0.2969437008858591}
2023-01-04 08:14:44,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:44,973 INFO:     Epoch: 84
2023-01-04 08:14:46,565 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37507937649885814, 'Total loss': 0.37507937649885814} | train loss {'Reaction outcome loss': 0.3837744653413909, 'Total loss': 0.3837744653413909}
2023-01-04 08:14:46,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:46,565 INFO:     Epoch: 85
2023-01-04 08:14:48,166 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35802961389223736, 'Total loss': 0.35802961389223736} | train loss {'Reaction outcome loss': 0.2971489333625262, 'Total loss': 0.2971489333625262}
2023-01-04 08:14:48,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:48,168 INFO:     Epoch: 86
2023-01-04 08:14:49,740 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3515144734332959, 'Total loss': 0.3515144734332959} | train loss {'Reaction outcome loss': 0.28594191426384274, 'Total loss': 0.28594191426384274}
2023-01-04 08:14:49,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:49,740 INFO:     Epoch: 87
2023-01-04 08:14:51,333 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3506564726432165, 'Total loss': 0.3506564726432165} | train loss {'Reaction outcome loss': 0.28917500922334904, 'Total loss': 0.28917500922334904}
2023-01-04 08:14:51,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:51,333 INFO:     Epoch: 88
2023-01-04 08:14:52,902 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35035332043965656, 'Total loss': 0.35035332043965656} | train loss {'Reaction outcome loss': 0.27671884070825425, 'Total loss': 0.27671884070825425}
2023-01-04 08:14:52,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:52,903 INFO:     Epoch: 89
2023-01-04 08:14:54,502 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3573133004208406, 'Total loss': 0.3573133004208406} | train loss {'Reaction outcome loss': 0.2790451690662598, 'Total loss': 0.2790451690662598}
2023-01-04 08:14:54,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:54,504 INFO:     Epoch: 90
2023-01-04 08:14:56,100 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36242540876070656, 'Total loss': 0.36242540876070656} | train loss {'Reaction outcome loss': 0.28103855710503634, 'Total loss': 0.28103855710503634}
2023-01-04 08:14:56,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:56,100 INFO:     Epoch: 91
2023-01-04 08:14:57,691 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34217915137608845, 'Total loss': 0.34217915137608845} | train loss {'Reaction outcome loss': 0.27691850522398087, 'Total loss': 0.27691850522398087}
2023-01-04 08:14:57,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:57,692 INFO:     Epoch: 92
2023-01-04 08:14:59,265 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37463228901227313, 'Total loss': 0.37463228901227313} | train loss {'Reaction outcome loss': 0.27565406850012747, 'Total loss': 0.27565406850012747}
2023-01-04 08:14:59,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:14:59,266 INFO:     Epoch: 93
2023-01-04 08:15:00,829 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3345476080973943, 'Total loss': 0.3345476080973943} | train loss {'Reaction outcome loss': 0.2869994944493806, 'Total loss': 0.2869994944493806}
2023-01-04 08:15:00,831 INFO:     Found new best model at epoch 93
2023-01-04 08:15:00,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:00,832 INFO:     Epoch: 94
2023-01-04 08:15:02,429 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3509650667508443, 'Total loss': 0.3509650667508443} | train loss {'Reaction outcome loss': 0.28520966126866965, 'Total loss': 0.28520966126866965}
2023-01-04 08:15:02,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:02,429 INFO:     Epoch: 95
2023-01-04 08:15:04,028 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35738821228345236, 'Total loss': 0.35738821228345236} | train loss {'Reaction outcome loss': 0.3300716416860519, 'Total loss': 0.3300716416860519}
2023-01-04 08:15:04,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:04,028 INFO:     Epoch: 96
2023-01-04 08:15:05,638 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34238288601239525, 'Total loss': 0.34238288601239525} | train loss {'Reaction outcome loss': 0.2761208220784191, 'Total loss': 0.2761208220784191}
2023-01-04 08:15:05,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:05,639 INFO:     Epoch: 97
2023-01-04 08:15:07,248 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.32872688670953115, 'Total loss': 0.32872688670953115} | train loss {'Reaction outcome loss': 0.2732274265479586, 'Total loss': 0.2732274265479586}
2023-01-04 08:15:07,249 INFO:     Found new best model at epoch 97
2023-01-04 08:15:07,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:07,250 INFO:     Epoch: 98
2023-01-04 08:15:08,834 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3699541032314301, 'Total loss': 0.3699541032314301} | train loss {'Reaction outcome loss': 0.2900072927519247, 'Total loss': 0.2900072927519247}
2023-01-04 08:15:08,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:08,834 INFO:     Epoch: 99
2023-01-04 08:15:10,404 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3709450920422872, 'Total loss': 0.3709450920422872} | train loss {'Reaction outcome loss': 0.2891946319436681, 'Total loss': 0.2891946319436681}
2023-01-04 08:15:10,405 INFO:     Best model found after epoch 98 of 100.
2023-01-04 08:15:10,405 INFO:   Done with stage: TRAINING
2023-01-04 08:15:10,405 INFO:   Starting stage: EVALUATION
2023-01-04 08:15:10,537 INFO:   Done with stage: EVALUATION
2023-01-04 08:15:10,538 INFO:   Leaving out SEQ value Fold_1
2023-01-04 08:15:10,550 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 08:15:10,550 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:15:11,201 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:15:11,201 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:15:11,269 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:15:11,270 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:15:11,270 INFO:     No hyperparam tuning for this model
2023-01-04 08:15:11,270 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:15:11,270 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:15:11,270 INFO:     None feature selector for col prot
2023-01-04 08:15:11,271 INFO:     None feature selector for col prot
2023-01-04 08:15:11,271 INFO:     None feature selector for col prot
2023-01-04 08:15:11,271 INFO:     None feature selector for col chem
2023-01-04 08:15:11,271 INFO:     None feature selector for col chem
2023-01-04 08:15:11,271 INFO:     None feature selector for col chem
2023-01-04 08:15:11,271 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:15:11,272 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:15:11,272 INFO:     Number of params in model 70111
2023-01-04 08:15:11,276 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:15:11,276 INFO:   Starting stage: TRAINING
2023-01-04 08:15:11,318 INFO:     Val loss before train {'Reaction outcome loss': 1.03892289797465, 'Total loss': 1.03892289797465}
2023-01-04 08:15:11,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:11,318 INFO:     Epoch: 0
2023-01-04 08:15:12,917 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7426502207914988, 'Total loss': 0.7426502207914988} | train loss {'Reaction outcome loss': 0.8456824651338916, 'Total loss': 0.8456824651338916}
2023-01-04 08:15:12,918 INFO:     Found new best model at epoch 0
2023-01-04 08:15:12,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:12,919 INFO:     Epoch: 1
2023-01-04 08:15:14,515 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.595891825358073, 'Total loss': 0.595891825358073} | train loss {'Reaction outcome loss': 0.7046349318023177, 'Total loss': 0.7046349318023177}
2023-01-04 08:15:14,515 INFO:     Found new best model at epoch 1
2023-01-04 08:15:14,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:14,516 INFO:     Epoch: 2
2023-01-04 08:15:16,119 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5784492512543996, 'Total loss': 0.5784492512543996} | train loss {'Reaction outcome loss': 0.5905121559466141, 'Total loss': 0.5905121559466141}
2023-01-04 08:15:16,120 INFO:     Found new best model at epoch 2
2023-01-04 08:15:16,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:16,120 INFO:     Epoch: 3
2023-01-04 08:15:17,657 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5174894839525223, 'Total loss': 0.5174894839525223} | train loss {'Reaction outcome loss': 0.5479575450113718, 'Total loss': 0.5479575450113718}
2023-01-04 08:15:17,657 INFO:     Found new best model at epoch 3
2023-01-04 08:15:17,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:17,658 INFO:     Epoch: 4
2023-01-04 08:15:19,229 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5619221200545629, 'Total loss': 0.5619221200545629} | train loss {'Reaction outcome loss': 0.5192650247405729, 'Total loss': 0.5192650247405729}
2023-01-04 08:15:19,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:19,230 INFO:     Epoch: 5
2023-01-04 08:15:20,831 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5037763098875682, 'Total loss': 0.5037763098875682} | train loss {'Reaction outcome loss': 0.5016090793406888, 'Total loss': 0.5016090793406888}
2023-01-04 08:15:20,831 INFO:     Found new best model at epoch 5
2023-01-04 08:15:20,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:20,832 INFO:     Epoch: 6
2023-01-04 08:15:22,414 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48930712342262267, 'Total loss': 0.48930712342262267} | train loss {'Reaction outcome loss': 0.48663684186876577, 'Total loss': 0.48663684186876577}
2023-01-04 08:15:22,414 INFO:     Found new best model at epoch 6
2023-01-04 08:15:22,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:22,415 INFO:     Epoch: 7
2023-01-04 08:15:24,023 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47709264357884723, 'Total loss': 0.47709264357884723} | train loss {'Reaction outcome loss': 0.47853555308951845, 'Total loss': 0.47853555308951845}
2023-01-04 08:15:24,023 INFO:     Found new best model at epoch 7
2023-01-04 08:15:24,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:24,024 INFO:     Epoch: 8
2023-01-04 08:15:25,615 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5084153612454733, 'Total loss': 0.5084153612454733} | train loss {'Reaction outcome loss': 0.47481262588036666, 'Total loss': 0.47481262588036666}
2023-01-04 08:15:25,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:25,617 INFO:     Epoch: 9
2023-01-04 08:15:27,170 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4853285272916158, 'Total loss': 0.4853285272916158} | train loss {'Reaction outcome loss': 0.47635211903547897, 'Total loss': 0.47635211903547897}
2023-01-04 08:15:27,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:27,170 INFO:     Epoch: 10
2023-01-04 08:15:28,699 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45727531214555106, 'Total loss': 0.45727531214555106} | train loss {'Reaction outcome loss': 0.4695704818519888, 'Total loss': 0.4695704818519888}
2023-01-04 08:15:28,699 INFO:     Found new best model at epoch 10
2023-01-04 08:15:28,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:28,700 INFO:     Epoch: 11
2023-01-04 08:15:30,255 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5108851810296376, 'Total loss': 0.5108851810296376} | train loss {'Reaction outcome loss': 0.4584416750130122, 'Total loss': 0.4584416750130122}
2023-01-04 08:15:30,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:30,255 INFO:     Epoch: 12
2023-01-04 08:15:31,819 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46988189419110615, 'Total loss': 0.46988189419110615} | train loss {'Reaction outcome loss': 0.45339498280183127, 'Total loss': 0.45339498280183127}
2023-01-04 08:15:31,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:31,821 INFO:     Epoch: 13
2023-01-04 08:15:33,369 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4568186620871226, 'Total loss': 0.4568186620871226} | train loss {'Reaction outcome loss': 0.45067356619744015, 'Total loss': 0.45067356619744015}
2023-01-04 08:15:33,369 INFO:     Found new best model at epoch 13
2023-01-04 08:15:33,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:33,370 INFO:     Epoch: 14
2023-01-04 08:15:34,930 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44788989226023357, 'Total loss': 0.44788989226023357} | train loss {'Reaction outcome loss': 0.45564200459183124, 'Total loss': 0.45564200459183124}
2023-01-04 08:15:34,930 INFO:     Found new best model at epoch 14
2023-01-04 08:15:34,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:34,931 INFO:     Epoch: 15
2023-01-04 08:15:36,444 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47623555064201356, 'Total loss': 0.47623555064201356} | train loss {'Reaction outcome loss': 0.46789409523025033, 'Total loss': 0.46789409523025033}
2023-01-04 08:15:36,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:36,444 INFO:     Epoch: 16
2023-01-04 08:15:38,002 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45293075243631997, 'Total loss': 0.45293075243631997} | train loss {'Reaction outcome loss': 0.4393934575149931, 'Total loss': 0.4393934575149931}
2023-01-04 08:15:38,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:38,003 INFO:     Epoch: 17
2023-01-04 08:15:39,566 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43926920294761657, 'Total loss': 0.43926920294761657} | train loss {'Reaction outcome loss': 0.43278061662103806, 'Total loss': 0.43278061662103806}
2023-01-04 08:15:39,566 INFO:     Found new best model at epoch 17
2023-01-04 08:15:39,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:39,567 INFO:     Epoch: 18
2023-01-04 08:15:41,147 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4615293562412262, 'Total loss': 0.4615293562412262} | train loss {'Reaction outcome loss': 0.42774045819160034, 'Total loss': 0.42774045819160034}
2023-01-04 08:15:41,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:41,147 INFO:     Epoch: 19
2023-01-04 08:15:42,712 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4380689193805059, 'Total loss': 0.4380689193805059} | train loss {'Reaction outcome loss': 0.42077611224806827, 'Total loss': 0.42077611224806827}
2023-01-04 08:15:42,712 INFO:     Found new best model at epoch 19
2023-01-04 08:15:42,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:42,713 INFO:     Epoch: 20
2023-01-04 08:15:44,268 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4392215311527252, 'Total loss': 0.4392215311527252} | train loss {'Reaction outcome loss': 0.41839210190337855, 'Total loss': 0.41839210190337855}
2023-01-04 08:15:44,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:44,269 INFO:     Epoch: 21
2023-01-04 08:15:45,765 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4410812864700953, 'Total loss': 0.4410812864700953} | train loss {'Reaction outcome loss': 0.41150817412046203, 'Total loss': 0.41150817412046203}
2023-01-04 08:15:45,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:45,765 INFO:     Epoch: 22
2023-01-04 08:15:47,346 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4160736014445623, 'Total loss': 0.4160736014445623} | train loss {'Reaction outcome loss': 0.4119338631374185, 'Total loss': 0.4119338631374185}
2023-01-04 08:15:47,346 INFO:     Found new best model at epoch 22
2023-01-04 08:15:47,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:47,347 INFO:     Epoch: 23
2023-01-04 08:15:48,906 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4303617258866628, 'Total loss': 0.4303617258866628} | train loss {'Reaction outcome loss': 0.4080868541276541, 'Total loss': 0.4080868541276541}
2023-01-04 08:15:48,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:48,907 INFO:     Epoch: 24
2023-01-04 08:15:50,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41786923011144, 'Total loss': 0.41786923011144} | train loss {'Reaction outcome loss': 0.4063110289052534, 'Total loss': 0.4063110289052534}
2023-01-04 08:15:50,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:50,479 INFO:     Epoch: 25
2023-01-04 08:15:52,043 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44307866593201956, 'Total loss': 0.44307866593201956} | train loss {'Reaction outcome loss': 0.39923621461713227, 'Total loss': 0.39923621461713227}
2023-01-04 08:15:52,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:52,043 INFO:     Epoch: 26
2023-01-04 08:15:53,574 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46518318057060243, 'Total loss': 0.46518318057060243} | train loss {'Reaction outcome loss': 0.3978310299672834, 'Total loss': 0.3978310299672834}
2023-01-04 08:15:53,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:53,575 INFO:     Epoch: 27
2023-01-04 08:15:55,128 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4250310222307841, 'Total loss': 0.4250310222307841} | train loss {'Reaction outcome loss': 0.3851517886127956, 'Total loss': 0.3851517886127956}
2023-01-04 08:15:55,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:55,128 INFO:     Epoch: 28
2023-01-04 08:15:56,721 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4119412754972776, 'Total loss': 0.4119412754972776} | train loss {'Reaction outcome loss': 0.38605203938441, 'Total loss': 0.38605203938441}
2023-01-04 08:15:56,723 INFO:     Found new best model at epoch 28
2023-01-04 08:15:56,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:56,723 INFO:     Epoch: 29
2023-01-04 08:15:58,277 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4025537600119909, 'Total loss': 0.4025537600119909} | train loss {'Reaction outcome loss': 0.3851657853077125, 'Total loss': 0.3851657853077125}
2023-01-04 08:15:58,277 INFO:     Found new best model at epoch 29
2023-01-04 08:15:58,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:58,278 INFO:     Epoch: 30
2023-01-04 08:15:59,856 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39963237643241883, 'Total loss': 0.39963237643241883} | train loss {'Reaction outcome loss': 0.3793190126121719, 'Total loss': 0.3793190126121719}
2023-01-04 08:15:59,856 INFO:     Found new best model at epoch 30
2023-01-04 08:15:59,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:15:59,857 INFO:     Epoch: 31
2023-01-04 08:16:01,452 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3996830532948176, 'Total loss': 0.3996830532948176} | train loss {'Reaction outcome loss': 0.373154036241813, 'Total loss': 0.373154036241813}
2023-01-04 08:16:01,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:01,452 INFO:     Epoch: 32
2023-01-04 08:16:02,975 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4009535402059555, 'Total loss': 0.4009535402059555} | train loss {'Reaction outcome loss': 0.37328716746423446, 'Total loss': 0.37328716746423446}
2023-01-04 08:16:02,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:02,976 INFO:     Epoch: 33
2023-01-04 08:16:04,517 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42863076627254487, 'Total loss': 0.42863076627254487} | train loss {'Reaction outcome loss': 0.36914959400926, 'Total loss': 0.36914959400926}
2023-01-04 08:16:04,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:04,517 INFO:     Epoch: 34
2023-01-04 08:16:06,087 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4180678576231003, 'Total loss': 0.4180678576231003} | train loss {'Reaction outcome loss': 0.36419997443242563, 'Total loss': 0.36419997443242563}
2023-01-04 08:16:06,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:06,087 INFO:     Epoch: 35
2023-01-04 08:16:07,646 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42875378429889677, 'Total loss': 0.42875378429889677} | train loss {'Reaction outcome loss': 0.3657357711075009, 'Total loss': 0.3657357711075009}
2023-01-04 08:16:07,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:07,646 INFO:     Epoch: 36
2023-01-04 08:16:09,208 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3917556713024775, 'Total loss': 0.3917556713024775} | train loss {'Reaction outcome loss': 0.36273088538344356, 'Total loss': 0.36273088538344356}
2023-01-04 08:16:09,209 INFO:     Found new best model at epoch 36
2023-01-04 08:16:09,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:09,210 INFO:     Epoch: 37
2023-01-04 08:16:10,776 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4069893678029378, 'Total loss': 0.4069893678029378} | train loss {'Reaction outcome loss': 0.3568542985940703, 'Total loss': 0.3568542985940703}
2023-01-04 08:16:10,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:10,776 INFO:     Epoch: 38
2023-01-04 08:16:12,312 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42123013039429985, 'Total loss': 0.42123013039429985} | train loss {'Reaction outcome loss': 0.34984628234288073, 'Total loss': 0.34984628234288073}
2023-01-04 08:16:12,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:12,313 INFO:     Epoch: 39
2023-01-04 08:16:13,855 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4249911367893219, 'Total loss': 0.4249911367893219} | train loss {'Reaction outcome loss': 0.3494005350627655, 'Total loss': 0.3494005350627655}
2023-01-04 08:16:13,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:13,855 INFO:     Epoch: 40
2023-01-04 08:16:15,435 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3958626965681712, 'Total loss': 0.3958626965681712} | train loss {'Reaction outcome loss': 0.3440820400306172, 'Total loss': 0.3440820400306172}
2023-01-04 08:16:15,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:15,436 INFO:     Epoch: 41
2023-01-04 08:16:16,997 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4111792186896006, 'Total loss': 0.4111792186896006} | train loss {'Reaction outcome loss': 0.34290823259431386, 'Total loss': 0.34290823259431386}
2023-01-04 08:16:16,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:16,997 INFO:     Epoch: 42
2023-01-04 08:16:18,578 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39365898768107094, 'Total loss': 0.39365898768107094} | train loss {'Reaction outcome loss': 0.33883253198818886, 'Total loss': 0.33883253198818886}
2023-01-04 08:16:18,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:18,578 INFO:     Epoch: 43
2023-01-04 08:16:20,152 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41959682206312815, 'Total loss': 0.41959682206312815} | train loss {'Reaction outcome loss': 0.3350012375470386, 'Total loss': 0.3350012375470386}
2023-01-04 08:16:20,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:20,154 INFO:     Epoch: 44
2023-01-04 08:16:21,696 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4008799582719803, 'Total loss': 0.4008799582719803} | train loss {'Reaction outcome loss': 0.3379701591780225, 'Total loss': 0.3379701591780225}
2023-01-04 08:16:21,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:21,696 INFO:     Epoch: 45
2023-01-04 08:16:23,244 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3815558562676112, 'Total loss': 0.3815558562676112} | train loss {'Reaction outcome loss': 0.3297467274672311, 'Total loss': 0.3297467274672311}
2023-01-04 08:16:23,244 INFO:     Found new best model at epoch 45
2023-01-04 08:16:23,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:23,245 INFO:     Epoch: 46
2023-01-04 08:16:24,842 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4081762691338857, 'Total loss': 0.4081762691338857} | train loss {'Reaction outcome loss': 0.3313280295705477, 'Total loss': 0.3313280295705477}
2023-01-04 08:16:24,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:24,842 INFO:     Epoch: 47
2023-01-04 08:16:26,450 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4268579741319021, 'Total loss': 0.4268579741319021} | train loss {'Reaction outcome loss': 0.32775985566980165, 'Total loss': 0.32775985566980165}
2023-01-04 08:16:26,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:26,452 INFO:     Epoch: 48
2023-01-04 08:16:28,024 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4448630621035894, 'Total loss': 0.4448630621035894} | train loss {'Reaction outcome loss': 0.3238540537743087, 'Total loss': 0.3238540537743087}
2023-01-04 08:16:28,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:28,024 INFO:     Epoch: 49
2023-01-04 08:16:29,625 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3912138730287552, 'Total loss': 0.3912138730287552} | train loss {'Reaction outcome loss': 0.3197448612141222, 'Total loss': 0.3197448612141222}
2023-01-04 08:16:29,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:29,625 INFO:     Epoch: 50
2023-01-04 08:16:31,126 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39104590664307276, 'Total loss': 0.39104590664307276} | train loss {'Reaction outcome loss': 0.3186533472676208, 'Total loss': 0.3186533472676208}
2023-01-04 08:16:31,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:31,126 INFO:     Epoch: 51
2023-01-04 08:16:32,727 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36741930345694224, 'Total loss': 0.36741930345694224} | train loss {'Reaction outcome loss': 0.32096610928630875, 'Total loss': 0.32096610928630875}
2023-01-04 08:16:32,728 INFO:     Found new best model at epoch 51
2023-01-04 08:16:32,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:32,729 INFO:     Epoch: 52
2023-01-04 08:16:34,337 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3940797299146652, 'Total loss': 0.3940797299146652} | train loss {'Reaction outcome loss': 0.31725154621391627, 'Total loss': 0.31725154621391627}
2023-01-04 08:16:34,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:34,337 INFO:     Epoch: 53
2023-01-04 08:16:35,970 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37551488280296325, 'Total loss': 0.37551488280296325} | train loss {'Reaction outcome loss': 0.3118454825025106, 'Total loss': 0.3118454825025106}
2023-01-04 08:16:35,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:35,970 INFO:     Epoch: 54
2023-01-04 08:16:37,572 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3868894169727961, 'Total loss': 0.3868894169727961} | train loss {'Reaction outcome loss': 0.32168384530730004, 'Total loss': 0.32168384530730004}
2023-01-04 08:16:37,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:37,572 INFO:     Epoch: 55
2023-01-04 08:16:39,142 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4093343983093897, 'Total loss': 0.4093343983093897} | train loss {'Reaction outcome loss': 0.31359771295894356, 'Total loss': 0.31359771295894356}
2023-01-04 08:16:39,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:39,143 INFO:     Epoch: 56
2023-01-04 08:16:40,702 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39969749450683595, 'Total loss': 0.39969749450683595} | train loss {'Reaction outcome loss': 0.3067388779912279, 'Total loss': 0.3067388779912279}
2023-01-04 08:16:40,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:40,703 INFO:     Epoch: 57
2023-01-04 08:16:42,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36625318638980386, 'Total loss': 0.36625318638980386} | train loss {'Reaction outcome loss': 0.30381942592140293, 'Total loss': 0.30381942592140293}
2023-01-04 08:16:42,293 INFO:     Found new best model at epoch 57
2023-01-04 08:16:42,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:42,294 INFO:     Epoch: 58
2023-01-04 08:16:43,873 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46396040817101797, 'Total loss': 0.46396040817101797} | train loss {'Reaction outcome loss': 0.30105489601576835, 'Total loss': 0.30105489601576835}
2023-01-04 08:16:43,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:43,873 INFO:     Epoch: 59
2023-01-04 08:16:45,469 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38762732644875847, 'Total loss': 0.38762732644875847} | train loss {'Reaction outcome loss': 0.30029985072547605, 'Total loss': 0.30029985072547605}
2023-01-04 08:16:45,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:45,470 INFO:     Epoch: 60
2023-01-04 08:16:47,061 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41270308891932167, 'Total loss': 0.41270308891932167} | train loss {'Reaction outcome loss': 0.30324291213806986, 'Total loss': 0.30324291213806986}
2023-01-04 08:16:47,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:47,061 INFO:     Epoch: 61
2023-01-04 08:16:48,620 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3821628987789154, 'Total loss': 0.3821628987789154} | train loss {'Reaction outcome loss': 0.34458873666606954, 'Total loss': 0.34458873666606954}
2023-01-04 08:16:48,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:48,621 INFO:     Epoch: 62
2023-01-04 08:16:50,197 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36972037255764006, 'Total loss': 0.36972037255764006} | train loss {'Reaction outcome loss': 0.30242566457288206, 'Total loss': 0.30242566457288206}
2023-01-04 08:16:50,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:50,198 INFO:     Epoch: 63
2023-01-04 08:16:51,796 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3865271786848704, 'Total loss': 0.3865271786848704} | train loss {'Reaction outcome loss': 0.2977840850143221, 'Total loss': 0.2977840850143221}
2023-01-04 08:16:51,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:51,798 INFO:     Epoch: 64
2023-01-04 08:16:53,369 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.379981592297554, 'Total loss': 0.379981592297554} | train loss {'Reaction outcome loss': 0.29817498626484384, 'Total loss': 0.29817498626484384}
2023-01-04 08:16:53,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:53,370 INFO:     Epoch: 65
2023-01-04 08:16:54,949 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3917842636505763, 'Total loss': 0.3917842636505763} | train loss {'Reaction outcome loss': 0.3041821460246338, 'Total loss': 0.3041821460246338}
2023-01-04 08:16:54,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:54,949 INFO:     Epoch: 66
2023-01-04 08:16:56,512 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39817137519518536, 'Total loss': 0.39817137519518536} | train loss {'Reaction outcome loss': 0.29264655943278334, 'Total loss': 0.29264655943278334}
2023-01-04 08:16:56,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:56,513 INFO:     Epoch: 67
2023-01-04 08:16:58,038 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39770455757776896, 'Total loss': 0.39770455757776896} | train loss {'Reaction outcome loss': 0.2882927096840264, 'Total loss': 0.2882927096840264}
2023-01-04 08:16:58,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:58,038 INFO:     Epoch: 68
2023-01-04 08:16:59,554 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41249850889046985, 'Total loss': 0.41249850889046985} | train loss {'Reaction outcome loss': 0.2984277514497871, 'Total loss': 0.2984277514497871}
2023-01-04 08:16:59,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:16:59,554 INFO:     Epoch: 69
2023-01-04 08:17:01,100 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3806589146455129, 'Total loss': 0.3806589146455129} | train loss {'Reaction outcome loss': 0.3208955366390528, 'Total loss': 0.3208955366390528}
2023-01-04 08:17:01,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:01,100 INFO:     Epoch: 70
2023-01-04 08:17:02,659 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.403060848514239, 'Total loss': 0.403060848514239} | train loss {'Reaction outcome loss': 0.28946978070450935, 'Total loss': 0.28946978070450935}
2023-01-04 08:17:02,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:02,660 INFO:     Epoch: 71
2023-01-04 08:17:04,214 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3926914761463801, 'Total loss': 0.3926914761463801} | train loss {'Reaction outcome loss': 0.2836795811932804, 'Total loss': 0.2836795811932804}
2023-01-04 08:17:04,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:04,214 INFO:     Epoch: 72
2023-01-04 08:17:05,765 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4083209176858266, 'Total loss': 0.4083209176858266} | train loss {'Reaction outcome loss': 0.3000541965779174, 'Total loss': 0.3000541965779174}
2023-01-04 08:17:05,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:05,765 INFO:     Epoch: 73
2023-01-04 08:17:07,283 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3717587560415268, 'Total loss': 0.3717587560415268} | train loss {'Reaction outcome loss': 0.28491082015460817, 'Total loss': 0.28491082015460817}
2023-01-04 08:17:07,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:07,283 INFO:     Epoch: 74
2023-01-04 08:17:08,826 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35899099906285603, 'Total loss': 0.35899099906285603} | train loss {'Reaction outcome loss': 0.27738543588708603, 'Total loss': 0.27738543588708603}
2023-01-04 08:17:08,827 INFO:     Found new best model at epoch 74
2023-01-04 08:17:08,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:08,828 INFO:     Epoch: 75
2023-01-04 08:17:10,402 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3818642020225525, 'Total loss': 0.3818642020225525} | train loss {'Reaction outcome loss': 0.2782868419274472, 'Total loss': 0.2782868419274472}
2023-01-04 08:17:10,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:10,402 INFO:     Epoch: 76
2023-01-04 08:17:11,964 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44986719091733296, 'Total loss': 0.44986719091733296} | train loss {'Reaction outcome loss': 0.30493328065705905, 'Total loss': 0.30493328065705905}
2023-01-04 08:17:11,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:11,964 INFO:     Epoch: 77
2023-01-04 08:17:13,528 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.388613693912824, 'Total loss': 0.388613693912824} | train loss {'Reaction outcome loss': 0.33327234197117767, 'Total loss': 0.33327234197117767}
2023-01-04 08:17:13,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:13,528 INFO:     Epoch: 78
2023-01-04 08:17:15,063 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38667813539505, 'Total loss': 0.38667813539505} | train loss {'Reaction outcome loss': 0.29550462332216726, 'Total loss': 0.29550462332216726}
2023-01-04 08:17:15,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:15,065 INFO:     Epoch: 79
2023-01-04 08:17:16,576 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38570270538330076, 'Total loss': 0.38570270538330076} | train loss {'Reaction outcome loss': 0.28576333560994355, 'Total loss': 0.28576333560994355}
2023-01-04 08:17:16,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:16,576 INFO:     Epoch: 80
2023-01-04 08:17:18,142 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43223130305608115, 'Total loss': 0.43223130305608115} | train loss {'Reaction outcome loss': 0.2765200124029012, 'Total loss': 0.2765200124029012}
2023-01-04 08:17:18,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:18,142 INFO:     Epoch: 81
2023-01-04 08:17:19,694 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35979730586210884, 'Total loss': 0.35979730586210884} | train loss {'Reaction outcome loss': 0.27380105825579737, 'Total loss': 0.27380105825579737}
2023-01-04 08:17:19,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:19,694 INFO:     Epoch: 82
2023-01-04 08:17:21,234 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37570217351118723, 'Total loss': 0.37570217351118723} | train loss {'Reaction outcome loss': 0.2720746120734923, 'Total loss': 0.2720746120734923}
2023-01-04 08:17:21,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:21,236 INFO:     Epoch: 83
2023-01-04 08:17:22,812 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38026583890120186, 'Total loss': 0.38026583890120186} | train loss {'Reaction outcome loss': 0.271631413229456, 'Total loss': 0.271631413229456}
2023-01-04 08:17:22,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:22,812 INFO:     Epoch: 84
2023-01-04 08:17:24,355 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36372701327006024, 'Total loss': 0.36372701327006024} | train loss {'Reaction outcome loss': 0.27072021981998196, 'Total loss': 0.27072021981998196}
2023-01-04 08:17:24,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:24,355 INFO:     Epoch: 85
2023-01-04 08:17:25,901 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3808408742149671, 'Total loss': 0.3808408742149671} | train loss {'Reaction outcome loss': 0.2689221948705803, 'Total loss': 0.2689221948705803}
2023-01-04 08:17:25,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:25,901 INFO:     Epoch: 86
2023-01-04 08:17:27,464 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39103734691937764, 'Total loss': 0.39103734691937764} | train loss {'Reaction outcome loss': 0.26731424793715763, 'Total loss': 0.26731424793715763}
2023-01-04 08:17:27,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:27,465 INFO:     Epoch: 87
2023-01-04 08:17:29,034 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39529236952463787, 'Total loss': 0.39529236952463787} | train loss {'Reaction outcome loss': 0.2674218551458224, 'Total loss': 0.2674218551458224}
2023-01-04 08:17:29,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:29,034 INFO:     Epoch: 88
2023-01-04 08:17:30,635 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40855968197186787, 'Total loss': 0.40855968197186787} | train loss {'Reaction outcome loss': 0.27481561164840707, 'Total loss': 0.27481561164840707}
2023-01-04 08:17:30,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:30,636 INFO:     Epoch: 89
2023-01-04 08:17:32,189 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39675869743029274, 'Total loss': 0.39675869743029274} | train loss {'Reaction outcome loss': 0.2592836543276528, 'Total loss': 0.2592836543276528}
2023-01-04 08:17:32,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:32,189 INFO:     Epoch: 90
2023-01-04 08:17:33,712 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3636069784561793, 'Total loss': 0.3636069784561793} | train loss {'Reaction outcome loss': 0.2614149305416082, 'Total loss': 0.2614149305416082}
2023-01-04 08:17:33,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:33,713 INFO:     Epoch: 91
2023-01-04 08:17:35,246 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3806915352741877, 'Total loss': 0.3806915352741877} | train loss {'Reaction outcome loss': 0.2602463319561903, 'Total loss': 0.2602463319561903}
2023-01-04 08:17:35,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:35,247 INFO:     Epoch: 92
2023-01-04 08:17:36,805 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39972176651159924, 'Total loss': 0.39972176651159924} | train loss {'Reaction outcome loss': 0.2580374806927031, 'Total loss': 0.2580374806927031}
2023-01-04 08:17:36,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:36,805 INFO:     Epoch: 93
2023-01-04 08:17:38,394 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3767400413751602, 'Total loss': 0.3767400413751602} | train loss {'Reaction outcome loss': 0.25785678160120395, 'Total loss': 0.25785678160120395}
2023-01-04 08:17:38,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:38,394 INFO:     Epoch: 94
2023-01-04 08:17:39,973 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4036949793497721, 'Total loss': 0.4036949793497721} | train loss {'Reaction outcome loss': 0.2499314987851877, 'Total loss': 0.2499314987851877}
2023-01-04 08:17:39,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:39,974 INFO:     Epoch: 95
2023-01-04 08:17:41,560 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3552995299299558, 'Total loss': 0.3552995299299558} | train loss {'Reaction outcome loss': 0.25609999511515774, 'Total loss': 0.25609999511515774}
2023-01-04 08:17:41,560 INFO:     Found new best model at epoch 95
2023-01-04 08:17:41,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:41,561 INFO:     Epoch: 96
2023-01-04 08:17:43,112 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3689556986093521, 'Total loss': 0.3689556986093521} | train loss {'Reaction outcome loss': 0.2582700156448139, 'Total loss': 0.2582700156448139}
2023-01-04 08:17:43,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:43,112 INFO:     Epoch: 97
2023-01-04 08:17:44,650 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4224957297245661, 'Total loss': 0.4224957297245661} | train loss {'Reaction outcome loss': 0.26747013218160987, 'Total loss': 0.26747013218160987}
2023-01-04 08:17:44,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:44,650 INFO:     Epoch: 98
2023-01-04 08:17:46,225 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40492198169231414, 'Total loss': 0.40492198169231414} | train loss {'Reaction outcome loss': 0.3259482232860519, 'Total loss': 0.3259482232860519}
2023-01-04 08:17:46,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:46,226 INFO:     Epoch: 99
2023-01-04 08:17:47,805 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3985709796349208, 'Total loss': 0.3985709796349208} | train loss {'Reaction outcome loss': 0.2667587466286563, 'Total loss': 0.2667587466286563}
2023-01-04 08:17:47,805 INFO:     Best model found after epoch 96 of 100.
2023-01-04 08:17:47,805 INFO:   Done with stage: TRAINING
2023-01-04 08:17:47,805 INFO:   Starting stage: EVALUATION
2023-01-04 08:17:47,933 INFO:   Done with stage: EVALUATION
2023-01-04 08:17:47,934 INFO:   Leaving out SEQ value Fold_2
2023-01-04 08:17:47,946 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 08:17:47,947 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:17:48,595 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:17:48,595 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:17:48,662 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:17:48,663 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:17:48,663 INFO:     No hyperparam tuning for this model
2023-01-04 08:17:48,663 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:17:48,663 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:17:48,663 INFO:     None feature selector for col prot
2023-01-04 08:17:48,664 INFO:     None feature selector for col prot
2023-01-04 08:17:48,664 INFO:     None feature selector for col prot
2023-01-04 08:17:48,664 INFO:     None feature selector for col chem
2023-01-04 08:17:48,664 INFO:     None feature selector for col chem
2023-01-04 08:17:48,664 INFO:     None feature selector for col chem
2023-01-04 08:17:48,664 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:17:48,664 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:17:48,665 INFO:     Number of params in model 70111
2023-01-04 08:17:48,669 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:17:48,669 INFO:   Starting stage: TRAINING
2023-01-04 08:17:48,713 INFO:     Val loss before train {'Reaction outcome loss': 1.0768735766410829, 'Total loss': 1.0768735766410829}
2023-01-04 08:17:48,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:48,713 INFO:     Epoch: 0
2023-01-04 08:17:50,302 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7993962327639262, 'Total loss': 0.7993962327639262} | train loss {'Reaction outcome loss': 0.8238025513979105, 'Total loss': 0.8238025513979105}
2023-01-04 08:17:50,303 INFO:     Found new best model at epoch 0
2023-01-04 08:17:50,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:50,303 INFO:     Epoch: 1
2023-01-04 08:17:51,836 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7274547715981802, 'Total loss': 0.7274547715981802} | train loss {'Reaction outcome loss': 0.6764117024102054, 'Total loss': 0.6764117024102054}
2023-01-04 08:17:51,837 INFO:     Found new best model at epoch 1
2023-01-04 08:17:51,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:51,838 INFO:     Epoch: 2
2023-01-04 08:17:53,357 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5971867382526398, 'Total loss': 0.5971867382526398} | train loss {'Reaction outcome loss': 0.5851666896771162, 'Total loss': 0.5851666896771162}
2023-01-04 08:17:53,357 INFO:     Found new best model at epoch 2
2023-01-04 08:17:53,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:53,357 INFO:     Epoch: 3
2023-01-04 08:17:54,926 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6018262187639872, 'Total loss': 0.6018262187639872} | train loss {'Reaction outcome loss': 0.5447874573560861, 'Total loss': 0.5447874573560861}
2023-01-04 08:17:54,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:54,926 INFO:     Epoch: 4
2023-01-04 08:17:56,481 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5630861192941665, 'Total loss': 0.5630861192941665} | train loss {'Reaction outcome loss': 0.5149692231482201, 'Total loss': 0.5149692231482201}
2023-01-04 08:17:56,482 INFO:     Found new best model at epoch 4
2023-01-04 08:17:56,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:56,483 INFO:     Epoch: 5
2023-01-04 08:17:58,033 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5416922668615977, 'Total loss': 0.5416922668615977} | train loss {'Reaction outcome loss': 0.5022985862069951, 'Total loss': 0.5022985862069951}
2023-01-04 08:17:58,033 INFO:     Found new best model at epoch 5
2023-01-04 08:17:58,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:58,034 INFO:     Epoch: 6
2023-01-04 08:17:59,616 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5203149894873301, 'Total loss': 0.5203149894873301} | train loss {'Reaction outcome loss': 0.4896409517570293, 'Total loss': 0.4896409517570293}
2023-01-04 08:17:59,616 INFO:     Found new best model at epoch 6
2023-01-04 08:17:59,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:17:59,617 INFO:     Epoch: 7
2023-01-04 08:18:01,121 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5325624247392019, 'Total loss': 0.5325624247392019} | train loss {'Reaction outcome loss': 0.4801776713722355, 'Total loss': 0.4801776713722355}
2023-01-04 08:18:01,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:01,121 INFO:     Epoch: 8
2023-01-04 08:18:02,634 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5099947333335877, 'Total loss': 0.5099947333335877} | train loss {'Reaction outcome loss': 0.4735871663132867, 'Total loss': 0.4735871663132867}
2023-01-04 08:18:02,635 INFO:     Found new best model at epoch 8
2023-01-04 08:18:02,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:02,636 INFO:     Epoch: 9
2023-01-04 08:18:04,166 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5196596304575603, 'Total loss': 0.5196596304575603} | train loss {'Reaction outcome loss': 0.4654270919797185, 'Total loss': 0.4654270919797185}
2023-01-04 08:18:04,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:04,166 INFO:     Epoch: 10
2023-01-04 08:18:05,706 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5038343628247579, 'Total loss': 0.5038343628247579} | train loss {'Reaction outcome loss': 0.4588573131805811, 'Total loss': 0.4588573131805811}
2023-01-04 08:18:05,706 INFO:     Found new best model at epoch 10
2023-01-04 08:18:05,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:05,707 INFO:     Epoch: 11
2023-01-04 08:18:07,253 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5068586339553197, 'Total loss': 0.5068586339553197} | train loss {'Reaction outcome loss': 0.45528042834975346, 'Total loss': 0.45528042834975346}
2023-01-04 08:18:07,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:07,253 INFO:     Epoch: 12
2023-01-04 08:18:08,807 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5049628168344498, 'Total loss': 0.5049628168344498} | train loss {'Reaction outcome loss': 0.44682627485130294, 'Total loss': 0.44682627485130294}
2023-01-04 08:18:08,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:08,808 INFO:     Epoch: 13
2023-01-04 08:18:10,315 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4988422612349192, 'Total loss': 0.4988422612349192} | train loss {'Reaction outcome loss': 0.43860697991900394, 'Total loss': 0.43860697991900394}
2023-01-04 08:18:10,315 INFO:     Found new best model at epoch 13
2023-01-04 08:18:10,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:10,315 INFO:     Epoch: 14
2023-01-04 08:18:11,835 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48923182090123496, 'Total loss': 0.48923182090123496} | train loss {'Reaction outcome loss': 0.4348576069969834, 'Total loss': 0.4348576069969834}
2023-01-04 08:18:11,835 INFO:     Found new best model at epoch 14
2023-01-04 08:18:11,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:11,836 INFO:     Epoch: 15
2023-01-04 08:18:13,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47656765977541604, 'Total loss': 0.47656765977541604} | train loss {'Reaction outcome loss': 0.4288803219467729, 'Total loss': 0.4288803219467729}
2023-01-04 08:18:13,386 INFO:     Found new best model at epoch 15
2023-01-04 08:18:13,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:13,387 INFO:     Epoch: 16
2023-01-04 08:18:14,934 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47936778018871945, 'Total loss': 0.47936778018871945} | train loss {'Reaction outcome loss': 0.4237973669837246, 'Total loss': 0.4237973669837246}
2023-01-04 08:18:14,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:14,935 INFO:     Epoch: 17
2023-01-04 08:18:16,489 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47829698224862416, 'Total loss': 0.47829698224862416} | train loss {'Reaction outcome loss': 0.4205656196280714, 'Total loss': 0.4205656196280714}
2023-01-04 08:18:16,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:16,489 INFO:     Epoch: 18
2023-01-04 08:18:18,039 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4828999191522598, 'Total loss': 0.4828999191522598} | train loss {'Reaction outcome loss': 0.4153017233579587, 'Total loss': 0.4153017233579587}
2023-01-04 08:18:18,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:18,039 INFO:     Epoch: 19
2023-01-04 08:18:19,536 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4628222073117892, 'Total loss': 0.4628222073117892} | train loss {'Reaction outcome loss': 0.4148824902135374, 'Total loss': 0.4148824902135374}
2023-01-04 08:18:19,537 INFO:     Found new best model at epoch 19
2023-01-04 08:18:19,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:19,537 INFO:     Epoch: 20
2023-01-04 08:18:21,100 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4697497328122457, 'Total loss': 0.4697497328122457} | train loss {'Reaction outcome loss': 0.40473402174182865, 'Total loss': 0.40473402174182865}
2023-01-04 08:18:21,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:21,101 INFO:     Epoch: 21
2023-01-04 08:18:22,681 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47229065696398415, 'Total loss': 0.47229065696398415} | train loss {'Reaction outcome loss': 0.40161027281712264, 'Total loss': 0.40161027281712264}
2023-01-04 08:18:22,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:22,681 INFO:     Epoch: 22
2023-01-04 08:18:24,223 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46731226046880087, 'Total loss': 0.46731226046880087} | train loss {'Reaction outcome loss': 0.3933937361825517, 'Total loss': 0.3933937361825517}
2023-01-04 08:18:24,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:24,224 INFO:     Epoch: 23
2023-01-04 08:18:25,810 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47712231079737344, 'Total loss': 0.47712231079737344} | train loss {'Reaction outcome loss': 0.3916392280368796, 'Total loss': 0.3916392280368796}
2023-01-04 08:18:25,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:25,810 INFO:     Epoch: 24
2023-01-04 08:18:27,332 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47181095282236735, 'Total loss': 0.47181095282236735} | train loss {'Reaction outcome loss': 0.38480031907885937, 'Total loss': 0.38480031907885937}
2023-01-04 08:18:27,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:27,333 INFO:     Epoch: 25
2023-01-04 08:18:28,868 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46691581010818484, 'Total loss': 0.46691581010818484} | train loss {'Reaction outcome loss': 0.38304263536200855, 'Total loss': 0.38304263536200855}
2023-01-04 08:18:28,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:28,869 INFO:     Epoch: 26
2023-01-04 08:18:30,434 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4537514706452688, 'Total loss': 0.4537514706452688} | train loss {'Reaction outcome loss': 0.37742678894773946, 'Total loss': 0.37742678894773946}
2023-01-04 08:18:30,434 INFO:     Found new best model at epoch 26
2023-01-04 08:18:30,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:30,435 INFO:     Epoch: 27
2023-01-04 08:18:32,030 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47866786321004234, 'Total loss': 0.47866786321004234} | train loss {'Reaction outcome loss': 0.3736516489705323, 'Total loss': 0.3736516489705323}
2023-01-04 08:18:32,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:32,030 INFO:     Epoch: 28
2023-01-04 08:18:33,616 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4581819146871567, 'Total loss': 0.4581819146871567} | train loss {'Reaction outcome loss': 0.3708971292872132, 'Total loss': 0.3708971292872132}
2023-01-04 08:18:33,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:33,617 INFO:     Epoch: 29
2023-01-04 08:18:35,183 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46200060049692787, 'Total loss': 0.46200060049692787} | train loss {'Reaction outcome loss': 0.3698985331551933, 'Total loss': 0.3698985331551933}
2023-01-04 08:18:35,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:35,183 INFO:     Epoch: 30
2023-01-04 08:18:36,714 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47794635891914367, 'Total loss': 0.47794635891914367} | train loss {'Reaction outcome loss': 0.3669184322431411, 'Total loss': 0.3669184322431411}
2023-01-04 08:18:36,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:36,715 INFO:     Epoch: 31
2023-01-04 08:18:38,218 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43620612124602, 'Total loss': 0.43620612124602} | train loss {'Reaction outcome loss': 0.3617080213167729, 'Total loss': 0.3617080213167729}
2023-01-04 08:18:38,218 INFO:     Found new best model at epoch 31
2023-01-04 08:18:38,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:38,219 INFO:     Epoch: 32
2023-01-04 08:18:39,756 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4481719007094701, 'Total loss': 0.4481719007094701} | train loss {'Reaction outcome loss': 0.3558727958045163, 'Total loss': 0.3558727958045163}
2023-01-04 08:18:39,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:39,757 INFO:     Epoch: 33
2023-01-04 08:18:41,301 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44718538026014965, 'Total loss': 0.44718538026014965} | train loss {'Reaction outcome loss': 0.35334224373975515, 'Total loss': 0.35334224373975515}
2023-01-04 08:18:41,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:41,301 INFO:     Epoch: 34
2023-01-04 08:18:42,835 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47681527336438495, 'Total loss': 0.47681527336438495} | train loss {'Reaction outcome loss': 0.3518539451526635, 'Total loss': 0.3518539451526635}
2023-01-04 08:18:42,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:42,835 INFO:     Epoch: 35
2023-01-04 08:18:44,402 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4887429674466451, 'Total loss': 0.4887429674466451} | train loss {'Reaction outcome loss': 0.34558332937977687, 'Total loss': 0.34558332937977687}
2023-01-04 08:18:44,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:44,402 INFO:     Epoch: 36
2023-01-04 08:18:45,936 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4664653460184733, 'Total loss': 0.4664653460184733} | train loss {'Reaction outcome loss': 0.34234123677015305, 'Total loss': 0.34234123677015305}
2023-01-04 08:18:45,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:45,937 INFO:     Epoch: 37
2023-01-04 08:18:47,455 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44621435801188153, 'Total loss': 0.44621435801188153} | train loss {'Reaction outcome loss': 0.34128771345693987, 'Total loss': 0.34128771345693987}
2023-01-04 08:18:47,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:47,455 INFO:     Epoch: 38
2023-01-04 08:18:49,024 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.476982569694519, 'Total loss': 0.476982569694519} | train loss {'Reaction outcome loss': 0.3369978497916962, 'Total loss': 0.3369978497916962}
2023-01-04 08:18:49,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:49,024 INFO:     Epoch: 39
2023-01-04 08:18:50,579 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4450205653905869, 'Total loss': 0.4450205653905869} | train loss {'Reaction outcome loss': 0.33704993442628844, 'Total loss': 0.33704993442628844}
2023-01-04 08:18:50,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:50,580 INFO:     Epoch: 40
2023-01-04 08:18:52,148 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4825891067584356, 'Total loss': 0.4825891067584356} | train loss {'Reaction outcome loss': 0.33153409786495097, 'Total loss': 0.33153409786495097}
2023-01-04 08:18:52,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:52,150 INFO:     Epoch: 41
2023-01-04 08:18:53,699 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47868913412094116, 'Total loss': 0.47868913412094116} | train loss {'Reaction outcome loss': 0.3292715288562216, 'Total loss': 0.3292715288562216}
2023-01-04 08:18:53,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:53,699 INFO:     Epoch: 42
2023-01-04 08:18:55,222 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4620007197062174, 'Total loss': 0.4620007197062174} | train loss {'Reaction outcome loss': 0.32998348425923685, 'Total loss': 0.32998348425923685}
2023-01-04 08:18:55,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:55,222 INFO:     Epoch: 43
2023-01-04 08:18:56,748 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44548253615697225, 'Total loss': 0.44548253615697225} | train loss {'Reaction outcome loss': 0.3236771695888959, 'Total loss': 0.3236771695888959}
2023-01-04 08:18:56,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:56,748 INFO:     Epoch: 44
2023-01-04 08:18:58,293 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44909985760847726, 'Total loss': 0.44909985760847726} | train loss {'Reaction outcome loss': 0.31891314120410563, 'Total loss': 0.31891314120410563}
2023-01-04 08:18:58,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:58,295 INFO:     Epoch: 45
2023-01-04 08:18:59,834 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.455339777469635, 'Total loss': 0.455339777469635} | train loss {'Reaction outcome loss': 0.3209237544200359, 'Total loss': 0.3209237544200359}
2023-01-04 08:18:59,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:18:59,834 INFO:     Epoch: 46
2023-01-04 08:19:01,376 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.449814580877622, 'Total loss': 0.449814580877622} | train loss {'Reaction outcome loss': 0.31708017259072035, 'Total loss': 0.31708017259072035}
2023-01-04 08:19:01,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:01,376 INFO:     Epoch: 47
2023-01-04 08:19:02,932 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4602637529373169, 'Total loss': 0.4602637529373169} | train loss {'Reaction outcome loss': 0.3176540296811324, 'Total loss': 0.3176540296811324}
2023-01-04 08:19:02,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:02,934 INFO:     Epoch: 48
2023-01-04 08:19:04,464 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4387233257293701, 'Total loss': 0.4387233257293701} | train loss {'Reaction outcome loss': 0.317482495591754, 'Total loss': 0.317482495591754}
2023-01-04 08:19:04,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:04,464 INFO:     Epoch: 49
2023-01-04 08:19:05,982 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46651279330253603, 'Total loss': 0.46651279330253603} | train loss {'Reaction outcome loss': 0.3083354603130739, 'Total loss': 0.3083354603130739}
2023-01-04 08:19:05,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:05,982 INFO:     Epoch: 50
2023-01-04 08:19:07,529 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4540627698103587, 'Total loss': 0.4540627698103587} | train loss {'Reaction outcome loss': 0.30698980481769794, 'Total loss': 0.30698980481769794}
2023-01-04 08:19:07,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:07,530 INFO:     Epoch: 51
2023-01-04 08:19:09,082 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4639294981956482, 'Total loss': 0.4639294981956482} | train loss {'Reaction outcome loss': 0.3086409289594535, 'Total loss': 0.3086409289594535}
2023-01-04 08:19:09,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:09,083 INFO:     Epoch: 52
2023-01-04 08:19:10,631 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4750285714864731, 'Total loss': 0.4750285714864731} | train loss {'Reaction outcome loss': 0.3015363927889656, 'Total loss': 0.3015363927889656}
2023-01-04 08:19:10,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:10,631 INFO:     Epoch: 53
2023-01-04 08:19:12,185 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45478819410006205, 'Total loss': 0.45478819410006205} | train loss {'Reaction outcome loss': 0.30543651169800495, 'Total loss': 0.30543651169800495}
2023-01-04 08:19:12,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:12,185 INFO:     Epoch: 54
2023-01-04 08:19:13,708 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45199268956979116, 'Total loss': 0.45199268956979116} | train loss {'Reaction outcome loss': 0.2997025803495676, 'Total loss': 0.2997025803495676}
2023-01-04 08:19:13,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:13,708 INFO:     Epoch: 55
2023-01-04 08:19:15,241 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4417597184578578, 'Total loss': 0.4417597184578578} | train loss {'Reaction outcome loss': 0.2982762742228124, 'Total loss': 0.2982762742228124}
2023-01-04 08:19:15,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:15,242 INFO:     Epoch: 56
2023-01-04 08:19:16,789 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44076510667800906, 'Total loss': 0.44076510667800906} | train loss {'Reaction outcome loss': 0.3049545399162359, 'Total loss': 0.3049545399162359}
2023-01-04 08:19:16,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:16,789 INFO:     Epoch: 57
2023-01-04 08:19:18,331 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44159162441889444, 'Total loss': 0.44159162441889444} | train loss {'Reaction outcome loss': 0.2979299920941993, 'Total loss': 0.2979299920941993}
2023-01-04 08:19:18,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:18,331 INFO:     Epoch: 58
2023-01-04 08:19:19,895 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4421486755212148, 'Total loss': 0.4421486755212148} | train loss {'Reaction outcome loss': 0.2930694940489727, 'Total loss': 0.2930694940489727}
2023-01-04 08:19:19,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:19,896 INFO:     Epoch: 59
2023-01-04 08:19:21,441 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45167410175005596, 'Total loss': 0.45167410175005596} | train loss {'Reaction outcome loss': 0.2968805530296141, 'Total loss': 0.2968805530296141}
2023-01-04 08:19:21,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:21,442 INFO:     Epoch: 60
2023-01-04 08:19:22,967 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4565927594900131, 'Total loss': 0.4565927594900131} | train loss {'Reaction outcome loss': 0.28798529257376987, 'Total loss': 0.28798529257376987}
2023-01-04 08:19:22,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:22,968 INFO:     Epoch: 61
2023-01-04 08:19:24,520 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4483629753192266, 'Total loss': 0.4483629753192266} | train loss {'Reaction outcome loss': 0.2926400879691372, 'Total loss': 0.2926400879691372}
2023-01-04 08:19:24,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:24,520 INFO:     Epoch: 62
2023-01-04 08:19:26,061 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4480948507785797, 'Total loss': 0.4480948507785797} | train loss {'Reaction outcome loss': 0.2899452040156165, 'Total loss': 0.2899452040156165}
2023-01-04 08:19:26,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:26,061 INFO:     Epoch: 63
2023-01-04 08:19:27,619 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4362472673257192, 'Total loss': 0.4362472673257192} | train loss {'Reaction outcome loss': 0.2878321087185716, 'Total loss': 0.2878321087185716}
2023-01-04 08:19:27,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:27,620 INFO:     Epoch: 64
2023-01-04 08:19:29,179 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4680179297924042, 'Total loss': 0.4680179297924042} | train loss {'Reaction outcome loss': 0.2797280933175768, 'Total loss': 0.2797280933175768}
2023-01-04 08:19:29,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:29,179 INFO:     Epoch: 65
2023-01-04 08:19:30,718 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48375030159950255, 'Total loss': 0.48375030159950255} | train loss {'Reaction outcome loss': 0.28606839843722054, 'Total loss': 0.28606839843722054}
2023-01-04 08:19:30,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:30,718 INFO:     Epoch: 66
2023-01-04 08:19:32,239 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4427905172109604, 'Total loss': 0.4427905172109604} | train loss {'Reaction outcome loss': 0.27919082825273384, 'Total loss': 0.27919082825273384}
2023-01-04 08:19:32,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:32,239 INFO:     Epoch: 67
2023-01-04 08:19:33,809 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4353629589080811, 'Total loss': 0.4353629589080811} | train loss {'Reaction outcome loss': 0.2791071593652278, 'Total loss': 0.2791071593652278}
2023-01-04 08:19:33,811 INFO:     Found new best model at epoch 67
2023-01-04 08:19:33,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:33,812 INFO:     Epoch: 68
2023-01-04 08:19:35,375 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44045847455660503, 'Total loss': 0.44045847455660503} | train loss {'Reaction outcome loss': 0.2768685542074315, 'Total loss': 0.2768685542074315}
2023-01-04 08:19:35,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:35,375 INFO:     Epoch: 69
2023-01-04 08:19:36,959 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4470601419607798, 'Total loss': 0.4470601419607798} | train loss {'Reaction outcome loss': 0.2752058504920303, 'Total loss': 0.2752058504920303}
2023-01-04 08:19:36,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:36,960 INFO:     Epoch: 70
2023-01-04 08:19:38,526 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4424843897422155, 'Total loss': 0.4424843897422155} | train loss {'Reaction outcome loss': 0.27637351200584964, 'Total loss': 0.27637351200584964}
2023-01-04 08:19:38,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:38,526 INFO:     Epoch: 71
2023-01-04 08:19:40,063 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46859170248111087, 'Total loss': 0.46859170248111087} | train loss {'Reaction outcome loss': 0.2740940293058371, 'Total loss': 0.2740940293058371}
2023-01-04 08:19:40,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:40,064 INFO:     Epoch: 72
2023-01-04 08:19:41,586 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47374975979328154, 'Total loss': 0.47374975979328154} | train loss {'Reaction outcome loss': 0.27629380370234397, 'Total loss': 0.27629380370234397}
2023-01-04 08:19:41,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:41,586 INFO:     Epoch: 73
2023-01-04 08:19:43,142 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4612079083919525, 'Total loss': 0.4612079083919525} | train loss {'Reaction outcome loss': 0.27202439901756714, 'Total loss': 0.27202439901756714}
2023-01-04 08:19:43,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:43,143 INFO:     Epoch: 74
2023-01-04 08:19:44,710 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4446146637201309, 'Total loss': 0.4446146637201309} | train loss {'Reaction outcome loss': 0.2683590907371525, 'Total loss': 0.2683590907371525}
2023-01-04 08:19:44,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:44,710 INFO:     Epoch: 75
2023-01-04 08:19:46,289 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44223574697971346, 'Total loss': 0.44223574697971346} | train loss {'Reaction outcome loss': 0.27504594551720024, 'Total loss': 0.27504594551720024}
2023-01-04 08:19:46,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:46,290 INFO:     Epoch: 76
2023-01-04 08:19:47,859 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45421225279569627, 'Total loss': 0.45421225279569627} | train loss {'Reaction outcome loss': 0.2677433492936494, 'Total loss': 0.2677433492936494}
2023-01-04 08:19:47,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:47,860 INFO:     Epoch: 77
2023-01-04 08:19:49,356 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44112049440542855, 'Total loss': 0.44112049440542855} | train loss {'Reaction outcome loss': 0.2670617471193219, 'Total loss': 0.2670617471193219}
2023-01-04 08:19:49,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:49,356 INFO:     Epoch: 78
2023-01-04 08:19:50,857 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4823360105355581, 'Total loss': 0.4823360105355581} | train loss {'Reaction outcome loss': 0.2638060261560229, 'Total loss': 0.2638060261560229}
2023-01-04 08:19:50,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:50,857 INFO:     Epoch: 79
2023-01-04 08:19:52,401 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4391722768545151, 'Total loss': 0.4391722768545151} | train loss {'Reaction outcome loss': 0.2645748592230863, 'Total loss': 0.2645748592230863}
2023-01-04 08:19:52,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:52,402 INFO:     Epoch: 80
2023-01-04 08:19:53,951 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4483459075291952, 'Total loss': 0.4483459075291952} | train loss {'Reaction outcome loss': 0.2621813519097073, 'Total loss': 0.2621813519097073}
2023-01-04 08:19:53,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:53,951 INFO:     Epoch: 81
2023-01-04 08:19:55,501 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4957663317521413, 'Total loss': 0.4957663317521413} | train loss {'Reaction outcome loss': 0.2644025485539611, 'Total loss': 0.2644025485539611}
2023-01-04 08:19:55,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:55,501 INFO:     Epoch: 82
2023-01-04 08:19:57,059 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4451652695735296, 'Total loss': 0.4451652695735296} | train loss {'Reaction outcome loss': 0.2634863631847577, 'Total loss': 0.2634863631847577}
2023-01-04 08:19:57,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:57,061 INFO:     Epoch: 83
2023-01-04 08:19:58,570 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48081532716751096, 'Total loss': 0.48081532716751096} | train loss {'Reaction outcome loss': 0.26084609376096024, 'Total loss': 0.26084609376096024}
2023-01-04 08:19:58,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:19:58,570 INFO:     Epoch: 84
2023-01-04 08:20:00,068 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4529735088348389, 'Total loss': 0.4529735088348389} | train loss {'Reaction outcome loss': 0.2622136583640462, 'Total loss': 0.2622136583640462}
2023-01-04 08:20:00,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:00,068 INFO:     Epoch: 85
2023-01-04 08:20:01,619 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4692462861537933, 'Total loss': 0.4692462861537933} | train loss {'Reaction outcome loss': 0.25836342788768774, 'Total loss': 0.25836342788768774}
2023-01-04 08:20:01,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:01,620 INFO:     Epoch: 86
2023-01-04 08:20:03,172 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4818841358025869, 'Total loss': 0.4818841358025869} | train loss {'Reaction outcome loss': 0.255770437501289, 'Total loss': 0.255770437501289}
2023-01-04 08:20:03,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:03,172 INFO:     Epoch: 87
2023-01-04 08:20:04,706 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45676883061726886, 'Total loss': 0.45676883061726886} | train loss {'Reaction outcome loss': 0.25648322678256386, 'Total loss': 0.25648322678256386}
2023-01-04 08:20:04,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:04,708 INFO:     Epoch: 88
2023-01-04 08:20:06,236 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5208778778711954, 'Total loss': 0.5208778778711954} | train loss {'Reaction outcome loss': 0.2531078611892877, 'Total loss': 0.2531078611892877}
2023-01-04 08:20:06,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:06,236 INFO:     Epoch: 89
2023-01-04 08:20:07,734 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49579339027404784, 'Total loss': 0.49579339027404784} | train loss {'Reaction outcome loss': 0.25394009665036815, 'Total loss': 0.25394009665036815}
2023-01-04 08:20:07,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:07,734 INFO:     Epoch: 90
2023-01-04 08:20:09,229 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47245455781618756, 'Total loss': 0.47245455781618756} | train loss {'Reaction outcome loss': 0.2570377370212978, 'Total loss': 0.2570377370212978}
2023-01-04 08:20:09,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:09,229 INFO:     Epoch: 91
2023-01-04 08:20:10,777 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4515633364518484, 'Total loss': 0.4515633364518484} | train loss {'Reaction outcome loss': 0.251289203217178, 'Total loss': 0.251289203217178}
2023-01-04 08:20:10,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:10,778 INFO:     Epoch: 92
2023-01-04 08:20:12,325 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4969891558090846, 'Total loss': 0.4969891558090846} | train loss {'Reaction outcome loss': 0.26256378890175525, 'Total loss': 0.26256378890175525}
2023-01-04 08:20:12,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:12,325 INFO:     Epoch: 93
2023-01-04 08:20:13,878 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47916348179181417, 'Total loss': 0.47916348179181417} | train loss {'Reaction outcome loss': 0.25375878982819045, 'Total loss': 0.25375878982819045}
2023-01-04 08:20:13,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:13,879 INFO:     Epoch: 94
2023-01-04 08:20:15,435 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46204191247622173, 'Total loss': 0.46204191247622173} | train loss {'Reaction outcome loss': 0.24744755471800708, 'Total loss': 0.24744755471800708}
2023-01-04 08:20:15,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:15,437 INFO:     Epoch: 95
2023-01-04 08:20:16,942 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4376285394032796, 'Total loss': 0.4376285394032796} | train loss {'Reaction outcome loss': 0.24911250208159944, 'Total loss': 0.24911250208159944}
2023-01-04 08:20:16,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:16,943 INFO:     Epoch: 96
2023-01-04 08:20:18,439 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44951168696085614, 'Total loss': 0.44951168696085614} | train loss {'Reaction outcome loss': 0.2468515405868054, 'Total loss': 0.2468515405868054}
2023-01-04 08:20:18,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:18,440 INFO:     Epoch: 97
2023-01-04 08:20:19,964 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4611711800098419, 'Total loss': 0.4611711800098419} | train loss {'Reaction outcome loss': 0.2465326513262677, 'Total loss': 0.2465326513262677}
2023-01-04 08:20:19,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:19,964 INFO:     Epoch: 98
2023-01-04 08:20:21,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4649045338233312, 'Total loss': 0.4649045338233312} | train loss {'Reaction outcome loss': 0.24990997370673623, 'Total loss': 0.24990997370673623}
2023-01-04 08:20:21,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:21,481 INFO:     Epoch: 99
2023-01-04 08:20:23,019 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4739633719126383, 'Total loss': 0.4739633719126383} | train loss {'Reaction outcome loss': 0.24380371771452627, 'Total loss': 0.24380371771452627}
2023-01-04 08:20:23,019 INFO:     Best model found after epoch 68 of 100.
2023-01-04 08:20:23,019 INFO:   Done with stage: TRAINING
2023-01-04 08:20:23,019 INFO:   Starting stage: EVALUATION
2023-01-04 08:20:23,159 INFO:   Done with stage: EVALUATION
2023-01-04 08:20:23,159 INFO:   Leaving out SEQ value Fold_3
2023-01-04 08:20:23,172 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 08:20:23,172 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:20:23,808 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:20:23,808 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:20:23,875 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:20:23,876 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:20:23,876 INFO:     No hyperparam tuning for this model
2023-01-04 08:20:23,876 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:20:23,876 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:20:23,876 INFO:     None feature selector for col prot
2023-01-04 08:20:23,877 INFO:     None feature selector for col prot
2023-01-04 08:20:23,877 INFO:     None feature selector for col prot
2023-01-04 08:20:23,877 INFO:     None feature selector for col chem
2023-01-04 08:20:23,877 INFO:     None feature selector for col chem
2023-01-04 08:20:23,877 INFO:     None feature selector for col chem
2023-01-04 08:20:23,877 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:20:23,877 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:20:23,878 INFO:     Number of params in model 70111
2023-01-04 08:20:23,881 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:20:23,882 INFO:   Starting stage: TRAINING
2023-01-04 08:20:23,924 INFO:     Val loss before train {'Reaction outcome loss': 1.0082671284675597, 'Total loss': 1.0082671284675597}
2023-01-04 08:20:23,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:23,924 INFO:     Epoch: 0
2023-01-04 08:20:25,437 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7341565052668254, 'Total loss': 0.7341565052668254} | train loss {'Reaction outcome loss': 0.8567585221824855, 'Total loss': 0.8567585221824855}
2023-01-04 08:20:25,437 INFO:     Found new best model at epoch 0
2023-01-04 08:20:25,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:25,438 INFO:     Epoch: 1
2023-01-04 08:20:26,951 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6194535315036773, 'Total loss': 0.6194535315036773} | train loss {'Reaction outcome loss': 0.7005143573466879, 'Total loss': 0.7005143573466879}
2023-01-04 08:20:26,953 INFO:     Found new best model at epoch 1
2023-01-04 08:20:26,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:26,954 INFO:     Epoch: 2
2023-01-04 08:20:28,514 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5747051020463307, 'Total loss': 0.5747051020463307} | train loss {'Reaction outcome loss': 0.6031675067913793, 'Total loss': 0.6031675067913793}
2023-01-04 08:20:28,514 INFO:     Found new best model at epoch 2
2023-01-04 08:20:28,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:28,515 INFO:     Epoch: 3
2023-01-04 08:20:30,067 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5262218693892161, 'Total loss': 0.5262218693892161} | train loss {'Reaction outcome loss': 0.5609446827077518, 'Total loss': 0.5609446827077518}
2023-01-04 08:20:30,067 INFO:     Found new best model at epoch 3
2023-01-04 08:20:30,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:30,067 INFO:     Epoch: 4
2023-01-04 08:20:31,619 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5329833010832469, 'Total loss': 0.5329833010832469} | train loss {'Reaction outcome loss': 0.5332789682123783, 'Total loss': 0.5332789682123783}
2023-01-04 08:20:31,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:31,619 INFO:     Epoch: 5
2023-01-04 08:20:33,201 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.544571210940679, 'Total loss': 0.544571210940679} | train loss {'Reaction outcome loss': 0.5168029104706144, 'Total loss': 0.5168029104706144}
2023-01-04 08:20:33,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:33,203 INFO:     Epoch: 6
2023-01-04 08:20:34,705 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5079232414563497, 'Total loss': 0.5079232414563497} | train loss {'Reaction outcome loss': 0.505866264122246, 'Total loss': 0.505866264122246}
2023-01-04 08:20:34,706 INFO:     Found new best model at epoch 6
2023-01-04 08:20:34,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:34,706 INFO:     Epoch: 7
2023-01-04 08:20:36,201 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.488998947540919, 'Total loss': 0.488998947540919} | train loss {'Reaction outcome loss': 0.49919429753166045, 'Total loss': 0.49919429753166045}
2023-01-04 08:20:36,201 INFO:     Found new best model at epoch 7
2023-01-04 08:20:36,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:36,202 INFO:     Epoch: 8
2023-01-04 08:20:37,752 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4939495543638865, 'Total loss': 0.4939495543638865} | train loss {'Reaction outcome loss': 0.48969687320237615, 'Total loss': 0.48969687320237615}
2023-01-04 08:20:37,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:37,752 INFO:     Epoch: 9
2023-01-04 08:20:39,285 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.517999525864919, 'Total loss': 0.517999525864919} | train loss {'Reaction outcome loss': 0.4835736506829297, 'Total loss': 0.4835736506829297}
2023-01-04 08:20:39,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:39,286 INFO:     Epoch: 10
2023-01-04 08:20:40,823 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4834141810735067, 'Total loss': 0.4834141810735067} | train loss {'Reaction outcome loss': 0.47478725799243815, 'Total loss': 0.47478725799243815}
2023-01-04 08:20:40,823 INFO:     Found new best model at epoch 10
2023-01-04 08:20:40,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:40,824 INFO:     Epoch: 11
2023-01-04 08:20:42,376 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4805258880058924, 'Total loss': 0.4805258880058924} | train loss {'Reaction outcome loss': 0.4700425964963697, 'Total loss': 0.4700425964963697}
2023-01-04 08:20:42,376 INFO:     Found new best model at epoch 11
2023-01-04 08:20:42,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:42,377 INFO:     Epoch: 12
2023-01-04 08:20:43,888 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47350961367289224, 'Total loss': 0.47350961367289224} | train loss {'Reaction outcome loss': 0.4641973071180991, 'Total loss': 0.4641973071180991}
2023-01-04 08:20:43,888 INFO:     Found new best model at epoch 12
2023-01-04 08:20:43,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:43,889 INFO:     Epoch: 13
2023-01-04 08:20:45,410 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47563901940981546, 'Total loss': 0.47563901940981546} | train loss {'Reaction outcome loss': 0.4561919745085013, 'Total loss': 0.4561919745085013}
2023-01-04 08:20:45,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:45,414 INFO:     Epoch: 14
2023-01-04 08:20:46,962 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4787157634894053, 'Total loss': 0.4787157634894053} | train loss {'Reaction outcome loss': 0.4508243321447912, 'Total loss': 0.4508243321447912}
2023-01-04 08:20:46,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:46,962 INFO:     Epoch: 15
2023-01-04 08:20:48,516 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48908753991127013, 'Total loss': 0.48908753991127013} | train loss {'Reaction outcome loss': 0.44317235683437683, 'Total loss': 0.44317235683437683}
2023-01-04 08:20:48,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:48,516 INFO:     Epoch: 16
2023-01-04 08:20:50,058 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4757136344909668, 'Total loss': 0.4757136344909668} | train loss {'Reaction outcome loss': 0.4428236297447316, 'Total loss': 0.4428236297447316}
2023-01-04 08:20:50,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:50,059 INFO:     Epoch: 17
2023-01-04 08:20:51,592 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.476537432273229, 'Total loss': 0.476537432273229} | train loss {'Reaction outcome loss': 0.4379974407327436, 'Total loss': 0.4379974407327436}
2023-01-04 08:20:51,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:51,593 INFO:     Epoch: 18
2023-01-04 08:20:53,106 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4806334376335144, 'Total loss': 0.4806334376335144} | train loss {'Reaction outcome loss': 0.43420618204196004, 'Total loss': 0.43420618204196004}
2023-01-04 08:20:53,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:53,106 INFO:     Epoch: 19
2023-01-04 08:20:54,626 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47032121221224465, 'Total loss': 0.47032121221224465} | train loss {'Reaction outcome loss': 0.4264422191211777, 'Total loss': 0.4264422191211777}
2023-01-04 08:20:54,626 INFO:     Found new best model at epoch 19
2023-01-04 08:20:54,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:54,627 INFO:     Epoch: 20
2023-01-04 08:20:56,173 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47619243860244753, 'Total loss': 0.47619243860244753} | train loss {'Reaction outcome loss': 0.42611857103931644, 'Total loss': 0.42611857103931644}
2023-01-04 08:20:56,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:56,174 INFO:     Epoch: 21
2023-01-04 08:20:57,720 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47326479653517406, 'Total loss': 0.47326479653517406} | train loss {'Reaction outcome loss': 0.42000096677428617, 'Total loss': 0.42000096677428617}
2023-01-04 08:20:57,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:57,722 INFO:     Epoch: 22
2023-01-04 08:20:59,304 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45995456775029503, 'Total loss': 0.45995456775029503} | train loss {'Reaction outcome loss': 0.41351430286673735, 'Total loss': 0.41351430286673735}
2023-01-04 08:20:59,304 INFO:     Found new best model at epoch 22
2023-01-04 08:20:59,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:20:59,305 INFO:     Epoch: 23
2023-01-04 08:21:00,837 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49048987627029417, 'Total loss': 0.49048987627029417} | train loss {'Reaction outcome loss': 0.407408764490681, 'Total loss': 0.407408764490681}
2023-01-04 08:21:00,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:00,837 INFO:     Epoch: 24
2023-01-04 08:21:02,325 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45588577588399254, 'Total loss': 0.45588577588399254} | train loss {'Reaction outcome loss': 0.4077788606340433, 'Total loss': 0.4077788606340433}
2023-01-04 08:21:02,325 INFO:     Found new best model at epoch 24
2023-01-04 08:21:02,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:02,326 INFO:     Epoch: 25
2023-01-04 08:21:03,894 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46034781138102215, 'Total loss': 0.46034781138102215} | train loss {'Reaction outcome loss': 0.39935604893486865, 'Total loss': 0.39935604893486865}
2023-01-04 08:21:03,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:03,895 INFO:     Epoch: 26
2023-01-04 08:21:05,464 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45218415011962254, 'Total loss': 0.45218415011962254} | train loss {'Reaction outcome loss': 0.39910322416872873, 'Total loss': 0.39910322416872873}
2023-01-04 08:21:05,464 INFO:     Found new best model at epoch 26
2023-01-04 08:21:05,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:05,465 INFO:     Epoch: 27
2023-01-04 08:21:07,044 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43810172080993653, 'Total loss': 0.43810172080993653} | train loss {'Reaction outcome loss': 0.39654410888787606, 'Total loss': 0.39654410888787606}
2023-01-04 08:21:07,044 INFO:     Found new best model at epoch 27
2023-01-04 08:21:07,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:07,045 INFO:     Epoch: 28
2023-01-04 08:21:08,615 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4386561264594396, 'Total loss': 0.4386561264594396} | train loss {'Reaction outcome loss': 0.3892036843908964, 'Total loss': 0.3892036843908964}
2023-01-04 08:21:08,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:08,615 INFO:     Epoch: 29
2023-01-04 08:21:10,156 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47671678811311724, 'Total loss': 0.47671678811311724} | train loss {'Reaction outcome loss': 0.3879908318393422, 'Total loss': 0.3879908318393422}
2023-01-04 08:21:10,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:10,157 INFO:     Epoch: 30
2023-01-04 08:21:11,714 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45569596290588377, 'Total loss': 0.45569596290588377} | train loss {'Reaction outcome loss': 0.38547193737578217, 'Total loss': 0.38547193737578217}
2023-01-04 08:21:11,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:11,714 INFO:     Epoch: 31
2023-01-04 08:21:12,773 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4286608080069224, 'Total loss': 0.4286608080069224} | train loss {'Reaction outcome loss': 0.37983690754231747, 'Total loss': 0.37983690754231747}
2023-01-04 08:21:12,773 INFO:     Found new best model at epoch 31
2023-01-04 08:21:12,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:12,774 INFO:     Epoch: 32
2023-01-04 08:21:13,784 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4279831568400065, 'Total loss': 0.4279831568400065} | train loss {'Reaction outcome loss': 0.3780413804589397, 'Total loss': 0.3780413804589397}
2023-01-04 08:21:13,784 INFO:     Found new best model at epoch 32
2023-01-04 08:21:13,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:13,785 INFO:     Epoch: 33
2023-01-04 08:21:14,794 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4589212069908778, 'Total loss': 0.4589212069908778} | train loss {'Reaction outcome loss': 0.3789091298669359, 'Total loss': 0.3789091298669359}
2023-01-04 08:21:14,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:14,794 INFO:     Epoch: 34
2023-01-04 08:21:15,805 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44737834880749383, 'Total loss': 0.44737834880749383} | train loss {'Reaction outcome loss': 0.37272469438340544, 'Total loss': 0.37272469438340544}
2023-01-04 08:21:15,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:15,807 INFO:     Epoch: 35
2023-01-04 08:21:17,095 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4394027064243952, 'Total loss': 0.4394027064243952} | train loss {'Reaction outcome loss': 0.3684268033635007, 'Total loss': 0.3684268033635007}
2023-01-04 08:21:17,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:17,096 INFO:     Epoch: 36
2023-01-04 08:21:18,667 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43535690506299335, 'Total loss': 0.43535690506299335} | train loss {'Reaction outcome loss': 0.36705121463232665, 'Total loss': 0.36705121463232665}
2023-01-04 08:21:18,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:18,667 INFO:     Epoch: 37
2023-01-04 08:21:20,205 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4167908171812693, 'Total loss': 0.4167908171812693} | train loss {'Reaction outcome loss': 0.36314087910373716, 'Total loss': 0.36314087910373716}
2023-01-04 08:21:20,205 INFO:     Found new best model at epoch 37
2023-01-04 08:21:20,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:20,206 INFO:     Epoch: 38
2023-01-04 08:21:21,758 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.441083562374115, 'Total loss': 0.441083562374115} | train loss {'Reaction outcome loss': 0.36118647257668257, 'Total loss': 0.36118647257668257}
2023-01-04 08:21:21,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:21,760 INFO:     Epoch: 39
2023-01-04 08:21:23,302 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4297622685631116, 'Total loss': 0.4297622685631116} | train loss {'Reaction outcome loss': 0.35814002082839497, 'Total loss': 0.35814002082839497}
2023-01-04 08:21:23,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:23,302 INFO:     Epoch: 40
2023-01-04 08:21:24,853 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41332089751958845, 'Total loss': 0.41332089751958845} | train loss {'Reaction outcome loss': 0.3537154247725967, 'Total loss': 0.3537154247725967}
2023-01-04 08:21:24,853 INFO:     Found new best model at epoch 40
2023-01-04 08:21:24,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:24,854 INFO:     Epoch: 41
2023-01-04 08:21:26,315 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41171747048695884, 'Total loss': 0.41171747048695884} | train loss {'Reaction outcome loss': 0.3495563976738575, 'Total loss': 0.3495563976738575}
2023-01-04 08:21:26,315 INFO:     Found new best model at epoch 41
2023-01-04 08:21:26,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:26,316 INFO:     Epoch: 42
2023-01-04 08:21:27,884 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.431270436445872, 'Total loss': 0.431270436445872} | train loss {'Reaction outcome loss': 0.3456231116786273, 'Total loss': 0.3456231116786273}
2023-01-04 08:21:27,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:27,885 INFO:     Epoch: 43
2023-01-04 08:21:29,418 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40327727099259697, 'Total loss': 0.40327727099259697} | train loss {'Reaction outcome loss': 0.3431878472766737, 'Total loss': 0.3431878472766737}
2023-01-04 08:21:29,418 INFO:     Found new best model at epoch 43
2023-01-04 08:21:29,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:29,419 INFO:     Epoch: 44
2023-01-04 08:21:30,968 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4491014619668325, 'Total loss': 0.4491014619668325} | train loss {'Reaction outcome loss': 0.33821411517849803, 'Total loss': 0.33821411517849803}
2023-01-04 08:21:30,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:30,968 INFO:     Epoch: 45
2023-01-04 08:21:32,517 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4288152317206065, 'Total loss': 0.4288152317206065} | train loss {'Reaction outcome loss': 0.33945949495273786, 'Total loss': 0.33945949495273786}
2023-01-04 08:21:32,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:32,517 INFO:     Epoch: 46
2023-01-04 08:21:34,073 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4469949642817179, 'Total loss': 0.4469949642817179} | train loss {'Reaction outcome loss': 0.3361988505960381, 'Total loss': 0.3361988505960381}
2023-01-04 08:21:34,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:34,075 INFO:     Epoch: 47
2023-01-04 08:21:35,566 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4352281590302785, 'Total loss': 0.4352281590302785} | train loss {'Reaction outcome loss': 0.33123395029101926, 'Total loss': 0.33123395029101926}
2023-01-04 08:21:35,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:35,566 INFO:     Epoch: 48
2023-01-04 08:21:37,119 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42196670174598694, 'Total loss': 0.42196670174598694} | train loss {'Reaction outcome loss': 0.3347908693780429, 'Total loss': 0.3347908693780429}
2023-01-04 08:21:37,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:37,119 INFO:     Epoch: 49
2023-01-04 08:21:38,694 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41935646831989287, 'Total loss': 0.41935646831989287} | train loss {'Reaction outcome loss': 0.3307720826816385, 'Total loss': 0.3307720826816385}
2023-01-04 08:21:38,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:38,694 INFO:     Epoch: 50
2023-01-04 08:21:40,237 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42588383952776593, 'Total loss': 0.42588383952776593} | train loss {'Reaction outcome loss': 0.3219288115654766, 'Total loss': 0.3219288115654766}
2023-01-04 08:21:40,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:40,238 INFO:     Epoch: 51
2023-01-04 08:21:41,788 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41916362245877586, 'Total loss': 0.41916362245877586} | train loss {'Reaction outcome loss': 0.3247043900191784, 'Total loss': 0.3247043900191784}
2023-01-04 08:21:41,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:41,788 INFO:     Epoch: 52
2023-01-04 08:21:43,328 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4291801154613495, 'Total loss': 0.4291801154613495} | train loss {'Reaction outcome loss': 0.32167123320655233, 'Total loss': 0.32167123320655233}
2023-01-04 08:21:43,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:43,328 INFO:     Epoch: 53
2023-01-04 08:21:44,830 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42092001835505166, 'Total loss': 0.42092001835505166} | train loss {'Reaction outcome loss': 0.3158956995356257, 'Total loss': 0.3158956995356257}
2023-01-04 08:21:44,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:44,830 INFO:     Epoch: 54
2023-01-04 08:21:46,394 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3890347758928935, 'Total loss': 0.3890347758928935} | train loss {'Reaction outcome loss': 0.31999901135581255, 'Total loss': 0.31999901135581255}
2023-01-04 08:21:46,396 INFO:     Found new best model at epoch 54
2023-01-04 08:21:46,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:46,396 INFO:     Epoch: 55
2023-01-04 08:21:47,980 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4104804863532384, 'Total loss': 0.4104804863532384} | train loss {'Reaction outcome loss': 0.31064979109342084, 'Total loss': 0.31064979109342084}
2023-01-04 08:21:47,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:47,981 INFO:     Epoch: 56
2023-01-04 08:21:49,566 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4233922898769379, 'Total loss': 0.4233922898769379} | train loss {'Reaction outcome loss': 0.3132495791481359, 'Total loss': 0.3132495791481359}
2023-01-04 08:21:49,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:49,566 INFO:     Epoch: 57
2023-01-04 08:21:51,143 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3993035505215327, 'Total loss': 0.3993035505215327} | train loss {'Reaction outcome loss': 0.3118792104460027, 'Total loss': 0.3118792104460027}
2023-01-04 08:21:51,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:51,143 INFO:     Epoch: 58
2023-01-04 08:21:52,658 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43813144564628603, 'Total loss': 0.43813144564628603} | train loss {'Reaction outcome loss': 0.304579869945989, 'Total loss': 0.304579869945989}
2023-01-04 08:21:52,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:52,659 INFO:     Epoch: 59
2023-01-04 08:21:54,186 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39861258963743845, 'Total loss': 0.39861258963743845} | train loss {'Reaction outcome loss': 0.3079604411320965, 'Total loss': 0.3079604411320965}
2023-01-04 08:21:54,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:54,186 INFO:     Epoch: 60
2023-01-04 08:21:55,761 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40759264727433525, 'Total loss': 0.40759264727433525} | train loss {'Reaction outcome loss': 0.30381982572322347, 'Total loss': 0.30381982572322347}
2023-01-04 08:21:55,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:55,762 INFO:     Epoch: 61
2023-01-04 08:21:57,313 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4252939889828364, 'Total loss': 0.4252939889828364} | train loss {'Reaction outcome loss': 0.3030526828646225, 'Total loss': 0.3030526828646225}
2023-01-04 08:21:57,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:57,314 INFO:     Epoch: 62
2023-01-04 08:21:58,867 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.417381410797437, 'Total loss': 0.417381410797437} | train loss {'Reaction outcome loss': 0.30283477282437093, 'Total loss': 0.30283477282437093}
2023-01-04 08:21:58,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:21:58,868 INFO:     Epoch: 63
2023-01-04 08:22:00,438 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4230522225300471, 'Total loss': 0.4230522225300471} | train loss {'Reaction outcome loss': 0.3014439046926742, 'Total loss': 0.3014439046926742}
2023-01-04 08:22:00,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:00,438 INFO:     Epoch: 64
2023-01-04 08:22:01,911 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43787232438723245, 'Total loss': 0.43787232438723245} | train loss {'Reaction outcome loss': 0.3008457352509246, 'Total loss': 0.3008457352509246}
2023-01-04 08:22:01,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:01,912 INFO:     Epoch: 65
2023-01-04 08:22:03,475 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3886149525642395, 'Total loss': 0.3886149525642395} | train loss {'Reaction outcome loss': 0.30067896190350946, 'Total loss': 0.30067896190350946}
2023-01-04 08:22:03,475 INFO:     Found new best model at epoch 65
2023-01-04 08:22:03,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:03,476 INFO:     Epoch: 66
2023-01-04 08:22:05,028 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41065042416254677, 'Total loss': 0.41065042416254677} | train loss {'Reaction outcome loss': 0.29399654361670907, 'Total loss': 0.29399654361670907}
2023-01-04 08:22:05,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:05,029 INFO:     Epoch: 67
2023-01-04 08:22:06,606 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4165146509806315, 'Total loss': 0.4165146509806315} | train loss {'Reaction outcome loss': 0.29755428514993976, 'Total loss': 0.29755428514993976}
2023-01-04 08:22:06,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:06,607 INFO:     Epoch: 68
2023-01-04 08:22:08,173 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39308655659357705, 'Total loss': 0.39308655659357705} | train loss {'Reaction outcome loss': 0.2936007721879839, 'Total loss': 0.2936007721879839}
2023-01-04 08:22:08,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:08,174 INFO:     Epoch: 69
2023-01-04 08:22:09,738 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.430143599708875, 'Total loss': 0.430143599708875} | train loss {'Reaction outcome loss': 0.292094324844597, 'Total loss': 0.292094324844597}
2023-01-04 08:22:09,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:09,738 INFO:     Epoch: 70
2023-01-04 08:22:11,219 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4163638641436895, 'Total loss': 0.4163638641436895} | train loss {'Reaction outcome loss': 0.28770621841515065, 'Total loss': 0.28770621841515065}
2023-01-04 08:22:11,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:11,220 INFO:     Epoch: 71
2023-01-04 08:22:12,816 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43258269925912224, 'Total loss': 0.43258269925912224} | train loss {'Reaction outcome loss': 0.28701795488052123, 'Total loss': 0.28701795488052123}
2023-01-04 08:22:12,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:12,817 INFO:     Epoch: 72
2023-01-04 08:22:14,418 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4119448810815811, 'Total loss': 0.4119448810815811} | train loss {'Reaction outcome loss': 0.2882704937109982, 'Total loss': 0.2882704937109982}
2023-01-04 08:22:14,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:14,418 INFO:     Epoch: 73
2023-01-04 08:22:16,031 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43783862789471945, 'Total loss': 0.43783862789471945} | train loss {'Reaction outcome loss': 0.283884234726429, 'Total loss': 0.283884234726429}
2023-01-04 08:22:16,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:16,031 INFO:     Epoch: 74
2023-01-04 08:22:17,641 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43625769317150115, 'Total loss': 0.43625769317150115} | train loss {'Reaction outcome loss': 0.27788488308552406, 'Total loss': 0.27788488308552406}
2023-01-04 08:22:17,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:17,642 INFO:     Epoch: 75
2023-01-04 08:22:19,252 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3906702478726705, 'Total loss': 0.3906702478726705} | train loss {'Reaction outcome loss': 0.282879274827938, 'Total loss': 0.282879274827938}
2023-01-04 08:22:19,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:19,253 INFO:     Epoch: 76
2023-01-04 08:22:20,785 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44366909662882487, 'Total loss': 0.44366909662882487} | train loss {'Reaction outcome loss': 0.2828606029931646, 'Total loss': 0.2828606029931646}
2023-01-04 08:22:20,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:20,785 INFO:     Epoch: 77
2023-01-04 08:22:22,376 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40758630832036336, 'Total loss': 0.40758630832036336} | train loss {'Reaction outcome loss': 0.2830263110027261, 'Total loss': 0.2830263110027261}
2023-01-04 08:22:22,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:22,376 INFO:     Epoch: 78
2023-01-04 08:22:23,967 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.437514191865921, 'Total loss': 0.437514191865921} | train loss {'Reaction outcome loss': 0.28139283845241925, 'Total loss': 0.28139283845241925}
2023-01-04 08:22:23,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:23,969 INFO:     Epoch: 79
2023-01-04 08:22:25,560 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42524812519550326, 'Total loss': 0.42524812519550326} | train loss {'Reaction outcome loss': 0.2758719266603028, 'Total loss': 0.2758719266603028}
2023-01-04 08:22:25,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:25,560 INFO:     Epoch: 80
2023-01-04 08:22:27,141 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4279411107301712, 'Total loss': 0.4279411107301712} | train loss {'Reaction outcome loss': 0.27352449077650576, 'Total loss': 0.27352449077650576}
2023-01-04 08:22:27,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:27,142 INFO:     Epoch: 81
2023-01-04 08:22:28,727 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4144631346066793, 'Total loss': 0.4144631346066793} | train loss {'Reaction outcome loss': 0.2733420263839899, 'Total loss': 0.2733420263839899}
2023-01-04 08:22:28,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:28,728 INFO:     Epoch: 82
2023-01-04 08:22:30,260 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3895049631595612, 'Total loss': 0.3895049631595612} | train loss {'Reaction outcome loss': 0.2701664520087686, 'Total loss': 0.2701664520087686}
2023-01-04 08:22:30,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:30,260 INFO:     Epoch: 83
2023-01-04 08:22:31,851 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4080502192179362, 'Total loss': 0.4080502192179362} | train loss {'Reaction outcome loss': 0.27055010463308243, 'Total loss': 0.27055010463308243}
2023-01-04 08:22:31,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:31,851 INFO:     Epoch: 84
2023-01-04 08:22:33,449 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4021686514218648, 'Total loss': 0.4021686514218648} | train loss {'Reaction outcome loss': 0.27237067977986196, 'Total loss': 0.27237067977986196}
2023-01-04 08:22:33,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:33,449 INFO:     Epoch: 85
2023-01-04 08:22:35,020 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40733965833981833, 'Total loss': 0.40733965833981833} | train loss {'Reaction outcome loss': 0.26902106287379335, 'Total loss': 0.26902106287379335}
2023-01-04 08:22:35,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:35,021 INFO:     Epoch: 86
2023-01-04 08:22:36,624 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4072641213734945, 'Total loss': 0.4072641213734945} | train loss {'Reaction outcome loss': 0.2663602390442125, 'Total loss': 0.2663602390442125}
2023-01-04 08:22:36,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:36,624 INFO:     Epoch: 87
2023-01-04 08:22:38,169 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4302567402521769, 'Total loss': 0.4302567402521769} | train loss {'Reaction outcome loss': 0.2699319058689323, 'Total loss': 0.2699319058689323}
2023-01-04 08:22:38,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:38,170 INFO:     Epoch: 88
2023-01-04 08:22:39,704 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4137382944424947, 'Total loss': 0.4137382944424947} | train loss {'Reaction outcome loss': 0.2651335559105569, 'Total loss': 0.2651335559105569}
2023-01-04 08:22:39,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:39,704 INFO:     Epoch: 89
2023-01-04 08:22:41,271 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4288266976674398, 'Total loss': 0.4288266976674398} | train loss {'Reaction outcome loss': 0.26967274000609875, 'Total loss': 0.26967274000609875}
2023-01-04 08:22:41,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:41,272 INFO:     Epoch: 90
2023-01-04 08:22:42,855 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4308135708173116, 'Total loss': 0.4308135708173116} | train loss {'Reaction outcome loss': 0.26378991756669795, 'Total loss': 0.26378991756669795}
2023-01-04 08:22:42,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:42,855 INFO:     Epoch: 91
2023-01-04 08:22:44,429 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4363313138484955, 'Total loss': 0.4363313138484955} | train loss {'Reaction outcome loss': 0.2604370646885712, 'Total loss': 0.2604370646885712}
2023-01-04 08:22:44,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:44,430 INFO:     Epoch: 92
2023-01-04 08:22:45,992 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4251696983973185, 'Total loss': 0.4251696983973185} | train loss {'Reaction outcome loss': 0.2601369591089931, 'Total loss': 0.2601369591089931}
2023-01-04 08:22:45,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:45,992 INFO:     Epoch: 93
2023-01-04 08:22:47,521 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4229748954375585, 'Total loss': 0.4229748954375585} | train loss {'Reaction outcome loss': 0.25915140464194936, 'Total loss': 0.25915140464194936}
2023-01-04 08:22:47,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:47,522 INFO:     Epoch: 94
2023-01-04 08:22:49,041 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.434772523244222, 'Total loss': 0.434772523244222} | train loss {'Reaction outcome loss': 0.25468116159802373, 'Total loss': 0.25468116159802373}
2023-01-04 08:22:49,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:49,042 INFO:     Epoch: 95
2023-01-04 08:22:50,591 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.459618271390597, 'Total loss': 0.459618271390597} | train loss {'Reaction outcome loss': 0.25833367701810206, 'Total loss': 0.25833367701810206}
2023-01-04 08:22:50,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:50,592 INFO:     Epoch: 96
2023-01-04 08:22:52,128 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4306209703286489, 'Total loss': 0.4306209703286489} | train loss {'Reaction outcome loss': 0.2625766115086357, 'Total loss': 0.2625766115086357}
2023-01-04 08:22:52,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:52,129 INFO:     Epoch: 97
2023-01-04 08:22:53,670 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.427894722421964, 'Total loss': 0.427894722421964} | train loss {'Reaction outcome loss': 0.2596524334954519, 'Total loss': 0.2596524334954519}
2023-01-04 08:22:53,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:53,672 INFO:     Epoch: 98
2023-01-04 08:22:55,223 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4163084333141645, 'Total loss': 0.4163084333141645} | train loss {'Reaction outcome loss': 0.255999931290637, 'Total loss': 0.255999931290637}
2023-01-04 08:22:55,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:55,224 INFO:     Epoch: 99
2023-01-04 08:22:56,725 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4216436366240183, 'Total loss': 0.4216436366240183} | train loss {'Reaction outcome loss': 0.2520579924521438, 'Total loss': 0.2520579924521438}
2023-01-04 08:22:56,725 INFO:     Best model found after epoch 66 of 100.
2023-01-04 08:22:56,725 INFO:   Done with stage: TRAINING
2023-01-04 08:22:56,725 INFO:   Starting stage: EVALUATION
2023-01-04 08:22:56,858 INFO:   Done with stage: EVALUATION
2023-01-04 08:22:56,859 INFO:   Leaving out SEQ value Fold_4
2023-01-04 08:22:56,871 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 08:22:56,871 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:22:57,522 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:22:57,522 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:22:57,591 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:22:57,591 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:22:57,591 INFO:     No hyperparam tuning for this model
2023-01-04 08:22:57,591 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:22:57,591 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:22:57,592 INFO:     None feature selector for col prot
2023-01-04 08:22:57,592 INFO:     None feature selector for col prot
2023-01-04 08:22:57,592 INFO:     None feature selector for col prot
2023-01-04 08:22:57,592 INFO:     None feature selector for col chem
2023-01-04 08:22:57,592 INFO:     None feature selector for col chem
2023-01-04 08:22:57,593 INFO:     None feature selector for col chem
2023-01-04 08:22:57,593 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:22:57,593 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:22:57,594 INFO:     Number of params in model 70111
2023-01-04 08:22:57,597 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:22:57,597 INFO:   Starting stage: TRAINING
2023-01-04 08:22:57,641 INFO:     Val loss before train {'Reaction outcome loss': 1.0549247860908508, 'Total loss': 1.0549247860908508}
2023-01-04 08:22:57,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:57,642 INFO:     Epoch: 0
2023-01-04 08:22:59,218 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7269048710664113, 'Total loss': 0.7269048710664113} | train loss {'Reaction outcome loss': 0.8355862897267377, 'Total loss': 0.8355862897267377}
2023-01-04 08:22:59,219 INFO:     Found new best model at epoch 0
2023-01-04 08:22:59,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:22:59,220 INFO:     Epoch: 1
2023-01-04 08:23:00,768 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5900087277094523, 'Total loss': 0.5900087277094523} | train loss {'Reaction outcome loss': 0.6813576887079102, 'Total loss': 0.6813576887079102}
2023-01-04 08:23:00,768 INFO:     Found new best model at epoch 1
2023-01-04 08:23:00,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:00,769 INFO:     Epoch: 2
2023-01-04 08:23:02,315 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5004880130290985, 'Total loss': 0.5004880130290985} | train loss {'Reaction outcome loss': 0.5925026696877204, 'Total loss': 0.5925026696877204}
2023-01-04 08:23:02,315 INFO:     Found new best model at epoch 2
2023-01-04 08:23:02,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:02,316 INFO:     Epoch: 3
2023-01-04 08:23:03,883 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49274195432662965, 'Total loss': 0.49274195432662965} | train loss {'Reaction outcome loss': 0.5554159980375266, 'Total loss': 0.5554159980375266}
2023-01-04 08:23:03,883 INFO:     Found new best model at epoch 3
2023-01-04 08:23:03,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:03,884 INFO:     Epoch: 4
2023-01-04 08:23:05,415 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5038970867792766, 'Total loss': 0.5038970867792766} | train loss {'Reaction outcome loss': 0.5272758068057938, 'Total loss': 0.5272758068057938}
2023-01-04 08:23:05,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:05,416 INFO:     Epoch: 5
2023-01-04 08:23:06,963 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4735773722330729, 'Total loss': 0.4735773722330729} | train loss {'Reaction outcome loss': 0.513063618035156, 'Total loss': 0.513063618035156}
2023-01-04 08:23:06,963 INFO:     Found new best model at epoch 5
2023-01-04 08:23:06,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:06,964 INFO:     Epoch: 6
2023-01-04 08:23:08,526 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4260755846897761, 'Total loss': 0.4260755846897761} | train loss {'Reaction outcome loss': 0.49932296763079753, 'Total loss': 0.49932296763079753}
2023-01-04 08:23:08,526 INFO:     Found new best model at epoch 6
2023-01-04 08:23:08,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:08,527 INFO:     Epoch: 7
2023-01-04 08:23:10,097 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4488974074522654, 'Total loss': 0.4488974074522654} | train loss {'Reaction outcome loss': 0.5053364241468734, 'Total loss': 0.5053364241468734}
2023-01-04 08:23:10,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:10,097 INFO:     Epoch: 8
2023-01-04 08:23:11,663 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4314624900619189, 'Total loss': 0.4314624900619189} | train loss {'Reaction outcome loss': 0.49865738221484684, 'Total loss': 0.49865738221484684}
2023-01-04 08:23:11,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:11,664 INFO:     Epoch: 9
2023-01-04 08:23:13,235 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.430417279402415, 'Total loss': 0.430417279402415} | train loss {'Reaction outcome loss': 0.4848084676609226, 'Total loss': 0.4848084676609226}
2023-01-04 08:23:13,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:13,236 INFO:     Epoch: 10
2023-01-04 08:23:14,739 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4437851866086324, 'Total loss': 0.4437851866086324} | train loss {'Reaction outcome loss': 0.4740489405601798, 'Total loss': 0.4740489405601798}
2023-01-04 08:23:14,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:14,739 INFO:     Epoch: 11
2023-01-04 08:23:16,321 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41693328122297924, 'Total loss': 0.41693328122297924} | train loss {'Reaction outcome loss': 0.46600054172745004, 'Total loss': 0.46600054172745004}
2023-01-04 08:23:16,321 INFO:     Found new best model at epoch 11
2023-01-04 08:23:16,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:16,322 INFO:     Epoch: 12
2023-01-04 08:23:17,907 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4195464531580607, 'Total loss': 0.4195464531580607} | train loss {'Reaction outcome loss': 0.4598705887042013, 'Total loss': 0.4598705887042013}
2023-01-04 08:23:17,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:17,908 INFO:     Epoch: 13
2023-01-04 08:23:19,488 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48146001299222313, 'Total loss': 0.48146001299222313} | train loss {'Reaction outcome loss': 0.45667201577537303, 'Total loss': 0.45667201577537303}
2023-01-04 08:23:19,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:19,488 INFO:     Epoch: 14
2023-01-04 08:23:21,056 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4158582895994186, 'Total loss': 0.4158582895994186} | train loss {'Reaction outcome loss': 0.4578033258684614, 'Total loss': 0.4578033258684614}
2023-01-04 08:23:21,056 INFO:     Found new best model at epoch 14
2023-01-04 08:23:21,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:21,057 INFO:     Epoch: 15
2023-01-04 08:23:22,630 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4458222766717275, 'Total loss': 0.4458222766717275} | train loss {'Reaction outcome loss': 0.458025769641002, 'Total loss': 0.458025769641002}
2023-01-04 08:23:22,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:22,631 INFO:     Epoch: 16
2023-01-04 08:23:24,140 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4330767383178075, 'Total loss': 0.4330767383178075} | train loss {'Reaction outcome loss': 0.4803386592319694, 'Total loss': 0.4803386592319694}
2023-01-04 08:23:24,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:24,140 INFO:     Epoch: 17
2023-01-04 08:23:25,761 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42569748560587567, 'Total loss': 0.42569748560587567} | train loss {'Reaction outcome loss': 0.44703721312343725, 'Total loss': 0.44703721312343725}
2023-01-04 08:23:25,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:25,761 INFO:     Epoch: 18
2023-01-04 08:23:27,374 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39721975177526475, 'Total loss': 0.39721975177526475} | train loss {'Reaction outcome loss': 0.4390596369647529, 'Total loss': 0.4390596369647529}
2023-01-04 08:23:27,374 INFO:     Found new best model at epoch 18
2023-01-04 08:23:27,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:27,375 INFO:     Epoch: 19
2023-01-04 08:23:28,982 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41726138691107434, 'Total loss': 0.41726138691107434} | train loss {'Reaction outcome loss': 0.4375058257871348, 'Total loss': 0.4375058257871348}
2023-01-04 08:23:28,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:28,982 INFO:     Epoch: 20
2023-01-04 08:23:30,590 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37927228411038716, 'Total loss': 0.37927228411038716} | train loss {'Reaction outcome loss': 0.43070126198669995, 'Total loss': 0.43070126198669995}
2023-01-04 08:23:30,591 INFO:     Found new best model at epoch 20
2023-01-04 08:23:30,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:30,592 INFO:     Epoch: 21
2023-01-04 08:23:32,192 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4021919310092926, 'Total loss': 0.4021919310092926} | train loss {'Reaction outcome loss': 0.4300746462051419, 'Total loss': 0.4300746462051419}
2023-01-04 08:23:32,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:32,192 INFO:     Epoch: 22
2023-01-04 08:23:33,709 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38132752577463785, 'Total loss': 0.38132752577463785} | train loss {'Reaction outcome loss': 0.4248850205778212, 'Total loss': 0.4248850205778212}
2023-01-04 08:23:33,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:33,709 INFO:     Epoch: 23
2023-01-04 08:23:35,319 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40193985402584076, 'Total loss': 0.40193985402584076} | train loss {'Reaction outcome loss': 0.4245728575826987, 'Total loss': 0.4245728575826987}
2023-01-04 08:23:35,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:35,319 INFO:     Epoch: 24
2023-01-04 08:23:36,938 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3628374017775059, 'Total loss': 0.3628374017775059} | train loss {'Reaction outcome loss': 0.41925115199916513, 'Total loss': 0.41925115199916513}
2023-01-04 08:23:36,939 INFO:     Found new best model at epoch 24
2023-01-04 08:23:36,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:36,940 INFO:     Epoch: 25
2023-01-04 08:23:38,561 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3891106277704239, 'Total loss': 0.3891106277704239} | train loss {'Reaction outcome loss': 0.4104656526193877, 'Total loss': 0.4104656526193877}
2023-01-04 08:23:38,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:38,561 INFO:     Epoch: 26
2023-01-04 08:23:40,175 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3754151215155919, 'Total loss': 0.3754151215155919} | train loss {'Reaction outcome loss': 0.4080877665854633, 'Total loss': 0.4080877665854633}
2023-01-04 08:23:40,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:40,175 INFO:     Epoch: 27
2023-01-04 08:23:41,746 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41006254255771635, 'Total loss': 0.41006254255771635} | train loss {'Reaction outcome loss': 0.405583024323594, 'Total loss': 0.405583024323594}
2023-01-04 08:23:41,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:41,747 INFO:     Epoch: 28
2023-01-04 08:23:43,323 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.385025159517924, 'Total loss': 0.385025159517924} | train loss {'Reaction outcome loss': 0.4015641035647064, 'Total loss': 0.4015641035647064}
2023-01-04 08:23:43,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:43,323 INFO:     Epoch: 29
2023-01-04 08:23:44,945 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37908894022305806, 'Total loss': 0.37908894022305806} | train loss {'Reaction outcome loss': 0.40149425433196156, 'Total loss': 0.40149425433196156}
2023-01-04 08:23:44,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:44,946 INFO:     Epoch: 30
2023-01-04 08:23:46,548 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40159641901652016, 'Total loss': 0.40159641901652016} | train loss {'Reaction outcome loss': 0.39863117897661193, 'Total loss': 0.39863117897661193}
2023-01-04 08:23:46,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:46,548 INFO:     Epoch: 31
2023-01-04 08:23:48,157 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36260662923256554, 'Total loss': 0.36260662923256554} | train loss {'Reaction outcome loss': 0.39306162749889534, 'Total loss': 0.39306162749889534}
2023-01-04 08:23:48,158 INFO:     Found new best model at epoch 31
2023-01-04 08:23:48,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:48,159 INFO:     Epoch: 32
2023-01-04 08:23:49,782 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39016081889470416, 'Total loss': 0.39016081889470416} | train loss {'Reaction outcome loss': 0.3881778258676776, 'Total loss': 0.3881778258676776}
2023-01-04 08:23:49,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:49,782 INFO:     Epoch: 33
2023-01-04 08:23:51,322 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3910404493411382, 'Total loss': 0.3910404493411382} | train loss {'Reaction outcome loss': 0.3862348421935694, 'Total loss': 0.3862348421935694}
2023-01-04 08:23:51,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:51,323 INFO:     Epoch: 34
2023-01-04 08:23:52,898 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3793156504631042, 'Total loss': 0.3793156504631042} | train loss {'Reaction outcome loss': 0.3825372732851816, 'Total loss': 0.3825372732851816}
2023-01-04 08:23:52,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:52,898 INFO:     Epoch: 35
2023-01-04 08:23:54,468 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3627318054437637, 'Total loss': 0.3627318054437637} | train loss {'Reaction outcome loss': 0.38102776405129046, 'Total loss': 0.38102776405129046}
2023-01-04 08:23:54,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:54,469 INFO:     Epoch: 36
2023-01-04 08:23:56,030 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3955375969409943, 'Total loss': 0.3955375969409943} | train loss {'Reaction outcome loss': 0.37732042423179507, 'Total loss': 0.37732042423179507}
2023-01-04 08:23:56,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:56,030 INFO:     Epoch: 37
2023-01-04 08:23:57,598 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3548305759827296, 'Total loss': 0.3548305759827296} | train loss {'Reaction outcome loss': 0.37450698596101417, 'Total loss': 0.37450698596101417}
2023-01-04 08:23:57,598 INFO:     Found new best model at epoch 37
2023-01-04 08:23:57,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:57,599 INFO:     Epoch: 38
2023-01-04 08:23:59,177 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36897961298624676, 'Total loss': 0.36897961298624676} | train loss {'Reaction outcome loss': 0.3706430479314174, 'Total loss': 0.3706430479314174}
2023-01-04 08:23:59,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:23:59,178 INFO:     Epoch: 39
2023-01-04 08:24:00,672 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.361983186006546, 'Total loss': 0.361983186006546} | train loss {'Reaction outcome loss': 0.3685518294507208, 'Total loss': 0.3685518294507208}
2023-01-04 08:24:00,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:00,673 INFO:     Epoch: 40
2023-01-04 08:24:02,239 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36109185715516406, 'Total loss': 0.36109185715516406} | train loss {'Reaction outcome loss': 0.3686605887622505, 'Total loss': 0.3686605887622505}
2023-01-04 08:24:02,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:02,240 INFO:     Epoch: 41
2023-01-04 08:24:03,814 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3698363244533539, 'Total loss': 0.3698363244533539} | train loss {'Reaction outcome loss': 0.3856413352330202, 'Total loss': 0.3856413352330202}
2023-01-04 08:24:03,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:03,814 INFO:     Epoch: 42
2023-01-04 08:24:05,376 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35728164613246916, 'Total loss': 0.35728164613246916} | train loss {'Reaction outcome loss': 0.35495899539682135, 'Total loss': 0.35495899539682135}
2023-01-04 08:24:05,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:05,377 INFO:     Epoch: 43
2023-01-04 08:24:06,938 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35689170062541964, 'Total loss': 0.35689170062541964} | train loss {'Reaction outcome loss': 0.3540663457105689, 'Total loss': 0.3540663457105689}
2023-01-04 08:24:06,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:06,938 INFO:     Epoch: 44
2023-01-04 08:24:08,499 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3523554901281993, 'Total loss': 0.3523554901281993} | train loss {'Reaction outcome loss': 0.35493617094513297, 'Total loss': 0.35493617094513297}
2023-01-04 08:24:08,499 INFO:     Found new best model at epoch 44
2023-01-04 08:24:08,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:08,500 INFO:     Epoch: 45
2023-01-04 08:24:09,994 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38623085220654807, 'Total loss': 0.38623085220654807} | train loss {'Reaction outcome loss': 0.3524345423970574, 'Total loss': 0.3524345423970574}
2023-01-04 08:24:09,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:09,995 INFO:     Epoch: 46
2023-01-04 08:24:11,566 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35315326750278475, 'Total loss': 0.35315326750278475} | train loss {'Reaction outcome loss': 0.3456600673692436, 'Total loss': 0.3456600673692436}
2023-01-04 08:24:11,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:11,567 INFO:     Epoch: 47
2023-01-04 08:24:13,138 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4061310440301895, 'Total loss': 0.4061310440301895} | train loss {'Reaction outcome loss': 0.3649753197433724, 'Total loss': 0.3649753197433724}
2023-01-04 08:24:13,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:13,139 INFO:     Epoch: 48
2023-01-04 08:24:14,703 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3437033027410507, 'Total loss': 0.3437033027410507} | train loss {'Reaction outcome loss': 0.3612214360872041, 'Total loss': 0.3612214360872041}
2023-01-04 08:24:14,703 INFO:     Found new best model at epoch 48
2023-01-04 08:24:14,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:14,704 INFO:     Epoch: 49
2023-01-04 08:24:16,280 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3578610042730967, 'Total loss': 0.3578610042730967} | train loss {'Reaction outcome loss': 0.3427324126528549, 'Total loss': 0.3427324126528549}
2023-01-04 08:24:16,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:16,281 INFO:     Epoch: 50
2023-01-04 08:24:17,852 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.366403470436732, 'Total loss': 0.366403470436732} | train loss {'Reaction outcome loss': 0.3376008833167124, 'Total loss': 0.3376008833167124}
2023-01-04 08:24:17,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:17,854 INFO:     Epoch: 51
2023-01-04 08:24:19,353 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3749414136012395, 'Total loss': 0.3749414136012395} | train loss {'Reaction outcome loss': 0.3342686194413598, 'Total loss': 0.3342686194413598}
2023-01-04 08:24:19,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:19,353 INFO:     Epoch: 52
2023-01-04 08:24:20,911 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38938387235005695, 'Total loss': 0.38938387235005695} | train loss {'Reaction outcome loss': 0.3343735370865982, 'Total loss': 0.3343735370865982}
2023-01-04 08:24:20,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:20,911 INFO:     Epoch: 53
2023-01-04 08:24:22,485 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3361727366844813, 'Total loss': 0.3361727366844813} | train loss {'Reaction outcome loss': 0.3307271588393791, 'Total loss': 0.3307271588393791}
2023-01-04 08:24:22,485 INFO:     Found new best model at epoch 53
2023-01-04 08:24:22,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:22,486 INFO:     Epoch: 54
2023-01-04 08:24:24,063 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3546643048524857, 'Total loss': 0.3546643048524857} | train loss {'Reaction outcome loss': 0.32706872391914343, 'Total loss': 0.32706872391914343}
2023-01-04 08:24:24,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:24,065 INFO:     Epoch: 55
2023-01-04 08:24:25,638 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38622532586256664, 'Total loss': 0.38622532586256664} | train loss {'Reaction outcome loss': 0.3365060241380032, 'Total loss': 0.3365060241380032}
2023-01-04 08:24:25,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:25,639 INFO:     Epoch: 56
2023-01-04 08:24:27,184 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3947957972685496, 'Total loss': 0.3947957972685496} | train loss {'Reaction outcome loss': 0.3585488979124289, 'Total loss': 0.3585488979124289}
2023-01-04 08:24:27,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:27,184 INFO:     Epoch: 57
2023-01-04 08:24:28,705 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37966391642888386, 'Total loss': 0.37966391642888386} | train loss {'Reaction outcome loss': 0.3320336368722011, 'Total loss': 0.3320336368722011}
2023-01-04 08:24:28,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:28,705 INFO:     Epoch: 58
2023-01-04 08:24:30,262 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35217629770437875, 'Total loss': 0.35217629770437875} | train loss {'Reaction outcome loss': 0.328549904130341, 'Total loss': 0.328549904130341}
2023-01-04 08:24:30,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:30,264 INFO:     Epoch: 59
2023-01-04 08:24:31,816 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40187098979949953, 'Total loss': 0.40187098979949953} | train loss {'Reaction outcome loss': 0.3259677995954627, 'Total loss': 0.3259677995954627}
2023-01-04 08:24:31,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:31,816 INFO:     Epoch: 60
2023-01-04 08:24:33,368 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36141839921474456, 'Total loss': 0.36141839921474456} | train loss {'Reaction outcome loss': 0.33043225921110075, 'Total loss': 0.33043225921110075}
2023-01-04 08:24:33,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:33,368 INFO:     Epoch: 61
2023-01-04 08:24:34,926 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38456800282001496, 'Total loss': 0.38456800282001496} | train loss {'Reaction outcome loss': 0.3240461993854547, 'Total loss': 0.3240461993854547}
2023-01-04 08:24:34,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:34,926 INFO:     Epoch: 62
2023-01-04 08:24:36,435 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3938076833883921, 'Total loss': 0.3938076833883921} | train loss {'Reaction outcome loss': 0.3241545766915964, 'Total loss': 0.3241545766915964}
2023-01-04 08:24:36,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:36,437 INFO:     Epoch: 63
2023-01-04 08:24:37,980 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3788796583811442, 'Total loss': 0.3788796583811442} | train loss {'Reaction outcome loss': 0.31598278431329824, 'Total loss': 0.31598278431329824}
2023-01-04 08:24:37,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:37,980 INFO:     Epoch: 64
2023-01-04 08:24:39,550 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3725064883629481, 'Total loss': 0.3725064883629481} | train loss {'Reaction outcome loss': 0.31875416189006134, 'Total loss': 0.31875416189006134}
2023-01-04 08:24:39,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:39,551 INFO:     Epoch: 65
2023-01-04 08:24:41,121 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3501030405362447, 'Total loss': 0.3501030405362447} | train loss {'Reaction outcome loss': 0.3232696258827396, 'Total loss': 0.3232696258827396}
2023-01-04 08:24:41,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:41,121 INFO:     Epoch: 66
2023-01-04 08:24:42,683 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3819890648126602, 'Total loss': 0.3819890648126602} | train loss {'Reaction outcome loss': 0.3203428425557027, 'Total loss': 0.3203428425557027}
2023-01-04 08:24:42,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:42,684 INFO:     Epoch: 67
2023-01-04 08:24:44,266 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3695648024479548, 'Total loss': 0.3695648024479548} | train loss {'Reaction outcome loss': 0.3118445427845354, 'Total loss': 0.3118445427845354}
2023-01-04 08:24:44,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:44,266 INFO:     Epoch: 68
2023-01-04 08:24:45,769 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3704046706358592, 'Total loss': 0.3704046706358592} | train loss {'Reaction outcome loss': 0.3100648503637716, 'Total loss': 0.3100648503637716}
2023-01-04 08:24:45,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:45,769 INFO:     Epoch: 69
2023-01-04 08:24:47,334 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35738605658213296, 'Total loss': 0.35738605658213296} | train loss {'Reaction outcome loss': 0.3113318774106818, 'Total loss': 0.3113318774106818}
2023-01-04 08:24:47,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:47,334 INFO:     Epoch: 70
2023-01-04 08:24:48,926 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3412154525518417, 'Total loss': 0.3412154525518417} | train loss {'Reaction outcome loss': 0.3068122911601044, 'Total loss': 0.3068122911601044}
2023-01-04 08:24:48,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:48,928 INFO:     Epoch: 71
2023-01-04 08:24:50,502 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3724860280752182, 'Total loss': 0.3724860280752182} | train loss {'Reaction outcome loss': 0.30490754880820925, 'Total loss': 0.30490754880820925}
2023-01-04 08:24:50,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:50,502 INFO:     Epoch: 72
2023-01-04 08:24:52,088 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36132759153842925, 'Total loss': 0.36132759153842925} | train loss {'Reaction outcome loss': 0.3033361336295628, 'Total loss': 0.3033361336295628}
2023-01-04 08:24:52,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:52,088 INFO:     Epoch: 73
2023-01-04 08:24:53,670 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36141324142615, 'Total loss': 0.36141324142615} | train loss {'Reaction outcome loss': 0.3088953714493824, 'Total loss': 0.3088953714493824}
2023-01-04 08:24:53,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:53,671 INFO:     Epoch: 74
2023-01-04 08:24:55,167 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3666107326745987, 'Total loss': 0.3666107326745987} | train loss {'Reaction outcome loss': 0.30770323341256817, 'Total loss': 0.30770323341256817}
2023-01-04 08:24:55,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:55,167 INFO:     Epoch: 75
2023-01-04 08:24:56,718 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36795105536778766, 'Total loss': 0.36795105536778766} | train loss {'Reaction outcome loss': 0.304742622786485, 'Total loss': 0.304742622786485}
2023-01-04 08:24:56,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:56,719 INFO:     Epoch: 76
2023-01-04 08:24:58,273 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3760355621576309, 'Total loss': 0.3760355621576309} | train loss {'Reaction outcome loss': 0.3024210827290148, 'Total loss': 0.3024210827290148}
2023-01-04 08:24:58,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:58,274 INFO:     Epoch: 77
2023-01-04 08:24:59,818 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38928537666797636, 'Total loss': 0.38928537666797636} | train loss {'Reaction outcome loss': 0.3277431121096015, 'Total loss': 0.3277431121096015}
2023-01-04 08:24:59,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:24:59,819 INFO:     Epoch: 78
2023-01-04 08:25:01,367 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3853536417086919, 'Total loss': 0.3853536417086919} | train loss {'Reaction outcome loss': 0.3045878422487041, 'Total loss': 0.3045878422487041}
2023-01-04 08:25:01,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:01,368 INFO:     Epoch: 79
2023-01-04 08:25:02,926 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34124022126197817, 'Total loss': 0.34124022126197817} | train loss {'Reaction outcome loss': 0.31880054185782775, 'Total loss': 0.31880054185782775}
2023-01-04 08:25:02,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:02,926 INFO:     Epoch: 80
2023-01-04 08:25:04,419 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3668136179447174, 'Total loss': 0.3668136179447174} | train loss {'Reaction outcome loss': 0.2965102788276862, 'Total loss': 0.2965102788276862}
2023-01-04 08:25:04,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:04,420 INFO:     Epoch: 81
2023-01-04 08:25:05,969 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3638514369726181, 'Total loss': 0.3638514369726181} | train loss {'Reaction outcome loss': 0.2950306706270962, 'Total loss': 0.2950306706270962}
2023-01-04 08:25:05,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:05,971 INFO:     Epoch: 82
2023-01-04 08:25:07,520 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3899049937725067, 'Total loss': 0.3899049937725067} | train loss {'Reaction outcome loss': 0.2970194426513668, 'Total loss': 0.2970194426513668}
2023-01-04 08:25:07,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:07,520 INFO:     Epoch: 83
2023-01-04 08:25:09,088 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40597748657067617, 'Total loss': 0.40597748657067617} | train loss {'Reaction outcome loss': 0.3440805430915477, 'Total loss': 0.3440805430915477}
2023-01-04 08:25:09,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:09,089 INFO:     Epoch: 84
2023-01-04 08:25:10,638 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3559497594833374, 'Total loss': 0.3559497594833374} | train loss {'Reaction outcome loss': 0.3190143650694602, 'Total loss': 0.3190143650694602}
2023-01-04 08:25:10,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:10,638 INFO:     Epoch: 85
2023-01-04 08:25:12,193 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36262052158514657, 'Total loss': 0.36262052158514657} | train loss {'Reaction outcome loss': 0.31142463939276227, 'Total loss': 0.31142463939276227}
2023-01-04 08:25:12,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:12,195 INFO:     Epoch: 86
2023-01-04 08:25:13,690 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36456574896971383, 'Total loss': 0.36456574896971383} | train loss {'Reaction outcome loss': 0.29687670059502125, 'Total loss': 0.29687670059502125}
2023-01-04 08:25:13,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:13,690 INFO:     Epoch: 87
2023-01-04 08:25:15,262 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3478100856145223, 'Total loss': 0.3478100856145223} | train loss {'Reaction outcome loss': 0.2902135954076505, 'Total loss': 0.2902135954076505}
2023-01-04 08:25:15,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:15,262 INFO:     Epoch: 88
2023-01-04 08:25:16,808 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3597273101409276, 'Total loss': 0.3597273101409276} | train loss {'Reaction outcome loss': 0.28272772969111154, 'Total loss': 0.28272772969111154}
2023-01-04 08:25:16,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:16,809 INFO:     Epoch: 89
2023-01-04 08:25:18,364 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3498032371203105, 'Total loss': 0.3498032371203105} | train loss {'Reaction outcome loss': 0.2911750601144403, 'Total loss': 0.2911750601144403}
2023-01-04 08:25:18,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:18,365 INFO:     Epoch: 90
2023-01-04 08:25:19,927 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3194738656282425, 'Total loss': 0.3194738656282425} | train loss {'Reaction outcome loss': 0.2858413170037818, 'Total loss': 0.2858413170037818}
2023-01-04 08:25:19,927 INFO:     Found new best model at epoch 90
2023-01-04 08:25:19,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:19,928 INFO:     Epoch: 91
2023-01-04 08:25:21,485 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4093840221563975, 'Total loss': 0.4093840221563975} | train loss {'Reaction outcome loss': 0.2922341031312565, 'Total loss': 0.2922341031312565}
2023-01-04 08:25:21,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:21,486 INFO:     Epoch: 92
2023-01-04 08:25:22,978 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.378303250670433, 'Total loss': 0.378303250670433} | train loss {'Reaction outcome loss': 0.29409742163683195, 'Total loss': 0.29409742163683195}
2023-01-04 08:25:22,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:22,978 INFO:     Epoch: 93
2023-01-04 08:25:24,538 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3456714098652204, 'Total loss': 0.3456714098652204} | train loss {'Reaction outcome loss': 0.2975633710983844, 'Total loss': 0.2975633710983844}
2023-01-04 08:25:24,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:24,540 INFO:     Epoch: 94
2023-01-04 08:25:26,102 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35669583405057587, 'Total loss': 0.35669583405057587} | train loss {'Reaction outcome loss': 0.28236922481167714, 'Total loss': 0.28236922481167714}
2023-01-04 08:25:26,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:26,102 INFO:     Epoch: 95
2023-01-04 08:25:27,663 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37839320103327434, 'Total loss': 0.37839320103327434} | train loss {'Reaction outcome loss': 0.28080744908146554, 'Total loss': 0.28080744908146554}
2023-01-04 08:25:27,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:27,663 INFO:     Epoch: 96
2023-01-04 08:25:29,215 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3707410792509715, 'Total loss': 0.3707410792509715} | train loss {'Reaction outcome loss': 0.29084550203296583, 'Total loss': 0.29084550203296583}
2023-01-04 08:25:29,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:29,216 INFO:     Epoch: 97
2023-01-04 08:25:30,779 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3499740997950236, 'Total loss': 0.3499740997950236} | train loss {'Reaction outcome loss': 0.3061423219025027, 'Total loss': 0.3061423219025027}
2023-01-04 08:25:30,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:30,781 INFO:     Epoch: 98
2023-01-04 08:25:32,287 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3459539959828059, 'Total loss': 0.3459539959828059} | train loss {'Reaction outcome loss': 0.29349104659124114, 'Total loss': 0.29349104659124114}
2023-01-04 08:25:32,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:32,287 INFO:     Epoch: 99
2023-01-04 08:25:33,846 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3424740801254908, 'Total loss': 0.3424740801254908} | train loss {'Reaction outcome loss': 0.2904592756505894, 'Total loss': 0.2904592756505894}
2023-01-04 08:25:33,846 INFO:     Best model found after epoch 91 of 100.
2023-01-04 08:25:33,847 INFO:   Done with stage: TRAINING
2023-01-04 08:25:33,847 INFO:   Starting stage: EVALUATION
2023-01-04 08:25:33,976 INFO:   Done with stage: EVALUATION
2023-01-04 08:25:33,976 INFO:   Leaving out SEQ value Fold_5
2023-01-04 08:25:33,988 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 08:25:33,988 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:25:34,647 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:25:34,647 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:25:34,716 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:25:34,716 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:25:34,716 INFO:     No hyperparam tuning for this model
2023-01-04 08:25:34,716 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:25:34,716 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:25:34,717 INFO:     None feature selector for col prot
2023-01-04 08:25:34,717 INFO:     None feature selector for col prot
2023-01-04 08:25:34,717 INFO:     None feature selector for col prot
2023-01-04 08:25:34,718 INFO:     None feature selector for col chem
2023-01-04 08:25:34,718 INFO:     None feature selector for col chem
2023-01-04 08:25:34,718 INFO:     None feature selector for col chem
2023-01-04 08:25:34,718 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:25:34,718 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:25:34,719 INFO:     Number of params in model 70111
2023-01-04 08:25:34,722 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:25:34,722 INFO:   Starting stage: TRAINING
2023-01-04 08:25:34,765 INFO:     Val loss before train {'Reaction outcome loss': 0.8454630732536316, 'Total loss': 0.8454630732536316}
2023-01-04 08:25:34,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:34,765 INFO:     Epoch: 0
2023-01-04 08:25:36,330 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6232914328575134, 'Total loss': 0.6232914328575134} | train loss {'Reaction outcome loss': 0.8423505818155268, 'Total loss': 0.8423505818155268}
2023-01-04 08:25:36,331 INFO:     Found new best model at epoch 0
2023-01-04 08:25:36,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:36,332 INFO:     Epoch: 1
2023-01-04 08:25:37,901 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.517318844795227, 'Total loss': 0.517318844795227} | train loss {'Reaction outcome loss': 0.6601934375960904, 'Total loss': 0.6601934375960904}
2023-01-04 08:25:37,901 INFO:     Found new best model at epoch 1
2023-01-04 08:25:37,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:37,902 INFO:     Epoch: 2
2023-01-04 08:25:39,467 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47002250850200655, 'Total loss': 0.47002250850200655} | train loss {'Reaction outcome loss': 0.5702656811970666, 'Total loss': 0.5702656811970666}
2023-01-04 08:25:39,467 INFO:     Found new best model at epoch 2
2023-01-04 08:25:39,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:39,468 INFO:     Epoch: 3
2023-01-04 08:25:40,966 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4614988505840302, 'Total loss': 0.4614988505840302} | train loss {'Reaction outcome loss': 0.5332134011527692, 'Total loss': 0.5332134011527692}
2023-01-04 08:25:40,966 INFO:     Found new best model at epoch 3
2023-01-04 08:25:40,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:40,967 INFO:     Epoch: 4
2023-01-04 08:25:42,510 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44744074245293936, 'Total loss': 0.44744074245293936} | train loss {'Reaction outcome loss': 0.5090696034341082, 'Total loss': 0.5090696034341082}
2023-01-04 08:25:42,512 INFO:     Found new best model at epoch 4
2023-01-04 08:25:42,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:42,512 INFO:     Epoch: 5
2023-01-04 08:25:44,117 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42837700843811033, 'Total loss': 0.42837700843811033} | train loss {'Reaction outcome loss': 0.5020867310168511, 'Total loss': 0.5020867310168511}
2023-01-04 08:25:44,117 INFO:     Found new best model at epoch 5
2023-01-04 08:25:44,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:44,118 INFO:     Epoch: 6
2023-01-04 08:25:45,693 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4143840382496516, 'Total loss': 0.4143840382496516} | train loss {'Reaction outcome loss': 0.48927723043446936, 'Total loss': 0.48927723043446936}
2023-01-04 08:25:45,694 INFO:     Found new best model at epoch 6
2023-01-04 08:25:45,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:45,694 INFO:     Epoch: 7
2023-01-04 08:25:47,313 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43031661907831825, 'Total loss': 0.43031661907831825} | train loss {'Reaction outcome loss': 0.4848183965317179, 'Total loss': 0.4848183965317179}
2023-01-04 08:25:47,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:47,313 INFO:     Epoch: 8
2023-01-04 08:25:48,885 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4242434392372767, 'Total loss': 0.4242434392372767} | train loss {'Reaction outcome loss': 0.47611879613855684, 'Total loss': 0.47611879613855684}
2023-01-04 08:25:48,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:48,886 INFO:     Epoch: 9
2023-01-04 08:25:50,424 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.418300054470698, 'Total loss': 0.418300054470698} | train loss {'Reaction outcome loss': 0.4647752868031767, 'Total loss': 0.4647752868031767}
2023-01-04 08:25:50,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:50,424 INFO:     Epoch: 10
2023-01-04 08:25:51,987 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4354813486337662, 'Total loss': 0.4354813486337662} | train loss {'Reaction outcome loss': 0.45944643972797944, 'Total loss': 0.45944643972797944}
2023-01-04 08:25:51,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:51,988 INFO:     Epoch: 11
2023-01-04 08:25:53,543 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3914592802524567, 'Total loss': 0.3914592802524567} | train loss {'Reaction outcome loss': 0.45319192073835796, 'Total loss': 0.45319192073835796}
2023-01-04 08:25:53,543 INFO:     Found new best model at epoch 11
2023-01-04 08:25:53,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:53,544 INFO:     Epoch: 12
2023-01-04 08:25:55,107 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4046310395002365, 'Total loss': 0.4046310395002365} | train loss {'Reaction outcome loss': 0.45181955095878146, 'Total loss': 0.45181955095878146}
2023-01-04 08:25:55,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:55,108 INFO:     Epoch: 13
2023-01-04 08:25:56,670 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40588908195495604, 'Total loss': 0.40588908195495604} | train loss {'Reaction outcome loss': 0.4449993279974383, 'Total loss': 0.4449993279974383}
2023-01-04 08:25:56,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:56,670 INFO:     Epoch: 14
2023-01-04 08:25:58,178 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3760972221692403, 'Total loss': 0.3760972221692403} | train loss {'Reaction outcome loss': 0.44084289336462745, 'Total loss': 0.44084289336462745}
2023-01-04 08:25:58,178 INFO:     Found new best model at epoch 14
2023-01-04 08:25:58,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:58,179 INFO:     Epoch: 15
2023-01-04 08:25:59,729 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41724010606606804, 'Total loss': 0.41724010606606804} | train loss {'Reaction outcome loss': 0.43407106781479254, 'Total loss': 0.43407106781479254}
2023-01-04 08:25:59,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:25:59,729 INFO:     Epoch: 16
2023-01-04 08:26:01,291 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39859984318415326, 'Total loss': 0.39859984318415326} | train loss {'Reaction outcome loss': 0.42981934052512105, 'Total loss': 0.42981934052512105}
2023-01-04 08:26:01,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:01,292 INFO:     Epoch: 17
2023-01-04 08:26:02,839 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39866891503334045, 'Total loss': 0.39866891503334045} | train loss {'Reaction outcome loss': 0.4289685804598598, 'Total loss': 0.4289685804598598}
2023-01-04 08:26:02,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:02,839 INFO:     Epoch: 18
2023-01-04 08:26:04,406 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38946384290854136, 'Total loss': 0.38946384290854136} | train loss {'Reaction outcome loss': 0.4204707893707692, 'Total loss': 0.4204707893707692}
2023-01-04 08:26:04,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:04,406 INFO:     Epoch: 19
2023-01-04 08:26:05,967 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3636862208445867, 'Total loss': 0.3636862208445867} | train loss {'Reaction outcome loss': 0.4202195790592944, 'Total loss': 0.4202195790592944}
2023-01-04 08:26:05,968 INFO:     Found new best model at epoch 19
2023-01-04 08:26:05,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:05,969 INFO:     Epoch: 20
2023-01-04 08:26:07,458 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3908074403802554, 'Total loss': 0.3908074403802554} | train loss {'Reaction outcome loss': 0.41186490213827964, 'Total loss': 0.41186490213827964}
2023-01-04 08:26:07,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:07,458 INFO:     Epoch: 21
2023-01-04 08:26:08,995 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36290380160013835, 'Total loss': 0.36290380160013835} | train loss {'Reaction outcome loss': 0.41114643460899486, 'Total loss': 0.41114643460899486}
2023-01-04 08:26:08,995 INFO:     Found new best model at epoch 21
2023-01-04 08:26:08,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:08,996 INFO:     Epoch: 22
2023-01-04 08:26:10,548 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38043231070041655, 'Total loss': 0.38043231070041655} | train loss {'Reaction outcome loss': 0.40692844669526235, 'Total loss': 0.40692844669526235}
2023-01-04 08:26:10,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:10,548 INFO:     Epoch: 23
2023-01-04 08:26:12,100 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38196215629577634, 'Total loss': 0.38196215629577634} | train loss {'Reaction outcome loss': 0.40393599550431386, 'Total loss': 0.40393599550431386}
2023-01-04 08:26:12,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:12,101 INFO:     Epoch: 24
2023-01-04 08:26:13,645 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3907775282859802, 'Total loss': 0.3907775282859802} | train loss {'Reaction outcome loss': 0.39712785932131195, 'Total loss': 0.39712785932131195}
2023-01-04 08:26:13,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:13,646 INFO:     Epoch: 25
2023-01-04 08:26:15,192 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3961114118496577, 'Total loss': 0.3961114118496577} | train loss {'Reaction outcome loss': 0.39264842964681906, 'Total loss': 0.39264842964681906}
2023-01-04 08:26:15,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:15,193 INFO:     Epoch: 26
2023-01-04 08:26:16,674 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36878611048062643, 'Total loss': 0.36878611048062643} | train loss {'Reaction outcome loss': 0.38827359670981604, 'Total loss': 0.38827359670981604}
2023-01-04 08:26:16,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:16,674 INFO:     Epoch: 27
2023-01-04 08:26:18,228 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3648530438542366, 'Total loss': 0.3648530438542366} | train loss {'Reaction outcome loss': 0.3844527359043218, 'Total loss': 0.3844527359043218}
2023-01-04 08:26:18,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:18,228 INFO:     Epoch: 28
2023-01-04 08:26:19,781 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3835865209499995, 'Total loss': 0.3835865209499995} | train loss {'Reaction outcome loss': 0.3848019109682486, 'Total loss': 0.3848019109682486}
2023-01-04 08:26:19,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:19,783 INFO:     Epoch: 29
2023-01-04 08:26:21,336 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36528274218241374, 'Total loss': 0.36528274218241374} | train loss {'Reaction outcome loss': 0.3801772010240314, 'Total loss': 0.3801772010240314}
2023-01-04 08:26:21,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:21,336 INFO:     Epoch: 30
2023-01-04 08:26:22,890 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.391912313302358, 'Total loss': 0.391912313302358} | train loss {'Reaction outcome loss': 0.3756101703277994, 'Total loss': 0.3756101703277994}
2023-01-04 08:26:22,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:22,891 INFO:     Epoch: 31
2023-01-04 08:26:24,458 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37555100321769713, 'Total loss': 0.37555100321769713} | train loss {'Reaction outcome loss': 0.3751844013856206, 'Total loss': 0.3751844013856206}
2023-01-04 08:26:24,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:24,459 INFO:     Epoch: 32
2023-01-04 08:26:25,955 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3822102705637614, 'Total loss': 0.3822102705637614} | train loss {'Reaction outcome loss': 0.3693523512689215, 'Total loss': 0.3693523512689215}
2023-01-04 08:26:25,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:25,955 INFO:     Epoch: 33
2023-01-04 08:26:27,509 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3925350407759349, 'Total loss': 0.3925350407759349} | train loss {'Reaction outcome loss': 0.36005331054060896, 'Total loss': 0.36005331054060896}
2023-01-04 08:26:27,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:27,510 INFO:     Epoch: 34
2023-01-04 08:26:29,067 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36984297931194304, 'Total loss': 0.36984297931194304} | train loss {'Reaction outcome loss': 0.3631170589463375, 'Total loss': 0.3631170589463375}
2023-01-04 08:26:29,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:29,068 INFO:     Epoch: 35
2023-01-04 08:26:30,634 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3690398375193278, 'Total loss': 0.3690398375193278} | train loss {'Reaction outcome loss': 0.3609564056088778, 'Total loss': 0.3609564056088778}
2023-01-04 08:26:30,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:30,635 INFO:     Epoch: 36
2023-01-04 08:26:32,216 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37606992075840634, 'Total loss': 0.37606992075840634} | train loss {'Reaction outcome loss': 0.3571224573071683, 'Total loss': 0.3571224573071683}
2023-01-04 08:26:32,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:32,216 INFO:     Epoch: 37
2023-01-04 08:26:33,767 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36785148779551186, 'Total loss': 0.36785148779551186} | train loss {'Reaction outcome loss': 0.35405863271454613, 'Total loss': 0.35405863271454613}
2023-01-04 08:26:33,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:33,767 INFO:     Epoch: 38
2023-01-04 08:26:34,977 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37273937165737153, 'Total loss': 0.37273937165737153} | train loss {'Reaction outcome loss': 0.3494429104702567, 'Total loss': 0.3494429104702567}
2023-01-04 08:26:34,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:34,977 INFO:     Epoch: 39
2023-01-04 08:26:36,003 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36434299051761626, 'Total loss': 0.36434299051761626} | train loss {'Reaction outcome loss': 0.34433370957736076, 'Total loss': 0.34433370957736076}
2023-01-04 08:26:36,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:36,004 INFO:     Epoch: 40
2023-01-04 08:26:37,020 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34364239275455477, 'Total loss': 0.34364239275455477} | train loss {'Reaction outcome loss': 0.3441353185835298, 'Total loss': 0.3441353185835298}
2023-01-04 08:26:37,020 INFO:     Found new best model at epoch 40
2023-01-04 08:26:37,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:37,021 INFO:     Epoch: 41
2023-01-04 08:26:38,036 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36412076056003573, 'Total loss': 0.36412076056003573} | train loss {'Reaction outcome loss': 0.34153609835821797, 'Total loss': 0.34153609835821797}
2023-01-04 08:26:38,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:38,037 INFO:     Epoch: 42
2023-01-04 08:26:39,294 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3867859582106272, 'Total loss': 0.3867859582106272} | train loss {'Reaction outcome loss': 0.3386901401870948, 'Total loss': 0.3386901401870948}
2023-01-04 08:26:39,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:39,295 INFO:     Epoch: 43
2023-01-04 08:26:40,846 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36768481532732644, 'Total loss': 0.36768481532732644} | train loss {'Reaction outcome loss': 0.33788114417653653, 'Total loss': 0.33788114417653653}
2023-01-04 08:26:40,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:40,847 INFO:     Epoch: 44
2023-01-04 08:26:42,425 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.352665255467097, 'Total loss': 0.352665255467097} | train loss {'Reaction outcome loss': 0.3316928930177155, 'Total loss': 0.3316928930177155}
2023-01-04 08:26:42,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:42,426 INFO:     Epoch: 45
2023-01-04 08:26:44,028 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3671530564626058, 'Total loss': 0.3671530564626058} | train loss {'Reaction outcome loss': 0.3308503033075522, 'Total loss': 0.3308503033075522}
2023-01-04 08:26:44,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:44,028 INFO:     Epoch: 46
2023-01-04 08:26:45,594 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37313315471013386, 'Total loss': 0.37313315471013386} | train loss {'Reaction outcome loss': 0.32773721976615894, 'Total loss': 0.32773721976615894}
2023-01-04 08:26:45,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:45,594 INFO:     Epoch: 47
2023-01-04 08:26:47,190 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3539337247610092, 'Total loss': 0.3539337247610092} | train loss {'Reaction outcome loss': 0.3284773283809531, 'Total loss': 0.3284773283809531}
2023-01-04 08:26:47,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:47,190 INFO:     Epoch: 48
2023-01-04 08:26:48,721 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35062755445639293, 'Total loss': 0.35062755445639293} | train loss {'Reaction outcome loss': 0.3233322657187493, 'Total loss': 0.3233322657187493}
2023-01-04 08:26:48,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:48,722 INFO:     Epoch: 49
2023-01-04 08:26:50,273 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36640654504299164, 'Total loss': 0.36640654504299164} | train loss {'Reaction outcome loss': 0.31907617408338435, 'Total loss': 0.31907617408338435}
2023-01-04 08:26:50,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:50,273 INFO:     Epoch: 50
2023-01-04 08:26:51,846 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35624663531780243, 'Total loss': 0.35624663531780243} | train loss {'Reaction outcome loss': 0.31795584488431466, 'Total loss': 0.31795584488431466}
2023-01-04 08:26:51,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:51,846 INFO:     Epoch: 51
2023-01-04 08:26:53,448 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34926682263612746, 'Total loss': 0.34926682263612746} | train loss {'Reaction outcome loss': 0.314975450534898, 'Total loss': 0.314975450534898}
2023-01-04 08:26:53,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:53,449 INFO:     Epoch: 52
2023-01-04 08:26:55,026 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3768828779459, 'Total loss': 0.3768828779459} | train loss {'Reaction outcome loss': 0.31584963743114297, 'Total loss': 0.31584963743114297}
2023-01-04 08:26:55,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:55,027 INFO:     Epoch: 53
2023-01-04 08:26:56,607 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.367236586411794, 'Total loss': 0.367236586411794} | train loss {'Reaction outcome loss': 0.3127925117308482, 'Total loss': 0.3127925117308482}
2023-01-04 08:26:56,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:56,607 INFO:     Epoch: 54
2023-01-04 08:26:58,143 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3328804229696592, 'Total loss': 0.3328804229696592} | train loss {'Reaction outcome loss': 0.3036634065345306, 'Total loss': 0.3036634065345306}
2023-01-04 08:26:58,144 INFO:     Found new best model at epoch 54
2023-01-04 08:26:58,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:58,144 INFO:     Epoch: 55
2023-01-04 08:26:59,688 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36592235465844475, 'Total loss': 0.36592235465844475} | train loss {'Reaction outcome loss': 0.31002683391532315, 'Total loss': 0.31002683391532315}
2023-01-04 08:26:59,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:26:59,688 INFO:     Epoch: 56
2023-01-04 08:27:01,246 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37892712155977887, 'Total loss': 0.37892712155977887} | train loss {'Reaction outcome loss': 0.3036583564664483, 'Total loss': 0.3036583564664483}
2023-01-04 08:27:01,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:01,248 INFO:     Epoch: 57
2023-01-04 08:27:02,844 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3420320600271225, 'Total loss': 0.3420320600271225} | train loss {'Reaction outcome loss': 0.30121719275033, 'Total loss': 0.30121719275033}
2023-01-04 08:27:02,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:02,844 INFO:     Epoch: 58
2023-01-04 08:27:04,403 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34186160067717236, 'Total loss': 0.34186160067717236} | train loss {'Reaction outcome loss': 0.29856977931859263, 'Total loss': 0.29856977931859263}
2023-01-04 08:27:04,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:04,403 INFO:     Epoch: 59
2023-01-04 08:27:05,948 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37435041964054105, 'Total loss': 0.37435041964054105} | train loss {'Reaction outcome loss': 0.2992634354192858, 'Total loss': 0.2992634354192858}
2023-01-04 08:27:05,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:05,949 INFO:     Epoch: 60
2023-01-04 08:27:07,516 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3671087165673574, 'Total loss': 0.3671087165673574} | train loss {'Reaction outcome loss': 0.29948292293380746, 'Total loss': 0.29948292293380746}
2023-01-04 08:27:07,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:07,517 INFO:     Epoch: 61
2023-01-04 08:27:09,049 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3216996818780899, 'Total loss': 0.3216996818780899} | train loss {'Reaction outcome loss': 0.2944725909764586, 'Total loss': 0.2944725909764586}
2023-01-04 08:27:09,049 INFO:     Found new best model at epoch 61
2023-01-04 08:27:09,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:09,050 INFO:     Epoch: 62
2023-01-04 08:27:10,612 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34424102132519085, 'Total loss': 0.34424102132519085} | train loss {'Reaction outcome loss': 0.2942492187238342, 'Total loss': 0.2942492187238342}
2023-01-04 08:27:10,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:10,613 INFO:     Epoch: 63
2023-01-04 08:27:12,188 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.33536389420429863, 'Total loss': 0.33536389420429863} | train loss {'Reaction outcome loss': 0.29230715702909854, 'Total loss': 0.29230715702909854}
2023-01-04 08:27:12,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:12,188 INFO:     Epoch: 64
2023-01-04 08:27:13,757 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34557949950297673, 'Total loss': 0.34557949950297673} | train loss {'Reaction outcome loss': 0.2880461782163231, 'Total loss': 0.2880461782163231}
2023-01-04 08:27:13,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:13,759 INFO:     Epoch: 65
2023-01-04 08:27:15,315 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.386980668703715, 'Total loss': 0.386980668703715} | train loss {'Reaction outcome loss': 0.2905099795129325, 'Total loss': 0.2905099795129325}
2023-01-04 08:27:15,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:15,315 INFO:     Epoch: 66
2023-01-04 08:27:16,859 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35387011667092644, 'Total loss': 0.35387011667092644} | train loss {'Reaction outcome loss': 0.2880637115439138, 'Total loss': 0.2880637115439138}
2023-01-04 08:27:16,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:16,860 INFO:     Epoch: 67
2023-01-04 08:27:18,406 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3586308906475703, 'Total loss': 0.3586308906475703} | train loss {'Reaction outcome loss': 0.2841796274380994, 'Total loss': 0.2841796274380994}
2023-01-04 08:27:18,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:18,406 INFO:     Epoch: 68
2023-01-04 08:27:19,963 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3478785450259844, 'Total loss': 0.3478785450259844} | train loss {'Reaction outcome loss': 0.2822938060878847, 'Total loss': 0.2822938060878847}
2023-01-04 08:27:19,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:19,964 INFO:     Epoch: 69
2023-01-04 08:27:21,520 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.32924639781316123, 'Total loss': 0.32924639781316123} | train loss {'Reaction outcome loss': 0.28371874479718157, 'Total loss': 0.28371874479718157}
2023-01-04 08:27:21,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:21,520 INFO:     Epoch: 70
2023-01-04 08:27:23,090 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3512862732013067, 'Total loss': 0.3512862732013067} | train loss {'Reaction outcome loss': 0.2811049820606459, 'Total loss': 0.2811049820606459}
2023-01-04 08:27:23,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:23,090 INFO:     Epoch: 71
2023-01-04 08:27:24,618 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3600188394387563, 'Total loss': 0.3600188394387563} | train loss {'Reaction outcome loss': 0.2782878245122811, 'Total loss': 0.2782878245122811}
2023-01-04 08:27:24,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:24,618 INFO:     Epoch: 72
2023-01-04 08:27:26,152 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3449403742949168, 'Total loss': 0.3449403742949168} | train loss {'Reaction outcome loss': 0.2835115084848249, 'Total loss': 0.2835115084848249}
2023-01-04 08:27:26,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:26,153 INFO:     Epoch: 73
2023-01-04 08:27:27,722 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33727999925613406, 'Total loss': 0.33727999925613406} | train loss {'Reaction outcome loss': 0.27999062278049086, 'Total loss': 0.27999062278049086}
2023-01-04 08:27:27,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:27,722 INFO:     Epoch: 74
2023-01-04 08:27:29,288 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.32408866435289385, 'Total loss': 0.32408866435289385} | train loss {'Reaction outcome loss': 0.2789588919454103, 'Total loss': 0.2789588919454103}
2023-01-04 08:27:29,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:29,288 INFO:     Epoch: 75
2023-01-04 08:27:30,868 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.34118111431598663, 'Total loss': 0.34118111431598663} | train loss {'Reaction outcome loss': 0.27315217380274076, 'Total loss': 0.27315217380274076}
2023-01-04 08:27:30,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:30,868 INFO:     Epoch: 76
2023-01-04 08:27:32,427 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38034327427546183, 'Total loss': 0.38034327427546183} | train loss {'Reaction outcome loss': 0.2773783467037583, 'Total loss': 0.2773783467037583}
2023-01-04 08:27:32,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:32,429 INFO:     Epoch: 77
2023-01-04 08:27:33,974 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3520232011874517, 'Total loss': 0.3520232011874517} | train loss {'Reaction outcome loss': 0.26976781650463166, 'Total loss': 0.26976781650463166}
2023-01-04 08:27:33,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:33,974 INFO:     Epoch: 78
2023-01-04 08:27:35,494 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3532079249620438, 'Total loss': 0.3532079249620438} | train loss {'Reaction outcome loss': 0.27161021019577547, 'Total loss': 0.27161021019577547}
2023-01-04 08:27:35,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:35,495 INFO:     Epoch: 79
2023-01-04 08:27:37,044 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.342176412542661, 'Total loss': 0.342176412542661} | train loss {'Reaction outcome loss': 0.2756694191360732, 'Total loss': 0.2756694191360732}
2023-01-04 08:27:37,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:37,044 INFO:     Epoch: 80
2023-01-04 08:27:38,587 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3232863575220108, 'Total loss': 0.3232863575220108} | train loss {'Reaction outcome loss': 0.2719958982554799, 'Total loss': 0.2719958982554799}
2023-01-04 08:27:38,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:38,588 INFO:     Epoch: 81
2023-01-04 08:27:40,149 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3712091455856959, 'Total loss': 0.3712091455856959} | train loss {'Reaction outcome loss': 0.26205980570630477, 'Total loss': 0.26205980570630477}
2023-01-04 08:27:40,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:40,150 INFO:     Epoch: 82
2023-01-04 08:27:41,710 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37414373755455016, 'Total loss': 0.37414373755455016} | train loss {'Reaction outcome loss': 0.2675109783503553, 'Total loss': 0.2675109783503553}
2023-01-04 08:27:41,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:41,710 INFO:     Epoch: 83
2023-01-04 08:27:43,244 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37946424186229705, 'Total loss': 0.37946424186229705} | train loss {'Reaction outcome loss': 0.26385410614177207, 'Total loss': 0.26385410614177207}
2023-01-04 08:27:43,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:43,246 INFO:     Epoch: 84
2023-01-04 08:27:44,784 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35824428002039593, 'Total loss': 0.35824428002039593} | train loss {'Reaction outcome loss': 0.26776692116572537, 'Total loss': 0.26776692116572537}
2023-01-04 08:27:44,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:44,784 INFO:     Epoch: 85
2023-01-04 08:27:46,349 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37682566146055857, 'Total loss': 0.37682566146055857} | train loss {'Reaction outcome loss': 0.26384774933061445, 'Total loss': 0.26384774933061445}
2023-01-04 08:27:46,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:46,350 INFO:     Epoch: 86
2023-01-04 08:27:47,891 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3182743236422539, 'Total loss': 0.3182743236422539} | train loss {'Reaction outcome loss': 0.2580731173822596, 'Total loss': 0.2580731173822596}
2023-01-04 08:27:47,891 INFO:     Found new best model at epoch 86
2023-01-04 08:27:47,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:47,892 INFO:     Epoch: 87
2023-01-04 08:27:49,439 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3370410626133283, 'Total loss': 0.3370410626133283} | train loss {'Reaction outcome loss': 0.265057972622262, 'Total loss': 0.265057972622262}
2023-01-04 08:27:49,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:49,440 INFO:     Epoch: 88
2023-01-04 08:27:50,985 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36342722475528716, 'Total loss': 0.36342722475528716} | train loss {'Reaction outcome loss': 0.25597167754754263, 'Total loss': 0.25597167754754263}
2023-01-04 08:27:50,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:50,987 INFO:     Epoch: 89
2023-01-04 08:27:52,527 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3419180393218994, 'Total loss': 0.3419180393218994} | train loss {'Reaction outcome loss': 0.2539725261689954, 'Total loss': 0.2539725261689954}
2023-01-04 08:27:52,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:52,527 INFO:     Epoch: 90
2023-01-04 08:27:54,044 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.34268667300542194, 'Total loss': 0.34268667300542194} | train loss {'Reaction outcome loss': 0.26085179102765094, 'Total loss': 0.26085179102765094}
2023-01-04 08:27:54,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:54,044 INFO:     Epoch: 91
2023-01-04 08:27:55,599 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3607350021600723, 'Total loss': 0.3607350021600723} | train loss {'Reaction outcome loss': 0.25959876362597467, 'Total loss': 0.25959876362597467}
2023-01-04 08:27:55,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:55,599 INFO:     Epoch: 92
2023-01-04 08:27:57,158 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.33077586988608043, 'Total loss': 0.33077586988608043} | train loss {'Reaction outcome loss': 0.2626167542775185, 'Total loss': 0.2626167542775185}
2023-01-04 08:27:57,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:57,160 INFO:     Epoch: 93
2023-01-04 08:27:58,742 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3510327031215032, 'Total loss': 0.3510327031215032} | train loss {'Reaction outcome loss': 0.253933825284673, 'Total loss': 0.253933825284673}
2023-01-04 08:27:58,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:27:58,743 INFO:     Epoch: 94
2023-01-04 08:28:00,268 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3362901210784912, 'Total loss': 0.3362901210784912} | train loss {'Reaction outcome loss': 0.26449967205309266, 'Total loss': 0.26449967205309266}
2023-01-04 08:28:00,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:00,268 INFO:     Epoch: 95
2023-01-04 08:28:01,790 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3426637147863706, 'Total loss': 0.3426637147863706} | train loss {'Reaction outcome loss': 0.2539224363056546, 'Total loss': 0.2539224363056546}
2023-01-04 08:28:01,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:01,792 INFO:     Epoch: 96
2023-01-04 08:28:03,336 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3362698217233022, 'Total loss': 0.3362698217233022} | train loss {'Reaction outcome loss': 0.25357257473931416, 'Total loss': 0.25357257473931416}
2023-01-04 08:28:03,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:03,336 INFO:     Epoch: 97
2023-01-04 08:28:04,891 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.341198605298996, 'Total loss': 0.341198605298996} | train loss {'Reaction outcome loss': 0.2557615696012113, 'Total loss': 0.2557615696012113}
2023-01-04 08:28:04,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:04,891 INFO:     Epoch: 98
2023-01-04 08:28:06,456 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33773620923360187, 'Total loss': 0.33773620923360187} | train loss {'Reaction outcome loss': 0.2535434250420612, 'Total loss': 0.2535434250420612}
2023-01-04 08:28:06,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:06,457 INFO:     Epoch: 99
2023-01-04 08:28:08,048 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34596135914325715, 'Total loss': 0.34596135914325715} | train loss {'Reaction outcome loss': 0.25152876370650334, 'Total loss': 0.25152876370650334}
2023-01-04 08:28:08,049 INFO:     Best model found after epoch 87 of 100.
2023-01-04 08:28:08,049 INFO:   Done with stage: TRAINING
2023-01-04 08:28:08,049 INFO:   Starting stage: EVALUATION
2023-01-04 08:28:08,171 INFO:   Done with stage: EVALUATION
2023-01-04 08:28:08,171 INFO:   Leaving out SEQ value Fold_6
2023-01-04 08:28:08,184 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 08:28:08,184 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:28:08,827 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:28:08,827 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:28:08,893 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:28:08,894 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:28:08,894 INFO:     No hyperparam tuning for this model
2023-01-04 08:28:08,894 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:28:08,894 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:28:08,895 INFO:     None feature selector for col prot
2023-01-04 08:28:08,895 INFO:     None feature selector for col prot
2023-01-04 08:28:08,895 INFO:     None feature selector for col prot
2023-01-04 08:28:08,895 INFO:     None feature selector for col chem
2023-01-04 08:28:08,896 INFO:     None feature selector for col chem
2023-01-04 08:28:08,896 INFO:     None feature selector for col chem
2023-01-04 08:28:08,896 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:28:08,896 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:28:08,897 INFO:     Number of params in model 70111
2023-01-04 08:28:08,900 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:28:08,900 INFO:   Starting stage: TRAINING
2023-01-04 08:28:08,939 INFO:     Val loss before train {'Reaction outcome loss': 0.9294970790545146, 'Total loss': 0.9294970790545146}
2023-01-04 08:28:08,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:08,939 INFO:     Epoch: 0
2023-01-04 08:28:10,518 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6901645243167878, 'Total loss': 0.6901645243167878} | train loss {'Reaction outcome loss': 0.8435226995361983, 'Total loss': 0.8435226995361983}
2023-01-04 08:28:10,518 INFO:     Found new best model at epoch 0
2023-01-04 08:28:10,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:10,519 INFO:     Epoch: 1
2023-01-04 08:28:12,039 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.57240309715271, 'Total loss': 0.57240309715271} | train loss {'Reaction outcome loss': 0.6759286277050519, 'Total loss': 0.6759286277050519}
2023-01-04 08:28:12,039 INFO:     Found new best model at epoch 1
2023-01-04 08:28:12,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:12,040 INFO:     Epoch: 2
2023-01-04 08:28:13,587 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5018920401732127, 'Total loss': 0.5018920401732127} | train loss {'Reaction outcome loss': 0.5912611041843456, 'Total loss': 0.5912611041843456}
2023-01-04 08:28:13,588 INFO:     Found new best model at epoch 2
2023-01-04 08:28:13,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:13,589 INFO:     Epoch: 3
2023-01-04 08:28:15,130 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48746510545412697, 'Total loss': 0.48746510545412697} | train loss {'Reaction outcome loss': 0.5459799991689459, 'Total loss': 0.5459799991689459}
2023-01-04 08:28:15,130 INFO:     Found new best model at epoch 3
2023-01-04 08:28:15,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:15,131 INFO:     Epoch: 4
2023-01-04 08:28:16,705 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4694699883460999, 'Total loss': 0.4694699883460999} | train loss {'Reaction outcome loss': 0.5243291676479535, 'Total loss': 0.5243291676479535}
2023-01-04 08:28:16,705 INFO:     Found new best model at epoch 4
2023-01-04 08:28:16,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:16,706 INFO:     Epoch: 5
2023-01-04 08:28:18,217 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4527776519457499, 'Total loss': 0.4527776519457499} | train loss {'Reaction outcome loss': 0.506825662279216, 'Total loss': 0.506825662279216}
2023-01-04 08:28:18,217 INFO:     Found new best model at epoch 5
2023-01-04 08:28:18,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:18,218 INFO:     Epoch: 6
2023-01-04 08:28:19,751 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4252089858055115, 'Total loss': 0.4252089858055115} | train loss {'Reaction outcome loss': 0.4961561536701926, 'Total loss': 0.4961561536701926}
2023-01-04 08:28:19,752 INFO:     Found new best model at epoch 6
2023-01-04 08:28:19,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:19,753 INFO:     Epoch: 7
2023-01-04 08:28:21,265 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43177420695622765, 'Total loss': 0.43177420695622765} | train loss {'Reaction outcome loss': 0.4839404423306458, 'Total loss': 0.4839404423306458}
2023-01-04 08:28:21,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:21,265 INFO:     Epoch: 8
2023-01-04 08:28:22,817 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42002187967300414, 'Total loss': 0.42002187967300414} | train loss {'Reaction outcome loss': 0.4746039146489471, 'Total loss': 0.4746039146489471}
2023-01-04 08:28:22,817 INFO:     Found new best model at epoch 8
2023-01-04 08:28:22,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:22,818 INFO:     Epoch: 9
2023-01-04 08:28:24,366 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4490392208099365, 'Total loss': 0.4490392208099365} | train loss {'Reaction outcome loss': 0.4710734189644347, 'Total loss': 0.4710734189644347}
2023-01-04 08:28:24,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:24,366 INFO:     Epoch: 10
2023-01-04 08:28:25,926 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.411342919866244, 'Total loss': 0.411342919866244} | train loss {'Reaction outcome loss': 0.4597325349484917, 'Total loss': 0.4597325349484917}
2023-01-04 08:28:25,927 INFO:     Found new best model at epoch 10
2023-01-04 08:28:25,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:25,928 INFO:     Epoch: 11
2023-01-04 08:28:27,435 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4118373940388362, 'Total loss': 0.4118373940388362} | train loss {'Reaction outcome loss': 0.46127781484031327, 'Total loss': 0.46127781484031327}
2023-01-04 08:28:27,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:27,436 INFO:     Epoch: 12
2023-01-04 08:28:28,969 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4000299413998922, 'Total loss': 0.4000299413998922} | train loss {'Reaction outcome loss': 0.4504753610078436, 'Total loss': 0.4504753610078436}
2023-01-04 08:28:28,969 INFO:     Found new best model at epoch 12
2023-01-04 08:28:28,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:28,970 INFO:     Epoch: 13
2023-01-04 08:28:30,485 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3806637302041054, 'Total loss': 0.3806637302041054} | train loss {'Reaction outcome loss': 0.4450269300680961, 'Total loss': 0.4450269300680961}
2023-01-04 08:28:30,485 INFO:     Found new best model at epoch 13
2023-01-04 08:28:30,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:30,486 INFO:     Epoch: 14
2023-01-04 08:28:32,035 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3944230635960897, 'Total loss': 0.3944230635960897} | train loss {'Reaction outcome loss': 0.44164543207326945, 'Total loss': 0.44164543207326945}
2023-01-04 08:28:32,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:32,037 INFO:     Epoch: 15
2023-01-04 08:28:33,580 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3851769248644511, 'Total loss': 0.3851769248644511} | train loss {'Reaction outcome loss': 0.4369364064866609, 'Total loss': 0.4369364064866609}
2023-01-04 08:28:33,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:33,580 INFO:     Epoch: 16
2023-01-04 08:28:35,137 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3953986744085948, 'Total loss': 0.3953986744085948} | train loss {'Reaction outcome loss': 0.4346204959943782, 'Total loss': 0.4346204959943782}
2023-01-04 08:28:35,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:35,137 INFO:     Epoch: 17
2023-01-04 08:28:36,645 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38618713517983755, 'Total loss': 0.38618713517983755} | train loss {'Reaction outcome loss': 0.42919722743278005, 'Total loss': 0.42919722743278005}
2023-01-04 08:28:36,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:36,645 INFO:     Epoch: 18
2023-01-04 08:28:38,193 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4191057672103246, 'Total loss': 0.4191057672103246} | train loss {'Reaction outcome loss': 0.42495469422671045, 'Total loss': 0.42495469422671045}
2023-01-04 08:28:38,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:38,194 INFO:     Epoch: 19
2023-01-04 08:28:39,721 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37882485538721083, 'Total loss': 0.37882485538721083} | train loss {'Reaction outcome loss': 0.42153702891112244, 'Total loss': 0.42153702891112244}
2023-01-04 08:28:39,721 INFO:     Found new best model at epoch 19
2023-01-04 08:28:39,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:39,722 INFO:     Epoch: 20
2023-01-04 08:28:41,284 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39929029444853464, 'Total loss': 0.39929029444853464} | train loss {'Reaction outcome loss': 0.4198573619453576, 'Total loss': 0.4198573619453576}
2023-01-04 08:28:41,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:41,285 INFO:     Epoch: 21
2023-01-04 08:28:42,842 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3802735388278961, 'Total loss': 0.3802735388278961} | train loss {'Reaction outcome loss': 0.4159769198320208, 'Total loss': 0.4159769198320208}
2023-01-04 08:28:42,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:42,842 INFO:     Epoch: 22
2023-01-04 08:28:44,410 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38416940172513325, 'Total loss': 0.38416940172513325} | train loss {'Reaction outcome loss': 0.40691930311222146, 'Total loss': 0.40691930311222146}
2023-01-04 08:28:44,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:44,411 INFO:     Epoch: 23
2023-01-04 08:28:45,936 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3886978437503179, 'Total loss': 0.3886978437503179} | train loss {'Reaction outcome loss': 0.41172047106236437, 'Total loss': 0.41172047106236437}
2023-01-04 08:28:45,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:45,936 INFO:     Epoch: 24
2023-01-04 08:28:47,481 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.393966347972552, 'Total loss': 0.393966347972552} | train loss {'Reaction outcome loss': 0.40172448338274536, 'Total loss': 0.40172448338274536}
2023-01-04 08:28:47,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:47,481 INFO:     Epoch: 25
2023-01-04 08:28:49,033 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3745639423529307, 'Total loss': 0.3745639423529307} | train loss {'Reaction outcome loss': 0.40234294680565813, 'Total loss': 0.40234294680565813}
2023-01-04 08:28:49,033 INFO:     Found new best model at epoch 25
2023-01-04 08:28:49,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:49,034 INFO:     Epoch: 26
2023-01-04 08:28:50,592 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3862486792107423, 'Total loss': 0.3862486792107423} | train loss {'Reaction outcome loss': 0.3944386611182759, 'Total loss': 0.3944386611182759}
2023-01-04 08:28:50,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:50,594 INFO:     Epoch: 27
2023-01-04 08:28:52,146 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3571758434176445, 'Total loss': 0.3571758434176445} | train loss {'Reaction outcome loss': 0.3956880929478764, 'Total loss': 0.3956880929478764}
2023-01-04 08:28:52,146 INFO:     Found new best model at epoch 27
2023-01-04 08:28:52,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:52,147 INFO:     Epoch: 28
2023-01-04 08:28:53,702 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4003662447134654, 'Total loss': 0.4003662447134654} | train loss {'Reaction outcome loss': 0.3874814428225921, 'Total loss': 0.3874814428225921}
2023-01-04 08:28:53,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:53,702 INFO:     Epoch: 29
2023-01-04 08:28:55,233 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37093694806098937, 'Total loss': 0.37093694806098937} | train loss {'Reaction outcome loss': 0.38594819605350494, 'Total loss': 0.38594819605350494}
2023-01-04 08:28:55,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:55,234 INFO:     Epoch: 30
2023-01-04 08:28:56,743 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3966977020104726, 'Total loss': 0.3966977020104726} | train loss {'Reaction outcome loss': 0.3804972886930417, 'Total loss': 0.3804972886930417}
2023-01-04 08:28:56,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:56,744 INFO:     Epoch: 31
2023-01-04 08:28:58,305 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3773377666870753, 'Total loss': 0.3773377666870753} | train loss {'Reaction outcome loss': 0.37626488553020204, 'Total loss': 0.37626488553020204}
2023-01-04 08:28:58,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:58,305 INFO:     Epoch: 32
2023-01-04 08:28:59,857 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3774397323528926, 'Total loss': 0.3774397323528926} | train loss {'Reaction outcome loss': 0.37345447728451153, 'Total loss': 0.37345447728451153}
2023-01-04 08:28:59,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:28:59,857 INFO:     Epoch: 33
2023-01-04 08:29:01,418 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37810026804606117, 'Total loss': 0.37810026804606117} | train loss {'Reaction outcome loss': 0.372301850005658, 'Total loss': 0.372301850005658}
2023-01-04 08:29:01,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:01,419 INFO:     Epoch: 34
2023-01-04 08:29:02,954 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.363064236442248, 'Total loss': 0.363064236442248} | train loss {'Reaction outcome loss': 0.3697923487120301, 'Total loss': 0.3697923487120301}
2023-01-04 08:29:02,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:02,955 INFO:     Epoch: 35
2023-01-04 08:29:04,478 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.368151714404424, 'Total loss': 0.368151714404424} | train loss {'Reaction outcome loss': 0.3713041797932917, 'Total loss': 0.3713041797932917}
2023-01-04 08:29:04,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:04,478 INFO:     Epoch: 36
2023-01-04 08:29:06,037 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3693277269601822, 'Total loss': 0.3693277269601822} | train loss {'Reaction outcome loss': 0.36428217065051527, 'Total loss': 0.36428217065051527}
2023-01-04 08:29:06,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:06,037 INFO:     Epoch: 37
2023-01-04 08:29:07,656 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37439765930175783, 'Total loss': 0.37439765930175783} | train loss {'Reaction outcome loss': 0.3572449723027483, 'Total loss': 0.3572449723027483}
2023-01-04 08:29:07,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:07,656 INFO:     Epoch: 38
2023-01-04 08:29:09,271 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3570883850256602, 'Total loss': 0.3570883850256602} | train loss {'Reaction outcome loss': 0.35309318877267143, 'Total loss': 0.35309318877267143}
2023-01-04 08:29:09,273 INFO:     Found new best model at epoch 38
2023-01-04 08:29:09,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:09,274 INFO:     Epoch: 39
2023-01-04 08:29:10,896 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3708575487136841, 'Total loss': 0.3708575487136841} | train loss {'Reaction outcome loss': 0.3500472850499362, 'Total loss': 0.3500472850499362}
2023-01-04 08:29:10,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:10,896 INFO:     Epoch: 40
2023-01-04 08:29:12,494 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38942487438519796, 'Total loss': 0.38942487438519796} | train loss {'Reaction outcome loss': 0.35142606186823255, 'Total loss': 0.35142606186823255}
2023-01-04 08:29:12,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:12,494 INFO:     Epoch: 41
2023-01-04 08:29:14,099 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3909313897291819, 'Total loss': 0.3909313897291819} | train loss {'Reaction outcome loss': 0.3477090551742237, 'Total loss': 0.3477090551742237}
2023-01-04 08:29:14,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:14,101 INFO:     Epoch: 42
2023-01-04 08:29:15,656 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3494161730011304, 'Total loss': 0.3494161730011304} | train loss {'Reaction outcome loss': 0.34782033198832596, 'Total loss': 0.34782033198832596}
2023-01-04 08:29:15,657 INFO:     Found new best model at epoch 42
2023-01-04 08:29:15,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:15,657 INFO:     Epoch: 43
2023-01-04 08:29:17,267 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36408592760562897, 'Total loss': 0.36408592760562897} | train loss {'Reaction outcome loss': 0.34089840671224314, 'Total loss': 0.34089840671224314}
2023-01-04 08:29:17,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:17,268 INFO:     Epoch: 44
2023-01-04 08:29:18,887 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38816307385762533, 'Total loss': 0.38816307385762533} | train loss {'Reaction outcome loss': 0.3363107258222834, 'Total loss': 0.3363107258222834}
2023-01-04 08:29:18,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:18,887 INFO:     Epoch: 45
2023-01-04 08:29:20,506 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3853748251994451, 'Total loss': 0.3853748251994451} | train loss {'Reaction outcome loss': 0.3375970898807919, 'Total loss': 0.3375970898807919}
2023-01-04 08:29:20,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:20,508 INFO:     Epoch: 46
2023-01-04 08:29:22,070 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3648072014252345, 'Total loss': 0.3648072014252345} | train loss {'Reaction outcome loss': 0.3396678939733627, 'Total loss': 0.3396678939733627}
2023-01-04 08:29:22,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:22,070 INFO:     Epoch: 47
2023-01-04 08:29:23,647 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3769508937994639, 'Total loss': 0.3769508937994639} | train loss {'Reaction outcome loss': 0.3318007131562616, 'Total loss': 0.3318007131562616}
2023-01-04 08:29:23,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:23,648 INFO:     Epoch: 48
2023-01-04 08:29:25,152 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3708221857746442, 'Total loss': 0.3708221857746442} | train loss {'Reaction outcome loss': 0.3292063734337796, 'Total loss': 0.3292063734337796}
2023-01-04 08:29:25,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:25,152 INFO:     Epoch: 49
2023-01-04 08:29:26,691 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37711156805356344, 'Total loss': 0.37711156805356344} | train loss {'Reaction outcome loss': 0.328674005901944, 'Total loss': 0.328674005901944}
2023-01-04 08:29:26,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:26,692 INFO:     Epoch: 50
2023-01-04 08:29:28,225 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3668335994084676, 'Total loss': 0.3668335994084676} | train loss {'Reaction outcome loss': 0.32579147184852264, 'Total loss': 0.32579147184852264}
2023-01-04 08:29:28,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:28,225 INFO:     Epoch: 51
2023-01-04 08:29:29,772 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36327998538812, 'Total loss': 0.36327998538812} | train loss {'Reaction outcome loss': 0.3240316509656663, 'Total loss': 0.3240316509656663}
2023-01-04 08:29:29,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:29,772 INFO:     Epoch: 52
2023-01-04 08:29:31,296 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39020493427912395, 'Total loss': 0.39020493427912395} | train loss {'Reaction outcome loss': 0.3212548739066089, 'Total loss': 0.3212548739066089}
2023-01-04 08:29:31,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:31,296 INFO:     Epoch: 53
2023-01-04 08:29:32,844 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3516380101442337, 'Total loss': 0.3516380101442337} | train loss {'Reaction outcome loss': 0.3190800764047316, 'Total loss': 0.3190800764047316}
2023-01-04 08:29:32,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:32,845 INFO:     Epoch: 54
2023-01-04 08:29:34,426 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.35911141633987426, 'Total loss': 0.35911141633987426} | train loss {'Reaction outcome loss': 0.3129706095605001, 'Total loss': 0.3129706095605001}
2023-01-04 08:29:34,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:34,427 INFO:     Epoch: 55
2023-01-04 08:29:35,993 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38528500000635785, 'Total loss': 0.38528500000635785} | train loss {'Reaction outcome loss': 0.31296952993330296, 'Total loss': 0.31296952993330296}
2023-01-04 08:29:35,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:35,993 INFO:     Epoch: 56
2023-01-04 08:29:37,540 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3780113846063614, 'Total loss': 0.3780113846063614} | train loss {'Reaction outcome loss': 0.3118084403992134, 'Total loss': 0.3118084403992134}
2023-01-04 08:29:37,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:37,540 INFO:     Epoch: 57
2023-01-04 08:29:39,105 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3884341210126877, 'Total loss': 0.3884341210126877} | train loss {'Reaction outcome loss': 0.306180480405362, 'Total loss': 0.306180480405362}
2023-01-04 08:29:39,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:39,106 INFO:     Epoch: 58
2023-01-04 08:29:40,660 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3709386497735977, 'Total loss': 0.3709386497735977} | train loss {'Reaction outcome loss': 0.30915708540782444, 'Total loss': 0.30915708540782444}
2023-01-04 08:29:40,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:40,660 INFO:     Epoch: 59
2023-01-04 08:29:42,209 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37449316680431366, 'Total loss': 0.37449316680431366} | train loss {'Reaction outcome loss': 0.30460454229890865, 'Total loss': 0.30460454229890865}
2023-01-04 08:29:42,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:42,210 INFO:     Epoch: 60
2023-01-04 08:29:43,789 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36561354299386345, 'Total loss': 0.36561354299386345} | train loss {'Reaction outcome loss': 0.3068995125129493, 'Total loss': 0.3068995125129493}
2023-01-04 08:29:43,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:43,789 INFO:     Epoch: 61
2023-01-04 08:29:45,371 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.379639545083046, 'Total loss': 0.379639545083046} | train loss {'Reaction outcome loss': 0.3047484765305136, 'Total loss': 0.3047484765305136}
2023-01-04 08:29:45,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:45,372 INFO:     Epoch: 62
2023-01-04 08:29:46,947 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36828379333019257, 'Total loss': 0.36828379333019257} | train loss {'Reaction outcome loss': 0.3000621809522166, 'Total loss': 0.3000621809522166}
2023-01-04 08:29:46,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:46,948 INFO:     Epoch: 63
2023-01-04 08:29:48,525 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3744390686353048, 'Total loss': 0.3744390686353048} | train loss {'Reaction outcome loss': 0.30224303082719334, 'Total loss': 0.30224303082719334}
2023-01-04 08:29:48,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:48,525 INFO:     Epoch: 64
2023-01-04 08:29:50,062 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38787575960159304, 'Total loss': 0.38787575960159304} | train loss {'Reaction outcome loss': 0.291913465453978, 'Total loss': 0.291913465453978}
2023-01-04 08:29:50,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:50,062 INFO:     Epoch: 65
2023-01-04 08:29:51,578 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.385488224029541, 'Total loss': 0.385488224029541} | train loss {'Reaction outcome loss': 0.2975434840106181, 'Total loss': 0.2975434840106181}
2023-01-04 08:29:51,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:51,579 INFO:     Epoch: 66
2023-01-04 08:29:53,147 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.374512846271197, 'Total loss': 0.374512846271197} | train loss {'Reaction outcome loss': 0.2948443995938249, 'Total loss': 0.2948443995938249}
2023-01-04 08:29:53,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:53,148 INFO:     Epoch: 67
2023-01-04 08:29:54,690 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4084221283594767, 'Total loss': 0.4084221283594767} | train loss {'Reaction outcome loss': 0.2907441733880852, 'Total loss': 0.2907441733880852}
2023-01-04 08:29:54,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:54,690 INFO:     Epoch: 68
2023-01-04 08:29:56,264 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3832706610361735, 'Total loss': 0.3832706610361735} | train loss {'Reaction outcome loss': 0.28982018616839045, 'Total loss': 0.28982018616839045}
2023-01-04 08:29:56,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:56,265 INFO:     Epoch: 69
2023-01-04 08:29:57,815 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3880249887704849, 'Total loss': 0.3880249887704849} | train loss {'Reaction outcome loss': 0.2872645826126537, 'Total loss': 0.2872645826126537}
2023-01-04 08:29:57,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:57,816 INFO:     Epoch: 70
2023-01-04 08:29:59,353 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37602301438649494, 'Total loss': 0.37602301438649494} | train loss {'Reaction outcome loss': 0.2854565616397962, 'Total loss': 0.2854565616397962}
2023-01-04 08:29:59,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:29:59,353 INFO:     Epoch: 71
2023-01-04 08:30:00,886 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3758265942335129, 'Total loss': 0.3758265942335129} | train loss {'Reaction outcome loss': 0.28533196666814986, 'Total loss': 0.28533196666814986}
2023-01-04 08:30:00,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:00,886 INFO:     Epoch: 72
2023-01-04 08:30:02,450 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4197027941544851, 'Total loss': 0.4197027941544851} | train loss {'Reaction outcome loss': 0.28751473240282416, 'Total loss': 0.28751473240282416}
2023-01-04 08:30:02,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:02,451 INFO:     Epoch: 73
2023-01-04 08:30:04,040 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3930035442113876, 'Total loss': 0.3930035442113876} | train loss {'Reaction outcome loss': 0.28076593898726204, 'Total loss': 0.28076593898726204}
2023-01-04 08:30:04,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:04,041 INFO:     Epoch: 74
2023-01-04 08:30:05,587 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4129938880602519, 'Total loss': 0.4129938880602519} | train loss {'Reaction outcome loss': 0.2806638539870725, 'Total loss': 0.2806638539870725}
2023-01-04 08:30:05,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:05,587 INFO:     Epoch: 75
2023-01-04 08:30:07,124 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39072512884934746, 'Total loss': 0.39072512884934746} | train loss {'Reaction outcome loss': 0.28466901830295577, 'Total loss': 0.28466901830295577}
2023-01-04 08:30:07,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:07,124 INFO:     Epoch: 76
2023-01-04 08:30:08,645 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39917696118354795, 'Total loss': 0.39917696118354795} | train loss {'Reaction outcome loss': 0.27728149188125, 'Total loss': 0.27728149188125}
2023-01-04 08:30:08,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:08,647 INFO:     Epoch: 77
2023-01-04 08:30:10,168 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40348985393842063, 'Total loss': 0.40348985393842063} | train loss {'Reaction outcome loss': 0.27917201719144835, 'Total loss': 0.27917201719144835}
2023-01-04 08:30:10,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:10,168 INFO:     Epoch: 78
2023-01-04 08:30:11,752 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42252663274606067, 'Total loss': 0.42252663274606067} | train loss {'Reaction outcome loss': 0.27740442168212287, 'Total loss': 0.27740442168212287}
2023-01-04 08:30:11,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:11,752 INFO:     Epoch: 79
2023-01-04 08:30:13,329 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37411595781644186, 'Total loss': 0.37411595781644186} | train loss {'Reaction outcome loss': 0.2768976190229402, 'Total loss': 0.2768976190229402}
2023-01-04 08:30:13,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:13,330 INFO:     Epoch: 80
2023-01-04 08:30:14,883 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4032007694244385, 'Total loss': 0.4032007694244385} | train loss {'Reaction outcome loss': 0.27520819605212576, 'Total loss': 0.27520819605212576}
2023-01-04 08:30:14,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:14,884 INFO:     Epoch: 81
2023-01-04 08:30:16,447 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38242069284121194, 'Total loss': 0.38242069284121194} | train loss {'Reaction outcome loss': 0.2735952326524867, 'Total loss': 0.2735952326524867}
2023-01-04 08:30:16,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:16,447 INFO:     Epoch: 82
2023-01-04 08:30:18,003 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3770709097385406, 'Total loss': 0.3770709097385406} | train loss {'Reaction outcome loss': 0.27052446253543355, 'Total loss': 0.27052446253543355}
2023-01-04 08:30:18,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:18,003 INFO:     Epoch: 83
2023-01-04 08:30:19,541 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38917465408643087, 'Total loss': 0.38917465408643087} | train loss {'Reaction outcome loss': 0.27123583385544103, 'Total loss': 0.27123583385544103}
2023-01-04 08:30:19,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:19,541 INFO:     Epoch: 84
2023-01-04 08:30:21,112 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.397641184926033, 'Total loss': 0.397641184926033} | train loss {'Reaction outcome loss': 0.27168814856966916, 'Total loss': 0.27168814856966916}
2023-01-04 08:30:21,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:21,113 INFO:     Epoch: 85
2023-01-04 08:30:22,671 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37264771858851115, 'Total loss': 0.37264771858851115} | train loss {'Reaction outcome loss': 0.2654171708128313, 'Total loss': 0.2654171708128313}
2023-01-04 08:30:22,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:22,672 INFO:     Epoch: 86
2023-01-04 08:30:24,234 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37205852766831715, 'Total loss': 0.37205852766831715} | train loss {'Reaction outcome loss': 0.2650811414295522, 'Total loss': 0.2650811414295522}
2023-01-04 08:30:24,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:24,234 INFO:     Epoch: 87
2023-01-04 08:30:25,745 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40936079025268557, 'Total loss': 0.40936079025268557} | train loss {'Reaction outcome loss': 0.2732686644596775, 'Total loss': 0.2732686644596775}
2023-01-04 08:30:25,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:25,745 INFO:     Epoch: 88
2023-01-04 08:30:27,309 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3747936944166819, 'Total loss': 0.3747936944166819} | train loss {'Reaction outcome loss': 0.2690374356606146, 'Total loss': 0.2690374356606146}
2023-01-04 08:30:27,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:27,310 INFO:     Epoch: 89
2023-01-04 08:30:28,844 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4032949715852737, 'Total loss': 0.4032949715852737} | train loss {'Reaction outcome loss': 0.2641337944643341, 'Total loss': 0.2641337944643341}
2023-01-04 08:30:28,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:28,844 INFO:     Epoch: 90
2023-01-04 08:30:30,408 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3601286788781484, 'Total loss': 0.3601286788781484} | train loss {'Reaction outcome loss': 0.262688177059928, 'Total loss': 0.262688177059928}
2023-01-04 08:30:30,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:30,408 INFO:     Epoch: 91
2023-01-04 08:30:31,971 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3795932491620382, 'Total loss': 0.3795932491620382} | train loss {'Reaction outcome loss': 0.26434465764212783, 'Total loss': 0.26434465764212783}
2023-01-04 08:30:31,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:31,971 INFO:     Epoch: 92
2023-01-04 08:30:33,533 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40361763040224713, 'Total loss': 0.40361763040224713} | train loss {'Reaction outcome loss': 0.2641698647643963, 'Total loss': 0.2641698647643963}
2023-01-04 08:30:33,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:33,535 INFO:     Epoch: 93
2023-01-04 08:30:35,067 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34595567602664234, 'Total loss': 0.34595567602664234} | train loss {'Reaction outcome loss': 0.26523928314338635, 'Total loss': 0.26523928314338635}
2023-01-04 08:30:35,067 INFO:     Found new best model at epoch 93
2023-01-04 08:30:35,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:35,068 INFO:     Epoch: 94
2023-01-04 08:30:36,587 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3756454159816106, 'Total loss': 0.3756454159816106} | train loss {'Reaction outcome loss': 0.2604155587100417, 'Total loss': 0.2604155587100417}
2023-01-04 08:30:36,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:36,587 INFO:     Epoch: 95
2023-01-04 08:30:38,154 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36937696834405265, 'Total loss': 0.36937696834405265} | train loss {'Reaction outcome loss': 0.2599954959956834, 'Total loss': 0.2599954959956834}
2023-01-04 08:30:38,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:38,154 INFO:     Epoch: 96
2023-01-04 08:30:39,729 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4011838515599569, 'Total loss': 0.4011838515599569} | train loss {'Reaction outcome loss': 0.25895294443751776, 'Total loss': 0.25895294443751776}
2023-01-04 08:30:39,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:39,730 INFO:     Epoch: 97
2023-01-04 08:30:41,302 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39285994867483776, 'Total loss': 0.39285994867483776} | train loss {'Reaction outcome loss': 0.25758086705077304, 'Total loss': 0.25758086705077304}
2023-01-04 08:30:41,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:41,302 INFO:     Epoch: 98
2023-01-04 08:30:42,854 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3748912970225016, 'Total loss': 0.3748912970225016} | train loss {'Reaction outcome loss': 0.26011765367575806, 'Total loss': 0.26011765367575806}
2023-01-04 08:30:42,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:42,854 INFO:     Epoch: 99
2023-01-04 08:30:44,359 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.412034727136294, 'Total loss': 0.412034727136294} | train loss {'Reaction outcome loss': 0.2554646921038193, 'Total loss': 0.2554646921038193}
2023-01-04 08:30:44,360 INFO:     Best model found after epoch 94 of 100.
2023-01-04 08:30:44,360 INFO:   Done with stage: TRAINING
2023-01-04 08:30:44,360 INFO:   Starting stage: EVALUATION
2023-01-04 08:30:44,492 INFO:   Done with stage: EVALUATION
2023-01-04 08:30:44,493 INFO:   Leaving out SEQ value Fold_7
2023-01-04 08:30:44,505 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 08:30:44,505 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:30:45,147 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:30:45,148 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:30:45,216 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:30:45,216 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:30:45,216 INFO:     No hyperparam tuning for this model
2023-01-04 08:30:45,217 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:30:45,217 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:30:45,217 INFO:     None feature selector for col prot
2023-01-04 08:30:45,217 INFO:     None feature selector for col prot
2023-01-04 08:30:45,217 INFO:     None feature selector for col prot
2023-01-04 08:30:45,218 INFO:     None feature selector for col chem
2023-01-04 08:30:45,218 INFO:     None feature selector for col chem
2023-01-04 08:30:45,218 INFO:     None feature selector for col chem
2023-01-04 08:30:45,218 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:30:45,218 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:30:45,219 INFO:     Number of params in model 70111
2023-01-04 08:30:45,222 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:30:45,222 INFO:   Starting stage: TRAINING
2023-01-04 08:30:45,261 INFO:     Val loss before train {'Reaction outcome loss': 1.0556884010632832, 'Total loss': 1.0556884010632832}
2023-01-04 08:30:45,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:45,261 INFO:     Epoch: 0
2023-01-04 08:30:46,809 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8049229363600413, 'Total loss': 0.8049229363600413} | train loss {'Reaction outcome loss': 0.8356649889780657, 'Total loss': 0.8356649889780657}
2023-01-04 08:30:46,809 INFO:     Found new best model at epoch 0
2023-01-04 08:30:46,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:46,809 INFO:     Epoch: 1
2023-01-04 08:30:48,349 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6491554876168569, 'Total loss': 0.6491554876168569} | train loss {'Reaction outcome loss': 0.6745598825224994, 'Total loss': 0.6745598825224994}
2023-01-04 08:30:48,350 INFO:     Found new best model at epoch 1
2023-01-04 08:30:48,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:48,350 INFO:     Epoch: 2
2023-01-04 08:30:49,900 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.58543185989062, 'Total loss': 0.58543185989062} | train loss {'Reaction outcome loss': 0.5870545485267674, 'Total loss': 0.5870545485267674}
2023-01-04 08:30:49,900 INFO:     Found new best model at epoch 2
2023-01-04 08:30:49,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:49,901 INFO:     Epoch: 3
2023-01-04 08:30:51,433 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5349390347798665, 'Total loss': 0.5349390347798665} | train loss {'Reaction outcome loss': 0.5443260321108094, 'Total loss': 0.5443260321108094}
2023-01-04 08:30:51,434 INFO:     Found new best model at epoch 3
2023-01-04 08:30:51,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:51,435 INFO:     Epoch: 4
2023-01-04 08:30:52,942 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.524492476383845, 'Total loss': 0.524492476383845} | train loss {'Reaction outcome loss': 0.5189006901244178, 'Total loss': 0.5189006901244178}
2023-01-04 08:30:52,942 INFO:     Found new best model at epoch 4
2023-01-04 08:30:52,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:52,943 INFO:     Epoch: 5
2023-01-04 08:30:54,457 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5208088258902231, 'Total loss': 0.5208088258902231} | train loss {'Reaction outcome loss': 0.5013917349007008, 'Total loss': 0.5013917349007008}
2023-01-04 08:30:54,457 INFO:     Found new best model at epoch 5
2023-01-04 08:30:54,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:54,458 INFO:     Epoch: 6
2023-01-04 08:30:56,012 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48438776334126793, 'Total loss': 0.48438776334126793} | train loss {'Reaction outcome loss': 0.4900788690378196, 'Total loss': 0.4900788690378196}
2023-01-04 08:30:56,012 INFO:     Found new best model at epoch 6
2023-01-04 08:30:56,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:56,013 INFO:     Epoch: 7
2023-01-04 08:30:57,562 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5241456111272176, 'Total loss': 0.5241456111272176} | train loss {'Reaction outcome loss': 0.47934240211535545, 'Total loss': 0.47934240211535545}
2023-01-04 08:30:57,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:57,563 INFO:     Epoch: 8
2023-01-04 08:30:59,116 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5086482505003611, 'Total loss': 0.5086482505003611} | train loss {'Reaction outcome loss': 0.47244009000323983, 'Total loss': 0.47244009000323983}
2023-01-04 08:30:59,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:30:59,116 INFO:     Epoch: 9
2023-01-04 08:31:00,687 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4761998931566874, 'Total loss': 0.4761998931566874} | train loss {'Reaction outcome loss': 0.4655429507694105, 'Total loss': 0.4655429507694105}
2023-01-04 08:31:00,687 INFO:     Found new best model at epoch 9
2023-01-04 08:31:00,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:00,688 INFO:     Epoch: 10
2023-01-04 08:31:02,213 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49984438717365265, 'Total loss': 0.49984438717365265} | train loss {'Reaction outcome loss': 0.4590320622235754, 'Total loss': 0.4590320622235754}
2023-01-04 08:31:02,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:02,213 INFO:     Epoch: 11
2023-01-04 08:31:03,732 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4950800557931264, 'Total loss': 0.4950800557931264} | train loss {'Reaction outcome loss': 0.4520736127874277, 'Total loss': 0.4520736127874277}
2023-01-04 08:31:03,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:03,734 INFO:     Epoch: 12
2023-01-04 08:31:05,304 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4857637782891591, 'Total loss': 0.4857637782891591} | train loss {'Reaction outcome loss': 0.44863471459515775, 'Total loss': 0.44863471459515775}
2023-01-04 08:31:05,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:05,305 INFO:     Epoch: 13
2023-01-04 08:31:06,870 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46300874650478363, 'Total loss': 0.46300874650478363} | train loss {'Reaction outcome loss': 0.4425167432666695, 'Total loss': 0.4425167432666695}
2023-01-04 08:31:06,870 INFO:     Found new best model at epoch 13
2023-01-04 08:31:06,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:06,871 INFO:     Epoch: 14
2023-01-04 08:31:08,427 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4729488144318263, 'Total loss': 0.4729488144318263} | train loss {'Reaction outcome loss': 0.43600495148749246, 'Total loss': 0.43600495148749246}
2023-01-04 08:31:08,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:08,427 INFO:     Epoch: 15
2023-01-04 08:31:09,980 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47310131788253784, 'Total loss': 0.47310131788253784} | train loss {'Reaction outcome loss': 0.4339435746906883, 'Total loss': 0.4339435746906883}
2023-01-04 08:31:09,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:09,982 INFO:     Epoch: 16
2023-01-04 08:31:11,514 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4503890474637349, 'Total loss': 0.4503890474637349} | train loss {'Reaction outcome loss': 0.4314252991419639, 'Total loss': 0.4314252991419639}
2023-01-04 08:31:11,514 INFO:     Found new best model at epoch 16
2023-01-04 08:31:11,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:11,515 INFO:     Epoch: 17
2023-01-04 08:31:13,029 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4578713357448578, 'Total loss': 0.4578713357448578} | train loss {'Reaction outcome loss': 0.42343005540705947, 'Total loss': 0.42343005540705947}
2023-01-04 08:31:13,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:13,029 INFO:     Epoch: 18
2023-01-04 08:31:14,605 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.501921518643697, 'Total loss': 0.501921518643697} | train loss {'Reaction outcome loss': 0.41531118601016753, 'Total loss': 0.41531118601016753}
2023-01-04 08:31:14,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:14,606 INFO:     Epoch: 19
2023-01-04 08:31:16,166 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4410452385743459, 'Total loss': 0.4410452385743459} | train loss {'Reaction outcome loss': 0.4171299055544999, 'Total loss': 0.4171299055544999}
2023-01-04 08:31:16,167 INFO:     Found new best model at epoch 19
2023-01-04 08:31:16,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:16,168 INFO:     Epoch: 20
2023-01-04 08:31:17,691 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4644207219282786, 'Total loss': 0.4644207219282786} | train loss {'Reaction outcome loss': 0.4097004668229688, 'Total loss': 0.4097004668229688}
2023-01-04 08:31:17,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:17,691 INFO:     Epoch: 21
2023-01-04 08:31:19,227 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4535169502099355, 'Total loss': 0.4535169502099355} | train loss {'Reaction outcome loss': 0.40346932623290666, 'Total loss': 0.40346932623290666}
2023-01-04 08:31:19,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:19,227 INFO:     Epoch: 22
2023-01-04 08:31:20,732 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.454857470591863, 'Total loss': 0.454857470591863} | train loss {'Reaction outcome loss': 0.40191418900542014, 'Total loss': 0.40191418900542014}
2023-01-04 08:31:20,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:20,733 INFO:     Epoch: 23
2023-01-04 08:31:22,240 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46402785181999207, 'Total loss': 0.46402785181999207} | train loss {'Reaction outcome loss': 0.39508749558216466, 'Total loss': 0.39508749558216466}
2023-01-04 08:31:22,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:22,240 INFO:     Epoch: 24
2023-01-04 08:31:23,784 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47006531357765197, 'Total loss': 0.47006531357765197} | train loss {'Reaction outcome loss': 0.39287617791743173, 'Total loss': 0.39287617791743173}
2023-01-04 08:31:23,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:23,785 INFO:     Epoch: 25
2023-01-04 08:31:25,347 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4316516081492106, 'Total loss': 0.4316516081492106} | train loss {'Reaction outcome loss': 0.3884807946364375, 'Total loss': 0.3884807946364375}
2023-01-04 08:31:25,347 INFO:     Found new best model at epoch 25
2023-01-04 08:31:25,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:25,348 INFO:     Epoch: 26
2023-01-04 08:31:26,923 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44790840744972227, 'Total loss': 0.44790840744972227} | train loss {'Reaction outcome loss': 0.3900529003708902, 'Total loss': 0.3900529003708902}
2023-01-04 08:31:26,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:26,924 INFO:     Epoch: 27
2023-01-04 08:31:28,491 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42828321556250254, 'Total loss': 0.42828321556250254} | train loss {'Reaction outcome loss': 0.37836979737464527, 'Total loss': 0.37836979737464527}
2023-01-04 08:31:28,491 INFO:     Found new best model at epoch 27
2023-01-04 08:31:28,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:28,492 INFO:     Epoch: 28
2023-01-04 08:31:30,037 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43905474444230397, 'Total loss': 0.43905474444230397} | train loss {'Reaction outcome loss': 0.3776882096689983, 'Total loss': 0.3776882096689983}
2023-01-04 08:31:30,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:30,037 INFO:     Epoch: 29
2023-01-04 08:31:31,583 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.463327760497729, 'Total loss': 0.463327760497729} | train loss {'Reaction outcome loss': 0.3725358263800179, 'Total loss': 0.3725358263800179}
2023-01-04 08:31:31,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:31,583 INFO:     Epoch: 30
2023-01-04 08:31:33,153 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44155816932519276, 'Total loss': 0.44155816932519276} | train loss {'Reaction outcome loss': 0.3717772883437846, 'Total loss': 0.3717772883437846}
2023-01-04 08:31:33,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:33,154 INFO:     Epoch: 31
2023-01-04 08:31:34,709 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41663237114747365, 'Total loss': 0.41663237114747365} | train loss {'Reaction outcome loss': 0.36143324823275097, 'Total loss': 0.36143324823275097}
2023-01-04 08:31:34,709 INFO:     Found new best model at epoch 31
2023-01-04 08:31:34,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:34,710 INFO:     Epoch: 32
2023-01-04 08:31:36,240 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.429127436876297, 'Total loss': 0.429127436876297} | train loss {'Reaction outcome loss': 0.3622217991110617, 'Total loss': 0.3622217991110617}
2023-01-04 08:31:36,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:36,241 INFO:     Epoch: 33
2023-01-04 08:31:37,763 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43780215581258136, 'Total loss': 0.43780215581258136} | train loss {'Reaction outcome loss': 0.3591020663071723, 'Total loss': 0.3591020663071723}
2023-01-04 08:31:37,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:37,763 INFO:     Epoch: 34
2023-01-04 08:31:39,321 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42581411202748615, 'Total loss': 0.42581411202748615} | train loss {'Reaction outcome loss': 0.35516565690075397, 'Total loss': 0.35516565690075397}
2023-01-04 08:31:39,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:39,323 INFO:     Epoch: 35
2023-01-04 08:31:40,851 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4172828118006388, 'Total loss': 0.4172828118006388} | train loss {'Reaction outcome loss': 0.3554815795191013, 'Total loss': 0.3554815795191013}
2023-01-04 08:31:40,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:40,851 INFO:     Epoch: 36
2023-01-04 08:31:42,423 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41922098994255064, 'Total loss': 0.41922098994255064} | train loss {'Reaction outcome loss': 0.3500406692606689, 'Total loss': 0.3500406692606689}
2023-01-04 08:31:42,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:42,424 INFO:     Epoch: 37
2023-01-04 08:31:44,005 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4376933991909027, 'Total loss': 0.4376933991909027} | train loss {'Reaction outcome loss': 0.3453637904276813, 'Total loss': 0.3453637904276813}
2023-01-04 08:31:44,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:44,005 INFO:     Epoch: 38
2023-01-04 08:31:45,571 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4205173929532369, 'Total loss': 0.4205173929532369} | train loss {'Reaction outcome loss': 0.348177608646398, 'Total loss': 0.348177608646398}
2023-01-04 08:31:45,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:45,573 INFO:     Epoch: 39
2023-01-04 08:31:47,108 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41208331485589345, 'Total loss': 0.41208331485589345} | train loss {'Reaction outcome loss': 0.34459370244158444, 'Total loss': 0.34459370244158444}
2023-01-04 08:31:47,109 INFO:     Found new best model at epoch 39
2023-01-04 08:31:47,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:47,109 INFO:     Epoch: 40
2023-01-04 08:31:48,672 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42241754233837125, 'Total loss': 0.42241754233837125} | train loss {'Reaction outcome loss': 0.33762815151445186, 'Total loss': 0.33762815151445186}
2023-01-04 08:31:48,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:48,672 INFO:     Epoch: 41
2023-01-04 08:31:50,215 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41296337644259135, 'Total loss': 0.41296337644259135} | train loss {'Reaction outcome loss': 0.33681679538784237, 'Total loss': 0.33681679538784237}
2023-01-04 08:31:50,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:50,215 INFO:     Epoch: 42
2023-01-04 08:31:51,814 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.423938391606013, 'Total loss': 0.423938391606013} | train loss {'Reaction outcome loss': 0.33360711990916814, 'Total loss': 0.33360711990916814}
2023-01-04 08:31:51,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:51,816 INFO:     Epoch: 43
2023-01-04 08:31:53,398 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45496330261230467, 'Total loss': 0.45496330261230467} | train loss {'Reaction outcome loss': 0.33070357630613945, 'Total loss': 0.33070357630613945}
2023-01-04 08:31:53,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:53,398 INFO:     Epoch: 44
2023-01-04 08:31:54,970 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41618168155352275, 'Total loss': 0.41618168155352275} | train loss {'Reaction outcome loss': 0.3336284194060051, 'Total loss': 0.3336284194060051}
2023-01-04 08:31:54,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:54,971 INFO:     Epoch: 45
2023-01-04 08:31:56,498 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4302070538202922, 'Total loss': 0.4302070538202922} | train loss {'Reaction outcome loss': 0.32589580173039956, 'Total loss': 0.32589580173039956}
2023-01-04 08:31:56,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:56,498 INFO:     Epoch: 46
2023-01-04 08:31:58,031 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41397707362969716, 'Total loss': 0.41397707362969716} | train loss {'Reaction outcome loss': 0.32497650662260336, 'Total loss': 0.32497650662260336}
2023-01-04 08:31:58,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:58,032 INFO:     Epoch: 47
2023-01-04 08:31:59,589 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42148263653119405, 'Total loss': 0.42148263653119405} | train loss {'Reaction outcome loss': 0.3216593635615206, 'Total loss': 0.3216593635615206}
2023-01-04 08:31:59,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:31:59,589 INFO:     Epoch: 48
2023-01-04 08:32:01,151 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4223218788703283, 'Total loss': 0.4223218788703283} | train loss {'Reaction outcome loss': 0.3226202139019096, 'Total loss': 0.3226202139019096}
2023-01-04 08:32:01,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:01,151 INFO:     Epoch: 49
2023-01-04 08:32:02,725 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40388340651988985, 'Total loss': 0.40388340651988985} | train loss {'Reaction outcome loss': 0.3178390781157208, 'Total loss': 0.3178390781157208}
2023-01-04 08:32:02,726 INFO:     Found new best model at epoch 49
2023-01-04 08:32:02,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:02,726 INFO:     Epoch: 50
2023-01-04 08:32:04,305 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4346483786900838, 'Total loss': 0.4346483786900838} | train loss {'Reaction outcome loss': 0.31695786749359467, 'Total loss': 0.31695786749359467}
2023-01-04 08:32:04,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:04,307 INFO:     Epoch: 51
2023-01-04 08:32:05,854 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44938587546348574, 'Total loss': 0.44938587546348574} | train loss {'Reaction outcome loss': 0.3127145464294148, 'Total loss': 0.3127145464294148}
2023-01-04 08:32:05,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:05,854 INFO:     Epoch: 52
2023-01-04 08:32:07,378 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4137859304745992, 'Total loss': 0.4137859304745992} | train loss {'Reaction outcome loss': 0.31231784574469945, 'Total loss': 0.31231784574469945}
2023-01-04 08:32:07,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:07,378 INFO:     Epoch: 53
2023-01-04 08:32:08,958 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4092972238858541, 'Total loss': 0.4092972238858541} | train loss {'Reaction outcome loss': 0.3120544116644964, 'Total loss': 0.3120544116644964}
2023-01-04 08:32:08,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:08,959 INFO:     Epoch: 54
2023-01-04 08:32:10,529 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4095509876807531, 'Total loss': 0.4095509876807531} | train loss {'Reaction outcome loss': 0.30862494865364404, 'Total loss': 0.30862494865364404}
2023-01-04 08:32:10,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:10,530 INFO:     Epoch: 55
2023-01-04 08:32:12,086 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41197935740152997, 'Total loss': 0.41197935740152997} | train loss {'Reaction outcome loss': 0.30142916567677996, 'Total loss': 0.30142916567677996}
2023-01-04 08:32:12,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:12,086 INFO:     Epoch: 56
2023-01-04 08:32:13,646 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41436451077461245, 'Total loss': 0.41436451077461245} | train loss {'Reaction outcome loss': 0.30192708714871946, 'Total loss': 0.30192708714871946}
2023-01-04 08:32:13,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:13,646 INFO:     Epoch: 57
2023-01-04 08:32:15,200 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41340799927711486, 'Total loss': 0.41340799927711486} | train loss {'Reaction outcome loss': 0.30396278547870853, 'Total loss': 0.30396278547870853}
2023-01-04 08:32:15,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:15,200 INFO:     Epoch: 58
2023-01-04 08:32:16,738 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41762098073959353, 'Total loss': 0.41762098073959353} | train loss {'Reaction outcome loss': 0.2969873456461151, 'Total loss': 0.2969873456461151}
2023-01-04 08:32:16,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:16,739 INFO:     Epoch: 59
2023-01-04 08:32:18,315 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41414324144522346, 'Total loss': 0.41414324144522346} | train loss {'Reaction outcome loss': 0.2988184015844425, 'Total loss': 0.2988184015844425}
2023-01-04 08:32:18,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:18,315 INFO:     Epoch: 60
2023-01-04 08:32:19,898 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42444013953208926, 'Total loss': 0.42444013953208926} | train loss {'Reaction outcome loss': 0.30183805082074916, 'Total loss': 0.30183805082074916}
2023-01-04 08:32:19,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:19,898 INFO:     Epoch: 61
2023-01-04 08:32:21,464 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41364813446998594, 'Total loss': 0.41364813446998594} | train loss {'Reaction outcome loss': 0.2981882498048953, 'Total loss': 0.2981882498048953}
2023-01-04 08:32:21,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:21,464 INFO:     Epoch: 62
2023-01-04 08:32:23,029 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4120582163333893, 'Total loss': 0.4120582163333893} | train loss {'Reaction outcome loss': 0.2920089206338799, 'Total loss': 0.2920089206338799}
2023-01-04 08:32:23,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:23,030 INFO:     Epoch: 63
2023-01-04 08:32:24,571 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4598041613896688, 'Total loss': 0.4598041613896688} | train loss {'Reaction outcome loss': 0.2876202361726195, 'Total loss': 0.2876202361726195}
2023-01-04 08:32:24,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:24,571 INFO:     Epoch: 64
2023-01-04 08:32:26,110 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44620438714822136, 'Total loss': 0.44620438714822136} | train loss {'Reaction outcome loss': 0.28944621338461435, 'Total loss': 0.28944621338461435}
2023-01-04 08:32:26,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:26,110 INFO:     Epoch: 65
2023-01-04 08:32:27,689 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.424175097544988, 'Total loss': 0.424175097544988} | train loss {'Reaction outcome loss': 0.28465306658270584, 'Total loss': 0.28465306658270584}
2023-01-04 08:32:27,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:27,689 INFO:     Epoch: 66
2023-01-04 08:32:29,253 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4029788593451182, 'Total loss': 0.4029788593451182} | train loss {'Reaction outcome loss': 0.2907115759967017, 'Total loss': 0.2907115759967017}
2023-01-04 08:32:29,254 INFO:     Found new best model at epoch 66
2023-01-04 08:32:29,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:29,255 INFO:     Epoch: 67
2023-01-04 08:32:30,845 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40475430389245354, 'Total loss': 0.40475430389245354} | train loss {'Reaction outcome loss': 0.2840286152586885, 'Total loss': 0.2840286152586885}
2023-01-04 08:32:30,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:30,845 INFO:     Epoch: 68
2023-01-04 08:32:32,405 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43127691050370537, 'Total loss': 0.43127691050370537} | train loss {'Reaction outcome loss': 0.2841774514012963, 'Total loss': 0.2841774514012963}
2023-01-04 08:32:32,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:32,406 INFO:     Epoch: 69
2023-01-04 08:32:33,966 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41442391673723855, 'Total loss': 0.41442391673723855} | train loss {'Reaction outcome loss': 0.28313727629282615, 'Total loss': 0.28313727629282615}
2023-01-04 08:32:33,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:33,967 INFO:     Epoch: 70
2023-01-04 08:32:35,492 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44936138689517974, 'Total loss': 0.44936138689517974} | train loss {'Reaction outcome loss': 0.28382059931755066, 'Total loss': 0.28382059931755066}
2023-01-04 08:32:35,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:35,492 INFO:     Epoch: 71
2023-01-04 08:32:37,074 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3989032159248988, 'Total loss': 0.3989032159248988} | train loss {'Reaction outcome loss': 0.2723630411672766, 'Total loss': 0.2723630411672766}
2023-01-04 08:32:37,075 INFO:     Found new best model at epoch 71
2023-01-04 08:32:37,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:37,075 INFO:     Epoch: 72
2023-01-04 08:32:38,635 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4149054100116094, 'Total loss': 0.4149054100116094} | train loss {'Reaction outcome loss': 0.2777854313081416, 'Total loss': 0.2777854313081416}
2023-01-04 08:32:38,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:38,635 INFO:     Epoch: 73
2023-01-04 08:32:40,198 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44721778432528175, 'Total loss': 0.44721778432528175} | train loss {'Reaction outcome loss': 0.27458671385245603, 'Total loss': 0.27458671385245603}
2023-01-04 08:32:40,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:40,199 INFO:     Epoch: 74
2023-01-04 08:32:41,730 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4266262412071228, 'Total loss': 0.4266262412071228} | train loss {'Reaction outcome loss': 0.273494518831046, 'Total loss': 0.273494518831046}
2023-01-04 08:32:41,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:41,730 INFO:     Epoch: 75
2023-01-04 08:32:43,308 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4497671713431676, 'Total loss': 0.4497671713431676} | train loss {'Reaction outcome loss': 0.271933697354402, 'Total loss': 0.271933697354402}
2023-01-04 08:32:43,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:43,309 INFO:     Epoch: 76
2023-01-04 08:32:44,837 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3969557657837868, 'Total loss': 0.3969557657837868} | train loss {'Reaction outcome loss': 0.26951672293137025, 'Total loss': 0.26951672293137025}
2023-01-04 08:32:44,837 INFO:     Found new best model at epoch 76
2023-01-04 08:32:44,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:44,838 INFO:     Epoch: 77
2023-01-04 08:32:46,416 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4233371237913767, 'Total loss': 0.4233371237913767} | train loss {'Reaction outcome loss': 0.27153857714448965, 'Total loss': 0.27153857714448965}
2023-01-04 08:32:46,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:46,417 INFO:     Epoch: 78
2023-01-04 08:32:47,981 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42487262388070424, 'Total loss': 0.42487262388070424} | train loss {'Reaction outcome loss': 0.271789265565411, 'Total loss': 0.271789265565411}
2023-01-04 08:32:47,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:47,981 INFO:     Epoch: 79
2023-01-04 08:32:49,552 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42719387114048, 'Total loss': 0.42719387114048} | train loss {'Reaction outcome loss': 0.27052941012882836, 'Total loss': 0.27052941012882836}
2023-01-04 08:32:49,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:49,552 INFO:     Epoch: 80
2023-01-04 08:32:51,082 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3882414331038793, 'Total loss': 0.3882414331038793} | train loss {'Reaction outcome loss': 0.2692042549215529, 'Total loss': 0.2692042549215529}
2023-01-04 08:32:51,082 INFO:     Found new best model at epoch 80
2023-01-04 08:32:51,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:51,083 INFO:     Epoch: 81
2023-01-04 08:32:52,629 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40991639296213783, 'Total loss': 0.40991639296213783} | train loss {'Reaction outcome loss': 0.26721979087612924, 'Total loss': 0.26721979087612924}
2023-01-04 08:32:52,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:52,630 INFO:     Epoch: 82
2023-01-04 08:32:54,191 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4019858221213023, 'Total loss': 0.4019858221213023} | train loss {'Reaction outcome loss': 0.26287758089330077, 'Total loss': 0.26287758089330077}
2023-01-04 08:32:54,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:54,192 INFO:     Epoch: 83
2023-01-04 08:32:55,775 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4164047638575236, 'Total loss': 0.4164047638575236} | train loss {'Reaction outcome loss': 0.2658538391446545, 'Total loss': 0.2658538391446545}
2023-01-04 08:32:55,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:55,776 INFO:     Epoch: 84
2023-01-04 08:32:57,337 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40219020942846934, 'Total loss': 0.40219020942846934} | train loss {'Reaction outcome loss': 0.26311340461736615, 'Total loss': 0.26311340461736615}
2023-01-04 08:32:57,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:57,337 INFO:     Epoch: 85
2023-01-04 08:32:58,911 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4258575369914373, 'Total loss': 0.4258575369914373} | train loss {'Reaction outcome loss': 0.2716042910614153, 'Total loss': 0.2716042910614153}
2023-01-04 08:32:58,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:32:58,913 INFO:     Epoch: 86
2023-01-04 08:33:00,442 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4001955548922221, 'Total loss': 0.4001955548922221} | train loss {'Reaction outcome loss': 0.25979545611860977, 'Total loss': 0.25979545611860977}
2023-01-04 08:33:00,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:00,443 INFO:     Epoch: 87
2023-01-04 08:33:01,961 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39009864926338195, 'Total loss': 0.39009864926338195} | train loss {'Reaction outcome loss': 0.26030871826801855, 'Total loss': 0.26030871826801855}
2023-01-04 08:33:01,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:01,961 INFO:     Epoch: 88
2023-01-04 08:33:03,544 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40832805037498476, 'Total loss': 0.40832805037498476} | train loss {'Reaction outcome loss': 0.2530432427913821, 'Total loss': 0.2530432427913821}
2023-01-04 08:33:03,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:03,544 INFO:     Epoch: 89
2023-01-04 08:33:05,121 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41180481513341266, 'Total loss': 0.41180481513341266} | train loss {'Reaction outcome loss': 0.25948141803489116, 'Total loss': 0.25948141803489116}
2023-01-04 08:33:05,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:05,122 INFO:     Epoch: 90
2023-01-04 08:33:06,681 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40073398252328235, 'Total loss': 0.40073398252328235} | train loss {'Reaction outcome loss': 0.2633333730980428, 'Total loss': 0.2633333730980428}
2023-01-04 08:33:06,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:06,682 INFO:     Epoch: 91
2023-01-04 08:33:08,257 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41769754787286123, 'Total loss': 0.41769754787286123} | train loss {'Reaction outcome loss': 0.2555757671540236, 'Total loss': 0.2555757671540236}
2023-01-04 08:33:08,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:08,257 INFO:     Epoch: 92
2023-01-04 08:33:09,790 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4205392062664032, 'Total loss': 0.4205392062664032} | train loss {'Reaction outcome loss': 0.2577378854536227, 'Total loss': 0.2577378854536227}
2023-01-04 08:33:09,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:09,790 INFO:     Epoch: 93
2023-01-04 08:33:11,325 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39533211042483646, 'Total loss': 0.39533211042483646} | train loss {'Reaction outcome loss': 0.25746704655679037, 'Total loss': 0.25746704655679037}
2023-01-04 08:33:11,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:11,326 INFO:     Epoch: 94
2023-01-04 08:33:12,895 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4301440159479777, 'Total loss': 0.4301440159479777} | train loss {'Reaction outcome loss': 0.2549199436648484, 'Total loss': 0.2549199436648484}
2023-01-04 08:33:12,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:12,895 INFO:     Epoch: 95
2023-01-04 08:33:14,475 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3973218768835068, 'Total loss': 0.3973218768835068} | train loss {'Reaction outcome loss': 0.2540627393300516, 'Total loss': 0.2540627393300516}
2023-01-04 08:33:14,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:14,475 INFO:     Epoch: 96
2023-01-04 08:33:16,049 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4129735082387924, 'Total loss': 0.4129735082387924} | train loss {'Reaction outcome loss': 0.24543129743831435, 'Total loss': 0.24543129743831435}
2023-01-04 08:33:16,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:16,049 INFO:     Epoch: 97
2023-01-04 08:33:17,614 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40119870702425636, 'Total loss': 0.40119870702425636} | train loss {'Reaction outcome loss': 0.25184573435707247, 'Total loss': 0.25184573435707247}
2023-01-04 08:33:17,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:17,616 INFO:     Epoch: 98
2023-01-04 08:33:19,136 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4192472537358602, 'Total loss': 0.4192472537358602} | train loss {'Reaction outcome loss': 0.2494809247186258, 'Total loss': 0.2494809247186258}
2023-01-04 08:33:19,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:19,136 INFO:     Epoch: 99
2023-01-04 08:33:20,651 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4592914273341497, 'Total loss': 0.4592914273341497} | train loss {'Reaction outcome loss': 0.2475241622513663, 'Total loss': 0.2475241622513663}
2023-01-04 08:33:20,651 INFO:     Best model found after epoch 81 of 100.
2023-01-04 08:33:20,651 INFO:   Done with stage: TRAINING
2023-01-04 08:33:20,651 INFO:   Starting stage: EVALUATION
2023-01-04 08:33:20,784 INFO:   Done with stage: EVALUATION
2023-01-04 08:33:20,784 INFO:   Leaving out SEQ value Fold_8
2023-01-04 08:33:20,797 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 08:33:20,797 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:33:21,437 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:33:21,437 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:33:21,506 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:33:21,506 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:33:21,506 INFO:     No hyperparam tuning for this model
2023-01-04 08:33:21,506 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:33:21,506 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:33:21,507 INFO:     None feature selector for col prot
2023-01-04 08:33:21,507 INFO:     None feature selector for col prot
2023-01-04 08:33:21,507 INFO:     None feature selector for col prot
2023-01-04 08:33:21,508 INFO:     None feature selector for col chem
2023-01-04 08:33:21,508 INFO:     None feature selector for col chem
2023-01-04 08:33:21,508 INFO:     None feature selector for col chem
2023-01-04 08:33:21,508 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:33:21,508 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:33:21,509 INFO:     Number of params in model 70111
2023-01-04 08:33:21,512 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:33:21,512 INFO:   Starting stage: TRAINING
2023-01-04 08:33:21,555 INFO:     Val loss before train {'Reaction outcome loss': 0.8505963563919068, 'Total loss': 0.8505963563919068}
2023-01-04 08:33:21,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:21,556 INFO:     Epoch: 0
2023-01-04 08:33:23,143 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6516555309295654, 'Total loss': 0.6516555309295654} | train loss {'Reaction outcome loss': 0.8583403454575728, 'Total loss': 0.8583403454575728}
2023-01-04 08:33:23,144 INFO:     Found new best model at epoch 0
2023-01-04 08:33:23,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:23,145 INFO:     Epoch: 1
2023-01-04 08:33:24,707 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5338838835557301, 'Total loss': 0.5338838835557301} | train loss {'Reaction outcome loss': 0.6921418573882175, 'Total loss': 0.6921418573882175}
2023-01-04 08:33:24,707 INFO:     Found new best model at epoch 1
2023-01-04 08:33:24,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:24,708 INFO:     Epoch: 2
2023-01-04 08:33:26,291 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4866375287373861, 'Total loss': 0.4866375287373861} | train loss {'Reaction outcome loss': 0.6048647581670259, 'Total loss': 0.6048647581670259}
2023-01-04 08:33:26,291 INFO:     Found new best model at epoch 2
2023-01-04 08:33:26,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:26,291 INFO:     Epoch: 3
2023-01-04 08:33:27,819 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4516590674718221, 'Total loss': 0.4516590674718221} | train loss {'Reaction outcome loss': 0.5575277273835688, 'Total loss': 0.5575277273835688}
2023-01-04 08:33:27,819 INFO:     Found new best model at epoch 3
2023-01-04 08:33:27,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:27,820 INFO:     Epoch: 4
2023-01-04 08:33:29,358 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4487610896428426, 'Total loss': 0.4487610896428426} | train loss {'Reaction outcome loss': 0.5302221692748879, 'Total loss': 0.5302221692748879}
2023-01-04 08:33:29,359 INFO:     Found new best model at epoch 4
2023-01-04 08:33:29,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:29,360 INFO:     Epoch: 5
2023-01-04 08:33:30,938 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4530227025349935, 'Total loss': 0.4530227025349935} | train loss {'Reaction outcome loss': 0.5148979494825597, 'Total loss': 0.5148979494825597}
2023-01-04 08:33:30,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:30,938 INFO:     Epoch: 6
2023-01-04 08:33:32,528 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43571192224820454, 'Total loss': 0.43571192224820454} | train loss {'Reaction outcome loss': 0.5025850860973557, 'Total loss': 0.5025850860973557}
2023-01-04 08:33:32,528 INFO:     Found new best model at epoch 6
2023-01-04 08:33:32,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:32,529 INFO:     Epoch: 7
2023-01-04 08:33:34,100 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4290993203719457, 'Total loss': 0.4290993203719457} | train loss {'Reaction outcome loss': 0.4866247255126492, 'Total loss': 0.4866247255126492}
2023-01-04 08:33:34,100 INFO:     Found new best model at epoch 7
2023-01-04 08:33:34,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:34,101 INFO:     Epoch: 8
2023-01-04 08:33:35,668 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44538634618123374, 'Total loss': 0.44538634618123374} | train loss {'Reaction outcome loss': 0.4835174909997933, 'Total loss': 0.4835174909997933}
2023-01-04 08:33:35,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:35,670 INFO:     Epoch: 9
2023-01-04 08:33:37,233 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4175961991151174, 'Total loss': 0.4175961991151174} | train loss {'Reaction outcome loss': 0.4716640339646529, 'Total loss': 0.4716640339646529}
2023-01-04 08:33:37,233 INFO:     Found new best model at epoch 9
2023-01-04 08:33:37,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:37,234 INFO:     Epoch: 10
2023-01-04 08:33:38,775 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41305360396703084, 'Total loss': 0.41305360396703084} | train loss {'Reaction outcome loss': 0.46967867673088926, 'Total loss': 0.46967867673088926}
2023-01-04 08:33:38,775 INFO:     Found new best model at epoch 10
2023-01-04 08:33:38,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:38,775 INFO:     Epoch: 11
2023-01-04 08:33:40,341 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42035345832506815, 'Total loss': 0.42035345832506815} | train loss {'Reaction outcome loss': 0.46120183331226183, 'Total loss': 0.46120183331226183}
2023-01-04 08:33:40,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:40,341 INFO:     Epoch: 12
2023-01-04 08:33:41,916 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43128492136796315, 'Total loss': 0.43128492136796315} | train loss {'Reaction outcome loss': 0.45591527734637693, 'Total loss': 0.45591527734637693}
2023-01-04 08:33:41,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:41,917 INFO:     Epoch: 13
2023-01-04 08:33:43,491 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42171331346035, 'Total loss': 0.42171331346035} | train loss {'Reaction outcome loss': 0.44656805005529726, 'Total loss': 0.44656805005529726}
2023-01-04 08:33:43,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:43,492 INFO:     Epoch: 14
2023-01-04 08:33:45,035 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.415909614165624, 'Total loss': 0.415909614165624} | train loss {'Reaction outcome loss': 0.4460745420750728, 'Total loss': 0.4460745420750728}
2023-01-04 08:33:45,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:45,036 INFO:     Epoch: 15
2023-01-04 08:33:46,626 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4285373071829478, 'Total loss': 0.4285373071829478} | train loss {'Reaction outcome loss': 0.44085728202270685, 'Total loss': 0.44085728202270685}
2023-01-04 08:33:46,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:46,627 INFO:     Epoch: 16
2023-01-04 08:33:48,178 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4083957274754842, 'Total loss': 0.4083957274754842} | train loss {'Reaction outcome loss': 0.4361641087471793, 'Total loss': 0.4361641087471793}
2023-01-04 08:33:48,178 INFO:     Found new best model at epoch 16
2023-01-04 08:33:48,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:48,179 INFO:     Epoch: 17
2023-01-04 08:33:49,780 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41933564841747284, 'Total loss': 0.41933564841747284} | train loss {'Reaction outcome loss': 0.43060594544298814, 'Total loss': 0.43060594544298814}
2023-01-04 08:33:49,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:49,780 INFO:     Epoch: 18
2023-01-04 08:33:51,374 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.426283472776413, 'Total loss': 0.426283472776413} | train loss {'Reaction outcome loss': 0.4327572836180887, 'Total loss': 0.4327572836180887}
2023-01-04 08:33:51,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:51,374 INFO:     Epoch: 19
2023-01-04 08:33:52,984 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40998832682768505, 'Total loss': 0.40998832682768505} | train loss {'Reaction outcome loss': 0.4192792696320193, 'Total loss': 0.4192792696320193}
2023-01-04 08:33:52,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:52,985 INFO:     Epoch: 20
2023-01-04 08:33:54,562 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4171925485134125, 'Total loss': 0.4171925485134125} | train loss {'Reaction outcome loss': 0.4162603966380715, 'Total loss': 0.4162603966380715}
2023-01-04 08:33:54,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:54,562 INFO:     Epoch: 21
2023-01-04 08:33:56,160 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4018839210271835, 'Total loss': 0.4018839210271835} | train loss {'Reaction outcome loss': 0.4093087313407595, 'Total loss': 0.4093087313407595}
2023-01-04 08:33:56,161 INFO:     Found new best model at epoch 21
2023-01-04 08:33:56,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:56,161 INFO:     Epoch: 22
2023-01-04 08:33:57,716 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42525006234645846, 'Total loss': 0.42525006234645846} | train loss {'Reaction outcome loss': 0.41047419989582434, 'Total loss': 0.41047419989582434}
2023-01-04 08:33:57,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:57,717 INFO:     Epoch: 23
2023-01-04 08:33:59,316 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3859637516240279, 'Total loss': 0.3859637516240279} | train loss {'Reaction outcome loss': 0.40733504628876915, 'Total loss': 0.40733504628876915}
2023-01-04 08:33:59,318 INFO:     Found new best model at epoch 23
2023-01-04 08:33:59,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:33:59,319 INFO:     Epoch: 24
2023-01-04 08:34:00,916 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42318514784177147, 'Total loss': 0.42318514784177147} | train loss {'Reaction outcome loss': 0.40026706381825333, 'Total loss': 0.40026706381825333}
2023-01-04 08:34:00,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:00,917 INFO:     Epoch: 25
2023-01-04 08:34:02,492 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40288760165373483, 'Total loss': 0.40288760165373483} | train loss {'Reaction outcome loss': 0.3949592692864931, 'Total loss': 0.3949592692864931}
2023-01-04 08:34:02,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:02,492 INFO:     Epoch: 26
2023-01-04 08:34:04,030 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.407405831416448, 'Total loss': 0.407405831416448} | train loss {'Reaction outcome loss': 0.39221485924742283, 'Total loss': 0.39221485924742283}
2023-01-04 08:34:04,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:04,030 INFO:     Epoch: 27
2023-01-04 08:34:05,562 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38747398853302, 'Total loss': 0.38747398853302} | train loss {'Reaction outcome loss': 0.3916812081844798, 'Total loss': 0.3916812081844798}
2023-01-04 08:34:05,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:05,563 INFO:     Epoch: 28
2023-01-04 08:34:07,147 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39592629472414653, 'Total loss': 0.39592629472414653} | train loss {'Reaction outcome loss': 0.38472263324024014, 'Total loss': 0.38472263324024014}
2023-01-04 08:34:07,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:07,147 INFO:     Epoch: 29
2023-01-04 08:34:08,718 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42254542708396914, 'Total loss': 0.42254542708396914} | train loss {'Reaction outcome loss': 0.38532942011683424, 'Total loss': 0.38532942011683424}
2023-01-04 08:34:08,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:08,718 INFO:     Epoch: 30
2023-01-04 08:34:10,285 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3951594978570938, 'Total loss': 0.3951594978570938} | train loss {'Reaction outcome loss': 0.3832786545318817, 'Total loss': 0.3832786545318817}
2023-01-04 08:34:10,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:10,285 INFO:     Epoch: 31
2023-01-04 08:34:11,843 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4082907736301422, 'Total loss': 0.4082907736301422} | train loss {'Reaction outcome loss': 0.3766588094486226, 'Total loss': 0.3766588094486226}
2023-01-04 08:34:11,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:11,844 INFO:     Epoch: 32
2023-01-04 08:34:13,379 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.388497120141983, 'Total loss': 0.388497120141983} | train loss {'Reaction outcome loss': 0.3757788835880128, 'Total loss': 0.3757788835880128}
2023-01-04 08:34:13,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:13,380 INFO:     Epoch: 33
2023-01-04 08:34:14,928 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3955723851919174, 'Total loss': 0.3955723851919174} | train loss {'Reaction outcome loss': 0.3700346690653033, 'Total loss': 0.3700346690653033}
2023-01-04 08:34:14,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:14,928 INFO:     Epoch: 34
2023-01-04 08:34:16,476 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3940036694208781, 'Total loss': 0.3940036694208781} | train loss {'Reaction outcome loss': 0.36644281237134, 'Total loss': 0.36644281237134}
2023-01-04 08:34:16,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:16,476 INFO:     Epoch: 35
2023-01-04 08:34:18,035 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38242884874343874, 'Total loss': 0.38242884874343874} | train loss {'Reaction outcome loss': 0.36548101014393763, 'Total loss': 0.36548101014393763}
2023-01-04 08:34:18,037 INFO:     Found new best model at epoch 35
2023-01-04 08:34:18,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:18,037 INFO:     Epoch: 36
2023-01-04 08:34:19,613 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3789000689983368, 'Total loss': 0.3789000689983368} | train loss {'Reaction outcome loss': 0.3625414711204677, 'Total loss': 0.3625414711204677}
2023-01-04 08:34:19,613 INFO:     Found new best model at epoch 36
2023-01-04 08:34:19,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:19,614 INFO:     Epoch: 37
2023-01-04 08:34:21,163 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41813903450965884, 'Total loss': 0.41813903450965884} | train loss {'Reaction outcome loss': 0.3571628636616662, 'Total loss': 0.3571628636616662}
2023-01-04 08:34:21,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:21,163 INFO:     Epoch: 38
2023-01-04 08:34:22,741 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38236402372519174, 'Total loss': 0.38236402372519174} | train loss {'Reaction outcome loss': 0.35366679975487264, 'Total loss': 0.35366679975487264}
2023-01-04 08:34:22,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:22,743 INFO:     Epoch: 39
2023-01-04 08:34:24,302 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3885535836219788, 'Total loss': 0.3885535836219788} | train loss {'Reaction outcome loss': 0.3534628937175558, 'Total loss': 0.3534628937175558}
2023-01-04 08:34:24,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:24,303 INFO:     Epoch: 40
2023-01-04 08:34:25,937 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3974896788597107, 'Total loss': 0.3974896788597107} | train loss {'Reaction outcome loss': 0.35027728622463206, 'Total loss': 0.35027728622463206}
2023-01-04 08:34:25,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:25,938 INFO:     Epoch: 41
2023-01-04 08:34:27,579 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36543627083301544, 'Total loss': 0.36543627083301544} | train loss {'Reaction outcome loss': 0.3450926188850231, 'Total loss': 0.3450926188850231}
2023-01-04 08:34:27,579 INFO:     Found new best model at epoch 41
2023-01-04 08:34:27,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:27,579 INFO:     Epoch: 42
2023-01-04 08:34:29,217 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3740254352490107, 'Total loss': 0.3740254352490107} | train loss {'Reaction outcome loss': 0.3438857078337067, 'Total loss': 0.3438857078337067}
2023-01-04 08:34:29,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:29,218 INFO:     Epoch: 43
2023-01-04 08:34:30,796 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.369881051282088, 'Total loss': 0.369881051282088} | train loss {'Reaction outcome loss': 0.34392482625986265, 'Total loss': 0.34392482625986265}
2023-01-04 08:34:30,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:30,796 INFO:     Epoch: 44
2023-01-04 08:34:32,431 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.411441578467687, 'Total loss': 0.411441578467687} | train loss {'Reaction outcome loss': 0.3429773477064143, 'Total loss': 0.3429773477064143}
2023-01-04 08:34:32,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:32,432 INFO:     Epoch: 45
2023-01-04 08:34:34,019 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3835494309663773, 'Total loss': 0.3835494309663773} | train loss {'Reaction outcome loss': 0.34126744682930865, 'Total loss': 0.34126744682930865}
2023-01-04 08:34:34,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:34,019 INFO:     Epoch: 46
2023-01-04 08:34:35,658 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37505207856496176, 'Total loss': 0.37505207856496176} | train loss {'Reaction outcome loss': 0.3356730088537781, 'Total loss': 0.3356730088537781}
2023-01-04 08:34:35,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:35,659 INFO:     Epoch: 47
2023-01-04 08:34:37,296 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40914784371852875, 'Total loss': 0.40914784371852875} | train loss {'Reaction outcome loss': 0.3353194758726371, 'Total loss': 0.3353194758726371}
2023-01-04 08:34:37,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:37,296 INFO:     Epoch: 48
2023-01-04 08:34:38,931 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3752863387266795, 'Total loss': 0.3752863387266795} | train loss {'Reaction outcome loss': 0.33285973223753357, 'Total loss': 0.33285973223753357}
2023-01-04 08:34:38,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:38,931 INFO:     Epoch: 49
2023-01-04 08:34:40,523 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38106000820795694, 'Total loss': 0.38106000820795694} | train loss {'Reaction outcome loss': 0.3280096379535723, 'Total loss': 0.3280096379535723}
2023-01-04 08:34:40,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:40,524 INFO:     Epoch: 50
2023-01-04 08:34:42,118 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3656242311000824, 'Total loss': 0.3656242311000824} | train loss {'Reaction outcome loss': 0.3231702584921238, 'Total loss': 0.3231702584921238}
2023-01-04 08:34:42,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:42,118 INFO:     Epoch: 51
2023-01-04 08:34:43,762 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3690899689992269, 'Total loss': 0.3690899689992269} | train loss {'Reaction outcome loss': 0.3219656469804716, 'Total loss': 0.3219656469804716}
2023-01-04 08:34:43,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:43,763 INFO:     Epoch: 52
2023-01-04 08:34:45,400 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36384822577238085, 'Total loss': 0.36384822577238085} | train loss {'Reaction outcome loss': 0.3209596432826149, 'Total loss': 0.3209596432826149}
2023-01-04 08:34:45,400 INFO:     Found new best model at epoch 52
2023-01-04 08:34:45,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:45,401 INFO:     Epoch: 53
2023-01-04 08:34:47,035 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3823574329415957, 'Total loss': 0.3823574329415957} | train loss {'Reaction outcome loss': 0.3180956793041221, 'Total loss': 0.3180956793041221}
2023-01-04 08:34:47,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:47,035 INFO:     Epoch: 54
2023-01-04 08:34:48,648 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3605537305275599, 'Total loss': 0.3605537305275599} | train loss {'Reaction outcome loss': 0.3168797068943401, 'Total loss': 0.3168797068943401}
2023-01-04 08:34:48,649 INFO:     Found new best model at epoch 54
2023-01-04 08:34:48,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:48,650 INFO:     Epoch: 55
2023-01-04 08:34:50,277 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37468662361303967, 'Total loss': 0.37468662361303967} | train loss {'Reaction outcome loss': 0.3155797569598962, 'Total loss': 0.3155797569598962}
2023-01-04 08:34:50,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:50,277 INFO:     Epoch: 56
2023-01-04 08:34:51,862 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35052455912033714, 'Total loss': 0.35052455912033714} | train loss {'Reaction outcome loss': 0.3162748058888026, 'Total loss': 0.3162748058888026}
2023-01-04 08:34:51,862 INFO:     Found new best model at epoch 56
2023-01-04 08:34:51,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:51,863 INFO:     Epoch: 57
2023-01-04 08:34:53,493 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3447302510341009, 'Total loss': 0.3447302510341009} | train loss {'Reaction outcome loss': 0.31077638012945435, 'Total loss': 0.31077638012945435}
2023-01-04 08:34:53,493 INFO:     Found new best model at epoch 57
2023-01-04 08:34:53,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:53,494 INFO:     Epoch: 58
2023-01-04 08:34:55,117 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36829119324684145, 'Total loss': 0.36829119324684145} | train loss {'Reaction outcome loss': 0.30922190541072014, 'Total loss': 0.30922190541072014}
2023-01-04 08:34:55,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:55,119 INFO:     Epoch: 59
2023-01-04 08:34:56,756 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3608200053373973, 'Total loss': 0.3608200053373973} | train loss {'Reaction outcome loss': 0.3088885334854952, 'Total loss': 0.3088885334854952}
2023-01-04 08:34:56,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:56,757 INFO:     Epoch: 60
2023-01-04 08:34:58,347 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3631978650887807, 'Total loss': 0.3631978650887807} | train loss {'Reaction outcome loss': 0.3046856337237014, 'Total loss': 0.3046856337237014}
2023-01-04 08:34:58,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:58,347 INFO:     Epoch: 61
2023-01-04 08:34:59,987 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.34423027535279593, 'Total loss': 0.34423027535279593} | train loss {'Reaction outcome loss': 0.3072905150453967, 'Total loss': 0.3072905150453967}
2023-01-04 08:34:59,989 INFO:     Found new best model at epoch 61
2023-01-04 08:34:59,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:34:59,990 INFO:     Epoch: 62
2023-01-04 08:35:01,573 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3539640744527181, 'Total loss': 0.3539640744527181} | train loss {'Reaction outcome loss': 0.30026438307783665, 'Total loss': 0.30026438307783665}
2023-01-04 08:35:01,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:01,574 INFO:     Epoch: 63
2023-01-04 08:35:03,213 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38020009994506837, 'Total loss': 0.38020009994506837} | train loss {'Reaction outcome loss': 0.30207686088575786, 'Total loss': 0.30207686088575786}
2023-01-04 08:35:03,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:03,213 INFO:     Epoch: 64
2023-01-04 08:35:04,856 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34700419108072916, 'Total loss': 0.34700419108072916} | train loss {'Reaction outcome loss': 0.3023800637963016, 'Total loss': 0.3023800637963016}
2023-01-04 08:35:04,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:04,857 INFO:     Epoch: 65
2023-01-04 08:35:06,492 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35568510442972184, 'Total loss': 0.35568510442972184} | train loss {'Reaction outcome loss': 0.299744736847034, 'Total loss': 0.299744736847034}
2023-01-04 08:35:06,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:06,493 INFO:     Epoch: 66
2023-01-04 08:35:08,085 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.380652775367101, 'Total loss': 0.380652775367101} | train loss {'Reaction outcome loss': 0.29614648736663673, 'Total loss': 0.29614648736663673}
2023-01-04 08:35:08,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:08,085 INFO:     Epoch: 67
2023-01-04 08:35:09,679 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3611187626918157, 'Total loss': 0.3611187626918157} | train loss {'Reaction outcome loss': 0.29382711412243895, 'Total loss': 0.29382711412243895}
2023-01-04 08:35:09,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:09,679 INFO:     Epoch: 68
2023-01-04 08:35:11,319 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3546453615029653, 'Total loss': 0.3546453615029653} | train loss {'Reaction outcome loss': 0.29401847604487347, 'Total loss': 0.29401847604487347}
2023-01-04 08:35:11,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:11,319 INFO:     Epoch: 69
2023-01-04 08:35:12,955 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3647274116675059, 'Total loss': 0.3647274116675059} | train loss {'Reaction outcome loss': 0.2967006830021147, 'Total loss': 0.2967006830021147}
2023-01-04 08:35:12,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:12,956 INFO:     Epoch: 70
2023-01-04 08:35:14,592 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3564243574937185, 'Total loss': 0.3564243574937185} | train loss {'Reaction outcome loss': 0.291938386117831, 'Total loss': 0.291938386117831}
2023-01-04 08:35:14,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:14,598 INFO:     Epoch: 71
2023-01-04 08:35:16,193 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3772958040237427, 'Total loss': 0.3772958040237427} | train loss {'Reaction outcome loss': 0.28663084194709676, 'Total loss': 0.28663084194709676}
2023-01-04 08:35:16,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:16,193 INFO:     Epoch: 72
2023-01-04 08:35:17,780 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36534732580184937, 'Total loss': 0.36534732580184937} | train loss {'Reaction outcome loss': 0.2924807913036553, 'Total loss': 0.2924807913036553}
2023-01-04 08:35:17,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:17,782 INFO:     Epoch: 73
2023-01-04 08:35:19,333 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35566187600294746, 'Total loss': 0.35566187600294746} | train loss {'Reaction outcome loss': 0.285104556634538, 'Total loss': 0.285104556634538}
2023-01-04 08:35:19,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:19,334 INFO:     Epoch: 74
2023-01-04 08:35:20,929 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3544969926277796, 'Total loss': 0.3544969926277796} | train loss {'Reaction outcome loss': 0.2845249615764306, 'Total loss': 0.2845249615764306}
2023-01-04 08:35:20,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:20,930 INFO:     Epoch: 75
2023-01-04 08:35:22,538 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3772142102320989, 'Total loss': 0.3772142102320989} | train loss {'Reaction outcome loss': 0.28503168853073774, 'Total loss': 0.28503168853073774}
2023-01-04 08:35:22,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:22,538 INFO:     Epoch: 76
2023-01-04 08:35:24,106 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3611155351003011, 'Total loss': 0.3611155351003011} | train loss {'Reaction outcome loss': 0.2870358697774178, 'Total loss': 0.2870358697774178}
2023-01-04 08:35:24,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:24,107 INFO:     Epoch: 77
2023-01-04 08:35:25,683 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35205385585625965, 'Total loss': 0.35205385585625965} | train loss {'Reaction outcome loss': 0.28408255280140077, 'Total loss': 0.28408255280140077}
2023-01-04 08:35:25,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:25,683 INFO:     Epoch: 78
2023-01-04 08:35:27,274 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35831494132677716, 'Total loss': 0.35831494132677716} | train loss {'Reaction outcome loss': 0.2798556697551524, 'Total loss': 0.2798556697551524}
2023-01-04 08:35:27,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:27,274 INFO:     Epoch: 79
2023-01-04 08:35:28,836 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.392964776357015, 'Total loss': 0.392964776357015} | train loss {'Reaction outcome loss': 0.28081314263038254, 'Total loss': 0.28081314263038254}
2023-01-04 08:35:28,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:28,836 INFO:     Epoch: 80
2023-01-04 08:35:30,444 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3520367294549942, 'Total loss': 0.3520367294549942} | train loss {'Reaction outcome loss': 0.2809485846101592, 'Total loss': 0.2809485846101592}
2023-01-04 08:35:30,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:30,446 INFO:     Epoch: 81
2023-01-04 08:35:32,039 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.34620393166939417, 'Total loss': 0.34620393166939417} | train loss {'Reaction outcome loss': 0.2779254487813165, 'Total loss': 0.2779254487813165}
2023-01-04 08:35:32,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:32,040 INFO:     Epoch: 82
2023-01-04 08:35:33,624 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3568196972211202, 'Total loss': 0.3568196972211202} | train loss {'Reaction outcome loss': 0.2744130022043786, 'Total loss': 0.2744130022043786}
2023-01-04 08:35:33,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:33,625 INFO:     Epoch: 83
2023-01-04 08:35:35,183 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35280995766321815, 'Total loss': 0.35280995766321815} | train loss {'Reaction outcome loss': 0.2779357773571238, 'Total loss': 0.2779357773571238}
2023-01-04 08:35:35,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:35,183 INFO:     Epoch: 84
2023-01-04 08:35:36,733 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35601552824179333, 'Total loss': 0.35601552824179333} | train loss {'Reaction outcome loss': 0.2709807845283071, 'Total loss': 0.2709807845283071}
2023-01-04 08:35:36,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:36,735 INFO:     Epoch: 85
2023-01-04 08:35:38,308 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37953785955905917, 'Total loss': 0.37953785955905917} | train loss {'Reaction outcome loss': 0.28066793124490697, 'Total loss': 0.28066793124490697}
2023-01-04 08:35:38,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:38,308 INFO:     Epoch: 86
2023-01-04 08:35:39,886 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33990199665228527, 'Total loss': 0.33990199665228527} | train loss {'Reaction outcome loss': 0.27362471665608756, 'Total loss': 0.27362471665608756}
2023-01-04 08:35:39,886 INFO:     Found new best model at epoch 86
2023-01-04 08:35:39,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:39,887 INFO:     Epoch: 87
2023-01-04 08:35:41,458 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.332001693546772, 'Total loss': 0.332001693546772} | train loss {'Reaction outcome loss': 0.26945432286292637, 'Total loss': 0.26945432286292637}
2023-01-04 08:35:41,458 INFO:     Found new best model at epoch 87
2023-01-04 08:35:41,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:41,459 INFO:     Epoch: 88
2023-01-04 08:35:43,031 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3631556838750839, 'Total loss': 0.3631556838750839} | train loss {'Reaction outcome loss': 0.2708093057309247, 'Total loss': 0.2708093057309247}
2023-01-04 08:35:43,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:43,032 INFO:     Epoch: 89
2023-01-04 08:35:44,591 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37870395481586455, 'Total loss': 0.37870395481586455} | train loss {'Reaction outcome loss': 0.2724959959783709, 'Total loss': 0.2724959959783709}
2023-01-04 08:35:44,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:44,592 INFO:     Epoch: 90
2023-01-04 08:35:46,151 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3803882489601771, 'Total loss': 0.3803882489601771} | train loss {'Reaction outcome loss': 0.27245659612468864, 'Total loss': 0.27245659612468864}
2023-01-04 08:35:46,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:46,151 INFO:     Epoch: 91
2023-01-04 08:35:47,750 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.348927208284537, 'Total loss': 0.348927208284537} | train loss {'Reaction outcome loss': 0.2732535604562355, 'Total loss': 0.2732535604562355}
2023-01-04 08:35:47,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:47,751 INFO:     Epoch: 92
2023-01-04 08:35:49,312 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.370645509660244, 'Total loss': 0.370645509660244} | train loss {'Reaction outcome loss': 0.27196484095406875, 'Total loss': 0.27196484095406875}
2023-01-04 08:35:49,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:49,312 INFO:     Epoch: 93
2023-01-04 08:35:50,897 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3746268262465795, 'Total loss': 0.3746268262465795} | train loss {'Reaction outcome loss': 0.2656355189152788, 'Total loss': 0.2656355189152788}
2023-01-04 08:35:50,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:50,897 INFO:     Epoch: 94
2023-01-04 08:35:52,479 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35012376656134925, 'Total loss': 0.35012376656134925} | train loss {'Reaction outcome loss': 0.26638179666460204, 'Total loss': 0.26638179666460204}
2023-01-04 08:35:52,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:52,479 INFO:     Epoch: 95
2023-01-04 08:35:54,042 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3590478152036667, 'Total loss': 0.3590478152036667} | train loss {'Reaction outcome loss': 0.26974313018930945, 'Total loss': 0.26974313018930945}
2023-01-04 08:35:54,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:54,042 INFO:     Epoch: 96
2023-01-04 08:35:55,606 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3574392557144165, 'Total loss': 0.3574392557144165} | train loss {'Reaction outcome loss': 0.2669653577548502, 'Total loss': 0.2669653577548502}
2023-01-04 08:35:55,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:55,607 INFO:     Epoch: 97
2023-01-04 08:35:57,178 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.35653146505355837, 'Total loss': 0.35653146505355837} | train loss {'Reaction outcome loss': 0.26636829461216494, 'Total loss': 0.26636829461216494}
2023-01-04 08:35:57,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:57,178 INFO:     Epoch: 98
2023-01-04 08:35:58,770 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37618890702724456, 'Total loss': 0.37618890702724456} | train loss {'Reaction outcome loss': 0.2629262491361329, 'Total loss': 0.2629262491361329}
2023-01-04 08:35:58,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:35:58,770 INFO:     Epoch: 99
2023-01-04 08:36:00,373 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35603783329327904, 'Total loss': 0.35603783329327904} | train loss {'Reaction outcome loss': 0.26546291165080743, 'Total loss': 0.26546291165080743}
2023-01-04 08:36:00,373 INFO:     Best model found after epoch 88 of 100.
2023-01-04 08:36:00,373 INFO:   Done with stage: TRAINING
2023-01-04 08:36:00,373 INFO:   Starting stage: EVALUATION
2023-01-04 08:36:00,499 INFO:   Done with stage: EVALUATION
2023-01-04 08:36:00,499 INFO:   Leaving out SEQ value Fold_9
2023-01-04 08:36:00,511 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 08:36:00,511 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:36:01,150 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:36:01,151 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:36:01,218 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:36:01,218 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:36:01,218 INFO:     No hyperparam tuning for this model
2023-01-04 08:36:01,218 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:36:01,218 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:36:01,219 INFO:     None feature selector for col prot
2023-01-04 08:36:01,219 INFO:     None feature selector for col prot
2023-01-04 08:36:01,219 INFO:     None feature selector for col prot
2023-01-04 08:36:01,220 INFO:     None feature selector for col chem
2023-01-04 08:36:01,220 INFO:     None feature selector for col chem
2023-01-04 08:36:01,220 INFO:     None feature selector for col chem
2023-01-04 08:36:01,220 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:36:01,220 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:36:01,221 INFO:     Number of params in model 70111
2023-01-04 08:36:01,224 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:36:01,224 INFO:   Starting stage: TRAINING
2023-01-04 08:36:01,266 INFO:     Val loss before train {'Reaction outcome loss': 0.9740177194277445, 'Total loss': 0.9740177194277445}
2023-01-04 08:36:01,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:01,266 INFO:     Epoch: 0
2023-01-04 08:36:02,825 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7514368335405985, 'Total loss': 0.7514368335405985} | train loss {'Reaction outcome loss': 0.8419373631477356, 'Total loss': 0.8419373631477356}
2023-01-04 08:36:02,825 INFO:     Found new best model at epoch 0
2023-01-04 08:36:02,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:02,826 INFO:     Epoch: 1
2023-01-04 08:36:04,357 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6608721335728963, 'Total loss': 0.6608721335728963} | train loss {'Reaction outcome loss': 0.6964074733265995, 'Total loss': 0.6964074733265995}
2023-01-04 08:36:04,357 INFO:     Found new best model at epoch 1
2023-01-04 08:36:04,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:04,358 INFO:     Epoch: 2
2023-01-04 08:36:05,937 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6061237990856171, 'Total loss': 0.6061237990856171} | train loss {'Reaction outcome loss': 0.6056713276970995, 'Total loss': 0.6056713276970995}
2023-01-04 08:36:05,937 INFO:     Found new best model at epoch 2
2023-01-04 08:36:05,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:05,938 INFO:     Epoch: 3
2023-01-04 08:36:07,511 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5975947717825572, 'Total loss': 0.5975947717825572} | train loss {'Reaction outcome loss': 0.559717123036402, 'Total loss': 0.559717123036402}
2023-01-04 08:36:07,512 INFO:     Found new best model at epoch 3
2023-01-04 08:36:07,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:07,513 INFO:     Epoch: 4
2023-01-04 08:36:09,097 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5462305168310801, 'Total loss': 0.5462305168310801} | train loss {'Reaction outcome loss': 0.5305896148520665, 'Total loss': 0.5305896148520665}
2023-01-04 08:36:09,098 INFO:     Found new best model at epoch 4
2023-01-04 08:36:09,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:09,098 INFO:     Epoch: 5
2023-01-04 08:36:10,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5197795907656352, 'Total loss': 0.5197795907656352} | train loss {'Reaction outcome loss': 0.5134405218554239, 'Total loss': 0.5134405218554239}
2023-01-04 08:36:10,652 INFO:     Found new best model at epoch 5
2023-01-04 08:36:10,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:10,652 INFO:     Epoch: 6
2023-01-04 08:36:12,219 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5238755544026693, 'Total loss': 0.5238755544026693} | train loss {'Reaction outcome loss': 0.4939894239506582, 'Total loss': 0.4939894239506582}
2023-01-04 08:36:12,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:12,220 INFO:     Epoch: 7
2023-01-04 08:36:13,736 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5096315324306488, 'Total loss': 0.5096315324306488} | train loss {'Reaction outcome loss': 0.48345797079322983, 'Total loss': 0.48345797079322983}
2023-01-04 08:36:13,736 INFO:     Found new best model at epoch 7
2023-01-04 08:36:13,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:13,737 INFO:     Epoch: 8
2023-01-04 08:36:15,271 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5084066907564799, 'Total loss': 0.5084066907564799} | train loss {'Reaction outcome loss': 0.47303781185271965, 'Total loss': 0.47303781185271965}
2023-01-04 08:36:15,271 INFO:     Found new best model at epoch 8
2023-01-04 08:36:15,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:15,272 INFO:     Epoch: 9
2023-01-04 08:36:16,825 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5187333881855011, 'Total loss': 0.5187333881855011} | train loss {'Reaction outcome loss': 0.4701643060811245, 'Total loss': 0.4701643060811245}
2023-01-04 08:36:16,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:16,825 INFO:     Epoch: 10
2023-01-04 08:36:18,365 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5156262318293253, 'Total loss': 0.5156262318293253} | train loss {'Reaction outcome loss': 0.4602366576555872, 'Total loss': 0.4602366576555872}
2023-01-04 08:36:18,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:18,365 INFO:     Epoch: 11
2023-01-04 08:36:19,888 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5069015145301818, 'Total loss': 0.5069015145301818} | train loss {'Reaction outcome loss': 0.4577859465005624, 'Total loss': 0.4577859465005624}
2023-01-04 08:36:19,888 INFO:     Found new best model at epoch 11
2023-01-04 08:36:19,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:19,889 INFO:     Epoch: 12
2023-01-04 08:36:21,424 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4859151065349579, 'Total loss': 0.4859151065349579} | train loss {'Reaction outcome loss': 0.44851163617015755, 'Total loss': 0.44851163617015755}
2023-01-04 08:36:21,424 INFO:     Found new best model at epoch 12
2023-01-04 08:36:21,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:21,425 INFO:     Epoch: 13
2023-01-04 08:36:22,613 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4865838954846064, 'Total loss': 0.4865838954846064} | train loss {'Reaction outcome loss': 0.44348765871603124, 'Total loss': 0.44348765871603124}
2023-01-04 08:36:22,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:22,614 INFO:     Epoch: 14
2023-01-04 08:36:23,626 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4900898893674215, 'Total loss': 0.4900898893674215} | train loss {'Reaction outcome loss': 0.43800434024229534, 'Total loss': 0.43800434024229534}
2023-01-04 08:36:23,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:23,626 INFO:     Epoch: 15
2023-01-04 08:36:24,632 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46793516079584757, 'Total loss': 0.46793516079584757} | train loss {'Reaction outcome loss': 0.4342110192906247, 'Total loss': 0.4342110192906247}
2023-01-04 08:36:24,632 INFO:     Found new best model at epoch 15
2023-01-04 08:36:24,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:24,633 INFO:     Epoch: 16
2023-01-04 08:36:25,642 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4616643945376078, 'Total loss': 0.4616643945376078} | train loss {'Reaction outcome loss': 0.4292080960895893, 'Total loss': 0.4292080960895893}
2023-01-04 08:36:25,642 INFO:     Found new best model at epoch 16
2023-01-04 08:36:25,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:25,643 INFO:     Epoch: 17
2023-01-04 08:36:26,761 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45739564994970955, 'Total loss': 0.45739564994970955} | train loss {'Reaction outcome loss': 0.423483748614353, 'Total loss': 0.423483748614353}
2023-01-04 08:36:26,762 INFO:     Found new best model at epoch 17
2023-01-04 08:36:26,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:26,763 INFO:     Epoch: 18
2023-01-04 08:36:28,322 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4715116520722707, 'Total loss': 0.4715116520722707} | train loss {'Reaction outcome loss': 0.4200129726507368, 'Total loss': 0.4200129726507368}
2023-01-04 08:36:28,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:28,322 INFO:     Epoch: 19
2023-01-04 08:36:29,874 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4660549879074097, 'Total loss': 0.4660549879074097} | train loss {'Reaction outcome loss': 0.41112128525537295, 'Total loss': 0.41112128525537295}
2023-01-04 08:36:29,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:29,874 INFO:     Epoch: 20
2023-01-04 08:36:31,446 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4576578696568807, 'Total loss': 0.4576578696568807} | train loss {'Reaction outcome loss': 0.40871664849075956, 'Total loss': 0.40871664849075956}
2023-01-04 08:36:31,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:31,446 INFO:     Epoch: 21
2023-01-04 08:36:32,995 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4561220000187556, 'Total loss': 0.4561220000187556} | train loss {'Reaction outcome loss': 0.40307426134491486, 'Total loss': 0.40307426134491486}
2023-01-04 08:36:32,995 INFO:     Found new best model at epoch 21
2023-01-04 08:36:32,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:32,996 INFO:     Epoch: 22
2023-01-04 08:36:34,565 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44270279407501223, 'Total loss': 0.44270279407501223} | train loss {'Reaction outcome loss': 0.4013152958376564, 'Total loss': 0.4013152958376564}
2023-01-04 08:36:34,565 INFO:     Found new best model at epoch 22
2023-01-04 08:36:34,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:34,565 INFO:     Epoch: 23
2023-01-04 08:36:36,046 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4553386439879735, 'Total loss': 0.4553386439879735} | train loss {'Reaction outcome loss': 0.39761093169124456, 'Total loss': 0.39761093169124456}
2023-01-04 08:36:36,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:36,046 INFO:     Epoch: 24
2023-01-04 08:36:37,613 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41566378275553384, 'Total loss': 0.41566378275553384} | train loss {'Reaction outcome loss': 0.3915072745867889, 'Total loss': 0.3915072745867889}
2023-01-04 08:36:37,613 INFO:     Found new best model at epoch 24
2023-01-04 08:36:37,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:37,614 INFO:     Epoch: 25
2023-01-04 08:36:39,172 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43972538113594056, 'Total loss': 0.43972538113594056} | train loss {'Reaction outcome loss': 0.389056409036156, 'Total loss': 0.389056409036156}
2023-01-04 08:36:39,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:39,173 INFO:     Epoch: 26
2023-01-04 08:36:40,734 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.427931110560894, 'Total loss': 0.427931110560894} | train loss {'Reaction outcome loss': 0.3836344477251498, 'Total loss': 0.3836344477251498}
2023-01-04 08:36:40,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:40,734 INFO:     Epoch: 27
2023-01-04 08:36:42,333 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43485271533330283, 'Total loss': 0.43485271533330283} | train loss {'Reaction outcome loss': 0.38055886072616507, 'Total loss': 0.38055886072616507}
2023-01-04 08:36:42,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:42,333 INFO:     Epoch: 28
2023-01-04 08:36:43,925 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43476071655750276, 'Total loss': 0.43476071655750276} | train loss {'Reaction outcome loss': 0.3758638357594065, 'Total loss': 0.3758638357594065}
2023-01-04 08:36:43,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:43,925 INFO:     Epoch: 29
2023-01-04 08:36:45,456 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4313244034846624, 'Total loss': 0.4313244034846624} | train loss {'Reaction outcome loss': 0.37545307954079915, 'Total loss': 0.37545307954079915}
2023-01-04 08:36:45,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:45,457 INFO:     Epoch: 30
2023-01-04 08:36:47,048 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4366876562436422, 'Total loss': 0.4366876562436422} | train loss {'Reaction outcome loss': 0.37138243465528004, 'Total loss': 0.37138243465528004}
2023-01-04 08:36:47,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:47,048 INFO:     Epoch: 31
2023-01-04 08:36:48,656 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44276729027430217, 'Total loss': 0.44276729027430217} | train loss {'Reaction outcome loss': 0.36564947422729793, 'Total loss': 0.36564947422729793}
2023-01-04 08:36:48,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:48,656 INFO:     Epoch: 32
2023-01-04 08:36:50,272 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43902440468470255, 'Total loss': 0.43902440468470255} | train loss {'Reaction outcome loss': 0.3593391068007824, 'Total loss': 0.3593391068007824}
2023-01-04 08:36:50,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:50,273 INFO:     Epoch: 33
2023-01-04 08:36:51,888 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4349033306042353, 'Total loss': 0.4349033306042353} | train loss {'Reaction outcome loss': 0.35574870923683594, 'Total loss': 0.35574870923683594}
2023-01-04 08:36:51,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:51,888 INFO:     Epoch: 34
2023-01-04 08:36:53,458 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41204696198304497, 'Total loss': 0.41204696198304497} | train loss {'Reaction outcome loss': 0.3561894835727493, 'Total loss': 0.3561894835727493}
2023-01-04 08:36:53,458 INFO:     Found new best model at epoch 34
2023-01-04 08:36:53,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:53,459 INFO:     Epoch: 35
2023-01-04 08:36:55,009 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42208322485287986, 'Total loss': 0.42208322485287986} | train loss {'Reaction outcome loss': 0.35434770464462084, 'Total loss': 0.35434770464462084}
2023-01-04 08:36:55,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:55,009 INFO:     Epoch: 36
2023-01-04 08:36:56,597 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4386271754900614, 'Total loss': 0.4386271754900614} | train loss {'Reaction outcome loss': 0.349084887707973, 'Total loss': 0.349084887707973}
2023-01-04 08:36:56,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:56,597 INFO:     Epoch: 37
2023-01-04 08:36:58,122 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4469712018966675, 'Total loss': 0.4469712018966675} | train loss {'Reaction outcome loss': 0.34362810423230605, 'Total loss': 0.34362810423230605}
2023-01-04 08:36:58,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:58,123 INFO:     Epoch: 38
2023-01-04 08:36:59,653 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4223196009794871, 'Total loss': 0.4223196009794871} | train loss {'Reaction outcome loss': 0.34207719942405274, 'Total loss': 0.34207719942405274}
2023-01-04 08:36:59,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:36:59,653 INFO:     Epoch: 39
2023-01-04 08:37:01,191 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45765830477078756, 'Total loss': 0.45765830477078756} | train loss {'Reaction outcome loss': 0.34291572463664693, 'Total loss': 0.34291572463664693}
2023-01-04 08:37:01,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:01,191 INFO:     Epoch: 40
2023-01-04 08:37:02,702 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.415621683994929, 'Total loss': 0.415621683994929} | train loss {'Reaction outcome loss': 0.3374754584183658, 'Total loss': 0.3374754584183658}
2023-01-04 08:37:02,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:02,702 INFO:     Epoch: 41
2023-01-04 08:37:04,203 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42940528790156046, 'Total loss': 0.42940528790156046} | train loss {'Reaction outcome loss': 0.3339928603139672, 'Total loss': 0.3339928603139672}
2023-01-04 08:37:04,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:04,203 INFO:     Epoch: 42
2023-01-04 08:37:05,736 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4141213099161784, 'Total loss': 0.4141213099161784} | train loss {'Reaction outcome loss': 0.33186380059397136, 'Total loss': 0.33186380059397136}
2023-01-04 08:37:05,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:05,737 INFO:     Epoch: 43
2023-01-04 08:37:07,273 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.396883532901605, 'Total loss': 0.396883532901605} | train loss {'Reaction outcome loss': 0.32766075410547046, 'Total loss': 0.32766075410547046}
2023-01-04 08:37:07,273 INFO:     Found new best model at epoch 43
2023-01-04 08:37:07,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:07,274 INFO:     Epoch: 44
2023-01-04 08:37:08,805 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4237499713897705, 'Total loss': 0.4237499713897705} | train loss {'Reaction outcome loss': 0.32242050247579596, 'Total loss': 0.32242050247579596}
2023-01-04 08:37:08,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:08,805 INFO:     Epoch: 45
2023-01-04 08:37:10,350 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40820876558621727, 'Total loss': 0.40820876558621727} | train loss {'Reaction outcome loss': 0.3237142350225553, 'Total loss': 0.3237142350225553}
2023-01-04 08:37:10,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:10,351 INFO:     Epoch: 46
2023-01-04 08:37:11,854 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.428356130917867, 'Total loss': 0.428356130917867} | train loss {'Reaction outcome loss': 0.3205535470569221, 'Total loss': 0.3205535470569221}
2023-01-04 08:37:11,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:11,854 INFO:     Epoch: 47
2023-01-04 08:37:13,373 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37555199960867564, 'Total loss': 0.37555199960867564} | train loss {'Reaction outcome loss': 0.3179992087674837, 'Total loss': 0.3179992087674837}
2023-01-04 08:37:13,374 INFO:     Found new best model at epoch 47
2023-01-04 08:37:13,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:13,374 INFO:     Epoch: 48
2023-01-04 08:37:14,901 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3970258782307307, 'Total loss': 0.3970258782307307} | train loss {'Reaction outcome loss': 0.31943849074470737, 'Total loss': 0.31943849074470737}
2023-01-04 08:37:14,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:14,902 INFO:     Epoch: 49
2023-01-04 08:37:16,453 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4118577420711517, 'Total loss': 0.4118577420711517} | train loss {'Reaction outcome loss': 0.31387165765257646, 'Total loss': 0.31387165765257646}
2023-01-04 08:37:16,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:16,454 INFO:     Epoch: 50
2023-01-04 08:37:17,977 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3875598818063736, 'Total loss': 0.3875598818063736} | train loss {'Reaction outcome loss': 0.3106864802811268, 'Total loss': 0.3106864802811268}
2023-01-04 08:37:17,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:17,977 INFO:     Epoch: 51
2023-01-04 08:37:19,526 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3757568950454394, 'Total loss': 0.3757568950454394} | train loss {'Reaction outcome loss': 0.3102336721154895, 'Total loss': 0.3102336721154895}
2023-01-04 08:37:19,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:19,526 INFO:     Epoch: 52
2023-01-04 08:37:21,014 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3918526992201805, 'Total loss': 0.3918526992201805} | train loss {'Reaction outcome loss': 0.30936148061151925, 'Total loss': 0.30936148061151925}
2023-01-04 08:37:21,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:21,015 INFO:     Epoch: 53
2023-01-04 08:37:22,558 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4108979081114133, 'Total loss': 0.4108979081114133} | train loss {'Reaction outcome loss': 0.304261806658911, 'Total loss': 0.304261806658911}
2023-01-04 08:37:22,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:22,558 INFO:     Epoch: 54
2023-01-04 08:37:24,107 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4104397277037303, 'Total loss': 0.4104397277037303} | train loss {'Reaction outcome loss': 0.3020458541212291, 'Total loss': 0.3020458541212291}
2023-01-04 08:37:24,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:24,108 INFO:     Epoch: 55
2023-01-04 08:37:25,662 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37793895105520886, 'Total loss': 0.37793895105520886} | train loss {'Reaction outcome loss': 0.30092047285424534, 'Total loss': 0.30092047285424534}
2023-01-04 08:37:25,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:25,663 INFO:     Epoch: 56
2023-01-04 08:37:27,201 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41757562309503554, 'Total loss': 0.41757562309503554} | train loss {'Reaction outcome loss': 0.2975557871761113, 'Total loss': 0.2975557871761113}
2023-01-04 08:37:27,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:27,201 INFO:     Epoch: 57
2023-01-04 08:37:28,750 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4170915315548579, 'Total loss': 0.4170915315548579} | train loss {'Reaction outcome loss': 0.3003358012677109, 'Total loss': 0.3003358012677109}
2023-01-04 08:37:28,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:28,750 INFO:     Epoch: 58
2023-01-04 08:37:30,237 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3778668021162351, 'Total loss': 0.3778668021162351} | train loss {'Reaction outcome loss': 0.29390498362209677, 'Total loss': 0.29390498362209677}
2023-01-04 08:37:30,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:30,238 INFO:     Epoch: 59
2023-01-04 08:37:31,804 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37481832603613535, 'Total loss': 0.37481832603613535} | train loss {'Reaction outcome loss': 0.2951388895566011, 'Total loss': 0.2951388895566011}
2023-01-04 08:37:31,804 INFO:     Found new best model at epoch 59
2023-01-04 08:37:31,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:31,805 INFO:     Epoch: 60
2023-01-04 08:37:33,343 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39500729242960614, 'Total loss': 0.39500729242960614} | train loss {'Reaction outcome loss': 0.2917625483832438, 'Total loss': 0.2917625483832438}
2023-01-04 08:37:33,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:33,344 INFO:     Epoch: 61
2023-01-04 08:37:34,885 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4096832772095998, 'Total loss': 0.4096832772095998} | train loss {'Reaction outcome loss': 0.29260865084990095, 'Total loss': 0.29260865084990095}
2023-01-04 08:37:34,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:34,885 INFO:     Epoch: 62
2023-01-04 08:37:36,433 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.35811525707443553, 'Total loss': 0.35811525707443553} | train loss {'Reaction outcome loss': 0.287994430448017, 'Total loss': 0.287994430448017}
2023-01-04 08:37:36,433 INFO:     Found new best model at epoch 62
2023-01-04 08:37:36,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:36,434 INFO:     Epoch: 63
2023-01-04 08:37:37,980 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39303547938664757, 'Total loss': 0.39303547938664757} | train loss {'Reaction outcome loss': 0.2889849484565049, 'Total loss': 0.2889849484565049}
2023-01-04 08:37:37,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:37,980 INFO:     Epoch: 64
2023-01-04 08:37:39,471 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3795319358507792, 'Total loss': 0.3795319358507792} | train loss {'Reaction outcome loss': 0.288263474964965, 'Total loss': 0.288263474964965}
2023-01-04 08:37:39,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:39,471 INFO:     Epoch: 65
2023-01-04 08:37:41,012 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38289528886477153, 'Total loss': 0.38289528886477153} | train loss {'Reaction outcome loss': 0.2893654644543672, 'Total loss': 0.2893654644543672}
2023-01-04 08:37:41,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:41,012 INFO:     Epoch: 66
2023-01-04 08:37:42,549 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40460086266199746, 'Total loss': 0.40460086266199746} | train loss {'Reaction outcome loss': 0.28452949908419245, 'Total loss': 0.28452949908419245}
2023-01-04 08:37:42,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:42,549 INFO:     Epoch: 67
2023-01-04 08:37:44,098 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38208395540714263, 'Total loss': 0.38208395540714263} | train loss {'Reaction outcome loss': 0.2723825416887981, 'Total loss': 0.2723825416887981}
2023-01-04 08:37:44,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:44,098 INFO:     Epoch: 68
2023-01-04 08:37:45,661 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39631512463092805, 'Total loss': 0.39631512463092805} | train loss {'Reaction outcome loss': 0.2790666413051586, 'Total loss': 0.2790666413051586}
2023-01-04 08:37:45,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:45,661 INFO:     Epoch: 69
2023-01-04 08:37:47,215 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39309790134429934, 'Total loss': 0.39309790134429934} | train loss {'Reaction outcome loss': 0.27923575503221393, 'Total loss': 0.27923575503221393}
2023-01-04 08:37:47,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:47,216 INFO:     Epoch: 70
2023-01-04 08:37:48,706 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38917270104090373, 'Total loss': 0.38917270104090373} | train loss {'Reaction outcome loss': 0.2793668864743553, 'Total loss': 0.2793668864743553}
2023-01-04 08:37:48,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:48,707 INFO:     Epoch: 71
2023-01-04 08:37:50,265 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3988171676794688, 'Total loss': 0.3988171676794688} | train loss {'Reaction outcome loss': 0.277319283843258, 'Total loss': 0.277319283843258}
2023-01-04 08:37:50,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:50,267 INFO:     Epoch: 72
2023-01-04 08:37:51,811 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37802285452683765, 'Total loss': 0.37802285452683765} | train loss {'Reaction outcome loss': 0.2727865635614543, 'Total loss': 0.2727865635614543}
2023-01-04 08:37:51,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:51,811 INFO:     Epoch: 73
2023-01-04 08:37:53,352 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38895148038864136, 'Total loss': 0.38895148038864136} | train loss {'Reaction outcome loss': 0.269925946152232, 'Total loss': 0.269925946152232}
2023-01-04 08:37:53,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:53,352 INFO:     Epoch: 74
2023-01-04 08:37:54,887 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35707866251468656, 'Total loss': 0.35707866251468656} | train loss {'Reaction outcome loss': 0.27477963581463716, 'Total loss': 0.27477963581463716}
2023-01-04 08:37:54,887 INFO:     Found new best model at epoch 74
2023-01-04 08:37:54,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:54,888 INFO:     Epoch: 75
2023-01-04 08:37:56,427 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4236945271492004, 'Total loss': 0.4236945271492004} | train loss {'Reaction outcome loss': 0.27208915017001384, 'Total loss': 0.27208915017001384}
2023-01-04 08:37:56,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:56,428 INFO:     Epoch: 76
2023-01-04 08:37:57,923 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37518626898527146, 'Total loss': 0.37518626898527146} | train loss {'Reaction outcome loss': 0.2687180296511111, 'Total loss': 0.2687180296511111}
2023-01-04 08:37:57,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:57,923 INFO:     Epoch: 77
2023-01-04 08:37:59,525 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39144426584243774, 'Total loss': 0.39144426584243774} | train loss {'Reaction outcome loss': 0.2654651388743498, 'Total loss': 0.2654651388743498}
2023-01-04 08:37:59,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:37:59,526 INFO:     Epoch: 78
2023-01-04 08:38:01,117 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42029207944869995, 'Total loss': 0.42029207944869995} | train loss {'Reaction outcome loss': 0.26403673893235025, 'Total loss': 0.26403673893235025}
2023-01-04 08:38:01,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:01,117 INFO:     Epoch: 79
2023-01-04 08:38:02,702 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38704299330711367, 'Total loss': 0.38704299330711367} | train loss {'Reaction outcome loss': 0.268659780549742, 'Total loss': 0.268659780549742}
2023-01-04 08:38:02,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:02,702 INFO:     Epoch: 80
2023-01-04 08:38:04,307 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3814470504721006, 'Total loss': 0.3814470504721006} | train loss {'Reaction outcome loss': 0.2658196340593761, 'Total loss': 0.2658196340593761}
2023-01-04 08:38:04,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:04,307 INFO:     Epoch: 81
2023-01-04 08:38:05,874 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37549379567305247, 'Total loss': 0.37549379567305247} | train loss {'Reaction outcome loss': 0.26289046181868897, 'Total loss': 0.26289046181868897}
2023-01-04 08:38:05,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:05,874 INFO:     Epoch: 82
2023-01-04 08:38:07,431 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3728766034046809, 'Total loss': 0.3728766034046809} | train loss {'Reaction outcome loss': 0.2593409894374165, 'Total loss': 0.2593409894374165}
2023-01-04 08:38:07,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:07,431 INFO:     Epoch: 83
2023-01-04 08:38:09,032 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3978147804737091, 'Total loss': 0.3978147804737091} | train loss {'Reaction outcome loss': 0.26199080475544845, 'Total loss': 0.26199080475544845}
2023-01-04 08:38:09,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:09,033 INFO:     Epoch: 84
2023-01-04 08:38:10,621 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4252673471967379, 'Total loss': 0.4252673471967379} | train loss {'Reaction outcome loss': 0.2597641645366476, 'Total loss': 0.2597641645366476}
2023-01-04 08:38:10,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:10,622 INFO:     Epoch: 85
2023-01-04 08:38:12,222 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4154633144537608, 'Total loss': 0.4154633144537608} | train loss {'Reaction outcome loss': 0.26219054791450935, 'Total loss': 0.26219054791450935}
2023-01-04 08:38:12,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:12,222 INFO:     Epoch: 86
2023-01-04 08:38:13,803 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38110672136147816, 'Total loss': 0.38110672136147816} | train loss {'Reaction outcome loss': 0.2546599389590921, 'Total loss': 0.2546599389590921}
2023-01-04 08:38:13,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:13,804 INFO:     Epoch: 87
2023-01-04 08:38:15,356 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3774784758687019, 'Total loss': 0.3774784758687019} | train loss {'Reaction outcome loss': 0.25457901067107264, 'Total loss': 0.25457901067107264}
2023-01-04 08:38:15,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:15,356 INFO:     Epoch: 88
2023-01-04 08:38:16,913 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4037877743442853, 'Total loss': 0.4037877743442853} | train loss {'Reaction outcome loss': 0.2634396642500902, 'Total loss': 0.2634396642500902}
2023-01-04 08:38:16,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:16,914 INFO:     Epoch: 89
2023-01-04 08:38:18,458 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37455995778242746, 'Total loss': 0.37455995778242746} | train loss {'Reaction outcome loss': 0.266919483328714, 'Total loss': 0.266919483328714}
2023-01-04 08:38:18,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:18,458 INFO:     Epoch: 90
2023-01-04 08:38:19,999 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.383564821879069, 'Total loss': 0.383564821879069} | train loss {'Reaction outcome loss': 0.25245702185117413, 'Total loss': 0.25245702185117413}
2023-01-04 08:38:19,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:19,999 INFO:     Epoch: 91
2023-01-04 08:38:21,530 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3758824378252029, 'Total loss': 0.3758824378252029} | train loss {'Reaction outcome loss': 0.25414341791485345, 'Total loss': 0.25414341791485345}
2023-01-04 08:38:21,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:21,531 INFO:     Epoch: 92
2023-01-04 08:38:23,068 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.33864668011665344, 'Total loss': 0.33864668011665344} | train loss {'Reaction outcome loss': 0.25273599360056603, 'Total loss': 0.25273599360056603}
2023-01-04 08:38:23,068 INFO:     Found new best model at epoch 92
2023-01-04 08:38:23,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:23,069 INFO:     Epoch: 93
2023-01-04 08:38:24,538 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35845420944194, 'Total loss': 0.35845420944194} | train loss {'Reaction outcome loss': 0.25216250600170914, 'Total loss': 0.25216250600170914}
2023-01-04 08:38:24,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:24,538 INFO:     Epoch: 94
2023-01-04 08:38:26,068 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3426707834005356, 'Total loss': 0.3426707834005356} | train loss {'Reaction outcome loss': 0.2546416026587686, 'Total loss': 0.2546416026587686}
2023-01-04 08:38:26,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:26,068 INFO:     Epoch: 95
2023-01-04 08:38:27,607 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37161854952573775, 'Total loss': 0.37161854952573775} | train loss {'Reaction outcome loss': 0.25241049559936474, 'Total loss': 0.25241049559936474}
2023-01-04 08:38:27,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:27,608 INFO:     Epoch: 96
2023-01-04 08:38:29,143 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3806917190551758, 'Total loss': 0.3806917190551758} | train loss {'Reaction outcome loss': 0.2538020797617679, 'Total loss': 0.2538020797617679}
2023-01-04 08:38:29,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:29,143 INFO:     Epoch: 97
2023-01-04 08:38:30,680 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4160782366991043, 'Total loss': 0.4160782366991043} | train loss {'Reaction outcome loss': 0.24966516761775434, 'Total loss': 0.24966516761775434}
2023-01-04 08:38:30,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:30,680 INFO:     Epoch: 98
2023-01-04 08:38:32,207 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3842069834470749, 'Total loss': 0.3842069834470749} | train loss {'Reaction outcome loss': 0.2491034290678527, 'Total loss': 0.2491034290678527}
2023-01-04 08:38:32,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:32,207 INFO:     Epoch: 99
2023-01-04 08:38:33,689 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37010141313076017, 'Total loss': 0.37010141313076017} | train loss {'Reaction outcome loss': 0.2481297038930611, 'Total loss': 0.2481297038930611}
2023-01-04 08:38:33,689 INFO:     Best model found after epoch 93 of 100.
2023-01-04 08:38:33,689 INFO:   Done with stage: TRAINING
2023-01-04 08:38:33,689 INFO:   Starting stage: EVALUATION
2023-01-04 08:38:33,823 INFO:   Done with stage: EVALUATION
2023-01-04 08:38:33,831 INFO:   Leaving out SEQ value Fold_0
2023-01-04 08:38:33,844 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 08:38:33,844 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:38:34,482 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:38:34,482 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:38:34,549 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:38:34,549 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:38:34,549 INFO:     No hyperparam tuning for this model
2023-01-04 08:38:34,549 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:38:34,549 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:38:34,550 INFO:     None feature selector for col prot
2023-01-04 08:38:34,550 INFO:     None feature selector for col prot
2023-01-04 08:38:34,550 INFO:     None feature selector for col prot
2023-01-04 08:38:34,551 INFO:     None feature selector for col chem
2023-01-04 08:38:34,551 INFO:     None feature selector for col chem
2023-01-04 08:38:34,551 INFO:     None feature selector for col chem
2023-01-04 08:38:34,551 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:38:34,551 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:38:34,552 INFO:     Number of params in model 70111
2023-01-04 08:38:34,555 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:38:34,555 INFO:   Starting stage: TRAINING
2023-01-04 08:38:34,597 INFO:     Val loss before train {'Reaction outcome loss': 1.0572500030199687, 'Total loss': 1.0572500030199687}
2023-01-04 08:38:34,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:34,597 INFO:     Epoch: 0
2023-01-04 08:38:36,124 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8151785055796306, 'Total loss': 0.8151785055796306} | train loss {'Reaction outcome loss': 0.8535458789421961, 'Total loss': 0.8535458789421961}
2023-01-04 08:38:36,125 INFO:     Found new best model at epoch 0
2023-01-04 08:38:36,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:36,125 INFO:     Epoch: 1
2023-01-04 08:38:37,646 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6529508332411448, 'Total loss': 0.6529508332411448} | train loss {'Reaction outcome loss': 0.6983534704634559, 'Total loss': 0.6983534704634559}
2023-01-04 08:38:37,646 INFO:     Found new best model at epoch 1
2023-01-04 08:38:37,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:37,647 INFO:     Epoch: 2
2023-01-04 08:38:39,170 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5944803098837534, 'Total loss': 0.5944803098837534} | train loss {'Reaction outcome loss': 0.588401449305234, 'Total loss': 0.588401449305234}
2023-01-04 08:38:39,170 INFO:     Found new best model at epoch 2
2023-01-04 08:38:39,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:39,171 INFO:     Epoch: 3
2023-01-04 08:38:40,704 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5724328090747197, 'Total loss': 0.5724328090747197} | train loss {'Reaction outcome loss': 0.5400130596462187, 'Total loss': 0.5400130596462187}
2023-01-04 08:38:40,704 INFO:     Found new best model at epoch 3
2023-01-04 08:38:40,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:40,705 INFO:     Epoch: 4
2023-01-04 08:38:42,192 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5473049193620682, 'Total loss': 0.5473049193620682} | train loss {'Reaction outcome loss': 0.5149803587368557, 'Total loss': 0.5149803587368557}
2023-01-04 08:38:42,192 INFO:     Found new best model at epoch 4
2023-01-04 08:38:42,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:42,193 INFO:     Epoch: 5
2023-01-04 08:38:43,724 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.559917946656545, 'Total loss': 0.559917946656545} | train loss {'Reaction outcome loss': 0.4982278724183966, 'Total loss': 0.4982278724183966}
2023-01-04 08:38:43,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:43,725 INFO:     Epoch: 6
2023-01-04 08:38:45,243 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5635327279567719, 'Total loss': 0.5635327279567719} | train loss {'Reaction outcome loss': 0.4895127199508332, 'Total loss': 0.4895127199508332}
2023-01-04 08:38:45,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:45,244 INFO:     Epoch: 7
2023-01-04 08:38:46,772 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5491169035434723, 'Total loss': 0.5491169035434723} | train loss {'Reaction outcome loss': 0.4788943972888884, 'Total loss': 0.4788943972888884}
2023-01-04 08:38:46,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:46,773 INFO:     Epoch: 8
2023-01-04 08:38:48,302 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5266650557518006, 'Total loss': 0.5266650557518006} | train loss {'Reaction outcome loss': 0.4743083642297612, 'Total loss': 0.4743083642297612}
2023-01-04 08:38:48,302 INFO:     Found new best model at epoch 8
2023-01-04 08:38:48,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:48,303 INFO:     Epoch: 9
2023-01-04 08:38:49,828 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5111360629399617, 'Total loss': 0.5111360629399617} | train loss {'Reaction outcome loss': 0.46493734823260113, 'Total loss': 0.46493734823260113}
2023-01-04 08:38:49,828 INFO:     Found new best model at epoch 9
2023-01-04 08:38:49,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:49,829 INFO:     Epoch: 10
2023-01-04 08:38:51,300 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.531885278224945, 'Total loss': 0.531885278224945} | train loss {'Reaction outcome loss': 0.45956381347589875, 'Total loss': 0.45956381347589875}
2023-01-04 08:38:51,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:51,300 INFO:     Epoch: 11
2023-01-04 08:38:52,824 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5313450555006664, 'Total loss': 0.5313450555006664} | train loss {'Reaction outcome loss': 0.45482352990043035, 'Total loss': 0.45482352990043035}
2023-01-04 08:38:52,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:52,824 INFO:     Epoch: 12
2023-01-04 08:38:54,348 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5331695536772411, 'Total loss': 0.5331695536772411} | train loss {'Reaction outcome loss': 0.45001667732502515, 'Total loss': 0.45001667732502515}
2023-01-04 08:38:54,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:54,349 INFO:     Epoch: 13
2023-01-04 08:38:55,883 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5285872608423233, 'Total loss': 0.5285872608423233} | train loss {'Reaction outcome loss': 0.44155631211651114, 'Total loss': 0.44155631211651114}
2023-01-04 08:38:55,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:55,883 INFO:     Epoch: 14
2023-01-04 08:38:57,411 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5167801042397817, 'Total loss': 0.5167801042397817} | train loss {'Reaction outcome loss': 0.4422249327321629, 'Total loss': 0.4422249327321629}
2023-01-04 08:38:57,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:57,413 INFO:     Epoch: 15
2023-01-04 08:38:58,976 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48453978896141053, 'Total loss': 0.48453978896141053} | train loss {'Reaction outcome loss': 0.4354239876344527, 'Total loss': 0.4354239876344527}
2023-01-04 08:38:58,976 INFO:     Found new best model at epoch 15
2023-01-04 08:38:58,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:38:58,977 INFO:     Epoch: 16
2023-01-04 08:39:00,459 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.483058500289917, 'Total loss': 0.483058500289917} | train loss {'Reaction outcome loss': 0.4329817650955675, 'Total loss': 0.4329817650955675}
2023-01-04 08:39:00,459 INFO:     Found new best model at epoch 16
2023-01-04 08:39:00,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:00,460 INFO:     Epoch: 17
2023-01-04 08:39:01,984 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5192697902520498, 'Total loss': 0.5192697902520498} | train loss {'Reaction outcome loss': 0.4281455794206032, 'Total loss': 0.4281455794206032}
2023-01-04 08:39:01,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:01,984 INFO:     Epoch: 18
2023-01-04 08:39:03,518 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5168036619822184, 'Total loss': 0.5168036619822184} | train loss {'Reaction outcome loss': 0.4225226864491627, 'Total loss': 0.4225226864491627}
2023-01-04 08:39:03,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:03,519 INFO:     Epoch: 19
2023-01-04 08:39:05,055 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4855461855729421, 'Total loss': 0.4855461855729421} | train loss {'Reaction outcome loss': 0.4185688441052978, 'Total loss': 0.4185688441052978}
2023-01-04 08:39:05,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:05,055 INFO:     Epoch: 20
2023-01-04 08:39:06,588 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4807875136534373, 'Total loss': 0.4807875136534373} | train loss {'Reaction outcome loss': 0.4169035985137953, 'Total loss': 0.4169035985137953}
2023-01-04 08:39:06,588 INFO:     Found new best model at epoch 20
2023-01-04 08:39:06,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:06,589 INFO:     Epoch: 21
2023-01-04 08:39:08,165 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4864395658175151, 'Total loss': 0.4864395658175151} | train loss {'Reaction outcome loss': 0.41247861517163426, 'Total loss': 0.41247861517163426}
2023-01-04 08:39:08,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:08,166 INFO:     Epoch: 22
2023-01-04 08:39:09,646 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5158749500910441, 'Total loss': 0.5158749500910441} | train loss {'Reaction outcome loss': 0.4069346575400768, 'Total loss': 0.4069346575400768}
2023-01-04 08:39:09,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:09,646 INFO:     Epoch: 23
2023-01-04 08:39:11,210 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48199076056480405, 'Total loss': 0.48199076056480405} | train loss {'Reaction outcome loss': 0.40658738908968567, 'Total loss': 0.40658738908968567}
2023-01-04 08:39:11,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:11,211 INFO:     Epoch: 24
2023-01-04 08:39:12,790 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4696710228919983, 'Total loss': 0.4696710228919983} | train loss {'Reaction outcome loss': 0.39770863980273186, 'Total loss': 0.39770863980273186}
2023-01-04 08:39:12,790 INFO:     Found new best model at epoch 24
2023-01-04 08:39:12,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:12,791 INFO:     Epoch: 25
2023-01-04 08:39:14,362 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48384901086489357, 'Total loss': 0.48384901086489357} | train loss {'Reaction outcome loss': 0.39591388431660857, 'Total loss': 0.39591388431660857}
2023-01-04 08:39:14,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:14,362 INFO:     Epoch: 26
2023-01-04 08:39:15,949 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46982399225234983, 'Total loss': 0.46982399225234983} | train loss {'Reaction outcome loss': 0.3975807994658694, 'Total loss': 0.3975807994658694}
2023-01-04 08:39:15,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:15,950 INFO:     Epoch: 27
2023-01-04 08:39:17,521 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4728437920411428, 'Total loss': 0.4728437920411428} | train loss {'Reaction outcome loss': 0.3889310310011382, 'Total loss': 0.3889310310011382}
2023-01-04 08:39:17,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:17,522 INFO:     Epoch: 28
2023-01-04 08:39:19,028 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47961272597312926, 'Total loss': 0.47961272597312926} | train loss {'Reaction outcome loss': 0.3851125260385183, 'Total loss': 0.3851125260385183}
2023-01-04 08:39:19,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:19,028 INFO:     Epoch: 29
2023-01-04 08:39:20,609 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4621339003245036, 'Total loss': 0.4621339003245036} | train loss {'Reaction outcome loss': 0.38569373255356765, 'Total loss': 0.38569373255356765}
2023-01-04 08:39:20,610 INFO:     Found new best model at epoch 29
2023-01-04 08:39:20,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:20,610 INFO:     Epoch: 30
2023-01-04 08:39:22,192 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4679273247718811, 'Total loss': 0.4679273247718811} | train loss {'Reaction outcome loss': 0.38625669610369334, 'Total loss': 0.38625669610369334}
2023-01-04 08:39:22,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:22,192 INFO:     Epoch: 31
2023-01-04 08:39:23,774 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45331551432609557, 'Total loss': 0.45331551432609557} | train loss {'Reaction outcome loss': 0.37471312349969216, 'Total loss': 0.37471312349969216}
2023-01-04 08:39:23,774 INFO:     Found new best model at epoch 31
2023-01-04 08:39:23,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:23,775 INFO:     Epoch: 32
2023-01-04 08:39:25,349 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4621807038784027, 'Total loss': 0.4621807038784027} | train loss {'Reaction outcome loss': 0.37559721220434805, 'Total loss': 0.37559721220434805}
2023-01-04 08:39:25,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:25,350 INFO:     Epoch: 33
2023-01-04 08:39:26,876 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47218724091847736, 'Total loss': 0.47218724091847736} | train loss {'Reaction outcome loss': 0.37100325028101605, 'Total loss': 0.37100325028101605}
2023-01-04 08:39:26,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:26,876 INFO:     Epoch: 34
2023-01-04 08:39:28,401 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4799875676631927, 'Total loss': 0.4799875676631927} | train loss {'Reaction outcome loss': 0.37108806187744103, 'Total loss': 0.37108806187744103}
2023-01-04 08:39:28,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:28,402 INFO:     Epoch: 35
2023-01-04 08:39:29,987 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43797027120987575, 'Total loss': 0.43797027120987575} | train loss {'Reaction outcome loss': 0.3681056922772428, 'Total loss': 0.3681056922772428}
2023-01-04 08:39:29,987 INFO:     Found new best model at epoch 35
2023-01-04 08:39:29,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:29,987 INFO:     Epoch: 36
2023-01-04 08:39:31,549 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46114890575408934, 'Total loss': 0.46114890575408934} | train loss {'Reaction outcome loss': 0.3641405673424676, 'Total loss': 0.3641405673424676}
2023-01-04 08:39:31,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:31,549 INFO:     Epoch: 37
2023-01-04 08:39:33,119 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4924091955025991, 'Total loss': 0.4924091955025991} | train loss {'Reaction outcome loss': 0.35887647761311725, 'Total loss': 0.35887647761311725}
2023-01-04 08:39:33,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:33,120 INFO:     Epoch: 38
2023-01-04 08:39:34,686 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.463821280002594, 'Total loss': 0.463821280002594} | train loss {'Reaction outcome loss': 0.3576331337565904, 'Total loss': 0.3576331337565904}
2023-01-04 08:39:34,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:34,687 INFO:     Epoch: 39
2023-01-04 08:39:36,214 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48426809112230934, 'Total loss': 0.48426809112230934} | train loss {'Reaction outcome loss': 0.35564679087518336, 'Total loss': 0.35564679087518336}
2023-01-04 08:39:36,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:36,214 INFO:     Epoch: 40
2023-01-04 08:39:37,728 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4107444554567337, 'Total loss': 0.4107444554567337} | train loss {'Reaction outcome loss': 0.3513567565834566, 'Total loss': 0.3513567565834566}
2023-01-04 08:39:37,728 INFO:     Found new best model at epoch 40
2023-01-04 08:39:37,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:37,729 INFO:     Epoch: 41
2023-01-04 08:39:39,268 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44177803794542947, 'Total loss': 0.44177803794542947} | train loss {'Reaction outcome loss': 0.3514491156453178, 'Total loss': 0.3514491156453178}
2023-01-04 08:39:39,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:39,269 INFO:     Epoch: 42
2023-01-04 08:39:40,832 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44271923502286276, 'Total loss': 0.44271923502286276} | train loss {'Reaction outcome loss': 0.3460170359047123, 'Total loss': 0.3460170359047123}
2023-01-04 08:39:40,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:40,832 INFO:     Epoch: 43
2023-01-04 08:39:42,384 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43508026202519734, 'Total loss': 0.43508026202519734} | train loss {'Reaction outcome loss': 0.34208575996396307, 'Total loss': 0.34208575996396307}
2023-01-04 08:39:42,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:42,384 INFO:     Epoch: 44
2023-01-04 08:39:43,937 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4125998636086782, 'Total loss': 0.4125998636086782} | train loss {'Reaction outcome loss': 0.34227863044201673, 'Total loss': 0.34227863044201673}
2023-01-04 08:39:43,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:43,937 INFO:     Epoch: 45
2023-01-04 08:39:45,462 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4260577877362569, 'Total loss': 0.4260577877362569} | train loss {'Reaction outcome loss': 0.3353016565352569, 'Total loss': 0.3353016565352569}
2023-01-04 08:39:45,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:45,463 INFO:     Epoch: 46
2023-01-04 08:39:46,979 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4453260213136673, 'Total loss': 0.4453260213136673} | train loss {'Reaction outcome loss': 0.3363664600002023, 'Total loss': 0.3363664600002023}
2023-01-04 08:39:46,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:46,979 INFO:     Epoch: 47
2023-01-04 08:39:48,531 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42497144838174183, 'Total loss': 0.42497144838174183} | train loss {'Reaction outcome loss': 0.3343832783209972, 'Total loss': 0.3343832783209972}
2023-01-04 08:39:48,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:48,532 INFO:     Epoch: 48
2023-01-04 08:39:50,061 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43457831094662347, 'Total loss': 0.43457831094662347} | train loss {'Reaction outcome loss': 0.33326306693501523, 'Total loss': 0.33326306693501523}
2023-01-04 08:39:50,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:50,062 INFO:     Epoch: 49
2023-01-04 08:39:51,608 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4808273911476135, 'Total loss': 0.4808273911476135} | train loss {'Reaction outcome loss': 0.32966120595678744, 'Total loss': 0.32966120595678744}
2023-01-04 08:39:51,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:51,609 INFO:     Epoch: 50
2023-01-04 08:39:53,147 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44448067744572956, 'Total loss': 0.44448067744572956} | train loss {'Reaction outcome loss': 0.3295053517643785, 'Total loss': 0.3295053517643785}
2023-01-04 08:39:53,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:53,148 INFO:     Epoch: 51
2023-01-04 08:39:54,645 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46163348356882733, 'Total loss': 0.46163348356882733} | train loss {'Reaction outcome loss': 0.32682749028607605, 'Total loss': 0.32682749028607605}
2023-01-04 08:39:54,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:54,645 INFO:     Epoch: 52
2023-01-04 08:39:56,143 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42514167229334515, 'Total loss': 0.42514167229334515} | train loss {'Reaction outcome loss': 0.3216398591414476, 'Total loss': 0.3216398591414476}
2023-01-04 08:39:56,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:56,144 INFO:     Epoch: 53
2023-01-04 08:39:57,677 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41198930342992146, 'Total loss': 0.41198930342992146} | train loss {'Reaction outcome loss': 0.3245419667753981, 'Total loss': 0.3245419667753981}
2023-01-04 08:39:57,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:57,678 INFO:     Epoch: 54
2023-01-04 08:39:59,220 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41665530304114023, 'Total loss': 0.41665530304114023} | train loss {'Reaction outcome loss': 0.32582631619858654, 'Total loss': 0.32582631619858654}
2023-01-04 08:39:59,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:39:59,220 INFO:     Epoch: 55
2023-01-04 08:40:00,760 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4385241448879242, 'Total loss': 0.4385241448879242} | train loss {'Reaction outcome loss': 0.3191314616100692, 'Total loss': 0.3191314616100692}
2023-01-04 08:40:00,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:00,760 INFO:     Epoch: 56
2023-01-04 08:40:02,297 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41053900917371117, 'Total loss': 0.41053900917371117} | train loss {'Reaction outcome loss': 0.31724701870928756, 'Total loss': 0.31724701870928756}
2023-01-04 08:40:02,299 INFO:     Found new best model at epoch 56
2023-01-04 08:40:02,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:02,299 INFO:     Epoch: 57
2023-01-04 08:40:03,791 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4040353526671728, 'Total loss': 0.4040353526671728} | train loss {'Reaction outcome loss': 0.31591326546865506, 'Total loss': 0.31591326546865506}
2023-01-04 08:40:03,792 INFO:     Found new best model at epoch 57
2023-01-04 08:40:03,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:03,792 INFO:     Epoch: 58
2023-01-04 08:40:05,294 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43277536034584047, 'Total loss': 0.43277536034584047} | train loss {'Reaction outcome loss': 0.3162543194798323, 'Total loss': 0.3162543194798323}
2023-01-04 08:40:05,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:05,294 INFO:     Epoch: 59
2023-01-04 08:40:06,832 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4146041830380758, 'Total loss': 0.4146041830380758} | train loss {'Reaction outcome loss': 0.3142629917779248, 'Total loss': 0.3142629917779248}
2023-01-04 08:40:06,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:06,833 INFO:     Epoch: 60
2023-01-04 08:40:08,378 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.432445161541303, 'Total loss': 0.432445161541303} | train loss {'Reaction outcome loss': 0.3085513717252693, 'Total loss': 0.3085513717252693}
2023-01-04 08:40:08,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:08,378 INFO:     Epoch: 61
2023-01-04 08:40:09,910 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4401093751192093, 'Total loss': 0.4401093751192093} | train loss {'Reaction outcome loss': 0.30832085684760585, 'Total loss': 0.30832085684760585}
2023-01-04 08:40:09,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:09,911 INFO:     Epoch: 62
2023-01-04 08:40:11,446 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.411122386654218, 'Total loss': 0.411122386654218} | train loss {'Reaction outcome loss': 0.3052213124848984, 'Total loss': 0.3052213124848984}
2023-01-04 08:40:11,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:11,447 INFO:     Epoch: 63
2023-01-04 08:40:12,949 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4455675264199575, 'Total loss': 0.4455675264199575} | train loss {'Reaction outcome loss': 0.30521003839188005, 'Total loss': 0.30521003839188005}
2023-01-04 08:40:12,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:12,949 INFO:     Epoch: 64
2023-01-04 08:40:14,446 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43114257951577506, 'Total loss': 0.43114257951577506} | train loss {'Reaction outcome loss': 0.30828071904160603, 'Total loss': 0.30828071904160603}
2023-01-04 08:40:14,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:14,446 INFO:     Epoch: 65
2023-01-04 08:40:15,989 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4325588603814443, 'Total loss': 0.4325588603814443} | train loss {'Reaction outcome loss': 0.2963720325094003, 'Total loss': 0.2963720325094003}
2023-01-04 08:40:15,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:15,991 INFO:     Epoch: 66
2023-01-04 08:40:17,528 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4141073678930601, 'Total loss': 0.4141073678930601} | train loss {'Reaction outcome loss': 0.3002791682824547, 'Total loss': 0.3002791682824547}
2023-01-04 08:40:17,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:17,528 INFO:     Epoch: 67
2023-01-04 08:40:19,068 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4686156431833903, 'Total loss': 0.4686156431833903} | train loss {'Reaction outcome loss': 0.2972938658553602, 'Total loss': 0.2972938658553602}
2023-01-04 08:40:19,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:19,068 INFO:     Epoch: 68
2023-01-04 08:40:20,623 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4345534880956014, 'Total loss': 0.4345534880956014} | train loss {'Reaction outcome loss': 0.2995731701371652, 'Total loss': 0.2995731701371652}
2023-01-04 08:40:20,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:20,625 INFO:     Epoch: 69
2023-01-04 08:40:22,120 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.411095929145813, 'Total loss': 0.411095929145813} | train loss {'Reaction outcome loss': 0.2954447259068926, 'Total loss': 0.2954447259068926}
2023-01-04 08:40:22,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:22,120 INFO:     Epoch: 70
2023-01-04 08:40:23,696 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42577990094820656, 'Total loss': 0.42577990094820656} | train loss {'Reaction outcome loss': 0.2945630531553384, 'Total loss': 0.2945630531553384}
2023-01-04 08:40:23,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:23,696 INFO:     Epoch: 71
2023-01-04 08:40:25,310 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4418920079867045, 'Total loss': 0.4418920079867045} | train loss {'Reaction outcome loss': 0.29321044800809887, 'Total loss': 0.29321044800809887}
2023-01-04 08:40:25,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:25,310 INFO:     Epoch: 72
2023-01-04 08:40:26,903 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4477572004000346, 'Total loss': 0.4477572004000346} | train loss {'Reaction outcome loss': 0.2933989520092587, 'Total loss': 0.2933989520092587}
2023-01-04 08:40:26,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:26,905 INFO:     Epoch: 73
2023-01-04 08:40:28,508 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42167290647824607, 'Total loss': 0.42167290647824607} | train loss {'Reaction outcome loss': 0.28792365104123785, 'Total loss': 0.28792365104123785}
2023-01-04 08:40:28,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:28,508 INFO:     Epoch: 74
2023-01-04 08:40:30,112 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44414939085642496, 'Total loss': 0.44414939085642496} | train loss {'Reaction outcome loss': 0.29168915054027417, 'Total loss': 0.29168915054027417}
2023-01-04 08:40:30,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:30,112 INFO:     Epoch: 75
2023-01-04 08:40:31,627 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43729833960533143, 'Total loss': 0.43729833960533143} | train loss {'Reaction outcome loss': 0.2875819058863671, 'Total loss': 0.2875819058863671}
2023-01-04 08:40:31,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:31,628 INFO:     Epoch: 76
2023-01-04 08:40:33,224 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43013003170490266, 'Total loss': 0.43013003170490266} | train loss {'Reaction outcome loss': 0.28590484264719507, 'Total loss': 0.28590484264719507}
2023-01-04 08:40:33,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:33,225 INFO:     Epoch: 77
2023-01-04 08:40:34,825 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.423371359705925, 'Total loss': 0.423371359705925} | train loss {'Reaction outcome loss': 0.29280687481055767, 'Total loss': 0.29280687481055767}
2023-01-04 08:40:34,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:34,825 INFO:     Epoch: 78
2023-01-04 08:40:36,434 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3951877464850744, 'Total loss': 0.3951877464850744} | train loss {'Reaction outcome loss': 0.28162620239805825, 'Total loss': 0.28162620239805825}
2023-01-04 08:40:36,434 INFO:     Found new best model at epoch 78
2023-01-04 08:40:36,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:36,434 INFO:     Epoch: 79
2023-01-04 08:40:38,035 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4607532093922297, 'Total loss': 0.4607532093922297} | train loss {'Reaction outcome loss': 0.28074679701101213, 'Total loss': 0.28074679701101213}
2023-01-04 08:40:38,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:38,036 INFO:     Epoch: 80
2023-01-04 08:40:39,637 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4184005777041117, 'Total loss': 0.4184005777041117} | train loss {'Reaction outcome loss': 0.2804910111967679, 'Total loss': 0.2804910111967679}
2023-01-04 08:40:39,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:39,638 INFO:     Epoch: 81
2023-01-04 08:40:41,158 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4325206995010376, 'Total loss': 0.4325206995010376} | train loss {'Reaction outcome loss': 0.2790885681880044, 'Total loss': 0.2790885681880044}
2023-01-04 08:40:41,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:41,158 INFO:     Epoch: 82
2023-01-04 08:40:42,763 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4244445045789083, 'Total loss': 0.4244445045789083} | train loss {'Reaction outcome loss': 0.2819626712864572, 'Total loss': 0.2819626712864572}
2023-01-04 08:40:42,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:42,763 INFO:     Epoch: 83
2023-01-04 08:40:44,366 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4262455781300863, 'Total loss': 0.4262455781300863} | train loss {'Reaction outcome loss': 0.28595047113877947, 'Total loss': 0.28595047113877947}
2023-01-04 08:40:44,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:44,366 INFO:     Epoch: 84
2023-01-04 08:40:45,980 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4237187763055166, 'Total loss': 0.4237187763055166} | train loss {'Reaction outcome loss': 0.2799890938423055, 'Total loss': 0.2799890938423055}
2023-01-04 08:40:45,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:45,981 INFO:     Epoch: 85
2023-01-04 08:40:47,583 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4315935472647349, 'Total loss': 0.4315935472647349} | train loss {'Reaction outcome loss': 0.281221020925831, 'Total loss': 0.281221020925831}
2023-01-04 08:40:47,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:47,583 INFO:     Epoch: 86
2023-01-04 08:40:49,198 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4243946671485901, 'Total loss': 0.4243946671485901} | train loss {'Reaction outcome loss': 0.2762190103257969, 'Total loss': 0.2762190103257969}
2023-01-04 08:40:49,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:49,198 INFO:     Epoch: 87
2023-01-04 08:40:50,682 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42278436621030174, 'Total loss': 0.42278436621030174} | train loss {'Reaction outcome loss': 0.2723861064611774, 'Total loss': 0.2723861064611774}
2023-01-04 08:40:50,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:50,682 INFO:     Epoch: 88
2023-01-04 08:40:52,290 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4774237076441447, 'Total loss': 0.4774237076441447} | train loss {'Reaction outcome loss': 0.27350831849179863, 'Total loss': 0.27350831849179863}
2023-01-04 08:40:52,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:52,292 INFO:     Epoch: 89
2023-01-04 08:40:53,901 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.438041885693868, 'Total loss': 0.438041885693868} | train loss {'Reaction outcome loss': 0.27133565208782534, 'Total loss': 0.27133565208782534}
2023-01-04 08:40:53,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:53,902 INFO:     Epoch: 90
2023-01-04 08:40:55,513 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4326087315877279, 'Total loss': 0.4326087315877279} | train loss {'Reaction outcome loss': 0.2732113705122427, 'Total loss': 0.2732113705122427}
2023-01-04 08:40:55,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:55,513 INFO:     Epoch: 91
2023-01-04 08:40:57,113 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.425607426961263, 'Total loss': 0.425607426961263} | train loss {'Reaction outcome loss': 0.27202888256136754, 'Total loss': 0.27202888256136754}
2023-01-04 08:40:57,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:57,113 INFO:     Epoch: 92
2023-01-04 08:40:58,702 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4048296883702278, 'Total loss': 0.4048296883702278} | train loss {'Reaction outcome loss': 0.2666668908827471, 'Total loss': 0.2666668908827471}
2023-01-04 08:40:58,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:40:58,703 INFO:     Epoch: 93
2023-01-04 08:41:00,249 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46368858218193054, 'Total loss': 0.46368858218193054} | train loss {'Reaction outcome loss': 0.26891909497397726, 'Total loss': 0.26891909497397726}
2023-01-04 08:41:00,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:00,250 INFO:     Epoch: 94
2023-01-04 08:41:01,858 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4252758880456289, 'Total loss': 0.4252758880456289} | train loss {'Reaction outcome loss': 0.2691147327627782, 'Total loss': 0.2691147327627782}
2023-01-04 08:41:01,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:01,858 INFO:     Epoch: 95
2023-01-04 08:41:03,460 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.445309857527415, 'Total loss': 0.445309857527415} | train loss {'Reaction outcome loss': 0.2665922252031473, 'Total loss': 0.2665922252031473}
2023-01-04 08:41:03,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:03,460 INFO:     Epoch: 96
2023-01-04 08:41:05,066 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.442562136054039, 'Total loss': 0.442562136054039} | train loss {'Reaction outcome loss': 0.26664837144124204, 'Total loss': 0.26664837144124204}
2023-01-04 08:41:05,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:05,067 INFO:     Epoch: 97
2023-01-04 08:41:06,660 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43784695367018384, 'Total loss': 0.43784695367018384} | train loss {'Reaction outcome loss': 0.2637307881872296, 'Total loss': 0.2637307881872296}
2023-01-04 08:41:06,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:06,660 INFO:     Epoch: 98
2023-01-04 08:41:08,217 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43216212193171183, 'Total loss': 0.43216212193171183} | train loss {'Reaction outcome loss': 0.26018051764903927, 'Total loss': 0.26018051764903927}
2023-01-04 08:41:08,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:08,217 INFO:     Epoch: 99
2023-01-04 08:41:09,767 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3981858015060425, 'Total loss': 0.3981858015060425} | train loss {'Reaction outcome loss': 0.26257116722809526, 'Total loss': 0.26257116722809526}
2023-01-04 08:41:09,767 INFO:     Best model found after epoch 79 of 100.
2023-01-04 08:41:09,767 INFO:   Done with stage: TRAINING
2023-01-04 08:41:09,767 INFO:   Starting stage: EVALUATION
2023-01-04 08:41:09,928 INFO:   Done with stage: EVALUATION
2023-01-04 08:41:09,928 INFO:   Leaving out SEQ value Fold_1
2023-01-04 08:41:09,942 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 08:41:09,942 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:41:10,631 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:41:10,632 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:41:10,708 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:41:10,708 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:41:10,708 INFO:     No hyperparam tuning for this model
2023-01-04 08:41:10,708 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:41:10,708 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:41:10,709 INFO:     None feature selector for col prot
2023-01-04 08:41:10,709 INFO:     None feature selector for col prot
2023-01-04 08:41:10,709 INFO:     None feature selector for col prot
2023-01-04 08:41:10,710 INFO:     None feature selector for col chem
2023-01-04 08:41:10,710 INFO:     None feature selector for col chem
2023-01-04 08:41:10,710 INFO:     None feature selector for col chem
2023-01-04 08:41:10,710 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:41:10,710 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:41:10,711 INFO:     Number of params in model 70111
2023-01-04 08:41:10,715 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:41:10,715 INFO:   Starting stage: TRAINING
2023-01-04 08:41:10,759 INFO:     Val loss before train {'Reaction outcome loss': 1.0473184982935588, 'Total loss': 1.0473184982935588}
2023-01-04 08:41:10,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:10,760 INFO:     Epoch: 0
2023-01-04 08:41:12,358 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7911989887555441, 'Total loss': 0.7911989887555441} | train loss {'Reaction outcome loss': 0.8623571630812039, 'Total loss': 0.8623571630812039}
2023-01-04 08:41:12,358 INFO:     Found new best model at epoch 0
2023-01-04 08:41:12,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:12,360 INFO:     Epoch: 1
2023-01-04 08:41:13,960 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.647575615843137, 'Total loss': 0.647575615843137} | train loss {'Reaction outcome loss': 0.7145255029636578, 'Total loss': 0.7145255029636578}
2023-01-04 08:41:13,960 INFO:     Found new best model at epoch 1
2023-01-04 08:41:13,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:13,961 INFO:     Epoch: 2
2023-01-04 08:41:15,527 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.584240984916687, 'Total loss': 0.584240984916687} | train loss {'Reaction outcome loss': 0.6038247228321367, 'Total loss': 0.6038247228321367}
2023-01-04 08:41:15,527 INFO:     Found new best model at epoch 2
2023-01-04 08:41:15,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:15,527 INFO:     Epoch: 3
2023-01-04 08:41:17,030 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5526367783546448, 'Total loss': 0.5526367783546448} | train loss {'Reaction outcome loss': 0.5588769250325043, 'Total loss': 0.5588769250325043}
2023-01-04 08:41:17,030 INFO:     Found new best model at epoch 3
2023-01-04 08:41:17,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:17,031 INFO:     Epoch: 4
2023-01-04 08:41:18,551 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5358807543913523, 'Total loss': 0.5358807543913523} | train loss {'Reaction outcome loss': 0.5330947336815569, 'Total loss': 0.5330947336815569}
2023-01-04 08:41:18,552 INFO:     Found new best model at epoch 4
2023-01-04 08:41:18,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:18,553 INFO:     Epoch: 5
2023-01-04 08:41:20,121 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5555961648623149, 'Total loss': 0.5555961648623149} | train loss {'Reaction outcome loss': 0.5164862180495784, 'Total loss': 0.5164862180495784}
2023-01-04 08:41:20,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:20,121 INFO:     Epoch: 6
2023-01-04 08:41:21,691 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.546701192855835, 'Total loss': 0.546701192855835} | train loss {'Reaction outcome loss': 0.5000610080187338, 'Total loss': 0.5000610080187338}
2023-01-04 08:41:21,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:21,691 INFO:     Epoch: 7
2023-01-04 08:41:23,242 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5179676045974095, 'Total loss': 0.5179676045974095} | train loss {'Reaction outcome loss': 0.4929059622605352, 'Total loss': 0.4929059622605352}
2023-01-04 08:41:23,242 INFO:     Found new best model at epoch 7
2023-01-04 08:41:23,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:23,243 INFO:     Epoch: 8
2023-01-04 08:41:24,797 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4999563038349152, 'Total loss': 0.4999563038349152} | train loss {'Reaction outcome loss': 0.4861740182242254, 'Total loss': 0.4861740182242254}
2023-01-04 08:41:24,797 INFO:     Found new best model at epoch 8
2023-01-04 08:41:24,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:24,798 INFO:     Epoch: 9
2023-01-04 08:41:26,307 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.507471098502477, 'Total loss': 0.507471098502477} | train loss {'Reaction outcome loss': 0.4775339918088739, 'Total loss': 0.4775339918088739}
2023-01-04 08:41:26,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:26,312 INFO:     Epoch: 10
2023-01-04 08:41:27,828 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5084629535675049, 'Total loss': 0.5084629535675049} | train loss {'Reaction outcome loss': 0.46859801092939657, 'Total loss': 0.46859801092939657}
2023-01-04 08:41:27,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:27,828 INFO:     Epoch: 11
2023-01-04 08:41:29,397 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5144315580526988, 'Total loss': 0.5144315580526988} | train loss {'Reaction outcome loss': 0.4652537274969755, 'Total loss': 0.4652537274969755}
2023-01-04 08:41:29,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:29,398 INFO:     Epoch: 12
2023-01-04 08:41:30,966 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4851198554039001, 'Total loss': 0.4851198554039001} | train loss {'Reaction outcome loss': 0.45947952448886675, 'Total loss': 0.45947952448886675}
2023-01-04 08:41:30,966 INFO:     Found new best model at epoch 12
2023-01-04 08:41:30,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:30,967 INFO:     Epoch: 13
2023-01-04 08:41:32,546 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5021831274032593, 'Total loss': 0.5021831274032593} | train loss {'Reaction outcome loss': 0.4561457593184318, 'Total loss': 0.4561457593184318}
2023-01-04 08:41:32,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:32,546 INFO:     Epoch: 14
2023-01-04 08:41:34,130 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4956120838721593, 'Total loss': 0.4956120838721593} | train loss {'Reaction outcome loss': 0.44878034935380423, 'Total loss': 0.44878034935380423}
2023-01-04 08:41:34,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:34,130 INFO:     Epoch: 15
2023-01-04 08:41:35,675 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4854282756646474, 'Total loss': 0.4854282756646474} | train loss {'Reaction outcome loss': 0.4454376011760566, 'Total loss': 0.4454376011760566}
2023-01-04 08:41:35,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:35,676 INFO:     Epoch: 16
2023-01-04 08:41:37,199 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49012948175271354, 'Total loss': 0.49012948175271354} | train loss {'Reaction outcome loss': 0.4372229224791492, 'Total loss': 0.4372229224791492}
2023-01-04 08:41:37,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:37,200 INFO:     Epoch: 17
2023-01-04 08:41:38,742 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4969554841518402, 'Total loss': 0.4969554841518402} | train loss {'Reaction outcome loss': 0.4316530107472935, 'Total loss': 0.4316530107472935}
2023-01-04 08:41:38,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:38,742 INFO:     Epoch: 18
2023-01-04 08:41:40,297 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4740381499131521, 'Total loss': 0.4740381499131521} | train loss {'Reaction outcome loss': 0.43138111921122474, 'Total loss': 0.43138111921122474}
2023-01-04 08:41:40,298 INFO:     Found new best model at epoch 18
2023-01-04 08:41:40,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:40,298 INFO:     Epoch: 19
2023-01-04 08:41:41,846 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4869246115287145, 'Total loss': 0.4869246115287145} | train loss {'Reaction outcome loss': 0.42760491626758645, 'Total loss': 0.42760491626758645}
2023-01-04 08:41:41,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:41,846 INFO:     Epoch: 20
2023-01-04 08:41:43,408 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4949182689189911, 'Total loss': 0.4949182689189911} | train loss {'Reaction outcome loss': 0.4214131369044746, 'Total loss': 0.4214131369044746}
2023-01-04 08:41:43,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:43,408 INFO:     Epoch: 21
2023-01-04 08:41:44,927 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48361991842587787, 'Total loss': 0.48361991842587787} | train loss {'Reaction outcome loss': 0.4151298683816499, 'Total loss': 0.4151298683816499}
2023-01-04 08:41:44,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:44,927 INFO:     Epoch: 22
2023-01-04 08:41:46,022 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4632827818393707, 'Total loss': 0.4632827818393707} | train loss {'Reaction outcome loss': 0.41434044793356944, 'Total loss': 0.41434044793356944}
2023-01-04 08:41:46,022 INFO:     Found new best model at epoch 22
2023-01-04 08:41:46,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:46,023 INFO:     Epoch: 23
2023-01-04 08:41:47,055 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4893055280049642, 'Total loss': 0.4893055280049642} | train loss {'Reaction outcome loss': 0.4100751110019475, 'Total loss': 0.4100751110019475}
2023-01-04 08:41:47,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:47,055 INFO:     Epoch: 24
2023-01-04 08:41:48,088 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4885283291339874, 'Total loss': 0.4885283291339874} | train loss {'Reaction outcome loss': 0.40455324300666795, 'Total loss': 0.40455324300666795}
2023-01-04 08:41:48,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:48,089 INFO:     Epoch: 25
2023-01-04 08:41:49,114 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4578265160322189, 'Total loss': 0.4578265160322189} | train loss {'Reaction outcome loss': 0.40077740243588483, 'Total loss': 0.40077740243588483}
2023-01-04 08:41:49,114 INFO:     Found new best model at epoch 25
2023-01-04 08:41:49,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:49,115 INFO:     Epoch: 26
2023-01-04 08:41:50,606 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46124304135640465, 'Total loss': 0.46124304135640465} | train loss {'Reaction outcome loss': 0.40050752189037575, 'Total loss': 0.40050752189037575}
2023-01-04 08:41:50,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:50,606 INFO:     Epoch: 27
2023-01-04 08:41:52,109 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46294694344202675, 'Total loss': 0.46294694344202675} | train loss {'Reaction outcome loss': 0.3935861750403895, 'Total loss': 0.3935861750403895}
2023-01-04 08:41:52,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:52,109 INFO:     Epoch: 28
2023-01-04 08:41:53,638 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46077618102232615, 'Total loss': 0.46077618102232615} | train loss {'Reaction outcome loss': 0.3927467974433064, 'Total loss': 0.3927467974433064}
2023-01-04 08:41:53,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:53,639 INFO:     Epoch: 29
2023-01-04 08:41:55,181 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44462668100992836, 'Total loss': 0.44462668100992836} | train loss {'Reaction outcome loss': 0.3904918400965033, 'Total loss': 0.3904918400965033}
2023-01-04 08:41:55,181 INFO:     Found new best model at epoch 29
2023-01-04 08:41:55,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:55,182 INFO:     Epoch: 30
2023-01-04 08:41:56,709 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.474979555606842, 'Total loss': 0.474979555606842} | train loss {'Reaction outcome loss': 0.3847111693318308, 'Total loss': 0.3847111693318308}
2023-01-04 08:41:56,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:56,710 INFO:     Epoch: 31
2023-01-04 08:41:58,236 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4356206605831782, 'Total loss': 0.4356206605831782} | train loss {'Reaction outcome loss': 0.38203141599023427, 'Total loss': 0.38203141599023427}
2023-01-04 08:41:58,236 INFO:     Found new best model at epoch 31
2023-01-04 08:41:58,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:58,237 INFO:     Epoch: 32
2023-01-04 08:41:59,760 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4373243818680445, 'Total loss': 0.4373243818680445} | train loss {'Reaction outcome loss': 0.38057362598224276, 'Total loss': 0.38057362598224276}
2023-01-04 08:41:59,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:41:59,760 INFO:     Epoch: 33
2023-01-04 08:42:01,284 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4521864453951518, 'Total loss': 0.4521864453951518} | train loss {'Reaction outcome loss': 0.37445021159675, 'Total loss': 0.37445021159675}
2023-01-04 08:42:01,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:01,285 INFO:     Epoch: 34
2023-01-04 08:42:02,820 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46431277791659037, 'Total loss': 0.46431277791659037} | train loss {'Reaction outcome loss': 0.36972030605712947, 'Total loss': 0.36972030605712947}
2023-01-04 08:42:02,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:02,820 INFO:     Epoch: 35
2023-01-04 08:42:04,355 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44388821522394817, 'Total loss': 0.44388821522394817} | train loss {'Reaction outcome loss': 0.36707066608606465, 'Total loss': 0.36707066608606465}
2023-01-04 08:42:04,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:04,356 INFO:     Epoch: 36
2023-01-04 08:42:05,897 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4316374679406484, 'Total loss': 0.4316374679406484} | train loss {'Reaction outcome loss': 0.36558597398935444, 'Total loss': 0.36558597398935444}
2023-01-04 08:42:05,898 INFO:     Found new best model at epoch 36
2023-01-04 08:42:05,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:05,898 INFO:     Epoch: 37
2023-01-04 08:42:07,428 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4484375854333242, 'Total loss': 0.4484375854333242} | train loss {'Reaction outcome loss': 0.361902605497489, 'Total loss': 0.361902605497489}
2023-01-04 08:42:07,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:07,429 INFO:     Epoch: 38
2023-01-04 08:42:08,930 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4521451681852341, 'Total loss': 0.4521451681852341} | train loss {'Reaction outcome loss': 0.3599180813851583, 'Total loss': 0.3599180813851583}
2023-01-04 08:42:08,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:08,930 INFO:     Epoch: 39
2023-01-04 08:42:10,467 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48650556008021034, 'Total loss': 0.48650556008021034} | train loss {'Reaction outcome loss': 0.3560370543468608, 'Total loss': 0.3560370543468608}
2023-01-04 08:42:10,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:10,467 INFO:     Epoch: 40
2023-01-04 08:42:12,004 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4458911796410879, 'Total loss': 0.4458911796410879} | train loss {'Reaction outcome loss': 0.353507666012449, 'Total loss': 0.353507666012449}
2023-01-04 08:42:12,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:12,004 INFO:     Epoch: 41
2023-01-04 08:42:13,556 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44312931001186373, 'Total loss': 0.44312931001186373} | train loss {'Reaction outcome loss': 0.3486164188841834, 'Total loss': 0.3486164188841834}
2023-01-04 08:42:13,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:13,556 INFO:     Epoch: 42
2023-01-04 08:42:15,083 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4492771635452906, 'Total loss': 0.4492771635452906} | train loss {'Reaction outcome loss': 0.3491426471104152, 'Total loss': 0.3491426471104152}
2023-01-04 08:42:15,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:15,083 INFO:     Epoch: 43
2023-01-04 08:42:16,587 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4495515604813894, 'Total loss': 0.4495515604813894} | train loss {'Reaction outcome loss': 0.3484008167564434, 'Total loss': 0.3484008167564434}
2023-01-04 08:42:16,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:16,587 INFO:     Epoch: 44
2023-01-04 08:42:18,100 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4240439693133036, 'Total loss': 0.4240439693133036} | train loss {'Reaction outcome loss': 0.34486987534230645, 'Total loss': 0.34486987534230645}
2023-01-04 08:42:18,100 INFO:     Found new best model at epoch 44
2023-01-04 08:42:18,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:18,101 INFO:     Epoch: 45
2023-01-04 08:42:19,654 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44126279950141906, 'Total loss': 0.44126279950141906} | train loss {'Reaction outcome loss': 0.34048982358870716, 'Total loss': 0.34048982358870716}
2023-01-04 08:42:19,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:19,655 INFO:     Epoch: 46
2023-01-04 08:42:21,196 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4332819918791453, 'Total loss': 0.4332819918791453} | train loss {'Reaction outcome loss': 0.3351609266369882, 'Total loss': 0.3351609266369882}
2023-01-04 08:42:21,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:21,196 INFO:     Epoch: 47
2023-01-04 08:42:22,747 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46463780601819354, 'Total loss': 0.46463780601819354} | train loss {'Reaction outcome loss': 0.3384805788850262, 'Total loss': 0.3384805788850262}
2023-01-04 08:42:22,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:22,748 INFO:     Epoch: 48
2023-01-04 08:42:24,288 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4312709838151932, 'Total loss': 0.4312709838151932} | train loss {'Reaction outcome loss': 0.33252590421560035, 'Total loss': 0.33252590421560035}
2023-01-04 08:42:24,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:24,288 INFO:     Epoch: 49
2023-01-04 08:42:25,797 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4730844547351201, 'Total loss': 0.4730844547351201} | train loss {'Reaction outcome loss': 0.3314269244616484, 'Total loss': 0.3314269244616484}
2023-01-04 08:42:25,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:25,797 INFO:     Epoch: 50
2023-01-04 08:42:27,311 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4344868799050649, 'Total loss': 0.4344868799050649} | train loss {'Reaction outcome loss': 0.329635187412483, 'Total loss': 0.329635187412483}
2023-01-04 08:42:27,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:27,311 INFO:     Epoch: 51
2023-01-04 08:42:28,865 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4608856201171875, 'Total loss': 0.4608856201171875} | train loss {'Reaction outcome loss': 0.32963394751622727, 'Total loss': 0.32963394751622727}
2023-01-04 08:42:28,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:28,865 INFO:     Epoch: 52
2023-01-04 08:42:30,419 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4780064622561137, 'Total loss': 0.4780064622561137} | train loss {'Reaction outcome loss': 0.32652905322339415, 'Total loss': 0.32652905322339415}
2023-01-04 08:42:30,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:30,419 INFO:     Epoch: 53
2023-01-04 08:42:31,983 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44230906168619794, 'Total loss': 0.44230906168619794} | train loss {'Reaction outcome loss': 0.3204057244651944, 'Total loss': 0.3204057244651944}
2023-01-04 08:42:31,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:31,983 INFO:     Epoch: 54
2023-01-04 08:42:33,552 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4491743584473928, 'Total loss': 0.4491743584473928} | train loss {'Reaction outcome loss': 0.32203005107432386, 'Total loss': 0.32203005107432386}
2023-01-04 08:42:33,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:33,552 INFO:     Epoch: 55
2023-01-04 08:42:35,086 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43485024670759836, 'Total loss': 0.43485024670759836} | train loss {'Reaction outcome loss': 0.3163939010433472, 'Total loss': 0.3163939010433472}
2023-01-04 08:42:35,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:35,087 INFO:     Epoch: 56
2023-01-04 08:42:36,629 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4484905779361725, 'Total loss': 0.4484905779361725} | train loss {'Reaction outcome loss': 0.3192444209580439, 'Total loss': 0.3192444209580439}
2023-01-04 08:42:36,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:36,631 INFO:     Epoch: 57
2023-01-04 08:42:38,210 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4625749131043752, 'Total loss': 0.4625749131043752} | train loss {'Reaction outcome loss': 0.31431055860254015, 'Total loss': 0.31431055860254015}
2023-01-04 08:42:38,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:38,210 INFO:     Epoch: 58
2023-01-04 08:42:39,782 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4308476557334264, 'Total loss': 0.4308476557334264} | train loss {'Reaction outcome loss': 0.3094915674768225, 'Total loss': 0.3094915674768225}
2023-01-04 08:42:39,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:39,782 INFO:     Epoch: 59
2023-01-04 08:42:41,356 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4517541577418645, 'Total loss': 0.4517541577418645} | train loss {'Reaction outcome loss': 0.3090194455572288, 'Total loss': 0.3090194455572288}
2023-01-04 08:42:41,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:41,356 INFO:     Epoch: 60
2023-01-04 08:42:42,922 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4338709314664205, 'Total loss': 0.4338709314664205} | train loss {'Reaction outcome loss': 0.31202279159078633, 'Total loss': 0.31202279159078633}
2023-01-04 08:42:42,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:42,923 INFO:     Epoch: 61
2023-01-04 08:42:44,464 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45037876069545746, 'Total loss': 0.45037876069545746} | train loss {'Reaction outcome loss': 0.31364309779592675, 'Total loss': 0.31364309779592675}
2023-01-04 08:42:44,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:44,464 INFO:     Epoch: 62
2023-01-04 08:42:46,006 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4337059736251831, 'Total loss': 0.4337059736251831} | train loss {'Reaction outcome loss': 0.30377492531590217, 'Total loss': 0.30377492531590217}
2023-01-04 08:42:46,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:46,006 INFO:     Epoch: 63
2023-01-04 08:42:47,587 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4384751598040263, 'Total loss': 0.4384751598040263} | train loss {'Reaction outcome loss': 0.3047504852233577, 'Total loss': 0.3047504852233577}
2023-01-04 08:42:47,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:47,588 INFO:     Epoch: 64
2023-01-04 08:42:49,147 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41993128061294555, 'Total loss': 0.41993128061294555} | train loss {'Reaction outcome loss': 0.3037878202859068, 'Total loss': 0.3037878202859068}
2023-01-04 08:42:49,147 INFO:     Found new best model at epoch 64
2023-01-04 08:42:49,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:49,148 INFO:     Epoch: 65
2023-01-04 08:42:50,721 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4447352051734924, 'Total loss': 0.4447352051734924} | train loss {'Reaction outcome loss': 0.3046782679964591, 'Total loss': 0.3046782679964591}
2023-01-04 08:42:50,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:50,721 INFO:     Epoch: 66
2023-01-04 08:42:52,286 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42332282463709514, 'Total loss': 0.42332282463709514} | train loss {'Reaction outcome loss': 0.2972040885012515, 'Total loss': 0.2972040885012515}
2023-01-04 08:42:52,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:52,286 INFO:     Epoch: 67
2023-01-04 08:42:53,815 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.443703430891037, 'Total loss': 0.443703430891037} | train loss {'Reaction outcome loss': 0.29927144591173116, 'Total loss': 0.29927144591173116}
2023-01-04 08:42:53,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:53,815 INFO:     Epoch: 68
2023-01-04 08:42:55,336 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46025174458821616, 'Total loss': 0.46025174458821616} | train loss {'Reaction outcome loss': 0.29638782853301426, 'Total loss': 0.29638782853301426}
2023-01-04 08:42:55,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:55,337 INFO:     Epoch: 69
2023-01-04 08:42:56,882 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45435856928428014, 'Total loss': 0.45435856928428014} | train loss {'Reaction outcome loss': 0.2955714446784806, 'Total loss': 0.2955714446784806}
2023-01-04 08:42:56,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:56,883 INFO:     Epoch: 70
2023-01-04 08:42:58,432 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4525379826625188, 'Total loss': 0.4525379826625188} | train loss {'Reaction outcome loss': 0.29385505158481373, 'Total loss': 0.29385505158481373}
2023-01-04 08:42:58,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:42:58,432 INFO:     Epoch: 71
2023-01-04 08:43:00,018 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4298080454270045, 'Total loss': 0.4298080454270045} | train loss {'Reaction outcome loss': 0.29550504148767814, 'Total loss': 0.29550504148767814}
2023-01-04 08:43:00,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:00,018 INFO:     Epoch: 72
2023-01-04 08:43:01,588 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4638244827588399, 'Total loss': 0.4638244827588399} | train loss {'Reaction outcome loss': 0.28921951949052566, 'Total loss': 0.28921951949052566}
2023-01-04 08:43:01,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:01,589 INFO:     Epoch: 73
2023-01-04 08:43:03,100 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4692534645398458, 'Total loss': 0.4692534645398458} | train loss {'Reaction outcome loss': 0.29029321681408987, 'Total loss': 0.29029321681408987}
2023-01-04 08:43:03,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:03,100 INFO:     Epoch: 74
2023-01-04 08:43:04,639 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4617003083229065, 'Total loss': 0.4617003083229065} | train loss {'Reaction outcome loss': 0.2839524630375587, 'Total loss': 0.2839524630375587}
2023-01-04 08:43:04,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:04,640 INFO:     Epoch: 75
2023-01-04 08:43:06,202 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4423437794049581, 'Total loss': 0.4423437794049581} | train loss {'Reaction outcome loss': 0.28601065819172095, 'Total loss': 0.28601065819172095}
2023-01-04 08:43:06,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:06,203 INFO:     Epoch: 76
2023-01-04 08:43:07,753 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44132978320121763, 'Total loss': 0.44132978320121763} | train loss {'Reaction outcome loss': 0.28658892010359, 'Total loss': 0.28658892010359}
2023-01-04 08:43:07,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:07,755 INFO:     Epoch: 77
2023-01-04 08:43:09,311 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46612651546796163, 'Total loss': 0.46612651546796163} | train loss {'Reaction outcome loss': 0.28357272291977476, 'Total loss': 0.28357272291977476}
2023-01-04 08:43:09,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:09,311 INFO:     Epoch: 78
2023-01-04 08:43:10,855 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4487021744251251, 'Total loss': 0.4487021744251251} | train loss {'Reaction outcome loss': 0.28581852688841575, 'Total loss': 0.28581852688841575}
2023-01-04 08:43:10,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:10,855 INFO:     Epoch: 79
2023-01-04 08:43:12,382 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48300211628278095, 'Total loss': 0.48300211628278095} | train loss {'Reaction outcome loss': 0.28375546250791445, 'Total loss': 0.28375546250791445}
2023-01-04 08:43:12,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:12,383 INFO:     Epoch: 80
2023-01-04 08:43:13,942 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4480309178431829, 'Total loss': 0.4480309178431829} | train loss {'Reaction outcome loss': 0.2803521501376246, 'Total loss': 0.2803521501376246}
2023-01-04 08:43:13,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:13,943 INFO:     Epoch: 81
2023-01-04 08:43:15,508 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40864920715490977, 'Total loss': 0.40864920715490977} | train loss {'Reaction outcome loss': 0.28528128227178196, 'Total loss': 0.28528128227178196}
2023-01-04 08:43:15,508 INFO:     Found new best model at epoch 81
2023-01-04 08:43:15,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:15,509 INFO:     Epoch: 82
2023-01-04 08:43:17,103 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4493932286898295, 'Total loss': 0.4493932286898295} | train loss {'Reaction outcome loss': 0.2731826328094641, 'Total loss': 0.2731826328094641}
2023-01-04 08:43:17,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:17,103 INFO:     Epoch: 83
2023-01-04 08:43:18,681 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4738990863164266, 'Total loss': 0.4738990863164266} | train loss {'Reaction outcome loss': 0.2731811707553855, 'Total loss': 0.2731811707553855}
2023-01-04 08:43:18,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:18,682 INFO:     Epoch: 84
2023-01-04 08:43:20,216 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41806566417217256, 'Total loss': 0.41806566417217256} | train loss {'Reaction outcome loss': 0.2740425177897415, 'Total loss': 0.2740425177897415}
2023-01-04 08:43:20,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:20,216 INFO:     Epoch: 85
2023-01-04 08:43:21,757 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47341813643773395, 'Total loss': 0.47341813643773395} | train loss {'Reaction outcome loss': 0.27827489778508235, 'Total loss': 0.27827489778508235}
2023-01-04 08:43:21,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:21,757 INFO:     Epoch: 86
2023-01-04 08:43:23,327 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4614880005518595, 'Total loss': 0.4614880005518595} | train loss {'Reaction outcome loss': 0.27603356382490074, 'Total loss': 0.27603356382490074}
2023-01-04 08:43:23,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:23,327 INFO:     Epoch: 87
2023-01-04 08:43:24,910 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45549421310424804, 'Total loss': 0.45549421310424804} | train loss {'Reaction outcome loss': 0.27123789701366074, 'Total loss': 0.27123789701366074}
2023-01-04 08:43:24,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:24,910 INFO:     Epoch: 88
2023-01-04 08:43:26,482 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47306620081265766, 'Total loss': 0.47306620081265766} | train loss {'Reaction outcome loss': 0.27140696991207824, 'Total loss': 0.27140696991207824}
2023-01-04 08:43:26,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:26,483 INFO:     Epoch: 89
2023-01-04 08:43:28,054 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48432171245416006, 'Total loss': 0.48432171245416006} | train loss {'Reaction outcome loss': 0.2694459508893753, 'Total loss': 0.2694459508893753}
2023-01-04 08:43:28,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:28,054 INFO:     Epoch: 90
2023-01-04 08:43:29,598 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42821773886680603, 'Total loss': 0.42821773886680603} | train loss {'Reaction outcome loss': 0.2767385391749605, 'Total loss': 0.2767385391749605}
2023-01-04 08:43:29,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:29,599 INFO:     Epoch: 91
2023-01-04 08:43:31,146 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46947856148084005, 'Total loss': 0.46947856148084005} | train loss {'Reaction outcome loss': 0.26778949650317213, 'Total loss': 0.26778949650317213}
2023-01-04 08:43:31,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:31,147 INFO:     Epoch: 92
2023-01-04 08:43:32,724 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45491747856140136, 'Total loss': 0.45491747856140136} | train loss {'Reaction outcome loss': 0.2702534297059705, 'Total loss': 0.2702534297059705}
2023-01-04 08:43:32,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:32,724 INFO:     Epoch: 93
2023-01-04 08:43:34,304 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4719380815823873, 'Total loss': 0.4719380815823873} | train loss {'Reaction outcome loss': 0.268677270053512, 'Total loss': 0.268677270053512}
2023-01-04 08:43:34,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:34,304 INFO:     Epoch: 94
2023-01-04 08:43:35,885 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4739521563053131, 'Total loss': 0.4739521563053131} | train loss {'Reaction outcome loss': 0.26488798266671, 'Total loss': 0.26488798266671}
2023-01-04 08:43:35,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:35,885 INFO:     Epoch: 95
2023-01-04 08:43:37,455 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47483706176280976, 'Total loss': 0.47483706176280976} | train loss {'Reaction outcome loss': 0.26306794347227924, 'Total loss': 0.26306794347227924}
2023-01-04 08:43:37,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:37,455 INFO:     Epoch: 96
2023-01-04 08:43:38,980 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44793306092421215, 'Total loss': 0.44793306092421215} | train loss {'Reaction outcome loss': 0.2631219895896468, 'Total loss': 0.2631219895896468}
2023-01-04 08:43:38,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:38,980 INFO:     Epoch: 97
2023-01-04 08:43:40,514 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4611377239227295, 'Total loss': 0.4611377239227295} | train loss {'Reaction outcome loss': 0.26385151537774254, 'Total loss': 0.26385151537774254}
2023-01-04 08:43:40,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:40,515 INFO:     Epoch: 98
2023-01-04 08:43:42,077 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4664996385574341, 'Total loss': 0.4664996385574341} | train loss {'Reaction outcome loss': 0.26405051080034164, 'Total loss': 0.26405051080034164}
2023-01-04 08:43:42,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:42,077 INFO:     Epoch: 99
2023-01-04 08:43:43,642 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4528010368347168, 'Total loss': 0.4528010368347168} | train loss {'Reaction outcome loss': 0.26090246535511347, 'Total loss': 0.26090246535511347}
2023-01-04 08:43:43,643 INFO:     Best model found after epoch 82 of 100.
2023-01-04 08:43:43,643 INFO:   Done with stage: TRAINING
2023-01-04 08:43:43,643 INFO:   Starting stage: EVALUATION
2023-01-04 08:43:43,779 INFO:   Done with stage: EVALUATION
2023-01-04 08:43:43,779 INFO:   Leaving out SEQ value Fold_2
2023-01-04 08:43:43,791 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 08:43:43,791 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:43:44,438 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:43:44,438 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:43:44,506 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:43:44,506 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:43:44,506 INFO:     No hyperparam tuning for this model
2023-01-04 08:43:44,506 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:43:44,506 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:43:44,507 INFO:     None feature selector for col prot
2023-01-04 08:43:44,507 INFO:     None feature selector for col prot
2023-01-04 08:43:44,507 INFO:     None feature selector for col prot
2023-01-04 08:43:44,507 INFO:     None feature selector for col chem
2023-01-04 08:43:44,508 INFO:     None feature selector for col chem
2023-01-04 08:43:44,508 INFO:     None feature selector for col chem
2023-01-04 08:43:44,508 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:43:44,508 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:43:44,509 INFO:     Number of params in model 70111
2023-01-04 08:43:44,512 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:43:44,512 INFO:   Starting stage: TRAINING
2023-01-04 08:43:44,555 INFO:     Val loss before train {'Reaction outcome loss': 0.9961997270584106, 'Total loss': 0.9961997270584106}
2023-01-04 08:43:44,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:44,555 INFO:     Epoch: 0
2023-01-04 08:43:46,105 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7178671896457672, 'Total loss': 0.7178671896457672} | train loss {'Reaction outcome loss': 0.8229760073480152, 'Total loss': 0.8229760073480152}
2023-01-04 08:43:46,106 INFO:     Found new best model at epoch 0
2023-01-04 08:43:46,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:46,107 INFO:     Epoch: 1
2023-01-04 08:43:47,630 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5759568055470784, 'Total loss': 0.5759568055470784} | train loss {'Reaction outcome loss': 0.6552602559218913, 'Total loss': 0.6552602559218913}
2023-01-04 08:43:47,631 INFO:     Found new best model at epoch 1
2023-01-04 08:43:47,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:47,631 INFO:     Epoch: 2
2023-01-04 08:43:49,153 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5434424082438151, 'Total loss': 0.5434424082438151} | train loss {'Reaction outcome loss': 0.5665879941548838, 'Total loss': 0.5665879941548838}
2023-01-04 08:43:49,153 INFO:     Found new best model at epoch 2
2023-01-04 08:43:49,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:49,154 INFO:     Epoch: 3
2023-01-04 08:43:50,705 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5080443640549978, 'Total loss': 0.5080443640549978} | train loss {'Reaction outcome loss': 0.5259200423519254, 'Total loss': 0.5259200423519254}
2023-01-04 08:43:50,705 INFO:     Found new best model at epoch 3
2023-01-04 08:43:50,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:50,706 INFO:     Epoch: 4
2023-01-04 08:43:52,276 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4910721848408381, 'Total loss': 0.4910721848408381} | train loss {'Reaction outcome loss': 0.5104927199554967, 'Total loss': 0.5104927199554967}
2023-01-04 08:43:52,276 INFO:     Found new best model at epoch 4
2023-01-04 08:43:52,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:52,276 INFO:     Epoch: 5
2023-01-04 08:43:53,847 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4897896567980448, 'Total loss': 0.4897896567980448} | train loss {'Reaction outcome loss': 0.49573613452169046, 'Total loss': 0.49573613452169046}
2023-01-04 08:43:53,847 INFO:     Found new best model at epoch 5
2023-01-04 08:43:53,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:53,848 INFO:     Epoch: 6
2023-01-04 08:43:55,398 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48356892267862955, 'Total loss': 0.48356892267862955} | train loss {'Reaction outcome loss': 0.48510753879180324, 'Total loss': 0.48510753879180324}
2023-01-04 08:43:55,399 INFO:     Found new best model at epoch 6
2023-01-04 08:43:55,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:55,399 INFO:     Epoch: 7
2023-01-04 08:43:56,914 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45528832376003264, 'Total loss': 0.45528832376003264} | train loss {'Reaction outcome loss': 0.4748557890072847, 'Total loss': 0.4748557890072847}
2023-01-04 08:43:56,914 INFO:     Found new best model at epoch 7
2023-01-04 08:43:56,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:56,915 INFO:     Epoch: 8
2023-01-04 08:43:58,435 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47899725536505383, 'Total loss': 0.47899725536505383} | train loss {'Reaction outcome loss': 0.4710092917357609, 'Total loss': 0.4710092917357609}
2023-01-04 08:43:58,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:43:58,436 INFO:     Epoch: 9
2023-01-04 08:44:00,027 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46299699147542317, 'Total loss': 0.46299699147542317} | train loss {'Reaction outcome loss': 0.46412242779801616, 'Total loss': 0.46412242779801616}
2023-01-04 08:44:00,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:00,027 INFO:     Epoch: 10
2023-01-04 08:44:01,641 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49323468208312987, 'Total loss': 0.49323468208312987} | train loss {'Reaction outcome loss': 0.4558728268786228, 'Total loss': 0.4558728268786228}
2023-01-04 08:44:01,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:01,641 INFO:     Epoch: 11
2023-01-04 08:44:03,202 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4755877594153086, 'Total loss': 0.4755877594153086} | train loss {'Reaction outcome loss': 0.448442803470643, 'Total loss': 0.448442803470643}
2023-01-04 08:44:03,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:03,203 INFO:     Epoch: 12
2023-01-04 08:44:04,800 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4657595313464602, 'Total loss': 0.4657595313464602} | train loss {'Reaction outcome loss': 0.4480032758998784, 'Total loss': 0.4480032758998784}
2023-01-04 08:44:04,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:04,800 INFO:     Epoch: 13
2023-01-04 08:44:06,354 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4599235643943151, 'Total loss': 0.4599235643943151} | train loss {'Reaction outcome loss': 0.4412593634683134, 'Total loss': 0.4412593634683134}
2023-01-04 08:44:06,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:06,355 INFO:     Epoch: 14
2023-01-04 08:44:07,900 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46776652137438457, 'Total loss': 0.46776652137438457} | train loss {'Reaction outcome loss': 0.4349973433729493, 'Total loss': 0.4349973433729493}
2023-01-04 08:44:07,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:07,900 INFO:     Epoch: 15
2023-01-04 08:44:09,508 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45090096990267436, 'Total loss': 0.45090096990267436} | train loss {'Reaction outcome loss': 0.43149846904116235, 'Total loss': 0.43149846904116235}
2023-01-04 08:44:09,508 INFO:     Found new best model at epoch 15
2023-01-04 08:44:09,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:09,509 INFO:     Epoch: 16
2023-01-04 08:44:11,110 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43733564416567483, 'Total loss': 0.43733564416567483} | train loss {'Reaction outcome loss': 0.4247984166219558, 'Total loss': 0.4247984166219558}
2023-01-04 08:44:11,111 INFO:     Found new best model at epoch 16
2023-01-04 08:44:11,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:11,111 INFO:     Epoch: 17
2023-01-04 08:44:12,706 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4634597659111023, 'Total loss': 0.4634597659111023} | train loss {'Reaction outcome loss': 0.4250428533597744, 'Total loss': 0.4250428533597744}
2023-01-04 08:44:12,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:12,707 INFO:     Epoch: 18
2023-01-04 08:44:14,273 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4554439544677734, 'Total loss': 0.4554439544677734} | train loss {'Reaction outcome loss': 0.41784496954727524, 'Total loss': 0.41784496954727524}
2023-01-04 08:44:14,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:14,273 INFO:     Epoch: 19
2023-01-04 08:44:15,830 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45281520585219065, 'Total loss': 0.45281520585219065} | train loss {'Reaction outcome loss': 0.41585670488002974, 'Total loss': 0.41585670488002974}
2023-01-04 08:44:15,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:15,831 INFO:     Epoch: 20
2023-01-04 08:44:17,413 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4371169477701187, 'Total loss': 0.4371169477701187} | train loss {'Reaction outcome loss': 0.4133259357932286, 'Total loss': 0.4133259357932286}
2023-01-04 08:44:17,413 INFO:     Found new best model at epoch 20
2023-01-04 08:44:17,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:17,414 INFO:     Epoch: 21
2023-01-04 08:44:19,010 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43970120549201963, 'Total loss': 0.43970120549201963} | train loss {'Reaction outcome loss': 0.40813655338007887, 'Total loss': 0.40813655338007887}
2023-01-04 08:44:19,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:19,012 INFO:     Epoch: 22
2023-01-04 08:44:20,604 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4703635404507319, 'Total loss': 0.4703635404507319} | train loss {'Reaction outcome loss': 0.4042292819818953, 'Total loss': 0.4042292819818953}
2023-01-04 08:44:20,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:20,604 INFO:     Epoch: 23
2023-01-04 08:44:22,195 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44440465569496157, 'Total loss': 0.44440465569496157} | train loss {'Reaction outcome loss': 0.3954207807397231, 'Total loss': 0.3954207807397231}
2023-01-04 08:44:22,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:22,195 INFO:     Epoch: 24
2023-01-04 08:44:23,707 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44993115166823067, 'Total loss': 0.44993115166823067} | train loss {'Reaction outcome loss': 0.39175442445190833, 'Total loss': 0.39175442445190833}
2023-01-04 08:44:23,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:23,708 INFO:     Epoch: 25
2023-01-04 08:44:25,204 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4073238710562388, 'Total loss': 0.4073238710562388} | train loss {'Reaction outcome loss': 0.38914517629823403, 'Total loss': 0.38914517629823403}
2023-01-04 08:44:25,205 INFO:     Found new best model at epoch 25
2023-01-04 08:44:25,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:25,206 INFO:     Epoch: 26
2023-01-04 08:44:26,732 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4573891331752141, 'Total loss': 0.4573891331752141} | train loss {'Reaction outcome loss': 0.3862526530311221, 'Total loss': 0.3862526530311221}
2023-01-04 08:44:26,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:26,732 INFO:     Epoch: 27
2023-01-04 08:44:28,266 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41166053861379626, 'Total loss': 0.41166053861379626} | train loss {'Reaction outcome loss': 0.38641161021295484, 'Total loss': 0.38641161021295484}
2023-01-04 08:44:28,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:28,267 INFO:     Epoch: 28
2023-01-04 08:44:29,808 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43142832318941754, 'Total loss': 0.43142832318941754} | train loss {'Reaction outcome loss': 0.3776249248711836, 'Total loss': 0.3776249248711836}
2023-01-04 08:44:29,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:29,809 INFO:     Epoch: 29
2023-01-04 08:44:31,364 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47907756368319193, 'Total loss': 0.47907756368319193} | train loss {'Reaction outcome loss': 0.3751186478214386, 'Total loss': 0.3751186478214386}
2023-01-04 08:44:31,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:31,364 INFO:     Epoch: 30
2023-01-04 08:44:32,871 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4320121804873149, 'Total loss': 0.4320121804873149} | train loss {'Reaction outcome loss': 0.37237294288454476, 'Total loss': 0.37237294288454476}
2023-01-04 08:44:32,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:32,871 INFO:     Epoch: 31
2023-01-04 08:44:34,372 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4150427008668582, 'Total loss': 0.4150427008668582} | train loss {'Reaction outcome loss': 0.3709795777123053, 'Total loss': 0.3709795777123053}
2023-01-04 08:44:34,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:34,372 INFO:     Epoch: 32
2023-01-04 08:44:35,932 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4401532232761383, 'Total loss': 0.4401532232761383} | train loss {'Reaction outcome loss': 0.36833164049483047, 'Total loss': 0.36833164049483047}
2023-01-04 08:44:35,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:35,932 INFO:     Epoch: 33
2023-01-04 08:44:37,501 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4226884384950002, 'Total loss': 0.4226884384950002} | train loss {'Reaction outcome loss': 0.37048868712160615, 'Total loss': 0.37048868712160615}
2023-01-04 08:44:37,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:37,502 INFO:     Epoch: 34
2023-01-04 08:44:39,070 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4606483260790507, 'Total loss': 0.4606483260790507} | train loss {'Reaction outcome loss': 0.3579578792110031, 'Total loss': 0.3579578792110031}
2023-01-04 08:44:39,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:39,071 INFO:     Epoch: 35
2023-01-04 08:44:40,624 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41072169740994774, 'Total loss': 0.41072169740994774} | train loss {'Reaction outcome loss': 0.3586685968351451, 'Total loss': 0.3586685968351451}
2023-01-04 08:44:40,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:40,624 INFO:     Epoch: 36
2023-01-04 08:44:42,125 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40593543847401936, 'Total loss': 0.40593543847401936} | train loss {'Reaction outcome loss': 0.357581058100903, 'Total loss': 0.357581058100903}
2023-01-04 08:44:42,125 INFO:     Found new best model at epoch 36
2023-01-04 08:44:42,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:42,126 INFO:     Epoch: 37
2023-01-04 08:44:43,623 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43639766772588096, 'Total loss': 0.43639766772588096} | train loss {'Reaction outcome loss': 0.3496495527061787, 'Total loss': 0.3496495527061787}
2023-01-04 08:44:43,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:43,623 INFO:     Epoch: 38
2023-01-04 08:44:45,159 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4338624944289525, 'Total loss': 0.4338624944289525} | train loss {'Reaction outcome loss': 0.3476611310309106, 'Total loss': 0.3476611310309106}
2023-01-04 08:44:45,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:45,159 INFO:     Epoch: 39
2023-01-04 08:44:46,703 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44334915379683176, 'Total loss': 0.44334915379683176} | train loss {'Reaction outcome loss': 0.3465278121905449, 'Total loss': 0.3465278121905449}
2023-01-04 08:44:46,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:46,703 INFO:     Epoch: 40
2023-01-04 08:44:48,245 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4484246512254079, 'Total loss': 0.4484246512254079} | train loss {'Reaction outcome loss': 0.34096108147731197, 'Total loss': 0.34096108147731197}
2023-01-04 08:44:48,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:48,246 INFO:     Epoch: 41
2023-01-04 08:44:49,782 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4171620587507884, 'Total loss': 0.4171620587507884} | train loss {'Reaction outcome loss': 0.3455085842546089, 'Total loss': 0.3455085842546089}
2023-01-04 08:44:49,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:49,784 INFO:     Epoch: 42
2023-01-04 08:44:51,273 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4351760149002075, 'Total loss': 0.4351760149002075} | train loss {'Reaction outcome loss': 0.3442041883483911, 'Total loss': 0.3442041883483911}
2023-01-04 08:44:51,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:51,274 INFO:     Epoch: 43
2023-01-04 08:44:52,772 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4548747877279917, 'Total loss': 0.4548747877279917} | train loss {'Reaction outcome loss': 0.33887284019818675, 'Total loss': 0.33887284019818675}
2023-01-04 08:44:52,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:52,772 INFO:     Epoch: 44
2023-01-04 08:44:54,293 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.434391176700592, 'Total loss': 0.434391176700592} | train loss {'Reaction outcome loss': 0.3332266592362643, 'Total loss': 0.3332266592362643}
2023-01-04 08:44:54,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:54,293 INFO:     Epoch: 45
2023-01-04 08:44:55,814 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42152928113937377, 'Total loss': 0.42152928113937377} | train loss {'Reaction outcome loss': 0.3293640507937788, 'Total loss': 0.3293640507937788}
2023-01-04 08:44:55,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:55,815 INFO:     Epoch: 46
2023-01-04 08:44:57,329 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42165473798910774, 'Total loss': 0.42165473798910774} | train loss {'Reaction outcome loss': 0.3265741811894672, 'Total loss': 0.3265741811894672}
2023-01-04 08:44:57,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:57,330 INFO:     Epoch: 47
2023-01-04 08:44:58,870 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4027181108792623, 'Total loss': 0.4027181108792623} | train loss {'Reaction outcome loss': 0.32977228797289915, 'Total loss': 0.32977228797289915}
2023-01-04 08:44:58,870 INFO:     Found new best model at epoch 47
2023-01-04 08:44:58,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:44:58,871 INFO:     Epoch: 48
2023-01-04 08:45:00,385 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39256363014380136, 'Total loss': 0.39256363014380136} | train loss {'Reaction outcome loss': 0.3315102763392113, 'Total loss': 0.3315102763392113}
2023-01-04 08:45:00,386 INFO:     Found new best model at epoch 48
2023-01-04 08:45:00,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:00,386 INFO:     Epoch: 49
2023-01-04 08:45:01,935 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40635882318019867, 'Total loss': 0.40635882318019867} | train loss {'Reaction outcome loss': 0.322434415829269, 'Total loss': 0.322434415829269}
2023-01-04 08:45:01,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:01,936 INFO:     Epoch: 50
2023-01-04 08:45:03,490 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4026296277840932, 'Total loss': 0.4026296277840932} | train loss {'Reaction outcome loss': 0.3187122889163293, 'Total loss': 0.3187122889163293}
2023-01-04 08:45:03,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:03,490 INFO:     Epoch: 51
2023-01-04 08:45:05,049 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40684632857640585, 'Total loss': 0.40684632857640585} | train loss {'Reaction outcome loss': 0.3190761412674691, 'Total loss': 0.3190761412674691}
2023-01-04 08:45:05,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:05,049 INFO:     Epoch: 52
2023-01-04 08:45:06,592 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4584491183360418, 'Total loss': 0.4584491183360418} | train loss {'Reaction outcome loss': 0.311155686571157, 'Total loss': 0.311155686571157}
2023-01-04 08:45:06,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:06,592 INFO:     Epoch: 53
2023-01-04 08:45:08,131 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4205923726161321, 'Total loss': 0.4205923726161321} | train loss {'Reaction outcome loss': 0.3176731263652389, 'Total loss': 0.3176731263652389}
2023-01-04 08:45:08,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:08,132 INFO:     Epoch: 54
2023-01-04 08:45:09,637 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41828383803367614, 'Total loss': 0.41828383803367614} | train loss {'Reaction outcome loss': 0.3111780571986686, 'Total loss': 0.3111780571986686}
2023-01-04 08:45:09,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:09,637 INFO:     Epoch: 55
2023-01-04 08:45:11,140 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41826046307881676, 'Total loss': 0.41826046307881676} | train loss {'Reaction outcome loss': 0.3081939598961628, 'Total loss': 0.3081939598961628}
2023-01-04 08:45:11,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:11,140 INFO:     Epoch: 56
2023-01-04 08:45:12,666 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3971712360779444, 'Total loss': 0.3971712360779444} | train loss {'Reaction outcome loss': 0.3107327414956285, 'Total loss': 0.3107327414956285}
2023-01-04 08:45:12,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:12,666 INFO:     Epoch: 57
2023-01-04 08:45:14,201 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37651781688133873, 'Total loss': 0.37651781688133873} | train loss {'Reaction outcome loss': 0.3077272682727038, 'Total loss': 0.3077272682727038}
2023-01-04 08:45:14,201 INFO:     Found new best model at epoch 57
2023-01-04 08:45:14,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:14,202 INFO:     Epoch: 58
2023-01-04 08:45:15,740 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39230764309565225, 'Total loss': 0.39230764309565225} | train loss {'Reaction outcome loss': 0.3047435209427998, 'Total loss': 0.3047435209427998}
2023-01-04 08:45:15,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:15,740 INFO:     Epoch: 59
2023-01-04 08:45:17,293 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39489895701408384, 'Total loss': 0.39489895701408384} | train loss {'Reaction outcome loss': 0.3046417779974885, 'Total loss': 0.3046417779974885}
2023-01-04 08:45:17,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:17,294 INFO:     Epoch: 60
2023-01-04 08:45:18,797 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4392362723747889, 'Total loss': 0.4392362723747889} | train loss {'Reaction outcome loss': 0.30057729732913846, 'Total loss': 0.30057729732913846}
2023-01-04 08:45:18,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:18,797 INFO:     Epoch: 61
2023-01-04 08:45:20,337 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4159261465072632, 'Total loss': 0.4159261465072632} | train loss {'Reaction outcome loss': 0.3043383885134052, 'Total loss': 0.3043383885134052}
2023-01-04 08:45:20,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:20,338 INFO:     Epoch: 62
2023-01-04 08:45:21,936 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41621613403161367, 'Total loss': 0.41621613403161367} | train loss {'Reaction outcome loss': 0.297885004062574, 'Total loss': 0.297885004062574}
2023-01-04 08:45:21,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:21,936 INFO:     Epoch: 63
2023-01-04 08:45:23,511 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40838203529516853, 'Total loss': 0.40838203529516853} | train loss {'Reaction outcome loss': 0.295050055252545, 'Total loss': 0.295050055252545}
2023-01-04 08:45:23,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:23,512 INFO:     Epoch: 64
2023-01-04 08:45:25,091 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4027962495883306, 'Total loss': 0.4027962495883306} | train loss {'Reaction outcome loss': 0.29874337510966553, 'Total loss': 0.29874337510966553}
2023-01-04 08:45:25,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:25,091 INFO:     Epoch: 65
2023-01-04 08:45:26,645 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4030420660972595, 'Total loss': 0.4030420660972595} | train loss {'Reaction outcome loss': 0.2964554436286509, 'Total loss': 0.2964554436286509}
2023-01-04 08:45:26,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:26,646 INFO:     Epoch: 66
2023-01-04 08:45:28,162 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41424297392368314, 'Total loss': 0.41424297392368314} | train loss {'Reaction outcome loss': 0.2949464049858925, 'Total loss': 0.2949464049858925}
2023-01-04 08:45:28,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:28,162 INFO:     Epoch: 67
2023-01-04 08:45:29,663 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4415967712799708, 'Total loss': 0.4415967712799708} | train loss {'Reaction outcome loss': 0.2906983660008663, 'Total loss': 0.2906983660008663}
2023-01-04 08:45:29,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:29,663 INFO:     Epoch: 68
2023-01-04 08:45:31,193 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42203423579533894, 'Total loss': 0.42203423579533894} | train loss {'Reaction outcome loss': 0.2889968202937217, 'Total loss': 0.2889968202937217}
2023-01-04 08:45:31,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:31,193 INFO:     Epoch: 69
2023-01-04 08:45:32,718 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40285475701093676, 'Total loss': 0.40285475701093676} | train loss {'Reaction outcome loss': 0.29046546411274116, 'Total loss': 0.29046546411274116}
2023-01-04 08:45:32,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:32,719 INFO:     Epoch: 70
2023-01-04 08:45:34,243 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41729342738787334, 'Total loss': 0.41729342738787334} | train loss {'Reaction outcome loss': 0.2892333197888437, 'Total loss': 0.2892333197888437}
2023-01-04 08:45:34,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:34,243 INFO:     Epoch: 71
2023-01-04 08:45:35,765 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38226410547892253, 'Total loss': 0.38226410547892253} | train loss {'Reaction outcome loss': 0.2830409729075465, 'Total loss': 0.2830409729075465}
2023-01-04 08:45:35,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:35,765 INFO:     Epoch: 72
2023-01-04 08:45:37,281 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4081949015458425, 'Total loss': 0.4081949015458425} | train loss {'Reaction outcome loss': 0.28451360880837334, 'Total loss': 0.28451360880837334}
2023-01-04 08:45:37,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:37,282 INFO:     Epoch: 73
2023-01-04 08:45:38,786 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3934978261590004, 'Total loss': 0.3934978261590004} | train loss {'Reaction outcome loss': 0.28313031025749424, 'Total loss': 0.28313031025749424}
2023-01-04 08:45:38,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:38,787 INFO:     Epoch: 74
2023-01-04 08:45:40,330 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4363059550523758, 'Total loss': 0.4363059550523758} | train loss {'Reaction outcome loss': 0.2797308634052347, 'Total loss': 0.2797308634052347}
2023-01-04 08:45:40,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:40,330 INFO:     Epoch: 75
2023-01-04 08:45:41,857 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4156803588072459, 'Total loss': 0.4156803588072459} | train loss {'Reaction outcome loss': 0.2823074134169044, 'Total loss': 0.2823074134169044}
2023-01-04 08:45:41,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:41,858 INFO:     Epoch: 76
2023-01-04 08:45:43,378 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4125714103380839, 'Total loss': 0.4125714103380839} | train loss {'Reaction outcome loss': 0.2779063267339935, 'Total loss': 0.2779063267339935}
2023-01-04 08:45:43,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:43,378 INFO:     Epoch: 77
2023-01-04 08:45:44,895 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40050215224424995, 'Total loss': 0.40050215224424995} | train loss {'Reaction outcome loss': 0.2809161759449012, 'Total loss': 0.2809161759449012}
2023-01-04 08:45:44,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:44,895 INFO:     Epoch: 78
2023-01-04 08:45:46,411 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.408619350194931, 'Total loss': 0.408619350194931} | train loss {'Reaction outcome loss': 0.2778870261141232, 'Total loss': 0.2778870261141232}
2023-01-04 08:45:46,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:46,411 INFO:     Epoch: 79
2023-01-04 08:45:47,920 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.445629080136617, 'Total loss': 0.445629080136617} | train loss {'Reaction outcome loss': 0.27561988949011534, 'Total loss': 0.27561988949011534}
2023-01-04 08:45:47,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:47,920 INFO:     Epoch: 80
2023-01-04 08:45:49,449 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38945297002792356, 'Total loss': 0.38945297002792356} | train loss {'Reaction outcome loss': 0.2788392762506838, 'Total loss': 0.2788392762506838}
2023-01-04 08:45:49,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:49,449 INFO:     Epoch: 81
2023-01-04 08:45:50,975 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39166020850340527, 'Total loss': 0.39166020850340527} | train loss {'Reaction outcome loss': 0.27616639394354037, 'Total loss': 0.27616639394354037}
2023-01-04 08:45:50,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:50,976 INFO:     Epoch: 82
2023-01-04 08:45:52,511 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4027228355407715, 'Total loss': 0.4027228355407715} | train loss {'Reaction outcome loss': 0.26844645684564505, 'Total loss': 0.26844645684564505}
2023-01-04 08:45:52,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:52,511 INFO:     Epoch: 83
2023-01-04 08:45:54,008 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41202169756094614, 'Total loss': 0.41202169756094614} | train loss {'Reaction outcome loss': 0.26996601396155007, 'Total loss': 0.26996601396155007}
2023-01-04 08:45:54,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:54,008 INFO:     Epoch: 84
2023-01-04 08:45:55,530 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44934410949548087, 'Total loss': 0.44934410949548087} | train loss {'Reaction outcome loss': 0.2696649820949787, 'Total loss': 0.2696649820949787}
2023-01-04 08:45:55,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:55,530 INFO:     Epoch: 85
2023-01-04 08:45:57,119 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4336596667766571, 'Total loss': 0.4336596667766571} | train loss {'Reaction outcome loss': 0.27024698059582886, 'Total loss': 0.27024698059582886}
2023-01-04 08:45:57,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:57,120 INFO:     Epoch: 86
2023-01-04 08:45:58,732 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3761757165193558, 'Total loss': 0.3761757165193558} | train loss {'Reaction outcome loss': 0.26706342775743086, 'Total loss': 0.26706342775743086}
2023-01-04 08:45:58,732 INFO:     Found new best model at epoch 86
2023-01-04 08:45:58,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:45:58,733 INFO:     Epoch: 87
2023-01-04 08:46:00,346 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3941754048069318, 'Total loss': 0.3941754048069318} | train loss {'Reaction outcome loss': 0.266240656321302, 'Total loss': 0.266240656321302}
2023-01-04 08:46:00,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:00,346 INFO:     Epoch: 88
2023-01-04 08:46:01,959 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3824011653661728, 'Total loss': 0.3824011653661728} | train loss {'Reaction outcome loss': 0.26517755943504007, 'Total loss': 0.26517755943504007}
2023-01-04 08:46:01,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:01,959 INFO:     Epoch: 89
2023-01-04 08:46:03,521 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4265387644370397, 'Total loss': 0.4265387644370397} | train loss {'Reaction outcome loss': 0.2685317927391538, 'Total loss': 0.2685317927391538}
2023-01-04 08:46:03,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:03,521 INFO:     Epoch: 90
2023-01-04 08:46:05,082 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47529808481534325, 'Total loss': 0.47529808481534325} | train loss {'Reaction outcome loss': 0.26557185252507526, 'Total loss': 0.26557185252507526}
2023-01-04 08:46:05,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:05,082 INFO:     Epoch: 91
2023-01-04 08:46:06,695 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44309844374656676, 'Total loss': 0.44309844374656676} | train loss {'Reaction outcome loss': 0.2627869048207016, 'Total loss': 0.2627869048207016}
2023-01-04 08:46:06,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:06,695 INFO:     Epoch: 92
2023-01-04 08:46:08,309 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4130942503611247, 'Total loss': 0.4130942503611247} | train loss {'Reaction outcome loss': 0.26183007133531044, 'Total loss': 0.26183007133531044}
2023-01-04 08:46:08,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:08,309 INFO:     Epoch: 93
2023-01-04 08:46:09,923 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41518761416276295, 'Total loss': 0.41518761416276295} | train loss {'Reaction outcome loss': 0.2630245595515429, 'Total loss': 0.2630245595515429}
2023-01-04 08:46:09,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:09,924 INFO:     Epoch: 94
2023-01-04 08:46:11,537 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3712982177734375, 'Total loss': 0.3712982177734375} | train loss {'Reaction outcome loss': 0.2661623935805354, 'Total loss': 0.2661623935805354}
2023-01-04 08:46:11,537 INFO:     Found new best model at epoch 94
2023-01-04 08:46:11,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:11,538 INFO:     Epoch: 95
2023-01-04 08:46:13,099 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42790375153223675, 'Total loss': 0.42790375153223675} | train loss {'Reaction outcome loss': 0.25912809262782227, 'Total loss': 0.25912809262782227}
2023-01-04 08:46:13,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:13,099 INFO:     Epoch: 96
2023-01-04 08:46:14,656 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42583351731300356, 'Total loss': 0.42583351731300356} | train loss {'Reaction outcome loss': 0.25876947374325315, 'Total loss': 0.25876947374325315}
2023-01-04 08:46:14,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:14,656 INFO:     Epoch: 97
2023-01-04 08:46:16,273 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38778456548849743, 'Total loss': 0.38778456548849743} | train loss {'Reaction outcome loss': 0.26072020555808867, 'Total loss': 0.26072020555808867}
2023-01-04 08:46:16,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:16,273 INFO:     Epoch: 98
2023-01-04 08:46:17,885 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4186159869035085, 'Total loss': 0.4186159869035085} | train loss {'Reaction outcome loss': 0.25975221259035036, 'Total loss': 0.25975221259035036}
2023-01-04 08:46:17,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:17,885 INFO:     Epoch: 99
2023-01-04 08:46:19,498 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42557375530401864, 'Total loss': 0.42557375530401864} | train loss {'Reaction outcome loss': 0.2556044633044851, 'Total loss': 0.2556044633044851}
2023-01-04 08:46:19,498 INFO:     Best model found after epoch 95 of 100.
2023-01-04 08:46:19,499 INFO:   Done with stage: TRAINING
2023-01-04 08:46:19,499 INFO:   Starting stage: EVALUATION
2023-01-04 08:46:19,639 INFO:   Done with stage: EVALUATION
2023-01-04 08:46:19,639 INFO:   Leaving out SEQ value Fold_3
2023-01-04 08:46:19,652 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 08:46:19,652 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:46:20,292 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:46:20,292 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:46:20,360 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:46:20,360 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:46:20,360 INFO:     No hyperparam tuning for this model
2023-01-04 08:46:20,360 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:46:20,360 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:46:20,361 INFO:     None feature selector for col prot
2023-01-04 08:46:20,361 INFO:     None feature selector for col prot
2023-01-04 08:46:20,361 INFO:     None feature selector for col prot
2023-01-04 08:46:20,362 INFO:     None feature selector for col chem
2023-01-04 08:46:20,362 INFO:     None feature selector for col chem
2023-01-04 08:46:20,362 INFO:     None feature selector for col chem
2023-01-04 08:46:20,362 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:46:20,362 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:46:20,363 INFO:     Number of params in model 70111
2023-01-04 08:46:20,366 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:46:20,366 INFO:   Starting stage: TRAINING
2023-01-04 08:46:20,409 INFO:     Val loss before train {'Reaction outcome loss': 1.0889059861501058, 'Total loss': 1.0889059861501058}
2023-01-04 08:46:20,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:20,409 INFO:     Epoch: 0
2023-01-04 08:46:21,931 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7620608409245809, 'Total loss': 0.7620608409245809} | train loss {'Reaction outcome loss': 0.8465422757350616, 'Total loss': 0.8465422757350616}
2023-01-04 08:46:21,932 INFO:     Found new best model at epoch 0
2023-01-04 08:46:21,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:21,933 INFO:     Epoch: 1
2023-01-04 08:46:23,459 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6226980944474538, 'Total loss': 0.6226980944474538} | train loss {'Reaction outcome loss': 0.6876603808716266, 'Total loss': 0.6876603808716266}
2023-01-04 08:46:23,459 INFO:     Found new best model at epoch 1
2023-01-04 08:46:23,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:23,459 INFO:     Epoch: 2
2023-01-04 08:46:25,040 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5475332458813985, 'Total loss': 0.5475332458813985} | train loss {'Reaction outcome loss': 0.5898684523183934, 'Total loss': 0.5898684523183934}
2023-01-04 08:46:25,040 INFO:     Found new best model at epoch 2
2023-01-04 08:46:25,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:25,041 INFO:     Epoch: 3
2023-01-04 08:46:26,625 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5396754324436188, 'Total loss': 0.5396754324436188} | train loss {'Reaction outcome loss': 0.5482794213360244, 'Total loss': 0.5482794213360244}
2023-01-04 08:46:26,625 INFO:     Found new best model at epoch 3
2023-01-04 08:46:26,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:26,626 INFO:     Epoch: 4
2023-01-04 08:46:28,193 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5123757302761078, 'Total loss': 0.5123757302761078} | train loss {'Reaction outcome loss': 0.5208191652476353, 'Total loss': 0.5208191652476353}
2023-01-04 08:46:28,194 INFO:     Found new best model at epoch 4
2023-01-04 08:46:28,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:28,195 INFO:     Epoch: 5
2023-01-04 08:46:29,757 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4886682947476705, 'Total loss': 0.4886682947476705} | train loss {'Reaction outcome loss': 0.509366162393215, 'Total loss': 0.509366162393215}
2023-01-04 08:46:29,757 INFO:     Found new best model at epoch 5
2023-01-04 08:46:29,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:29,758 INFO:     Epoch: 6
2023-01-04 08:46:31,300 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48936538795630136, 'Total loss': 0.48936538795630136} | train loss {'Reaction outcome loss': 0.49346284356212966, 'Total loss': 0.49346284356212966}
2023-01-04 08:46:31,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:31,300 INFO:     Epoch: 7
2023-01-04 08:46:32,853 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47124165097872417, 'Total loss': 0.47124165097872417} | train loss {'Reaction outcome loss': 0.48105185652953864, 'Total loss': 0.48105185652953864}
2023-01-04 08:46:32,853 INFO:     Found new best model at epoch 7
2023-01-04 08:46:32,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:32,854 INFO:     Epoch: 8
2023-01-04 08:46:34,427 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46262892882029216, 'Total loss': 0.46262892882029216} | train loss {'Reaction outcome loss': 0.47604118447995536, 'Total loss': 0.47604118447995536}
2023-01-04 08:46:34,427 INFO:     Found new best model at epoch 8
2023-01-04 08:46:34,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:34,428 INFO:     Epoch: 9
2023-01-04 08:46:35,977 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4848077416419983, 'Total loss': 0.4848077416419983} | train loss {'Reaction outcome loss': 0.4693608505882486, 'Total loss': 0.4693608505882486}
2023-01-04 08:46:35,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:35,977 INFO:     Epoch: 10
2023-01-04 08:46:37,516 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47349765797456106, 'Total loss': 0.47349765797456106} | train loss {'Reaction outcome loss': 0.4628583518040441, 'Total loss': 0.4628583518040441}
2023-01-04 08:46:37,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:37,516 INFO:     Epoch: 11
2023-01-04 08:46:39,055 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46947799722353617, 'Total loss': 0.46947799722353617} | train loss {'Reaction outcome loss': 0.45552097369719596, 'Total loss': 0.45552097369719596}
2023-01-04 08:46:39,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:39,055 INFO:     Epoch: 12
2023-01-04 08:46:40,598 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4599698007106781, 'Total loss': 0.4599698007106781} | train loss {'Reaction outcome loss': 0.4539189958659402, 'Total loss': 0.4539189958659402}
2023-01-04 08:46:40,599 INFO:     Found new best model at epoch 12
2023-01-04 08:46:40,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:40,599 INFO:     Epoch: 13
2023-01-04 08:46:42,123 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47419917583465576, 'Total loss': 0.47419917583465576} | train loss {'Reaction outcome loss': 0.44769748501534007, 'Total loss': 0.44769748501534007}
2023-01-04 08:46:42,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:42,123 INFO:     Epoch: 14
2023-01-04 08:46:43,673 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4493367205063502, 'Total loss': 0.4493367205063502} | train loss {'Reaction outcome loss': 0.4412037531172272, 'Total loss': 0.4412037531172272}
2023-01-04 08:46:43,673 INFO:     Found new best model at epoch 14
2023-01-04 08:46:43,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:43,674 INFO:     Epoch: 15
2023-01-04 08:46:45,240 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4761703113714854, 'Total loss': 0.4761703113714854} | train loss {'Reaction outcome loss': 0.43683500354089877, 'Total loss': 0.43683500354089877}
2023-01-04 08:46:45,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:45,240 INFO:     Epoch: 16
2023-01-04 08:46:46,800 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43557690978050234, 'Total loss': 0.43557690978050234} | train loss {'Reaction outcome loss': 0.433919848697464, 'Total loss': 0.433919848697464}
2023-01-04 08:46:46,800 INFO:     Found new best model at epoch 16
2023-01-04 08:46:46,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:46,801 INFO:     Epoch: 17
2023-01-04 08:46:48,333 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4572365164756775, 'Total loss': 0.4572365164756775} | train loss {'Reaction outcome loss': 0.4269824301021813, 'Total loss': 0.4269824301021813}
2023-01-04 08:46:48,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:48,334 INFO:     Epoch: 18
2023-01-04 08:46:49,885 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44262972275416057, 'Total loss': 0.44262972275416057} | train loss {'Reaction outcome loss': 0.4208064335432366, 'Total loss': 0.4208064335432366}
2023-01-04 08:46:49,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:49,885 INFO:     Epoch: 19
2023-01-04 08:46:51,428 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42965913911660514, 'Total loss': 0.42965913911660514} | train loss {'Reaction outcome loss': 0.4177381940675478, 'Total loss': 0.4177381940675478}
2023-01-04 08:46:51,428 INFO:     Found new best model at epoch 19
2023-01-04 08:46:51,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:51,429 INFO:     Epoch: 20
2023-01-04 08:46:52,973 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4400808980067571, 'Total loss': 0.4400808980067571} | train loss {'Reaction outcome loss': 0.41748513349325117, 'Total loss': 0.41748513349325117}
2023-01-04 08:46:52,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:52,973 INFO:     Epoch: 21
2023-01-04 08:46:54,512 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45340887308120725, 'Total loss': 0.45340887308120725} | train loss {'Reaction outcome loss': 0.41229709860508457, 'Total loss': 0.41229709860508457}
2023-01-04 08:46:54,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:54,513 INFO:     Epoch: 22
2023-01-04 08:46:56,061 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4480849355459213, 'Total loss': 0.4480849355459213} | train loss {'Reaction outcome loss': 0.4086495327906017, 'Total loss': 0.4086495327906017}
2023-01-04 08:46:56,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:56,061 INFO:     Epoch: 23
2023-01-04 08:46:57,561 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42897580862045287, 'Total loss': 0.42897580862045287} | train loss {'Reaction outcome loss': 0.4003626834193285, 'Total loss': 0.4003626834193285}
2023-01-04 08:46:57,561 INFO:     Found new best model at epoch 23
2023-01-04 08:46:57,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:57,562 INFO:     Epoch: 24
2023-01-04 08:46:59,078 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4345073223114014, 'Total loss': 0.4345073223114014} | train loss {'Reaction outcome loss': 0.39952242823086515, 'Total loss': 0.39952242823086515}
2023-01-04 08:46:59,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:46:59,079 INFO:     Epoch: 25
2023-01-04 08:47:00,618 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4026629666487376, 'Total loss': 0.4026629666487376} | train loss {'Reaction outcome loss': 0.3960268988008917, 'Total loss': 0.3960268988008917}
2023-01-04 08:47:00,619 INFO:     Found new best model at epoch 25
2023-01-04 08:47:00,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:00,620 INFO:     Epoch: 26
2023-01-04 08:47:02,174 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4324143389860789, 'Total loss': 0.4324143389860789} | train loss {'Reaction outcome loss': 0.3946090242995398, 'Total loss': 0.3946090242995398}
2023-01-04 08:47:02,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:02,175 INFO:     Epoch: 27
2023-01-04 08:47:03,731 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44942360917727153, 'Total loss': 0.44942360917727153} | train loss {'Reaction outcome loss': 0.39052830680008355, 'Total loss': 0.39052830680008355}
2023-01-04 08:47:03,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:03,731 INFO:     Epoch: 28
2023-01-04 08:47:05,272 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42284976641337074, 'Total loss': 0.42284976641337074} | train loss {'Reaction outcome loss': 0.38567889925010884, 'Total loss': 0.38567889925010884}
2023-01-04 08:47:05,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:05,272 INFO:     Epoch: 29
2023-01-04 08:47:06,802 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42916517456372577, 'Total loss': 0.42916517456372577} | train loss {'Reaction outcome loss': 0.37801936404765957, 'Total loss': 0.37801936404765957}
2023-01-04 08:47:06,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:06,803 INFO:     Epoch: 30
2023-01-04 08:47:08,302 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42517392337322235, 'Total loss': 0.42517392337322235} | train loss {'Reaction outcome loss': 0.3754936171709186, 'Total loss': 0.3754936171709186}
2023-01-04 08:47:08,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:08,302 INFO:     Epoch: 31
2023-01-04 08:47:09,866 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3886086149762074, 'Total loss': 0.3886086149762074} | train loss {'Reaction outcome loss': 0.3727874883117467, 'Total loss': 0.3727874883117467}
2023-01-04 08:47:09,866 INFO:     Found new best model at epoch 31
2023-01-04 08:47:09,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:09,867 INFO:     Epoch: 32
2023-01-04 08:47:11,432 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43714266618092856, 'Total loss': 0.43714266618092856} | train loss {'Reaction outcome loss': 0.37155782034362317, 'Total loss': 0.37155782034362317}
2023-01-04 08:47:11,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:11,432 INFO:     Epoch: 33
2023-01-04 08:47:12,994 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4216877738634745, 'Total loss': 0.4216877738634745} | train loss {'Reaction outcome loss': 0.3662258572604534, 'Total loss': 0.3662258572604534}
2023-01-04 08:47:12,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:12,995 INFO:     Epoch: 34
2023-01-04 08:47:14,519 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43172882199287416, 'Total loss': 0.43172882199287416} | train loss {'Reaction outcome loss': 0.3630663046382204, 'Total loss': 0.3630663046382204}
2023-01-04 08:47:14,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:14,520 INFO:     Epoch: 35
2023-01-04 08:47:16,036 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44241357147693633, 'Total loss': 0.44241357147693633} | train loss {'Reaction outcome loss': 0.3562641625367377, 'Total loss': 0.3562641625367377}
2023-01-04 08:47:16,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:16,036 INFO:     Epoch: 36
2023-01-04 08:47:17,545 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4083851486444473, 'Total loss': 0.4083851486444473} | train loss {'Reaction outcome loss': 0.35532674519685065, 'Total loss': 0.35532674519685065}
2023-01-04 08:47:17,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:17,545 INFO:     Epoch: 37
2023-01-04 08:47:19,108 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43817259669303893, 'Total loss': 0.43817259669303893} | train loss {'Reaction outcome loss': 0.3515061196891496, 'Total loss': 0.3515061196891496}
2023-01-04 08:47:19,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:19,109 INFO:     Epoch: 38
2023-01-04 08:47:20,669 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4061483676234881, 'Total loss': 0.4061483676234881} | train loss {'Reaction outcome loss': 0.34750248214406687, 'Total loss': 0.34750248214406687}
2023-01-04 08:47:20,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:20,669 INFO:     Epoch: 39
2023-01-04 08:47:22,234 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44631375968456266, 'Total loss': 0.44631375968456266} | train loss {'Reaction outcome loss': 0.3411553319081338, 'Total loss': 0.3411553319081338}
2023-01-04 08:47:22,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:22,234 INFO:     Epoch: 40
2023-01-04 08:47:23,787 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4265339940786362, 'Total loss': 0.4265339940786362} | train loss {'Reaction outcome loss': 0.3463751347939463, 'Total loss': 0.3463751347939463}
2023-01-04 08:47:23,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:23,788 INFO:     Epoch: 41
2023-01-04 08:47:25,319 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41045172810554503, 'Total loss': 0.41045172810554503} | train loss {'Reaction outcome loss': 0.33919480984119604, 'Total loss': 0.33919480984119604}
2023-01-04 08:47:25,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:25,320 INFO:     Epoch: 42
2023-01-04 08:47:26,851 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43721661070982615, 'Total loss': 0.43721661070982615} | train loss {'Reaction outcome loss': 0.3355899358263416, 'Total loss': 0.3355899358263416}
2023-01-04 08:47:26,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:26,851 INFO:     Epoch: 43
2023-01-04 08:47:28,456 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4214927832285563, 'Total loss': 0.4214927832285563} | train loss {'Reaction outcome loss': 0.3346212395895137, 'Total loss': 0.3346212395895137}
2023-01-04 08:47:28,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:28,457 INFO:     Epoch: 44
2023-01-04 08:47:30,067 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4123510112365087, 'Total loss': 0.4123510112365087} | train loss {'Reaction outcome loss': 0.330485226600057, 'Total loss': 0.330485226600057}
2023-01-04 08:47:30,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:30,069 INFO:     Epoch: 45
2023-01-04 08:47:31,672 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40871665080388386, 'Total loss': 0.40871665080388386} | train loss {'Reaction outcome loss': 0.33415312978037953, 'Total loss': 0.33415312978037953}
2023-01-04 08:47:31,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:31,673 INFO:     Epoch: 46
2023-01-04 08:47:33,280 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4403500308593114, 'Total loss': 0.4403500308593114} | train loss {'Reaction outcome loss': 0.32623719065076245, 'Total loss': 0.32623719065076245}
2023-01-04 08:47:33,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:33,280 INFO:     Epoch: 47
2023-01-04 08:47:34,860 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43825679024060565, 'Total loss': 0.43825679024060565} | train loss {'Reaction outcome loss': 0.3242712983739202, 'Total loss': 0.3242712983739202}
2023-01-04 08:47:34,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:34,860 INFO:     Epoch: 48
2023-01-04 08:47:36,404 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4143654922644297, 'Total loss': 0.4143654922644297} | train loss {'Reaction outcome loss': 0.3219350150303684, 'Total loss': 0.3219350150303684}
2023-01-04 08:47:36,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:36,405 INFO:     Epoch: 49
2023-01-04 08:47:37,996 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43623405396938325, 'Total loss': 0.43623405396938325} | train loss {'Reaction outcome loss': 0.3195698960364735, 'Total loss': 0.3195698960364735}
2023-01-04 08:47:37,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:37,996 INFO:     Epoch: 50
2023-01-04 08:47:39,538 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4416120767593384, 'Total loss': 0.4416120767593384} | train loss {'Reaction outcome loss': 0.31256185980500095, 'Total loss': 0.31256185980500095}
2023-01-04 08:47:39,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:39,538 INFO:     Epoch: 51
2023-01-04 08:47:41,094 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4364832560221354, 'Total loss': 0.4364832560221354} | train loss {'Reaction outcome loss': 0.3119119398676566, 'Total loss': 0.3119119398676566}
2023-01-04 08:47:41,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:41,094 INFO:     Epoch: 52
2023-01-04 08:47:42,625 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4351316630840302, 'Total loss': 0.4351316630840302} | train loss {'Reaction outcome loss': 0.31338224377836627, 'Total loss': 0.31338224377836627}
2023-01-04 08:47:42,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:42,625 INFO:     Epoch: 53
2023-01-04 08:47:44,154 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4620363175868988, 'Total loss': 0.4620363175868988} | train loss {'Reaction outcome loss': 0.31179682619489024, 'Total loss': 0.31179682619489024}
2023-01-04 08:47:44,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:44,154 INFO:     Epoch: 54
2023-01-04 08:47:45,662 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4316569904486338, 'Total loss': 0.4316569904486338} | train loss {'Reaction outcome loss': 0.308811180837398, 'Total loss': 0.308811180837398}
2023-01-04 08:47:45,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:45,662 INFO:     Epoch: 55
2023-01-04 08:47:47,201 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45958505968252816, 'Total loss': 0.45958505968252816} | train loss {'Reaction outcome loss': 0.3113775400132158, 'Total loss': 0.3113775400132158}
2023-01-04 08:47:47,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:47,201 INFO:     Epoch: 56
2023-01-04 08:47:48,738 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4433601886034012, 'Total loss': 0.4433601886034012} | train loss {'Reaction outcome loss': 0.3055500707786231, 'Total loss': 0.3055500707786231}
2023-01-04 08:47:48,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:48,739 INFO:     Epoch: 57
2023-01-04 08:47:50,297 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44312225381533304, 'Total loss': 0.44312225381533304} | train loss {'Reaction outcome loss': 0.302645223582313, 'Total loss': 0.302645223582313}
2023-01-04 08:47:50,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:50,297 INFO:     Epoch: 58
2023-01-04 08:47:51,809 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43256349563598634, 'Total loss': 0.43256349563598634} | train loss {'Reaction outcome loss': 0.3022434516490376, 'Total loss': 0.3022434516490376}
2023-01-04 08:47:51,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:51,809 INFO:     Epoch: 59
2023-01-04 08:47:53,348 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.442052161693573, 'Total loss': 0.442052161693573} | train loss {'Reaction outcome loss': 0.3035811081963734, 'Total loss': 0.3035811081963734}
2023-01-04 08:47:53,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:53,348 INFO:     Epoch: 60
2023-01-04 08:47:54,844 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4314310570557912, 'Total loss': 0.4314310570557912} | train loss {'Reaction outcome loss': 0.2969898886869859, 'Total loss': 0.2969898886869859}
2023-01-04 08:47:54,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:54,845 INFO:     Epoch: 61
2023-01-04 08:47:56,382 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4534379780292511, 'Total loss': 0.4534379780292511} | train loss {'Reaction outcome loss': 0.2949989306176231, 'Total loss': 0.2949989306176231}
2023-01-04 08:47:56,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:56,382 INFO:     Epoch: 62
2023-01-04 08:47:57,925 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4541297972202301, 'Total loss': 0.4541297972202301} | train loss {'Reaction outcome loss': 0.2944824906324383, 'Total loss': 0.2944824906324383}
2023-01-04 08:47:57,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:57,925 INFO:     Epoch: 63
2023-01-04 08:47:59,485 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45389227469762167, 'Total loss': 0.45389227469762167} | train loss {'Reaction outcome loss': 0.2971700441065061, 'Total loss': 0.2971700441065061}
2023-01-04 08:47:59,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:47:59,485 INFO:     Epoch: 64
2023-01-04 08:48:01,013 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4370971530675888, 'Total loss': 0.4370971530675888} | train loss {'Reaction outcome loss': 0.29186031271288865, 'Total loss': 0.29186031271288865}
2023-01-04 08:48:01,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:01,013 INFO:     Epoch: 65
2023-01-04 08:48:02,575 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4375693360964457, 'Total loss': 0.4375693360964457} | train loss {'Reaction outcome loss': 0.28731885415087216, 'Total loss': 0.28731885415087216}
2023-01-04 08:48:02,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:02,575 INFO:     Epoch: 66
2023-01-04 08:48:04,133 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4336261421442032, 'Total loss': 0.4336261421442032} | train loss {'Reaction outcome loss': 0.2884969788256788, 'Total loss': 0.2884969788256788}
2023-01-04 08:48:04,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:04,134 INFO:     Epoch: 67
2023-01-04 08:48:05,698 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4258050978183746, 'Total loss': 0.4258050978183746} | train loss {'Reaction outcome loss': 0.28840982046549335, 'Total loss': 0.28840982046549335}
2023-01-04 08:48:05,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:05,699 INFO:     Epoch: 68
2023-01-04 08:48:07,238 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4469264487425486, 'Total loss': 0.4469264487425486} | train loss {'Reaction outcome loss': 0.2864165749455238, 'Total loss': 0.2864165749455238}
2023-01-04 08:48:07,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:07,238 INFO:     Epoch: 69
2023-01-04 08:48:08,795 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43582916458447774, 'Total loss': 0.43582916458447774} | train loss {'Reaction outcome loss': 0.2860640767064408, 'Total loss': 0.2860640767064408}
2023-01-04 08:48:08,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:08,795 INFO:     Epoch: 70
2023-01-04 08:48:10,318 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46374610165754954, 'Total loss': 0.46374610165754954} | train loss {'Reaction outcome loss': 0.285333037593939, 'Total loss': 0.285333037593939}
2023-01-04 08:48:10,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:10,318 INFO:     Epoch: 71
2023-01-04 08:48:11,853 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4347313195466995, 'Total loss': 0.4347313195466995} | train loss {'Reaction outcome loss': 0.2848643312896908, 'Total loss': 0.2848643312896908}
2023-01-04 08:48:11,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:11,854 INFO:     Epoch: 72
2023-01-04 08:48:13,388 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4403542121251424, 'Total loss': 0.4403542121251424} | train loss {'Reaction outcome loss': 0.2771125589327438, 'Total loss': 0.2771125589327438}
2023-01-04 08:48:13,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:13,389 INFO:     Epoch: 73
2023-01-04 08:48:14,919 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4355358084042867, 'Total loss': 0.4355358084042867} | train loss {'Reaction outcome loss': 0.2805731690685897, 'Total loss': 0.2805731690685897}
2023-01-04 08:48:14,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:14,919 INFO:     Epoch: 74
2023-01-04 08:48:16,474 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45596218208471934, 'Total loss': 0.45596218208471934} | train loss {'Reaction outcome loss': 0.28035613921654484, 'Total loss': 0.28035613921654484}
2023-01-04 08:48:16,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:16,474 INFO:     Epoch: 75
2023-01-04 08:48:18,023 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4550225426753362, 'Total loss': 0.4550225426753362} | train loss {'Reaction outcome loss': 0.27736037303387684, 'Total loss': 0.27736037303387684}
2023-01-04 08:48:18,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:18,024 INFO:     Epoch: 76
2023-01-04 08:48:19,552 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4558734675248464, 'Total loss': 0.4558734675248464} | train loss {'Reaction outcome loss': 0.27671549297923587, 'Total loss': 0.27671549297923587}
2023-01-04 08:48:19,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:19,552 INFO:     Epoch: 77
2023-01-04 08:48:21,085 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45084423224131265, 'Total loss': 0.45084423224131265} | train loss {'Reaction outcome loss': 0.2752943567686925, 'Total loss': 0.2752943567686925}
2023-01-04 08:48:21,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:21,085 INFO:     Epoch: 78
2023-01-04 08:48:22,644 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4539153307676315, 'Total loss': 0.4539153307676315} | train loss {'Reaction outcome loss': 0.2760015515488212, 'Total loss': 0.2760015515488212}
2023-01-04 08:48:22,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:22,644 INFO:     Epoch: 79
2023-01-04 08:48:24,185 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44357310235500336, 'Total loss': 0.44357310235500336} | train loss {'Reaction outcome loss': 0.2722221099683186, 'Total loss': 0.2722221099683186}
2023-01-04 08:48:24,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:24,186 INFO:     Epoch: 80
2023-01-04 08:48:25,733 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44303666849931084, 'Total loss': 0.44303666849931084} | train loss {'Reaction outcome loss': 0.27466943242797887, 'Total loss': 0.27466943242797887}
2023-01-04 08:48:25,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:25,733 INFO:     Epoch: 81
2023-01-04 08:48:27,273 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4354399174451828, 'Total loss': 0.4354399174451828} | train loss {'Reaction outcome loss': 0.27460516438595134, 'Total loss': 0.27460516438595134}
2023-01-04 08:48:27,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:27,274 INFO:     Epoch: 82
2023-01-04 08:48:28,807 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43973830540974934, 'Total loss': 0.43973830540974934} | train loss {'Reaction outcome loss': 0.26836828316432715, 'Total loss': 0.26836828316432715}
2023-01-04 08:48:28,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:28,807 INFO:     Epoch: 83
2023-01-04 08:48:30,330 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42571412920951845, 'Total loss': 0.42571412920951845} | train loss {'Reaction outcome loss': 0.2680803369186873, 'Total loss': 0.2680803369186873}
2023-01-04 08:48:30,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:30,330 INFO:     Epoch: 84
2023-01-04 08:48:31,883 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4240758935610453, 'Total loss': 0.4240758935610453} | train loss {'Reaction outcome loss': 0.2682615473567352, 'Total loss': 0.2682615473567352}
2023-01-04 08:48:31,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:31,884 INFO:     Epoch: 85
2023-01-04 08:48:33,458 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47032071352005006, 'Total loss': 0.47032071352005006} | train loss {'Reaction outcome loss': 0.26554180417944045, 'Total loss': 0.26554180417944045}
2023-01-04 08:48:33,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:33,458 INFO:     Epoch: 86
2023-01-04 08:48:35,020 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4593920012315114, 'Total loss': 0.4593920012315114} | train loss {'Reaction outcome loss': 0.2665889985098021, 'Total loss': 0.2665889985098021}
2023-01-04 08:48:35,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:35,020 INFO:     Epoch: 87
2023-01-04 08:48:36,556 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45889999071757, 'Total loss': 0.45889999071757} | train loss {'Reaction outcome loss': 0.26904258072158715, 'Total loss': 0.26904258072158715}
2023-01-04 08:48:36,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:36,557 INFO:     Epoch: 88
2023-01-04 08:48:38,077 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44168559511502586, 'Total loss': 0.44168559511502586} | train loss {'Reaction outcome loss': 0.26576196154865034, 'Total loss': 0.26576196154865034}
2023-01-04 08:48:38,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:38,078 INFO:     Epoch: 89
2023-01-04 08:48:39,586 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46744411687056225, 'Total loss': 0.46744411687056225} | train loss {'Reaction outcome loss': 0.26463910007346286, 'Total loss': 0.26463910007346286}
2023-01-04 08:48:39,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:39,586 INFO:     Epoch: 90
2023-01-04 08:48:41,123 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49700523614883424, 'Total loss': 0.49700523614883424} | train loss {'Reaction outcome loss': 0.2590156586799961, 'Total loss': 0.2590156586799961}
2023-01-04 08:48:41,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:41,124 INFO:     Epoch: 91
2023-01-04 08:48:42,682 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44634289741516114, 'Total loss': 0.44634289741516114} | train loss {'Reaction outcome loss': 0.25609275046056207, 'Total loss': 0.25609275046056207}
2023-01-04 08:48:42,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:42,682 INFO:     Epoch: 92
2023-01-04 08:48:44,223 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4402544816335042, 'Total loss': 0.4402544816335042} | train loss {'Reaction outcome loss': 0.26145601593447426, 'Total loss': 0.26145601593447426}
2023-01-04 08:48:44,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:44,224 INFO:     Epoch: 93
2023-01-04 08:48:45,763 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4520201007525126, 'Total loss': 0.4520201007525126} | train loss {'Reaction outcome loss': 0.26172835124235083, 'Total loss': 0.26172835124235083}
2023-01-04 08:48:45,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:45,763 INFO:     Epoch: 94
2023-01-04 08:48:47,295 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4824889709552129, 'Total loss': 0.4824889709552129} | train loss {'Reaction outcome loss': 0.25991659002364986, 'Total loss': 0.25991659002364986}
2023-01-04 08:48:47,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:47,296 INFO:     Epoch: 95
2023-01-04 08:48:48,830 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4377671827872594, 'Total loss': 0.4377671827872594} | train loss {'Reaction outcome loss': 0.25988661772469535, 'Total loss': 0.25988661772469535}
2023-01-04 08:48:48,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:48,830 INFO:     Epoch: 96
2023-01-04 08:48:50,387 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4703734854857127, 'Total loss': 0.4703734854857127} | train loss {'Reaction outcome loss': 0.25879421601765346, 'Total loss': 0.25879421601765346}
2023-01-04 08:48:50,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:50,387 INFO:     Epoch: 97
2023-01-04 08:48:51,922 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4715368072191874, 'Total loss': 0.4715368072191874} | train loss {'Reaction outcome loss': 0.25649919233074153, 'Total loss': 0.25649919233074153}
2023-01-04 08:48:51,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:51,923 INFO:     Epoch: 98
2023-01-04 08:48:53,463 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45128656923770905, 'Total loss': 0.45128656923770905} | train loss {'Reaction outcome loss': 0.25734064624692404, 'Total loss': 0.25734064624692404}
2023-01-04 08:48:53,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:53,463 INFO:     Epoch: 99
2023-01-04 08:48:55,024 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46923862397670746, 'Total loss': 0.46923862397670746} | train loss {'Reaction outcome loss': 0.2530906276682215, 'Total loss': 0.2530906276682215}
2023-01-04 08:48:55,024 INFO:     Best model found after epoch 32 of 100.
2023-01-04 08:48:55,024 INFO:   Done with stage: TRAINING
2023-01-04 08:48:55,024 INFO:   Starting stage: EVALUATION
2023-01-04 08:48:55,157 INFO:   Done with stage: EVALUATION
2023-01-04 08:48:55,157 INFO:   Leaving out SEQ value Fold_4
2023-01-04 08:48:55,170 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 08:48:55,170 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:48:55,816 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:48:55,816 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:48:55,884 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:48:55,884 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:48:55,884 INFO:     No hyperparam tuning for this model
2023-01-04 08:48:55,884 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:48:55,884 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:48:55,885 INFO:     None feature selector for col prot
2023-01-04 08:48:55,885 INFO:     None feature selector for col prot
2023-01-04 08:48:55,885 INFO:     None feature selector for col prot
2023-01-04 08:48:55,885 INFO:     None feature selector for col chem
2023-01-04 08:48:55,886 INFO:     None feature selector for col chem
2023-01-04 08:48:55,886 INFO:     None feature selector for col chem
2023-01-04 08:48:55,886 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:48:55,886 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:48:55,887 INFO:     Number of params in model 70111
2023-01-04 08:48:55,890 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:48:55,890 INFO:   Starting stage: TRAINING
2023-01-04 08:48:55,932 INFO:     Val loss before train {'Reaction outcome loss': 1.0137154618899027, 'Total loss': 1.0137154618899027}
2023-01-04 08:48:55,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:55,933 INFO:     Epoch: 0
2023-01-04 08:48:57,465 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6971589207649231, 'Total loss': 0.6971589207649231} | train loss {'Reaction outcome loss': 0.8594887513613355, 'Total loss': 0.8594887513613355}
2023-01-04 08:48:57,465 INFO:     Found new best model at epoch 0
2023-01-04 08:48:57,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:57,466 INFO:     Epoch: 1
2023-01-04 08:48:59,025 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6182407736778259, 'Total loss': 0.6182407736778259} | train loss {'Reaction outcome loss': 0.7061207082824431, 'Total loss': 0.7061207082824431}
2023-01-04 08:48:59,025 INFO:     Found new best model at epoch 1
2023-01-04 08:48:59,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:48:59,026 INFO:     Epoch: 2
2023-01-04 08:49:00,587 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5403845032056173, 'Total loss': 0.5403845032056173} | train loss {'Reaction outcome loss': 0.6001258136475108, 'Total loss': 0.6001258136475108}
2023-01-04 08:49:00,588 INFO:     Found new best model at epoch 2
2023-01-04 08:49:00,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:00,589 INFO:     Epoch: 3
2023-01-04 08:49:02,147 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5447762171427409, 'Total loss': 0.5447762171427409} | train loss {'Reaction outcome loss': 0.547694575687722, 'Total loss': 0.547694575687722}
2023-01-04 08:49:02,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:02,148 INFO:     Epoch: 4
2023-01-04 08:49:03,714 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5168402314186096, 'Total loss': 0.5168402314186096} | train loss {'Reaction outcome loss': 0.5227550283560286, 'Total loss': 0.5227550283560286}
2023-01-04 08:49:03,715 INFO:     Found new best model at epoch 4
2023-01-04 08:49:03,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:03,715 INFO:     Epoch: 5
2023-01-04 08:49:05,268 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4741039156913757, 'Total loss': 0.4741039156913757} | train loss {'Reaction outcome loss': 0.5066253498088622, 'Total loss': 0.5066253498088622}
2023-01-04 08:49:05,269 INFO:     Found new best model at epoch 5
2023-01-04 08:49:05,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:05,269 INFO:     Epoch: 6
2023-01-04 08:49:06,801 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.470266584555308, 'Total loss': 0.470266584555308} | train loss {'Reaction outcome loss': 0.4942345073905544, 'Total loss': 0.4942345073905544}
2023-01-04 08:49:06,801 INFO:     Found new best model at epoch 6
2023-01-04 08:49:06,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:06,802 INFO:     Epoch: 7
2023-01-04 08:49:08,378 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5053571452697118, 'Total loss': 0.5053571452697118} | train loss {'Reaction outcome loss': 0.48822891748294345, 'Total loss': 0.48822891748294345}
2023-01-04 08:49:08,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:08,379 INFO:     Epoch: 8
2023-01-04 08:49:09,981 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47341720163822176, 'Total loss': 0.47341720163822176} | train loss {'Reaction outcome loss': 0.47194627934283967, 'Total loss': 0.47194627934283967}
2023-01-04 08:49:09,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:09,981 INFO:     Epoch: 9
2023-01-04 08:49:11,572 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4617032493154208, 'Total loss': 0.4617032493154208} | train loss {'Reaction outcome loss': 0.4655058431790035, 'Total loss': 0.4655058431790035}
2023-01-04 08:49:11,573 INFO:     Found new best model at epoch 9
2023-01-04 08:49:11,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:11,574 INFO:     Epoch: 10
2023-01-04 08:49:13,118 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.460845402876536, 'Total loss': 0.460845402876536} | train loss {'Reaction outcome loss': 0.4785569914333198, 'Total loss': 0.4785569914333198}
2023-01-04 08:49:13,118 INFO:     Found new best model at epoch 10
2023-01-04 08:49:13,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:13,119 INFO:     Epoch: 11
2023-01-04 08:49:14,716 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46945381462574004, 'Total loss': 0.46945381462574004} | train loss {'Reaction outcome loss': 0.47326821283153864, 'Total loss': 0.47326821283153864}
2023-01-04 08:49:14,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:14,717 INFO:     Epoch: 12
2023-01-04 08:49:16,254 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46759085257848104, 'Total loss': 0.46759085257848104} | train loss {'Reaction outcome loss': 0.4723040605152863, 'Total loss': 0.4723040605152863}
2023-01-04 08:49:16,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:16,254 INFO:     Epoch: 13
2023-01-04 08:49:17,823 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4525622089703878, 'Total loss': 0.4525622089703878} | train loss {'Reaction outcome loss': 0.44899429526665935, 'Total loss': 0.44899429526665935}
2023-01-04 08:49:17,824 INFO:     Found new best model at epoch 13
2023-01-04 08:49:17,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:17,825 INFO:     Epoch: 14
2023-01-04 08:49:19,389 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48185880184173585, 'Total loss': 0.48185880184173585} | train loss {'Reaction outcome loss': 0.4580322929415042, 'Total loss': 0.4580322929415042}
2023-01-04 08:49:19,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:19,390 INFO:     Epoch: 15
2023-01-04 08:49:20,954 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47895811398824056, 'Total loss': 0.47895811398824056} | train loss {'Reaction outcome loss': 0.432637321589383, 'Total loss': 0.432637321589383}
2023-01-04 08:49:20,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:20,954 INFO:     Epoch: 16
2023-01-04 08:49:22,452 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4513260314861933, 'Total loss': 0.4513260314861933} | train loss {'Reaction outcome loss': 0.42845727355587226, 'Total loss': 0.42845727355587226}
2023-01-04 08:49:22,453 INFO:     Found new best model at epoch 16
2023-01-04 08:49:22,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:22,453 INFO:     Epoch: 17
2023-01-04 08:49:24,000 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46202571988105773, 'Total loss': 0.46202571988105773} | train loss {'Reaction outcome loss': 0.4244757630055666, 'Total loss': 0.4244757630055666}
2023-01-04 08:49:24,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:24,000 INFO:     Epoch: 18
2023-01-04 08:49:25,539 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46111618479092914, 'Total loss': 0.46111618479092914} | train loss {'Reaction outcome loss': 0.4197957111333591, 'Total loss': 0.4197957111333591}
2023-01-04 08:49:25,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:25,539 INFO:     Epoch: 19
2023-01-04 08:49:27,099 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4459278682867686, 'Total loss': 0.4459278682867686} | train loss {'Reaction outcome loss': 0.4261834941048553, 'Total loss': 0.4261834941048553}
2023-01-04 08:49:27,100 INFO:     Found new best model at epoch 19
2023-01-04 08:49:27,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:27,100 INFO:     Epoch: 20
2023-01-04 08:49:28,663 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4439127524693807, 'Total loss': 0.4439127524693807} | train loss {'Reaction outcome loss': 0.4131816647401085, 'Total loss': 0.4131816647401085}
2023-01-04 08:49:28,663 INFO:     Found new best model at epoch 20
2023-01-04 08:49:28,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:28,664 INFO:     Epoch: 21
2023-01-04 08:49:30,253 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.425348957379659, 'Total loss': 0.425348957379659} | train loss {'Reaction outcome loss': 0.40297533919152373, 'Total loss': 0.40297533919152373}
2023-01-04 08:49:30,254 INFO:     Found new best model at epoch 21
2023-01-04 08:49:30,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:30,255 INFO:     Epoch: 22
2023-01-04 08:49:31,829 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4327817589044571, 'Total loss': 0.4327817589044571} | train loss {'Reaction outcome loss': 0.4012204695837167, 'Total loss': 0.4012204695837167}
2023-01-04 08:49:31,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:31,829 INFO:     Epoch: 23
2023-01-04 08:49:33,397 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4290195991595586, 'Total loss': 0.4290195991595586} | train loss {'Reaction outcome loss': 0.3993312191876981, 'Total loss': 0.3993312191876981}
2023-01-04 08:49:33,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:33,397 INFO:     Epoch: 24
2023-01-04 08:49:35,022 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41651811401049293, 'Total loss': 0.41651811401049293} | train loss {'Reaction outcome loss': 0.3973683424267, 'Total loss': 0.3973683424267}
2023-01-04 08:49:35,022 INFO:     Found new best model at epoch 24
2023-01-04 08:49:35,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:35,023 INFO:     Epoch: 25
2023-01-04 08:49:36,651 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4312181899944941, 'Total loss': 0.4312181899944941} | train loss {'Reaction outcome loss': 0.39120410447197873, 'Total loss': 0.39120410447197873}
2023-01-04 08:49:36,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:36,651 INFO:     Epoch: 26
2023-01-04 08:49:38,275 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4517196834087372, 'Total loss': 0.4517196834087372} | train loss {'Reaction outcome loss': 0.3904822107887004, 'Total loss': 0.3904822107887004}
2023-01-04 08:49:38,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:38,275 INFO:     Epoch: 27
2023-01-04 08:49:39,894 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44156248768170675, 'Total loss': 0.44156248768170675} | train loss {'Reaction outcome loss': 0.38864479183583805, 'Total loss': 0.38864479183583805}
2023-01-04 08:49:39,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:39,894 INFO:     Epoch: 28
2023-01-04 08:49:41,461 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4323253115018209, 'Total loss': 0.4323253115018209} | train loss {'Reaction outcome loss': 0.3821217525831383, 'Total loss': 0.3821217525831383}
2023-01-04 08:49:41,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:41,462 INFO:     Epoch: 29
2023-01-04 08:49:43,036 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4409420470396678, 'Total loss': 0.4409420470396678} | train loss {'Reaction outcome loss': 0.39143783323790715, 'Total loss': 0.39143783323790715}
2023-01-04 08:49:43,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:43,036 INFO:     Epoch: 30
2023-01-04 08:49:44,640 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4278888056675593, 'Total loss': 0.4278888056675593} | train loss {'Reaction outcome loss': 0.41611824173858203, 'Total loss': 0.41611824173858203}
2023-01-04 08:49:44,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:44,640 INFO:     Epoch: 31
2023-01-04 08:49:46,240 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4269947836796443, 'Total loss': 0.4269947836796443} | train loss {'Reaction outcome loss': 0.3856985282044912, 'Total loss': 0.3856985282044912}
2023-01-04 08:49:46,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:46,240 INFO:     Epoch: 32
2023-01-04 08:49:47,847 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46100881447394687, 'Total loss': 0.46100881447394687} | train loss {'Reaction outcome loss': 0.3773027758073548, 'Total loss': 0.3773027758073548}
2023-01-04 08:49:47,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:47,849 INFO:     Epoch: 33
2023-01-04 08:49:49,370 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41193752189477284, 'Total loss': 0.41193752189477284} | train loss {'Reaction outcome loss': 0.3766396834879466, 'Total loss': 0.3766396834879466}
2023-01-04 08:49:49,370 INFO:     Found new best model at epoch 33
2023-01-04 08:49:49,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:49,371 INFO:     Epoch: 34
2023-01-04 08:49:50,952 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42155165870984396, 'Total loss': 0.42155165870984396} | train loss {'Reaction outcome loss': 0.3704921208807956, 'Total loss': 0.3704921208807956}
2023-01-04 08:49:50,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:50,953 INFO:     Epoch: 35
2023-01-04 08:49:52,491 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44343098004659015, 'Total loss': 0.44343098004659015} | train loss {'Reaction outcome loss': 0.3638488162963557, 'Total loss': 0.3638488162963557}
2023-01-04 08:49:52,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:52,492 INFO:     Epoch: 36
2023-01-04 08:49:54,050 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4298877646525701, 'Total loss': 0.4298877646525701} | train loss {'Reaction outcome loss': 0.36251497419847956, 'Total loss': 0.36251497419847956}
2023-01-04 08:49:54,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:54,050 INFO:     Epoch: 37
2023-01-04 08:49:55,616 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4259603500366211, 'Total loss': 0.4259603500366211} | train loss {'Reaction outcome loss': 0.36004406489445356, 'Total loss': 0.36004406489445356}
2023-01-04 08:49:55,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:55,616 INFO:     Epoch: 38
2023-01-04 08:49:57,165 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40295362696051595, 'Total loss': 0.40295362696051595} | train loss {'Reaction outcome loss': 0.3585008329347424, 'Total loss': 0.3585008329347424}
2023-01-04 08:49:57,165 INFO:     Found new best model at epoch 38
2023-01-04 08:49:57,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:57,166 INFO:     Epoch: 39
2023-01-04 08:49:58,703 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41781648298104607, 'Total loss': 0.41781648298104607} | train loss {'Reaction outcome loss': 0.364349974694736, 'Total loss': 0.364349974694736}
2023-01-04 08:49:58,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:49:58,703 INFO:     Epoch: 40
2023-01-04 08:50:00,332 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4442797899246216, 'Total loss': 0.4442797899246216} | train loss {'Reaction outcome loss': 0.35240001015473105, 'Total loss': 0.35240001015473105}
2023-01-04 08:50:00,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:00,332 INFO:     Epoch: 41
2023-01-04 08:50:01,912 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4093346784512202, 'Total loss': 0.4093346784512202} | train loss {'Reaction outcome loss': 0.3587380051359777, 'Total loss': 0.3587380051359777}
2023-01-04 08:50:01,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:01,912 INFO:     Epoch: 42
2023-01-04 08:50:03,521 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4048742155234019, 'Total loss': 0.4048742155234019} | train loss {'Reaction outcome loss': 0.3467298395854954, 'Total loss': 0.3467298395854954}
2023-01-04 08:50:03,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:03,521 INFO:     Epoch: 43
2023-01-04 08:50:05,137 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4269239127635956, 'Total loss': 0.4269239127635956} | train loss {'Reaction outcome loss': 0.34145068509531196, 'Total loss': 0.34145068509531196}
2023-01-04 08:50:05,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:05,137 INFO:     Epoch: 44
2023-01-04 08:50:06,770 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4021608601013819, 'Total loss': 0.4021608601013819} | train loss {'Reaction outcome loss': 0.3425980206748531, 'Total loss': 0.3425980206748531}
2023-01-04 08:50:06,771 INFO:     Found new best model at epoch 44
2023-01-04 08:50:06,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:06,771 INFO:     Epoch: 45
2023-01-04 08:50:08,344 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38985704630613327, 'Total loss': 0.38985704630613327} | train loss {'Reaction outcome loss': 0.33397230814022105, 'Total loss': 0.33397230814022105}
2023-01-04 08:50:08,344 INFO:     Found new best model at epoch 45
2023-01-04 08:50:08,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:08,344 INFO:     Epoch: 46
2023-01-04 08:50:09,936 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4091556747754415, 'Total loss': 0.4091556747754415} | train loss {'Reaction outcome loss': 0.3379941251081671, 'Total loss': 0.3379941251081671}
2023-01-04 08:50:09,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:09,936 INFO:     Epoch: 47
2023-01-04 08:50:11,536 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39564921458562213, 'Total loss': 0.39564921458562213} | train loss {'Reaction outcome loss': 0.33241366042985, 'Total loss': 0.33241366042985}
2023-01-04 08:50:11,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:11,536 INFO:     Epoch: 48
2023-01-04 08:50:13,136 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40644915054241815, 'Total loss': 0.40644915054241815} | train loss {'Reaction outcome loss': 0.331553157472956, 'Total loss': 0.331553157472956}
2023-01-04 08:50:13,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:13,137 INFO:     Epoch: 49
2023-01-04 08:50:14,756 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3979581465323766, 'Total loss': 0.3979581465323766} | train loss {'Reaction outcome loss': 0.33002044539917746, 'Total loss': 0.33002044539917746}
2023-01-04 08:50:14,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:14,756 INFO:     Epoch: 50
2023-01-04 08:50:16,357 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4146690219640732, 'Total loss': 0.4146690219640732} | train loss {'Reaction outcome loss': 0.32769982581553253, 'Total loss': 0.32769982581553253}
2023-01-04 08:50:16,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:16,357 INFO:     Epoch: 51
2023-01-04 08:50:17,939 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.414695597688357, 'Total loss': 0.414695597688357} | train loss {'Reaction outcome loss': 0.324990325953231, 'Total loss': 0.324990325953231}
2023-01-04 08:50:17,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:17,939 INFO:     Epoch: 52
2023-01-04 08:50:19,512 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.426441901922226, 'Total loss': 0.426441901922226} | train loss {'Reaction outcome loss': 0.3257488083310317, 'Total loss': 0.3257488083310317}
2023-01-04 08:50:19,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:19,513 INFO:     Epoch: 53
2023-01-04 08:50:21,105 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4433908998966217, 'Total loss': 0.4433908998966217} | train loss {'Reaction outcome loss': 0.34286064101194125, 'Total loss': 0.34286064101194125}
2023-01-04 08:50:21,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:21,105 INFO:     Epoch: 54
2023-01-04 08:50:22,716 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39757716556390127, 'Total loss': 0.39757716556390127} | train loss {'Reaction outcome loss': 0.34971562280670565, 'Total loss': 0.34971562280670565}
2023-01-04 08:50:22,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:22,717 INFO:     Epoch: 55
2023-01-04 08:50:24,313 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39268295268217723, 'Total loss': 0.39268295268217723} | train loss {'Reaction outcome loss': 0.32231809913882636, 'Total loss': 0.32231809913882636}
2023-01-04 08:50:24,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:24,313 INFO:     Epoch: 56
2023-01-04 08:50:25,874 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41917565564314524, 'Total loss': 0.41917565564314524} | train loss {'Reaction outcome loss': 0.31500175947566394, 'Total loss': 0.31500175947566394}
2023-01-04 08:50:25,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:25,874 INFO:     Epoch: 57
2023-01-04 08:50:27,501 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40666599770387013, 'Total loss': 0.40666599770387013} | train loss {'Reaction outcome loss': 0.3177233200892089, 'Total loss': 0.3177233200892089}
2023-01-04 08:50:27,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:27,501 INFO:     Epoch: 58
2023-01-04 08:50:29,066 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42614076534907025, 'Total loss': 0.42614076534907025} | train loss {'Reaction outcome loss': 0.31784465733537637, 'Total loss': 0.31784465733537637}
2023-01-04 08:50:29,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:29,066 INFO:     Epoch: 59
2023-01-04 08:50:30,680 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4037388612826665, 'Total loss': 0.4037388612826665} | train loss {'Reaction outcome loss': 0.36436679636708635, 'Total loss': 0.36436679636708635}
2023-01-04 08:50:30,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:30,680 INFO:     Epoch: 60
2023-01-04 08:50:32,301 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4138853336373965, 'Total loss': 0.4138853336373965} | train loss {'Reaction outcome loss': 0.31382974777817796, 'Total loss': 0.31382974777817796}
2023-01-04 08:50:32,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:32,302 INFO:     Epoch: 61
2023-01-04 08:50:33,921 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4089626590410868, 'Total loss': 0.4089626590410868} | train loss {'Reaction outcome loss': 0.3105735433434703, 'Total loss': 0.3105735433434703}
2023-01-04 08:50:33,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:33,922 INFO:     Epoch: 62
2023-01-04 08:50:35,503 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40052679777145384, 'Total loss': 0.40052679777145384} | train loss {'Reaction outcome loss': 0.3079434194318626, 'Total loss': 0.3079434194318626}
2023-01-04 08:50:35,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:35,503 INFO:     Epoch: 63
2023-01-04 08:50:37,112 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4158285101254781, 'Total loss': 0.4158285101254781} | train loss {'Reaction outcome loss': 0.3080728312886187, 'Total loss': 0.3080728312886187}
2023-01-04 08:50:37,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:37,112 INFO:     Epoch: 64
2023-01-04 08:50:38,708 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40062757233778634, 'Total loss': 0.40062757233778634} | train loss {'Reaction outcome loss': 0.30406613300716423, 'Total loss': 0.30406613300716423}
2023-01-04 08:50:38,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:38,708 INFO:     Epoch: 65
2023-01-04 08:50:40,332 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3858488800625006, 'Total loss': 0.3858488800625006} | train loss {'Reaction outcome loss': 0.30984914035576844, 'Total loss': 0.30984914035576844}
2023-01-04 08:50:40,333 INFO:     Found new best model at epoch 65
2023-01-04 08:50:40,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:40,333 INFO:     Epoch: 66
2023-01-04 08:50:41,961 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38237285713354746, 'Total loss': 0.38237285713354746} | train loss {'Reaction outcome loss': 0.3085978543191838, 'Total loss': 0.3085978543191838}
2023-01-04 08:50:41,961 INFO:     Found new best model at epoch 66
2023-01-04 08:50:41,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:41,962 INFO:     Epoch: 67
2023-01-04 08:50:43,561 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43049981792767844, 'Total loss': 0.43049981792767844} | train loss {'Reaction outcome loss': 0.3000614190393168, 'Total loss': 0.3000614190393168}
2023-01-04 08:50:43,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:43,561 INFO:     Epoch: 68
2023-01-04 08:50:45,127 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40327201386292777, 'Total loss': 0.40327201386292777} | train loss {'Reaction outcome loss': 0.3036784375815288, 'Total loss': 0.3036784375815288}
2023-01-04 08:50:45,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:45,127 INFO:     Epoch: 69
2023-01-04 08:50:46,701 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38843129376570384, 'Total loss': 0.38843129376570384} | train loss {'Reaction outcome loss': 0.3045390075324879, 'Total loss': 0.3045390075324879}
2023-01-04 08:50:46,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:46,701 INFO:     Epoch: 70
2023-01-04 08:50:48,317 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44367466966311137, 'Total loss': 0.44367466966311137} | train loss {'Reaction outcome loss': 0.300746807416874, 'Total loss': 0.300746807416874}
2023-01-04 08:50:48,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:48,317 INFO:     Epoch: 71
2023-01-04 08:50:49,931 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41687074104944866, 'Total loss': 0.41687074104944866} | train loss {'Reaction outcome loss': 0.2977637532774521, 'Total loss': 0.2977637532774521}
2023-01-04 08:50:49,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:49,931 INFO:     Epoch: 72
2023-01-04 08:50:51,560 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4030450850725174, 'Total loss': 0.4030450850725174} | train loss {'Reaction outcome loss': 0.2970000000339865, 'Total loss': 0.2970000000339865}
2023-01-04 08:50:51,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:51,560 INFO:     Epoch: 73
2023-01-04 08:50:53,144 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39720713198184965, 'Total loss': 0.39720713198184965} | train loss {'Reaction outcome loss': 0.2887453650650771, 'Total loss': 0.2887453650650771}
2023-01-04 08:50:53,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:53,144 INFO:     Epoch: 74
2023-01-04 08:50:54,759 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37652116318543755, 'Total loss': 0.37652116318543755} | train loss {'Reaction outcome loss': 0.29276707931716955, 'Total loss': 0.29276707931716955}
2023-01-04 08:50:54,760 INFO:     Found new best model at epoch 74
2023-01-04 08:50:54,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:54,760 INFO:     Epoch: 75
2023-01-04 08:50:56,338 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41397652129332224, 'Total loss': 0.41397652129332224} | train loss {'Reaction outcome loss': 0.28791407981475786, 'Total loss': 0.28791407981475786}
2023-01-04 08:50:56,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:56,338 INFO:     Epoch: 76
2023-01-04 08:50:57,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38660361667474114, 'Total loss': 0.38660361667474114} | train loss {'Reaction outcome loss': 0.2893491015129257, 'Total loss': 0.2893491015129257}
2023-01-04 08:50:57,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:57,937 INFO:     Epoch: 77
2023-01-04 08:50:59,549 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4130911489327749, 'Total loss': 0.4130911489327749} | train loss {'Reaction outcome loss': 0.2887862420276455, 'Total loss': 0.2887862420276455}
2023-01-04 08:50:59,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:50:59,549 INFO:     Epoch: 78
2023-01-04 08:51:01,156 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3875554462273916, 'Total loss': 0.3875554462273916} | train loss {'Reaction outcome loss': 0.29739835261758685, 'Total loss': 0.29739835261758685}
2023-01-04 08:51:01,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:01,157 INFO:     Epoch: 79
2023-01-04 08:51:02,732 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4168808917204539, 'Total loss': 0.4168808917204539} | train loss {'Reaction outcome loss': 0.2909798250682112, 'Total loss': 0.2909798250682112}
2023-01-04 08:51:02,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:02,732 INFO:     Epoch: 80
2023-01-04 08:51:04,334 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4010433594385783, 'Total loss': 0.4010433594385783} | train loss {'Reaction outcome loss': 0.2895691600515255, 'Total loss': 0.2895691600515255}
2023-01-04 08:51:04,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:04,334 INFO:     Epoch: 81
2023-01-04 08:51:05,920 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3813022414843241, 'Total loss': 0.3813022414843241} | train loss {'Reaction outcome loss': 0.285220987993576, 'Total loss': 0.285220987993576}
2023-01-04 08:51:05,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:05,921 INFO:     Epoch: 82
2023-01-04 08:51:07,541 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.385922834277153, 'Total loss': 0.385922834277153} | train loss {'Reaction outcome loss': 0.2868166638781195, 'Total loss': 0.2868166638781195}
2023-01-04 08:51:07,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:07,541 INFO:     Epoch: 83
2023-01-04 08:51:09,168 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3942355791727702, 'Total loss': 0.3942355791727702} | train loss {'Reaction outcome loss': 0.28642515016490244, 'Total loss': 0.28642515016490244}
2023-01-04 08:51:09,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:09,168 INFO:     Epoch: 84
2023-01-04 08:51:10,798 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4201363205909729, 'Total loss': 0.4201363205909729} | train loss {'Reaction outcome loss': 0.2990456932642754, 'Total loss': 0.2990456932642754}
2023-01-04 08:51:10,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:10,798 INFO:     Epoch: 85
2023-01-04 08:51:12,382 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40583814680576324, 'Total loss': 0.40583814680576324} | train loss {'Reaction outcome loss': 0.304118639452086, 'Total loss': 0.304118639452086}
2023-01-04 08:51:12,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:12,382 INFO:     Epoch: 86
2023-01-04 08:51:13,953 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38574307958285015, 'Total loss': 0.38574307958285015} | train loss {'Reaction outcome loss': 0.2808502827993716, 'Total loss': 0.2808502827993716}
2023-01-04 08:51:13,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:13,954 INFO:     Epoch: 87
2023-01-04 08:51:15,568 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43392235040664673, 'Total loss': 0.43392235040664673} | train loss {'Reaction outcome loss': 0.2730942624543061, 'Total loss': 0.2730942624543061}
2023-01-04 08:51:15,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:15,569 INFO:     Epoch: 88
2023-01-04 08:51:17,181 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4045153160889943, 'Total loss': 0.4045153160889943} | train loss {'Reaction outcome loss': 0.2766432209831217, 'Total loss': 0.2766432209831217}
2023-01-04 08:51:17,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:17,181 INFO:     Epoch: 89
2023-01-04 08:51:18,781 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37699078222115834, 'Total loss': 0.37699078222115834} | train loss {'Reaction outcome loss': 0.2896550009769482, 'Total loss': 0.2896550009769482}
2023-01-04 08:51:18,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:18,782 INFO:     Epoch: 90
2023-01-04 08:51:20,339 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38714675505956014, 'Total loss': 0.38714675505956014} | train loss {'Reaction outcome loss': 0.27114496082200223, 'Total loss': 0.27114496082200223}
2023-01-04 08:51:20,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:20,340 INFO:     Epoch: 91
2023-01-04 08:51:21,960 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3798357864220937, 'Total loss': 0.3798357864220937} | train loss {'Reaction outcome loss': 0.2721834440101478, 'Total loss': 0.2721834440101478}
2023-01-04 08:51:21,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:21,960 INFO:     Epoch: 92
2023-01-04 08:51:23,511 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.419484161088864, 'Total loss': 0.419484161088864} | train loss {'Reaction outcome loss': 0.28217567789597786, 'Total loss': 0.28217567789597786}
2023-01-04 08:51:23,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:23,511 INFO:     Epoch: 93
2023-01-04 08:51:25,130 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39707502772410713, 'Total loss': 0.39707502772410713} | train loss {'Reaction outcome loss': 0.3112069210113512, 'Total loss': 0.3112069210113512}
2023-01-04 08:51:25,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:25,131 INFO:     Epoch: 94
2023-01-04 08:51:26,742 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40668868919213613, 'Total loss': 0.40668868919213613} | train loss {'Reaction outcome loss': 0.2712795914326241, 'Total loss': 0.2712795914326241}
2023-01-04 08:51:26,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:26,742 INFO:     Epoch: 95
2023-01-04 08:51:28,365 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.388728233675162, 'Total loss': 0.388728233675162} | train loss {'Reaction outcome loss': 0.2742429609272116, 'Total loss': 0.2742429609272116}
2023-01-04 08:51:28,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:28,365 INFO:     Epoch: 96
2023-01-04 08:51:29,931 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3793889065583547, 'Total loss': 0.3793889065583547} | train loss {'Reaction outcome loss': 0.2773173967835264, 'Total loss': 0.2773173967835264}
2023-01-04 08:51:29,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:29,932 INFO:     Epoch: 97
2023-01-04 08:51:31,546 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38389503260453545, 'Total loss': 0.38389503260453545} | train loss {'Reaction outcome loss': 0.285472326081894, 'Total loss': 0.285472326081894}
2023-01-04 08:51:31,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:31,546 INFO:     Epoch: 98
2023-01-04 08:51:32,655 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3847461005051931, 'Total loss': 0.3847461005051931} | train loss {'Reaction outcome loss': 0.2728333860986691, 'Total loss': 0.2728333860986691}
2023-01-04 08:51:32,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:32,655 INFO:     Epoch: 99
2023-01-04 08:51:33,684 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39239639838536583, 'Total loss': 0.39239639838536583} | train loss {'Reaction outcome loss': 0.2689805793883009, 'Total loss': 0.2689805793883009}
2023-01-04 08:51:33,684 INFO:     Best model found after epoch 75 of 100.
2023-01-04 08:51:33,684 INFO:   Done with stage: TRAINING
2023-01-04 08:51:33,684 INFO:   Starting stage: EVALUATION
2023-01-04 08:51:33,810 INFO:   Done with stage: EVALUATION
2023-01-04 08:51:33,810 INFO:   Leaving out SEQ value Fold_5
2023-01-04 08:51:33,823 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 08:51:33,823 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:51:34,468 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:51:34,468 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:51:34,537 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:51:34,537 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:51:34,537 INFO:     No hyperparam tuning for this model
2023-01-04 08:51:34,537 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:51:34,537 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:51:34,538 INFO:     None feature selector for col prot
2023-01-04 08:51:34,538 INFO:     None feature selector for col prot
2023-01-04 08:51:34,538 INFO:     None feature selector for col prot
2023-01-04 08:51:34,538 INFO:     None feature selector for col chem
2023-01-04 08:51:34,539 INFO:     None feature selector for col chem
2023-01-04 08:51:34,539 INFO:     None feature selector for col chem
2023-01-04 08:51:34,539 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:51:34,539 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:51:34,540 INFO:     Number of params in model 70111
2023-01-04 08:51:34,543 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:51:34,543 INFO:   Starting stage: TRAINING
2023-01-04 08:51:34,577 INFO:     Val loss before train {'Reaction outcome loss': 1.0221959431966146, 'Total loss': 1.0221959431966146}
2023-01-04 08:51:34,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:34,577 INFO:     Epoch: 0
2023-01-04 08:51:35,605 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7620314876238505, 'Total loss': 0.7620314876238505} | train loss {'Reaction outcome loss': 0.8247819062005188, 'Total loss': 0.8247819062005188}
2023-01-04 08:51:35,605 INFO:     Found new best model at epoch 0
2023-01-04 08:51:35,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:35,606 INFO:     Epoch: 1
2023-01-04 08:51:36,788 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6386678000291188, 'Total loss': 0.6386678000291188} | train loss {'Reaction outcome loss': 0.6681140652681411, 'Total loss': 0.6681140652681411}
2023-01-04 08:51:36,788 INFO:     Found new best model at epoch 1
2023-01-04 08:51:36,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:36,789 INFO:     Epoch: 2
2023-01-04 08:51:38,420 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5946959535280864, 'Total loss': 0.5946959535280864} | train loss {'Reaction outcome loss': 0.5793489979013152, 'Total loss': 0.5793489979013152}
2023-01-04 08:51:38,420 INFO:     Found new best model at epoch 2
2023-01-04 08:51:38,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:38,421 INFO:     Epoch: 3
2023-01-04 08:51:40,031 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5592288017272949, 'Total loss': 0.5592288017272949} | train loss {'Reaction outcome loss': 0.5378664331219625, 'Total loss': 0.5378664331219625}
2023-01-04 08:51:40,031 INFO:     Found new best model at epoch 3
2023-01-04 08:51:40,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:40,032 INFO:     Epoch: 4
2023-01-04 08:51:41,657 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5354247073332469, 'Total loss': 0.5354247073332469} | train loss {'Reaction outcome loss': 0.5074648525754827, 'Total loss': 0.5074648525754827}
2023-01-04 08:51:41,657 INFO:     Found new best model at epoch 4
2023-01-04 08:51:41,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:41,658 INFO:     Epoch: 5
2023-01-04 08:51:43,282 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5363207658131918, 'Total loss': 0.5363207658131918} | train loss {'Reaction outcome loss': 0.4911144502676915, 'Total loss': 0.4911144502676915}
2023-01-04 08:51:43,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:43,283 INFO:     Epoch: 6
2023-01-04 08:51:44,877 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5235954334338506, 'Total loss': 0.5235954334338506} | train loss {'Reaction outcome loss': 0.4944662257921005, 'Total loss': 0.4944662257921005}
2023-01-04 08:51:44,877 INFO:     Found new best model at epoch 6
2023-01-04 08:51:44,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:44,878 INFO:     Epoch: 7
2023-01-04 08:51:46,458 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5437920192877451, 'Total loss': 0.5437920192877451} | train loss {'Reaction outcome loss': 0.4973260863967564, 'Total loss': 0.4973260863967564}
2023-01-04 08:51:46,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:46,458 INFO:     Epoch: 8
2023-01-04 08:51:48,074 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5112501303354899, 'Total loss': 0.5112501303354899} | train loss {'Reaction outcome loss': 0.4831365119071974, 'Total loss': 0.4831365119071974}
2023-01-04 08:51:48,074 INFO:     Found new best model at epoch 8
2023-01-04 08:51:48,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:48,075 INFO:     Epoch: 9
2023-01-04 08:51:49,678 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5030083934466044, 'Total loss': 0.5030083934466044} | train loss {'Reaction outcome loss': 0.4621787748798944, 'Total loss': 0.4621787748798944}
2023-01-04 08:51:49,679 INFO:     Found new best model at epoch 9
2023-01-04 08:51:49,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:49,680 INFO:     Epoch: 10
2023-01-04 08:51:51,279 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.506989233692487, 'Total loss': 0.506989233692487} | train loss {'Reaction outcome loss': 0.4566052261389036, 'Total loss': 0.4566052261389036}
2023-01-04 08:51:51,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:51,279 INFO:     Epoch: 11
2023-01-04 08:51:52,873 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4997353176275889, 'Total loss': 0.4997353176275889} | train loss {'Reaction outcome loss': 0.45092013952903537, 'Total loss': 0.45092013952903537}
2023-01-04 08:51:52,873 INFO:     Found new best model at epoch 11
2023-01-04 08:51:52,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:52,873 INFO:     Epoch: 12
2023-01-04 08:51:54,424 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48602168560028075, 'Total loss': 0.48602168560028075} | train loss {'Reaction outcome loss': 0.44544655046817183, 'Total loss': 0.44544655046817183}
2023-01-04 08:51:54,425 INFO:     Found new best model at epoch 12
2023-01-04 08:51:54,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:54,425 INFO:     Epoch: 13
2023-01-04 08:51:55,969 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49815002679824827, 'Total loss': 0.49815002679824827} | train loss {'Reaction outcome loss': 0.4425938955433937, 'Total loss': 0.4425938955433937}
2023-01-04 08:51:55,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:55,969 INFO:     Epoch: 14
2023-01-04 08:51:57,540 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5033121128877004, 'Total loss': 0.5033121128877004} | train loss {'Reaction outcome loss': 0.4384036518201448, 'Total loss': 0.4384036518201448}
2023-01-04 08:51:57,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:57,541 INFO:     Epoch: 15
2023-01-04 08:51:59,103 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5025549829006195, 'Total loss': 0.5025549829006195} | train loss {'Reaction outcome loss': 0.43245221826968505, 'Total loss': 0.43245221826968505}
2023-01-04 08:51:59,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:51:59,104 INFO:     Epoch: 16
2023-01-04 08:52:00,682 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5111044347286224, 'Total loss': 0.5111044347286224} | train loss {'Reaction outcome loss': 0.43010874426682427, 'Total loss': 0.43010874426682427}
2023-01-04 08:52:00,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:00,683 INFO:     Epoch: 17
2023-01-04 08:52:02,261 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48247796992460884, 'Total loss': 0.48247796992460884} | train loss {'Reaction outcome loss': 0.4223262608891515, 'Total loss': 0.4223262608891515}
2023-01-04 08:52:02,261 INFO:     Found new best model at epoch 17
2023-01-04 08:52:02,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:02,262 INFO:     Epoch: 18
2023-01-04 08:52:03,784 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5075405776500702, 'Total loss': 0.5075405776500702} | train loss {'Reaction outcome loss': 0.4223513788125221, 'Total loss': 0.4223513788125221}
2023-01-04 08:52:03,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:03,785 INFO:     Epoch: 19
2023-01-04 08:52:05,360 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4789722293615341, 'Total loss': 0.4789722293615341} | train loss {'Reaction outcome loss': 0.4163471815156062, 'Total loss': 0.4163471815156062}
2023-01-04 08:52:05,360 INFO:     Found new best model at epoch 19
2023-01-04 08:52:05,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:05,361 INFO:     Epoch: 20
2023-01-04 08:52:06,950 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49361435969670614, 'Total loss': 0.49361435969670614} | train loss {'Reaction outcome loss': 0.4162594267113161, 'Total loss': 0.4162594267113161}
2023-01-04 08:52:06,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:06,951 INFO:     Epoch: 21
2023-01-04 08:52:08,538 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4850142737229665, 'Total loss': 0.4850142737229665} | train loss {'Reaction outcome loss': 0.41823290396427765, 'Total loss': 0.41823290396427765}
2023-01-04 08:52:08,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:08,538 INFO:     Epoch: 22
2023-01-04 08:52:10,131 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4843608677387238, 'Total loss': 0.4843608677387238} | train loss {'Reaction outcome loss': 0.41796455456726794, 'Total loss': 0.41796455456726794}
2023-01-04 08:52:10,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:10,131 INFO:     Epoch: 23
2023-01-04 08:52:11,756 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47960813442866007, 'Total loss': 0.47960813442866007} | train loss {'Reaction outcome loss': 0.40822511703110015, 'Total loss': 0.40822511703110015}
2023-01-04 08:52:11,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:11,756 INFO:     Epoch: 24
2023-01-04 08:52:13,280 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48402246832847595, 'Total loss': 0.48402246832847595} | train loss {'Reaction outcome loss': 0.40346625263708225, 'Total loss': 0.40346625263708225}
2023-01-04 08:52:13,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:13,280 INFO:     Epoch: 25
2023-01-04 08:52:14,876 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4693929642438889, 'Total loss': 0.4693929642438889} | train loss {'Reaction outcome loss': 0.39796038928434957, 'Total loss': 0.39796038928434957}
2023-01-04 08:52:14,876 INFO:     Found new best model at epoch 25
2023-01-04 08:52:14,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:14,877 INFO:     Epoch: 26
2023-01-04 08:52:16,475 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48673017422358195, 'Total loss': 0.48673017422358195} | train loss {'Reaction outcome loss': 0.3990399942503891, 'Total loss': 0.3990399942503891}
2023-01-04 08:52:16,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:16,475 INFO:     Epoch: 27
2023-01-04 08:52:18,050 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47490819891293845, 'Total loss': 0.47490819891293845} | train loss {'Reaction outcome loss': 0.4126689280865964, 'Total loss': 0.4126689280865964}
2023-01-04 08:52:18,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:18,051 INFO:     Epoch: 28
2023-01-04 08:52:19,625 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5100254317124685, 'Total loss': 0.5100254317124685} | train loss {'Reaction outcome loss': 0.3929789713921322, 'Total loss': 0.3929789713921322}
2023-01-04 08:52:19,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:19,626 INFO:     Epoch: 29
2023-01-04 08:52:21,218 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4785705049832662, 'Total loss': 0.4785705049832662} | train loss {'Reaction outcome loss': 0.3959121410768695, 'Total loss': 0.3959121410768695}
2023-01-04 08:52:21,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:21,218 INFO:     Epoch: 30
2023-01-04 08:52:22,710 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4819930707414945, 'Total loss': 0.4819930707414945} | train loss {'Reaction outcome loss': 0.3962654642274846, 'Total loss': 0.3962654642274846}
2023-01-04 08:52:22,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:22,710 INFO:     Epoch: 31
2023-01-04 08:52:24,276 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47802619139353436, 'Total loss': 0.47802619139353436} | train loss {'Reaction outcome loss': 0.43938735246226407, 'Total loss': 0.43938735246226407}
2023-01-04 08:52:24,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:24,276 INFO:     Epoch: 32
2023-01-04 08:52:25,844 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46691901683807374, 'Total loss': 0.46691901683807374} | train loss {'Reaction outcome loss': 0.40665116649714933, 'Total loss': 0.40665116649714933}
2023-01-04 08:52:25,844 INFO:     Found new best model at epoch 32
2023-01-04 08:52:25,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:25,845 INFO:     Epoch: 33
2023-01-04 08:52:27,415 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4860659847656886, 'Total loss': 0.4860659847656886} | train loss {'Reaction outcome loss': 0.3888118057579234, 'Total loss': 0.3888118057579234}
2023-01-04 08:52:27,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:27,415 INFO:     Epoch: 34
2023-01-04 08:52:28,982 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47504185438156127, 'Total loss': 0.47504185438156127} | train loss {'Reaction outcome loss': 0.40728872283986106, 'Total loss': 0.40728872283986106}
2023-01-04 08:52:28,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:28,982 INFO:     Epoch: 35
2023-01-04 08:52:30,542 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4750689476728439, 'Total loss': 0.4750689476728439} | train loss {'Reaction outcome loss': 0.3765130618290193, 'Total loss': 0.3765130618290193}
2023-01-04 08:52:30,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:30,543 INFO:     Epoch: 36
2023-01-04 08:52:32,069 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47030650774637855, 'Total loss': 0.47030650774637855} | train loss {'Reaction outcome loss': 0.38357478153446445, 'Total loss': 0.38357478153446445}
2023-01-04 08:52:32,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:32,070 INFO:     Epoch: 37
2023-01-04 08:52:33,629 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4710219631592433, 'Total loss': 0.4710219631592433} | train loss {'Reaction outcome loss': 0.3735061715613457, 'Total loss': 0.3735061715613457}
2023-01-04 08:52:33,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:33,629 INFO:     Epoch: 38
2023-01-04 08:52:35,205 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4898048977057139, 'Total loss': 0.4898048977057139} | train loss {'Reaction outcome loss': 0.36222291281819047, 'Total loss': 0.36222291281819047}
2023-01-04 08:52:35,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:35,205 INFO:     Epoch: 39
2023-01-04 08:52:36,766 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4740289688110352, 'Total loss': 0.4740289688110352} | train loss {'Reaction outcome loss': 0.3594767274874924, 'Total loss': 0.3594767274874924}
2023-01-04 08:52:36,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:36,766 INFO:     Epoch: 40
2023-01-04 08:52:38,330 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48250622550646466, 'Total loss': 0.48250622550646466} | train loss {'Reaction outcome loss': 0.357552610574361, 'Total loss': 0.357552610574361}
2023-01-04 08:52:38,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:38,331 INFO:     Epoch: 41
2023-01-04 08:52:39,869 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46094384118914605, 'Total loss': 0.46094384118914605} | train loss {'Reaction outcome loss': 0.35022223951544723, 'Total loss': 0.35022223951544723}
2023-01-04 08:52:39,869 INFO:     Found new best model at epoch 41
2023-01-04 08:52:39,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:39,870 INFO:     Epoch: 42
2023-01-04 08:52:41,399 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47714107235272724, 'Total loss': 0.47714107235272724} | train loss {'Reaction outcome loss': 0.350773847506692, 'Total loss': 0.350773847506692}
2023-01-04 08:52:41,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:41,400 INFO:     Epoch: 43
2023-01-04 08:52:42,966 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4632291893164317, 'Total loss': 0.4632291893164317} | train loss {'Reaction outcome loss': 0.3494711681066648, 'Total loss': 0.3494711681066648}
2023-01-04 08:52:42,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:42,966 INFO:     Epoch: 44
2023-01-04 08:52:44,526 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4948508302370707, 'Total loss': 0.4948508302370707} | train loss {'Reaction outcome loss': 0.34841673419324926, 'Total loss': 0.34841673419324926}
2023-01-04 08:52:44,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:44,526 INFO:     Epoch: 45
2023-01-04 08:52:46,085 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47343916495641075, 'Total loss': 0.47343916495641075} | train loss {'Reaction outcome loss': 0.34441905854792043, 'Total loss': 0.34441905854792043}
2023-01-04 08:52:46,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:46,085 INFO:     Epoch: 46
2023-01-04 08:52:47,648 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4688180307547251, 'Total loss': 0.4688180307547251} | train loss {'Reaction outcome loss': 0.3415610212292792, 'Total loss': 0.3415610212292792}
2023-01-04 08:52:47,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:47,649 INFO:     Epoch: 47
2023-01-04 08:52:49,176 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45744240283966064, 'Total loss': 0.45744240283966064} | train loss {'Reaction outcome loss': 0.34238867892924213, 'Total loss': 0.34238867892924213}
2023-01-04 08:52:49,176 INFO:     Found new best model at epoch 47
2023-01-04 08:52:49,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:49,177 INFO:     Epoch: 48
2023-01-04 08:52:50,716 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4708936303853989, 'Total loss': 0.4708936303853989} | train loss {'Reaction outcome loss': 0.3388663767574322, 'Total loss': 0.3388663767574322}
2023-01-04 08:52:50,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:50,717 INFO:     Epoch: 49
2023-01-04 08:52:52,296 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46141080458958944, 'Total loss': 0.46141080458958944} | train loss {'Reaction outcome loss': 0.33578367656825675, 'Total loss': 0.33578367656825675}
2023-01-04 08:52:52,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:52,296 INFO:     Epoch: 50
2023-01-04 08:52:53,863 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4842738648255666, 'Total loss': 0.4842738648255666} | train loss {'Reaction outcome loss': 0.33265394476188376, 'Total loss': 0.33265394476188376}
2023-01-04 08:52:53,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:53,863 INFO:     Epoch: 51
2023-01-04 08:52:55,442 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47461272875467936, 'Total loss': 0.47461272875467936} | train loss {'Reaction outcome loss': 0.3314405410564032, 'Total loss': 0.3314405410564032}
2023-01-04 08:52:55,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:55,442 INFO:     Epoch: 52
2023-01-04 08:52:57,009 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4742413371801376, 'Total loss': 0.4742413371801376} | train loss {'Reaction outcome loss': 0.32734375996042747, 'Total loss': 0.32734375996042747}
2023-01-04 08:52:57,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:57,009 INFO:     Epoch: 53
2023-01-04 08:52:58,528 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4743959923585256, 'Total loss': 0.4743959923585256} | train loss {'Reaction outcome loss': 0.32289139071896067, 'Total loss': 0.32289139071896067}
2023-01-04 08:52:58,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:52:58,529 INFO:     Epoch: 54
2023-01-04 08:53:00,059 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46146260102589926, 'Total loss': 0.46146260102589926} | train loss {'Reaction outcome loss': 0.3209222742133652, 'Total loss': 0.3209222742133652}
2023-01-04 08:53:00,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:00,060 INFO:     Epoch: 55
2023-01-04 08:53:01,622 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4488824168841044, 'Total loss': 0.4488824168841044} | train loss {'Reaction outcome loss': 0.33483237157697265, 'Total loss': 0.33483237157697265}
2023-01-04 08:53:01,622 INFO:     Found new best model at epoch 55
2023-01-04 08:53:01,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:01,623 INFO:     Epoch: 56
2023-01-04 08:53:03,198 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4561540643374125, 'Total loss': 0.4561540643374125} | train loss {'Reaction outcome loss': 0.35325914378399437, 'Total loss': 0.35325914378399437}
2023-01-04 08:53:03,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:03,198 INFO:     Epoch: 57
2023-01-04 08:53:04,779 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44987425605456033, 'Total loss': 0.44987425605456033} | train loss {'Reaction outcome loss': 0.3256532779120354, 'Total loss': 0.3256532779120354}
2023-01-04 08:53:04,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:04,779 INFO:     Epoch: 58
2023-01-04 08:53:06,348 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4595036198695501, 'Total loss': 0.4595036198695501} | train loss {'Reaction outcome loss': 0.31808467847767513, 'Total loss': 0.31808467847767513}
2023-01-04 08:53:06,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:06,348 INFO:     Epoch: 59
2023-01-04 08:53:07,858 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4667225400606791, 'Total loss': 0.4667225400606791} | train loss {'Reaction outcome loss': 0.3171133761204766, 'Total loss': 0.3171133761204766}
2023-01-04 08:53:07,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:07,859 INFO:     Epoch: 60
2023-01-04 08:53:09,397 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45156262516975404, 'Total loss': 0.45156262516975404} | train loss {'Reaction outcome loss': 0.312887422349034, 'Total loss': 0.312887422349034}
2023-01-04 08:53:09,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:09,397 INFO:     Epoch: 61
2023-01-04 08:53:10,946 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47059401174386345, 'Total loss': 0.47059401174386345} | train loss {'Reaction outcome loss': 0.3097150211913791, 'Total loss': 0.3097150211913791}
2023-01-04 08:53:10,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:10,946 INFO:     Epoch: 62
2023-01-04 08:53:12,507 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47995097637176515, 'Total loss': 0.47995097637176515} | train loss {'Reaction outcome loss': 0.31160958880639594, 'Total loss': 0.31160958880639594}
2023-01-04 08:53:12,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:12,507 INFO:     Epoch: 63
2023-01-04 08:53:14,061 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45093230058749517, 'Total loss': 0.45093230058749517} | train loss {'Reaction outcome loss': 0.3065383973146748, 'Total loss': 0.3065383973146748}
2023-01-04 08:53:14,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:14,062 INFO:     Epoch: 64
2023-01-04 08:53:15,616 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46756946841875713, 'Total loss': 0.46756946841875713} | train loss {'Reaction outcome loss': 0.3063222013305927, 'Total loss': 0.3063222013305927}
2023-01-04 08:53:15,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:15,616 INFO:     Epoch: 65
2023-01-04 08:53:17,098 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46013209025065105, 'Total loss': 0.46013209025065105} | train loss {'Reaction outcome loss': 0.31591268982468307, 'Total loss': 0.31591268982468307}
2023-01-04 08:53:17,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:17,098 INFO:     Epoch: 66
2023-01-04 08:53:18,647 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45399176875750225, 'Total loss': 0.45399176875750225} | train loss {'Reaction outcome loss': 0.3018518711399773, 'Total loss': 0.3018518711399773}
2023-01-04 08:53:18,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:18,648 INFO:     Epoch: 67
2023-01-04 08:53:20,247 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4536255290110906, 'Total loss': 0.4536255290110906} | train loss {'Reaction outcome loss': 0.3136019731561343, 'Total loss': 0.3136019731561343}
2023-01-04 08:53:20,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:20,247 INFO:     Epoch: 68
2023-01-04 08:53:21,797 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4829321543375651, 'Total loss': 0.4829321543375651} | train loss {'Reaction outcome loss': 0.3010586389505804, 'Total loss': 0.3010586389505804}
2023-01-04 08:53:21,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:21,797 INFO:     Epoch: 69
2023-01-04 08:53:23,336 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42243714903791746, 'Total loss': 0.42243714903791746} | train loss {'Reaction outcome loss': 0.29659932100996916, 'Total loss': 0.29659932100996916}
2023-01-04 08:53:23,336 INFO:     Found new best model at epoch 69
2023-01-04 08:53:23,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:23,337 INFO:     Epoch: 70
2023-01-04 08:53:24,874 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.467499769727389, 'Total loss': 0.467499769727389} | train loss {'Reaction outcome loss': 0.30381710649184557, 'Total loss': 0.30381710649184557}
2023-01-04 08:53:24,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:24,875 INFO:     Epoch: 71
2023-01-04 08:53:26,358 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4567456642786662, 'Total loss': 0.4567456642786662} | train loss {'Reaction outcome loss': 0.35640858094110084, 'Total loss': 0.35640858094110084}
2023-01-04 08:53:26,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:26,359 INFO:     Epoch: 72
2023-01-04 08:53:27,911 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48915944894154867, 'Total loss': 0.48915944894154867} | train loss {'Reaction outcome loss': 0.3040148594376186, 'Total loss': 0.3040148594376186}
2023-01-04 08:53:27,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:27,912 INFO:     Epoch: 73
2023-01-04 08:53:29,525 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.464115697145462, 'Total loss': 0.464115697145462} | train loss {'Reaction outcome loss': 0.2992474766503184, 'Total loss': 0.2992474766503184}
2023-01-04 08:53:29,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:29,525 INFO:     Epoch: 74
2023-01-04 08:53:31,142 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46122408906618756, 'Total loss': 0.46122408906618756} | train loss {'Reaction outcome loss': 0.29340408669422424, 'Total loss': 0.29340408669422424}
2023-01-04 08:53:31,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:31,142 INFO:     Epoch: 75
2023-01-04 08:53:32,770 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44480083386103314, 'Total loss': 0.44480083386103314} | train loss {'Reaction outcome loss': 0.2971089930017141, 'Total loss': 0.2971089930017141}
2023-01-04 08:53:32,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:32,770 INFO:     Epoch: 76
2023-01-04 08:53:34,388 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.489497172832489, 'Total loss': 0.489497172832489} | train loss {'Reaction outcome loss': 0.3025703944157863, 'Total loss': 0.3025703944157863}
2023-01-04 08:53:34,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:34,388 INFO:     Epoch: 77
2023-01-04 08:53:35,886 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49795908729235333, 'Total loss': 0.49795908729235333} | train loss {'Reaction outcome loss': 0.3536687672722637, 'Total loss': 0.3536687672722637}
2023-01-04 08:53:35,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:35,886 INFO:     Epoch: 78
2023-01-04 08:53:37,443 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47835119962692263, 'Total loss': 0.47835119962692263} | train loss {'Reaction outcome loss': 0.3084972022789652, 'Total loss': 0.3084972022789652}
2023-01-04 08:53:37,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:37,443 INFO:     Epoch: 79
2023-01-04 08:53:39,039 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4441960483789444, 'Total loss': 0.4441960483789444} | train loss {'Reaction outcome loss': 0.2995842827696596, 'Total loss': 0.2995842827696596}
2023-01-04 08:53:39,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:39,039 INFO:     Epoch: 80
2023-01-04 08:53:40,621 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.445208777487278, 'Total loss': 0.445208777487278} | train loss {'Reaction outcome loss': 0.3121285266580357, 'Total loss': 0.3121285266580357}
2023-01-04 08:53:40,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:40,621 INFO:     Epoch: 81
2023-01-04 08:53:42,190 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.436305566628774, 'Total loss': 0.436305566628774} | train loss {'Reaction outcome loss': 0.3252838340088509, 'Total loss': 0.3252838340088509}
2023-01-04 08:53:42,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:42,190 INFO:     Epoch: 82
2023-01-04 08:53:43,743 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4635215550661087, 'Total loss': 0.4635215550661087} | train loss {'Reaction outcome loss': 0.30312713512482686, 'Total loss': 0.30312713512482686}
2023-01-04 08:53:43,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:43,745 INFO:     Epoch: 83
2023-01-04 08:53:45,288 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44849999745686847, 'Total loss': 0.44849999745686847} | train loss {'Reaction outcome loss': 0.2898734512121376, 'Total loss': 0.2898734512121376}
2023-01-04 08:53:45,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:45,289 INFO:     Epoch: 84
2023-01-04 08:53:46,835 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47383426229159037, 'Total loss': 0.47383426229159037} | train loss {'Reaction outcome loss': 0.28446338021110906, 'Total loss': 0.28446338021110906}
2023-01-04 08:53:46,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:46,836 INFO:     Epoch: 85
2023-01-04 08:53:48,384 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46189268430074054, 'Total loss': 0.46189268430074054} | train loss {'Reaction outcome loss': 0.28011000303440203, 'Total loss': 0.28011000303440203}
2023-01-04 08:53:48,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:48,384 INFO:     Epoch: 86
2023-01-04 08:53:49,939 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45093244016170503, 'Total loss': 0.45093244016170503} | train loss {'Reaction outcome loss': 0.27865873022137355, 'Total loss': 0.27865873022137355}
2023-01-04 08:53:49,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:49,940 INFO:     Epoch: 87
2023-01-04 08:53:51,501 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47974413534005483, 'Total loss': 0.47974413534005483} | train loss {'Reaction outcome loss': 0.2791534335862008, 'Total loss': 0.2791534335862008}
2023-01-04 08:53:51,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:51,501 INFO:     Epoch: 88
2023-01-04 08:53:53,013 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4494318882624308, 'Total loss': 0.4494318882624308} | train loss {'Reaction outcome loss': 0.2795310444029831, 'Total loss': 0.2795310444029831}
2023-01-04 08:53:53,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:53,013 INFO:     Epoch: 89
2023-01-04 08:53:54,542 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4523982693751653, 'Total loss': 0.4523982693751653} | train loss {'Reaction outcome loss': 0.2797804376434373, 'Total loss': 0.2797804376434373}
2023-01-04 08:53:54,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:54,542 INFO:     Epoch: 90
2023-01-04 08:53:56,115 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43504706025123596, 'Total loss': 0.43504706025123596} | train loss {'Reaction outcome loss': 0.2755324362584835, 'Total loss': 0.2755324362584835}
2023-01-04 08:53:56,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:56,115 INFO:     Epoch: 91
2023-01-04 08:53:57,675 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4788868526617686, 'Total loss': 0.4788868526617686} | train loss {'Reaction outcome loss': 0.26963473620244127, 'Total loss': 0.26963473620244127}
2023-01-04 08:53:57,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:57,675 INFO:     Epoch: 92
2023-01-04 08:53:59,240 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4566059490044912, 'Total loss': 0.4566059490044912} | train loss {'Reaction outcome loss': 0.2695961847658391, 'Total loss': 0.2695961847658391}
2023-01-04 08:53:59,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:53:59,240 INFO:     Epoch: 93
2023-01-04 08:54:00,795 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45110785166422523, 'Total loss': 0.45110785166422523} | train loss {'Reaction outcome loss': 0.27456083329583425, 'Total loss': 0.27456083329583425}
2023-01-04 08:54:00,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:00,795 INFO:     Epoch: 94
2023-01-04 08:54:02,318 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45962640444437664, 'Total loss': 0.45962640444437664} | train loss {'Reaction outcome loss': 0.27409990465241496, 'Total loss': 0.27409990465241496}
2023-01-04 08:54:02,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:02,319 INFO:     Epoch: 95
2023-01-04 08:54:03,829 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47064808110396067, 'Total loss': 0.47064808110396067} | train loss {'Reaction outcome loss': 0.26719156127639004, 'Total loss': 0.26719156127639004}
2023-01-04 08:54:03,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:03,829 INFO:     Epoch: 96
2023-01-04 08:54:05,378 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44569074312845863, 'Total loss': 0.44569074312845863} | train loss {'Reaction outcome loss': 0.27039372290491354, 'Total loss': 0.27039372290491354}
2023-01-04 08:54:05,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:05,378 INFO:     Epoch: 97
2023-01-04 08:54:06,935 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43945288757483164, 'Total loss': 0.43945288757483164} | train loss {'Reaction outcome loss': 0.2674095045337273, 'Total loss': 0.2674095045337273}
2023-01-04 08:54:06,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:06,935 INFO:     Epoch: 98
2023-01-04 08:54:08,518 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.436246982216835, 'Total loss': 0.436246982216835} | train loss {'Reaction outcome loss': 0.27014737116701, 'Total loss': 0.27014737116701}
2023-01-04 08:54:08,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:08,519 INFO:     Epoch: 99
2023-01-04 08:54:10,110 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45276538133621214, 'Total loss': 0.45276538133621214} | train loss {'Reaction outcome loss': 0.2671595883985519, 'Total loss': 0.2671595883985519}
2023-01-04 08:54:10,110 INFO:     Best model found after epoch 70 of 100.
2023-01-04 08:54:10,110 INFO:   Done with stage: TRAINING
2023-01-04 08:54:10,110 INFO:   Starting stage: EVALUATION
2023-01-04 08:54:10,240 INFO:   Done with stage: EVALUATION
2023-01-04 08:54:10,240 INFO:   Leaving out SEQ value Fold_6
2023-01-04 08:54:10,252 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 08:54:10,252 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:54:10,898 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:54:10,898 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:54:10,967 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:54:10,968 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:54:10,968 INFO:     No hyperparam tuning for this model
2023-01-04 08:54:10,968 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:54:10,968 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:54:10,968 INFO:     None feature selector for col prot
2023-01-04 08:54:10,969 INFO:     None feature selector for col prot
2023-01-04 08:54:10,969 INFO:     None feature selector for col prot
2023-01-04 08:54:10,969 INFO:     None feature selector for col chem
2023-01-04 08:54:10,969 INFO:     None feature selector for col chem
2023-01-04 08:54:10,969 INFO:     None feature selector for col chem
2023-01-04 08:54:10,969 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:54:10,970 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:54:10,970 INFO:     Number of params in model 70111
2023-01-04 08:54:10,974 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:54:10,974 INFO:   Starting stage: TRAINING
2023-01-04 08:54:11,018 INFO:     Val loss before train {'Reaction outcome loss': 0.9480905691782634, 'Total loss': 0.9480905691782634}
2023-01-04 08:54:11,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:11,018 INFO:     Epoch: 0
2023-01-04 08:54:12,554 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7364789883295695, 'Total loss': 0.7364789883295695} | train loss {'Reaction outcome loss': 0.8281672646422679, 'Total loss': 0.8281672646422679}
2023-01-04 08:54:12,554 INFO:     Found new best model at epoch 0
2023-01-04 08:54:12,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:12,555 INFO:     Epoch: 1
2023-01-04 08:54:14,125 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6360746920108795, 'Total loss': 0.6360746920108795} | train loss {'Reaction outcome loss': 0.6566746561966218, 'Total loss': 0.6566746561966218}
2023-01-04 08:54:14,125 INFO:     Found new best model at epoch 1
2023-01-04 08:54:14,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:14,126 INFO:     Epoch: 2
2023-01-04 08:54:15,700 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5468351582686106, 'Total loss': 0.5468351582686106} | train loss {'Reaction outcome loss': 0.5755494340232133, 'Total loss': 0.5755494340232133}
2023-01-04 08:54:15,701 INFO:     Found new best model at epoch 2
2023-01-04 08:54:15,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:15,701 INFO:     Epoch: 3
2023-01-04 08:54:17,266 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5202169994513194, 'Total loss': 0.5202169994513194} | train loss {'Reaction outcome loss': 0.5416771680224243, 'Total loss': 0.5416771680224243}
2023-01-04 08:54:17,267 INFO:     Found new best model at epoch 3
2023-01-04 08:54:17,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:17,267 INFO:     Epoch: 4
2023-01-04 08:54:18,852 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.538480653365453, 'Total loss': 0.538480653365453} | train loss {'Reaction outcome loss': 0.5183816157308296, 'Total loss': 0.5183816157308296}
2023-01-04 08:54:18,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:18,853 INFO:     Epoch: 5
2023-01-04 08:54:20,379 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5003682871659597, 'Total loss': 0.5003682871659597} | train loss {'Reaction outcome loss': 0.5052733839311324, 'Total loss': 0.5052733839311324}
2023-01-04 08:54:20,379 INFO:     Found new best model at epoch 5
2023-01-04 08:54:20,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:20,380 INFO:     Epoch: 6
2023-01-04 08:54:21,938 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4994184921185176, 'Total loss': 0.4994184921185176} | train loss {'Reaction outcome loss': 0.4978100006545924, 'Total loss': 0.4978100006545924}
2023-01-04 08:54:21,938 INFO:     Found new best model at epoch 6
2023-01-04 08:54:21,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:21,939 INFO:     Epoch: 7
2023-01-04 08:54:23,502 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48634188771247866, 'Total loss': 0.48634188771247866} | train loss {'Reaction outcome loss': 0.4849253858469884, 'Total loss': 0.4849253858469884}
2023-01-04 08:54:23,502 INFO:     Found new best model at epoch 7
2023-01-04 08:54:23,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:23,503 INFO:     Epoch: 8
2023-01-04 08:54:25,068 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4842196921507517, 'Total loss': 0.4842196921507517} | train loss {'Reaction outcome loss': 0.4781455408364857, 'Total loss': 0.4781455408364857}
2023-01-04 08:54:25,069 INFO:     Found new best model at epoch 8
2023-01-04 08:54:25,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:25,070 INFO:     Epoch: 9
2023-01-04 08:54:26,654 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4712810297807058, 'Total loss': 0.4712810297807058} | train loss {'Reaction outcome loss': 0.46848784333316856, 'Total loss': 0.46848784333316856}
2023-01-04 08:54:26,654 INFO:     Found new best model at epoch 9
2023-01-04 08:54:26,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:26,655 INFO:     Epoch: 10
2023-01-04 08:54:28,219 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47202677925427755, 'Total loss': 0.47202677925427755} | train loss {'Reaction outcome loss': 0.46129687915855366, 'Total loss': 0.46129687915855366}
2023-01-04 08:54:28,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:28,219 INFO:     Epoch: 11
2023-01-04 08:54:29,736 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5076533565918605, 'Total loss': 0.5076533565918605} | train loss {'Reaction outcome loss': 0.46123114201351195, 'Total loss': 0.46123114201351195}
2023-01-04 08:54:29,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:29,736 INFO:     Epoch: 12
2023-01-04 08:54:31,299 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44908665418624877, 'Total loss': 0.44908665418624877} | train loss {'Reaction outcome loss': 0.4526433385774117, 'Total loss': 0.4526433385774117}
2023-01-04 08:54:31,299 INFO:     Found new best model at epoch 12
2023-01-04 08:54:31,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:31,300 INFO:     Epoch: 13
2023-01-04 08:54:32,863 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44811131358146666, 'Total loss': 0.44811131358146666} | train loss {'Reaction outcome loss': 0.44953059154942576, 'Total loss': 0.44953059154942576}
2023-01-04 08:54:32,864 INFO:     Found new best model at epoch 13
2023-01-04 08:54:32,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:32,864 INFO:     Epoch: 14
2023-01-04 08:54:34,431 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45251251260439557, 'Total loss': 0.45251251260439557} | train loss {'Reaction outcome loss': 0.44421731123855396, 'Total loss': 0.44421731123855396}
2023-01-04 08:54:34,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:34,431 INFO:     Epoch: 15
2023-01-04 08:54:35,984 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4532542904218038, 'Total loss': 0.4532542904218038} | train loss {'Reaction outcome loss': 0.4408736183217286, 'Total loss': 0.4408736183217286}
2023-01-04 08:54:35,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:35,984 INFO:     Epoch: 16
2023-01-04 08:54:37,529 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47436524629592897, 'Total loss': 0.47436524629592897} | train loss {'Reaction outcome loss': 0.43087437366965875, 'Total loss': 0.43087437366965875}
2023-01-04 08:54:37,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:37,530 INFO:     Epoch: 17
2023-01-04 08:54:39,016 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4531009038289388, 'Total loss': 0.4531009038289388} | train loss {'Reaction outcome loss': 0.43089680771750233, 'Total loss': 0.43089680771750233}
2023-01-04 08:54:39,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:39,016 INFO:     Epoch: 18
2023-01-04 08:54:40,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4535940100749334, 'Total loss': 0.4535940100749334} | train loss {'Reaction outcome loss': 0.4246414311310875, 'Total loss': 0.4246414311310875}
2023-01-04 08:54:40,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:40,568 INFO:     Epoch: 19
2023-01-04 08:54:42,112 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45228636264801025, 'Total loss': 0.45228636264801025} | train loss {'Reaction outcome loss': 0.42030505018328934, 'Total loss': 0.42030505018328934}
2023-01-04 08:54:42,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:42,113 INFO:     Epoch: 20
2023-01-04 08:54:43,676 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4401022473971049, 'Total loss': 0.4401022473971049} | train loss {'Reaction outcome loss': 0.4138732605516265, 'Total loss': 0.4138732605516265}
2023-01-04 08:54:43,676 INFO:     Found new best model at epoch 20
2023-01-04 08:54:43,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:43,677 INFO:     Epoch: 21
2023-01-04 08:54:45,218 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44926322201887764, 'Total loss': 0.44926322201887764} | train loss {'Reaction outcome loss': 0.4116979418894014, 'Total loss': 0.4116979418894014}
2023-01-04 08:54:45,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:45,218 INFO:     Epoch: 22
2023-01-04 08:54:46,776 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44106613447268805, 'Total loss': 0.44106613447268805} | train loss {'Reaction outcome loss': 0.4086537331019928, 'Total loss': 0.4086537331019928}
2023-01-04 08:54:46,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:46,776 INFO:     Epoch: 23
2023-01-04 08:54:48,274 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43002743025620777, 'Total loss': 0.43002743025620777} | train loss {'Reaction outcome loss': 0.404770107529654, 'Total loss': 0.404770107529654}
2023-01-04 08:54:48,274 INFO:     Found new best model at epoch 23
2023-01-04 08:54:48,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:48,275 INFO:     Epoch: 24
2023-01-04 08:54:49,837 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4418188512325287, 'Total loss': 0.4418188512325287} | train loss {'Reaction outcome loss': 0.40112464958364785, 'Total loss': 0.40112464958364785}
2023-01-04 08:54:49,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:49,838 INFO:     Epoch: 25
2023-01-04 08:54:51,396 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4381697128216426, 'Total loss': 0.4381697128216426} | train loss {'Reaction outcome loss': 0.3972907780740235, 'Total loss': 0.3972907780740235}
2023-01-04 08:54:51,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:51,397 INFO:     Epoch: 26
2023-01-04 08:54:52,954 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41284195333719254, 'Total loss': 0.41284195333719254} | train loss {'Reaction outcome loss': 0.39382585627615235, 'Total loss': 0.39382585627615235}
2023-01-04 08:54:52,954 INFO:     Found new best model at epoch 26
2023-01-04 08:54:52,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:52,955 INFO:     Epoch: 27
2023-01-04 08:54:54,521 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41537506779034933, 'Total loss': 0.41537506779034933} | train loss {'Reaction outcome loss': 0.39096350125995355, 'Total loss': 0.39096350125995355}
2023-01-04 08:54:54,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:54,521 INFO:     Epoch: 28
2023-01-04 08:54:56,067 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4475003103415171, 'Total loss': 0.4475003103415171} | train loss {'Reaction outcome loss': 0.38865001429719614, 'Total loss': 0.38865001429719614}
2023-01-04 08:54:56,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:56,068 INFO:     Epoch: 29
2023-01-04 08:54:57,581 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4435103992621104, 'Total loss': 0.4435103992621104} | train loss {'Reaction outcome loss': 0.3809530843681377, 'Total loss': 0.3809530843681377}
2023-01-04 08:54:57,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:57,581 INFO:     Epoch: 30
2023-01-04 08:54:59,142 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.437087086836497, 'Total loss': 0.437087086836497} | train loss {'Reaction outcome loss': 0.38215282080621066, 'Total loss': 0.38215282080621066}
2023-01-04 08:54:59,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:54:59,143 INFO:     Epoch: 31
2023-01-04 08:55:00,693 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4195615331331889, 'Total loss': 0.4195615331331889} | train loss {'Reaction outcome loss': 0.3757060739860638, 'Total loss': 0.3757060739860638}
2023-01-04 08:55:00,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:00,694 INFO:     Epoch: 32
2023-01-04 08:55:02,253 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4278165300687154, 'Total loss': 0.4278165300687154} | train loss {'Reaction outcome loss': 0.37321124502898123, 'Total loss': 0.37321124502898123}
2023-01-04 08:55:02,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:02,253 INFO:     Epoch: 33
2023-01-04 08:55:03,813 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4335271338621775, 'Total loss': 0.4335271338621775} | train loss {'Reaction outcome loss': 0.37383681718623163, 'Total loss': 0.37383681718623163}
2023-01-04 08:55:03,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:03,814 INFO:     Epoch: 34
2023-01-04 08:55:05,347 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4152832309405009, 'Total loss': 0.4152832309405009} | train loss {'Reaction outcome loss': 0.3668282431170398, 'Total loss': 0.3668282431170398}
2023-01-04 08:55:05,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:05,348 INFO:     Epoch: 35
2023-01-04 08:55:06,887 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4307366579771042, 'Total loss': 0.4307366579771042} | train loss {'Reaction outcome loss': 0.360942267419414, 'Total loss': 0.360942267419414}
2023-01-04 08:55:06,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:06,887 INFO:     Epoch: 36
2023-01-04 08:55:08,451 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.416308402021726, 'Total loss': 0.416308402021726} | train loss {'Reaction outcome loss': 0.36153865210200903, 'Total loss': 0.36153865210200903}
2023-01-04 08:55:08,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:08,452 INFO:     Epoch: 37
2023-01-04 08:55:10,005 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4143089567621549, 'Total loss': 0.4143089567621549} | train loss {'Reaction outcome loss': 0.3651625591494977, 'Total loss': 0.3651625591494977}
2023-01-04 08:55:10,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:10,005 INFO:     Epoch: 38
2023-01-04 08:55:11,567 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4206066995859146, 'Total loss': 0.4206066995859146} | train loss {'Reaction outcome loss': 0.3532837593275717, 'Total loss': 0.3532837593275717}
2023-01-04 08:55:11,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:11,568 INFO:     Epoch: 39
2023-01-04 08:55:13,122 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4312506546576818, 'Total loss': 0.4312506546576818} | train loss {'Reaction outcome loss': 0.3512542601473065, 'Total loss': 0.3512542601473065}
2023-01-04 08:55:13,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:13,123 INFO:     Epoch: 40
2023-01-04 08:55:14,633 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.415082519253095, 'Total loss': 0.415082519253095} | train loss {'Reaction outcome loss': 0.35093736586695545, 'Total loss': 0.35093736586695545}
2023-01-04 08:55:14,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:14,634 INFO:     Epoch: 41
2023-01-04 08:55:16,165 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4208053946495056, 'Total loss': 0.4208053946495056} | train loss {'Reaction outcome loss': 0.34718041181133974, 'Total loss': 0.34718041181133974}
2023-01-04 08:55:16,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:16,165 INFO:     Epoch: 42
2023-01-04 08:55:17,724 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39089038570721946, 'Total loss': 0.39089038570721946} | train loss {'Reaction outcome loss': 0.348878585420791, 'Total loss': 0.348878585420791}
2023-01-04 08:55:17,724 INFO:     Found new best model at epoch 42
2023-01-04 08:55:17,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:17,724 INFO:     Epoch: 43
2023-01-04 08:55:19,275 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.426019753019015, 'Total loss': 0.426019753019015} | train loss {'Reaction outcome loss': 0.3434134921603685, 'Total loss': 0.3434134921603685}
2023-01-04 08:55:19,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:19,275 INFO:     Epoch: 44
2023-01-04 08:55:20,839 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4205926696459452, 'Total loss': 0.4205926696459452} | train loss {'Reaction outcome loss': 0.34095686323106933, 'Total loss': 0.34095686323106933}
2023-01-04 08:55:20,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:20,840 INFO:     Epoch: 45
2023-01-04 08:55:22,407 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42674182951450346, 'Total loss': 0.42674182951450346} | train loss {'Reaction outcome loss': 0.33968828871362045, 'Total loss': 0.33968828871362045}
2023-01-04 08:55:22,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:22,407 INFO:     Epoch: 46
2023-01-04 08:55:23,961 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42597051461537677, 'Total loss': 0.42597051461537677} | train loss {'Reaction outcome loss': 0.33530711279072484, 'Total loss': 0.33530711279072484}
2023-01-04 08:55:23,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:23,961 INFO:     Epoch: 47
2023-01-04 08:55:25,482 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4020676518479983, 'Total loss': 0.4020676518479983} | train loss {'Reaction outcome loss': 0.3289371966401162, 'Total loss': 0.3289371966401162}
2023-01-04 08:55:25,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:25,483 INFO:     Epoch: 48
2023-01-04 08:55:27,036 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4242202381292979, 'Total loss': 0.4242202381292979} | train loss {'Reaction outcome loss': 0.3286293344807539, 'Total loss': 0.3286293344807539}
2023-01-04 08:55:27,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:27,037 INFO:     Epoch: 49
2023-01-04 08:55:28,601 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4013940433661143, 'Total loss': 0.4013940433661143} | train loss {'Reaction outcome loss': 0.32860529936500404, 'Total loss': 0.32860529936500404}
2023-01-04 08:55:28,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:28,601 INFO:     Epoch: 50
2023-01-04 08:55:30,157 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4397524992624919, 'Total loss': 0.4397524992624919} | train loss {'Reaction outcome loss': 0.32128799929945906, 'Total loss': 0.32128799929945906}
2023-01-04 08:55:30,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:30,157 INFO:     Epoch: 51
2023-01-04 08:55:31,710 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42779351274172467, 'Total loss': 0.42779351274172467} | train loss {'Reaction outcome loss': 0.3216689865135114, 'Total loss': 0.3216689865135114}
2023-01-04 08:55:31,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:31,711 INFO:     Epoch: 52
2023-01-04 08:55:33,228 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4234891215960185, 'Total loss': 0.4234891215960185} | train loss {'Reaction outcome loss': 0.3206228347031218, 'Total loss': 0.3206228347031218}
2023-01-04 08:55:33,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:33,228 INFO:     Epoch: 53
2023-01-04 08:55:34,777 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3977969894806544, 'Total loss': 0.3977969894806544} | train loss {'Reaction outcome loss': 0.31913275155995297, 'Total loss': 0.31913275155995297}
2023-01-04 08:55:34,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:34,777 INFO:     Epoch: 54
2023-01-04 08:55:36,338 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4285013198852539, 'Total loss': 0.4285013198852539} | train loss {'Reaction outcome loss': 0.3182067429438395, 'Total loss': 0.3182067429438395}
2023-01-04 08:55:36,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:36,338 INFO:     Epoch: 55
2023-01-04 08:55:37,903 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3966584453980128, 'Total loss': 0.3966584453980128} | train loss {'Reaction outcome loss': 0.31238363933369573, 'Total loss': 0.31238363933369573}
2023-01-04 08:55:37,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:37,903 INFO:     Epoch: 56
2023-01-04 08:55:39,466 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39856622318426765, 'Total loss': 0.39856622318426765} | train loss {'Reaction outcome loss': 0.3159263660653834, 'Total loss': 0.3159263660653834}
2023-01-04 08:55:39,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:39,467 INFO:     Epoch: 57
2023-01-04 08:55:41,038 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38287709256013236, 'Total loss': 0.38287709256013236} | train loss {'Reaction outcome loss': 0.30970915382734704, 'Total loss': 0.30970915382734704}
2023-01-04 08:55:41,038 INFO:     Found new best model at epoch 57
2023-01-04 08:55:41,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:41,039 INFO:     Epoch: 58
2023-01-04 08:55:42,551 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41130418131748836, 'Total loss': 0.41130418131748836} | train loss {'Reaction outcome loss': 0.3116065986750358, 'Total loss': 0.3116065986750358}
2023-01-04 08:55:42,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:42,551 INFO:     Epoch: 59
2023-01-04 08:55:44,113 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40638325760761895, 'Total loss': 0.40638325760761895} | train loss {'Reaction outcome loss': 0.3064192938836903, 'Total loss': 0.3064192938836903}
2023-01-04 08:55:44,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:44,114 INFO:     Epoch: 60
2023-01-04 08:55:45,683 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4054690440495809, 'Total loss': 0.4054690440495809} | train loss {'Reaction outcome loss': 0.3055466816152046, 'Total loss': 0.3055466816152046}
2023-01-04 08:55:45,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:45,683 INFO:     Epoch: 61
2023-01-04 08:55:47,244 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41715184251467385, 'Total loss': 0.41715184251467385} | train loss {'Reaction outcome loss': 0.3064074323442008, 'Total loss': 0.3064074323442008}
2023-01-04 08:55:47,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:47,244 INFO:     Epoch: 62
2023-01-04 08:55:48,825 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3985405017932256, 'Total loss': 0.3985405017932256} | train loss {'Reaction outcome loss': 0.30117233517152736, 'Total loss': 0.30117233517152736}
2023-01-04 08:55:48,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:48,826 INFO:     Epoch: 63
2023-01-04 08:55:50,389 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38784108211596807, 'Total loss': 0.38784108211596807} | train loss {'Reaction outcome loss': 0.3047125998225453, 'Total loss': 0.3047125998225453}
2023-01-04 08:55:50,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:50,389 INFO:     Epoch: 64
2023-01-04 08:55:51,904 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39493194421132405, 'Total loss': 0.39493194421132405} | train loss {'Reaction outcome loss': 0.30042581443106653, 'Total loss': 0.30042581443106653}
2023-01-04 08:55:51,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:51,905 INFO:     Epoch: 65
2023-01-04 08:55:53,500 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36877132654190065, 'Total loss': 0.36877132654190065} | train loss {'Reaction outcome loss': 0.2937309736594396, 'Total loss': 0.2937309736594396}
2023-01-04 08:55:53,500 INFO:     Found new best model at epoch 65
2023-01-04 08:55:53,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:53,500 INFO:     Epoch: 66
2023-01-04 08:55:55,095 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3774393161137899, 'Total loss': 0.3774393161137899} | train loss {'Reaction outcome loss': 0.29483948188030334, 'Total loss': 0.29483948188030334}
2023-01-04 08:55:55,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:55,095 INFO:     Epoch: 67
2023-01-04 08:55:56,685 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4130889008442561, 'Total loss': 0.4130889008442561} | train loss {'Reaction outcome loss': 0.29527149707186523, 'Total loss': 0.29527149707186523}
2023-01-04 08:55:56,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:56,686 INFO:     Epoch: 68
2023-01-04 08:55:58,270 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39619305630524954, 'Total loss': 0.39619305630524954} | train loss {'Reaction outcome loss': 0.29308270886271437, 'Total loss': 0.29308270886271437}
2023-01-04 08:55:58,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:58,271 INFO:     Epoch: 69
2023-01-04 08:55:59,834 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3921746199329694, 'Total loss': 0.3921746199329694} | train loss {'Reaction outcome loss': 0.29200177755381657, 'Total loss': 0.29200177755381657}
2023-01-04 08:55:59,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:55:59,834 INFO:     Epoch: 70
2023-01-04 08:56:01,338 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41205302278200784, 'Total loss': 0.41205302278200784} | train loss {'Reaction outcome loss': 0.29198551167219555, 'Total loss': 0.29198551167219555}
2023-01-04 08:56:01,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:01,338 INFO:     Epoch: 71
2023-01-04 08:56:02,893 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39684511423110963, 'Total loss': 0.39684511423110963} | train loss {'Reaction outcome loss': 0.28524455783169195, 'Total loss': 0.28524455783169195}
2023-01-04 08:56:02,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:02,893 INFO:     Epoch: 72
2023-01-04 08:56:04,451 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3916254679361979, 'Total loss': 0.3916254679361979} | train loss {'Reaction outcome loss': 0.2837805586197962, 'Total loss': 0.2837805586197962}
2023-01-04 08:56:04,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:04,451 INFO:     Epoch: 73
2023-01-04 08:56:06,028 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3993053515752157, 'Total loss': 0.3993053515752157} | train loss {'Reaction outcome loss': 0.28985499636360884, 'Total loss': 0.28985499636360884}
2023-01-04 08:56:06,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:06,028 INFO:     Epoch: 74
2023-01-04 08:56:07,604 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3900379439194997, 'Total loss': 0.3900379439194997} | train loss {'Reaction outcome loss': 0.27953900517862196, 'Total loss': 0.27953900517862196}
2023-01-04 08:56:07,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:07,604 INFO:     Epoch: 75
2023-01-04 08:56:09,130 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40041540265083314, 'Total loss': 0.40041540265083314} | train loss {'Reaction outcome loss': 0.27865744804432246, 'Total loss': 0.27865744804432246}
2023-01-04 08:56:09,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:09,130 INFO:     Epoch: 76
2023-01-04 08:56:10,673 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3731656382481257, 'Total loss': 0.3731656382481257} | train loss {'Reaction outcome loss': 0.27823183099177773, 'Total loss': 0.27823183099177773}
2023-01-04 08:56:10,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:10,674 INFO:     Epoch: 77
2023-01-04 08:56:12,242 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41306551098823546, 'Total loss': 0.41306551098823546} | train loss {'Reaction outcome loss': 0.27849272848359086, 'Total loss': 0.27849272848359086}
2023-01-04 08:56:12,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:12,242 INFO:     Epoch: 78
2023-01-04 08:56:13,806 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3898620982964834, 'Total loss': 0.3898620982964834} | train loss {'Reaction outcome loss': 0.27407679690673464, 'Total loss': 0.27407679690673464}
2023-01-04 08:56:13,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:13,807 INFO:     Epoch: 79
2023-01-04 08:56:15,358 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3880244751771291, 'Total loss': 0.3880244751771291} | train loss {'Reaction outcome loss': 0.27860035263136407, 'Total loss': 0.27860035263136407}
2023-01-04 08:56:15,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:15,358 INFO:     Epoch: 80
2023-01-04 08:56:16,916 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3963894764582316, 'Total loss': 0.3963894764582316} | train loss {'Reaction outcome loss': 0.27528755089758966, 'Total loss': 0.27528755089758966}
2023-01-04 08:56:16,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:16,916 INFO:     Epoch: 81
2023-01-04 08:56:18,431 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41213658452033997, 'Total loss': 0.41213658452033997} | train loss {'Reaction outcome loss': 0.272978222004343, 'Total loss': 0.272978222004343}
2023-01-04 08:56:18,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:18,431 INFO:     Epoch: 82
2023-01-04 08:56:19,985 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4058395008246104, 'Total loss': 0.4058395008246104} | train loss {'Reaction outcome loss': 0.2698799656024909, 'Total loss': 0.2698799656024909}
2023-01-04 08:56:19,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:19,986 INFO:     Epoch: 83
2023-01-04 08:56:21,593 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4063453674316406, 'Total loss': 0.4063453674316406} | train loss {'Reaction outcome loss': 0.27480337959764667, 'Total loss': 0.27480337959764667}
2023-01-04 08:56:21,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:21,593 INFO:     Epoch: 84
2023-01-04 08:56:23,183 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39676407078901926, 'Total loss': 0.39676407078901926} | train loss {'Reaction outcome loss': 0.27295593634947113, 'Total loss': 0.27295593634947113}
2023-01-04 08:56:23,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:23,183 INFO:     Epoch: 85
2023-01-04 08:56:24,760 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3831558336814245, 'Total loss': 0.3831558336814245} | train loss {'Reaction outcome loss': 0.27085111300975406, 'Total loss': 0.27085111300975406}
2023-01-04 08:56:24,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:24,760 INFO:     Epoch: 86
2023-01-04 08:56:26,358 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3993392566839854, 'Total loss': 0.3993392566839854} | train loss {'Reaction outcome loss': 0.2680076345102021, 'Total loss': 0.2680076345102021}
2023-01-04 08:56:26,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:26,359 INFO:     Epoch: 87
2023-01-04 08:56:27,863 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3595420718193054, 'Total loss': 0.3595420718193054} | train loss {'Reaction outcome loss': 0.26400614696611996, 'Total loss': 0.26400614696611996}
2023-01-04 08:56:27,864 INFO:     Found new best model at epoch 87
2023-01-04 08:56:27,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:27,865 INFO:     Epoch: 88
2023-01-04 08:56:29,433 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4043769180774689, 'Total loss': 0.4043769180774689} | train loss {'Reaction outcome loss': 0.2669462017741875, 'Total loss': 0.2669462017741875}
2023-01-04 08:56:29,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:29,433 INFO:     Epoch: 89
2023-01-04 08:56:30,998 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38118603924910227, 'Total loss': 0.38118603924910227} | train loss {'Reaction outcome loss': 0.2673597659256699, 'Total loss': 0.2673597659256699}
2023-01-04 08:56:30,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:30,999 INFO:     Epoch: 90
2023-01-04 08:56:32,561 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39578829109668734, 'Total loss': 0.39578829109668734} | train loss {'Reaction outcome loss': 0.26466574956955463, 'Total loss': 0.26466574956955463}
2023-01-04 08:56:32,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:32,561 INFO:     Epoch: 91
2023-01-04 08:56:34,140 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.413761035601298, 'Total loss': 0.413761035601298} | train loss {'Reaction outcome loss': 0.26010558680237844, 'Total loss': 0.26010558680237844}
2023-01-04 08:56:34,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:34,141 INFO:     Epoch: 92
2023-01-04 08:56:35,714 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37210230628649393, 'Total loss': 0.37210230628649393} | train loss {'Reaction outcome loss': 0.2607367114039535, 'Total loss': 0.2607367114039535}
2023-01-04 08:56:35,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:35,714 INFO:     Epoch: 93
2023-01-04 08:56:37,211 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37968696753184, 'Total loss': 0.37968696753184} | train loss {'Reaction outcome loss': 0.25825212669932024, 'Total loss': 0.25825212669932024}
2023-01-04 08:56:37,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:37,211 INFO:     Epoch: 94
2023-01-04 08:56:38,791 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3771957834561666, 'Total loss': 0.3771957834561666} | train loss {'Reaction outcome loss': 0.2630475641695601, 'Total loss': 0.2630475641695601}
2023-01-04 08:56:38,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:38,791 INFO:     Epoch: 95
2023-01-04 08:56:40,370 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3774641434351603, 'Total loss': 0.3774641434351603} | train loss {'Reaction outcome loss': 0.25709523957236147, 'Total loss': 0.25709523957236147}
2023-01-04 08:56:40,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:40,370 INFO:     Epoch: 96
2023-01-04 08:56:41,954 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3924495110909144, 'Total loss': 0.3924495110909144} | train loss {'Reaction outcome loss': 0.2560748345880947, 'Total loss': 0.2560748345880947}
2023-01-04 08:56:41,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:41,954 INFO:     Epoch: 97
2023-01-04 08:56:43,543 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.381753279765447, 'Total loss': 0.381753279765447} | train loss {'Reaction outcome loss': 0.254968406276152, 'Total loss': 0.254968406276152}
2023-01-04 08:56:43,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:43,543 INFO:     Epoch: 98
2023-01-04 08:56:45,140 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36040673553943636, 'Total loss': 0.36040673553943636} | train loss {'Reaction outcome loss': 0.2553806802802568, 'Total loss': 0.2553806802802568}
2023-01-04 08:56:45,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:45,141 INFO:     Epoch: 99
2023-01-04 08:56:46,657 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3684174547592799, 'Total loss': 0.3684174547592799} | train loss {'Reaction outcome loss': 0.2527316672868677, 'Total loss': 0.2527316672868677}
2023-01-04 08:56:46,658 INFO:     Best model found after epoch 88 of 100.
2023-01-04 08:56:46,658 INFO:   Done with stage: TRAINING
2023-01-04 08:56:46,658 INFO:   Starting stage: EVALUATION
2023-01-04 08:56:46,780 INFO:   Done with stage: EVALUATION
2023-01-04 08:56:46,780 INFO:   Leaving out SEQ value Fold_7
2023-01-04 08:56:46,792 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 08:56:46,793 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:56:47,442 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:56:47,442 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:56:47,511 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:56:47,511 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:56:47,511 INFO:     No hyperparam tuning for this model
2023-01-04 08:56:47,511 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:56:47,511 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:56:47,512 INFO:     None feature selector for col prot
2023-01-04 08:56:47,512 INFO:     None feature selector for col prot
2023-01-04 08:56:47,512 INFO:     None feature selector for col prot
2023-01-04 08:56:47,513 INFO:     None feature selector for col chem
2023-01-04 08:56:47,513 INFO:     None feature selector for col chem
2023-01-04 08:56:47,513 INFO:     None feature selector for col chem
2023-01-04 08:56:47,513 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:56:47,513 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:56:47,514 INFO:     Number of params in model 70111
2023-01-04 08:56:47,517 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:56:47,518 INFO:   Starting stage: TRAINING
2023-01-04 08:56:47,561 INFO:     Val loss before train {'Reaction outcome loss': 1.0119166533152262, 'Total loss': 1.0119166533152262}
2023-01-04 08:56:47,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:47,561 INFO:     Epoch: 0
2023-01-04 08:56:49,150 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8101513504981994, 'Total loss': 0.8101513504981994} | train loss {'Reaction outcome loss': 0.8275426517539937, 'Total loss': 0.8275426517539937}
2023-01-04 08:56:49,150 INFO:     Found new best model at epoch 0
2023-01-04 08:56:49,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:49,151 INFO:     Epoch: 1
2023-01-04 08:56:50,747 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.668537292877833, 'Total loss': 0.668537292877833} | train loss {'Reaction outcome loss': 0.6705070837310075, 'Total loss': 0.6705070837310075}
2023-01-04 08:56:50,747 INFO:     Found new best model at epoch 1
2023-01-04 08:56:50,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:50,748 INFO:     Epoch: 2
2023-01-04 08:56:52,338 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5993783016999562, 'Total loss': 0.5993783016999562} | train loss {'Reaction outcome loss': 0.5772031524659064, 'Total loss': 0.5772031524659064}
2023-01-04 08:56:52,339 INFO:     Found new best model at epoch 2
2023-01-04 08:56:52,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:52,339 INFO:     Epoch: 3
2023-01-04 08:56:53,950 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5760474999745687, 'Total loss': 0.5760474999745687} | train loss {'Reaction outcome loss': 0.5345305535767483, 'Total loss': 0.5345305535767483}
2023-01-04 08:56:53,950 INFO:     Found new best model at epoch 3
2023-01-04 08:56:53,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:53,951 INFO:     Epoch: 4
2023-01-04 08:56:55,055 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5652836620807647, 'Total loss': 0.5652836620807647} | train loss {'Reaction outcome loss': 0.5127495341675377, 'Total loss': 0.5127495341675377}
2023-01-04 08:56:55,055 INFO:     Found new best model at epoch 4
2023-01-04 08:56:55,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:55,056 INFO:     Epoch: 5
2023-01-04 08:56:56,077 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5608707825342815, 'Total loss': 0.5608707825342815} | train loss {'Reaction outcome loss': 0.5003808113319349, 'Total loss': 0.5003808113319349}
2023-01-04 08:56:56,077 INFO:     Found new best model at epoch 5
2023-01-04 08:56:56,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:56,078 INFO:     Epoch: 6
2023-01-04 08:56:57,092 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5562553425629934, 'Total loss': 0.5562553425629934} | train loss {'Reaction outcome loss': 0.4899627188698049, 'Total loss': 0.4899627188698049}
2023-01-04 08:56:57,092 INFO:     Found new best model at epoch 6
2023-01-04 08:56:57,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:57,093 INFO:     Epoch: 7
2023-01-04 08:56:58,114 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5341551919778188, 'Total loss': 0.5341551919778188} | train loss {'Reaction outcome loss': 0.4773683597464854, 'Total loss': 0.4773683597464854}
2023-01-04 08:56:58,114 INFO:     Found new best model at epoch 7
2023-01-04 08:56:58,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:58,115 INFO:     Epoch: 8
2023-01-04 08:56:59,533 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5606743574142456, 'Total loss': 0.5606743574142456} | train loss {'Reaction outcome loss': 0.47125107679341244, 'Total loss': 0.47125107679341244}
2023-01-04 08:56:59,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:56:59,534 INFO:     Epoch: 9
2023-01-04 08:57:01,085 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5289159019788107, 'Total loss': 0.5289159019788107} | train loss {'Reaction outcome loss': 0.4632069993535534, 'Total loss': 0.4632069993535534}
2023-01-04 08:57:01,085 INFO:     Found new best model at epoch 9
2023-01-04 08:57:01,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:01,086 INFO:     Epoch: 10
2023-01-04 08:57:02,610 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.547171409924825, 'Total loss': 0.547171409924825} | train loss {'Reaction outcome loss': 0.45869715232065866, 'Total loss': 0.45869715232065866}
2023-01-04 08:57:02,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:02,611 INFO:     Epoch: 11
2023-01-04 08:57:04,170 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.522608749071757, 'Total loss': 0.522608749071757} | train loss {'Reaction outcome loss': 0.45050663272396324, 'Total loss': 0.45050663272396324}
2023-01-04 08:57:04,170 INFO:     Found new best model at epoch 11
2023-01-04 08:57:04,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:04,171 INFO:     Epoch: 12
2023-01-04 08:57:05,733 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5308671315511068, 'Total loss': 0.5308671315511068} | train loss {'Reaction outcome loss': 0.4440907711694387, 'Total loss': 0.4440907711694387}
2023-01-04 08:57:05,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:05,733 INFO:     Epoch: 13
2023-01-04 08:57:07,288 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49214044312636057, 'Total loss': 0.49214044312636057} | train loss {'Reaction outcome loss': 0.44223659870211396, 'Total loss': 0.44223659870211396}
2023-01-04 08:57:07,288 INFO:     Found new best model at epoch 13
2023-01-04 08:57:07,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:07,289 INFO:     Epoch: 14
2023-01-04 08:57:08,837 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5116041958332062, 'Total loss': 0.5116041958332062} | train loss {'Reaction outcome loss': 0.4350978031162751, 'Total loss': 0.4350978031162751}
2023-01-04 08:57:08,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:08,838 INFO:     Epoch: 15
2023-01-04 08:57:10,367 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.521610689163208, 'Total loss': 0.521610689163208} | train loss {'Reaction outcome loss': 0.43169167662032676, 'Total loss': 0.43169167662032676}
2023-01-04 08:57:10,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:10,367 INFO:     Epoch: 16
2023-01-04 08:57:11,945 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4826033075650533, 'Total loss': 0.4826033075650533} | train loss {'Reaction outcome loss': 0.4278798143678624, 'Total loss': 0.4278798143678624}
2023-01-04 08:57:11,945 INFO:     Found new best model at epoch 16
2023-01-04 08:57:11,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:11,946 INFO:     Epoch: 17
2023-01-04 08:57:13,514 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5000496327877044, 'Total loss': 0.5000496327877044} | train loss {'Reaction outcome loss': 0.42415586057445204, 'Total loss': 0.42415586057445204}
2023-01-04 08:57:13,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:13,515 INFO:     Epoch: 18
2023-01-04 08:57:15,075 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5123032828172048, 'Total loss': 0.5123032828172048} | train loss {'Reaction outcome loss': 0.4181361934876184, 'Total loss': 0.4181361934876184}
2023-01-04 08:57:15,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:15,076 INFO:     Epoch: 19
2023-01-04 08:57:16,636 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5261203626791636, 'Total loss': 0.5261203626791636} | train loss {'Reaction outcome loss': 0.4114824829333956, 'Total loss': 0.4114824829333956}
2023-01-04 08:57:16,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:16,637 INFO:     Epoch: 20
2023-01-04 08:57:18,185 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4894890348116557, 'Total loss': 0.4894890348116557} | train loss {'Reaction outcome loss': 0.410093838718824, 'Total loss': 0.410093838718824}
2023-01-04 08:57:18,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:18,185 INFO:     Epoch: 21
2023-01-04 08:57:19,700 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48545929193496706, 'Total loss': 0.48545929193496706} | train loss {'Reaction outcome loss': 0.4072933766439503, 'Total loss': 0.4072933766439503}
2023-01-04 08:57:19,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:19,700 INFO:     Epoch: 22
2023-01-04 08:57:21,259 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47577751775582633, 'Total loss': 0.47577751775582633} | train loss {'Reaction outcome loss': 0.39918044230998206, 'Total loss': 0.39918044230998206}
2023-01-04 08:57:21,259 INFO:     Found new best model at epoch 22
2023-01-04 08:57:21,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:21,260 INFO:     Epoch: 23
2023-01-04 08:57:22,818 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4841532309850057, 'Total loss': 0.4841532309850057} | train loss {'Reaction outcome loss': 0.39907709347749876, 'Total loss': 0.39907709347749876}
2023-01-04 08:57:22,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:22,819 INFO:     Epoch: 24
2023-01-04 08:57:24,368 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.486259921391805, 'Total loss': 0.486259921391805} | train loss {'Reaction outcome loss': 0.392107891745946, 'Total loss': 0.392107891745946}
2023-01-04 08:57:24,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:24,368 INFO:     Epoch: 25
2023-01-04 08:57:25,904 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5014097770055135, 'Total loss': 0.5014097770055135} | train loss {'Reaction outcome loss': 0.3880447782172623, 'Total loss': 0.3880447782172623}
2023-01-04 08:57:25,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:25,904 INFO:     Epoch: 26
2023-01-04 08:57:27,471 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4989733477433523, 'Total loss': 0.4989733477433523} | train loss {'Reaction outcome loss': 0.38758529316539797, 'Total loss': 0.38758529316539797}
2023-01-04 08:57:27,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:27,471 INFO:     Epoch: 27
2023-01-04 08:57:29,008 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4578120479981104, 'Total loss': 0.4578120479981104} | train loss {'Reaction outcome loss': 0.38193443697282126, 'Total loss': 0.38193443697282126}
2023-01-04 08:57:29,008 INFO:     Found new best model at epoch 27
2023-01-04 08:57:29,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:29,009 INFO:     Epoch: 28
2023-01-04 08:57:30,585 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46826888918876647, 'Total loss': 0.46826888918876647} | train loss {'Reaction outcome loss': 0.37665592381454976, 'Total loss': 0.37665592381454976}
2023-01-04 08:57:30,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:30,586 INFO:     Epoch: 29
2023-01-04 08:57:32,147 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4630142092704773, 'Total loss': 0.4630142092704773} | train loss {'Reaction outcome loss': 0.37278069765559174, 'Total loss': 0.37278069765559174}
2023-01-04 08:57:32,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:32,148 INFO:     Epoch: 30
2023-01-04 08:57:33,726 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46391141017278037, 'Total loss': 0.46391141017278037} | train loss {'Reaction outcome loss': 0.37560346711843884, 'Total loss': 0.37560346711843884}
2023-01-04 08:57:33,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:33,727 INFO:     Epoch: 31
2023-01-04 08:57:35,248 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46146984696388244, 'Total loss': 0.46146984696388244} | train loss {'Reaction outcome loss': 0.36381874774122064, 'Total loss': 0.36381874774122064}
2023-01-04 08:57:35,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:35,248 INFO:     Epoch: 32
2023-01-04 08:57:36,808 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4483465870221456, 'Total loss': 0.4483465870221456} | train loss {'Reaction outcome loss': 0.36195773413465343, 'Total loss': 0.36195773413465343}
2023-01-04 08:57:36,808 INFO:     Found new best model at epoch 32
2023-01-04 08:57:36,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:36,809 INFO:     Epoch: 33
2023-01-04 08:57:38,330 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45645986596743265, 'Total loss': 0.45645986596743265} | train loss {'Reaction outcome loss': 0.3599018456703489, 'Total loss': 0.3599018456703489}
2023-01-04 08:57:38,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:38,331 INFO:     Epoch: 34
2023-01-04 08:57:39,884 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4487451414267222, 'Total loss': 0.4487451414267222} | train loss {'Reaction outcome loss': 0.35989496114559555, 'Total loss': 0.35989496114559555}
2023-01-04 08:57:39,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:39,885 INFO:     Epoch: 35
2023-01-04 08:57:41,451 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45616265137990314, 'Total loss': 0.45616265137990314} | train loss {'Reaction outcome loss': 0.35151928488420664, 'Total loss': 0.35151928488420664}
2023-01-04 08:57:41,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:41,451 INFO:     Epoch: 36
2023-01-04 08:57:43,016 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4550826042890549, 'Total loss': 0.4550826042890549} | train loss {'Reaction outcome loss': 0.34804151099619024, 'Total loss': 0.34804151099619024}
2023-01-04 08:57:43,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:43,016 INFO:     Epoch: 37
2023-01-04 08:57:44,542 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.440872718890508, 'Total loss': 0.440872718890508} | train loss {'Reaction outcome loss': 0.34358423119847953, 'Total loss': 0.34358423119847953}
2023-01-04 08:57:44,542 INFO:     Found new best model at epoch 37
2023-01-04 08:57:44,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:44,543 INFO:     Epoch: 38
2023-01-04 08:57:46,110 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.452498205502828, 'Total loss': 0.452498205502828} | train loss {'Reaction outcome loss': 0.34260917740070435, 'Total loss': 0.34260917740070435}
2023-01-04 08:57:46,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:46,110 INFO:     Epoch: 39
2023-01-04 08:57:47,629 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4502778430779775, 'Total loss': 0.4502778430779775} | train loss {'Reaction outcome loss': 0.3387424031319601, 'Total loss': 0.3387424031319601}
2023-01-04 08:57:47,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:47,629 INFO:     Epoch: 40
2023-01-04 08:57:49,192 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4342210014661153, 'Total loss': 0.4342210014661153} | train loss {'Reaction outcome loss': 0.3349570322660763, 'Total loss': 0.3349570322660763}
2023-01-04 08:57:49,192 INFO:     Found new best model at epoch 40
2023-01-04 08:57:49,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:49,193 INFO:     Epoch: 41
2023-01-04 08:57:50,752 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44233446617921196, 'Total loss': 0.44233446617921196} | train loss {'Reaction outcome loss': 0.3334253093073084, 'Total loss': 0.3334253093073084}
2023-01-04 08:57:50,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:50,752 INFO:     Epoch: 42
2023-01-04 08:57:52,314 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4250461926062902, 'Total loss': 0.4250461926062902} | train loss {'Reaction outcome loss': 0.32843720213600874, 'Total loss': 0.32843720213600874}
2023-01-04 08:57:52,315 INFO:     Found new best model at epoch 42
2023-01-04 08:57:52,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:52,316 INFO:     Epoch: 43
2023-01-04 08:57:53,843 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47858954469362897, 'Total loss': 0.47858954469362897} | train loss {'Reaction outcome loss': 0.331453048311416, 'Total loss': 0.331453048311416}
2023-01-04 08:57:53,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:53,844 INFO:     Epoch: 44
2023-01-04 08:57:55,409 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44353327055772146, 'Total loss': 0.44353327055772146} | train loss {'Reaction outcome loss': 0.33111050087514765, 'Total loss': 0.33111050087514765}
2023-01-04 08:57:55,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:55,409 INFO:     Epoch: 45
2023-01-04 08:57:56,942 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4209873616695404, 'Total loss': 0.4209873616695404} | train loss {'Reaction outcome loss': 0.32555368556119907, 'Total loss': 0.32555368556119907}
2023-01-04 08:57:56,942 INFO:     Found new best model at epoch 45
2023-01-04 08:57:56,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:56,943 INFO:     Epoch: 46
2023-01-04 08:57:58,507 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44762158195177715, 'Total loss': 0.44762158195177715} | train loss {'Reaction outcome loss': 0.32380847864202644, 'Total loss': 0.32380847864202644}
2023-01-04 08:57:58,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:57:58,508 INFO:     Epoch: 47
2023-01-04 08:58:00,066 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4646056373914083, 'Total loss': 0.4646056373914083} | train loss {'Reaction outcome loss': 0.3217500714511217, 'Total loss': 0.3217500714511217}
2023-01-04 08:58:00,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:00,066 INFO:     Epoch: 48
2023-01-04 08:58:01,634 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43466030756632484, 'Total loss': 0.43466030756632484} | train loss {'Reaction outcome loss': 0.31973240638844375, 'Total loss': 0.31973240638844375}
2023-01-04 08:58:01,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:01,634 INFO:     Epoch: 49
2023-01-04 08:58:03,163 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43181095123291013, 'Total loss': 0.43181095123291013} | train loss {'Reaction outcome loss': 0.31759453726266695, 'Total loss': 0.31759453726266695}
2023-01-04 08:58:03,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:03,163 INFO:     Epoch: 50
2023-01-04 08:58:04,736 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44656063318252565, 'Total loss': 0.44656063318252565} | train loss {'Reaction outcome loss': 0.31263745597661186, 'Total loss': 0.31263745597661186}
2023-01-04 08:58:04,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:04,738 INFO:     Epoch: 51
2023-01-04 08:58:06,267 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4327468434969584, 'Total loss': 0.4327468434969584} | train loss {'Reaction outcome loss': 0.30939295056817334, 'Total loss': 0.30939295056817334}
2023-01-04 08:58:06,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:06,267 INFO:     Epoch: 52
2023-01-04 08:58:07,832 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4340273797512054, 'Total loss': 0.4340273797512054} | train loss {'Reaction outcome loss': 0.30708513602560605, 'Total loss': 0.30708513602560605}
2023-01-04 08:58:07,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:07,832 INFO:     Epoch: 53
2023-01-04 08:58:09,422 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4211933453877767, 'Total loss': 0.4211933453877767} | train loss {'Reaction outcome loss': 0.3044779206548787, 'Total loss': 0.3044779206548787}
2023-01-04 08:58:09,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:09,422 INFO:     Epoch: 54
2023-01-04 08:58:10,998 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4330500145753225, 'Total loss': 0.4330500145753225} | train loss {'Reaction outcome loss': 0.3017602426534525, 'Total loss': 0.3017602426534525}
2023-01-04 08:58:10,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:10,999 INFO:     Epoch: 55
2023-01-04 08:58:12,534 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.422314308087031, 'Total loss': 0.422314308087031} | train loss {'Reaction outcome loss': 0.30431020700974587, 'Total loss': 0.30431020700974587}
2023-01-04 08:58:12,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:12,534 INFO:     Epoch: 56
2023-01-04 08:58:14,076 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42792399326960245, 'Total loss': 0.42792399326960245} | train loss {'Reaction outcome loss': 0.30042072918118123, 'Total loss': 0.30042072918118123}
2023-01-04 08:58:14,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:14,076 INFO:     Epoch: 57
2023-01-04 08:58:15,638 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42644703189531963, 'Total loss': 0.42644703189531963} | train loss {'Reaction outcome loss': 0.29689573448164797, 'Total loss': 0.29689573448164797}
2023-01-04 08:58:15,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:15,638 INFO:     Epoch: 58
2023-01-04 08:58:17,208 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4240996221701304, 'Total loss': 0.4240996221701304} | train loss {'Reaction outcome loss': 0.297162444179454, 'Total loss': 0.297162444179454}
2023-01-04 08:58:17,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:17,208 INFO:     Epoch: 59
2023-01-04 08:58:18,775 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44152856469154356, 'Total loss': 0.44152856469154356} | train loss {'Reaction outcome loss': 0.2949391055838726, 'Total loss': 0.2949391055838726}
2023-01-04 08:58:18,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:18,775 INFO:     Epoch: 60
2023-01-04 08:58:20,333 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4217346062262853, 'Total loss': 0.4217346062262853} | train loss {'Reaction outcome loss': 0.29553695316241535, 'Total loss': 0.29553695316241535}
2023-01-04 08:58:20,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:20,333 INFO:     Epoch: 61
2023-01-04 08:58:21,888 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46072888672351836, 'Total loss': 0.46072888672351836} | train loss {'Reaction outcome loss': 0.2954603826042117, 'Total loss': 0.2954603826042117}
2023-01-04 08:58:21,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:21,888 INFO:     Epoch: 62
2023-01-04 08:58:23,417 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3976812183856964, 'Total loss': 0.3976812183856964} | train loss {'Reaction outcome loss': 0.2946099443663759, 'Total loss': 0.2946099443663759}
2023-01-04 08:58:23,418 INFO:     Found new best model at epoch 62
2023-01-04 08:58:23,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:23,419 INFO:     Epoch: 63
2023-01-04 08:58:25,038 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.443270081281662, 'Total loss': 0.443270081281662} | train loss {'Reaction outcome loss': 0.28947675384123833, 'Total loss': 0.28947675384123833}
2023-01-04 08:58:25,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:25,038 INFO:     Epoch: 64
2023-01-04 08:58:26,672 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4330192585786184, 'Total loss': 0.4330192585786184} | train loss {'Reaction outcome loss': 0.29034882057659894, 'Total loss': 0.29034882057659894}
2023-01-04 08:58:26,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:26,672 INFO:     Epoch: 65
2023-01-04 08:58:28,281 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4383346458276113, 'Total loss': 0.4383346458276113} | train loss {'Reaction outcome loss': 0.2906733102262666, 'Total loss': 0.2906733102262666}
2023-01-04 08:58:28,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:28,282 INFO:     Epoch: 66
2023-01-04 08:58:29,845 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4340733170509338, 'Total loss': 0.4340733170509338} | train loss {'Reaction outcome loss': 0.2880587199104392, 'Total loss': 0.2880587199104392}
2023-01-04 08:58:29,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:29,846 INFO:     Epoch: 67
2023-01-04 08:58:31,446 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4196288307507833, 'Total loss': 0.4196288307507833} | train loss {'Reaction outcome loss': 0.28471006184063236, 'Total loss': 0.28471006184063236}
2023-01-04 08:58:31,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:31,447 INFO:     Epoch: 68
2023-01-04 08:58:33,017 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4457764208316803, 'Total loss': 0.4457764208316803} | train loss {'Reaction outcome loss': 0.2834957299303492, 'Total loss': 0.2834957299303492}
2023-01-04 08:58:33,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:33,017 INFO:     Epoch: 69
2023-01-04 08:58:34,638 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40512445867061614, 'Total loss': 0.40512445867061614} | train loss {'Reaction outcome loss': 0.28103254722021115, 'Total loss': 0.28103254722021115}
2023-01-04 08:58:34,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:34,638 INFO:     Epoch: 70
2023-01-04 08:58:36,259 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4126765827337901, 'Total loss': 0.4126765827337901} | train loss {'Reaction outcome loss': 0.27845915642294644, 'Total loss': 0.27845915642294644}
2023-01-04 08:58:36,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:36,260 INFO:     Epoch: 71
2023-01-04 08:58:37,864 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.413431719938914, 'Total loss': 0.413431719938914} | train loss {'Reaction outcome loss': 0.2776155737817072, 'Total loss': 0.2776155737817072}
2023-01-04 08:58:37,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:37,864 INFO:     Epoch: 72
2023-01-04 08:58:39,439 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4135453124841054, 'Total loss': 0.4135453124841054} | train loss {'Reaction outcome loss': 0.2768328852063912, 'Total loss': 0.2768328852063912}
2023-01-04 08:58:39,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:39,439 INFO:     Epoch: 73
2023-01-04 08:58:41,067 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44335709015528363, 'Total loss': 0.44335709015528363} | train loss {'Reaction outcome loss': 0.27668881796919054, 'Total loss': 0.27668881796919054}
2023-01-04 08:58:41,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:41,068 INFO:     Epoch: 74
2023-01-04 08:58:42,641 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4408571441968282, 'Total loss': 0.4408571441968282} | train loss {'Reaction outcome loss': 0.27313835912179, 'Total loss': 0.27313835912179}
2023-01-04 08:58:42,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:42,641 INFO:     Epoch: 75
2023-01-04 08:58:44,265 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40907816886901854, 'Total loss': 0.40907816886901854} | train loss {'Reaction outcome loss': 0.2685706321728359, 'Total loss': 0.2685706321728359}
2023-01-04 08:58:44,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:44,265 INFO:     Epoch: 76
2023-01-04 08:58:45,884 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4431772102912267, 'Total loss': 0.4431772102912267} | train loss {'Reaction outcome loss': 0.2768499271587775, 'Total loss': 0.2768499271587775}
2023-01-04 08:58:45,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:45,884 INFO:     Epoch: 77
2023-01-04 08:58:47,504 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4211573928594589, 'Total loss': 0.4211573928594589} | train loss {'Reaction outcome loss': 0.2706944997345067, 'Total loss': 0.2706944997345067}
2023-01-04 08:58:47,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:47,505 INFO:     Epoch: 78
2023-01-04 08:58:49,045 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4245695104201635, 'Total loss': 0.4245695104201635} | train loss {'Reaction outcome loss': 0.2690315929238116, 'Total loss': 0.2690315929238116}
2023-01-04 08:58:49,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:49,046 INFO:     Epoch: 79
2023-01-04 08:58:50,647 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4227897514899572, 'Total loss': 0.4227897514899572} | train loss {'Reaction outcome loss': 0.26662879827220515, 'Total loss': 0.26662879827220515}
2023-01-04 08:58:50,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:50,648 INFO:     Epoch: 80
2023-01-04 08:58:52,273 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.400189275542895, 'Total loss': 0.400189275542895} | train loss {'Reaction outcome loss': 0.2654889207131596, 'Total loss': 0.2654889207131596}
2023-01-04 08:58:52,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:52,273 INFO:     Epoch: 81
2023-01-04 08:58:53,906 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4516437153021495, 'Total loss': 0.4516437153021495} | train loss {'Reaction outcome loss': 0.26860080159097804, 'Total loss': 0.26860080159097804}
2023-01-04 08:58:53,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:53,906 INFO:     Epoch: 82
2023-01-04 08:58:55,526 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4349191417296728, 'Total loss': 0.4349191417296728} | train loss {'Reaction outcome loss': 0.26572925858334084, 'Total loss': 0.26572925858334084}
2023-01-04 08:58:55,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:55,526 INFO:     Epoch: 83
2023-01-04 08:58:57,104 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.401384902993838, 'Total loss': 0.401384902993838} | train loss {'Reaction outcome loss': 0.2656950166563265, 'Total loss': 0.2656950166563265}
2023-01-04 08:58:57,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:57,104 INFO:     Epoch: 84
2023-01-04 08:58:58,735 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3851804127295812, 'Total loss': 0.3851804127295812} | train loss {'Reaction outcome loss': 0.26462951321356565, 'Total loss': 0.26462951321356565}
2023-01-04 08:58:58,735 INFO:     Found new best model at epoch 84
2023-01-04 08:58:58,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:58:58,736 INFO:     Epoch: 85
2023-01-04 08:59:00,307 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42266710499922433, 'Total loss': 0.42266710499922433} | train loss {'Reaction outcome loss': 0.2646383820135241, 'Total loss': 0.2646383820135241}
2023-01-04 08:59:00,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:00,308 INFO:     Epoch: 86
2023-01-04 08:59:01,919 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40149395962556206, 'Total loss': 0.40149395962556206} | train loss {'Reaction outcome loss': 0.2619256388113602, 'Total loss': 0.2619256388113602}
2023-01-04 08:59:01,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:01,919 INFO:     Epoch: 87
2023-01-04 08:59:03,526 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4161593953768412, 'Total loss': 0.4161593953768412} | train loss {'Reaction outcome loss': 0.25961548049634975, 'Total loss': 0.25961548049634975}
2023-01-04 08:59:03,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:03,527 INFO:     Epoch: 88
2023-01-04 08:59:05,141 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4324663559595744, 'Total loss': 0.4324663559595744} | train loss {'Reaction outcome loss': 0.26247146197120635, 'Total loss': 0.26247146197120635}
2023-01-04 08:59:05,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:05,141 INFO:     Epoch: 89
2023-01-04 08:59:06,723 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4201591471831004, 'Total loss': 0.4201591471831004} | train loss {'Reaction outcome loss': 0.25634360930710925, 'Total loss': 0.25634360930710925}
2023-01-04 08:59:06,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:06,724 INFO:     Epoch: 90
2023-01-04 08:59:08,359 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4161039034525553, 'Total loss': 0.4161039034525553} | train loss {'Reaction outcome loss': 0.25405190517917436, 'Total loss': 0.25405190517917436}
2023-01-04 08:59:08,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:08,360 INFO:     Epoch: 91
2023-01-04 08:59:09,929 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4201724241177241, 'Total loss': 0.4201724241177241} | train loss {'Reaction outcome loss': 0.2589957949971034, 'Total loss': 0.2589957949971034}
2023-01-04 08:59:09,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:09,929 INFO:     Epoch: 92
2023-01-04 08:59:11,540 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42258656919002535, 'Total loss': 0.42258656919002535} | train loss {'Reaction outcome loss': 0.25608184497924485, 'Total loss': 0.25608184497924485}
2023-01-04 08:59:11,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:11,540 INFO:     Epoch: 93
2023-01-04 08:59:13,153 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44071289896965027, 'Total loss': 0.44071289896965027} | train loss {'Reaction outcome loss': 0.2587408248456161, 'Total loss': 0.2587408248456161}
2023-01-04 08:59:13,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:13,153 INFO:     Epoch: 94
2023-01-04 08:59:14,782 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4235978583494822, 'Total loss': 0.4235978583494822} | train loss {'Reaction outcome loss': 0.2573453040544737, 'Total loss': 0.2573453040544737}
2023-01-04 08:59:14,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:14,783 INFO:     Epoch: 95
2023-01-04 08:59:16,373 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43397813439369204, 'Total loss': 0.43397813439369204} | train loss {'Reaction outcome loss': 0.2538163966435388, 'Total loss': 0.2538163966435388}
2023-01-04 08:59:16,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:16,375 INFO:     Epoch: 96
2023-01-04 08:59:17,974 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4156330992778142, 'Total loss': 0.4156330992778142} | train loss {'Reaction outcome loss': 0.2515276413316761, 'Total loss': 0.2515276413316761}
2023-01-04 08:59:17,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:17,974 INFO:     Epoch: 97
2023-01-04 08:59:19,580 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3974827080965042, 'Total loss': 0.3974827080965042} | train loss {'Reaction outcome loss': 0.25644468744739296, 'Total loss': 0.25644468744739296}
2023-01-04 08:59:19,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:19,580 INFO:     Epoch: 98
2023-01-04 08:59:21,213 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4199840803941091, 'Total loss': 0.4199840803941091} | train loss {'Reaction outcome loss': 0.2555916464151243, 'Total loss': 0.2555916464151243}
2023-01-04 08:59:21,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:21,213 INFO:     Epoch: 99
2023-01-04 08:59:22,841 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4086957653363546, 'Total loss': 0.4086957653363546} | train loss {'Reaction outcome loss': 0.25274173772829966, 'Total loss': 0.25274173772829966}
2023-01-04 08:59:22,842 INFO:     Best model found after epoch 85 of 100.
2023-01-04 08:59:22,842 INFO:   Done with stage: TRAINING
2023-01-04 08:59:22,842 INFO:   Starting stage: EVALUATION
2023-01-04 08:59:22,965 INFO:   Done with stage: EVALUATION
2023-01-04 08:59:22,965 INFO:   Leaving out SEQ value Fold_8
2023-01-04 08:59:22,978 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 08:59:22,978 INFO:   Starting stage: FEATURE SCALING
2023-01-04 08:59:23,632 INFO:   Done with stage: FEATURE SCALING
2023-01-04 08:59:23,632 INFO:   Starting stage: SCALING TARGETS
2023-01-04 08:59:23,700 INFO:   Done with stage: SCALING TARGETS
2023-01-04 08:59:23,700 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:59:23,700 INFO:     No hyperparam tuning for this model
2023-01-04 08:59:23,700 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 08:59:23,700 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 08:59:23,701 INFO:     None feature selector for col prot
2023-01-04 08:59:23,701 INFO:     None feature selector for col prot
2023-01-04 08:59:23,701 INFO:     None feature selector for col prot
2023-01-04 08:59:23,702 INFO:     None feature selector for col chem
2023-01-04 08:59:23,702 INFO:     None feature selector for col chem
2023-01-04 08:59:23,702 INFO:     None feature selector for col chem
2023-01-04 08:59:23,702 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 08:59:23,702 INFO:   Starting stage: BUILD MODEL
2023-01-04 08:59:23,703 INFO:     Number of params in model 70111
2023-01-04 08:59:23,706 INFO:   Done with stage: BUILD MODEL
2023-01-04 08:59:23,706 INFO:   Starting stage: TRAINING
2023-01-04 08:59:23,749 INFO:     Val loss before train {'Reaction outcome loss': 0.9779061277707418, 'Total loss': 0.9779061277707418}
2023-01-04 08:59:23,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:23,749 INFO:     Epoch: 0
2023-01-04 08:59:25,330 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7197833975156148, 'Total loss': 0.7197833975156148} | train loss {'Reaction outcome loss': 0.8469855460449246, 'Total loss': 0.8469855460449246}
2023-01-04 08:59:25,330 INFO:     Found new best model at epoch 0
2023-01-04 08:59:25,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:25,331 INFO:     Epoch: 1
2023-01-04 08:59:26,889 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6107851723829906, 'Total loss': 0.6107851723829906} | train loss {'Reaction outcome loss': 0.6812786882749964, 'Total loss': 0.6812786882749964}
2023-01-04 08:59:26,889 INFO:     Found new best model at epoch 1
2023-01-04 08:59:26,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:26,890 INFO:     Epoch: 2
2023-01-04 08:59:28,517 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5769848167896271, 'Total loss': 0.5769848167896271} | train loss {'Reaction outcome loss': 0.5916730945506251, 'Total loss': 0.5916730945506251}
2023-01-04 08:59:28,518 INFO:     Found new best model at epoch 2
2023-01-04 08:59:28,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:28,518 INFO:     Epoch: 3
2023-01-04 08:59:30,152 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5306601544221242, 'Total loss': 0.5306601544221242} | train loss {'Reaction outcome loss': 0.5506134382331415, 'Total loss': 0.5506134382331415}
2023-01-04 08:59:30,152 INFO:     Found new best model at epoch 3
2023-01-04 08:59:30,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:30,153 INFO:     Epoch: 4
2023-01-04 08:59:31,775 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5025128920873007, 'Total loss': 0.5025128920873007} | train loss {'Reaction outcome loss': 0.5259286023757087, 'Total loss': 0.5259286023757087}
2023-01-04 08:59:31,775 INFO:     Found new best model at epoch 4
2023-01-04 08:59:31,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:31,776 INFO:     Epoch: 5
2023-01-04 08:59:33,364 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5157310386498769, 'Total loss': 0.5157310386498769} | train loss {'Reaction outcome loss': 0.5147707298236633, 'Total loss': 0.5147707298236633}
2023-01-04 08:59:33,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:33,364 INFO:     Epoch: 6
2023-01-04 08:59:34,969 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4988867481549581, 'Total loss': 0.4988867481549581} | train loss {'Reaction outcome loss': 0.5013268830436232, 'Total loss': 0.5013268830436232}
2023-01-04 08:59:34,970 INFO:     Found new best model at epoch 6
2023-01-04 08:59:34,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:34,971 INFO:     Epoch: 7
2023-01-04 08:59:36,548 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5125317752361298, 'Total loss': 0.5125317752361298} | train loss {'Reaction outcome loss': 0.48720337455883783, 'Total loss': 0.48720337455883783}
2023-01-04 08:59:36,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:36,549 INFO:     Epoch: 8
2023-01-04 08:59:38,169 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5001352210839589, 'Total loss': 0.5001352210839589} | train loss {'Reaction outcome loss': 0.4818278578537035, 'Total loss': 0.4818278578537035}
2023-01-04 08:59:38,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:38,169 INFO:     Epoch: 9
2023-01-04 08:59:39,782 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46776267091433205, 'Total loss': 0.46776267091433205} | train loss {'Reaction outcome loss': 0.47183889155998987, 'Total loss': 0.47183889155998987}
2023-01-04 08:59:39,782 INFO:     Found new best model at epoch 9
2023-01-04 08:59:39,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:39,783 INFO:     Epoch: 10
2023-01-04 08:59:41,393 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4826837380727132, 'Total loss': 0.4826837380727132} | train loss {'Reaction outcome loss': 0.4655780083489762, 'Total loss': 0.4655780083489762}
2023-01-04 08:59:41,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:41,393 INFO:     Epoch: 11
2023-01-04 08:59:42,978 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46810559630393983, 'Total loss': 0.46810559630393983} | train loss {'Reaction outcome loss': 0.46100486890288467, 'Total loss': 0.46100486890288467}
2023-01-04 08:59:42,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:42,978 INFO:     Epoch: 12
2023-01-04 08:59:44,587 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46511332392692567, 'Total loss': 0.46511332392692567} | train loss {'Reaction outcome loss': 0.4569137787130335, 'Total loss': 0.4569137787130335}
2023-01-04 08:59:44,587 INFO:     Found new best model at epoch 12
2023-01-04 08:59:44,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:44,588 INFO:     Epoch: 13
2023-01-04 08:59:46,168 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4760699232419332, 'Total loss': 0.4760699232419332} | train loss {'Reaction outcome loss': 0.44869220477364125, 'Total loss': 0.44869220477364125}
2023-01-04 08:59:46,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:46,168 INFO:     Epoch: 14
2023-01-04 08:59:47,787 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.465133798122406, 'Total loss': 0.465133798122406} | train loss {'Reaction outcome loss': 0.44646632972607114, 'Total loss': 0.44646632972607114}
2023-01-04 08:59:47,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:47,788 INFO:     Epoch: 15
2023-01-04 08:59:49,418 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4546045978864034, 'Total loss': 0.4546045978864034} | train loss {'Reaction outcome loss': 0.4375431979821477, 'Total loss': 0.4375431979821477}
2023-01-04 08:59:49,418 INFO:     Found new best model at epoch 15
2023-01-04 08:59:49,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:49,419 INFO:     Epoch: 16
2023-01-04 08:59:51,035 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46299025416374207, 'Total loss': 0.46299025416374207} | train loss {'Reaction outcome loss': 0.437611889107563, 'Total loss': 0.437611889107563}
2023-01-04 08:59:51,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:51,035 INFO:     Epoch: 17
2023-01-04 08:59:52,608 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47391523321469625, 'Total loss': 0.47391523321469625} | train loss {'Reaction outcome loss': 0.43376090918206994, 'Total loss': 0.43376090918206994}
2023-01-04 08:59:52,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:52,609 INFO:     Epoch: 18
2023-01-04 08:59:54,193 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45712043245633444, 'Total loss': 0.45712043245633444} | train loss {'Reaction outcome loss': 0.4287960422813677, 'Total loss': 0.4287960422813677}
2023-01-04 08:59:54,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:54,194 INFO:     Epoch: 19
2023-01-04 08:59:55,820 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4444492479165395, 'Total loss': 0.4444492479165395} | train loss {'Reaction outcome loss': 0.42557637183674835, 'Total loss': 0.42557637183674835}
2023-01-04 08:59:55,820 INFO:     Found new best model at epoch 19
2023-01-04 08:59:55,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:55,821 INFO:     Epoch: 20
2023-01-04 08:59:57,438 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4366300940513611, 'Total loss': 0.4366300940513611} | train loss {'Reaction outcome loss': 0.419805933960078, 'Total loss': 0.419805933960078}
2023-01-04 08:59:57,438 INFO:     Found new best model at epoch 20
2023-01-04 08:59:57,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:57,439 INFO:     Epoch: 21
2023-01-04 08:59:59,055 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43918414215246837, 'Total loss': 0.43918414215246837} | train loss {'Reaction outcome loss': 0.4174689627403817, 'Total loss': 0.4174689627403817}
2023-01-04 08:59:59,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 08:59:59,055 INFO:     Epoch: 22
2023-01-04 09:00:00,636 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43706801533699036, 'Total loss': 0.43706801533699036} | train loss {'Reaction outcome loss': 0.4147502244164367, 'Total loss': 0.4147502244164367}
2023-01-04 09:00:00,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:00,636 INFO:     Epoch: 23
2023-01-04 09:00:02,264 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4570699195067088, 'Total loss': 0.4570699195067088} | train loss {'Reaction outcome loss': 0.4104266574182665, 'Total loss': 0.4104266574182665}
2023-01-04 09:00:02,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:02,264 INFO:     Epoch: 24
2023-01-04 09:00:03,849 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4231665392716726, 'Total loss': 0.4231665392716726} | train loss {'Reaction outcome loss': 0.407783380430528, 'Total loss': 0.407783380430528}
2023-01-04 09:00:03,849 INFO:     Found new best model at epoch 24
2023-01-04 09:00:03,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:03,849 INFO:     Epoch: 25
2023-01-04 09:00:05,467 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47110219995180763, 'Total loss': 0.47110219995180763} | train loss {'Reaction outcome loss': 0.40237142683581756, 'Total loss': 0.40237142683581756}
2023-01-04 09:00:05,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:05,467 INFO:     Epoch: 26
2023-01-04 09:00:07,086 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44244138300418856, 'Total loss': 0.44244138300418856} | train loss {'Reaction outcome loss': 0.40023677992476453, 'Total loss': 0.40023677992476453}
2023-01-04 09:00:07,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:07,088 INFO:     Epoch: 27
2023-01-04 09:00:08,716 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42643585602442424, 'Total loss': 0.42643585602442424} | train loss {'Reaction outcome loss': 0.39125968429801267, 'Total loss': 0.39125968429801267}
2023-01-04 09:00:08,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:08,716 INFO:     Epoch: 28
2023-01-04 09:00:10,301 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45389311710993446, 'Total loss': 0.45389311710993446} | train loss {'Reaction outcome loss': 0.39309579671935485, 'Total loss': 0.39309579671935485}
2023-01-04 09:00:10,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:10,302 INFO:     Epoch: 29
2023-01-04 09:00:11,913 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4304086109002431, 'Total loss': 0.4304086109002431} | train loss {'Reaction outcome loss': 0.38810644734529814, 'Total loss': 0.38810644734529814}
2023-01-04 09:00:11,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:11,914 INFO:     Epoch: 30
2023-01-04 09:00:13,489 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42730131447315217, 'Total loss': 0.42730131447315217} | train loss {'Reaction outcome loss': 0.3871595034853216, 'Total loss': 0.3871595034853216}
2023-01-04 09:00:13,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:13,489 INFO:     Epoch: 31
2023-01-04 09:00:15,100 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42790932456652325, 'Total loss': 0.42790932456652325} | train loss {'Reaction outcome loss': 0.38043828660938284, 'Total loss': 0.38043828660938284}
2023-01-04 09:00:15,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:15,100 INFO:     Epoch: 32
2023-01-04 09:00:16,703 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41179486910502117, 'Total loss': 0.41179486910502117} | train loss {'Reaction outcome loss': 0.3817772717359694, 'Total loss': 0.3817772717359694}
2023-01-04 09:00:16,703 INFO:     Found new best model at epoch 32
2023-01-04 09:00:16,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:16,704 INFO:     Epoch: 33
2023-01-04 09:00:18,334 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40598863959312437, 'Total loss': 0.40598863959312437} | train loss {'Reaction outcome loss': 0.3760010600090027, 'Total loss': 0.3760010600090027}
2023-01-04 09:00:18,334 INFO:     Found new best model at epoch 33
2023-01-04 09:00:18,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:18,335 INFO:     Epoch: 34
2023-01-04 09:00:19,918 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43704770008722943, 'Total loss': 0.43704770008722943} | train loss {'Reaction outcome loss': 0.3793491384397775, 'Total loss': 0.3793491384397775}
2023-01-04 09:00:19,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:19,918 INFO:     Epoch: 35
2023-01-04 09:00:21,490 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4287390093008677, 'Total loss': 0.4287390093008677} | train loss {'Reaction outcome loss': 0.3718103925136022, 'Total loss': 0.3718103925136022}
2023-01-04 09:00:21,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:21,490 INFO:     Epoch: 36
2023-01-04 09:00:23,099 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4387774129708608, 'Total loss': 0.4387774129708608} | train loss {'Reaction outcome loss': 0.36850833064382255, 'Total loss': 0.36850833064382255}
2023-01-04 09:00:23,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:23,100 INFO:     Epoch: 37
2023-01-04 09:00:24,723 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43744275867939, 'Total loss': 0.43744275867939} | train loss {'Reaction outcome loss': 0.3663230177674053, 'Total loss': 0.3663230177674053}
2023-01-04 09:00:24,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:24,724 INFO:     Epoch: 38
2023-01-04 09:00:26,331 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42334299683570864, 'Total loss': 0.42334299683570864} | train loss {'Reaction outcome loss': 0.36428637945157094, 'Total loss': 0.36428637945157094}
2023-01-04 09:00:26,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:26,331 INFO:     Epoch: 39
2023-01-04 09:00:27,922 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4213840534289678, 'Total loss': 0.4213840534289678} | train loss {'Reaction outcome loss': 0.3630435864040998, 'Total loss': 0.3630435864040998}
2023-01-04 09:00:27,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:27,922 INFO:     Epoch: 40
2023-01-04 09:00:29,548 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3994067003329595, 'Total loss': 0.3994067003329595} | train loss {'Reaction outcome loss': 0.3593237815350832, 'Total loss': 0.3593237815350832}
2023-01-04 09:00:29,549 INFO:     Found new best model at epoch 40
2023-01-04 09:00:29,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:29,550 INFO:     Epoch: 41
2023-01-04 09:00:31,134 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4221541672945023, 'Total loss': 0.4221541672945023} | train loss {'Reaction outcome loss': 0.3559630647947212, 'Total loss': 0.3559630647947212}
2023-01-04 09:00:31,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:31,134 INFO:     Epoch: 42
2023-01-04 09:00:32,756 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4188035766283671, 'Total loss': 0.4188035766283671} | train loss {'Reaction outcome loss': 0.35582911642772624, 'Total loss': 0.35582911642772624}
2023-01-04 09:00:32,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:32,756 INFO:     Epoch: 43
2023-01-04 09:00:34,375 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41496905287106833, 'Total loss': 0.41496905287106833} | train loss {'Reaction outcome loss': 0.35196914803572943, 'Total loss': 0.35196914803572943}
2023-01-04 09:00:34,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:34,375 INFO:     Epoch: 44
2023-01-04 09:00:35,972 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4110817611217499, 'Total loss': 0.4110817611217499} | train loss {'Reaction outcome loss': 0.3451618601699168, 'Total loss': 0.3451618601699168}
2023-01-04 09:00:35,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:35,973 INFO:     Epoch: 45
2023-01-04 09:00:37,560 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4115818868080775, 'Total loss': 0.4115818868080775} | train loss {'Reaction outcome loss': 0.34555199537896936, 'Total loss': 0.34555199537896936}
2023-01-04 09:00:37,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:37,560 INFO:     Epoch: 46
2023-01-04 09:00:39,180 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4120697855949402, 'Total loss': 0.4120697855949402} | train loss {'Reaction outcome loss': 0.3440377114051516, 'Total loss': 0.3440377114051516}
2023-01-04 09:00:39,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:39,180 INFO:     Epoch: 47
2023-01-04 09:00:40,732 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4123729050159454, 'Total loss': 0.4123729050159454} | train loss {'Reaction outcome loss': 0.3432396046467637, 'Total loss': 0.3432396046467637}
2023-01-04 09:00:40,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:40,733 INFO:     Epoch: 48
2023-01-04 09:00:42,355 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3985115498304367, 'Total loss': 0.3985115498304367} | train loss {'Reaction outcome loss': 0.34446140924730884, 'Total loss': 0.34446140924730884}
2023-01-04 09:00:42,356 INFO:     Found new best model at epoch 48
2023-01-04 09:00:42,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:42,357 INFO:     Epoch: 49
2023-01-04 09:00:43,983 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3852179616689682, 'Total loss': 0.3852179616689682} | train loss {'Reaction outcome loss': 0.33597956619322944, 'Total loss': 0.33597956619322944}
2023-01-04 09:00:43,983 INFO:     Found new best model at epoch 49
2023-01-04 09:00:43,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:43,983 INFO:     Epoch: 50
2023-01-04 09:00:45,594 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4096992592016856, 'Total loss': 0.4096992592016856} | train loss {'Reaction outcome loss': 0.3359097475286856, 'Total loss': 0.3359097475286856}
2023-01-04 09:00:45,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:45,594 INFO:     Epoch: 51
2023-01-04 09:00:47,163 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.390797883272171, 'Total loss': 0.390797883272171} | train loss {'Reaction outcome loss': 0.33639178126512453, 'Total loss': 0.33639178126512453}
2023-01-04 09:00:47,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:47,163 INFO:     Epoch: 52
2023-01-04 09:00:48,741 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4017491231362025, 'Total loss': 0.4017491231362025} | train loss {'Reaction outcome loss': 0.3370559693512503, 'Total loss': 0.3370559693512503}
2023-01-04 09:00:48,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:48,741 INFO:     Epoch: 53
2023-01-04 09:00:50,362 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39757348199685416, 'Total loss': 0.39757348199685416} | train loss {'Reaction outcome loss': 0.33297262276230305, 'Total loss': 0.33297262276230305}
2023-01-04 09:00:50,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:50,362 INFO:     Epoch: 54
2023-01-04 09:00:51,968 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3961250901222229, 'Total loss': 0.3961250901222229} | train loss {'Reaction outcome loss': 0.3295790932615311, 'Total loss': 0.3295790932615311}
2023-01-04 09:00:51,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:51,969 INFO:     Epoch: 55
2023-01-04 09:00:53,577 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3963967969020208, 'Total loss': 0.3963967969020208} | train loss {'Reaction outcome loss': 0.32695540185977406, 'Total loss': 0.32695540185977406}
2023-01-04 09:00:53,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:53,577 INFO:     Epoch: 56
2023-01-04 09:00:55,165 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4051527390877406, 'Total loss': 0.4051527390877406} | train loss {'Reaction outcome loss': 0.3293475591802855, 'Total loss': 0.3293475591802855}
2023-01-04 09:00:55,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:55,165 INFO:     Epoch: 57
2023-01-04 09:00:56,741 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4164017597834269, 'Total loss': 0.4164017597834269} | train loss {'Reaction outcome loss': 0.3262064501589386, 'Total loss': 0.3262064501589386}
2023-01-04 09:00:56,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:56,741 INFO:     Epoch: 58
2023-01-04 09:00:58,277 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44199835459391273, 'Total loss': 0.44199835459391273} | train loss {'Reaction outcome loss': 0.323569142942179, 'Total loss': 0.323569142942179}
2023-01-04 09:00:58,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:58,278 INFO:     Epoch: 59
2023-01-04 09:00:59,833 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40741508404413856, 'Total loss': 0.40741508404413856} | train loss {'Reaction outcome loss': 0.3248285778028225, 'Total loss': 0.3248285778028225}
2023-01-04 09:00:59,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:00:59,834 INFO:     Epoch: 60
2023-01-04 09:01:01,402 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4004744658867518, 'Total loss': 0.4004744658867518} | train loss {'Reaction outcome loss': 0.321197478053587, 'Total loss': 0.321197478053587}
2023-01-04 09:01:01,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:01,402 INFO:     Epoch: 61
2023-01-04 09:01:02,971 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40978883604208627, 'Total loss': 0.40978883604208627} | train loss {'Reaction outcome loss': 0.31829441365674943, 'Total loss': 0.31829441365674943}
2023-01-04 09:01:02,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:02,972 INFO:     Epoch: 62
2023-01-04 09:01:04,499 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4038362383842468, 'Total loss': 0.4038362383842468} | train loss {'Reaction outcome loss': 0.31570521099257554, 'Total loss': 0.31570521099257554}
2023-01-04 09:01:04,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:04,500 INFO:     Epoch: 63
2023-01-04 09:01:06,057 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38550792932510375, 'Total loss': 0.38550792932510375} | train loss {'Reaction outcome loss': 0.31394186728913, 'Total loss': 0.31394186728913}
2023-01-04 09:01:06,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:06,058 INFO:     Epoch: 64
2023-01-04 09:01:07,585 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41038448810577394, 'Total loss': 0.41038448810577394} | train loss {'Reaction outcome loss': 0.31208297314411465, 'Total loss': 0.31208297314411465}
2023-01-04 09:01:07,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:07,585 INFO:     Epoch: 65
2023-01-04 09:01:09,158 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3840056816736857, 'Total loss': 0.3840056816736857} | train loss {'Reaction outcome loss': 0.3111641965403023, 'Total loss': 0.3111641965403023}
2023-01-04 09:01:09,158 INFO:     Found new best model at epoch 65
2023-01-04 09:01:09,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:09,159 INFO:     Epoch: 66
2023-01-04 09:01:10,737 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4059122145175934, 'Total loss': 0.4059122145175934} | train loss {'Reaction outcome loss': 0.31228994128936466, 'Total loss': 0.31228994128936466}
2023-01-04 09:01:10,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:10,738 INFO:     Epoch: 67
2023-01-04 09:01:12,315 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37974245051542915, 'Total loss': 0.37974245051542915} | train loss {'Reaction outcome loss': 0.3075411590455026, 'Total loss': 0.3075411590455026}
2023-01-04 09:01:12,315 INFO:     Found new best model at epoch 67
2023-01-04 09:01:12,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:12,316 INFO:     Epoch: 68
2023-01-04 09:01:13,841 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4044670954346657, 'Total loss': 0.4044670954346657} | train loss {'Reaction outcome loss': 0.3074137494505958, 'Total loss': 0.3074137494505958}
2023-01-04 09:01:13,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:13,841 INFO:     Epoch: 69
2023-01-04 09:01:15,399 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39556317826112114, 'Total loss': 0.39556317826112114} | train loss {'Reaction outcome loss': 0.3047007618720781, 'Total loss': 0.3047007618720781}
2023-01-04 09:01:15,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:15,399 INFO:     Epoch: 70
2023-01-04 09:01:16,910 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3908949355284373, 'Total loss': 0.3908949355284373} | train loss {'Reaction outcome loss': 0.3026085155696645, 'Total loss': 0.3026085155696645}
2023-01-04 09:01:16,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:16,911 INFO:     Epoch: 71
2023-01-04 09:01:18,466 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4125562568505605, 'Total loss': 0.4125562568505605} | train loss {'Reaction outcome loss': 0.2998421985104626, 'Total loss': 0.2998421985104626}
2023-01-04 09:01:18,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:18,466 INFO:     Epoch: 72
2023-01-04 09:01:20,022 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39843055109182995, 'Total loss': 0.39843055109182995} | train loss {'Reaction outcome loss': 0.30154404504096893, 'Total loss': 0.30154404504096893}
2023-01-04 09:01:20,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:20,022 INFO:     Epoch: 73
2023-01-04 09:01:21,582 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3953136612971624, 'Total loss': 0.3953136612971624} | train loss {'Reaction outcome loss': 0.2991814314781113, 'Total loss': 0.2991814314781113}
2023-01-04 09:01:21,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:21,583 INFO:     Epoch: 74
2023-01-04 09:01:23,103 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39397998054822286, 'Total loss': 0.39397998054822286} | train loss {'Reaction outcome loss': 0.30245335206443225, 'Total loss': 0.30245335206443225}
2023-01-04 09:01:23,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:23,103 INFO:     Epoch: 75
2023-01-04 09:01:24,661 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38923718432585397, 'Total loss': 0.38923718432585397} | train loss {'Reaction outcome loss': 0.2998236571892504, 'Total loss': 0.2998236571892504}
2023-01-04 09:01:24,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:24,661 INFO:     Epoch: 76
2023-01-04 09:01:26,200 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4140054692824682, 'Total loss': 0.4140054692824682} | train loss {'Reaction outcome loss': 0.2926124322231496, 'Total loss': 0.2926124322231496}
2023-01-04 09:01:26,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:26,200 INFO:     Epoch: 77
2023-01-04 09:01:27,753 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40543217261632286, 'Total loss': 0.40543217261632286} | train loss {'Reaction outcome loss': 0.2954638606266855, 'Total loss': 0.2954638606266855}
2023-01-04 09:01:27,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:27,754 INFO:     Epoch: 78
2023-01-04 09:01:29,330 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41363093654314675, 'Total loss': 0.41363093654314675} | train loss {'Reaction outcome loss': 0.29229203746099336, 'Total loss': 0.29229203746099336}
2023-01-04 09:01:29,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:29,331 INFO:     Epoch: 79
2023-01-04 09:01:30,905 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3944866627454758, 'Total loss': 0.3944866627454758} | train loss {'Reaction outcome loss': 0.29588702070906703, 'Total loss': 0.29588702070906703}
2023-01-04 09:01:30,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:30,905 INFO:     Epoch: 80
2023-01-04 09:01:32,417 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3983952164649963, 'Total loss': 0.3983952164649963} | train loss {'Reaction outcome loss': 0.29566390056579983, 'Total loss': 0.29566390056579983}
2023-01-04 09:01:32,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:32,417 INFO:     Epoch: 81
2023-01-04 09:01:33,944 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3852276116609573, 'Total loss': 0.3852276116609573} | train loss {'Reaction outcome loss': 0.29182723589537374, 'Total loss': 0.29182723589537374}
2023-01-04 09:01:33,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:33,944 INFO:     Epoch: 82
2023-01-04 09:01:35,503 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39008351465066277, 'Total loss': 0.39008351465066277} | train loss {'Reaction outcome loss': 0.28920399852177725, 'Total loss': 0.28920399852177725}
2023-01-04 09:01:35,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:35,504 INFO:     Epoch: 83
2023-01-04 09:01:37,064 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4102052281300227, 'Total loss': 0.4102052281300227} | train loss {'Reaction outcome loss': 0.28843730696164316, 'Total loss': 0.28843730696164316}
2023-01-04 09:01:37,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:37,064 INFO:     Epoch: 84
2023-01-04 09:01:38,615 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4234142909447352, 'Total loss': 0.4234142909447352} | train loss {'Reaction outcome loss': 0.28780026521385793, 'Total loss': 0.28780026521385793}
2023-01-04 09:01:38,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:38,616 INFO:     Epoch: 85
2023-01-04 09:01:40,175 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3771653652191162, 'Total loss': 0.3771653652191162} | train loss {'Reaction outcome loss': 0.290292554060905, 'Total loss': 0.290292554060905}
2023-01-04 09:01:40,175 INFO:     Found new best model at epoch 85
2023-01-04 09:01:40,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:40,176 INFO:     Epoch: 86
2023-01-04 09:01:41,707 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.414109202226003, 'Total loss': 0.414109202226003} | train loss {'Reaction outcome loss': 0.2831215007963594, 'Total loss': 0.2831215007963594}
2023-01-04 09:01:41,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:41,707 INFO:     Epoch: 87
2023-01-04 09:01:43,235 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39431434075037636, 'Total loss': 0.39431434075037636} | train loss {'Reaction outcome loss': 0.2845132213206928, 'Total loss': 0.2845132213206928}
2023-01-04 09:01:43,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:43,235 INFO:     Epoch: 88
2023-01-04 09:01:44,799 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40351720253626505, 'Total loss': 0.40351720253626505} | train loss {'Reaction outcome loss': 0.28191875145915185, 'Total loss': 0.28191875145915185}
2023-01-04 09:01:44,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:44,799 INFO:     Epoch: 89
2023-01-04 09:01:46,354 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3836470514535904, 'Total loss': 0.3836470514535904} | train loss {'Reaction outcome loss': 0.2843020439201744, 'Total loss': 0.2843020439201744}
2023-01-04 09:01:46,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:46,354 INFO:     Epoch: 90
2023-01-04 09:01:47,934 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40601933002471924, 'Total loss': 0.40601933002471924} | train loss {'Reaction outcome loss': 0.28367453517681424, 'Total loss': 0.28367453517681424}
2023-01-04 09:01:47,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:47,935 INFO:     Epoch: 91
2023-01-04 09:01:49,470 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3966666221618652, 'Total loss': 0.3966666221618652} | train loss {'Reaction outcome loss': 0.28061926878639076, 'Total loss': 0.28061926878639076}
2023-01-04 09:01:49,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:49,470 INFO:     Epoch: 92
2023-01-04 09:01:51,079 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39501256346702573, 'Total loss': 0.39501256346702573} | train loss {'Reaction outcome loss': 0.27420824639741265, 'Total loss': 0.27420824639741265}
2023-01-04 09:01:51,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:51,079 INFO:     Epoch: 93
2023-01-04 09:01:52,648 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3794668197631836, 'Total loss': 0.3794668197631836} | train loss {'Reaction outcome loss': 0.2758548744157333, 'Total loss': 0.2758548744157333}
2023-01-04 09:01:52,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:52,648 INFO:     Epoch: 94
2023-01-04 09:01:54,282 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39308031896750134, 'Total loss': 0.39308031896750134} | train loss {'Reaction outcome loss': 0.27924370313809666, 'Total loss': 0.27924370313809666}
2023-01-04 09:01:54,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:54,282 INFO:     Epoch: 95
2023-01-04 09:01:55,911 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39377604027589164, 'Total loss': 0.39377604027589164} | train loss {'Reaction outcome loss': 0.27345842862710196, 'Total loss': 0.27345842862710196}
2023-01-04 09:01:55,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:55,911 INFO:     Epoch: 96
2023-01-04 09:01:57,545 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4230439176162084, 'Total loss': 0.4230439176162084} | train loss {'Reaction outcome loss': 0.27659474115563215, 'Total loss': 0.27659474115563215}
2023-01-04 09:01:57,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:57,545 INFO:     Epoch: 97
2023-01-04 09:01:59,120 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.387362015247345, 'Total loss': 0.387362015247345} | train loss {'Reaction outcome loss': 0.2767452370872997, 'Total loss': 0.2767452370872997}
2023-01-04 09:01:59,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:01:59,120 INFO:     Epoch: 98
2023-01-04 09:02:00,740 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39751408497492474, 'Total loss': 0.39751408497492474} | train loss {'Reaction outcome loss': 0.272924784947496, 'Total loss': 0.272924784947496}
2023-01-04 09:02:00,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:00,741 INFO:     Epoch: 99
2023-01-04 09:02:02,324 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4241010040044785, 'Total loss': 0.4241010040044785} | train loss {'Reaction outcome loss': 0.2748120590936836, 'Total loss': 0.2748120590936836}
2023-01-04 09:02:02,324 INFO:     Best model found after epoch 86 of 100.
2023-01-04 09:02:02,324 INFO:   Done with stage: TRAINING
2023-01-04 09:02:02,324 INFO:   Starting stage: EVALUATION
2023-01-04 09:02:02,446 INFO:   Done with stage: EVALUATION
2023-01-04 09:02:02,446 INFO:   Leaving out SEQ value Fold_9
2023-01-04 09:02:02,458 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 09:02:02,459 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:02:03,101 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:02:03,101 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:02:03,169 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:02:03,169 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:02:03,169 INFO:     No hyperparam tuning for this model
2023-01-04 09:02:03,169 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:02:03,170 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:02:03,170 INFO:     None feature selector for col prot
2023-01-04 09:02:03,170 INFO:     None feature selector for col prot
2023-01-04 09:02:03,170 INFO:     None feature selector for col prot
2023-01-04 09:02:03,171 INFO:     None feature selector for col chem
2023-01-04 09:02:03,171 INFO:     None feature selector for col chem
2023-01-04 09:02:03,171 INFO:     None feature selector for col chem
2023-01-04 09:02:03,171 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:02:03,171 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:02:03,172 INFO:     Number of params in model 70111
2023-01-04 09:02:03,176 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:02:03,176 INFO:   Starting stage: TRAINING
2023-01-04 09:02:03,218 INFO:     Val loss before train {'Reaction outcome loss': 0.9881864786148071, 'Total loss': 0.9881864786148071}
2023-01-04 09:02:03,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:03,218 INFO:     Epoch: 0
2023-01-04 09:02:04,817 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7130478302637736, 'Total loss': 0.7130478302637736} | train loss {'Reaction outcome loss': 0.8529364261096412, 'Total loss': 0.8529364261096412}
2023-01-04 09:02:04,818 INFO:     Found new best model at epoch 0
2023-01-04 09:02:04,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:04,818 INFO:     Epoch: 1
2023-01-04 09:02:06,436 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5678802649180095, 'Total loss': 0.5678802649180095} | train loss {'Reaction outcome loss': 0.6699458032193846, 'Total loss': 0.6699458032193846}
2023-01-04 09:02:06,437 INFO:     Found new best model at epoch 1
2023-01-04 09:02:06,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:06,437 INFO:     Epoch: 2
2023-01-04 09:02:08,009 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5150741597016653, 'Total loss': 0.5150741597016653} | train loss {'Reaction outcome loss': 0.5651939862618481, 'Total loss': 0.5651939862618481}
2023-01-04 09:02:08,009 INFO:     Found new best model at epoch 2
2023-01-04 09:02:08,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:08,010 INFO:     Epoch: 3
2023-01-04 09:02:09,624 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4761567831039429, 'Total loss': 0.4761567831039429} | train loss {'Reaction outcome loss': 0.527475507154952, 'Total loss': 0.527475507154952}
2023-01-04 09:02:09,624 INFO:     Found new best model at epoch 3
2023-01-04 09:02:09,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:09,625 INFO:     Epoch: 4
2023-01-04 09:02:11,188 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49833114941914874, 'Total loss': 0.49833114941914874} | train loss {'Reaction outcome loss': 0.5129178717297359, 'Total loss': 0.5129178717297359}
2023-01-04 09:02:11,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:11,189 INFO:     Epoch: 5
2023-01-04 09:02:12,798 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47551230192184446, 'Total loss': 0.47551230192184446} | train loss {'Reaction outcome loss': 0.4943060994583325, 'Total loss': 0.4943060994583325}
2023-01-04 09:02:12,799 INFO:     Found new best model at epoch 5
2023-01-04 09:02:12,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:12,799 INFO:     Epoch: 6
2023-01-04 09:02:14,413 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47353788614273074, 'Total loss': 0.47353788614273074} | train loss {'Reaction outcome loss': 0.48598262107502804, 'Total loss': 0.48598262107502804}
2023-01-04 09:02:14,413 INFO:     Found new best model at epoch 6
2023-01-04 09:02:14,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:14,414 INFO:     Epoch: 7
2023-01-04 09:02:16,030 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44908039768536884, 'Total loss': 0.44908039768536884} | train loss {'Reaction outcome loss': 0.4768228685333781, 'Total loss': 0.4768228685333781}
2023-01-04 09:02:16,030 INFO:     Found new best model at epoch 7
2023-01-04 09:02:16,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:16,031 INFO:     Epoch: 8
2023-01-04 09:02:17,598 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43994670708974204, 'Total loss': 0.43994670708974204} | train loss {'Reaction outcome loss': 0.4705149423140679, 'Total loss': 0.4705149423140679}
2023-01-04 09:02:17,598 INFO:     Found new best model at epoch 8
2023-01-04 09:02:17,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:17,599 INFO:     Epoch: 9
2023-01-04 09:02:19,152 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4468049337466558, 'Total loss': 0.4468049337466558} | train loss {'Reaction outcome loss': 0.4615449452378454, 'Total loss': 0.4615449452378454}
2023-01-04 09:02:19,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:19,152 INFO:     Epoch: 10
2023-01-04 09:02:20,765 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44275068243344623, 'Total loss': 0.44275068243344623} | train loss {'Reaction outcome loss': 0.4568581113958881, 'Total loss': 0.4568581113958881}
2023-01-04 09:02:20,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:20,766 INFO:     Epoch: 11
2023-01-04 09:02:22,382 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43543280561765035, 'Total loss': 0.43543280561765035} | train loss {'Reaction outcome loss': 0.45052578278484134, 'Total loss': 0.45052578278484134}
2023-01-04 09:02:22,382 INFO:     Found new best model at epoch 11
2023-01-04 09:02:22,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:22,383 INFO:     Epoch: 12
2023-01-04 09:02:23,999 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41642790933450063, 'Total loss': 0.41642790933450063} | train loss {'Reaction outcome loss': 0.4465327435275064, 'Total loss': 0.4465327435275064}
2023-01-04 09:02:23,999 INFO:     Found new best model at epoch 12
2023-01-04 09:02:23,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:24,000 INFO:     Epoch: 13
2023-01-04 09:02:25,565 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41751522024472554, 'Total loss': 0.41751522024472554} | train loss {'Reaction outcome loss': 0.4437870536081112, 'Total loss': 0.4437870536081112}
2023-01-04 09:02:25,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:25,565 INFO:     Epoch: 14
2023-01-04 09:02:27,156 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4114452083905538, 'Total loss': 0.4114452083905538} | train loss {'Reaction outcome loss': 0.4384370906835925, 'Total loss': 0.4384370906835925}
2023-01-04 09:02:27,156 INFO:     Found new best model at epoch 14
2023-01-04 09:02:27,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:27,156 INFO:     Epoch: 15
2023-01-04 09:02:28,694 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4270767500003179, 'Total loss': 0.4270767500003179} | train loss {'Reaction outcome loss': 0.43062790820415875, 'Total loss': 0.43062790820415875}
2023-01-04 09:02:28,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:28,694 INFO:     Epoch: 16
2023-01-04 09:02:30,230 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4314394146203995, 'Total loss': 0.4314394146203995} | train loss {'Reaction outcome loss': 0.4288224236917322, 'Total loss': 0.4288224236917322}
2023-01-04 09:02:30,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:30,230 INFO:     Epoch: 17
2023-01-04 09:02:31,782 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4067300736904144, 'Total loss': 0.4067300736904144} | train loss {'Reaction outcome loss': 0.42295513302087784, 'Total loss': 0.42295513302087784}
2023-01-04 09:02:31,782 INFO:     Found new best model at epoch 17
2023-01-04 09:02:31,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:31,783 INFO:     Epoch: 18
2023-01-04 09:02:33,372 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4223360389471054, 'Total loss': 0.4223360389471054} | train loss {'Reaction outcome loss': 0.418475076501822, 'Total loss': 0.418475076501822}
2023-01-04 09:02:33,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:33,372 INFO:     Epoch: 19
2023-01-04 09:02:34,908 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42102892994880675, 'Total loss': 0.42102892994880675} | train loss {'Reaction outcome loss': 0.4143107326796455, 'Total loss': 0.4143107326796455}
2023-01-04 09:02:34,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:34,908 INFO:     Epoch: 20
2023-01-04 09:02:36,487 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40621493458747865, 'Total loss': 0.40621493458747865} | train loss {'Reaction outcome loss': 0.4102286735590357, 'Total loss': 0.4102286735590357}
2023-01-04 09:02:36,488 INFO:     Found new best model at epoch 20
2023-01-04 09:02:36,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:36,489 INFO:     Epoch: 21
2023-01-04 09:02:38,036 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41282099187374116, 'Total loss': 0.41282099187374116} | train loss {'Reaction outcome loss': 0.4065786705073649, 'Total loss': 0.4065786705073649}
2023-01-04 09:02:38,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:38,037 INFO:     Epoch: 22
2023-01-04 09:02:39,620 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41227486928304036, 'Total loss': 0.41227486928304036} | train loss {'Reaction outcome loss': 0.39753149300269836, 'Total loss': 0.39753149300269836}
2023-01-04 09:02:39,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:39,620 INFO:     Epoch: 23
2023-01-04 09:02:41,213 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3902666260798772, 'Total loss': 0.3902666260798772} | train loss {'Reaction outcome loss': 0.39770960505970204, 'Total loss': 0.39770960505970204}
2023-01-04 09:02:41,213 INFO:     Found new best model at epoch 23
2023-01-04 09:02:41,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:41,214 INFO:     Epoch: 24
2023-01-04 09:02:42,768 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3781828999519348, 'Total loss': 0.3781828999519348} | train loss {'Reaction outcome loss': 0.3934231317010674, 'Total loss': 0.3934231317010674}
2023-01-04 09:02:42,769 INFO:     Found new best model at epoch 24
2023-01-04 09:02:42,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:42,770 INFO:     Epoch: 25
2023-01-04 09:02:44,277 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39446428616841633, 'Total loss': 0.39446428616841633} | train loss {'Reaction outcome loss': 0.39122314810970404, 'Total loss': 0.39122314810970404}
2023-01-04 09:02:44,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:44,277 INFO:     Epoch: 26
2023-01-04 09:02:45,834 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4116074105103811, 'Total loss': 0.4116074105103811} | train loss {'Reaction outcome loss': 0.3894043072623058, 'Total loss': 0.3894043072623058}
2023-01-04 09:02:45,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:45,834 INFO:     Epoch: 27
2023-01-04 09:02:47,343 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42506119310855867, 'Total loss': 0.42506119310855867} | train loss {'Reaction outcome loss': 0.3829031227713954, 'Total loss': 0.3829031227713954}
2023-01-04 09:02:47,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:47,343 INFO:     Epoch: 28
2023-01-04 09:02:48,886 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3964926173289617, 'Total loss': 0.3964926173289617} | train loss {'Reaction outcome loss': 0.3806235732877777, 'Total loss': 0.3806235732877777}
2023-01-04 09:02:48,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:48,887 INFO:     Epoch: 29
2023-01-04 09:02:50,434 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38183864057064054, 'Total loss': 0.38183864057064054} | train loss {'Reaction outcome loss': 0.3725537861133144, 'Total loss': 0.3725537861133144}
2023-01-04 09:02:50,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:50,435 INFO:     Epoch: 30
2023-01-04 09:02:51,966 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4227883795897166, 'Total loss': 0.4227883795897166} | train loss {'Reaction outcome loss': 0.3744480244978501, 'Total loss': 0.3744480244978501}
2023-01-04 09:02:51,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:51,967 INFO:     Epoch: 31
2023-01-04 09:02:53,481 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38494888742764793, 'Total loss': 0.38494888742764793} | train loss {'Reaction outcome loss': 0.3679561086243739, 'Total loss': 0.3679561086243739}
2023-01-04 09:02:53,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:53,481 INFO:     Epoch: 32
2023-01-04 09:02:55,010 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3939694851636887, 'Total loss': 0.3939694851636887} | train loss {'Reaction outcome loss': 0.36319264677101676, 'Total loss': 0.36319264677101676}
2023-01-04 09:02:55,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:55,011 INFO:     Epoch: 33
2023-01-04 09:02:56,506 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37853889067967733, 'Total loss': 0.37853889067967733} | train loss {'Reaction outcome loss': 0.36233264346518657, 'Total loss': 0.36233264346518657}
2023-01-04 09:02:56,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:56,506 INFO:     Epoch: 34
2023-01-04 09:02:58,040 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40470121502876283, 'Total loss': 0.40470121502876283} | train loss {'Reaction outcome loss': 0.36049750216142107, 'Total loss': 0.36049750216142107}
2023-01-04 09:02:58,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:58,041 INFO:     Epoch: 35
2023-01-04 09:02:59,594 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37826453348000844, 'Total loss': 0.37826453348000844} | train loss {'Reaction outcome loss': 0.3531697684776609, 'Total loss': 0.3531697684776609}
2023-01-04 09:02:59,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:02:59,594 INFO:     Epoch: 36
2023-01-04 09:03:01,118 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38375177383422854, 'Total loss': 0.38375177383422854} | train loss {'Reaction outcome loss': 0.3501036789839285, 'Total loss': 0.3501036789839285}
2023-01-04 09:03:01,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:01,118 INFO:     Epoch: 37
2023-01-04 09:03:02,630 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3842767089605331, 'Total loss': 0.3842767089605331} | train loss {'Reaction outcome loss': 0.3475171326231347, 'Total loss': 0.3475171326231347}
2023-01-04 09:03:02,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:02,630 INFO:     Epoch: 38
2023-01-04 09:03:04,162 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.377407173315684, 'Total loss': 0.377407173315684} | train loss {'Reaction outcome loss': 0.34704117188706013, 'Total loss': 0.34704117188706013}
2023-01-04 09:03:04,162 INFO:     Found new best model at epoch 38
2023-01-04 09:03:04,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:04,163 INFO:     Epoch: 39
2023-01-04 09:03:05,691 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4088686724503835, 'Total loss': 0.4088686724503835} | train loss {'Reaction outcome loss': 0.34527094485442134, 'Total loss': 0.34527094485442134}
2023-01-04 09:03:05,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:05,691 INFO:     Epoch: 40
2023-01-04 09:03:07,239 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3902582049369812, 'Total loss': 0.3902582049369812} | train loss {'Reaction outcome loss': 0.3425545470286025, 'Total loss': 0.3425545470286025}
2023-01-04 09:03:07,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:07,239 INFO:     Epoch: 41
2023-01-04 09:03:08,781 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3888673762480418, 'Total loss': 0.3888673762480418} | train loss {'Reaction outcome loss': 0.3379868611584615, 'Total loss': 0.3379868611584615}
2023-01-04 09:03:08,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:08,782 INFO:     Epoch: 42
2023-01-04 09:03:10,360 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40560142596562704, 'Total loss': 0.40560142596562704} | train loss {'Reaction outcome loss': 0.336215843929209, 'Total loss': 0.336215843929209}
2023-01-04 09:03:10,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:10,360 INFO:     Epoch: 43
2023-01-04 09:03:11,934 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36634613225857415, 'Total loss': 0.36634613225857415} | train loss {'Reaction outcome loss': 0.3383789324086078, 'Total loss': 0.3383789324086078}
2023-01-04 09:03:11,935 INFO:     Found new best model at epoch 43
2023-01-04 09:03:11,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:11,936 INFO:     Epoch: 44
2023-01-04 09:03:13,474 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43566782275835675, 'Total loss': 0.43566782275835675} | train loss {'Reaction outcome loss': 0.3319610621045976, 'Total loss': 0.3319610621045976}
2023-01-04 09:03:13,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:13,474 INFO:     Epoch: 45
2023-01-04 09:03:15,017 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3769581417242686, 'Total loss': 0.3769581417242686} | train loss {'Reaction outcome loss': 0.3330184363481337, 'Total loss': 0.3330184363481337}
2023-01-04 09:03:15,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:15,017 INFO:     Epoch: 46
2023-01-04 09:03:16,564 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.374964398642381, 'Total loss': 0.374964398642381} | train loss {'Reaction outcome loss': 0.32666681462178265, 'Total loss': 0.32666681462178265}
2023-01-04 09:03:16,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:16,564 INFO:     Epoch: 47
2023-01-04 09:03:18,123 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4116420179605484, 'Total loss': 0.4116420179605484} | train loss {'Reaction outcome loss': 0.3268182946328264, 'Total loss': 0.3268182946328264}
2023-01-04 09:03:18,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:18,124 INFO:     Epoch: 48
2023-01-04 09:03:19,679 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3903847058614095, 'Total loss': 0.3903847058614095} | train loss {'Reaction outcome loss': 0.31955956167330707, 'Total loss': 0.31955956167330707}
2023-01-04 09:03:19,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:19,680 INFO:     Epoch: 49
2023-01-04 09:03:21,223 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3907241274913152, 'Total loss': 0.3907241274913152} | train loss {'Reaction outcome loss': 0.3169248976955449, 'Total loss': 0.3169248976955449}
2023-01-04 09:03:21,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:21,223 INFO:     Epoch: 50
2023-01-04 09:03:22,776 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37853957315286, 'Total loss': 0.37853957315286} | train loss {'Reaction outcome loss': 0.318987343841008, 'Total loss': 0.318987343841008}
2023-01-04 09:03:22,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:22,776 INFO:     Epoch: 51
2023-01-04 09:03:24,369 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3776186466217041, 'Total loss': 0.3776186466217041} | train loss {'Reaction outcome loss': 0.31834500568517804, 'Total loss': 0.31834500568517804}
2023-01-04 09:03:24,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:24,369 INFO:     Epoch: 52
2023-01-04 09:03:25,928 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39693953742583593, 'Total loss': 0.39693953742583593} | train loss {'Reaction outcome loss': 0.31570449221308217, 'Total loss': 0.31570449221308217}
2023-01-04 09:03:25,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:25,929 INFO:     Epoch: 53
2023-01-04 09:03:27,508 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36524898012479146, 'Total loss': 0.36524898012479146} | train loss {'Reaction outcome loss': 0.31033965915332745, 'Total loss': 0.31033965915332745}
2023-01-04 09:03:27,508 INFO:     Found new best model at epoch 53
2023-01-04 09:03:27,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:27,509 INFO:     Epoch: 54
2023-01-04 09:03:29,091 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40935285488764445, 'Total loss': 0.40935285488764445} | train loss {'Reaction outcome loss': 0.3140557176929756, 'Total loss': 0.3140557176929756}
2023-01-04 09:03:29,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:29,091 INFO:     Epoch: 55
2023-01-04 09:03:30,630 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3892128308614095, 'Total loss': 0.3892128308614095} | train loss {'Reaction outcome loss': 0.3122799220311381, 'Total loss': 0.3122799220311381}
2023-01-04 09:03:30,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:30,631 INFO:     Epoch: 56
2023-01-04 09:03:32,195 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38627719978491465, 'Total loss': 0.38627719978491465} | train loss {'Reaction outcome loss': 0.31172583360959144, 'Total loss': 0.31172583360959144}
2023-01-04 09:03:32,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:32,195 INFO:     Epoch: 57
2023-01-04 09:03:33,775 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40077885389328005, 'Total loss': 0.40077885389328005} | train loss {'Reaction outcome loss': 0.30662186122941276, 'Total loss': 0.30662186122941276}
2023-01-04 09:03:33,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:33,776 INFO:     Epoch: 58
2023-01-04 09:03:35,330 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.404093070824941, 'Total loss': 0.404093070824941} | train loss {'Reaction outcome loss': 0.3046208603212433, 'Total loss': 0.3046208603212433}
2023-01-04 09:03:35,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:35,331 INFO:     Epoch: 59
2023-01-04 09:03:36,867 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4017418603102366, 'Total loss': 0.4017418603102366} | train loss {'Reaction outcome loss': 0.30892689849664695, 'Total loss': 0.30892689849664695}
2023-01-04 09:03:36,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:36,868 INFO:     Epoch: 60
2023-01-04 09:03:38,402 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37042908668518065, 'Total loss': 0.37042908668518065} | train loss {'Reaction outcome loss': 0.3006383333436764, 'Total loss': 0.3006383333436764}
2023-01-04 09:03:38,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:38,402 INFO:     Epoch: 61
2023-01-04 09:03:39,929 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4166952629884084, 'Total loss': 0.4166952629884084} | train loss {'Reaction outcome loss': 0.298950663502634, 'Total loss': 0.298950663502634}
2023-01-04 09:03:39,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:39,930 INFO:     Epoch: 62
2023-01-04 09:03:41,460 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.365817254781723, 'Total loss': 0.365817254781723} | train loss {'Reaction outcome loss': 0.2979659778575828, 'Total loss': 0.2979659778575828}
2023-01-04 09:03:41,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:41,460 INFO:     Epoch: 63
2023-01-04 09:03:43,010 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40021199484666187, 'Total loss': 0.40021199484666187} | train loss {'Reaction outcome loss': 0.3002184044542539, 'Total loss': 0.3002184044542539}
2023-01-04 09:03:43,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:43,011 INFO:     Epoch: 64
2023-01-04 09:03:44,555 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3654842495918274, 'Total loss': 0.3654842495918274} | train loss {'Reaction outcome loss': 0.2927468995815211, 'Total loss': 0.2927468995815211}
2023-01-04 09:03:44,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:44,555 INFO:     Epoch: 65
2023-01-04 09:03:46,168 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40467342038949333, 'Total loss': 0.40467342038949333} | train loss {'Reaction outcome loss': 0.29211575967552017, 'Total loss': 0.29211575967552017}
2023-01-04 09:03:46,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:46,168 INFO:     Epoch: 66
2023-01-04 09:03:47,720 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3879046152035395, 'Total loss': 0.3879046152035395} | train loss {'Reaction outcome loss': 0.2918267676973865, 'Total loss': 0.2918267676973865}
2023-01-04 09:03:47,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:47,720 INFO:     Epoch: 67
2023-01-04 09:03:49,330 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44843324820200603, 'Total loss': 0.44843324820200603} | train loss {'Reaction outcome loss': 0.2907817642320029, 'Total loss': 0.2907817642320029}
2023-01-04 09:03:49,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:49,331 INFO:     Epoch: 68
2023-01-04 09:03:50,872 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39503598809242246, 'Total loss': 0.39503598809242246} | train loss {'Reaction outcome loss': 0.2899254696158162, 'Total loss': 0.2899254696158162}
2023-01-04 09:03:50,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:50,873 INFO:     Epoch: 69
2023-01-04 09:03:52,474 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3674426088730494, 'Total loss': 0.3674426088730494} | train loss {'Reaction outcome loss': 0.28937265589615724, 'Total loss': 0.28937265589615724}
2023-01-04 09:03:52,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:52,474 INFO:     Epoch: 70
2023-01-04 09:03:54,036 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38065345287323, 'Total loss': 0.38065345287323} | train loss {'Reaction outcome loss': 0.2821819453507009, 'Total loss': 0.2821819453507009}
2023-01-04 09:03:54,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:54,036 INFO:     Epoch: 71
2023-01-04 09:03:55,599 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3955764025449753, 'Total loss': 0.3955764025449753} | train loss {'Reaction outcome loss': 0.28659974428804685, 'Total loss': 0.28659974428804685}
2023-01-04 09:03:55,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:55,600 INFO:     Epoch: 72
2023-01-04 09:03:57,135 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39543198347091674, 'Total loss': 0.39543198347091674} | train loss {'Reaction outcome loss': 0.2865935061806745, 'Total loss': 0.2865935061806745}
2023-01-04 09:03:57,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:57,135 INFO:     Epoch: 73
2023-01-04 09:03:58,668 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3791515568892161, 'Total loss': 0.3791515568892161} | train loss {'Reaction outcome loss': 0.28148787297362826, 'Total loss': 0.28148787297362826}
2023-01-04 09:03:58,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:03:58,668 INFO:     Epoch: 74
2023-01-04 09:04:00,169 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3680650532245636, 'Total loss': 0.3680650532245636} | train loss {'Reaction outcome loss': 0.28017852097124296, 'Total loss': 0.28017852097124296}
2023-01-04 09:04:00,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:00,169 INFO:     Epoch: 75
2023-01-04 09:04:01,700 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39864551623662314, 'Total loss': 0.39864551623662314} | train loss {'Reaction outcome loss': 0.2756933525041507, 'Total loss': 0.2756933525041507}
2023-01-04 09:04:01,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:01,701 INFO:     Epoch: 76
2023-01-04 09:04:03,232 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40799233118693035, 'Total loss': 0.40799233118693035} | train loss {'Reaction outcome loss': 0.2754640211317226, 'Total loss': 0.2754640211317226}
2023-01-04 09:04:03,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:03,232 INFO:     Epoch: 77
2023-01-04 09:04:04,776 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3604416027665138, 'Total loss': 0.3604416027665138} | train loss {'Reaction outcome loss': 0.2767154746247034, 'Total loss': 0.2767154746247034}
2023-01-04 09:04:04,777 INFO:     Found new best model at epoch 77
2023-01-04 09:04:04,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:04,777 INFO:     Epoch: 78
2023-01-04 09:04:06,281 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4005135883887609, 'Total loss': 0.4005135883887609} | train loss {'Reaction outcome loss': 0.2765856293050477, 'Total loss': 0.2765856293050477}
2023-01-04 09:04:06,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:06,282 INFO:     Epoch: 79
2023-01-04 09:04:07,823 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.381267578403155, 'Total loss': 0.381267578403155} | train loss {'Reaction outcome loss': 0.2754579359108079, 'Total loss': 0.2754579359108079}
2023-01-04 09:04:07,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:07,823 INFO:     Epoch: 80
2023-01-04 09:04:09,331 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40027761459350586, 'Total loss': 0.40027761459350586} | train loss {'Reaction outcome loss': 0.27845731888809344, 'Total loss': 0.27845731888809344}
2023-01-04 09:04:09,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:09,332 INFO:     Epoch: 81
2023-01-04 09:04:10,867 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37106354037920636, 'Total loss': 0.37106354037920636} | train loss {'Reaction outcome loss': 0.27253565170469074, 'Total loss': 0.27253565170469074}
2023-01-04 09:04:10,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:10,867 INFO:     Epoch: 82
2023-01-04 09:04:12,417 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39437723755836485, 'Total loss': 0.39437723755836485} | train loss {'Reaction outcome loss': 0.2719956386671232, 'Total loss': 0.2719956386671232}
2023-01-04 09:04:12,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:12,417 INFO:     Epoch: 83
2023-01-04 09:04:13,953 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44468526045481366, 'Total loss': 0.44468526045481366} | train loss {'Reaction outcome loss': 0.27165369946428025, 'Total loss': 0.27165369946428025}
2023-01-04 09:04:13,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:13,954 INFO:     Epoch: 84
2023-01-04 09:04:15,446 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40813645124435427, 'Total loss': 0.40813645124435427} | train loss {'Reaction outcome loss': 0.2753947088970755, 'Total loss': 0.2753947088970755}
2023-01-04 09:04:15,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:15,446 INFO:     Epoch: 85
2023-01-04 09:04:17,000 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3809631506601969, 'Total loss': 0.3809631506601969} | train loss {'Reaction outcome loss': 0.2688775541954232, 'Total loss': 0.2688775541954232}
2023-01-04 09:04:17,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:17,000 INFO:     Epoch: 86
2023-01-04 09:04:18,518 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3532881160577138, 'Total loss': 0.3532881160577138} | train loss {'Reaction outcome loss': 0.2691709462308536, 'Total loss': 0.2691709462308536}
2023-01-04 09:04:18,519 INFO:     Found new best model at epoch 86
2023-01-04 09:04:18,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:18,520 INFO:     Epoch: 87
2023-01-04 09:04:20,069 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3731101115544637, 'Total loss': 0.3731101115544637} | train loss {'Reaction outcome loss': 0.26657019900905826, 'Total loss': 0.26657019900905826}
2023-01-04 09:04:20,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:20,069 INFO:     Epoch: 88
2023-01-04 09:04:21,620 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3607270767291387, 'Total loss': 0.3607270767291387} | train loss {'Reaction outcome loss': 0.2623715350662705, 'Total loss': 0.2623715350662705}
2023-01-04 09:04:21,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:21,620 INFO:     Epoch: 89
2023-01-04 09:04:23,177 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42651785810788473, 'Total loss': 0.42651785810788473} | train loss {'Reaction outcome loss': 0.26695656012335833, 'Total loss': 0.26695656012335833}
2023-01-04 09:04:23,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:23,177 INFO:     Epoch: 90
2023-01-04 09:04:24,701 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3553492138783137, 'Total loss': 0.3553492138783137} | train loss {'Reaction outcome loss': 0.2638553933097716, 'Total loss': 0.2638553933097716}
2023-01-04 09:04:24,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:24,702 INFO:     Epoch: 91
2023-01-04 09:04:26,214 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45922294656435647, 'Total loss': 0.45922294656435647} | train loss {'Reaction outcome loss': 0.26206821254896423, 'Total loss': 0.26206821254896423}
2023-01-04 09:04:26,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:26,214 INFO:     Epoch: 92
2023-01-04 09:04:27,754 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37428456644217173, 'Total loss': 0.37428456644217173} | train loss {'Reaction outcome loss': 0.2630599153357266, 'Total loss': 0.2630599153357266}
2023-01-04 09:04:27,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:27,754 INFO:     Epoch: 93
2023-01-04 09:04:29,295 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4008759707212448, 'Total loss': 0.4008759707212448} | train loss {'Reaction outcome loss': 0.26172253876978896, 'Total loss': 0.26172253876978896}
2023-01-04 09:04:29,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:29,295 INFO:     Epoch: 94
2023-01-04 09:04:30,851 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3976756473382314, 'Total loss': 0.3976756473382314} | train loss {'Reaction outcome loss': 0.2608718054681799, 'Total loss': 0.2608718054681799}
2023-01-04 09:04:30,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:30,851 INFO:     Epoch: 95
2023-01-04 09:04:32,415 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4034234255552292, 'Total loss': 0.4034234255552292} | train loss {'Reaction outcome loss': 0.2541223935320647, 'Total loss': 0.2541223935320647}
2023-01-04 09:04:32,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:32,415 INFO:     Epoch: 96
2023-01-04 09:04:33,940 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4265620976686478, 'Total loss': 0.4265620976686478} | train loss {'Reaction outcome loss': 0.25916986980468687, 'Total loss': 0.25916986980468687}
2023-01-04 09:04:33,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:33,940 INFO:     Epoch: 97
2023-01-04 09:04:35,459 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3753131995598475, 'Total loss': 0.3753131995598475} | train loss {'Reaction outcome loss': 0.2583113955537768, 'Total loss': 0.2583113955537768}
2023-01-04 09:04:35,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:35,459 INFO:     Epoch: 98
2023-01-04 09:04:37,054 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39177325268586477, 'Total loss': 0.39177325268586477} | train loss {'Reaction outcome loss': 0.25511476968544244, 'Total loss': 0.25511476968544244}
2023-01-04 09:04:37,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:37,055 INFO:     Epoch: 99
2023-01-04 09:04:38,673 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43263610899448396, 'Total loss': 0.43263610899448396} | train loss {'Reaction outcome loss': 0.25136942915400884, 'Total loss': 0.25136942915400884}
2023-01-04 09:04:38,673 INFO:     Best model found after epoch 87 of 100.
2023-01-04 09:04:38,673 INFO:   Done with stage: TRAINING
2023-01-04 09:04:38,673 INFO:   Starting stage: EVALUATION
2023-01-04 09:04:38,811 INFO:   Done with stage: EVALUATION
2023-01-04 09:04:38,819 INFO:   Leaving out SEQ value Fold_0
2023-01-04 09:04:38,832 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 09:04:38,832 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:04:39,485 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:04:39,485 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:04:39,553 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:04:39,553 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:04:39,553 INFO:     No hyperparam tuning for this model
2023-01-04 09:04:39,553 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:04:39,553 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:04:39,554 INFO:     None feature selector for col prot
2023-01-04 09:04:39,554 INFO:     None feature selector for col prot
2023-01-04 09:04:39,554 INFO:     None feature selector for col prot
2023-01-04 09:04:39,555 INFO:     None feature selector for col chem
2023-01-04 09:04:39,555 INFO:     None feature selector for col chem
2023-01-04 09:04:39,555 INFO:     None feature selector for col chem
2023-01-04 09:04:39,555 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:04:39,555 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:04:39,556 INFO:     Number of params in model 70111
2023-01-04 09:04:39,559 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:04:39,559 INFO:   Starting stage: TRAINING
2023-01-04 09:04:39,602 INFO:     Val loss before train {'Reaction outcome loss': 1.1237899343172708, 'Total loss': 1.1237899343172708}
2023-01-04 09:04:39,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:39,602 INFO:     Epoch: 0
2023-01-04 09:04:41,225 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7951348284880321, 'Total loss': 0.7951348284880321} | train loss {'Reaction outcome loss': 0.8297511148844322, 'Total loss': 0.8297511148844322}
2023-01-04 09:04:41,226 INFO:     Found new best model at epoch 0
2023-01-04 09:04:41,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:41,226 INFO:     Epoch: 1
2023-01-04 09:04:42,794 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7013488709926605, 'Total loss': 0.7013488709926605} | train loss {'Reaction outcome loss': 0.6581152005352243, 'Total loss': 0.6581152005352243}
2023-01-04 09:04:42,794 INFO:     Found new best model at epoch 1
2023-01-04 09:04:42,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:42,795 INFO:     Epoch: 2
2023-01-04 09:04:44,368 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6540400862693787, 'Total loss': 0.6540400862693787} | train loss {'Reaction outcome loss': 0.5658108526228989, 'Total loss': 0.5658108526228989}
2023-01-04 09:04:44,368 INFO:     Found new best model at epoch 2
2023-01-04 09:04:44,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:44,369 INFO:     Epoch: 3
2023-01-04 09:04:45,990 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5836925903956095, 'Total loss': 0.5836925903956095} | train loss {'Reaction outcome loss': 0.5241765466919781, 'Total loss': 0.5241765466919781}
2023-01-04 09:04:45,991 INFO:     Found new best model at epoch 3
2023-01-04 09:04:45,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:45,991 INFO:     Epoch: 4
2023-01-04 09:04:47,567 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5728447159131368, 'Total loss': 0.5728447159131368} | train loss {'Reaction outcome loss': 0.5051677809470762, 'Total loss': 0.5051677809470762}
2023-01-04 09:04:47,567 INFO:     Found new best model at epoch 4
2023-01-04 09:04:47,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:47,568 INFO:     Epoch: 5
2023-01-04 09:04:49,137 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5824003914992014, 'Total loss': 0.5824003914992014} | train loss {'Reaction outcome loss': 0.48867278535218134, 'Total loss': 0.48867278535218134}
2023-01-04 09:04:49,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:49,137 INFO:     Epoch: 6
2023-01-04 09:04:50,725 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5638398885726928, 'Total loss': 0.5638398885726928} | train loss {'Reaction outcome loss': 0.4800511946643356, 'Total loss': 0.4800511946643356}
2023-01-04 09:04:50,725 INFO:     Found new best model at epoch 6
2023-01-04 09:04:50,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:50,726 INFO:     Epoch: 7
2023-01-04 09:04:52,291 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5697457094987234, 'Total loss': 0.5697457094987234} | train loss {'Reaction outcome loss': 0.4744260570809354, 'Total loss': 0.4744260570809354}
2023-01-04 09:04:52,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:52,291 INFO:     Epoch: 8
2023-01-04 09:04:53,840 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5426172196865082, 'Total loss': 0.5426172196865082} | train loss {'Reaction outcome loss': 0.46225727855289067, 'Total loss': 0.46225727855289067}
2023-01-04 09:04:53,841 INFO:     Found new best model at epoch 8
2023-01-04 09:04:53,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:53,842 INFO:     Epoch: 9
2023-01-04 09:04:55,386 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.531039975086848, 'Total loss': 0.531039975086848} | train loss {'Reaction outcome loss': 0.4541464441177184, 'Total loss': 0.4541464441177184}
2023-01-04 09:04:55,386 INFO:     Found new best model at epoch 9
2023-01-04 09:04:55,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:55,387 INFO:     Epoch: 10
2023-01-04 09:04:56,915 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.544710769255956, 'Total loss': 0.544710769255956} | train loss {'Reaction outcome loss': 0.4490294159546386, 'Total loss': 0.4490294159546386}
2023-01-04 09:04:56,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:56,916 INFO:     Epoch: 11
2023-01-04 09:04:58,461 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5505585769812266, 'Total loss': 0.5505585769812266} | train loss {'Reaction outcome loss': 0.444420279758255, 'Total loss': 0.444420279758255}
2023-01-04 09:04:58,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:04:58,461 INFO:     Epoch: 12
2023-01-04 09:05:00,004 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5264994144439697, 'Total loss': 0.5264994144439697} | train loss {'Reaction outcome loss': 0.43900450574655603, 'Total loss': 0.43900450574655603}
2023-01-04 09:05:00,005 INFO:     Found new best model at epoch 12
2023-01-04 09:05:00,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:00,006 INFO:     Epoch: 13
2023-01-04 09:05:01,516 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.511199509104093, 'Total loss': 0.511199509104093} | train loss {'Reaction outcome loss': 0.43888686700676477, 'Total loss': 0.43888686700676477}
2023-01-04 09:05:01,516 INFO:     Found new best model at epoch 13
2023-01-04 09:05:01,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:01,517 INFO:     Epoch: 14
2023-01-04 09:05:03,037 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5239377518494924, 'Total loss': 0.5239377518494924} | train loss {'Reaction outcome loss': 0.4276193961174819, 'Total loss': 0.4276193961174819}
2023-01-04 09:05:03,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:03,037 INFO:     Epoch: 15
2023-01-04 09:05:04,578 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5403395692507426, 'Total loss': 0.5403395692507426} | train loss {'Reaction outcome loss': 0.4241135143233042, 'Total loss': 0.4241135143233042}
2023-01-04 09:05:04,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:04,578 INFO:     Epoch: 16
2023-01-04 09:05:06,118 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5204970955848693, 'Total loss': 0.5204970955848693} | train loss {'Reaction outcome loss': 0.42377741952990966, 'Total loss': 0.42377741952990966}
2023-01-04 09:05:06,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:06,118 INFO:     Epoch: 17
2023-01-04 09:05:07,661 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5478439221779505, 'Total loss': 0.5478439221779505} | train loss {'Reaction outcome loss': 0.4188009705802385, 'Total loss': 0.4188009705802385}
2023-01-04 09:05:07,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:07,661 INFO:     Epoch: 18
2023-01-04 09:05:09,208 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5662312686443329, 'Total loss': 0.5662312686443329} | train loss {'Reaction outcome loss': 0.41363044825457307, 'Total loss': 0.41363044825457307}
2023-01-04 09:05:09,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:09,208 INFO:     Epoch: 19
2023-01-04 09:05:10,758 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5421874125798544, 'Total loss': 0.5421874125798544} | train loss {'Reaction outcome loss': 0.40952397630053716, 'Total loss': 0.40952397630053716}
2023-01-04 09:05:10,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:10,758 INFO:     Epoch: 20
2023-01-04 09:05:12,310 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5173466344674428, 'Total loss': 0.5173466344674428} | train loss {'Reaction outcome loss': 0.40699901872307714, 'Total loss': 0.40699901872307714}
2023-01-04 09:05:12,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:12,311 INFO:     Epoch: 21
2023-01-04 09:05:13,884 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5220361848672231, 'Total loss': 0.5220361848672231} | train loss {'Reaction outcome loss': 0.4013618656644856, 'Total loss': 0.4013618656644856}
2023-01-04 09:05:13,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:13,884 INFO:     Epoch: 22
2023-01-04 09:05:15,456 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5372668266296386, 'Total loss': 0.5372668266296386} | train loss {'Reaction outcome loss': 0.3970152075762731, 'Total loss': 0.3970152075762731}
2023-01-04 09:05:15,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:15,456 INFO:     Epoch: 23
2023-01-04 09:05:16,988 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5146410743395488, 'Total loss': 0.5146410743395488} | train loss {'Reaction outcome loss': 0.3949955679530645, 'Total loss': 0.3949955679530645}
2023-01-04 09:05:16,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:16,988 INFO:     Epoch: 24
2023-01-04 09:05:18,512 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5049167066812515, 'Total loss': 0.5049167066812515} | train loss {'Reaction outcome loss': 0.3936905136508663, 'Total loss': 0.3936905136508663}
2023-01-04 09:05:18,512 INFO:     Found new best model at epoch 24
2023-01-04 09:05:18,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:18,513 INFO:     Epoch: 25
2023-01-04 09:05:20,008 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5159495641787847, 'Total loss': 0.5159495641787847} | train loss {'Reaction outcome loss': 0.3876979381498629, 'Total loss': 0.3876979381498629}
2023-01-04 09:05:20,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:20,008 INFO:     Epoch: 26
2023-01-04 09:05:21,504 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5298795759677887, 'Total loss': 0.5298795759677887} | train loss {'Reaction outcome loss': 0.38447292091963936, 'Total loss': 0.38447292091963936}
2023-01-04 09:05:21,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:21,504 INFO:     Epoch: 27
2023-01-04 09:05:23,041 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5259114980697632, 'Total loss': 0.5259114980697632} | train loss {'Reaction outcome loss': 0.3794628188122798, 'Total loss': 0.3794628188122798}
2023-01-04 09:05:23,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:23,042 INFO:     Epoch: 28
2023-01-04 09:05:24,571 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5246209621429443, 'Total loss': 0.5246209621429443} | train loss {'Reaction outcome loss': 0.3771909787761469, 'Total loss': 0.3771909787761469}
2023-01-04 09:05:24,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:24,572 INFO:     Epoch: 29
2023-01-04 09:05:26,096 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.544706420103709, 'Total loss': 0.544706420103709} | train loss {'Reaction outcome loss': 0.377047555670686, 'Total loss': 0.377047555670686}
2023-01-04 09:05:26,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:26,096 INFO:     Epoch: 30
2023-01-04 09:05:27,622 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.513505627711614, 'Total loss': 0.513505627711614} | train loss {'Reaction outcome loss': 0.3735206702003514, 'Total loss': 0.3735206702003514}
2023-01-04 09:05:27,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:27,622 INFO:     Epoch: 31
2023-01-04 09:05:29,119 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5220408320426941, 'Total loss': 0.5220408320426941} | train loss {'Reaction outcome loss': 0.37004942648167155, 'Total loss': 0.37004942648167155}
2023-01-04 09:05:29,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:29,119 INFO:     Epoch: 32
2023-01-04 09:05:30,624 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.51329611937205, 'Total loss': 0.51329611937205} | train loss {'Reaction outcome loss': 0.3666016449947862, 'Total loss': 0.3666016449947862}
2023-01-04 09:05:30,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:30,625 INFO:     Epoch: 33
2023-01-04 09:05:32,159 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.511113566160202, 'Total loss': 0.511113566160202} | train loss {'Reaction outcome loss': 0.36401094577825854, 'Total loss': 0.36401094577825854}
2023-01-04 09:05:32,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:32,160 INFO:     Epoch: 34
2023-01-04 09:05:33,706 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.522887239853541, 'Total loss': 0.522887239853541} | train loss {'Reaction outcome loss': 0.3582762020238995, 'Total loss': 0.3582762020238995}
2023-01-04 09:05:33,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:33,706 INFO:     Epoch: 35
2023-01-04 09:05:35,247 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5112164576848348, 'Total loss': 0.5112164576848348} | train loss {'Reaction outcome loss': 0.3558352063172055, 'Total loss': 0.3558352063172055}
2023-01-04 09:05:35,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:35,247 INFO:     Epoch: 36
2023-01-04 09:05:36,789 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5324366668860118, 'Total loss': 0.5324366668860118} | train loss {'Reaction outcome loss': 0.35475016439700646, 'Total loss': 0.35475016439700646}
2023-01-04 09:05:36,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:36,790 INFO:     Epoch: 37
2023-01-04 09:05:38,309 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5214457710584005, 'Total loss': 0.5214457710584005} | train loss {'Reaction outcome loss': 0.3508130380217611, 'Total loss': 0.3508130380217611}
2023-01-04 09:05:38,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:38,309 INFO:     Epoch: 38
2023-01-04 09:05:39,832 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5131953398386637, 'Total loss': 0.5131953398386637} | train loss {'Reaction outcome loss': 0.3437541152493362, 'Total loss': 0.3437541152493362}
2023-01-04 09:05:39,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:39,832 INFO:     Epoch: 39
2023-01-04 09:05:41,384 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5162143429120382, 'Total loss': 0.5162143429120382} | train loss {'Reaction outcome loss': 0.34696261228544867, 'Total loss': 0.34696261228544867}
2023-01-04 09:05:41,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:41,384 INFO:     Epoch: 40
2023-01-04 09:05:42,925 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5244407892227173, 'Total loss': 0.5244407892227173} | train loss {'Reaction outcome loss': 0.3406141020466376, 'Total loss': 0.3406141020466376}
2023-01-04 09:05:42,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:42,926 INFO:     Epoch: 41
2023-01-04 09:05:44,473 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48680501282215116, 'Total loss': 0.48680501282215116} | train loss {'Reaction outcome loss': 0.3434015122534585, 'Total loss': 0.3434015122534585}
2023-01-04 09:05:44,473 INFO:     Found new best model at epoch 41
2023-01-04 09:05:44,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:44,474 INFO:     Epoch: 42
2023-01-04 09:05:46,017 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5060386876265208, 'Total loss': 0.5060386876265208} | train loss {'Reaction outcome loss': 0.3337148088608345, 'Total loss': 0.3337148088608345}
2023-01-04 09:05:46,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:46,017 INFO:     Epoch: 43
2023-01-04 09:05:47,520 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5125870267550151, 'Total loss': 0.5125870267550151} | train loss {'Reaction outcome loss': 0.33449240953382786, 'Total loss': 0.33449240953382786}
2023-01-04 09:05:47,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:47,520 INFO:     Epoch: 44
2023-01-04 09:05:49,024 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5008363604545594, 'Total loss': 0.5008363604545594} | train loss {'Reaction outcome loss': 0.3322375408870025, 'Total loss': 0.3322375408870025}
2023-01-04 09:05:49,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:49,024 INFO:     Epoch: 45
2023-01-04 09:05:50,551 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5105965554714202, 'Total loss': 0.5105965554714202} | train loss {'Reaction outcome loss': 0.33212994234840365, 'Total loss': 0.33212994234840365}
2023-01-04 09:05:50,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:50,551 INFO:     Epoch: 46
2023-01-04 09:05:52,086 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5222398738066355, 'Total loss': 0.5222398738066355} | train loss {'Reaction outcome loss': 0.327720508251312, 'Total loss': 0.327720508251312}
2023-01-04 09:05:52,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:52,086 INFO:     Epoch: 47
2023-01-04 09:05:53,633 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5219997048377991, 'Total loss': 0.5219997048377991} | train loss {'Reaction outcome loss': 0.32145389055248597, 'Total loss': 0.32145389055248597}
2023-01-04 09:05:53,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:53,633 INFO:     Epoch: 48
2023-01-04 09:05:55,202 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5342769960562388, 'Total loss': 0.5342769960562388} | train loss {'Reaction outcome loss': 0.32556971312113053, 'Total loss': 0.32556971312113053}
2023-01-04 09:05:55,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:55,203 INFO:     Epoch: 49
2023-01-04 09:05:56,728 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48214452068010966, 'Total loss': 0.48214452068010966} | train loss {'Reaction outcome loss': 0.3162492993049813, 'Total loss': 0.3162492993049813}
2023-01-04 09:05:56,728 INFO:     Found new best model at epoch 49
2023-01-04 09:05:56,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:56,729 INFO:     Epoch: 50
2023-01-04 09:05:58,245 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48191494345664976, 'Total loss': 0.48191494345664976} | train loss {'Reaction outcome loss': 0.3215053323248442, 'Total loss': 0.3215053323248442}
2023-01-04 09:05:58,245 INFO:     Found new best model at epoch 50
2023-01-04 09:05:58,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:58,246 INFO:     Epoch: 51
2023-01-04 09:05:59,817 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4724137882391612, 'Total loss': 0.4724137882391612} | train loss {'Reaction outcome loss': 0.31916099036261986, 'Total loss': 0.31916099036261986}
2023-01-04 09:05:59,817 INFO:     Found new best model at epoch 51
2023-01-04 09:05:59,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:05:59,818 INFO:     Epoch: 52
2023-01-04 09:06:01,380 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4876907666524251, 'Total loss': 0.4876907666524251} | train loss {'Reaction outcome loss': 0.31191961597787204, 'Total loss': 0.31191961597787204}
2023-01-04 09:06:01,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:01,381 INFO:     Epoch: 53
2023-01-04 09:06:02,924 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5215202947457631, 'Total loss': 0.5215202947457631} | train loss {'Reaction outcome loss': 0.31176163862547734, 'Total loss': 0.31176163862547734}
2023-01-04 09:06:02,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:02,924 INFO:     Epoch: 54
2023-01-04 09:06:04,473 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4821543653806051, 'Total loss': 0.4821543653806051} | train loss {'Reaction outcome loss': 0.30940578388471673, 'Total loss': 0.30940578388471673}
2023-01-04 09:06:04,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:04,473 INFO:     Epoch: 55
2023-01-04 09:06:06,005 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4602518985668818, 'Total loss': 0.4602518985668818} | train loss {'Reaction outcome loss': 0.3054286174639298, 'Total loss': 0.3054286174639298}
2023-01-04 09:06:06,005 INFO:     Found new best model at epoch 55
2023-01-04 09:06:06,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:06,006 INFO:     Epoch: 56
2023-01-04 09:06:07,536 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46978023946285247, 'Total loss': 0.46978023946285247} | train loss {'Reaction outcome loss': 0.30805543186075063, 'Total loss': 0.30805543186075063}
2023-01-04 09:06:07,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:07,537 INFO:     Epoch: 57
2023-01-04 09:06:09,090 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5027328133583069, 'Total loss': 0.5027328133583069} | train loss {'Reaction outcome loss': 0.3047213739559163, 'Total loss': 0.3047213739559163}
2023-01-04 09:06:09,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:09,090 INFO:     Epoch: 58
2023-01-04 09:06:10,622 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5001068363587061, 'Total loss': 0.5001068363587061} | train loss {'Reaction outcome loss': 0.30114801029545546, 'Total loss': 0.30114801029545546}
2023-01-04 09:06:10,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:10,623 INFO:     Epoch: 59
2023-01-04 09:06:12,154 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44954399367173514, 'Total loss': 0.44954399367173514} | train loss {'Reaction outcome loss': 0.2996214618974358, 'Total loss': 0.2996214618974358}
2023-01-04 09:06:12,154 INFO:     Found new best model at epoch 59
2023-01-04 09:06:12,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:12,155 INFO:     Epoch: 60
2023-01-04 09:06:13,668 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5094888389110566, 'Total loss': 0.5094888389110566} | train loss {'Reaction outcome loss': 0.29568976715859707, 'Total loss': 0.29568976715859707}
2023-01-04 09:06:13,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:13,669 INFO:     Epoch: 61
2023-01-04 09:06:15,192 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4771791934967041, 'Total loss': 0.4771791934967041} | train loss {'Reaction outcome loss': 0.2992001424686317, 'Total loss': 0.2992001424686317}
2023-01-04 09:06:15,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:15,192 INFO:     Epoch: 62
2023-01-04 09:06:16,713 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4624045689900716, 'Total loss': 0.4624045689900716} | train loss {'Reaction outcome loss': 0.29372885448001596, 'Total loss': 0.29372885448001596}
2023-01-04 09:06:16,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:16,714 INFO:     Epoch: 63
2023-01-04 09:06:18,262 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4847637156645457, 'Total loss': 0.4847637156645457} | train loss {'Reaction outcome loss': 0.29231268232756286, 'Total loss': 0.29231268232756286}
2023-01-04 09:06:18,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:18,262 INFO:     Epoch: 64
2023-01-04 09:06:19,804 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44270762701829275, 'Total loss': 0.44270762701829275} | train loss {'Reaction outcome loss': 0.29008758340003715, 'Total loss': 0.29008758340003715}
2023-01-04 09:06:19,804 INFO:     Found new best model at epoch 64
2023-01-04 09:06:19,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:19,805 INFO:     Epoch: 65
2023-01-04 09:06:21,345 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5138149619102478, 'Total loss': 0.5138149619102478} | train loss {'Reaction outcome loss': 0.2886790298061432, 'Total loss': 0.2886790298061432}
2023-01-04 09:06:21,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:21,345 INFO:     Epoch: 66
2023-01-04 09:06:22,858 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4877531290054321, 'Total loss': 0.4877531290054321} | train loss {'Reaction outcome loss': 0.28674443327162386, 'Total loss': 0.28674443327162386}
2023-01-04 09:06:22,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:22,858 INFO:     Epoch: 67
2023-01-04 09:06:24,416 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48107811212539675, 'Total loss': 0.48107811212539675} | train loss {'Reaction outcome loss': 0.28425922685295996, 'Total loss': 0.28425922685295996}
2023-01-04 09:06:24,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:24,416 INFO:     Epoch: 68
2023-01-04 09:06:26,003 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49988318979740143, 'Total loss': 0.49988318979740143} | train loss {'Reaction outcome loss': 0.28267447286061126, 'Total loss': 0.28267447286061126}
2023-01-04 09:06:26,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:26,005 INFO:     Epoch: 69
2023-01-04 09:06:27,587 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49881741404533386, 'Total loss': 0.49881741404533386} | train loss {'Reaction outcome loss': 0.2874696154120195, 'Total loss': 0.2874696154120195}
2023-01-04 09:06:27,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:27,587 INFO:     Epoch: 70
2023-01-04 09:06:29,170 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4939444919427236, 'Total loss': 0.4939444919427236} | train loss {'Reaction outcome loss': 0.28179132415620733, 'Total loss': 0.28179132415620733}
2023-01-04 09:06:29,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:29,171 INFO:     Epoch: 71
2023-01-04 09:06:30,733 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49621179898579915, 'Total loss': 0.49621179898579915} | train loss {'Reaction outcome loss': 0.27818907556688266, 'Total loss': 0.27818907556688266}
2023-01-04 09:06:30,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:30,733 INFO:     Epoch: 72
2023-01-04 09:06:32,291 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5237875282764435, 'Total loss': 0.5237875282764435} | train loss {'Reaction outcome loss': 0.2792978580959522, 'Total loss': 0.2792978580959522}
2023-01-04 09:06:32,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:32,292 INFO:     Epoch: 73
2023-01-04 09:06:33,839 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44312247931957244, 'Total loss': 0.44312247931957244} | train loss {'Reaction outcome loss': 0.2800170345925284, 'Total loss': 0.2800170345925284}
2023-01-04 09:06:33,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:33,840 INFO:     Epoch: 74
2023-01-04 09:06:35,435 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4424516836802165, 'Total loss': 0.4424516836802165} | train loss {'Reaction outcome loss': 0.2790057886745373, 'Total loss': 0.2790057886745373}
2023-01-04 09:06:35,435 INFO:     Found new best model at epoch 74
2023-01-04 09:06:35,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:35,436 INFO:     Epoch: 75
2023-01-04 09:06:37,024 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4547501305739085, 'Total loss': 0.4547501305739085} | train loss {'Reaction outcome loss': 0.27501686381679163, 'Total loss': 0.27501686381679163}
2023-01-04 09:06:37,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:37,024 INFO:     Epoch: 76
2023-01-04 09:06:38,610 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48612192273139954, 'Total loss': 0.48612192273139954} | train loss {'Reaction outcome loss': 0.27570863640493287, 'Total loss': 0.27570863640493287}
2023-01-04 09:06:38,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:38,610 INFO:     Epoch: 77
2023-01-04 09:06:40,149 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48967128346363703, 'Total loss': 0.48967128346363703} | train loss {'Reaction outcome loss': 0.2702458083466457, 'Total loss': 0.2702458083466457}
2023-01-04 09:06:40,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:40,149 INFO:     Epoch: 78
2023-01-04 09:06:41,663 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46338687936464945, 'Total loss': 0.46338687936464945} | train loss {'Reaction outcome loss': 0.2702961296223811, 'Total loss': 0.2702961296223811}
2023-01-04 09:06:41,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:41,664 INFO:     Epoch: 79
2023-01-04 09:06:43,007 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4661273270845413, 'Total loss': 0.4661273270845413} | train loss {'Reaction outcome loss': 0.27398774933314674, 'Total loss': 0.27398774933314674}
2023-01-04 09:06:43,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:43,007 INFO:     Epoch: 80
2023-01-04 09:06:44,026 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4834510107835134, 'Total loss': 0.4834510107835134} | train loss {'Reaction outcome loss': 0.2716974521694827, 'Total loss': 0.2716974521694827}
2023-01-04 09:06:44,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:44,026 INFO:     Epoch: 81
2023-01-04 09:06:45,038 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4785463551680247, 'Total loss': 0.4785463551680247} | train loss {'Reaction outcome loss': 0.26617591866176493, 'Total loss': 0.26617591866176493}
2023-01-04 09:06:45,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:45,038 INFO:     Epoch: 82
2023-01-04 09:06:46,053 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48827405174573263, 'Total loss': 0.48827405174573263} | train loss {'Reaction outcome loss': 0.26749969356740916, 'Total loss': 0.26749969356740916}
2023-01-04 09:06:46,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:46,053 INFO:     Epoch: 83
2023-01-04 09:06:47,061 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47562747200330097, 'Total loss': 0.47562747200330097} | train loss {'Reaction outcome loss': 0.2708639868120425, 'Total loss': 0.2708639868120425}
2023-01-04 09:06:47,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:47,061 INFO:     Epoch: 84
2023-01-04 09:06:48,420 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47059106777111687, 'Total loss': 0.47059106777111687} | train loss {'Reaction outcome loss': 0.26976230478145347, 'Total loss': 0.26976230478145347}
2023-01-04 09:06:48,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:48,420 INFO:     Epoch: 85
2023-01-04 09:06:49,958 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4673481782277425, 'Total loss': 0.4673481782277425} | train loss {'Reaction outcome loss': 0.2652683093953524, 'Total loss': 0.2652683093953524}
2023-01-04 09:06:49,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:49,958 INFO:     Epoch: 86
2023-01-04 09:06:51,497 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49657596945762633, 'Total loss': 0.49657596945762633} | train loss {'Reaction outcome loss': 0.26384308771060333, 'Total loss': 0.26384308771060333}
2023-01-04 09:06:51,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:51,497 INFO:     Epoch: 87
2023-01-04 09:06:53,041 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4295601750413577, 'Total loss': 0.4295601750413577} | train loss {'Reaction outcome loss': 0.2599205518562863, 'Total loss': 0.2599205518562863}
2023-01-04 09:06:53,041 INFO:     Found new best model at epoch 87
2023-01-04 09:06:53,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:53,042 INFO:     Epoch: 88
2023-01-04 09:06:54,593 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45329633553822835, 'Total loss': 0.45329633553822835} | train loss {'Reaction outcome loss': 0.2656765486637171, 'Total loss': 0.2656765486637171}
2023-01-04 09:06:54,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:54,593 INFO:     Epoch: 89
2023-01-04 09:06:56,145 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46073937018712363, 'Total loss': 0.46073937018712363} | train loss {'Reaction outcome loss': 0.25964153707571275, 'Total loss': 0.25964153707571275}
2023-01-04 09:06:56,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:56,145 INFO:     Epoch: 90
2023-01-04 09:06:57,572 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4525807946920395, 'Total loss': 0.4525807946920395} | train loss {'Reaction outcome loss': 0.2614661472557235, 'Total loss': 0.2614661472557235}
2023-01-04 09:06:57,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:57,573 INFO:     Epoch: 91
2023-01-04 09:06:59,124 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47944523096084596, 'Total loss': 0.47944523096084596} | train loss {'Reaction outcome loss': 0.25908205671793355, 'Total loss': 0.25908205671793355}
2023-01-04 09:06:59,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:06:59,124 INFO:     Epoch: 92
2023-01-04 09:07:00,670 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4472499420245489, 'Total loss': 0.4472499420245489} | train loss {'Reaction outcome loss': 0.2594877849638897, 'Total loss': 0.2594877849638897}
2023-01-04 09:07:00,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:00,670 INFO:     Epoch: 93
2023-01-04 09:07:02,215 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4788442671298981, 'Total loss': 0.4788442671298981} | train loss {'Reaction outcome loss': 0.2586784113579205, 'Total loss': 0.2586784113579205}
2023-01-04 09:07:02,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:02,216 INFO:     Epoch: 94
2023-01-04 09:07:03,756 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4690582116444906, 'Total loss': 0.4690582116444906} | train loss {'Reaction outcome loss': 0.2594089771070293, 'Total loss': 0.2594089771070293}
2023-01-04 09:07:03,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:03,757 INFO:     Epoch: 95
2023-01-04 09:07:05,285 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47159567674001057, 'Total loss': 0.47159567674001057} | train loss {'Reaction outcome loss': 0.2517591628252807, 'Total loss': 0.2517591628252807}
2023-01-04 09:07:05,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:05,285 INFO:     Epoch: 96
2023-01-04 09:07:06,680 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5016693909962971, 'Total loss': 0.5016693909962971} | train loss {'Reaction outcome loss': 0.2554136299711727, 'Total loss': 0.2554136299711727}
2023-01-04 09:07:06,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:06,680 INFO:     Epoch: 97
2023-01-04 09:07:08,225 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44147129158178966, 'Total loss': 0.44147129158178966} | train loss {'Reaction outcome loss': 0.254741139030152, 'Total loss': 0.254741139030152}
2023-01-04 09:07:08,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:08,225 INFO:     Epoch: 98
2023-01-04 09:07:09,770 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4561624526977539, 'Total loss': 0.4561624526977539} | train loss {'Reaction outcome loss': 0.2558796935626408, 'Total loss': 0.2558796935626408}
2023-01-04 09:07:09,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:09,770 INFO:     Epoch: 99
2023-01-04 09:07:11,298 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41269264618555707, 'Total loss': 0.41269264618555707} | train loss {'Reaction outcome loss': 0.25103135472231536, 'Total loss': 0.25103135472231536}
2023-01-04 09:07:11,298 INFO:     Found new best model at epoch 99
2023-01-04 09:07:11,299 INFO:     Best model found after epoch 100 of 100.
2023-01-04 09:07:11,299 INFO:   Done with stage: TRAINING
2023-01-04 09:07:11,299 INFO:   Starting stage: EVALUATION
2023-01-04 09:07:11,432 INFO:   Done with stage: EVALUATION
2023-01-04 09:07:11,432 INFO:   Leaving out SEQ value Fold_1
2023-01-04 09:07:11,445 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:07:11,445 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:07:12,093 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:07:12,093 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:07:12,160 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:07:12,161 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:07:12,161 INFO:     No hyperparam tuning for this model
2023-01-04 09:07:12,161 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:07:12,161 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:07:12,161 INFO:     None feature selector for col prot
2023-01-04 09:07:12,162 INFO:     None feature selector for col prot
2023-01-04 09:07:12,162 INFO:     None feature selector for col prot
2023-01-04 09:07:12,162 INFO:     None feature selector for col chem
2023-01-04 09:07:12,162 INFO:     None feature selector for col chem
2023-01-04 09:07:12,162 INFO:     None feature selector for col chem
2023-01-04 09:07:12,162 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:07:12,163 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:07:12,163 INFO:     Number of params in model 70111
2023-01-04 09:07:12,167 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:07:12,167 INFO:   Starting stage: TRAINING
2023-01-04 09:07:12,208 INFO:     Val loss before train {'Reaction outcome loss': 1.031526267528534, 'Total loss': 1.031526267528534}
2023-01-04 09:07:12,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:12,208 INFO:     Epoch: 0
2023-01-04 09:07:13,769 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.760907010237376, 'Total loss': 0.760907010237376} | train loss {'Reaction outcome loss': 0.8374387559926381, 'Total loss': 0.8374387559926381}
2023-01-04 09:07:13,769 INFO:     Found new best model at epoch 0
2023-01-04 09:07:13,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:13,770 INFO:     Epoch: 1
2023-01-04 09:07:15,204 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.61017018755277, 'Total loss': 0.61017018755277} | train loss {'Reaction outcome loss': 0.6994093379032784, 'Total loss': 0.6994093379032784}
2023-01-04 09:07:15,204 INFO:     Found new best model at epoch 1
2023-01-04 09:07:15,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:15,205 INFO:     Epoch: 2
2023-01-04 09:07:16,752 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5636897762616475, 'Total loss': 0.5636897762616475} | train loss {'Reaction outcome loss': 0.6086710361836384, 'Total loss': 0.6086710361836384}
2023-01-04 09:07:16,752 INFO:     Found new best model at epoch 2
2023-01-04 09:07:16,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:16,753 INFO:     Epoch: 3
2023-01-04 09:07:18,313 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5643438319365184, 'Total loss': 0.5643438319365184} | train loss {'Reaction outcome loss': 0.552661263856335, 'Total loss': 0.552661263856335}
2023-01-04 09:07:18,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:18,313 INFO:     Epoch: 4
2023-01-04 09:07:19,868 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5309870382150014, 'Total loss': 0.5309870382150014} | train loss {'Reaction outcome loss': 0.5541746026255946, 'Total loss': 0.5541746026255946}
2023-01-04 09:07:19,868 INFO:     Found new best model at epoch 4
2023-01-04 09:07:19,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:19,869 INFO:     Epoch: 5
2023-01-04 09:07:21,427 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48129165669282276, 'Total loss': 0.48129165669282276} | train loss {'Reaction outcome loss': 0.5466589651785899, 'Total loss': 0.5466589651785899}
2023-01-04 09:07:21,427 INFO:     Found new best model at epoch 5
2023-01-04 09:07:21,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:21,427 INFO:     Epoch: 6
2023-01-04 09:07:22,982 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47993425528208417, 'Total loss': 0.47993425528208417} | train loss {'Reaction outcome loss': 0.5117355080901821, 'Total loss': 0.5117355080901821}
2023-01-04 09:07:22,983 INFO:     Found new best model at epoch 6
2023-01-04 09:07:22,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:22,983 INFO:     Epoch: 7
2023-01-04 09:07:24,401 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48019272486368814, 'Total loss': 0.48019272486368814} | train loss {'Reaction outcome loss': 0.48878411094293645, 'Total loss': 0.48878411094293645}
2023-01-04 09:07:24,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:24,401 INFO:     Epoch: 8
2023-01-04 09:07:25,951 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46130975186824796, 'Total loss': 0.46130975186824796} | train loss {'Reaction outcome loss': 0.47952612240096903, 'Total loss': 0.47952612240096903}
2023-01-04 09:07:25,951 INFO:     Found new best model at epoch 8
2023-01-04 09:07:25,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:25,952 INFO:     Epoch: 9
2023-01-04 09:07:27,505 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45434619188308717, 'Total loss': 0.45434619188308717} | train loss {'Reaction outcome loss': 0.47339905668859894, 'Total loss': 0.47339905668859894}
2023-01-04 09:07:27,505 INFO:     Found new best model at epoch 9
2023-01-04 09:07:27,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:27,506 INFO:     Epoch: 10
2023-01-04 09:07:29,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4270420789718628, 'Total loss': 0.4270420789718628} | train loss {'Reaction outcome loss': 0.4701708289056483, 'Total loss': 0.4701708289056483}
2023-01-04 09:07:29,061 INFO:     Found new best model at epoch 10
2023-01-04 09:07:29,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:29,062 INFO:     Epoch: 11
2023-01-04 09:07:30,612 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42961732943852743, 'Total loss': 0.42961732943852743} | train loss {'Reaction outcome loss': 0.4625049317491821, 'Total loss': 0.4625049317491821}
2023-01-04 09:07:30,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:30,612 INFO:     Epoch: 12
2023-01-04 09:07:32,160 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4793948103984197, 'Total loss': 0.4793948103984197} | train loss {'Reaction outcome loss': 0.4589570391099846, 'Total loss': 0.4589570391099846}
2023-01-04 09:07:32,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:32,160 INFO:     Epoch: 13
2023-01-04 09:07:33,608 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43014294902483624, 'Total loss': 0.43014294902483624} | train loss {'Reaction outcome loss': 0.45748342400875647, 'Total loss': 0.45748342400875647}
2023-01-04 09:07:33,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:33,609 INFO:     Epoch: 14
2023-01-04 09:07:35,178 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44223439594109853, 'Total loss': 0.44223439594109853} | train loss {'Reaction outcome loss': 0.4605232847435231, 'Total loss': 0.4605232847435231}
2023-01-04 09:07:35,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:35,178 INFO:     Epoch: 15
2023-01-04 09:07:36,740 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4318292657534281, 'Total loss': 0.4318292657534281} | train loss {'Reaction outcome loss': 0.44644425206723204, 'Total loss': 0.44644425206723204}
2023-01-04 09:07:36,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:36,740 INFO:     Epoch: 16
2023-01-04 09:07:38,330 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4251733660697937, 'Total loss': 0.4251733660697937} | train loss {'Reaction outcome loss': 0.4419230581885474, 'Total loss': 0.4419230581885474}
2023-01-04 09:07:38,330 INFO:     Found new best model at epoch 16
2023-01-04 09:07:38,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:38,331 INFO:     Epoch: 17
2023-01-04 09:07:39,894 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4438966025908788, 'Total loss': 0.4438966025908788} | train loss {'Reaction outcome loss': 0.44026326783173514, 'Total loss': 0.44026326783173514}
2023-01-04 09:07:39,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:39,895 INFO:     Epoch: 18
2023-01-04 09:07:41,422 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44044770499070485, 'Total loss': 0.44044770499070485} | train loss {'Reaction outcome loss': 0.43399798340987467, 'Total loss': 0.43399798340987467}
2023-01-04 09:07:41,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:41,422 INFO:     Epoch: 19
2023-01-04 09:07:42,904 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4321555525064468, 'Total loss': 0.4321555525064468} | train loss {'Reaction outcome loss': 0.42935535840798117, 'Total loss': 0.42935535840798117}
2023-01-04 09:07:42,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:42,905 INFO:     Epoch: 20
2023-01-04 09:07:44,471 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41703560849030813, 'Total loss': 0.41703560849030813} | train loss {'Reaction outcome loss': 0.4256221203971148, 'Total loss': 0.4256221203971148}
2023-01-04 09:07:44,471 INFO:     Found new best model at epoch 20
2023-01-04 09:07:44,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:44,472 INFO:     Epoch: 21
2023-01-04 09:07:46,031 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3923910327255726, 'Total loss': 0.3923910327255726} | train loss {'Reaction outcome loss': 0.41837448100905283, 'Total loss': 0.41837448100905283}
2023-01-04 09:07:46,031 INFO:     Found new best model at epoch 21
2023-01-04 09:07:46,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:46,032 INFO:     Epoch: 22
2023-01-04 09:07:47,602 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4108179191748301, 'Total loss': 0.4108179191748301} | train loss {'Reaction outcome loss': 0.41505661564287555, 'Total loss': 0.41505661564287555}
2023-01-04 09:07:47,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:47,602 INFO:     Epoch: 23
2023-01-04 09:07:49,156 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41659281253814695, 'Total loss': 0.41659281253814695} | train loss {'Reaction outcome loss': 0.41325699753951334, 'Total loss': 0.41325699753951334}
2023-01-04 09:07:49,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:49,156 INFO:     Epoch: 24
2023-01-04 09:07:50,611 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40972956220308937, 'Total loss': 0.40972956220308937} | train loss {'Reaction outcome loss': 0.41049244748833386, 'Total loss': 0.41049244748833386}
2023-01-04 09:07:50,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:50,611 INFO:     Epoch: 25
2023-01-04 09:07:52,174 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39626708229382834, 'Total loss': 0.39626708229382834} | train loss {'Reaction outcome loss': 0.41002682300134347, 'Total loss': 0.41002682300134347}
2023-01-04 09:07:52,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:52,175 INFO:     Epoch: 26
2023-01-04 09:07:53,744 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3982515066862106, 'Total loss': 0.3982515066862106} | train loss {'Reaction outcome loss': 0.39910708425357344, 'Total loss': 0.39910708425357344}
2023-01-04 09:07:53,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:53,744 INFO:     Epoch: 27
2023-01-04 09:07:55,308 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4000817398230235, 'Total loss': 0.4000817398230235} | train loss {'Reaction outcome loss': 0.39671854740616097, 'Total loss': 0.39671854740616097}
2023-01-04 09:07:55,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:55,308 INFO:     Epoch: 28
2023-01-04 09:07:56,855 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38300735453764595, 'Total loss': 0.38300735453764595} | train loss {'Reaction outcome loss': 0.3915126076798238, 'Total loss': 0.3915126076798238}
2023-01-04 09:07:56,855 INFO:     Found new best model at epoch 28
2023-01-04 09:07:56,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:56,856 INFO:     Epoch: 29
2023-01-04 09:07:58,408 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41237262487411497, 'Total loss': 0.41237262487411497} | train loss {'Reaction outcome loss': 0.3844197291671636, 'Total loss': 0.3844197291671636}
2023-01-04 09:07:58,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:58,408 INFO:     Epoch: 30
2023-01-04 09:07:59,818 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40114552279313404, 'Total loss': 0.40114552279313404} | train loss {'Reaction outcome loss': 0.38831746544219903, 'Total loss': 0.38831746544219903}
2023-01-04 09:07:59,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:07:59,818 INFO:     Epoch: 31
2023-01-04 09:08:01,369 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.388093090057373, 'Total loss': 0.388093090057373} | train loss {'Reaction outcome loss': 0.38248109535408625, 'Total loss': 0.38248109535408625}
2023-01-04 09:08:01,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:01,369 INFO:     Epoch: 32
2023-01-04 09:08:02,937 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41377508640289307, 'Total loss': 0.41377508640289307} | train loss {'Reaction outcome loss': 0.3884883343471565, 'Total loss': 0.3884883343471565}
2023-01-04 09:08:02,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:02,938 INFO:     Epoch: 33
2023-01-04 09:08:04,497 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3850041747093201, 'Total loss': 0.3850041747093201} | train loss {'Reaction outcome loss': 0.4058886505663395, 'Total loss': 0.4058886505663395}
2023-01-04 09:08:04,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:04,497 INFO:     Epoch: 34
2023-01-04 09:08:06,054 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3850363612174988, 'Total loss': 0.3850363612174988} | train loss {'Reaction outcome loss': 0.3799820479133801, 'Total loss': 0.3799820479133801}
2023-01-04 09:08:06,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:06,054 INFO:     Epoch: 35
2023-01-04 09:08:07,606 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4118423422177633, 'Total loss': 0.4118423422177633} | train loss {'Reaction outcome loss': 0.3707906122764815, 'Total loss': 0.3707906122764815}
2023-01-04 09:08:07,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:07,606 INFO:     Epoch: 36
2023-01-04 09:08:09,040 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3733336001634598, 'Total loss': 0.3733336001634598} | train loss {'Reaction outcome loss': 0.36963869885801326, 'Total loss': 0.36963869885801326}
2023-01-04 09:08:09,041 INFO:     Found new best model at epoch 36
2023-01-04 09:08:09,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:09,042 INFO:     Epoch: 37
2023-01-04 09:08:10,613 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37507409453392027, 'Total loss': 0.37507409453392027} | train loss {'Reaction outcome loss': 0.36495436636218126, 'Total loss': 0.36495436636218126}
2023-01-04 09:08:10,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:10,613 INFO:     Epoch: 38
2023-01-04 09:08:12,163 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39013835191726687, 'Total loss': 0.39013835191726687} | train loss {'Reaction outcome loss': 0.36950423255346826, 'Total loss': 0.36950423255346826}
2023-01-04 09:08:12,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:12,164 INFO:     Epoch: 39
2023-01-04 09:08:13,691 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3831382095813751, 'Total loss': 0.3831382095813751} | train loss {'Reaction outcome loss': 0.36382266912362643, 'Total loss': 0.36382266912362643}
2023-01-04 09:08:13,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:13,692 INFO:     Epoch: 40
2023-01-04 09:08:15,243 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3882055163383484, 'Total loss': 0.3882055163383484} | train loss {'Reaction outcome loss': 0.3582812135657836, 'Total loss': 0.3582812135657836}
2023-01-04 09:08:15,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:15,244 INFO:     Epoch: 41
2023-01-04 09:08:16,801 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3714859962463379, 'Total loss': 0.3714859962463379} | train loss {'Reaction outcome loss': 0.35334231812452926, 'Total loss': 0.35334231812452926}
2023-01-04 09:08:16,801 INFO:     Found new best model at epoch 41
2023-01-04 09:08:16,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:16,802 INFO:     Epoch: 42
2023-01-04 09:08:18,183 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39298875133196515, 'Total loss': 0.39298875133196515} | train loss {'Reaction outcome loss': 0.3521682049976189, 'Total loss': 0.3521682049976189}
2023-01-04 09:08:18,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:18,183 INFO:     Epoch: 43
2023-01-04 09:08:19,741 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3917805294195811, 'Total loss': 0.3917805294195811} | train loss {'Reaction outcome loss': 0.3498432075995378, 'Total loss': 0.3498432075995378}
2023-01-04 09:08:19,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:19,742 INFO:     Epoch: 44
2023-01-04 09:08:21,294 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37601031064987184, 'Total loss': 0.37601031064987184} | train loss {'Reaction outcome loss': 0.34360841284438537, 'Total loss': 0.34360841284438537}
2023-01-04 09:08:21,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:21,295 INFO:     Epoch: 45
2023-01-04 09:08:22,844 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3843578805526098, 'Total loss': 0.3843578805526098} | train loss {'Reaction outcome loss': 0.3448785568064035, 'Total loss': 0.3448785568064035}
2023-01-04 09:08:22,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:22,844 INFO:     Epoch: 46
2023-01-04 09:08:24,414 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4036165694395701, 'Total loss': 0.4036165694395701} | train loss {'Reaction outcome loss': 0.33932177098197996, 'Total loss': 0.33932177098197996}
2023-01-04 09:08:24,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:24,415 INFO:     Epoch: 47
2023-01-04 09:08:25,980 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3841045379638672, 'Total loss': 0.3841045379638672} | train loss {'Reaction outcome loss': 0.337418664638223, 'Total loss': 0.337418664638223}
2023-01-04 09:08:25,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:25,980 INFO:     Epoch: 48
2023-01-04 09:08:27,389 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37691256900628406, 'Total loss': 0.37691256900628406} | train loss {'Reaction outcome loss': 0.3373341226239142, 'Total loss': 0.3373341226239142}
2023-01-04 09:08:27,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:27,390 INFO:     Epoch: 49
2023-01-04 09:08:28,938 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4009248485167821, 'Total loss': 0.4009248485167821} | train loss {'Reaction outcome loss': 0.33277406733807013, 'Total loss': 0.33277406733807013}
2023-01-04 09:08:28,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:28,939 INFO:     Epoch: 50
2023-01-04 09:08:30,475 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39817956189314524, 'Total loss': 0.39817956189314524} | train loss {'Reaction outcome loss': 0.3328632548775362, 'Total loss': 0.3328632548775362}
2023-01-04 09:08:30,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:30,476 INFO:     Epoch: 51
2023-01-04 09:08:32,019 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3852212260166804, 'Total loss': 0.3852212260166804} | train loss {'Reaction outcome loss': 0.3335661137395579, 'Total loss': 0.3335661137395579}
2023-01-04 09:08:32,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:32,019 INFO:     Epoch: 52
2023-01-04 09:08:33,565 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3683517465988795, 'Total loss': 0.3683517465988795} | train loss {'Reaction outcome loss': 0.32568790695728717, 'Total loss': 0.32568790695728717}
2023-01-04 09:08:33,565 INFO:     Found new best model at epoch 52
2023-01-04 09:08:33,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:33,566 INFO:     Epoch: 53
2023-01-04 09:08:35,117 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3953383247057597, 'Total loss': 0.3953383247057597} | train loss {'Reaction outcome loss': 0.3252752322620928, 'Total loss': 0.3252752322620928}
2023-01-04 09:08:35,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:35,117 INFO:     Epoch: 54
2023-01-04 09:08:36,510 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4018728226423264, 'Total loss': 0.4018728226423264} | train loss {'Reaction outcome loss': 0.3213458125938432, 'Total loss': 0.3213458125938432}
2023-01-04 09:08:36,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:36,510 INFO:     Epoch: 55
2023-01-04 09:08:38,056 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3926514754692713, 'Total loss': 0.3926514754692713} | train loss {'Reaction outcome loss': 0.3191642617546123, 'Total loss': 0.3191642617546123}
2023-01-04 09:08:38,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:38,056 INFO:     Epoch: 56
2023-01-04 09:08:39,597 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40304631491502124, 'Total loss': 0.40304631491502124} | train loss {'Reaction outcome loss': 0.31598953227459814, 'Total loss': 0.31598953227459814}
2023-01-04 09:08:39,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:39,597 INFO:     Epoch: 57
2023-01-04 09:08:41,150 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3655874778827031, 'Total loss': 0.3655874778827031} | train loss {'Reaction outcome loss': 0.3128435373346556, 'Total loss': 0.3128435373346556}
2023-01-04 09:08:41,150 INFO:     Found new best model at epoch 57
2023-01-04 09:08:41,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:41,151 INFO:     Epoch: 58
2023-01-04 09:08:42,701 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3499475508928299, 'Total loss': 0.3499475508928299} | train loss {'Reaction outcome loss': 0.3158462837986324, 'Total loss': 0.3158462837986324}
2023-01-04 09:08:42,701 INFO:     Found new best model at epoch 58
2023-01-04 09:08:42,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:42,702 INFO:     Epoch: 59
2023-01-04 09:08:44,250 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37103824118773143, 'Total loss': 0.37103824118773143} | train loss {'Reaction outcome loss': 0.30722912937715696, 'Total loss': 0.30722912937715696}
2023-01-04 09:08:44,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:44,251 INFO:     Epoch: 60
2023-01-04 09:08:45,633 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4127061019341151, 'Total loss': 0.4127061019341151} | train loss {'Reaction outcome loss': 0.31019629774264235, 'Total loss': 0.31019629774264235}
2023-01-04 09:08:45,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:45,633 INFO:     Epoch: 61
2023-01-04 09:08:47,177 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3717838833729426, 'Total loss': 0.3717838833729426} | train loss {'Reaction outcome loss': 0.3080273084682024, 'Total loss': 0.3080273084682024}
2023-01-04 09:08:47,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:47,177 INFO:     Epoch: 62
2023-01-04 09:08:48,734 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38370566566785175, 'Total loss': 0.38370566566785175} | train loss {'Reaction outcome loss': 0.30424687007199164, 'Total loss': 0.30424687007199164}
2023-01-04 09:08:48,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:48,734 INFO:     Epoch: 63
2023-01-04 09:08:50,278 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37262639304002126, 'Total loss': 0.37262639304002126} | train loss {'Reaction outcome loss': 0.32249313852061395, 'Total loss': 0.32249313852061395}
2023-01-04 09:08:50,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:50,279 INFO:     Epoch: 64
2023-01-04 09:08:51,839 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37684554755687716, 'Total loss': 0.37684554755687716} | train loss {'Reaction outcome loss': 0.32023201906628423, 'Total loss': 0.32023201906628423}
2023-01-04 09:08:51,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:51,839 INFO:     Epoch: 65
2023-01-04 09:08:53,392 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3898300180832545, 'Total loss': 0.3898300180832545} | train loss {'Reaction outcome loss': 0.3036595092600454, 'Total loss': 0.3036595092600454}
2023-01-04 09:08:53,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:53,392 INFO:     Epoch: 66
2023-01-04 09:08:54,800 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39175273130337396, 'Total loss': 0.39175273130337396} | train loss {'Reaction outcome loss': 0.30960115825460444, 'Total loss': 0.30960115825460444}
2023-01-04 09:08:54,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:54,800 INFO:     Epoch: 67
2023-01-04 09:08:56,366 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3988191306591034, 'Total loss': 0.3988191306591034} | train loss {'Reaction outcome loss': 0.36613894043409306, 'Total loss': 0.36613894043409306}
2023-01-04 09:08:56,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:56,366 INFO:     Epoch: 68
2023-01-04 09:08:57,943 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3487988660732905, 'Total loss': 0.3487988660732905} | train loss {'Reaction outcome loss': 0.33787928365062975, 'Total loss': 0.33787928365062975}
2023-01-04 09:08:57,943 INFO:     Found new best model at epoch 68
2023-01-04 09:08:57,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:57,944 INFO:     Epoch: 69
2023-01-04 09:08:59,518 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.374110879500707, 'Total loss': 0.374110879500707} | train loss {'Reaction outcome loss': 0.299432086681338, 'Total loss': 0.299432086681338}
2023-01-04 09:08:59,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:08:59,518 INFO:     Epoch: 70
2023-01-04 09:09:01,070 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3806884169578552, 'Total loss': 0.3806884169578552} | train loss {'Reaction outcome loss': 0.29417541877879505, 'Total loss': 0.29417541877879505}
2023-01-04 09:09:01,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:01,071 INFO:     Epoch: 71
2023-01-04 09:09:02,640 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3638737032810847, 'Total loss': 0.3638737032810847} | train loss {'Reaction outcome loss': 0.2971786046655852, 'Total loss': 0.2971786046655852}
2023-01-04 09:09:02,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:02,641 INFO:     Epoch: 72
2023-01-04 09:09:04,039 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38957353830337527, 'Total loss': 0.38957353830337527} | train loss {'Reaction outcome loss': 0.28853179114884225, 'Total loss': 0.28853179114884225}
2023-01-04 09:09:04,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:04,039 INFO:     Epoch: 73
2023-01-04 09:09:05,589 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3714894379178683, 'Total loss': 0.3714894379178683} | train loss {'Reaction outcome loss': 0.29158206624181376, 'Total loss': 0.29158206624181376}
2023-01-04 09:09:05,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:05,589 INFO:     Epoch: 74
2023-01-04 09:09:07,139 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35204570392767587, 'Total loss': 0.35204570392767587} | train loss {'Reaction outcome loss': 0.2932159734174501, 'Total loss': 0.2932159734174501}
2023-01-04 09:09:07,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:07,139 INFO:     Epoch: 75
2023-01-04 09:09:08,689 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37871721386909485, 'Total loss': 0.37871721386909485} | train loss {'Reaction outcome loss': 0.2905254877645664, 'Total loss': 0.2905254877645664}
2023-01-04 09:09:08,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:08,690 INFO:     Epoch: 76
2023-01-04 09:09:10,265 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3672128558158875, 'Total loss': 0.3672128558158875} | train loss {'Reaction outcome loss': 0.28204232796459744, 'Total loss': 0.28204232796459744}
2023-01-04 09:09:10,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:10,265 INFO:     Epoch: 77
2023-01-04 09:09:11,832 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36167988975842796, 'Total loss': 0.36167988975842796} | train loss {'Reaction outcome loss': 0.2860954647353999, 'Total loss': 0.2860954647353999}
2023-01-04 09:09:11,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:11,832 INFO:     Epoch: 78
2023-01-04 09:09:13,271 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3424534151951472, 'Total loss': 0.3424534151951472} | train loss {'Reaction outcome loss': 0.28640279054567486, 'Total loss': 0.28640279054567486}
2023-01-04 09:09:13,271 INFO:     Found new best model at epoch 78
2023-01-04 09:09:13,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:13,272 INFO:     Epoch: 79
2023-01-04 09:09:14,828 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3691073526938756, 'Total loss': 0.3691073526938756} | train loss {'Reaction outcome loss': 0.2848442473543295, 'Total loss': 0.2848442473543295}
2023-01-04 09:09:14,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:14,829 INFO:     Epoch: 80
2023-01-04 09:09:16,375 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3648222297430038, 'Total loss': 0.3648222297430038} | train loss {'Reaction outcome loss': 0.28288244266751345, 'Total loss': 0.28288244266751345}
2023-01-04 09:09:16,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:16,376 INFO:     Epoch: 81
2023-01-04 09:09:17,921 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36664782961209613, 'Total loss': 0.36664782961209613} | train loss {'Reaction outcome loss': 0.2782513056377154, 'Total loss': 0.2782513056377154}
2023-01-04 09:09:17,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:17,921 INFO:     Epoch: 82
2023-01-04 09:09:19,474 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3932787199815114, 'Total loss': 0.3932787199815114} | train loss {'Reaction outcome loss': 0.2841116578142712, 'Total loss': 0.2841116578142712}
2023-01-04 09:09:19,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:19,474 INFO:     Epoch: 83
2023-01-04 09:09:21,013 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38215948541959127, 'Total loss': 0.38215948541959127} | train loss {'Reaction outcome loss': 0.35008920070485794, 'Total loss': 0.35008920070485794}
2023-01-04 09:09:21,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:21,014 INFO:     Epoch: 84
2023-01-04 09:09:22,413 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36409384608268736, 'Total loss': 0.36409384608268736} | train loss {'Reaction outcome loss': 0.2812710990013632, 'Total loss': 0.2812710990013632}
2023-01-04 09:09:22,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:22,414 INFO:     Epoch: 85
2023-01-04 09:09:23,982 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.362527334690094, 'Total loss': 0.362527334690094} | train loss {'Reaction outcome loss': 0.2819067556950925, 'Total loss': 0.2819067556950925}
2023-01-04 09:09:23,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:23,982 INFO:     Epoch: 86
2023-01-04 09:09:25,535 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3786650687456131, 'Total loss': 0.3786650687456131} | train loss {'Reaction outcome loss': 0.2722421960257318, 'Total loss': 0.2722421960257318}
2023-01-04 09:09:25,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:25,535 INFO:     Epoch: 87
2023-01-04 09:09:27,110 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34977833926677704, 'Total loss': 0.34977833926677704} | train loss {'Reaction outcome loss': 0.27770451884801634, 'Total loss': 0.27770451884801634}
2023-01-04 09:09:27,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:27,110 INFO:     Epoch: 88
2023-01-04 09:09:28,670 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35851536293824515, 'Total loss': 0.35851536293824515} | train loss {'Reaction outcome loss': 0.27414291523450957, 'Total loss': 0.27414291523450957}
2023-01-04 09:09:28,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:28,670 INFO:     Epoch: 89
2023-01-04 09:09:30,246 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36626745263735455, 'Total loss': 0.36626745263735455} | train loss {'Reaction outcome loss': 0.27148242721307103, 'Total loss': 0.27148242721307103}
2023-01-04 09:09:30,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:30,246 INFO:     Epoch: 90
2023-01-04 09:09:31,649 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38747500578562416, 'Total loss': 0.38747500578562416} | train loss {'Reaction outcome loss': 0.27330470219106023, 'Total loss': 0.27330470219106023}
2023-01-04 09:09:31,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:31,649 INFO:     Epoch: 91
2023-01-04 09:09:33,198 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37030695378780365, 'Total loss': 0.37030695378780365} | train loss {'Reaction outcome loss': 0.2734522682925065, 'Total loss': 0.2734522682925065}
2023-01-04 09:09:33,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:33,199 INFO:     Epoch: 92
2023-01-04 09:09:34,745 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3760154714186986, 'Total loss': 0.3760154714186986} | train loss {'Reaction outcome loss': 0.26716253123637557, 'Total loss': 0.26716253123637557}
2023-01-04 09:09:34,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:34,745 INFO:     Epoch: 93
2023-01-04 09:09:36,291 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3851428518692652, 'Total loss': 0.3851428518692652} | train loss {'Reaction outcome loss': 0.2733380735811332, 'Total loss': 0.2733380735811332}
2023-01-04 09:09:36,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:36,291 INFO:     Epoch: 94
2023-01-04 09:09:37,843 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3725053404768308, 'Total loss': 0.3725053404768308} | train loss {'Reaction outcome loss': 0.2740995229991234, 'Total loss': 0.2740995229991234}
2023-01-04 09:09:37,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:37,843 INFO:     Epoch: 95
2023-01-04 09:09:39,399 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35431334426005684, 'Total loss': 0.35431334426005684} | train loss {'Reaction outcome loss': 0.2626935370279935, 'Total loss': 0.2626935370279935}
2023-01-04 09:09:39,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:39,399 INFO:     Epoch: 96
2023-01-04 09:09:40,813 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35998663306236267, 'Total loss': 0.35998663306236267} | train loss {'Reaction outcome loss': 0.2639020328601346, 'Total loss': 0.2639020328601346}
2023-01-04 09:09:40,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:40,813 INFO:     Epoch: 97
2023-01-04 09:09:42,372 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3928236275911331, 'Total loss': 0.3928236275911331} | train loss {'Reaction outcome loss': 0.26085599035402574, 'Total loss': 0.26085599035402574}
2023-01-04 09:09:42,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:42,372 INFO:     Epoch: 98
2023-01-04 09:09:43,931 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34992554287115735, 'Total loss': 0.34992554287115735} | train loss {'Reaction outcome loss': 0.2795213475419323, 'Total loss': 0.2795213475419323}
2023-01-04 09:09:43,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:43,931 INFO:     Epoch: 99
2023-01-04 09:09:45,487 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35942068497339885, 'Total loss': 0.35942068497339885} | train loss {'Reaction outcome loss': 0.25610611004673917, 'Total loss': 0.25610611004673917}
2023-01-04 09:09:45,488 INFO:     Best model found after epoch 79 of 100.
2023-01-04 09:09:45,488 INFO:   Done with stage: TRAINING
2023-01-04 09:09:45,489 INFO:   Starting stage: EVALUATION
2023-01-04 09:09:45,616 INFO:   Done with stage: EVALUATION
2023-01-04 09:09:45,617 INFO:   Leaving out SEQ value Fold_2
2023-01-04 09:09:45,629 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 09:09:45,629 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:09:46,273 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:09:46,273 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:09:46,341 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:09:46,341 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:09:46,341 INFO:     No hyperparam tuning for this model
2023-01-04 09:09:46,341 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:09:46,341 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:09:46,342 INFO:     None feature selector for col prot
2023-01-04 09:09:46,342 INFO:     None feature selector for col prot
2023-01-04 09:09:46,342 INFO:     None feature selector for col prot
2023-01-04 09:09:46,342 INFO:     None feature selector for col chem
2023-01-04 09:09:46,343 INFO:     None feature selector for col chem
2023-01-04 09:09:46,343 INFO:     None feature selector for col chem
2023-01-04 09:09:46,343 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:09:46,343 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:09:46,344 INFO:     Number of params in model 70111
2023-01-04 09:09:46,347 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:09:46,347 INFO:   Starting stage: TRAINING
2023-01-04 09:09:46,390 INFO:     Val loss before train {'Reaction outcome loss': 0.973026442527771, 'Total loss': 0.973026442527771}
2023-01-04 09:09:46,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:46,390 INFO:     Epoch: 0
2023-01-04 09:09:47,931 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6972592751185099, 'Total loss': 0.6972592751185099} | train loss {'Reaction outcome loss': 0.8360441503298544, 'Total loss': 0.8360441503298544}
2023-01-04 09:09:47,931 INFO:     Found new best model at epoch 0
2023-01-04 09:09:47,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:47,932 INFO:     Epoch: 1
2023-01-04 09:09:49,342 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5982206165790558, 'Total loss': 0.5982206165790558} | train loss {'Reaction outcome loss': 0.6737743448602022, 'Total loss': 0.6737743448602022}
2023-01-04 09:09:49,342 INFO:     Found new best model at epoch 1
2023-01-04 09:09:49,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:49,343 INFO:     Epoch: 2
2023-01-04 09:09:50,888 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49782110850016276, 'Total loss': 0.49782110850016276} | train loss {'Reaction outcome loss': 0.5745252759678521, 'Total loss': 0.5745252759678521}
2023-01-04 09:09:50,888 INFO:     Found new best model at epoch 2
2023-01-04 09:09:50,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:50,889 INFO:     Epoch: 3
2023-01-04 09:09:52,445 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47831824819246926, 'Total loss': 0.47831824819246926} | train loss {'Reaction outcome loss': 0.5365259827379762, 'Total loss': 0.5365259827379762}
2023-01-04 09:09:52,446 INFO:     Found new best model at epoch 3
2023-01-04 09:09:52,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:52,447 INFO:     Epoch: 4
2023-01-04 09:09:54,004 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4574651728073756, 'Total loss': 0.4574651728073756} | train loss {'Reaction outcome loss': 0.5169806939406987, 'Total loss': 0.5169806939406987}
2023-01-04 09:09:54,004 INFO:     Found new best model at epoch 4
2023-01-04 09:09:54,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:54,005 INFO:     Epoch: 5
2023-01-04 09:09:55,565 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44648971160252887, 'Total loss': 0.44648971160252887} | train loss {'Reaction outcome loss': 0.5028829236317726, 'Total loss': 0.5028829236317726}
2023-01-04 09:09:55,565 INFO:     Found new best model at epoch 5
2023-01-04 09:09:55,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:55,566 INFO:     Epoch: 6
2023-01-04 09:09:57,131 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4421989311774572, 'Total loss': 0.4421989311774572} | train loss {'Reaction outcome loss': 0.4961186893773775, 'Total loss': 0.4961186893773775}
2023-01-04 09:09:57,131 INFO:     Found new best model at epoch 6
2023-01-04 09:09:57,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:57,132 INFO:     Epoch: 7
2023-01-04 09:09:58,549 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4488618512948354, 'Total loss': 0.4488618512948354} | train loss {'Reaction outcome loss': 0.4850880488427016, 'Total loss': 0.4850880488427016}
2023-01-04 09:09:58,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:09:58,549 INFO:     Epoch: 8
2023-01-04 09:10:00,095 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4185323596000671, 'Total loss': 0.4185323596000671} | train loss {'Reaction outcome loss': 0.47305246170637383, 'Total loss': 0.47305246170637383}
2023-01-04 09:10:00,095 INFO:     Found new best model at epoch 8
2023-01-04 09:10:00,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:00,096 INFO:     Epoch: 9
2023-01-04 09:10:01,650 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.421878919005394, 'Total loss': 0.421878919005394} | train loss {'Reaction outcome loss': 0.4724794525625932, 'Total loss': 0.4724794525625932}
2023-01-04 09:10:01,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:01,650 INFO:     Epoch: 10
2023-01-04 09:10:03,195 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39862351963917414, 'Total loss': 0.39862351963917414} | train loss {'Reaction outcome loss': 0.4608725997598937, 'Total loss': 0.4608725997598937}
2023-01-04 09:10:03,195 INFO:     Found new best model at epoch 10
2023-01-04 09:10:03,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:03,196 INFO:     Epoch: 11
2023-01-04 09:10:04,753 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4028444270292918, 'Total loss': 0.4028444270292918} | train loss {'Reaction outcome loss': 0.45457007942626076, 'Total loss': 0.45457007942626076}
2023-01-04 09:10:04,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:04,754 INFO:     Epoch: 12
2023-01-04 09:10:06,308 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4002428521712621, 'Total loss': 0.4002428521712621} | train loss {'Reaction outcome loss': 0.4535691952944672, 'Total loss': 0.4535691952944672}
2023-01-04 09:10:06,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:06,308 INFO:     Epoch: 13
2023-01-04 09:10:07,689 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41852057675520576, 'Total loss': 0.41852057675520576} | train loss {'Reaction outcome loss': 0.44581497629193495, 'Total loss': 0.44581497629193495}
2023-01-04 09:10:07,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:07,689 INFO:     Epoch: 14
2023-01-04 09:10:09,241 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41563685337702433, 'Total loss': 0.41563685337702433} | train loss {'Reaction outcome loss': 0.4455087323040858, 'Total loss': 0.4455087323040858}
2023-01-04 09:10:09,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:09,242 INFO:     Epoch: 15
2023-01-04 09:10:10,791 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4354454517364502, 'Total loss': 0.4354454517364502} | train loss {'Reaction outcome loss': 0.43666789435992276, 'Total loss': 0.43666789435992276}
2023-01-04 09:10:10,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:10,791 INFO:     Epoch: 16
2023-01-04 09:10:12,342 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41311651170253755, 'Total loss': 0.41311651170253755} | train loss {'Reaction outcome loss': 0.43431009667633225, 'Total loss': 0.43431009667633225}
2023-01-04 09:10:12,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:12,343 INFO:     Epoch: 17
2023-01-04 09:10:13,887 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39277174870173137, 'Total loss': 0.39277174870173137} | train loss {'Reaction outcome loss': 0.4300166253734679, 'Total loss': 0.4300166253734679}
2023-01-04 09:10:13,887 INFO:     Found new best model at epoch 17
2023-01-04 09:10:13,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:13,887 INFO:     Epoch: 18
2023-01-04 09:10:15,430 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37940262953440346, 'Total loss': 0.37940262953440346} | train loss {'Reaction outcome loss': 0.4237233208370035, 'Total loss': 0.4237233208370035}
2023-01-04 09:10:15,430 INFO:     Found new best model at epoch 18
2023-01-04 09:10:15,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:15,431 INFO:     Epoch: 19
2023-01-04 09:10:16,837 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4039150714874268, 'Total loss': 0.4039150714874268} | train loss {'Reaction outcome loss': 0.4214452376222088, 'Total loss': 0.4214452376222088}
2023-01-04 09:10:16,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:16,839 INFO:     Epoch: 20
2023-01-04 09:10:18,367 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38554319242636365, 'Total loss': 0.38554319242636365} | train loss {'Reaction outcome loss': 0.4173199140677487, 'Total loss': 0.4173199140677487}
2023-01-04 09:10:18,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:18,367 INFO:     Epoch: 21
2023-01-04 09:10:19,918 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3908515860637029, 'Total loss': 0.3908515860637029} | train loss {'Reaction outcome loss': 0.41451787013207037, 'Total loss': 0.41451787013207037}
2023-01-04 09:10:19,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:19,918 INFO:     Epoch: 22
2023-01-04 09:10:21,474 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39152956008911133, 'Total loss': 0.39152956008911133} | train loss {'Reaction outcome loss': 0.40741967779659005, 'Total loss': 0.40741967779659005}
2023-01-04 09:10:21,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:21,474 INFO:     Epoch: 23
2023-01-04 09:10:23,007 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3642993410428365, 'Total loss': 0.3642993410428365} | train loss {'Reaction outcome loss': 0.40478938804381953, 'Total loss': 0.40478938804381953}
2023-01-04 09:10:23,008 INFO:     Found new best model at epoch 23
2023-01-04 09:10:23,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:23,009 INFO:     Epoch: 24
2023-01-04 09:10:24,568 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37820299367109933, 'Total loss': 0.37820299367109933} | train loss {'Reaction outcome loss': 0.3983786843553947, 'Total loss': 0.3983786843553947}
2023-01-04 09:10:24,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:24,568 INFO:     Epoch: 25
2023-01-04 09:10:25,977 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36440141797065734, 'Total loss': 0.36440141797065734} | train loss {'Reaction outcome loss': 0.39833708507192395, 'Total loss': 0.39833708507192395}
2023-01-04 09:10:25,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:25,977 INFO:     Epoch: 26
2023-01-04 09:10:27,537 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3434165775775909, 'Total loss': 0.3434165775775909} | train loss {'Reaction outcome loss': 0.3893260773080979, 'Total loss': 0.3893260773080979}
2023-01-04 09:10:27,538 INFO:     Found new best model at epoch 26
2023-01-04 09:10:27,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:27,538 INFO:     Epoch: 27
2023-01-04 09:10:29,091 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.36576664745807647, 'Total loss': 0.36576664745807647} | train loss {'Reaction outcome loss': 0.38818694172549423, 'Total loss': 0.38818694172549423}
2023-01-04 09:10:29,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:29,091 INFO:     Epoch: 28
2023-01-04 09:10:30,657 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.364215079943339, 'Total loss': 0.364215079943339} | train loss {'Reaction outcome loss': 0.38850850212204197, 'Total loss': 0.38850850212204197}
2023-01-04 09:10:30,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:30,657 INFO:     Epoch: 29
2023-01-04 09:10:32,222 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.345443602403005, 'Total loss': 0.345443602403005} | train loss {'Reaction outcome loss': 0.38370361233497186, 'Total loss': 0.38370361233497186}
2023-01-04 09:10:32,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:32,222 INFO:     Epoch: 30
2023-01-04 09:10:33,774 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3642530977725983, 'Total loss': 0.3642530977725983} | train loss {'Reaction outcome loss': 0.3756331410666887, 'Total loss': 0.3756331410666887}
2023-01-04 09:10:33,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:33,774 INFO:     Epoch: 31
2023-01-04 09:10:35,245 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.33640125493208567, 'Total loss': 0.33640125493208567} | train loss {'Reaction outcome loss': 0.37795722046799035, 'Total loss': 0.37795722046799035}
2023-01-04 09:10:35,246 INFO:     Found new best model at epoch 31
2023-01-04 09:10:35,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:35,246 INFO:     Epoch: 32
2023-01-04 09:10:36,795 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.34975903332233427, 'Total loss': 0.34975903332233427} | train loss {'Reaction outcome loss': 0.3699516679031135, 'Total loss': 0.3699516679031135}
2023-01-04 09:10:36,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:36,796 INFO:     Epoch: 33
2023-01-04 09:10:38,364 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.34303118288517, 'Total loss': 0.34303118288517} | train loss {'Reaction outcome loss': 0.36876877750793513, 'Total loss': 0.36876877750793513}
2023-01-04 09:10:38,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:38,364 INFO:     Epoch: 34
2023-01-04 09:10:39,922 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35024071534474693, 'Total loss': 0.35024071534474693} | train loss {'Reaction outcome loss': 0.36762680175856954, 'Total loss': 0.36762680175856954}
2023-01-04 09:10:39,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:39,923 INFO:     Epoch: 35
2023-01-04 09:10:41,481 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3462543532252312, 'Total loss': 0.3462543532252312} | train loss {'Reaction outcome loss': 0.36175791193207685, 'Total loss': 0.36175791193207685}
2023-01-04 09:10:41,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:41,481 INFO:     Epoch: 36
2023-01-04 09:10:42,958 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3418591598669688, 'Total loss': 0.3418591598669688} | train loss {'Reaction outcome loss': 0.35890323820992975, 'Total loss': 0.35890323820992975}
2023-01-04 09:10:42,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:42,959 INFO:     Epoch: 37
2023-01-04 09:10:44,462 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.32295774221420287, 'Total loss': 0.32295774221420287} | train loss {'Reaction outcome loss': 0.3507946212062218, 'Total loss': 0.3507946212062218}
2023-01-04 09:10:44,463 INFO:     Found new best model at epoch 37
2023-01-04 09:10:44,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:44,463 INFO:     Epoch: 38
2023-01-04 09:10:46,022 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3554730216662089, 'Total loss': 0.3554730216662089} | train loss {'Reaction outcome loss': 0.3501661551205346, 'Total loss': 0.3501661551205346}
2023-01-04 09:10:46,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:46,023 INFO:     Epoch: 39
2023-01-04 09:10:47,583 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.34388260344664257, 'Total loss': 0.34388260344664257} | train loss {'Reaction outcome loss': 0.3473029792798262, 'Total loss': 0.3473029792798262}
2023-01-04 09:10:47,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:47,583 INFO:     Epoch: 40
2023-01-04 09:10:49,143 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35661785304546356, 'Total loss': 0.35661785304546356} | train loss {'Reaction outcome loss': 0.34202863289600743, 'Total loss': 0.34202863289600743}
2023-01-04 09:10:49,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:49,144 INFO:     Epoch: 41
2023-01-04 09:10:50,717 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35233812729517616, 'Total loss': 0.35233812729517616} | train loss {'Reaction outcome loss': 0.34427038449658093, 'Total loss': 0.34427038449658093}
2023-01-04 09:10:50,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:50,718 INFO:     Epoch: 42
2023-01-04 09:10:52,167 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3205606132745743, 'Total loss': 0.3205606132745743} | train loss {'Reaction outcome loss': 0.3366391298218365, 'Total loss': 0.3366391298218365}
2023-01-04 09:10:52,168 INFO:     Found new best model at epoch 42
2023-01-04 09:10:52,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:52,169 INFO:     Epoch: 43
2023-01-04 09:10:53,740 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34614870746930443, 'Total loss': 0.34614870746930443} | train loss {'Reaction outcome loss': 0.33971358354400544, 'Total loss': 0.33971358354400544}
2023-01-04 09:10:53,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:53,740 INFO:     Epoch: 44
2023-01-04 09:10:55,324 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35496210952599844, 'Total loss': 0.35496210952599844} | train loss {'Reaction outcome loss': 0.33053805350060883, 'Total loss': 0.33053805350060883}
2023-01-04 09:10:55,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:55,325 INFO:     Epoch: 45
2023-01-04 09:10:56,903 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.33133180836836496, 'Total loss': 0.33133180836836496} | train loss {'Reaction outcome loss': 0.332807817054491, 'Total loss': 0.332807817054491}
2023-01-04 09:10:56,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:56,903 INFO:     Epoch: 46
2023-01-04 09:10:58,474 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.33074186046918236, 'Total loss': 0.33074186046918236} | train loss {'Reaction outcome loss': 0.3280094057104013, 'Total loss': 0.3280094057104013}
2023-01-04 09:10:58,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:10:58,475 INFO:     Epoch: 47
2023-01-04 09:11:00,056 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.33044081926345825, 'Total loss': 0.33044081926345825} | train loss {'Reaction outcome loss': 0.32271912405743214, 'Total loss': 0.32271912405743214}
2023-01-04 09:11:00,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:00,057 INFO:     Epoch: 48
2023-01-04 09:11:01,486 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3237607479095459, 'Total loss': 0.3237607479095459} | train loss {'Reaction outcome loss': 0.32226741814265286, 'Total loss': 0.32226741814265286}
2023-01-04 09:11:01,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:01,486 INFO:     Epoch: 49
2023-01-04 09:11:03,061 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3374835401773453, 'Total loss': 0.3374835401773453} | train loss {'Reaction outcome loss': 0.3218740275959029, 'Total loss': 0.3218740275959029}
2023-01-04 09:11:03,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:03,061 INFO:     Epoch: 50
2023-01-04 09:11:04,646 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33488864699999493, 'Total loss': 0.33488864699999493} | train loss {'Reaction outcome loss': 0.3200533809888102, 'Total loss': 0.3200533809888102}
2023-01-04 09:11:04,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:04,646 INFO:     Epoch: 51
2023-01-04 09:11:06,243 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.33730161786079405, 'Total loss': 0.33730161786079405} | train loss {'Reaction outcome loss': 0.3149166255917427, 'Total loss': 0.3149166255917427}
2023-01-04 09:11:06,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:06,243 INFO:     Epoch: 52
2023-01-04 09:11:07,827 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3424449682235718, 'Total loss': 0.3424449682235718} | train loss {'Reaction outcome loss': 0.3140131394195296, 'Total loss': 0.3140131394195296}
2023-01-04 09:11:07,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:07,828 INFO:     Epoch: 53
2023-01-04 09:11:09,406 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.354433806737264, 'Total loss': 0.354433806737264} | train loss {'Reaction outcome loss': 0.3128167819367708, 'Total loss': 0.3128167819367708}
2023-01-04 09:11:09,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:09,406 INFO:     Epoch: 54
2023-01-04 09:11:10,829 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.32808271845181786, 'Total loss': 0.32808271845181786} | train loss {'Reaction outcome loss': 0.31092502810332895, 'Total loss': 0.31092502810332895}
2023-01-04 09:11:10,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:10,833 INFO:     Epoch: 55
2023-01-04 09:11:12,413 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.33989768028259276, 'Total loss': 0.33989768028259276} | train loss {'Reaction outcome loss': 0.30715813088047245, 'Total loss': 0.30715813088047245}
2023-01-04 09:11:12,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:12,413 INFO:     Epoch: 56
2023-01-04 09:11:13,980 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.31957511603832245, 'Total loss': 0.31957511603832245} | train loss {'Reaction outcome loss': 0.30905542851690826, 'Total loss': 0.30905542851690826}
2023-01-04 09:11:13,981 INFO:     Found new best model at epoch 56
2023-01-04 09:11:13,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:13,981 INFO:     Epoch: 57
2023-01-04 09:11:15,557 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.31756885051727296, 'Total loss': 0.31756885051727296} | train loss {'Reaction outcome loss': 0.30510082979598185, 'Total loss': 0.30510082979598185}
2023-01-04 09:11:15,557 INFO:     Found new best model at epoch 57
2023-01-04 09:11:15,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:15,558 INFO:     Epoch: 58
2023-01-04 09:11:17,101 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3251273542642593, 'Total loss': 0.3251273542642593} | train loss {'Reaction outcome loss': 0.302873812996558, 'Total loss': 0.302873812996558}
2023-01-04 09:11:17,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:17,101 INFO:     Epoch: 59
2023-01-04 09:11:18,670 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3316713829835256, 'Total loss': 0.3316713829835256} | train loss {'Reaction outcome loss': 0.30481934411464817, 'Total loss': 0.30481934411464817}
2023-01-04 09:11:18,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:18,671 INFO:     Epoch: 60
2023-01-04 09:11:20,069 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3798859586318334, 'Total loss': 0.3798859586318334} | train loss {'Reaction outcome loss': 0.2996022728727247, 'Total loss': 0.2996022728727247}
2023-01-04 09:11:20,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:20,070 INFO:     Epoch: 61
2023-01-04 09:11:21,627 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3504226634899775, 'Total loss': 0.3504226634899775} | train loss {'Reaction outcome loss': 0.2998525029741717, 'Total loss': 0.2998525029741717}
2023-01-04 09:11:21,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:21,627 INFO:     Epoch: 62
2023-01-04 09:11:23,205 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3269587526718775, 'Total loss': 0.3269587526718775} | train loss {'Reaction outcome loss': 0.29402879410742844, 'Total loss': 0.29402879410742844}
2023-01-04 09:11:23,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:23,206 INFO:     Epoch: 63
2023-01-04 09:11:24,784 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3191165551543236, 'Total loss': 0.3191165551543236} | train loss {'Reaction outcome loss': 0.2976476348338336, 'Total loss': 0.2976476348338336}
2023-01-04 09:11:24,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:24,784 INFO:     Epoch: 64
2023-01-04 09:11:26,335 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.32458225389321643, 'Total loss': 0.32458225389321643} | train loss {'Reaction outcome loss': 0.29439913258500344, 'Total loss': 0.29439913258500344}
2023-01-04 09:11:26,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:26,336 INFO:     Epoch: 65
2023-01-04 09:11:27,892 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33738689323266347, 'Total loss': 0.33738689323266347} | train loss {'Reaction outcome loss': 0.29799573090824766, 'Total loss': 0.29799573090824766}
2023-01-04 09:11:27,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:27,892 INFO:     Epoch: 66
2023-01-04 09:11:29,324 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.331907194852829, 'Total loss': 0.331907194852829} | train loss {'Reaction outcome loss': 0.29185419858698425, 'Total loss': 0.29185419858698425}
2023-01-04 09:11:29,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:29,325 INFO:     Epoch: 67
2023-01-04 09:11:30,899 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34389703373114267, 'Total loss': 0.34389703373114267} | train loss {'Reaction outcome loss': 0.2869255435619041, 'Total loss': 0.2869255435619041}
2023-01-04 09:11:30,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:30,899 INFO:     Epoch: 68
2023-01-04 09:11:32,486 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3187452509999275, 'Total loss': 0.3187452509999275} | train loss {'Reaction outcome loss': 0.28848331443367214, 'Total loss': 0.28848331443367214}
2023-01-04 09:11:32,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:32,487 INFO:     Epoch: 69
2023-01-04 09:11:34,068 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3258065973718961, 'Total loss': 0.3258065973718961} | train loss {'Reaction outcome loss': 0.2881663413650363, 'Total loss': 0.2881663413650363}
2023-01-04 09:11:34,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:34,068 INFO:     Epoch: 70
2023-01-04 09:11:35,648 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.31374104966719946, 'Total loss': 0.31374104966719946} | train loss {'Reaction outcome loss': 0.2832440918270689, 'Total loss': 0.2832440918270689}
2023-01-04 09:11:35,648 INFO:     Found new best model at epoch 70
2023-01-04 09:11:35,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:35,649 INFO:     Epoch: 71
2023-01-04 09:11:37,231 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.33153098821640015, 'Total loss': 0.33153098821640015} | train loss {'Reaction outcome loss': 0.2832687880544767, 'Total loss': 0.2832687880544767}
2023-01-04 09:11:37,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:37,231 INFO:     Epoch: 72
2023-01-04 09:11:38,671 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.32925377289454144, 'Total loss': 0.32925377289454144} | train loss {'Reaction outcome loss': 0.2826470033041317, 'Total loss': 0.2826470033041317}
2023-01-04 09:11:38,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:38,672 INFO:     Epoch: 73
2023-01-04 09:11:40,257 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3515641838312149, 'Total loss': 0.3515641838312149} | train loss {'Reaction outcome loss': 0.280116039348671, 'Total loss': 0.280116039348671}
2023-01-04 09:11:40,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:40,257 INFO:     Epoch: 74
2023-01-04 09:11:41,846 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.33781533539295194, 'Total loss': 0.33781533539295194} | train loss {'Reaction outcome loss': 0.2779009168165444, 'Total loss': 0.2779009168165444}
2023-01-04 09:11:41,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:41,847 INFO:     Epoch: 75
2023-01-04 09:11:43,424 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3593714565038681, 'Total loss': 0.3593714565038681} | train loss {'Reaction outcome loss': 0.2791964417989672, 'Total loss': 0.2791964417989672}
2023-01-04 09:11:43,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:43,424 INFO:     Epoch: 76
2023-01-04 09:11:45,011 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3487124780813853, 'Total loss': 0.3487124780813853} | train loss {'Reaction outcome loss': 0.27532736067898084, 'Total loss': 0.27532736067898084}
2023-01-04 09:11:45,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:45,011 INFO:     Epoch: 77
2023-01-04 09:11:46,611 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3435478995243708, 'Total loss': 0.3435478995243708} | train loss {'Reaction outcome loss': 0.2758371480706617, 'Total loss': 0.2758371480706617}
2023-01-04 09:11:46,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:46,611 INFO:     Epoch: 78
2023-01-04 09:11:48,039 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3326167722543081, 'Total loss': 0.3326167722543081} | train loss {'Reaction outcome loss': 0.27787466548437617, 'Total loss': 0.27787466548437617}
2023-01-04 09:11:48,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:48,040 INFO:     Epoch: 79
2023-01-04 09:11:49,631 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34687096377213794, 'Total loss': 0.34687096377213794} | train loss {'Reaction outcome loss': 0.2748951473864761, 'Total loss': 0.2748951473864761}
2023-01-04 09:11:49,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:49,631 INFO:     Epoch: 80
2023-01-04 09:11:51,189 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35878630677858986, 'Total loss': 0.35878630677858986} | train loss {'Reaction outcome loss': 0.27558375057512824, 'Total loss': 0.27558375057512824}
2023-01-04 09:11:51,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:51,190 INFO:     Epoch: 81
2023-01-04 09:11:52,732 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3086238483587901, 'Total loss': 0.3086238483587901} | train loss {'Reaction outcome loss': 0.2736268919369165, 'Total loss': 0.2736268919369165}
2023-01-04 09:11:52,733 INFO:     Found new best model at epoch 81
2023-01-04 09:11:52,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:52,733 INFO:     Epoch: 82
2023-01-04 09:11:54,282 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3205904831488927, 'Total loss': 0.3205904831488927} | train loss {'Reaction outcome loss': 0.27314385429133464, 'Total loss': 0.27314385429133464}
2023-01-04 09:11:54,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:54,283 INFO:     Epoch: 83
2023-01-04 09:11:55,835 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.33232782582441966, 'Total loss': 0.33232782582441966} | train loss {'Reaction outcome loss': 0.2668735786837383, 'Total loss': 0.2668735786837383}
2023-01-04 09:11:55,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:55,835 INFO:     Epoch: 84
2023-01-04 09:11:57,303 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.330472590525945, 'Total loss': 0.330472590525945} | train loss {'Reaction outcome loss': 0.2714144439864768, 'Total loss': 0.2714144439864768}
2023-01-04 09:11:57,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:57,304 INFO:     Epoch: 85
2023-01-04 09:11:58,878 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3415137747923533, 'Total loss': 0.3415137747923533} | train loss {'Reaction outcome loss': 0.26637738532502286, 'Total loss': 0.26637738532502286}
2023-01-04 09:11:58,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:11:58,878 INFO:     Epoch: 86
2023-01-04 09:12:00,441 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3289951821168264, 'Total loss': 0.3289951821168264} | train loss {'Reaction outcome loss': 0.26949265221283386, 'Total loss': 0.26949265221283386}
2023-01-04 09:12:00,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:00,442 INFO:     Epoch: 87
2023-01-04 09:12:01,993 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3192132552464803, 'Total loss': 0.3192132552464803} | train loss {'Reaction outcome loss': 0.2649500216935238, 'Total loss': 0.2649500216935238}
2023-01-04 09:12:01,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:01,993 INFO:     Epoch: 88
2023-01-04 09:12:03,549 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36108063062032064, 'Total loss': 0.36108063062032064} | train loss {'Reaction outcome loss': 0.26690768249278524, 'Total loss': 0.26690768249278524}
2023-01-04 09:12:03,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:03,549 INFO:     Epoch: 89
2023-01-04 09:12:05,039 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3284146358569463, 'Total loss': 0.3284146358569463} | train loss {'Reaction outcome loss': 0.26356418313880037, 'Total loss': 0.26356418313880037}
2023-01-04 09:12:05,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:05,039 INFO:     Epoch: 90
2023-01-04 09:12:06,055 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.31836602576076983, 'Total loss': 0.31836602576076983} | train loss {'Reaction outcome loss': 0.2646911202175339, 'Total loss': 0.2646911202175339}
2023-01-04 09:12:06,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:06,056 INFO:     Epoch: 91
2023-01-04 09:12:07,075 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.32990632553895316, 'Total loss': 0.32990632553895316} | train loss {'Reaction outcome loss': 0.2617045854809728, 'Total loss': 0.2617045854809728}
2023-01-04 09:12:07,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:07,075 INFO:     Epoch: 92
2023-01-04 09:12:08,091 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3077122906843821, 'Total loss': 0.3077122906843821} | train loss {'Reaction outcome loss': 0.2622870923067531, 'Total loss': 0.2622870923067531}
2023-01-04 09:12:08,092 INFO:     Found new best model at epoch 92
2023-01-04 09:12:08,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:08,092 INFO:     Epoch: 93
2023-01-04 09:12:09,108 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.32946254312992096, 'Total loss': 0.32946254312992096} | train loss {'Reaction outcome loss': 0.25814423908608675, 'Total loss': 0.25814423908608675}
2023-01-04 09:12:09,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:09,108 INFO:     Epoch: 94
2023-01-04 09:12:10,552 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.32108978033065794, 'Total loss': 0.32108978033065794} | train loss {'Reaction outcome loss': 0.261015251346857, 'Total loss': 0.261015251346857}
2023-01-04 09:12:10,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:10,552 INFO:     Epoch: 95
2023-01-04 09:12:12,052 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.34388171633084613, 'Total loss': 0.34388171633084613} | train loss {'Reaction outcome loss': 0.2617708779327626, 'Total loss': 0.2617708779327626}
2023-01-04 09:12:12,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:12,052 INFO:     Epoch: 96
2023-01-04 09:12:13,570 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.319997505346934, 'Total loss': 0.319997505346934} | train loss {'Reaction outcome loss': 0.2574340549236449, 'Total loss': 0.2574340549236449}
2023-01-04 09:12:13,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:13,571 INFO:     Epoch: 97
2023-01-04 09:12:15,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3299799457192421, 'Total loss': 0.3299799457192421} | train loss {'Reaction outcome loss': 0.25360861828509906, 'Total loss': 0.25360861828509906}
2023-01-04 09:12:15,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:15,087 INFO:     Epoch: 98
2023-01-04 09:12:16,606 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.31883792678515116, 'Total loss': 0.31883792678515116} | train loss {'Reaction outcome loss': 0.2580764818746243, 'Total loss': 0.2580764818746243}
2023-01-04 09:12:16,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:16,606 INFO:     Epoch: 99
2023-01-04 09:12:18,121 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34458849132061004, 'Total loss': 0.34458849132061004} | train loss {'Reaction outcome loss': 0.2542364451164094, 'Total loss': 0.2542364451164094}
2023-01-04 09:12:18,122 INFO:     Best model found after epoch 93 of 100.
2023-01-04 09:12:18,122 INFO:   Done with stage: TRAINING
2023-01-04 09:12:18,122 INFO:   Starting stage: EVALUATION
2023-01-04 09:12:18,256 INFO:   Done with stage: EVALUATION
2023-01-04 09:12:18,256 INFO:   Leaving out SEQ value Fold_3
2023-01-04 09:12:18,269 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 09:12:18,269 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:12:18,917 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:12:18,917 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:12:18,986 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:12:18,986 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:12:18,986 INFO:     No hyperparam tuning for this model
2023-01-04 09:12:18,986 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:12:18,986 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:12:18,987 INFO:     None feature selector for col prot
2023-01-04 09:12:18,987 INFO:     None feature selector for col prot
2023-01-04 09:12:18,987 INFO:     None feature selector for col prot
2023-01-04 09:12:18,987 INFO:     None feature selector for col chem
2023-01-04 09:12:18,987 INFO:     None feature selector for col chem
2023-01-04 09:12:18,988 INFO:     None feature selector for col chem
2023-01-04 09:12:18,988 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:12:18,988 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:12:18,989 INFO:     Number of params in model 70111
2023-01-04 09:12:18,992 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:12:18,992 INFO:   Starting stage: TRAINING
2023-01-04 09:12:19,036 INFO:     Val loss before train {'Reaction outcome loss': 0.9926669359207153, 'Total loss': 0.9926669359207153}
2023-01-04 09:12:19,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:19,036 INFO:     Epoch: 0
2023-01-04 09:12:20,543 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8001752773920695, 'Total loss': 0.8001752773920695} | train loss {'Reaction outcome loss': 0.8442458078101441, 'Total loss': 0.8442458078101441}
2023-01-04 09:12:20,543 INFO:     Found new best model at epoch 0
2023-01-04 09:12:20,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:20,544 INFO:     Epoch: 1
2023-01-04 09:12:22,079 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6517085750897725, 'Total loss': 0.6517085750897725} | train loss {'Reaction outcome loss': 0.6848634783819918, 'Total loss': 0.6848634783819918}
2023-01-04 09:12:22,079 INFO:     Found new best model at epoch 1
2023-01-04 09:12:22,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:22,080 INFO:     Epoch: 2
2023-01-04 09:12:23,610 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5958582560221354, 'Total loss': 0.5958582560221354} | train loss {'Reaction outcome loss': 0.5870812694668334, 'Total loss': 0.5870812694668334}
2023-01-04 09:12:23,610 INFO:     Found new best model at epoch 2
2023-01-04 09:12:23,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:23,611 INFO:     Epoch: 3
2023-01-04 09:12:25,158 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5487363914648692, 'Total loss': 0.5487363914648692} | train loss {'Reaction outcome loss': 0.5412907967746476, 'Total loss': 0.5412907967746476}
2023-01-04 09:12:25,158 INFO:     Found new best model at epoch 3
2023-01-04 09:12:25,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:25,159 INFO:     Epoch: 4
2023-01-04 09:12:26,695 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5355281601349513, 'Total loss': 0.5355281601349513} | train loss {'Reaction outcome loss': 0.5168651738118776, 'Total loss': 0.5168651738118776}
2023-01-04 09:12:26,696 INFO:     Found new best model at epoch 4
2023-01-04 09:12:26,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:26,696 INFO:     Epoch: 5
2023-01-04 09:12:28,207 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5263436675071717, 'Total loss': 0.5263436675071717} | train loss {'Reaction outcome loss': 0.4960350941716533, 'Total loss': 0.4960350941716533}
2023-01-04 09:12:28,207 INFO:     Found new best model at epoch 5
2023-01-04 09:12:28,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:28,208 INFO:     Epoch: 6
2023-01-04 09:12:29,711 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5118915955225627, 'Total loss': 0.5118915955225627} | train loss {'Reaction outcome loss': 0.4869269864572274, 'Total loss': 0.4869269864572274}
2023-01-04 09:12:29,712 INFO:     Found new best model at epoch 6
2023-01-04 09:12:29,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:29,713 INFO:     Epoch: 7
2023-01-04 09:12:31,235 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5018427620331446, 'Total loss': 0.5018427620331446} | train loss {'Reaction outcome loss': 0.48118447919031637, 'Total loss': 0.48118447919031637}
2023-01-04 09:12:31,235 INFO:     Found new best model at epoch 7
2023-01-04 09:12:31,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:31,235 INFO:     Epoch: 8
2023-01-04 09:12:32,762 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49191333254178365, 'Total loss': 0.49191333254178365} | train loss {'Reaction outcome loss': 0.4687310224706, 'Total loss': 0.4687310224706}
2023-01-04 09:12:32,762 INFO:     Found new best model at epoch 8
2023-01-04 09:12:32,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:32,763 INFO:     Epoch: 9
2023-01-04 09:12:34,287 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4947203735510508, 'Total loss': 0.4947203735510508} | train loss {'Reaction outcome loss': 0.46460240566250166, 'Total loss': 0.46460240566250166}
2023-01-04 09:12:34,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:34,287 INFO:     Epoch: 10
2023-01-04 09:12:35,822 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49959285855293273, 'Total loss': 0.49959285855293273} | train loss {'Reaction outcome loss': 0.4579733728598326, 'Total loss': 0.4579733728598326}
2023-01-04 09:12:35,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:35,823 INFO:     Epoch: 11
2023-01-04 09:12:37,321 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5096303999423981, 'Total loss': 0.5096303999423981} | train loss {'Reaction outcome loss': 0.4528173950565604, 'Total loss': 0.4528173950565604}
2023-01-04 09:12:37,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:37,321 INFO:     Epoch: 12
2023-01-04 09:12:38,818 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48251571456591286, 'Total loss': 0.48251571456591286} | train loss {'Reaction outcome loss': 0.4475849020284611, 'Total loss': 0.4475849020284611}
2023-01-04 09:12:38,818 INFO:     Found new best model at epoch 12
2023-01-04 09:12:38,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:38,819 INFO:     Epoch: 13
2023-01-04 09:12:40,363 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48460761507352196, 'Total loss': 0.48460761507352196} | train loss {'Reaction outcome loss': 0.4380972779495812, 'Total loss': 0.4380972779495812}
2023-01-04 09:12:40,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:40,363 INFO:     Epoch: 14
2023-01-04 09:12:41,909 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46091368794441223, 'Total loss': 0.46091368794441223} | train loss {'Reaction outcome loss': 0.43716377112673316, 'Total loss': 0.43716377112673316}
2023-01-04 09:12:41,909 INFO:     Found new best model at epoch 14
2023-01-04 09:12:41,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:41,910 INFO:     Epoch: 15
2023-01-04 09:12:43,495 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47124850352605185, 'Total loss': 0.47124850352605185} | train loss {'Reaction outcome loss': 0.43155303564700453, 'Total loss': 0.43155303564700453}
2023-01-04 09:12:43,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:43,496 INFO:     Epoch: 16
2023-01-04 09:12:45,062 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46842866043249765, 'Total loss': 0.46842866043249765} | train loss {'Reaction outcome loss': 0.4273277346467797, 'Total loss': 0.4273277346467797}
2023-01-04 09:12:45,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:45,062 INFO:     Epoch: 17
2023-01-04 09:12:46,593 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4494714121023814, 'Total loss': 0.4494714121023814} | train loss {'Reaction outcome loss': 0.4224882035792529, 'Total loss': 0.4224882035792529}
2023-01-04 09:12:46,593 INFO:     Found new best model at epoch 17
2023-01-04 09:12:46,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:46,594 INFO:     Epoch: 18
2023-01-04 09:12:48,112 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47057883739471434, 'Total loss': 0.47057883739471434} | train loss {'Reaction outcome loss': 0.4174506385084037, 'Total loss': 0.4174506385084037}
2023-01-04 09:12:48,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:48,113 INFO:     Epoch: 19
2023-01-04 09:12:49,666 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46365621586640676, 'Total loss': 0.46365621586640676} | train loss {'Reaction outcome loss': 0.41555483096139334, 'Total loss': 0.41555483096139334}
2023-01-04 09:12:49,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:49,666 INFO:     Epoch: 20
2023-01-04 09:12:51,223 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4868074357509613, 'Total loss': 0.4868074357509613} | train loss {'Reaction outcome loss': 0.41566708730363144, 'Total loss': 0.41566708730363144}
2023-01-04 09:12:51,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:51,223 INFO:     Epoch: 21
2023-01-04 09:12:52,753 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4524394035339355, 'Total loss': 0.4524394035339355} | train loss {'Reaction outcome loss': 0.4080367317020675, 'Total loss': 0.4080367317020675}
2023-01-04 09:12:52,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:52,753 INFO:     Epoch: 22
2023-01-04 09:12:54,289 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44198749512434005, 'Total loss': 0.44198749512434005} | train loss {'Reaction outcome loss': 0.4040345996345356, 'Total loss': 0.4040345996345356}
2023-01-04 09:12:54,289 INFO:     Found new best model at epoch 22
2023-01-04 09:12:54,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:54,290 INFO:     Epoch: 23
2023-01-04 09:12:55,786 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47771177589893343, 'Total loss': 0.47771177589893343} | train loss {'Reaction outcome loss': 0.40312333224893926, 'Total loss': 0.40312333224893926}
2023-01-04 09:12:55,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:55,786 INFO:     Epoch: 24
2023-01-04 09:12:57,282 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44398508469263714, 'Total loss': 0.44398508469263714} | train loss {'Reaction outcome loss': 0.39893808232231454, 'Total loss': 0.39893808232231454}
2023-01-04 09:12:57,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:57,282 INFO:     Epoch: 25
2023-01-04 09:12:58,818 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4479305326938629, 'Total loss': 0.4479305326938629} | train loss {'Reaction outcome loss': 0.3960538376190942, 'Total loss': 0.3960538376190942}
2023-01-04 09:12:58,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:12:58,818 INFO:     Epoch: 26
2023-01-04 09:13:00,358 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4659450550874074, 'Total loss': 0.4659450550874074} | train loss {'Reaction outcome loss': 0.39212245273066093, 'Total loss': 0.39212245273066093}
2023-01-04 09:13:00,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:00,358 INFO:     Epoch: 27
2023-01-04 09:13:01,897 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43461327652136483, 'Total loss': 0.43461327652136483} | train loss {'Reaction outcome loss': 0.3840756297602758, 'Total loss': 0.3840756297602758}
2023-01-04 09:13:01,899 INFO:     Found new best model at epoch 27
2023-01-04 09:13:01,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:01,900 INFO:     Epoch: 28
2023-01-04 09:13:03,457 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4578501323858897, 'Total loss': 0.4578501323858897} | train loss {'Reaction outcome loss': 0.3865586085852249, 'Total loss': 0.3865586085852249}
2023-01-04 09:13:03,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:03,457 INFO:     Epoch: 29
2023-01-04 09:13:04,973 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44788124163945514, 'Total loss': 0.44788124163945514} | train loss {'Reaction outcome loss': 0.3846009408325066, 'Total loss': 0.3846009408325066}
2023-01-04 09:13:04,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:04,973 INFO:     Epoch: 30
2023-01-04 09:13:06,490 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4465177863836288, 'Total loss': 0.4465177863836288} | train loss {'Reaction outcome loss': 0.3819665746701943, 'Total loss': 0.3819665746701943}
2023-01-04 09:13:06,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:06,490 INFO:     Epoch: 31
2023-01-04 09:13:08,041 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.426867421468099, 'Total loss': 0.426867421468099} | train loss {'Reaction outcome loss': 0.37731122757707325, 'Total loss': 0.37731122757707325}
2023-01-04 09:13:08,042 INFO:     Found new best model at epoch 31
2023-01-04 09:13:08,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:08,043 INFO:     Epoch: 32
2023-01-04 09:13:09,585 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43918651541074116, 'Total loss': 0.43918651541074116} | train loss {'Reaction outcome loss': 0.3699333547672509, 'Total loss': 0.3699333547672509}
2023-01-04 09:13:09,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:09,586 INFO:     Epoch: 33
2023-01-04 09:13:11,125 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4391938388347626, 'Total loss': 0.4391938388347626} | train loss {'Reaction outcome loss': 0.3699339706000391, 'Total loss': 0.3699339706000391}
2023-01-04 09:13:11,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:11,126 INFO:     Epoch: 34
2023-01-04 09:13:12,646 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4420783092578252, 'Total loss': 0.4420783092578252} | train loss {'Reaction outcome loss': 0.36377402624258626, 'Total loss': 0.36377402624258626}
2023-01-04 09:13:12,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:12,647 INFO:     Epoch: 35
2023-01-04 09:13:14,166 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4149003009001414, 'Total loss': 0.4149003009001414} | train loss {'Reaction outcome loss': 0.36574302589172847, 'Total loss': 0.36574302589172847}
2023-01-04 09:13:14,166 INFO:     Found new best model at epoch 35
2023-01-04 09:13:14,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:14,167 INFO:     Epoch: 36
2023-01-04 09:13:15,668 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43155273149410883, 'Total loss': 0.43155273149410883} | train loss {'Reaction outcome loss': 0.36154764459806155, 'Total loss': 0.36154764459806155}
2023-01-04 09:13:15,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:15,668 INFO:     Epoch: 37
2023-01-04 09:13:17,201 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46019277969996136, 'Total loss': 0.46019277969996136} | train loss {'Reaction outcome loss': 0.3573818204057959, 'Total loss': 0.3573818204057959}
2023-01-04 09:13:17,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:17,201 INFO:     Epoch: 38
2023-01-04 09:13:18,757 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44497468769550325, 'Total loss': 0.44497468769550325} | train loss {'Reaction outcome loss': 0.35890991663758137, 'Total loss': 0.35890991663758137}
2023-01-04 09:13:18,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:18,758 INFO:     Epoch: 39
2023-01-04 09:13:20,331 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4448715955018997, 'Total loss': 0.4448715955018997} | train loss {'Reaction outcome loss': 0.35221260166539375, 'Total loss': 0.35221260166539375}
2023-01-04 09:13:20,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:20,332 INFO:     Epoch: 40
2023-01-04 09:13:21,853 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.420948068300883, 'Total loss': 0.420948068300883} | train loss {'Reaction outcome loss': 0.3507068382896783, 'Total loss': 0.3507068382896783}
2023-01-04 09:13:21,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:21,853 INFO:     Epoch: 41
2023-01-04 09:13:23,406 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43044766585032146, 'Total loss': 0.43044766585032146} | train loss {'Reaction outcome loss': 0.34811804470889296, 'Total loss': 0.34811804470889296}
2023-01-04 09:13:23,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:23,407 INFO:     Epoch: 42
2023-01-04 09:13:24,909 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4520914047956467, 'Total loss': 0.4520914047956467} | train loss {'Reaction outcome loss': 0.3459956764274246, 'Total loss': 0.3459956764274246}
2023-01-04 09:13:24,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:24,909 INFO:     Epoch: 43
2023-01-04 09:13:26,462 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43204792638619743, 'Total loss': 0.43204792638619743} | train loss {'Reaction outcome loss': 0.3459361488675023, 'Total loss': 0.3459361488675023}
2023-01-04 09:13:26,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:26,462 INFO:     Epoch: 44
2023-01-04 09:13:28,017 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43449425796667734, 'Total loss': 0.43449425796667734} | train loss {'Reaction outcome loss': 0.34217087302234145, 'Total loss': 0.34217087302234145}
2023-01-04 09:13:28,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:28,017 INFO:     Epoch: 45
2023-01-04 09:13:29,561 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42629928489526114, 'Total loss': 0.42629928489526114} | train loss {'Reaction outcome loss': 0.33787098711172303, 'Total loss': 0.33787098711172303}
2023-01-04 09:13:29,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:29,561 INFO:     Epoch: 46
2023-01-04 09:13:31,093 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.413880189259847, 'Total loss': 0.413880189259847} | train loss {'Reaction outcome loss': 0.3388996264818824, 'Total loss': 0.3388996264818824}
2023-01-04 09:13:31,094 INFO:     Found new best model at epoch 46
2023-01-04 09:13:31,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:31,094 INFO:     Epoch: 47
2023-01-04 09:13:32,641 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4370746781428655, 'Total loss': 0.4370746781428655} | train loss {'Reaction outcome loss': 0.3382721740766104, 'Total loss': 0.3382721740766104}
2023-01-04 09:13:32,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:32,642 INFO:     Epoch: 48
2023-01-04 09:13:34,156 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40474485953648887, 'Total loss': 0.40474485953648887} | train loss {'Reaction outcome loss': 0.3263840785884595, 'Total loss': 0.3263840785884595}
2023-01-04 09:13:34,156 INFO:     Found new best model at epoch 48
2023-01-04 09:13:34,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:34,157 INFO:     Epoch: 49
2023-01-04 09:13:35,700 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41875295837720233, 'Total loss': 0.41875295837720233} | train loss {'Reaction outcome loss': 0.32478359267934337, 'Total loss': 0.32478359267934337}
2023-01-04 09:13:35,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:35,700 INFO:     Epoch: 50
2023-01-04 09:13:37,232 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4602975328763326, 'Total loss': 0.4602975328763326} | train loss {'Reaction outcome loss': 0.3229034609628684, 'Total loss': 0.3229034609628684}
2023-01-04 09:13:37,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:37,233 INFO:     Epoch: 51
2023-01-04 09:13:38,785 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42403524816036225, 'Total loss': 0.42403524816036225} | train loss {'Reaction outcome loss': 0.32766102379931633, 'Total loss': 0.32766102379931633}
2023-01-04 09:13:38,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:38,785 INFO:     Epoch: 52
2023-01-04 09:13:40,325 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44219138026237487, 'Total loss': 0.44219138026237487} | train loss {'Reaction outcome loss': 0.32022742917522407, 'Total loss': 0.32022742917522407}
2023-01-04 09:13:40,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:40,325 INFO:     Epoch: 53
2023-01-04 09:13:41,859 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4292366221547127, 'Total loss': 0.4292366221547127} | train loss {'Reaction outcome loss': 0.3211328110797501, 'Total loss': 0.3211328110797501}
2023-01-04 09:13:41,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:41,859 INFO:     Epoch: 54
2023-01-04 09:13:43,342 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4097652902205785, 'Total loss': 0.4097652902205785} | train loss {'Reaction outcome loss': 0.3164616091784103, 'Total loss': 0.3164616091784103}
2023-01-04 09:13:43,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:43,343 INFO:     Epoch: 55
2023-01-04 09:13:44,885 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4235495001077652, 'Total loss': 0.4235495001077652} | train loss {'Reaction outcome loss': 0.31670208196172783, 'Total loss': 0.31670208196172783}
2023-01-04 09:13:44,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:44,886 INFO:     Epoch: 56
2023-01-04 09:13:46,418 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4344232420126597, 'Total loss': 0.4344232420126597} | train loss {'Reaction outcome loss': 0.3143678147877966, 'Total loss': 0.3143678147877966}
2023-01-04 09:13:46,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:46,418 INFO:     Epoch: 57
2023-01-04 09:13:47,966 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40494072834650674, 'Total loss': 0.40494072834650674} | train loss {'Reaction outcome loss': 0.30994272968926273, 'Total loss': 0.30994272968926273}
2023-01-04 09:13:47,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:47,966 INFO:     Epoch: 58
2023-01-04 09:13:49,481 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.409719588359197, 'Total loss': 0.409719588359197} | train loss {'Reaction outcome loss': 0.3140388663325991, 'Total loss': 0.3140388663325991}
2023-01-04 09:13:49,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:49,482 INFO:     Epoch: 59
2023-01-04 09:13:51,051 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3887678121527036, 'Total loss': 0.3887678121527036} | train loss {'Reaction outcome loss': 0.3080663797837911, 'Total loss': 0.3080663797837911}
2023-01-04 09:13:51,051 INFO:     Found new best model at epoch 59
2023-01-04 09:13:51,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:51,052 INFO:     Epoch: 60
2023-01-04 09:13:52,561 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41055354475975037, 'Total loss': 0.41055354475975037} | train loss {'Reaction outcome loss': 0.3067201847967866, 'Total loss': 0.3067201847967866}
2023-01-04 09:13:52,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:52,561 INFO:     Epoch: 61
2023-01-04 09:13:54,123 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42087842226028443, 'Total loss': 0.42087842226028443} | train loss {'Reaction outcome loss': 0.3020974514466939, 'Total loss': 0.3020974514466939}
2023-01-04 09:13:54,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:54,123 INFO:     Epoch: 62
2023-01-04 09:13:55,684 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43305238982041677, 'Total loss': 0.43305238982041677} | train loss {'Reaction outcome loss': 0.2976811077486683, 'Total loss': 0.2976811077486683}
2023-01-04 09:13:55,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:55,685 INFO:     Epoch: 63
2023-01-04 09:13:57,252 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4257635792096456, 'Total loss': 0.4257635792096456} | train loss {'Reaction outcome loss': 0.308472746075728, 'Total loss': 0.308472746075728}
2023-01-04 09:13:57,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:57,253 INFO:     Epoch: 64
2023-01-04 09:13:58,761 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4314742585023244, 'Total loss': 0.4314742585023244} | train loss {'Reaction outcome loss': 0.30214506866676466, 'Total loss': 0.30214506866676466}
2023-01-04 09:13:58,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:13:58,761 INFO:     Epoch: 65
2023-01-04 09:14:00,296 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41789794663588203, 'Total loss': 0.41789794663588203} | train loss {'Reaction outcome loss': 0.29553198192145796, 'Total loss': 0.29553198192145796}
2023-01-04 09:14:00,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:00,296 INFO:     Epoch: 66
2023-01-04 09:14:01,844 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4197037100791931, 'Total loss': 0.4197037100791931} | train loss {'Reaction outcome loss': 0.3030915536504962, 'Total loss': 0.3030915536504962}
2023-01-04 09:14:01,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:01,844 INFO:     Epoch: 67
2023-01-04 09:14:03,387 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4392166376113892, 'Total loss': 0.4392166376113892} | train loss {'Reaction outcome loss': 0.2930677529158337, 'Total loss': 0.2930677529158337}
2023-01-04 09:14:03,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:03,387 INFO:     Epoch: 68
2023-01-04 09:14:04,930 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41789478063583374, 'Total loss': 0.41789478063583374} | train loss {'Reaction outcome loss': 0.2917422955726093, 'Total loss': 0.2917422955726093}
2023-01-04 09:14:04,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:04,930 INFO:     Epoch: 69
2023-01-04 09:14:06,452 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4094183286031087, 'Total loss': 0.4094183286031087} | train loss {'Reaction outcome loss': 0.29601484130481226, 'Total loss': 0.29601484130481226}
2023-01-04 09:14:06,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:06,452 INFO:     Epoch: 70
2023-01-04 09:14:07,965 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43043791353702543, 'Total loss': 0.43043791353702543} | train loss {'Reaction outcome loss': 0.28923684578975695, 'Total loss': 0.28923684578975695}
2023-01-04 09:14:07,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:07,965 INFO:     Epoch: 71
2023-01-04 09:14:09,475 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43646222551663716, 'Total loss': 0.43646222551663716} | train loss {'Reaction outcome loss': 0.2893331072706006, 'Total loss': 0.2893331072706006}
2023-01-04 09:14:09,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:09,475 INFO:     Epoch: 72
2023-01-04 09:14:10,999 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41226739684740704, 'Total loss': 0.41226739684740704} | train loss {'Reaction outcome loss': 0.2920802746875546, 'Total loss': 0.2920802746875546}
2023-01-04 09:14:10,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:10,999 INFO:     Epoch: 73
2023-01-04 09:14:12,539 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41575673818588255, 'Total loss': 0.41575673818588255} | train loss {'Reaction outcome loss': 0.28904443640848654, 'Total loss': 0.28904443640848654}
2023-01-04 09:14:12,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:12,540 INFO:     Epoch: 74
2023-01-04 09:14:14,091 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43899510900179545, 'Total loss': 0.43899510900179545} | train loss {'Reaction outcome loss': 0.2896289137420637, 'Total loss': 0.2896289137420637}
2023-01-04 09:14:14,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:14,091 INFO:     Epoch: 75
2023-01-04 09:14:15,622 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4125418245792389, 'Total loss': 0.4125418245792389} | train loss {'Reaction outcome loss': 0.2856929701763195, 'Total loss': 0.2856929701763195}
2023-01-04 09:14:15,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:15,623 INFO:     Epoch: 76
2023-01-04 09:14:17,107 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44635587533315024, 'Total loss': 0.44635587533315024} | train loss {'Reaction outcome loss': 0.28157375898850134, 'Total loss': 0.28157375898850134}
2023-01-04 09:14:17,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:17,107 INFO:     Epoch: 77
2023-01-04 09:14:18,585 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42196919322013854, 'Total loss': 0.42196919322013854} | train loss {'Reaction outcome loss': 0.28514696629001546, 'Total loss': 0.28514696629001546}
2023-01-04 09:14:18,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:18,586 INFO:     Epoch: 78
2023-01-04 09:14:20,136 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4195484399795532, 'Total loss': 0.4195484399795532} | train loss {'Reaction outcome loss': 0.28376291351113125, 'Total loss': 0.28376291351113125}
2023-01-04 09:14:20,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:20,136 INFO:     Epoch: 79
2023-01-04 09:14:21,673 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4289748817682266, 'Total loss': 0.4289748817682266} | train loss {'Reaction outcome loss': 0.27938510822098117, 'Total loss': 0.27938510822098117}
2023-01-04 09:14:21,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:21,673 INFO:     Epoch: 80
2023-01-04 09:14:23,211 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4084542473157247, 'Total loss': 0.4084542473157247} | train loss {'Reaction outcome loss': 0.2739547120591441, 'Total loss': 0.2739547120591441}
2023-01-04 09:14:23,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:23,212 INFO:     Epoch: 81
2023-01-04 09:14:24,766 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41370967229207356, 'Total loss': 0.41370967229207356} | train loss {'Reaction outcome loss': 0.27744650278554295, 'Total loss': 0.27744650278554295}
2023-01-04 09:14:24,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:24,766 INFO:     Epoch: 82
2023-01-04 09:14:26,274 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41615978082021077, 'Total loss': 0.41615978082021077} | train loss {'Reaction outcome loss': 0.2753115584289198, 'Total loss': 0.2753115584289198}
2023-01-04 09:14:26,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:26,274 INFO:     Epoch: 83
2023-01-04 09:14:27,786 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39928970535596214, 'Total loss': 0.39928970535596214} | train loss {'Reaction outcome loss': 0.2782767176655404, 'Total loss': 0.2782767176655404}
2023-01-04 09:14:27,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:27,786 INFO:     Epoch: 84
2023-01-04 09:14:29,328 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41018284956614176, 'Total loss': 0.41018284956614176} | train loss {'Reaction outcome loss': 0.27972949187070023, 'Total loss': 0.27972949187070023}
2023-01-04 09:14:29,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:29,328 INFO:     Epoch: 85
2023-01-04 09:14:30,889 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39955286582310995, 'Total loss': 0.39955286582310995} | train loss {'Reaction outcome loss': 0.27382204987299746, 'Total loss': 0.27382204987299746}
2023-01-04 09:14:30,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:30,890 INFO:     Epoch: 86
2023-01-04 09:14:32,444 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42315502762794494, 'Total loss': 0.42315502762794494} | train loss {'Reaction outcome loss': 0.27816943117441273, 'Total loss': 0.27816943117441273}
2023-01-04 09:14:32,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:32,444 INFO:     Epoch: 87
2023-01-04 09:14:34,003 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3925245523452759, 'Total loss': 0.3925245523452759} | train loss {'Reaction outcome loss': 0.2742059419661651, 'Total loss': 0.2742059419661651}
2023-01-04 09:14:34,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:34,003 INFO:     Epoch: 88
2023-01-04 09:14:35,509 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40039249261220294, 'Total loss': 0.40039249261220294} | train loss {'Reaction outcome loss': 0.268149412690829, 'Total loss': 0.268149412690829}
2023-01-04 09:14:35,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:35,509 INFO:     Epoch: 89
2023-01-04 09:14:37,017 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40531946818033854, 'Total loss': 0.40531946818033854} | train loss {'Reaction outcome loss': 0.27006660625611467, 'Total loss': 0.27006660625611467}
2023-01-04 09:14:37,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:37,017 INFO:     Epoch: 90
2023-01-04 09:14:38,562 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41310039212306343, 'Total loss': 0.41310039212306343} | train loss {'Reaction outcome loss': 0.2690352700896316, 'Total loss': 0.2690352700896316}
2023-01-04 09:14:38,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:38,562 INFO:     Epoch: 91
2023-01-04 09:14:40,107 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40912958880265554, 'Total loss': 0.40912958880265554} | train loss {'Reaction outcome loss': 0.26644771236366843, 'Total loss': 0.26644771236366843}
2023-01-04 09:14:40,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:40,107 INFO:     Epoch: 92
2023-01-04 09:14:41,670 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41737818519274394, 'Total loss': 0.41737818519274394} | train loss {'Reaction outcome loss': 0.2698230521391818, 'Total loss': 0.2698230521391818}
2023-01-04 09:14:41,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:41,670 INFO:     Epoch: 93
2023-01-04 09:14:43,214 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3894199915230274, 'Total loss': 0.3894199915230274} | train loss {'Reaction outcome loss': 0.27008448580737077, 'Total loss': 0.27008448580737077}
2023-01-04 09:14:43,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:43,216 INFO:     Epoch: 94
2023-01-04 09:14:44,729 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42458601395289103, 'Total loss': 0.42458601395289103} | train loss {'Reaction outcome loss': 0.2677476861865529, 'Total loss': 0.2677476861865529}
2023-01-04 09:14:44,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:44,730 INFO:     Epoch: 95
2023-01-04 09:14:46,256 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4153529077768326, 'Total loss': 0.4153529077768326} | train loss {'Reaction outcome loss': 0.26346329456338513, 'Total loss': 0.26346329456338513}
2023-01-04 09:14:46,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:46,257 INFO:     Epoch: 96
2023-01-04 09:14:47,807 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40866434276103974, 'Total loss': 0.40866434276103974} | train loss {'Reaction outcome loss': 0.26801378588318386, 'Total loss': 0.26801378588318386}
2023-01-04 09:14:47,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:47,807 INFO:     Epoch: 97
2023-01-04 09:14:49,353 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4377543081839879, 'Total loss': 0.4377543081839879} | train loss {'Reaction outcome loss': 0.26038439798376933, 'Total loss': 0.26038439798376933}
2023-01-04 09:14:49,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:49,354 INFO:     Epoch: 98
2023-01-04 09:14:50,906 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4039476285378138, 'Total loss': 0.4039476285378138} | train loss {'Reaction outcome loss': 0.26419123183021614, 'Total loss': 0.26419123183021614}
2023-01-04 09:14:50,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:50,907 INFO:     Epoch: 99
2023-01-04 09:14:52,458 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42540381054083504, 'Total loss': 0.42540381054083504} | train loss {'Reaction outcome loss': 0.2637736206744617, 'Total loss': 0.2637736206744617}
2023-01-04 09:14:52,458 INFO:     Best model found after epoch 60 of 100.
2023-01-04 09:14:52,458 INFO:   Done with stage: TRAINING
2023-01-04 09:14:52,458 INFO:   Starting stage: EVALUATION
2023-01-04 09:14:52,598 INFO:   Done with stage: EVALUATION
2023-01-04 09:14:52,598 INFO:   Leaving out SEQ value Fold_4
2023-01-04 09:14:52,611 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:14:52,611 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:14:53,254 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:14:53,254 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:14:53,323 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:14:53,323 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:14:53,323 INFO:     No hyperparam tuning for this model
2023-01-04 09:14:53,323 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:14:53,323 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:14:53,324 INFO:     None feature selector for col prot
2023-01-04 09:14:53,324 INFO:     None feature selector for col prot
2023-01-04 09:14:53,324 INFO:     None feature selector for col prot
2023-01-04 09:14:53,324 INFO:     None feature selector for col chem
2023-01-04 09:14:53,325 INFO:     None feature selector for col chem
2023-01-04 09:14:53,325 INFO:     None feature selector for col chem
2023-01-04 09:14:53,325 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:14:53,325 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:14:53,326 INFO:     Number of params in model 70111
2023-01-04 09:14:53,329 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:14:53,329 INFO:   Starting stage: TRAINING
2023-01-04 09:14:53,372 INFO:     Val loss before train {'Reaction outcome loss': 1.07738010485967, 'Total loss': 1.07738010485967}
2023-01-04 09:14:53,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:53,372 INFO:     Epoch: 0
2023-01-04 09:14:54,888 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.783750609556834, 'Total loss': 0.783750609556834} | train loss {'Reaction outcome loss': 0.8369198985991703, 'Total loss': 0.8369198985991703}
2023-01-04 09:14:54,888 INFO:     Found new best model at epoch 0
2023-01-04 09:14:54,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:54,889 INFO:     Epoch: 1
2023-01-04 09:14:56,449 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6213739454746247, 'Total loss': 0.6213739454746247} | train loss {'Reaction outcome loss': 0.6722001736794693, 'Total loss': 0.6722001736794693}
2023-01-04 09:14:56,449 INFO:     Found new best model at epoch 1
2023-01-04 09:14:56,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:56,450 INFO:     Epoch: 2
2023-01-04 09:14:58,014 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5675779104232788, 'Total loss': 0.5675779104232788} | train loss {'Reaction outcome loss': 0.5705732841734721, 'Total loss': 0.5705732841734721}
2023-01-04 09:14:58,014 INFO:     Found new best model at epoch 2
2023-01-04 09:14:58,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:58,015 INFO:     Epoch: 3
2023-01-04 09:14:59,582 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5396259129047394, 'Total loss': 0.5396259129047394} | train loss {'Reaction outcome loss': 0.5283144955401835, 'Total loss': 0.5283144955401835}
2023-01-04 09:14:59,582 INFO:     Found new best model at epoch 3
2023-01-04 09:14:59,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:14:59,583 INFO:     Epoch: 4
2023-01-04 09:15:01,156 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5136477291584015, 'Total loss': 0.5136477291584015} | train loss {'Reaction outcome loss': 0.5172956711140232, 'Total loss': 0.5172956711140232}
2023-01-04 09:15:01,156 INFO:     Found new best model at epoch 4
2023-01-04 09:15:01,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:01,157 INFO:     Epoch: 5
2023-01-04 09:15:02,719 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5108625193436941, 'Total loss': 0.5108625193436941} | train loss {'Reaction outcome loss': 0.5070551114453785, 'Total loss': 0.5070551114453785}
2023-01-04 09:15:02,720 INFO:     Found new best model at epoch 5
2023-01-04 09:15:02,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:02,721 INFO:     Epoch: 6
2023-01-04 09:15:04,254 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49405916333198546, 'Total loss': 0.49405916333198546} | train loss {'Reaction outcome loss': 0.48870602628506976, 'Total loss': 0.48870602628506976}
2023-01-04 09:15:04,254 INFO:     Found new best model at epoch 6
2023-01-04 09:15:04,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:04,255 INFO:     Epoch: 7
2023-01-04 09:15:05,829 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5071757892767589, 'Total loss': 0.5071757892767589} | train loss {'Reaction outcome loss': 0.48189361415047577, 'Total loss': 0.48189361415047577}
2023-01-04 09:15:05,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:05,829 INFO:     Epoch: 8
2023-01-04 09:15:07,375 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4848473370075226, 'Total loss': 0.4848473370075226} | train loss {'Reaction outcome loss': 0.5036918364222283, 'Total loss': 0.5036918364222283}
2023-01-04 09:15:07,375 INFO:     Found new best model at epoch 8
2023-01-04 09:15:07,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:07,376 INFO:     Epoch: 9
2023-01-04 09:15:08,953 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4656338612238566, 'Total loss': 0.4656338612238566} | train loss {'Reaction outcome loss': 0.46180201694369316, 'Total loss': 0.46180201694369316}
2023-01-04 09:15:08,953 INFO:     Found new best model at epoch 9
2023-01-04 09:15:08,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:08,954 INFO:     Epoch: 10
2023-01-04 09:15:10,496 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4723682324091593, 'Total loss': 0.4723682324091593} | train loss {'Reaction outcome loss': 0.4590953363888506, 'Total loss': 0.4590953363888506}
2023-01-04 09:15:10,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:10,503 INFO:     Epoch: 11
2023-01-04 09:15:12,081 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.500152838230133, 'Total loss': 0.500152838230133} | train loss {'Reaction outcome loss': 0.4579592919693349, 'Total loss': 0.4579592919693349}
2023-01-04 09:15:12,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:12,081 INFO:     Epoch: 12
2023-01-04 09:15:13,610 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4667809267838796, 'Total loss': 0.4667809267838796} | train loss {'Reaction outcome loss': 0.44726611212051165, 'Total loss': 0.44726611212051165}
2023-01-04 09:15:13,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:13,611 INFO:     Epoch: 13
2023-01-04 09:15:15,174 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4832306663195292, 'Total loss': 0.4832306663195292} | train loss {'Reaction outcome loss': 0.4425365024556716, 'Total loss': 0.4425365024556716}
2023-01-04 09:15:15,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:15,174 INFO:     Epoch: 14
2023-01-04 09:15:16,726 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4663350760936737, 'Total loss': 0.4663350760936737} | train loss {'Reaction outcome loss': 0.4392679153496157, 'Total loss': 0.4392679153496157}
2023-01-04 09:15:16,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:16,726 INFO:     Epoch: 15
2023-01-04 09:15:18,295 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4723626752694448, 'Total loss': 0.4723626752694448} | train loss {'Reaction outcome loss': 0.43468935004826903, 'Total loss': 0.43468935004826903}
2023-01-04 09:15:18,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:18,295 INFO:     Epoch: 16
2023-01-04 09:15:19,825 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4648610711097717, 'Total loss': 0.4648610711097717} | train loss {'Reaction outcome loss': 0.4289865183873453, 'Total loss': 0.4289865183873453}
2023-01-04 09:15:19,826 INFO:     Found new best model at epoch 16
2023-01-04 09:15:19,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:19,827 INFO:     Epoch: 17
2023-01-04 09:15:21,392 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4542426427205404, 'Total loss': 0.4542426427205404} | train loss {'Reaction outcome loss': 0.4400332678324279, 'Total loss': 0.4400332678324279}
2023-01-04 09:15:21,392 INFO:     Found new best model at epoch 17
2023-01-04 09:15:21,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:21,393 INFO:     Epoch: 18
2023-01-04 09:15:22,930 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46044621666272484, 'Total loss': 0.46044621666272484} | train loss {'Reaction outcome loss': 0.42378377811848256, 'Total loss': 0.42378377811848256}
2023-01-04 09:15:22,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:22,930 INFO:     Epoch: 19
2023-01-04 09:15:24,509 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4429615120093028, 'Total loss': 0.4429615120093028} | train loss {'Reaction outcome loss': 0.4164218524775883, 'Total loss': 0.4164218524775883}
2023-01-04 09:15:24,509 INFO:     Found new best model at epoch 19
2023-01-04 09:15:24,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:24,510 INFO:     Epoch: 20
2023-01-04 09:15:26,064 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.425753116607666, 'Total loss': 0.425753116607666} | train loss {'Reaction outcome loss': 0.41338640393392334, 'Total loss': 0.41338640393392334}
2023-01-04 09:15:26,065 INFO:     Found new best model at epoch 20
2023-01-04 09:15:26,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:26,065 INFO:     Epoch: 21
2023-01-04 09:15:27,639 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46475691397984825, 'Total loss': 0.46475691397984825} | train loss {'Reaction outcome loss': 0.41200616975328413, 'Total loss': 0.41200616975328413}
2023-01-04 09:15:27,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:27,639 INFO:     Epoch: 22
2023-01-04 09:15:29,142 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44045220911502836, 'Total loss': 0.44045220911502836} | train loss {'Reaction outcome loss': 0.406478590618792, 'Total loss': 0.406478590618792}
2023-01-04 09:15:29,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:29,142 INFO:     Epoch: 23
2023-01-04 09:15:30,683 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42177567481994627, 'Total loss': 0.42177567481994627} | train loss {'Reaction outcome loss': 0.4066817698109409, 'Total loss': 0.4066817698109409}
2023-01-04 09:15:30,683 INFO:     Found new best model at epoch 23
2023-01-04 09:15:30,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:30,684 INFO:     Epoch: 24
2023-01-04 09:15:32,183 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41714997092882794, 'Total loss': 0.41714997092882794} | train loss {'Reaction outcome loss': 0.40752528350286954, 'Total loss': 0.40752528350286954}
2023-01-04 09:15:32,184 INFO:     Found new best model at epoch 24
2023-01-04 09:15:32,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:32,185 INFO:     Epoch: 25
2023-01-04 09:15:33,721 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41290893256664274, 'Total loss': 0.41290893256664274} | train loss {'Reaction outcome loss': 0.39558069349985325, 'Total loss': 0.39558069349985325}
2023-01-04 09:15:33,721 INFO:     Found new best model at epoch 25
2023-01-04 09:15:33,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:33,721 INFO:     Epoch: 26
2023-01-04 09:15:35,259 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42861823936303456, 'Total loss': 0.42861823936303456} | train loss {'Reaction outcome loss': 0.40066055877917056, 'Total loss': 0.40066055877917056}
2023-01-04 09:15:35,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:35,259 INFO:     Epoch: 27
2023-01-04 09:15:36,829 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4348793029785156, 'Total loss': 0.4348793029785156} | train loss {'Reaction outcome loss': 0.4200959459581561, 'Total loss': 0.4200959459581561}
2023-01-04 09:15:36,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:36,829 INFO:     Epoch: 28
2023-01-04 09:15:38,340 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4178990006446838, 'Total loss': 0.4178990006446838} | train loss {'Reaction outcome loss': 0.38835315205901483, 'Total loss': 0.38835315205901483}
2023-01-04 09:15:38,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:38,341 INFO:     Epoch: 29
2023-01-04 09:15:39,882 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43878724575042727, 'Total loss': 0.43878724575042727} | train loss {'Reaction outcome loss': 0.3863231391187055, 'Total loss': 0.3863231391187055}
2023-01-04 09:15:39,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:39,882 INFO:     Epoch: 30
2023-01-04 09:15:41,412 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42577887574831647, 'Total loss': 0.42577887574831647} | train loss {'Reaction outcome loss': 0.3819757681264056, 'Total loss': 0.3819757681264056}
2023-01-04 09:15:41,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:41,413 INFO:     Epoch: 31
2023-01-04 09:15:42,975 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40294554432233176, 'Total loss': 0.40294554432233176} | train loss {'Reaction outcome loss': 0.37962433502105053, 'Total loss': 0.37962433502105053}
2023-01-04 09:15:42,975 INFO:     Found new best model at epoch 31
2023-01-04 09:15:42,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:42,976 INFO:     Epoch: 32
2023-01-04 09:15:44,531 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41031850477059684, 'Total loss': 0.41031850477059684} | train loss {'Reaction outcome loss': 0.38971165654020035, 'Total loss': 0.38971165654020035}
2023-01-04 09:15:44,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:44,532 INFO:     Epoch: 33
2023-01-04 09:15:46,093 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3883603105942408, 'Total loss': 0.3883603105942408} | train loss {'Reaction outcome loss': 0.41084836666350777, 'Total loss': 0.41084836666350777}
2023-01-04 09:15:46,093 INFO:     Found new best model at epoch 33
2023-01-04 09:15:46,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:46,094 INFO:     Epoch: 34
2023-01-04 09:15:47,625 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40038152535756427, 'Total loss': 0.40038152535756427} | train loss {'Reaction outcome loss': 0.386718056330869, 'Total loss': 0.386718056330869}
2023-01-04 09:15:47,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:47,625 INFO:     Epoch: 35
2023-01-04 09:15:49,172 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41924955348173776, 'Total loss': 0.41924955348173776} | train loss {'Reaction outcome loss': 0.3685045534132413, 'Total loss': 0.3685045534132413}
2023-01-04 09:15:49,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:49,173 INFO:     Epoch: 36
2023-01-04 09:15:50,804 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3879308640956879, 'Total loss': 0.3879308640956879} | train loss {'Reaction outcome loss': 0.3616282814486033, 'Total loss': 0.3616282814486033}
2023-01-04 09:15:50,805 INFO:     Found new best model at epoch 36
2023-01-04 09:15:50,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:50,806 INFO:     Epoch: 37
2023-01-04 09:15:52,435 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40199234783649446, 'Total loss': 0.40199234783649446} | train loss {'Reaction outcome loss': 0.3616415582735604, 'Total loss': 0.3616415582735604}
2023-01-04 09:15:52,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:52,435 INFO:     Epoch: 38
2023-01-04 09:15:54,068 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40089109241962434, 'Total loss': 0.40089109241962434} | train loss {'Reaction outcome loss': 0.3588049691575377, 'Total loss': 0.3588049691575377}
2023-01-04 09:15:54,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:54,068 INFO:     Epoch: 39
2023-01-04 09:15:55,697 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.407956929008166, 'Total loss': 0.407956929008166} | train loss {'Reaction outcome loss': 0.3718674104471785, 'Total loss': 0.3718674104471785}
2023-01-04 09:15:55,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:55,698 INFO:     Epoch: 40
2023-01-04 09:15:57,264 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3813682744900386, 'Total loss': 0.3813682744900386} | train loss {'Reaction outcome loss': 0.3551276350440078, 'Total loss': 0.3551276350440078}
2023-01-04 09:15:57,264 INFO:     Found new best model at epoch 40
2023-01-04 09:15:57,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:57,265 INFO:     Epoch: 41
2023-01-04 09:15:58,840 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3950510064760844, 'Total loss': 0.3950510064760844} | train loss {'Reaction outcome loss': 0.3499009143117186, 'Total loss': 0.3499009143117186}
2023-01-04 09:15:58,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:15:58,840 INFO:     Epoch: 42
2023-01-04 09:16:00,476 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39364360173543295, 'Total loss': 0.39364360173543295} | train loss {'Reaction outcome loss': 0.35910304969149653, 'Total loss': 0.35910304969149653}
2023-01-04 09:16:00,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:00,476 INFO:     Epoch: 43
2023-01-04 09:16:02,105 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.386106472214063, 'Total loss': 0.386106472214063} | train loss {'Reaction outcome loss': 0.36716822610385175, 'Total loss': 0.36716822610385175}
2023-01-04 09:16:02,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:02,105 INFO:     Epoch: 44
2023-01-04 09:16:03,721 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41305178701877593, 'Total loss': 0.41305178701877593} | train loss {'Reaction outcome loss': 0.3744817245481671, 'Total loss': 0.3744817245481671}
2023-01-04 09:16:03,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:03,722 INFO:     Epoch: 45
2023-01-04 09:16:05,298 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.408099036415418, 'Total loss': 0.408099036415418} | train loss {'Reaction outcome loss': 0.38144780341046525, 'Total loss': 0.38144780341046525}
2023-01-04 09:16:05,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:05,298 INFO:     Epoch: 46
2023-01-04 09:16:06,932 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39278860092163087, 'Total loss': 0.39278860092163087} | train loss {'Reaction outcome loss': 0.3457163406562978, 'Total loss': 0.3457163406562978}
2023-01-04 09:16:06,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:06,932 INFO:     Epoch: 47
2023-01-04 09:16:08,508 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3990479499101639, 'Total loss': 0.3990479499101639} | train loss {'Reaction outcome loss': 0.34594125559121586, 'Total loss': 0.34594125559121586}
2023-01-04 09:16:08,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:08,508 INFO:     Epoch: 48
2023-01-04 09:16:10,139 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3911473363637924, 'Total loss': 0.3911473363637924} | train loss {'Reaction outcome loss': 0.338793160798757, 'Total loss': 0.338793160798757}
2023-01-04 09:16:10,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:10,139 INFO:     Epoch: 49
2023-01-04 09:16:11,767 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4187862624724706, 'Total loss': 0.4187862624724706} | train loss {'Reaction outcome loss': 0.33330864026219637, 'Total loss': 0.33330864026219637}
2023-01-04 09:16:11,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:11,768 INFO:     Epoch: 50
2023-01-04 09:16:13,395 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42442480425039925, 'Total loss': 0.42442480425039925} | train loss {'Reaction outcome loss': 0.3324942814712378, 'Total loss': 0.3324942814712378}
2023-01-04 09:16:13,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:13,395 INFO:     Epoch: 51
2023-01-04 09:16:14,976 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3758741190036138, 'Total loss': 0.3758741190036138} | train loss {'Reaction outcome loss': 0.3301093068945667, 'Total loss': 0.3301093068945667}
2023-01-04 09:16:14,977 INFO:     Found new best model at epoch 51
2023-01-04 09:16:14,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:14,978 INFO:     Epoch: 52
2023-01-04 09:16:16,577 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4066580057144165, 'Total loss': 0.4066580057144165} | train loss {'Reaction outcome loss': 0.3522719649355049, 'Total loss': 0.3522719649355049}
2023-01-04 09:16:16,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:16,577 INFO:     Epoch: 53
2023-01-04 09:16:18,202 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3643920083840688, 'Total loss': 0.3643920083840688} | train loss {'Reaction outcome loss': 0.35300851657613774, 'Total loss': 0.35300851657613774}
2023-01-04 09:16:18,202 INFO:     Found new best model at epoch 53
2023-01-04 09:16:18,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:18,203 INFO:     Epoch: 54
2023-01-04 09:16:19,829 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39783400495847066, 'Total loss': 0.39783400495847066} | train loss {'Reaction outcome loss': 0.32438895454717986, 'Total loss': 0.32438895454717986}
2023-01-04 09:16:19,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:19,829 INFO:     Epoch: 55
2023-01-04 09:16:21,449 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4140960395336151, 'Total loss': 0.4140960395336151} | train loss {'Reaction outcome loss': 0.3229245324112961, 'Total loss': 0.3229245324112961}
2023-01-04 09:16:21,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:21,450 INFO:     Epoch: 56
2023-01-04 09:16:23,083 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39466094772020976, 'Total loss': 0.39466094772020976} | train loss {'Reaction outcome loss': 0.320444253217315, 'Total loss': 0.320444253217315}
2023-01-04 09:16:23,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:23,083 INFO:     Epoch: 57
2023-01-04 09:16:24,658 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38900430748860043, 'Total loss': 0.38900430748860043} | train loss {'Reaction outcome loss': 0.32028921067282773, 'Total loss': 0.32028921067282773}
2023-01-04 09:16:24,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:24,658 INFO:     Epoch: 58
2023-01-04 09:16:26,204 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36971023480097454, 'Total loss': 0.36971023480097454} | train loss {'Reaction outcome loss': 0.32270835010996857, 'Total loss': 0.32270835010996857}
2023-01-04 09:16:26,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:26,205 INFO:     Epoch: 59
2023-01-04 09:16:27,758 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3689328610897064, 'Total loss': 0.3689328610897064} | train loss {'Reaction outcome loss': 0.31243531556822784, 'Total loss': 0.31243531556822784}
2023-01-04 09:16:27,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:27,758 INFO:     Epoch: 60
2023-01-04 09:16:29,332 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36372400671243665, 'Total loss': 0.36372400671243665} | train loss {'Reaction outcome loss': 0.30970126748687343, 'Total loss': 0.30970126748687343}
2023-01-04 09:16:29,332 INFO:     Found new best model at epoch 60
2023-01-04 09:16:29,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:29,333 INFO:     Epoch: 61
2023-01-04 09:16:30,909 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3673974951108297, 'Total loss': 0.3673974951108297} | train loss {'Reaction outcome loss': 0.3101182267469678, 'Total loss': 0.3101182267469678}
2023-01-04 09:16:30,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:30,909 INFO:     Epoch: 62
2023-01-04 09:16:32,465 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.396936422586441, 'Total loss': 0.396936422586441} | train loss {'Reaction outcome loss': 0.3102924392045732, 'Total loss': 0.3102924392045732}
2023-01-04 09:16:32,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:32,465 INFO:     Epoch: 63
2023-01-04 09:16:34,027 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3653822859128316, 'Total loss': 0.3653822859128316} | train loss {'Reaction outcome loss': 0.30809507940801373, 'Total loss': 0.30809507940801373}
2023-01-04 09:16:34,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:34,028 INFO:     Epoch: 64
2023-01-04 09:16:35,568 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3919350932041804, 'Total loss': 0.3919350932041804} | train loss {'Reaction outcome loss': 0.3086292280543906, 'Total loss': 0.3086292280543906}
2023-01-04 09:16:35,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:35,568 INFO:     Epoch: 65
2023-01-04 09:16:37,141 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36318489611148835, 'Total loss': 0.36318489611148835} | train loss {'Reaction outcome loss': 0.3033141436711615, 'Total loss': 0.3033141436711615}
2023-01-04 09:16:37,142 INFO:     Found new best model at epoch 65
2023-01-04 09:16:37,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:37,142 INFO:     Epoch: 66
2023-01-04 09:16:38,703 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3863222340742747, 'Total loss': 0.3863222340742747} | train loss {'Reaction outcome loss': 0.29941673708125943, 'Total loss': 0.29941673708125943}
2023-01-04 09:16:38,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:38,704 INFO:     Epoch: 67
2023-01-04 09:16:40,286 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40033363600571953, 'Total loss': 0.40033363600571953} | train loss {'Reaction outcome loss': 0.30430355707210477, 'Total loss': 0.30430355707210477}
2023-01-04 09:16:40,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:40,287 INFO:     Epoch: 68
2023-01-04 09:16:41,811 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3827969421943029, 'Total loss': 0.3827969421943029} | train loss {'Reaction outcome loss': 0.32917442595931207, 'Total loss': 0.32917442595931207}
2023-01-04 09:16:41,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:41,811 INFO:     Epoch: 69
2023-01-04 09:16:43,383 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3750389109055201, 'Total loss': 0.3750389109055201} | train loss {'Reaction outcome loss': 0.297175230507307, 'Total loss': 0.297175230507307}
2023-01-04 09:16:43,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:43,384 INFO:     Epoch: 70
2023-01-04 09:16:44,916 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38583176136016845, 'Total loss': 0.38583176136016845} | train loss {'Reaction outcome loss': 0.29701391334874905, 'Total loss': 0.29701391334874905}
2023-01-04 09:16:44,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:44,916 INFO:     Epoch: 71
2023-01-04 09:16:46,477 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3925667454799016, 'Total loss': 0.3925667454799016} | train loss {'Reaction outcome loss': 0.30551352808117005, 'Total loss': 0.30551352808117005}
2023-01-04 09:16:46,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:46,477 INFO:     Epoch: 72
2023-01-04 09:16:48,042 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37212307353814444, 'Total loss': 0.37212307353814444} | train loss {'Reaction outcome loss': 0.3174203846585073, 'Total loss': 0.3174203846585073}
2023-01-04 09:16:48,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:48,043 INFO:     Epoch: 73
2023-01-04 09:16:49,613 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3739603022734324, 'Total loss': 0.3739603022734324} | train loss {'Reaction outcome loss': 0.29449201954285736, 'Total loss': 0.29449201954285736}
2023-01-04 09:16:49,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:49,613 INFO:     Epoch: 74
2023-01-04 09:16:51,139 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38387742439905803, 'Total loss': 0.38387742439905803} | train loss {'Reaction outcome loss': 0.30683560783918307, 'Total loss': 0.30683560783918307}
2023-01-04 09:16:51,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:51,140 INFO:     Epoch: 75
2023-01-04 09:16:52,722 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3867294316490491, 'Total loss': 0.3867294316490491} | train loss {'Reaction outcome loss': 0.2953827907263801, 'Total loss': 0.2953827907263801}
2023-01-04 09:16:52,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:52,722 INFO:     Epoch: 76
2023-01-04 09:16:54,257 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.455411555369695, 'Total loss': 0.455411555369695} | train loss {'Reaction outcome loss': 0.32581816384217877, 'Total loss': 0.32581816384217877}
2023-01-04 09:16:54,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:54,257 INFO:     Epoch: 77
2023-01-04 09:16:55,825 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3859839032093684, 'Total loss': 0.3859839032093684} | train loss {'Reaction outcome loss': 0.3294007470426352, 'Total loss': 0.3294007470426352}
2023-01-04 09:16:55,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:55,825 INFO:     Epoch: 78
2023-01-04 09:16:57,397 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3928571194410324, 'Total loss': 0.3928571194410324} | train loss {'Reaction outcome loss': 0.3001118668058104, 'Total loss': 0.3001118668058104}
2023-01-04 09:16:57,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:57,398 INFO:     Epoch: 79
2023-01-04 09:16:58,963 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39020594755808513, 'Total loss': 0.39020594755808513} | train loss {'Reaction outcome loss': 0.2905120269158784, 'Total loss': 0.2905120269158784}
2023-01-04 09:16:58,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:16:58,963 INFO:     Epoch: 80
2023-01-04 09:17:00,485 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4000258266925812, 'Total loss': 0.4000258266925812} | train loss {'Reaction outcome loss': 0.28940761799289694, 'Total loss': 0.28940761799289694}
2023-01-04 09:17:00,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:00,485 INFO:     Epoch: 81
2023-01-04 09:17:02,019 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37280719776948296, 'Total loss': 0.37280719776948296} | train loss {'Reaction outcome loss': 0.29551179135096783, 'Total loss': 0.29551179135096783}
2023-01-04 09:17:02,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:02,020 INFO:     Epoch: 82
2023-01-04 09:17:03,558 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35951876441637676, 'Total loss': 0.35951876441637676} | train loss {'Reaction outcome loss': 0.2876236234805074, 'Total loss': 0.2876236234805074}
2023-01-04 09:17:03,558 INFO:     Found new best model at epoch 82
2023-01-04 09:17:03,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:03,559 INFO:     Epoch: 83
2023-01-04 09:17:05,127 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37291385531425475, 'Total loss': 0.37291385531425475} | train loss {'Reaction outcome loss': 0.2910460334231544, 'Total loss': 0.2910460334231544}
2023-01-04 09:17:05,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:05,127 INFO:     Epoch: 84
2023-01-04 09:17:06,672 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.403794805208842, 'Total loss': 0.403794805208842} | train loss {'Reaction outcome loss': 0.27882914879001625, 'Total loss': 0.27882914879001625}
2023-01-04 09:17:06,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:06,673 INFO:     Epoch: 85
2023-01-04 09:17:08,236 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38001777132352194, 'Total loss': 0.38001777132352194} | train loss {'Reaction outcome loss': 0.2834473402248662, 'Total loss': 0.2834473402248662}
2023-01-04 09:17:08,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:08,236 INFO:     Epoch: 86
2023-01-04 09:17:09,775 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3691182143986225, 'Total loss': 0.3691182143986225} | train loss {'Reaction outcome loss': 0.2778247808902592, 'Total loss': 0.2778247808902592}
2023-01-04 09:17:09,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:09,776 INFO:     Epoch: 87
2023-01-04 09:17:11,320 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3699243684609731, 'Total loss': 0.3699243684609731} | train loss {'Reaction outcome loss': 0.2762920108988233, 'Total loss': 0.2762920108988233}
2023-01-04 09:17:11,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:11,320 INFO:     Epoch: 88
2023-01-04 09:17:12,862 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3587464908758799, 'Total loss': 0.3587464908758799} | train loss {'Reaction outcome loss': 0.2780275153315864, 'Total loss': 0.2780275153315864}
2023-01-04 09:17:12,862 INFO:     Found new best model at epoch 88
2023-01-04 09:17:12,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:12,862 INFO:     Epoch: 89
2023-01-04 09:17:14,416 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36979658206303917, 'Total loss': 0.36979658206303917} | train loss {'Reaction outcome loss': 0.2739711688305049, 'Total loss': 0.2739711688305049}
2023-01-04 09:17:14,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:14,416 INFO:     Epoch: 90
2023-01-04 09:17:15,961 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40106245627005893, 'Total loss': 0.40106245627005893} | train loss {'Reaction outcome loss': 0.27897396189687046, 'Total loss': 0.27897396189687046}
2023-01-04 09:17:15,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:15,961 INFO:     Epoch: 91
2023-01-04 09:17:17,510 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3507218261559804, 'Total loss': 0.3507218261559804} | train loss {'Reaction outcome loss': 0.2858528498981141, 'Total loss': 0.2858528498981141}
2023-01-04 09:17:17,510 INFO:     Found new best model at epoch 91
2023-01-04 09:17:17,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:17,511 INFO:     Epoch: 92
2023-01-04 09:17:19,044 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4019736776749293, 'Total loss': 0.4019736776749293} | train loss {'Reaction outcome loss': 0.2749087261782615, 'Total loss': 0.2749087261782615}
2023-01-04 09:17:19,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:19,044 INFO:     Epoch: 93
2023-01-04 09:17:20,578 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37349702219168346, 'Total loss': 0.37349702219168346} | train loss {'Reaction outcome loss': 0.27200279655971826, 'Total loss': 0.27200279655971826}
2023-01-04 09:17:20,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:20,578 INFO:     Epoch: 94
2023-01-04 09:17:22,134 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35945980151494344, 'Total loss': 0.35945980151494344} | train loss {'Reaction outcome loss': 0.2710060937393607, 'Total loss': 0.2710060937393607}
2023-01-04 09:17:22,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:22,136 INFO:     Epoch: 95
2023-01-04 09:17:23,688 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40164056420326233, 'Total loss': 0.40164056420326233} | train loss {'Reaction outcome loss': 0.27253646919152874, 'Total loss': 0.27253646919152874}
2023-01-04 09:17:23,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:23,688 INFO:     Epoch: 96
2023-01-04 09:17:25,240 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3950427790482839, 'Total loss': 0.3950427790482839} | train loss {'Reaction outcome loss': 0.28300604128963786, 'Total loss': 0.28300604128963786}
2023-01-04 09:17:25,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:25,240 INFO:     Epoch: 97
2023-01-04 09:17:26,793 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.384203980366389, 'Total loss': 0.384203980366389} | train loss {'Reaction outcome loss': 0.2686639484228985, 'Total loss': 0.2686639484228985}
2023-01-04 09:17:26,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:26,794 INFO:     Epoch: 98
2023-01-04 09:17:28,334 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37452700138092043, 'Total loss': 0.37452700138092043} | train loss {'Reaction outcome loss': 0.2661082296989912, 'Total loss': 0.2661082296989912}
2023-01-04 09:17:28,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:28,335 INFO:     Epoch: 99
2023-01-04 09:17:29,857 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38892181515693663, 'Total loss': 0.38892181515693663} | train loss {'Reaction outcome loss': 0.26572763868540095, 'Total loss': 0.26572763868540095}
2023-01-04 09:17:29,857 INFO:     Best model found after epoch 92 of 100.
2023-01-04 09:17:29,857 INFO:   Done with stage: TRAINING
2023-01-04 09:17:29,857 INFO:   Starting stage: EVALUATION
2023-01-04 09:17:29,986 INFO:   Done with stage: EVALUATION
2023-01-04 09:17:29,986 INFO:   Leaving out SEQ value Fold_5
2023-01-04 09:17:29,999 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:17:29,999 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:17:30,639 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:17:30,639 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:17:30,707 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:17:30,707 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:17:30,708 INFO:     No hyperparam tuning for this model
2023-01-04 09:17:30,708 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:17:30,708 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:17:30,708 INFO:     None feature selector for col prot
2023-01-04 09:17:30,708 INFO:     None feature selector for col prot
2023-01-04 09:17:30,709 INFO:     None feature selector for col prot
2023-01-04 09:17:30,709 INFO:     None feature selector for col chem
2023-01-04 09:17:30,709 INFO:     None feature selector for col chem
2023-01-04 09:17:30,709 INFO:     None feature selector for col chem
2023-01-04 09:17:30,709 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:17:30,709 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:17:30,710 INFO:     Number of params in model 70111
2023-01-04 09:17:30,714 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:17:30,714 INFO:   Starting stage: TRAINING
2023-01-04 09:17:30,756 INFO:     Val loss before train {'Reaction outcome loss': 1.0288869500160218, 'Total loss': 1.0288869500160218}
2023-01-04 09:17:30,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:30,756 INFO:     Epoch: 0
2023-01-04 09:17:32,333 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7429005821545919, 'Total loss': 0.7429005821545919} | train loss {'Reaction outcome loss': 0.8355983088629834, 'Total loss': 0.8355983088629834}
2023-01-04 09:17:32,333 INFO:     Found new best model at epoch 0
2023-01-04 09:17:32,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:32,333 INFO:     Epoch: 1
2023-01-04 09:17:33,872 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6109491149584453, 'Total loss': 0.6109491149584453} | train loss {'Reaction outcome loss': 0.6830423062910205, 'Total loss': 0.6830423062910205}
2023-01-04 09:17:33,872 INFO:     Found new best model at epoch 1
2023-01-04 09:17:33,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:33,872 INFO:     Epoch: 2
2023-01-04 09:17:35,436 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5092889805634816, 'Total loss': 0.5092889805634816} | train loss {'Reaction outcome loss': 0.6079112180117248, 'Total loss': 0.6079112180117248}
2023-01-04 09:17:35,436 INFO:     Found new best model at epoch 2
2023-01-04 09:17:35,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:35,437 INFO:     Epoch: 3
2023-01-04 09:17:36,961 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4893697579701742, 'Total loss': 0.4893697579701742} | train loss {'Reaction outcome loss': 0.5511562458401464, 'Total loss': 0.5511562458401464}
2023-01-04 09:17:36,961 INFO:     Found new best model at epoch 3
2023-01-04 09:17:36,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:36,962 INFO:     Epoch: 4
2023-01-04 09:17:38,533 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45868831872940063, 'Total loss': 0.45868831872940063} | train loss {'Reaction outcome loss': 0.5225026914951109, 'Total loss': 0.5225026914951109}
2023-01-04 09:17:38,533 INFO:     Found new best model at epoch 4
2023-01-04 09:17:38,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:38,534 INFO:     Epoch: 5
2023-01-04 09:17:40,154 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47290127476056415, 'Total loss': 0.47290127476056415} | train loss {'Reaction outcome loss': 0.5066607808692134, 'Total loss': 0.5066607808692134}
2023-01-04 09:17:40,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:40,154 INFO:     Epoch: 6
2023-01-04 09:17:41,770 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4519574701786041, 'Total loss': 0.4519574701786041} | train loss {'Reaction outcome loss': 0.49350478536398673, 'Total loss': 0.49350478536398673}
2023-01-04 09:17:41,771 INFO:     Found new best model at epoch 6
2023-01-04 09:17:41,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:41,772 INFO:     Epoch: 7
2023-01-04 09:17:43,371 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44519776701927183, 'Total loss': 0.44519776701927183} | train loss {'Reaction outcome loss': 0.4970625501827917, 'Total loss': 0.4970625501827917}
2023-01-04 09:17:43,371 INFO:     Found new best model at epoch 7
2023-01-04 09:17:43,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:43,372 INFO:     Epoch: 8
2023-01-04 09:17:44,960 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4330280303955078, 'Total loss': 0.4330280303955078} | train loss {'Reaction outcome loss': 0.5019154176655887, 'Total loss': 0.5019154176655887}
2023-01-04 09:17:44,960 INFO:     Found new best model at epoch 8
2023-01-04 09:17:44,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:44,961 INFO:     Epoch: 9
2023-01-04 09:17:46,531 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41850192546844484, 'Total loss': 0.41850192546844484} | train loss {'Reaction outcome loss': 0.47179645208128984, 'Total loss': 0.47179645208128984}
2023-01-04 09:17:46,531 INFO:     Found new best model at epoch 9
2023-01-04 09:17:46,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:46,532 INFO:     Epoch: 10
2023-01-04 09:17:48,058 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41623171269893644, 'Total loss': 0.41623171269893644} | train loss {'Reaction outcome loss': 0.4874033623145542, 'Total loss': 0.4874033623145542}
2023-01-04 09:17:48,058 INFO:     Found new best model at epoch 10
2023-01-04 09:17:48,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:48,058 INFO:     Epoch: 11
2023-01-04 09:17:49,617 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42631566723187764, 'Total loss': 0.42631566723187764} | train loss {'Reaction outcome loss': 0.4620376851905704, 'Total loss': 0.4620376851905704}
2023-01-04 09:17:49,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:49,617 INFO:     Epoch: 12
2023-01-04 09:17:51,184 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41850695610046384, 'Total loss': 0.41850695610046384} | train loss {'Reaction outcome loss': 0.455344636959152, 'Total loss': 0.455344636959152}
2023-01-04 09:17:51,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:51,185 INFO:     Epoch: 13
2023-01-04 09:17:52,743 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4160669267177582, 'Total loss': 0.4160669267177582} | train loss {'Reaction outcome loss': 0.4537782176833033, 'Total loss': 0.4537782176833033}
2023-01-04 09:17:52,744 INFO:     Found new best model at epoch 13
2023-01-04 09:17:52,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:52,745 INFO:     Epoch: 14
2023-01-04 09:17:54,267 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4161656399567922, 'Total loss': 0.4161656399567922} | train loss {'Reaction outcome loss': 0.44682854775717296, 'Total loss': 0.44682854775717296}
2023-01-04 09:17:54,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:54,267 INFO:     Epoch: 15
2023-01-04 09:17:55,821 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.399942805369695, 'Total loss': 0.399942805369695} | train loss {'Reaction outcome loss': 0.4401851531415098, 'Total loss': 0.4401851531415098}
2023-01-04 09:17:55,822 INFO:     Found new best model at epoch 15
2023-01-04 09:17:55,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:55,822 INFO:     Epoch: 16
2023-01-04 09:17:57,347 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4020263542731603, 'Total loss': 0.4020263542731603} | train loss {'Reaction outcome loss': 0.4365977683029495, 'Total loss': 0.4365977683029495}
2023-01-04 09:17:57,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:57,347 INFO:     Epoch: 17
2023-01-04 09:17:58,950 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42083455522855123, 'Total loss': 0.42083455522855123} | train loss {'Reaction outcome loss': 0.434968534993248, 'Total loss': 0.434968534993248}
2023-01-04 09:17:58,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:17:58,951 INFO:     Epoch: 18
2023-01-04 09:18:00,519 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4066151042779287, 'Total loss': 0.4066151042779287} | train loss {'Reaction outcome loss': 0.43200706628461677, 'Total loss': 0.43200706628461677}
2023-01-04 09:18:00,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:00,519 INFO:     Epoch: 19
2023-01-04 09:18:02,097 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4038096268971761, 'Total loss': 0.4038096268971761} | train loss {'Reaction outcome loss': 0.43142590019851923, 'Total loss': 0.43142590019851923}
2023-01-04 09:18:02,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:02,098 INFO:     Epoch: 20
2023-01-04 09:18:03,629 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.395884562532107, 'Total loss': 0.395884562532107} | train loss {'Reaction outcome loss': 0.4208210983656961, 'Total loss': 0.4208210983656961}
2023-01-04 09:18:03,629 INFO:     Found new best model at epoch 20
2023-01-04 09:18:03,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:03,630 INFO:     Epoch: 21
2023-01-04 09:18:05,188 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41077462434768675, 'Total loss': 0.41077462434768675} | train loss {'Reaction outcome loss': 0.41801704235536896, 'Total loss': 0.41801704235536896}
2023-01-04 09:18:05,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:05,188 INFO:     Epoch: 22
2023-01-04 09:18:06,723 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.424788236618042, 'Total loss': 0.424788236618042} | train loss {'Reaction outcome loss': 0.4198586628704831, 'Total loss': 0.4198586628704831}
2023-01-04 09:18:06,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:06,723 INFO:     Epoch: 23
2023-01-04 09:18:08,295 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39876496692498525, 'Total loss': 0.39876496692498525} | train loss {'Reaction outcome loss': 0.42534825794860226, 'Total loss': 0.42534825794860226}
2023-01-04 09:18:08,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:08,295 INFO:     Epoch: 24
2023-01-04 09:18:09,869 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3826677888631821, 'Total loss': 0.3826677888631821} | train loss {'Reaction outcome loss': 0.41263812837069447, 'Total loss': 0.41263812837069447}
2023-01-04 09:18:09,869 INFO:     Found new best model at epoch 24
2023-01-04 09:18:09,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:09,870 INFO:     Epoch: 25
2023-01-04 09:18:11,455 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3869462291399638, 'Total loss': 0.3869462291399638} | train loss {'Reaction outcome loss': 0.41729871971883636, 'Total loss': 0.41729871971883636}
2023-01-04 09:18:11,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:11,456 INFO:     Epoch: 26
2023-01-04 09:18:12,999 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3936218043168386, 'Total loss': 0.3936218043168386} | train loss {'Reaction outcome loss': 0.4272190822335635, 'Total loss': 0.4272190822335635}
2023-01-04 09:18:12,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:12,999 INFO:     Epoch: 27
2023-01-04 09:18:14,549 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41616212924321494, 'Total loss': 0.41616212924321494} | train loss {'Reaction outcome loss': 0.4037321571301183, 'Total loss': 0.4037321571301183}
2023-01-04 09:18:14,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:14,549 INFO:     Epoch: 28
2023-01-04 09:18:16,088 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4033023635546366, 'Total loss': 0.4033023635546366} | train loss {'Reaction outcome loss': 0.398991058671685, 'Total loss': 0.398991058671685}
2023-01-04 09:18:16,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:16,088 INFO:     Epoch: 29
2023-01-04 09:18:17,664 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3886625607808431, 'Total loss': 0.3886625607808431} | train loss {'Reaction outcome loss': 0.39413562349300657, 'Total loss': 0.39413562349300657}
2023-01-04 09:18:17,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:17,664 INFO:     Epoch: 30
2023-01-04 09:18:19,231 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37243316719929376, 'Total loss': 0.37243316719929376} | train loss {'Reaction outcome loss': 0.39131192333972675, 'Total loss': 0.39131192333972675}
2023-01-04 09:18:19,231 INFO:     Found new best model at epoch 30
2023-01-04 09:18:19,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:19,231 INFO:     Epoch: 31
2023-01-04 09:18:20,809 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3858917107184728, 'Total loss': 0.3858917107184728} | train loss {'Reaction outcome loss': 0.3886561811719414, 'Total loss': 0.3886561811719414}
2023-01-04 09:18:20,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:20,810 INFO:     Epoch: 32
2023-01-04 09:18:22,345 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40583255191644035, 'Total loss': 0.40583255191644035} | train loss {'Reaction outcome loss': 0.3855048300701774, 'Total loss': 0.3855048300701774}
2023-01-04 09:18:22,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:22,346 INFO:     Epoch: 33
2023-01-04 09:18:23,912 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.383518319328626, 'Total loss': 0.383518319328626} | train loss {'Reaction outcome loss': 0.3810557816987452, 'Total loss': 0.3810557816987452}
2023-01-04 09:18:23,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:23,913 INFO:     Epoch: 34
2023-01-04 09:18:25,485 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38105272402366, 'Total loss': 0.38105272402366} | train loss {'Reaction outcome loss': 0.3806544923749955, 'Total loss': 0.3806544923749955}
2023-01-04 09:18:25,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:25,485 INFO:     Epoch: 35
2023-01-04 09:18:27,079 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3681970437367757, 'Total loss': 0.3681970437367757} | train loss {'Reaction outcome loss': 0.39261069561462797, 'Total loss': 0.39261069561462797}
2023-01-04 09:18:27,079 INFO:     Found new best model at epoch 35
2023-01-04 09:18:27,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:27,080 INFO:     Epoch: 36
2023-01-04 09:18:28,639 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3754158506790797, 'Total loss': 0.3754158506790797} | train loss {'Reaction outcome loss': 0.37264508919021033, 'Total loss': 0.37264508919021033}
2023-01-04 09:18:28,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:28,639 INFO:     Epoch: 37
2023-01-04 09:18:30,215 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36685070594151814, 'Total loss': 0.36685070594151814} | train loss {'Reaction outcome loss': 0.36925874077006365, 'Total loss': 0.36925874077006365}
2023-01-04 09:18:30,216 INFO:     Found new best model at epoch 37
2023-01-04 09:18:30,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:30,217 INFO:     Epoch: 38
2023-01-04 09:18:31,755 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3800982395807902, 'Total loss': 0.3800982395807902} | train loss {'Reaction outcome loss': 0.3644555260737737, 'Total loss': 0.3644555260737737}
2023-01-04 09:18:31,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:31,755 INFO:     Epoch: 39
2023-01-04 09:18:33,304 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36712247927983604, 'Total loss': 0.36712247927983604} | train loss {'Reaction outcome loss': 0.3606788697180109, 'Total loss': 0.3606788697180109}
2023-01-04 09:18:33,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:33,304 INFO:     Epoch: 40
2023-01-04 09:18:34,875 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3753190596898397, 'Total loss': 0.3753190596898397} | train loss {'Reaction outcome loss': 0.35798258034755354, 'Total loss': 0.35798258034755354}
2023-01-04 09:18:34,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:34,876 INFO:     Epoch: 41
2023-01-04 09:18:36,455 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37903242111206054, 'Total loss': 0.37903242111206054} | train loss {'Reaction outcome loss': 0.35559832829597365, 'Total loss': 0.35559832829597365}
2023-01-04 09:18:36,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:36,456 INFO:     Epoch: 42
2023-01-04 09:18:38,064 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3950156569480896, 'Total loss': 0.3950156569480896} | train loss {'Reaction outcome loss': 0.3524819874319423, 'Total loss': 0.3524819874319423}
2023-01-04 09:18:38,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:38,064 INFO:     Epoch: 43
2023-01-04 09:18:39,646 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3722580373287201, 'Total loss': 0.3722580373287201} | train loss {'Reaction outcome loss': 0.35259232055693207, 'Total loss': 0.35259232055693207}
2023-01-04 09:18:39,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:39,646 INFO:     Epoch: 44
2023-01-04 09:18:41,236 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39963064591089886, 'Total loss': 0.39963064591089886} | train loss {'Reaction outcome loss': 0.3505440571385881, 'Total loss': 0.3505440571385881}
2023-01-04 09:18:41,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:41,236 INFO:     Epoch: 45
2023-01-04 09:18:42,804 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.376598647236824, 'Total loss': 0.376598647236824} | train loss {'Reaction outcome loss': 0.3439785042705214, 'Total loss': 0.3439785042705214}
2023-01-04 09:18:42,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:42,805 INFO:     Epoch: 46
2023-01-04 09:18:44,388 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39733568429946897, 'Total loss': 0.39733568429946897} | train loss {'Reaction outcome loss': 0.3396196983268727, 'Total loss': 0.3396196983268727}
2023-01-04 09:18:44,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:44,388 INFO:     Epoch: 47
2023-01-04 09:18:45,968 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39229402045408884, 'Total loss': 0.39229402045408884} | train loss {'Reaction outcome loss': 0.34135014817550563, 'Total loss': 0.34135014817550563}
2023-01-04 09:18:45,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:45,968 INFO:     Epoch: 48
2023-01-04 09:18:47,546 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3695615877707799, 'Total loss': 0.3695615877707799} | train loss {'Reaction outcome loss': 0.34098717950932356, 'Total loss': 0.34098717950932356}
2023-01-04 09:18:47,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:47,547 INFO:     Epoch: 49
2023-01-04 09:18:49,092 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3641265372435252, 'Total loss': 0.3641265372435252} | train loss {'Reaction outcome loss': 0.3386710056144258, 'Total loss': 0.3386710056144258}
2023-01-04 09:18:49,093 INFO:     Found new best model at epoch 49
2023-01-04 09:18:49,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:49,093 INFO:     Epoch: 50
2023-01-04 09:18:50,675 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36673116087913515, 'Total loss': 0.36673116087913515} | train loss {'Reaction outcome loss': 0.3430986910053711, 'Total loss': 0.3430986910053711}
2023-01-04 09:18:50,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:50,676 INFO:     Epoch: 51
2023-01-04 09:18:52,232 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4505920817454656, 'Total loss': 0.4505920817454656} | train loss {'Reaction outcome loss': 0.3257035740610698, 'Total loss': 0.3257035740610698}
2023-01-04 09:18:52,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:52,232 INFO:     Epoch: 52
2023-01-04 09:18:53,801 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3763007581233978, 'Total loss': 0.3763007581233978} | train loss {'Reaction outcome loss': 0.33022552126667637, 'Total loss': 0.33022552126667637}
2023-01-04 09:18:53,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:53,801 INFO:     Epoch: 53
2023-01-04 09:18:55,404 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43021338681379956, 'Total loss': 0.43021338681379956} | train loss {'Reaction outcome loss': 0.33206604950237967, 'Total loss': 0.33206604950237967}
2023-01-04 09:18:55,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:55,404 INFO:     Epoch: 54
2023-01-04 09:18:56,970 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3774270981550217, 'Total loss': 0.3774270981550217} | train loss {'Reaction outcome loss': 0.35361788473159506, 'Total loss': 0.35361788473159506}
2023-01-04 09:18:56,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:56,970 INFO:     Epoch: 55
2023-01-04 09:18:58,529 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3877449999252955, 'Total loss': 0.3877449999252955} | train loss {'Reaction outcome loss': 0.33705104053513135, 'Total loss': 0.33705104053513135}
2023-01-04 09:18:58,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:18:58,529 INFO:     Epoch: 56
2023-01-04 09:19:00,115 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38091774682203927, 'Total loss': 0.38091774682203927} | train loss {'Reaction outcome loss': 0.3200687653683733, 'Total loss': 0.3200687653683733}
2023-01-04 09:19:00,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:00,116 INFO:     Epoch: 57
2023-01-04 09:19:01,683 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3678900847832362, 'Total loss': 0.3678900847832362} | train loss {'Reaction outcome loss': 0.3166785175132606, 'Total loss': 0.3166785175132606}
2023-01-04 09:19:01,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:01,683 INFO:     Epoch: 58
2023-01-04 09:19:03,275 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37419704894224803, 'Total loss': 0.37419704894224803} | train loss {'Reaction outcome loss': 0.31072480462329544, 'Total loss': 0.31072480462329544}
2023-01-04 09:19:03,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:03,276 INFO:     Epoch: 59
2023-01-04 09:19:04,863 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37228217124938967, 'Total loss': 0.37228217124938967} | train loss {'Reaction outcome loss': 0.3173992910794724, 'Total loss': 0.3173992910794724}
2023-01-04 09:19:04,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:04,863 INFO:     Epoch: 60
2023-01-04 09:19:06,446 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3628285149733225, 'Total loss': 0.3628285149733225} | train loss {'Reaction outcome loss': 0.3091039944219106, 'Total loss': 0.3091039944219106}
2023-01-04 09:19:06,446 INFO:     Found new best model at epoch 60
2023-01-04 09:19:06,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:06,447 INFO:     Epoch: 61
2023-01-04 09:19:07,987 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3844172378381093, 'Total loss': 0.3844172378381093} | train loss {'Reaction outcome loss': 0.31101373191652953, 'Total loss': 0.31101373191652953}
2023-01-04 09:19:07,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:07,987 INFO:     Epoch: 62
2023-01-04 09:19:09,528 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4066540022691091, 'Total loss': 0.4066540022691091} | train loss {'Reaction outcome loss': 0.30932696867882664, 'Total loss': 0.30932696867882664}
2023-01-04 09:19:09,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:09,528 INFO:     Epoch: 63
2023-01-04 09:19:11,117 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3920057733853658, 'Total loss': 0.3920057733853658} | train loss {'Reaction outcome loss': 0.30686918907947297, 'Total loss': 0.30686918907947297}
2023-01-04 09:19:11,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:11,117 INFO:     Epoch: 64
2023-01-04 09:19:12,694 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.33736056784788765, 'Total loss': 0.33736056784788765} | train loss {'Reaction outcome loss': 0.30405901577593625, 'Total loss': 0.30405901577593625}
2023-01-04 09:19:12,695 INFO:     Found new best model at epoch 64
2023-01-04 09:19:12,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:12,695 INFO:     Epoch: 65
2023-01-04 09:19:14,270 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3650731603304545, 'Total loss': 0.3650731603304545} | train loss {'Reaction outcome loss': 0.30335000304140797, 'Total loss': 0.30335000304140797}
2023-01-04 09:19:14,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:14,270 INFO:     Epoch: 66
2023-01-04 09:19:15,827 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3912205050388972, 'Total loss': 0.3912205050388972} | train loss {'Reaction outcome loss': 0.2991900895840313, 'Total loss': 0.2991900895840313}
2023-01-04 09:19:15,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:15,827 INFO:     Epoch: 67
2023-01-04 09:19:17,387 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3787674163778623, 'Total loss': 0.3787674163778623} | train loss {'Reaction outcome loss': 0.3037212609272936, 'Total loss': 0.3037212609272936}
2023-01-04 09:19:17,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:17,387 INFO:     Epoch: 68
2023-01-04 09:19:18,945 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3943901002407074, 'Total loss': 0.3943901002407074} | train loss {'Reaction outcome loss': 0.30801079839980905, 'Total loss': 0.30801079839980905}
2023-01-04 09:19:18,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:18,946 INFO:     Epoch: 69
2023-01-04 09:19:20,532 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38204940060774484, 'Total loss': 0.38204940060774484} | train loss {'Reaction outcome loss': 0.29734603582840896, 'Total loss': 0.29734603582840896}
2023-01-04 09:19:20,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:20,532 INFO:     Epoch: 70
2023-01-04 09:19:22,119 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.35668505330880484, 'Total loss': 0.35668505330880484} | train loss {'Reaction outcome loss': 0.2927111897818353, 'Total loss': 0.2927111897818353}
2023-01-04 09:19:22,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:22,119 INFO:     Epoch: 71
2023-01-04 09:19:23,691 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3726177175839742, 'Total loss': 0.3726177175839742} | train loss {'Reaction outcome loss': 0.29423973992790864, 'Total loss': 0.29423973992790864}
2023-01-04 09:19:23,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:23,691 INFO:     Epoch: 72
2023-01-04 09:19:25,256 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35561190446217855, 'Total loss': 0.35561190446217855} | train loss {'Reaction outcome loss': 0.29978987135573465, 'Total loss': 0.29978987135573465}
2023-01-04 09:19:25,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:25,256 INFO:     Epoch: 73
2023-01-04 09:19:26,854 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3472875118255615, 'Total loss': 0.3472875118255615} | train loss {'Reaction outcome loss': 0.2900699431535242, 'Total loss': 0.2900699431535242}
2023-01-04 09:19:26,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:26,854 INFO:     Epoch: 74
2023-01-04 09:19:28,402 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36828129589557645, 'Total loss': 0.36828129589557645} | train loss {'Reaction outcome loss': 0.2882197089138967, 'Total loss': 0.2882197089138967}
2023-01-04 09:19:28,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:28,403 INFO:     Epoch: 75
2023-01-04 09:19:30,005 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37422362665335335, 'Total loss': 0.37422362665335335} | train loss {'Reaction outcome loss': 0.2929839789732427, 'Total loss': 0.2929839789732427}
2023-01-04 09:19:30,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:30,005 INFO:     Epoch: 76
2023-01-04 09:19:31,583 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36597721676031747, 'Total loss': 0.36597721676031747} | train loss {'Reaction outcome loss': 0.29235967139349034, 'Total loss': 0.29235967139349034}
2023-01-04 09:19:31,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:31,583 INFO:     Epoch: 77
2023-01-04 09:19:33,173 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35966708362102506, 'Total loss': 0.35966708362102506} | train loss {'Reaction outcome loss': 0.2817990065086633, 'Total loss': 0.2817990065086633}
2023-01-04 09:19:33,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:33,173 INFO:     Epoch: 78
2023-01-04 09:19:34,716 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38099472324053446, 'Total loss': 0.38099472324053446} | train loss {'Reaction outcome loss': 0.2816525280401381, 'Total loss': 0.2816525280401381}
2023-01-04 09:19:34,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:34,717 INFO:     Epoch: 79
2023-01-04 09:19:36,286 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3510424425204595, 'Total loss': 0.3510424425204595} | train loss {'Reaction outcome loss': 0.2825946216404006, 'Total loss': 0.2825946216404006}
2023-01-04 09:19:36,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:36,286 INFO:     Epoch: 80
2023-01-04 09:19:37,831 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3820197135210037, 'Total loss': 0.3820197135210037} | train loss {'Reaction outcome loss': 0.29027816378115, 'Total loss': 0.29027816378115}
2023-01-04 09:19:37,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:37,832 INFO:     Epoch: 81
2023-01-04 09:19:39,450 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36965241432189944, 'Total loss': 0.36965241432189944} | train loss {'Reaction outcome loss': 0.2798968239592901, 'Total loss': 0.2798968239592901}
2023-01-04 09:19:39,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:39,451 INFO:     Epoch: 82
2023-01-04 09:19:41,047 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3519076849023501, 'Total loss': 0.3519076849023501} | train loss {'Reaction outcome loss': 0.31978895876934565, 'Total loss': 0.31978895876934565}
2023-01-04 09:19:41,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:41,047 INFO:     Epoch: 83
2023-01-04 09:19:42,638 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3702568769454956, 'Total loss': 0.3702568769454956} | train loss {'Reaction outcome loss': 0.29369271757162135, 'Total loss': 0.29369271757162135}
2023-01-04 09:19:42,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:42,638 INFO:     Epoch: 84
2023-01-04 09:19:44,200 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37234912713368734, 'Total loss': 0.37234912713368734} | train loss {'Reaction outcome loss': 0.2867051049041143, 'Total loss': 0.2867051049041143}
2023-01-04 09:19:44,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:44,200 INFO:     Epoch: 85
2023-01-04 09:19:45,735 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3845735917488734, 'Total loss': 0.3845735917488734} | train loss {'Reaction outcome loss': 0.29746882136627706, 'Total loss': 0.29746882136627706}
2023-01-04 09:19:45,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:45,735 INFO:     Epoch: 86
2023-01-04 09:19:47,321 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3933496634165446, 'Total loss': 0.3933496634165446} | train loss {'Reaction outcome loss': 0.2731706461990657, 'Total loss': 0.2731706461990657}
2023-01-04 09:19:47,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:47,321 INFO:     Epoch: 87
2023-01-04 09:19:48,900 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3442873626947403, 'Total loss': 0.3442873626947403} | train loss {'Reaction outcome loss': 0.27091209750179207, 'Total loss': 0.27091209750179207}
2023-01-04 09:19:48,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:48,900 INFO:     Epoch: 88
2023-01-04 09:19:50,479 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36626852850119274, 'Total loss': 0.36626852850119274} | train loss {'Reaction outcome loss': 0.271746747314245, 'Total loss': 0.271746747314245}
2023-01-04 09:19:50,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:50,479 INFO:     Epoch: 89
2023-01-04 09:19:52,065 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3482519785563151, 'Total loss': 0.3482519785563151} | train loss {'Reaction outcome loss': 0.27110006457761576, 'Total loss': 0.27110006457761576}
2023-01-04 09:19:52,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:52,065 INFO:     Epoch: 90
2023-01-04 09:19:53,612 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.35307975808779396, 'Total loss': 0.35307975808779396} | train loss {'Reaction outcome loss': 0.2672951275219574, 'Total loss': 0.2672951275219574}
2023-01-04 09:19:53,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:53,613 INFO:     Epoch: 91
2023-01-04 09:19:55,176 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3577090193827947, 'Total loss': 0.3577090193827947} | train loss {'Reaction outcome loss': 0.269051016267875, 'Total loss': 0.269051016267875}
2023-01-04 09:19:55,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:55,176 INFO:     Epoch: 92
2023-01-04 09:19:56,737 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37222835669914883, 'Total loss': 0.37222835669914883} | train loss {'Reaction outcome loss': 0.2674153717690269, 'Total loss': 0.2674153717690269}
2023-01-04 09:19:56,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:56,737 INFO:     Epoch: 93
2023-01-04 09:19:58,320 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35841772655646004, 'Total loss': 0.35841772655646004} | train loss {'Reaction outcome loss': 0.26478763546902634, 'Total loss': 0.26478763546902634}
2023-01-04 09:19:58,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:58,320 INFO:     Epoch: 94
2023-01-04 09:19:59,922 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3830500990152359, 'Total loss': 0.3830500990152359} | train loss {'Reaction outcome loss': 0.27191806633187376, 'Total loss': 0.27191806633187376}
2023-01-04 09:19:59,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:19:59,923 INFO:     Epoch: 95
2023-01-04 09:20:01,461 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.361345049738884, 'Total loss': 0.361345049738884} | train loss {'Reaction outcome loss': 0.2705960056973972, 'Total loss': 0.2705960056973972}
2023-01-04 09:20:01,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:01,462 INFO:     Epoch: 96
2023-01-04 09:20:03,048 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34054144819577536, 'Total loss': 0.34054144819577536} | train loss {'Reaction outcome loss': 0.26910548930965783, 'Total loss': 0.26910548930965783}
2023-01-04 09:20:03,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:03,048 INFO:     Epoch: 97
2023-01-04 09:20:04,591 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.412930961449941, 'Total loss': 0.412930961449941} | train loss {'Reaction outcome loss': 0.2622498780542958, 'Total loss': 0.2622498780542958}
2023-01-04 09:20:04,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:04,592 INFO:     Epoch: 98
2023-01-04 09:20:06,168 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36201640566190085, 'Total loss': 0.36201640566190085} | train loss {'Reaction outcome loss': 0.2717852749308382, 'Total loss': 0.2717852749308382}
2023-01-04 09:20:06,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:06,169 INFO:     Epoch: 99
2023-01-04 09:20:07,739 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3773564577102661, 'Total loss': 0.3773564577102661} | train loss {'Reaction outcome loss': 0.2589021978100114, 'Total loss': 0.2589021978100114}
2023-01-04 09:20:07,740 INFO:     Best model found after epoch 65 of 100.
2023-01-04 09:20:07,740 INFO:   Done with stage: TRAINING
2023-01-04 09:20:07,740 INFO:   Starting stage: EVALUATION
2023-01-04 09:20:07,871 INFO:   Done with stage: EVALUATION
2023-01-04 09:20:07,871 INFO:   Leaving out SEQ value Fold_6
2023-01-04 09:20:07,883 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:20:07,884 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:20:08,537 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:20:08,537 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:20:08,605 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:20:08,605 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:20:08,605 INFO:     No hyperparam tuning for this model
2023-01-04 09:20:08,605 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:20:08,605 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:20:08,606 INFO:     None feature selector for col prot
2023-01-04 09:20:08,606 INFO:     None feature selector for col prot
2023-01-04 09:20:08,606 INFO:     None feature selector for col prot
2023-01-04 09:20:08,607 INFO:     None feature selector for col chem
2023-01-04 09:20:08,607 INFO:     None feature selector for col chem
2023-01-04 09:20:08,607 INFO:     None feature selector for col chem
2023-01-04 09:20:08,607 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:20:08,607 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:20:08,608 INFO:     Number of params in model 70111
2023-01-04 09:20:08,611 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:20:08,611 INFO:   Starting stage: TRAINING
2023-01-04 09:20:08,655 INFO:     Val loss before train {'Reaction outcome loss': 1.0377095818519593, 'Total loss': 1.0377095818519593}
2023-01-04 09:20:08,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:08,655 INFO:     Epoch: 0
2023-01-04 09:20:10,207 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7822291811307271, 'Total loss': 0.7822291811307271} | train loss {'Reaction outcome loss': 0.8347435809344567, 'Total loss': 0.8347435809344567}
2023-01-04 09:20:10,207 INFO:     Found new best model at epoch 0
2023-01-04 09:20:10,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:10,208 INFO:     Epoch: 1
2023-01-04 09:20:11,794 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6441417614618937, 'Total loss': 0.6441417614618937} | train loss {'Reaction outcome loss': 0.6862060879255928, 'Total loss': 0.6862060879255928}
2023-01-04 09:20:11,795 INFO:     Found new best model at epoch 1
2023-01-04 09:20:11,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:11,796 INFO:     Epoch: 2
2023-01-04 09:20:13,353 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5812046130498251, 'Total loss': 0.5812046130498251} | train loss {'Reaction outcome loss': 0.5902769364841768, 'Total loss': 0.5902769364841768}
2023-01-04 09:20:13,353 INFO:     Found new best model at epoch 2
2023-01-04 09:20:13,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:13,354 INFO:     Epoch: 3
2023-01-04 09:20:14,944 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5506409565607707, 'Total loss': 0.5506409565607707} | train loss {'Reaction outcome loss': 0.539897783360768, 'Total loss': 0.539897783360768}
2023-01-04 09:20:14,944 INFO:     Found new best model at epoch 3
2023-01-04 09:20:14,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:14,945 INFO:     Epoch: 4
2023-01-04 09:20:16,532 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5562604367733002, 'Total loss': 0.5562604367733002} | train loss {'Reaction outcome loss': 0.5193863055952217, 'Total loss': 0.5193863055952217}
2023-01-04 09:20:16,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:16,532 INFO:     Epoch: 5
2023-01-04 09:20:18,101 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5460958361625672, 'Total loss': 0.5460958361625672} | train loss {'Reaction outcome loss': 0.506052741666149, 'Total loss': 0.506052741666149}
2023-01-04 09:20:18,102 INFO:     Found new best model at epoch 5
2023-01-04 09:20:18,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:18,102 INFO:     Epoch: 6
2023-01-04 09:20:19,661 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5640209496021271, 'Total loss': 0.5640209496021271} | train loss {'Reaction outcome loss': 0.49174046284262685, 'Total loss': 0.49174046284262685}
2023-01-04 09:20:19,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:19,662 INFO:     Epoch: 7
2023-01-04 09:20:21,291 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5146308928728104, 'Total loss': 0.5146308928728104} | train loss {'Reaction outcome loss': 0.48894085162164236, 'Total loss': 0.48894085162164236}
2023-01-04 09:20:21,291 INFO:     Found new best model at epoch 7
2023-01-04 09:20:21,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:21,292 INFO:     Epoch: 8
2023-01-04 09:20:22,872 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5156486958265305, 'Total loss': 0.5156486958265305} | train loss {'Reaction outcome loss': 0.4720423649360104, 'Total loss': 0.4720423649360104}
2023-01-04 09:20:22,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:22,872 INFO:     Epoch: 9
2023-01-04 09:20:24,513 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5111713687578837, 'Total loss': 0.5111713687578837} | train loss {'Reaction outcome loss': 0.4686373536967659, 'Total loss': 0.4686373536967659}
2023-01-04 09:20:24,514 INFO:     Found new best model at epoch 9
2023-01-04 09:20:24,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:24,515 INFO:     Epoch: 10
2023-01-04 09:20:26,142 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5266046086947124, 'Total loss': 0.5266046086947124} | train loss {'Reaction outcome loss': 0.46096353567596793, 'Total loss': 0.46096353567596793}
2023-01-04 09:20:26,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:26,142 INFO:     Epoch: 11
2023-01-04 09:20:27,773 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5182834744453431, 'Total loss': 0.5182834744453431} | train loss {'Reaction outcome loss': 0.45990322881202766, 'Total loss': 0.45990322881202766}
2023-01-04 09:20:27,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:27,773 INFO:     Epoch: 12
2023-01-04 09:20:29,363 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5270349701245626, 'Total loss': 0.5270349701245626} | train loss {'Reaction outcome loss': 0.4584480874456357, 'Total loss': 0.4584480874456357}
2023-01-04 09:20:29,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:29,363 INFO:     Epoch: 13
2023-01-04 09:20:30,979 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5078824460506439, 'Total loss': 0.5078824460506439} | train loss {'Reaction outcome loss': 0.4438829125908829, 'Total loss': 0.4438829125908829}
2023-01-04 09:20:30,980 INFO:     Found new best model at epoch 13
2023-01-04 09:20:30,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:30,981 INFO:     Epoch: 14
2023-01-04 09:20:32,560 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5071761727333068, 'Total loss': 0.5071761727333068} | train loss {'Reaction outcome loss': 0.4385350411892801, 'Total loss': 0.4385350411892801}
2023-01-04 09:20:32,560 INFO:     Found new best model at epoch 14
2023-01-04 09:20:32,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:32,562 INFO:     Epoch: 15
2023-01-04 09:20:34,182 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5229353725910186, 'Total loss': 0.5229353725910186} | train loss {'Reaction outcome loss': 0.44794322455814783, 'Total loss': 0.44794322455814783}
2023-01-04 09:20:34,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:34,182 INFO:     Epoch: 16
2023-01-04 09:20:35,814 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5003118515014648, 'Total loss': 0.5003118515014648} | train loss {'Reaction outcome loss': 0.44897411034806917, 'Total loss': 0.44897411034806917}
2023-01-04 09:20:35,814 INFO:     Found new best model at epoch 16
2023-01-04 09:20:35,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:35,816 INFO:     Epoch: 17
2023-01-04 09:20:37,423 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5010343293348948, 'Total loss': 0.5010343293348948} | train loss {'Reaction outcome loss': 0.45005649970709416, 'Total loss': 0.45005649970709416}
2023-01-04 09:20:37,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:37,424 INFO:     Epoch: 18
2023-01-04 09:20:39,035 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4886318882306417, 'Total loss': 0.4886318882306417} | train loss {'Reaction outcome loss': 0.44500226454566355, 'Total loss': 0.44500226454566355}
2023-01-04 09:20:39,035 INFO:     Found new best model at epoch 18
2023-01-04 09:20:39,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:39,037 INFO:     Epoch: 19
2023-01-04 09:20:40,631 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4683801551659902, 'Total loss': 0.4683801551659902} | train loss {'Reaction outcome loss': 0.4289809178452993, 'Total loss': 0.4289809178452993}
2023-01-04 09:20:40,631 INFO:     Found new best model at epoch 19
2023-01-04 09:20:40,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:40,632 INFO:     Epoch: 20
2023-01-04 09:20:42,218 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4848879277706146, 'Total loss': 0.4848879277706146} | train loss {'Reaction outcome loss': 0.4201716591321425, 'Total loss': 0.4201716591321425}
2023-01-04 09:20:42,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:42,219 INFO:     Epoch: 21
2023-01-04 09:20:43,816 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.488411017258962, 'Total loss': 0.488411017258962} | train loss {'Reaction outcome loss': 0.41445422239021223, 'Total loss': 0.41445422239021223}
2023-01-04 09:20:43,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:43,816 INFO:     Epoch: 22
2023-01-04 09:20:45,425 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48894197344779966, 'Total loss': 0.48894197344779966} | train loss {'Reaction outcome loss': 0.4070175644912946, 'Total loss': 0.4070175644912946}
2023-01-04 09:20:45,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:45,426 INFO:     Epoch: 23
2023-01-04 09:20:46,999 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.484955100218455, 'Total loss': 0.484955100218455} | train loss {'Reaction outcome loss': 0.40496842935681343, 'Total loss': 0.40496842935681343}
2023-01-04 09:20:46,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:46,999 INFO:     Epoch: 24
2023-01-04 09:20:48,606 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4571301241715749, 'Total loss': 0.4571301241715749} | train loss {'Reaction outcome loss': 0.408898271978799, 'Total loss': 0.408898271978799}
2023-01-04 09:20:48,606 INFO:     Found new best model at epoch 24
2023-01-04 09:20:48,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:48,608 INFO:     Epoch: 25
2023-01-04 09:20:50,197 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47002745072046914, 'Total loss': 0.47002745072046914} | train loss {'Reaction outcome loss': 0.398361642183601, 'Total loss': 0.398361642183601}
2023-01-04 09:20:50,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:50,197 INFO:     Epoch: 26
2023-01-04 09:20:51,796 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48230745593706764, 'Total loss': 0.48230745593706764} | train loss {'Reaction outcome loss': 0.3946234638924184, 'Total loss': 0.3946234638924184}
2023-01-04 09:20:51,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:51,796 INFO:     Epoch: 27
2023-01-04 09:20:53,415 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47534404198328656, 'Total loss': 0.47534404198328656} | train loss {'Reaction outcome loss': 0.39365468341587245, 'Total loss': 0.39365468341587245}
2023-01-04 09:20:53,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:53,416 INFO:     Epoch: 28
2023-01-04 09:20:55,024 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4767919639746348, 'Total loss': 0.4767919639746348} | train loss {'Reaction outcome loss': 0.40329405659998674, 'Total loss': 0.40329405659998674}
2023-01-04 09:20:55,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:55,024 INFO:     Epoch: 29
2023-01-04 09:20:56,571 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4856308827797572, 'Total loss': 0.4856308827797572} | train loss {'Reaction outcome loss': 0.3863296115204044, 'Total loss': 0.3863296115204044}
2023-01-04 09:20:56,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:56,572 INFO:     Epoch: 30
2023-01-04 09:20:58,166 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4771577715873718, 'Total loss': 0.4771577715873718} | train loss {'Reaction outcome loss': 0.38275660015642643, 'Total loss': 0.38275660015642643}
2023-01-04 09:20:58,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:58,166 INFO:     Epoch: 31
2023-01-04 09:20:59,720 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4529404322306315, 'Total loss': 0.4529404322306315} | train loss {'Reaction outcome loss': 0.3767896507996593, 'Total loss': 0.3767896507996593}
2023-01-04 09:20:59,720 INFO:     Found new best model at epoch 31
2023-01-04 09:20:59,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:20:59,721 INFO:     Epoch: 32
2023-01-04 09:21:01,300 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4717678050200144, 'Total loss': 0.4717678050200144} | train loss {'Reaction outcome loss': 0.3777879945987809, 'Total loss': 0.3777879945987809}
2023-01-04 09:21:01,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:01,300 INFO:     Epoch: 33
2023-01-04 09:21:02,878 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44656533797581993, 'Total loss': 0.44656533797581993} | train loss {'Reaction outcome loss': 0.3801117845763709, 'Total loss': 0.3801117845763709}
2023-01-04 09:21:02,878 INFO:     Found new best model at epoch 33
2023-01-04 09:21:02,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:02,879 INFO:     Epoch: 34
2023-01-04 09:21:04,438 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45159711639086403, 'Total loss': 0.45159711639086403} | train loss {'Reaction outcome loss': 0.3643945309643944, 'Total loss': 0.3643945309643944}
2023-01-04 09:21:04,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:04,439 INFO:     Epoch: 35
2023-01-04 09:21:05,988 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45880012114842733, 'Total loss': 0.45880012114842733} | train loss {'Reaction outcome loss': 0.38066748494579306, 'Total loss': 0.38066748494579306}
2023-01-04 09:21:05,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:05,988 INFO:     Epoch: 36
2023-01-04 09:21:07,561 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46237150629361473, 'Total loss': 0.46237150629361473} | train loss {'Reaction outcome loss': 0.3738557449904729, 'Total loss': 0.3738557449904729}
2023-01-04 09:21:07,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:07,562 INFO:     Epoch: 37
2023-01-04 09:21:09,099 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.470013202726841, 'Total loss': 0.470013202726841} | train loss {'Reaction outcome loss': 0.3540058044338788, 'Total loss': 0.3540058044338788}
2023-01-04 09:21:09,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:09,099 INFO:     Epoch: 38
2023-01-04 09:21:10,674 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4505572974681854, 'Total loss': 0.4505572974681854} | train loss {'Reaction outcome loss': 0.353424461555245, 'Total loss': 0.353424461555245}
2023-01-04 09:21:10,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:10,674 INFO:     Epoch: 39
2023-01-04 09:21:12,266 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45197352866331736, 'Total loss': 0.45197352866331736} | train loss {'Reaction outcome loss': 0.3520301977995837, 'Total loss': 0.3520301977995837}
2023-01-04 09:21:12,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:12,266 INFO:     Epoch: 40
2023-01-04 09:21:13,818 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43879312872886655, 'Total loss': 0.43879312872886655} | train loss {'Reaction outcome loss': 0.34785440060617134, 'Total loss': 0.34785440060617134}
2023-01-04 09:21:13,819 INFO:     Found new best model at epoch 40
2023-01-04 09:21:13,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:13,819 INFO:     Epoch: 41
2023-01-04 09:21:15,403 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4626306533813477, 'Total loss': 0.4626306533813477} | train loss {'Reaction outcome loss': 0.36849581706675066, 'Total loss': 0.36849581706675066}
2023-01-04 09:21:15,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:15,403 INFO:     Epoch: 42
2023-01-04 09:21:16,992 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46001480221748353, 'Total loss': 0.46001480221748353} | train loss {'Reaction outcome loss': 0.35325448345273786, 'Total loss': 0.35325448345273786}
2023-01-04 09:21:16,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:16,993 INFO:     Epoch: 43
2023-01-04 09:21:18,535 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4560602287451426, 'Total loss': 0.4560602287451426} | train loss {'Reaction outcome loss': 0.34665168429711374, 'Total loss': 0.34665168429711374}
2023-01-04 09:21:18,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:18,537 INFO:     Epoch: 44
2023-01-04 09:21:20,132 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4781605005264282, 'Total loss': 0.4781605005264282} | train loss {'Reaction outcome loss': 0.3388274777950584, 'Total loss': 0.3388274777950584}
2023-01-04 09:21:20,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:20,132 INFO:     Epoch: 45
2023-01-04 09:21:21,716 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4457999348640442, 'Total loss': 0.4457999348640442} | train loss {'Reaction outcome loss': 0.3436995043648758, 'Total loss': 0.3436995043648758}
2023-01-04 09:21:21,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:21,716 INFO:     Epoch: 46
2023-01-04 09:21:23,246 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4712358733018239, 'Total loss': 0.4712358733018239} | train loss {'Reaction outcome loss': 0.3458437016368776, 'Total loss': 0.3458437016368776}
2023-01-04 09:21:23,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:23,246 INFO:     Epoch: 47
2023-01-04 09:21:24,822 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45353609720865884, 'Total loss': 0.45353609720865884} | train loss {'Reaction outcome loss': 0.36895014783721825, 'Total loss': 0.36895014783721825}
2023-01-04 09:21:24,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:24,823 INFO:     Epoch: 48
2023-01-04 09:21:26,392 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45666115085283915, 'Total loss': 0.45666115085283915} | train loss {'Reaction outcome loss': 0.3321771127386086, 'Total loss': 0.3321771127386086}
2023-01-04 09:21:26,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:26,392 INFO:     Epoch: 49
2023-01-04 09:21:27,925 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4224327584107717, 'Total loss': 0.4224327584107717} | train loss {'Reaction outcome loss': 0.32119479228434933, 'Total loss': 0.32119479228434933}
2023-01-04 09:21:27,925 INFO:     Found new best model at epoch 49
2023-01-04 09:21:27,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:27,926 INFO:     Epoch: 50
2023-01-04 09:21:29,495 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44961832960446674, 'Total loss': 0.44961832960446674} | train loss {'Reaction outcome loss': 0.32153070985299087, 'Total loss': 0.32153070985299087}
2023-01-04 09:21:29,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:29,495 INFO:     Epoch: 51
2023-01-04 09:21:31,075 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43903437852859495, 'Total loss': 0.43903437852859495} | train loss {'Reaction outcome loss': 0.33347283730256383, 'Total loss': 0.33347283730256383}
2023-01-04 09:21:31,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:31,076 INFO:     Epoch: 52
2023-01-04 09:21:32,600 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4371327539285024, 'Total loss': 0.4371327539285024} | train loss {'Reaction outcome loss': 0.3216373852683582, 'Total loss': 0.3216373852683582}
2023-01-04 09:21:32,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:32,600 INFO:     Epoch: 53
2023-01-04 09:21:34,156 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46906938354174293, 'Total loss': 0.46906938354174293} | train loss {'Reaction outcome loss': 0.3273745611768918, 'Total loss': 0.3273745611768918}
2023-01-04 09:21:34,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:34,157 INFO:     Epoch: 54
2023-01-04 09:21:35,718 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4648917039235433, 'Total loss': 0.4648917039235433} | train loss {'Reaction outcome loss': 0.3211119733210923, 'Total loss': 0.3211119733210923}
2023-01-04 09:21:35,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:35,719 INFO:     Epoch: 55
2023-01-04 09:21:37,266 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43817331691583, 'Total loss': 0.43817331691583} | train loss {'Reaction outcome loss': 0.3406333198291722, 'Total loss': 0.3406333198291722}
2023-01-04 09:21:37,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:37,267 INFO:     Epoch: 56
2023-01-04 09:21:38,835 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.419803985953331, 'Total loss': 0.419803985953331} | train loss {'Reaction outcome loss': 0.31560243766390433, 'Total loss': 0.31560243766390433}
2023-01-04 09:21:38,836 INFO:     Found new best model at epoch 56
2023-01-04 09:21:38,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:38,836 INFO:     Epoch: 57
2023-01-04 09:21:40,396 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4411042253176371, 'Total loss': 0.4411042253176371} | train loss {'Reaction outcome loss': 0.31356246276265953, 'Total loss': 0.31356246276265953}
2023-01-04 09:21:40,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:40,397 INFO:     Epoch: 58
2023-01-04 09:21:41,935 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4216383516788483, 'Total loss': 0.4216383516788483} | train loss {'Reaction outcome loss': 0.30862909404263983, 'Total loss': 0.30862909404263983}
2023-01-04 09:21:41,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:41,936 INFO:     Epoch: 59
2023-01-04 09:21:43,508 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4480984042088191, 'Total loss': 0.4480984042088191} | train loss {'Reaction outcome loss': 0.3086437545564126, 'Total loss': 0.3086437545564126}
2023-01-04 09:21:43,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:43,508 INFO:     Epoch: 60
2023-01-04 09:21:45,042 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4203395793835322, 'Total loss': 0.4203395793835322} | train loss {'Reaction outcome loss': 0.30233420191359694, 'Total loss': 0.30233420191359694}
2023-01-04 09:21:45,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:45,043 INFO:     Epoch: 61
2023-01-04 09:21:46,574 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41763503352801007, 'Total loss': 0.41763503352801007} | train loss {'Reaction outcome loss': 0.29789414737994474, 'Total loss': 0.29789414737994474}
2023-01-04 09:21:46,575 INFO:     Found new best model at epoch 61
2023-01-04 09:21:46,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:46,575 INFO:     Epoch: 62
2023-01-04 09:21:48,126 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4504607041676839, 'Total loss': 0.4504607041676839} | train loss {'Reaction outcome loss': 0.2988488786732373, 'Total loss': 0.2988488786732373}
2023-01-04 09:21:48,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:48,127 INFO:     Epoch: 63
2023-01-04 09:21:49,718 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4126067971189817, 'Total loss': 0.4126067971189817} | train loss {'Reaction outcome loss': 0.30553082949441834, 'Total loss': 0.30553082949441834}
2023-01-04 09:21:49,718 INFO:     Found new best model at epoch 63
2023-01-04 09:21:49,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:49,719 INFO:     Epoch: 64
2023-01-04 09:21:51,285 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4712312161922455, 'Total loss': 0.4712312161922455} | train loss {'Reaction outcome loss': 0.298360071907873, 'Total loss': 0.298360071907873}
2023-01-04 09:21:51,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:51,285 INFO:     Epoch: 65
2023-01-04 09:21:52,909 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42028270463148754, 'Total loss': 0.42028270463148754} | train loss {'Reaction outcome loss': 0.2943893588701452, 'Total loss': 0.2943893588701452}
2023-01-04 09:21:52,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:52,910 INFO:     Epoch: 66
2023-01-04 09:21:54,389 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4495514571666718, 'Total loss': 0.4495514571666718} | train loss {'Reaction outcome loss': 0.3121750228970811, 'Total loss': 0.3121750228970811}
2023-01-04 09:21:54,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:54,389 INFO:     Epoch: 67
2023-01-04 09:21:55,422 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42151194214820864, 'Total loss': 0.42151194214820864} | train loss {'Reaction outcome loss': 0.29312516629621654, 'Total loss': 0.29312516629621654}
2023-01-04 09:21:55,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:55,422 INFO:     Epoch: 68
2023-01-04 09:21:56,451 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4353009780248006, 'Total loss': 0.4353009780248006} | train loss {'Reaction outcome loss': 0.28923637832285487, 'Total loss': 0.28923637832285487}
2023-01-04 09:21:56,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:56,452 INFO:     Epoch: 69
2023-01-04 09:21:57,478 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41857811411221824, 'Total loss': 0.41857811411221824} | train loss {'Reaction outcome loss': 0.28814040424396703, 'Total loss': 0.28814040424396703}
2023-01-04 09:21:57,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:57,478 INFO:     Epoch: 70
2023-01-04 09:21:58,499 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4407798945903778, 'Total loss': 0.4407798945903778} | train loss {'Reaction outcome loss': 0.2850316367989433, 'Total loss': 0.2850316367989433}
2023-01-04 09:21:58,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:58,499 INFO:     Epoch: 71
2023-01-04 09:21:59,974 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44886268575986227, 'Total loss': 0.44886268575986227} | train loss {'Reaction outcome loss': 0.28391683999317413, 'Total loss': 0.28391683999317413}
2023-01-04 09:21:59,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:21:59,975 INFO:     Epoch: 72
2023-01-04 09:22:01,564 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40829807221889497, 'Total loss': 0.40829807221889497} | train loss {'Reaction outcome loss': 0.2829348326582835, 'Total loss': 0.2829348326582835}
2023-01-04 09:22:01,564 INFO:     Found new best model at epoch 72
2023-01-04 09:22:01,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:01,565 INFO:     Epoch: 73
2023-01-04 09:22:03,130 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.431286358833313, 'Total loss': 0.431286358833313} | train loss {'Reaction outcome loss': 0.2823260558804538, 'Total loss': 0.2823260558804538}
2023-01-04 09:22:03,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:03,131 INFO:     Epoch: 74
2023-01-04 09:22:04,702 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4252363304297129, 'Total loss': 0.4252363304297129} | train loss {'Reaction outcome loss': 0.278554722794966, 'Total loss': 0.278554722794966}
2023-01-04 09:22:04,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:04,702 INFO:     Epoch: 75
2023-01-04 09:22:06,227 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4239680995543798, 'Total loss': 0.4239680995543798} | train loss {'Reaction outcome loss': 0.2822568070382197, 'Total loss': 0.2822568070382197}
2023-01-04 09:22:06,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:06,227 INFO:     Epoch: 76
2023-01-04 09:22:07,809 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40519206325213114, 'Total loss': 0.40519206325213114} | train loss {'Reaction outcome loss': 0.278148793787493, 'Total loss': 0.278148793787493}
2023-01-04 09:22:07,809 INFO:     Found new best model at epoch 76
2023-01-04 09:22:07,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:07,810 INFO:     Epoch: 77
2023-01-04 09:22:09,384 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4622364322344462, 'Total loss': 0.4622364322344462} | train loss {'Reaction outcome loss': 0.27948666123510507, 'Total loss': 0.27948666123510507}
2023-01-04 09:22:09,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:09,384 INFO:     Epoch: 78
2023-01-04 09:22:10,977 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4354977210362752, 'Total loss': 0.4354977210362752} | train loss {'Reaction outcome loss': 0.27842525596455403, 'Total loss': 0.27842525596455403}
2023-01-04 09:22:10,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:10,977 INFO:     Epoch: 79
2023-01-04 09:22:12,554 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.403703839580218, 'Total loss': 0.403703839580218} | train loss {'Reaction outcome loss': 0.2739553328272819, 'Total loss': 0.2739553328272819}
2023-01-04 09:22:12,555 INFO:     Found new best model at epoch 79
2023-01-04 09:22:12,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:12,556 INFO:     Epoch: 80
2023-01-04 09:22:14,143 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.410916527112325, 'Total loss': 0.410916527112325} | train loss {'Reaction outcome loss': 0.2709051366166576, 'Total loss': 0.2709051366166576}
2023-01-04 09:22:14,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:14,143 INFO:     Epoch: 81
2023-01-04 09:22:15,701 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4281856069962184, 'Total loss': 0.4281856069962184} | train loss {'Reaction outcome loss': 0.27189224525595224, 'Total loss': 0.27189224525595224}
2023-01-04 09:22:15,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:15,701 INFO:     Epoch: 82
2023-01-04 09:22:17,251 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4507178783416748, 'Total loss': 0.4507178783416748} | train loss {'Reaction outcome loss': 0.27105275183187233, 'Total loss': 0.27105275183187233}
2023-01-04 09:22:17,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:17,251 INFO:     Epoch: 83
2023-01-04 09:22:18,847 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4118512660264969, 'Total loss': 0.4118512660264969} | train loss {'Reaction outcome loss': 0.2705816673570434, 'Total loss': 0.2705816673570434}
2023-01-04 09:22:18,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:18,847 INFO:     Epoch: 84
2023-01-04 09:22:20,461 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43649666706720985, 'Total loss': 0.43649666706720985} | train loss {'Reaction outcome loss': 0.2661409323235326, 'Total loss': 0.2661409323235326}
2023-01-04 09:22:20,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:20,462 INFO:     Epoch: 85
2023-01-04 09:22:22,041 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4343484858671824, 'Total loss': 0.4343484858671824} | train loss {'Reaction outcome loss': 0.27561052381128504, 'Total loss': 0.27561052381128504}
2023-01-04 09:22:22,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:22,041 INFO:     Epoch: 86
2023-01-04 09:22:23,610 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42161631137132644, 'Total loss': 0.42161631137132644} | train loss {'Reaction outcome loss': 0.3173807563422167, 'Total loss': 0.3173807563422167}
2023-01-04 09:22:23,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:23,610 INFO:     Epoch: 87
2023-01-04 09:22:25,147 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45725910663604735, 'Total loss': 0.45725910663604735} | train loss {'Reaction outcome loss': 0.3343027959969165, 'Total loss': 0.3343027959969165}
2023-01-04 09:22:25,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:25,147 INFO:     Epoch: 88
2023-01-04 09:22:26,694 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4078913522263368, 'Total loss': 0.4078913522263368} | train loss {'Reaction outcome loss': 0.2942439475623162, 'Total loss': 0.2942439475623162}
2023-01-04 09:22:26,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:26,694 INFO:     Epoch: 89
2023-01-04 09:22:28,269 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43636207779248554, 'Total loss': 0.43636207779248554} | train loss {'Reaction outcome loss': 0.30193385195014055, 'Total loss': 0.30193385195014055}
2023-01-04 09:22:28,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:28,269 INFO:     Epoch: 90
2023-01-04 09:22:29,820 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41244633396466573, 'Total loss': 0.41244633396466573} | train loss {'Reaction outcome loss': 0.2749384917939703, 'Total loss': 0.2749384917939703}
2023-01-04 09:22:29,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:29,822 INFO:     Epoch: 91
2023-01-04 09:22:31,388 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39651909867922464, 'Total loss': 0.39651909867922464} | train loss {'Reaction outcome loss': 0.2710520161156281, 'Total loss': 0.2710520161156281}
2023-01-04 09:22:31,388 INFO:     Found new best model at epoch 91
2023-01-04 09:22:31,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:31,389 INFO:     Epoch: 92
2023-01-04 09:22:32,912 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4135463853677114, 'Total loss': 0.4135463853677114} | train loss {'Reaction outcome loss': 0.2595808120019248, 'Total loss': 0.2595808120019248}
2023-01-04 09:22:32,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:32,913 INFO:     Epoch: 93
2023-01-04 09:22:34,478 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4341019054253896, 'Total loss': 0.4341019054253896} | train loss {'Reaction outcome loss': 0.2619279214869375, 'Total loss': 0.2619279214869375}
2023-01-04 09:22:34,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:34,478 INFO:     Epoch: 94
2023-01-04 09:22:36,009 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4299206227064133, 'Total loss': 0.4299206227064133} | train loss {'Reaction outcome loss': 0.27524546493330726, 'Total loss': 0.27524546493330726}
2023-01-04 09:22:36,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:36,010 INFO:     Epoch: 95
2023-01-04 09:22:37,581 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4263299306233724, 'Total loss': 0.4263299306233724} | train loss {'Reaction outcome loss': 0.2726163477164464, 'Total loss': 0.2726163477164464}
2023-01-04 09:22:37,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:37,581 INFO:     Epoch: 96
2023-01-04 09:22:39,139 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4105033593873183, 'Total loss': 0.4105033593873183} | train loss {'Reaction outcome loss': 0.2638082949725567, 'Total loss': 0.2638082949725567}
2023-01-04 09:22:39,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:39,139 INFO:     Epoch: 97
2023-01-04 09:22:40,716 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41466079354286195, 'Total loss': 0.41466079354286195} | train loss {'Reaction outcome loss': 0.2614420589177272, 'Total loss': 0.2614420589177272}
2023-01-04 09:22:40,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:40,717 INFO:     Epoch: 98
2023-01-04 09:22:42,265 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4277836670478185, 'Total loss': 0.4277836670478185} | train loss {'Reaction outcome loss': 0.26804618367358396, 'Total loss': 0.26804618367358396}
2023-01-04 09:22:42,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:42,266 INFO:     Epoch: 99
2023-01-04 09:22:43,856 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4554763396581014, 'Total loss': 0.4554763396581014} | train loss {'Reaction outcome loss': 0.29117215632763016, 'Total loss': 0.29117215632763016}
2023-01-04 09:22:43,856 INFO:     Best model found after epoch 92 of 100.
2023-01-04 09:22:43,856 INFO:   Done with stage: TRAINING
2023-01-04 09:22:43,856 INFO:   Starting stage: EVALUATION
2023-01-04 09:22:43,987 INFO:   Done with stage: EVALUATION
2023-01-04 09:22:43,988 INFO:   Leaving out SEQ value Fold_7
2023-01-04 09:22:44,000 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 09:22:44,000 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:22:44,667 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:22:44,667 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:22:44,737 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:22:44,737 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:22:44,737 INFO:     No hyperparam tuning for this model
2023-01-04 09:22:44,737 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:22:44,737 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:22:44,738 INFO:     None feature selector for col prot
2023-01-04 09:22:44,738 INFO:     None feature selector for col prot
2023-01-04 09:22:44,738 INFO:     None feature selector for col prot
2023-01-04 09:22:44,738 INFO:     None feature selector for col chem
2023-01-04 09:22:44,738 INFO:     None feature selector for col chem
2023-01-04 09:22:44,739 INFO:     None feature selector for col chem
2023-01-04 09:22:44,739 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:22:44,739 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:22:44,740 INFO:     Number of params in model 70111
2023-01-04 09:22:44,743 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:22:44,743 INFO:   Starting stage: TRAINING
2023-01-04 09:22:44,786 INFO:     Val loss before train {'Reaction outcome loss': 1.0776677131652832, 'Total loss': 1.0776677131652832}
2023-01-04 09:22:44,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:44,786 INFO:     Epoch: 0
2023-01-04 09:22:46,376 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7687184651692708, 'Total loss': 0.7687184651692708} | train loss {'Reaction outcome loss': 0.8350788518409866, 'Total loss': 0.8350788518409866}
2023-01-04 09:22:46,377 INFO:     Found new best model at epoch 0
2023-01-04 09:22:46,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:46,377 INFO:     Epoch: 1
2023-01-04 09:22:47,951 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6535805344581604, 'Total loss': 0.6535805344581604} | train loss {'Reaction outcome loss': 0.6796735984538866, 'Total loss': 0.6796735984538866}
2023-01-04 09:22:47,951 INFO:     Found new best model at epoch 1
2023-01-04 09:22:47,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:47,952 INFO:     Epoch: 2
2023-01-04 09:22:49,551 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5966555595397949, 'Total loss': 0.5966555595397949} | train loss {'Reaction outcome loss': 0.5782123282820739, 'Total loss': 0.5782123282820739}
2023-01-04 09:22:49,552 INFO:     Found new best model at epoch 2
2023-01-04 09:22:49,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:49,553 INFO:     Epoch: 3
2023-01-04 09:22:51,128 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5625823517640431, 'Total loss': 0.5625823517640431} | train loss {'Reaction outcome loss': 0.5443702346581414, 'Total loss': 0.5443702346581414}
2023-01-04 09:22:51,128 INFO:     Found new best model at epoch 3
2023-01-04 09:22:51,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:51,129 INFO:     Epoch: 4
2023-01-04 09:22:52,725 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5259845405817032, 'Total loss': 0.5259845405817032} | train loss {'Reaction outcome loss': 0.520390984975474, 'Total loss': 0.520390984975474}
2023-01-04 09:22:52,725 INFO:     Found new best model at epoch 4
2023-01-04 09:22:52,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:52,726 INFO:     Epoch: 5
2023-01-04 09:22:54,283 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5283124109109243, 'Total loss': 0.5283124109109243} | train loss {'Reaction outcome loss': 0.5038848490276061, 'Total loss': 0.5038848490276061}
2023-01-04 09:22:54,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:54,283 INFO:     Epoch: 6
2023-01-04 09:22:55,887 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5154987196127574, 'Total loss': 0.5154987196127574} | train loss {'Reaction outcome loss': 0.49124794391518467, 'Total loss': 0.49124794391518467}
2023-01-04 09:22:55,888 INFO:     Found new best model at epoch 6
2023-01-04 09:22:55,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:55,888 INFO:     Epoch: 7
2023-01-04 09:22:57,492 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.505402151743571, 'Total loss': 0.505402151743571} | train loss {'Reaction outcome loss': 0.48324737065750767, 'Total loss': 0.48324737065750767}
2023-01-04 09:22:57,492 INFO:     Found new best model at epoch 7
2023-01-04 09:22:57,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:57,493 INFO:     Epoch: 8
2023-01-04 09:22:59,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.516790262858073, 'Total loss': 0.516790262858073} | train loss {'Reaction outcome loss': 0.47262627623356634, 'Total loss': 0.47262627623356634}
2023-01-04 09:22:59,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:22:59,104 INFO:     Epoch: 9
2023-01-04 09:23:00,703 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4938886404037476, 'Total loss': 0.4938886404037476} | train loss {'Reaction outcome loss': 0.46860100710865393, 'Total loss': 0.46860100710865393}
2023-01-04 09:23:00,703 INFO:     Found new best model at epoch 9
2023-01-04 09:23:00,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:00,704 INFO:     Epoch: 10
2023-01-04 09:23:02,229 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5095336854457855, 'Total loss': 0.5095336854457855} | train loss {'Reaction outcome loss': 0.4617374540451201, 'Total loss': 0.4617374540451201}
2023-01-04 09:23:02,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:02,229 INFO:     Epoch: 11
2023-01-04 09:23:03,800 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4930492122968038, 'Total loss': 0.4930492122968038} | train loss {'Reaction outcome loss': 0.453387126595535, 'Total loss': 0.453387126595535}
2023-01-04 09:23:03,801 INFO:     Found new best model at epoch 11
2023-01-04 09:23:03,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:03,801 INFO:     Epoch: 12
2023-01-04 09:23:05,364 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4899959146976471, 'Total loss': 0.4899959146976471} | train loss {'Reaction outcome loss': 0.4493491726554258, 'Total loss': 0.4493491726554258}
2023-01-04 09:23:05,365 INFO:     Found new best model at epoch 12
2023-01-04 09:23:05,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:05,366 INFO:     Epoch: 13
2023-01-04 09:23:06,942 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4697303334871928, 'Total loss': 0.4697303334871928} | train loss {'Reaction outcome loss': 0.44651304013247095, 'Total loss': 0.44651304013247095}
2023-01-04 09:23:06,942 INFO:     Found new best model at epoch 13
2023-01-04 09:23:06,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:06,943 INFO:     Epoch: 14
2023-01-04 09:23:08,515 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4791152576605479, 'Total loss': 0.4791152576605479} | train loss {'Reaction outcome loss': 0.44049766482213776, 'Total loss': 0.44049766482213776}
2023-01-04 09:23:08,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:08,515 INFO:     Epoch: 15
2023-01-04 09:23:10,068 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4780303100744883, 'Total loss': 0.4780303100744883} | train loss {'Reaction outcome loss': 0.4365748924468829, 'Total loss': 0.4365748924468829}
2023-01-04 09:23:10,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:10,068 INFO:     Epoch: 16
2023-01-04 09:23:11,611 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4565502057472865, 'Total loss': 0.4565502057472865} | train loss {'Reaction outcome loss': 0.4284164211595102, 'Total loss': 0.4284164211595102}
2023-01-04 09:23:11,612 INFO:     Found new best model at epoch 16
2023-01-04 09:23:11,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:11,613 INFO:     Epoch: 17
2023-01-04 09:23:13,205 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4542246550321579, 'Total loss': 0.4542246550321579} | train loss {'Reaction outcome loss': 0.4248338136754742, 'Total loss': 0.4248338136754742}
2023-01-04 09:23:13,206 INFO:     Found new best model at epoch 17
2023-01-04 09:23:13,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:13,206 INFO:     Epoch: 18
2023-01-04 09:23:14,792 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44172346889972686, 'Total loss': 0.44172346889972686} | train loss {'Reaction outcome loss': 0.4219548712461003, 'Total loss': 0.4219548712461003}
2023-01-04 09:23:14,792 INFO:     Found new best model at epoch 18
2023-01-04 09:23:14,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:14,793 INFO:     Epoch: 19
2023-01-04 09:23:16,382 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47392531832059226, 'Total loss': 0.47392531832059226} | train loss {'Reaction outcome loss': 0.416748486109589, 'Total loss': 0.416748486109589}
2023-01-04 09:23:16,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:16,382 INFO:     Epoch: 20
2023-01-04 09:23:17,966 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4659205595652262, 'Total loss': 0.4659205595652262} | train loss {'Reaction outcome loss': 0.4135141271546429, 'Total loss': 0.4135141271546429}
2023-01-04 09:23:17,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:17,966 INFO:     Epoch: 21
2023-01-04 09:23:19,521 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4580181082089742, 'Total loss': 0.4580181082089742} | train loss {'Reaction outcome loss': 0.4069149128366463, 'Total loss': 0.4069149128366463}
2023-01-04 09:23:19,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:19,521 INFO:     Epoch: 22
2023-01-04 09:23:21,067 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44888435999552406, 'Total loss': 0.44888435999552406} | train loss {'Reaction outcome loss': 0.40834735436129654, 'Total loss': 0.40834735436129654}
2023-01-04 09:23:21,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:21,067 INFO:     Epoch: 23
2023-01-04 09:23:22,649 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43512577811876935, 'Total loss': 0.43512577811876935} | train loss {'Reaction outcome loss': 0.4010728229415546, 'Total loss': 0.4010728229415546}
2023-01-04 09:23:22,649 INFO:     Found new best model at epoch 23
2023-01-04 09:23:22,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:22,650 INFO:     Epoch: 24
2023-01-04 09:23:24,237 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43491249283154804, 'Total loss': 0.43491249283154804} | train loss {'Reaction outcome loss': 0.39855427518218, 'Total loss': 0.39855427518218}
2023-01-04 09:23:24,238 INFO:     Found new best model at epoch 24
2023-01-04 09:23:24,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:24,238 INFO:     Epoch: 25
2023-01-04 09:23:25,840 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4464745899041494, 'Total loss': 0.4464745899041494} | train loss {'Reaction outcome loss': 0.3937844853538899, 'Total loss': 0.3937844853538899}
2023-01-04 09:23:25,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:25,840 INFO:     Epoch: 26
2023-01-04 09:23:27,402 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45261843005816144, 'Total loss': 0.45261843005816144} | train loss {'Reaction outcome loss': 0.3887183959410939, 'Total loss': 0.3887183959410939}
2023-01-04 09:23:27,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:27,403 INFO:     Epoch: 27
2023-01-04 09:23:28,985 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4458698203166326, 'Total loss': 0.4458698203166326} | train loss {'Reaction outcome loss': 0.3897503084546822, 'Total loss': 0.3897503084546822}
2023-01-04 09:23:28,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:28,985 INFO:     Epoch: 28
2023-01-04 09:23:30,503 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4318542679150899, 'Total loss': 0.4318542679150899} | train loss {'Reaction outcome loss': 0.3822311761146848, 'Total loss': 0.3822311761146848}
2023-01-04 09:23:30,504 INFO:     Found new best model at epoch 28
2023-01-04 09:23:30,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:30,504 INFO:     Epoch: 29
2023-01-04 09:23:32,067 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44840958615144094, 'Total loss': 0.44840958615144094} | train loss {'Reaction outcome loss': 0.37987615800183605, 'Total loss': 0.37987615800183605}
2023-01-04 09:23:32,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:32,068 INFO:     Epoch: 30
2023-01-04 09:23:33,629 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44887122412522634, 'Total loss': 0.44887122412522634} | train loss {'Reaction outcome loss': 0.3757323255554003, 'Total loss': 0.3757323255554003}
2023-01-04 09:23:33,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:33,629 INFO:     Epoch: 31
2023-01-04 09:23:35,177 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46101583043734234, 'Total loss': 0.46101583043734234} | train loss {'Reaction outcome loss': 0.36891735256363767, 'Total loss': 0.36891735256363767}
2023-01-04 09:23:35,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:35,177 INFO:     Epoch: 32
2023-01-04 09:23:36,705 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43855008284250896, 'Total loss': 0.43855008284250896} | train loss {'Reaction outcome loss': 0.3691093627403789, 'Total loss': 0.3691093627403789}
2023-01-04 09:23:36,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:36,707 INFO:     Epoch: 33
2023-01-04 09:23:38,250 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4416138599316279, 'Total loss': 0.4416138599316279} | train loss {'Reaction outcome loss': 0.3654245392617766, 'Total loss': 0.3654245392617766}
2023-01-04 09:23:38,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:38,250 INFO:     Epoch: 34
2023-01-04 09:23:39,808 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4442679266134898, 'Total loss': 0.4442679266134898} | train loss {'Reaction outcome loss': 0.36334743910210227, 'Total loss': 0.36334743910210227}
2023-01-04 09:23:39,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:39,808 INFO:     Epoch: 35
2023-01-04 09:23:41,376 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4408619542916616, 'Total loss': 0.4408619542916616} | train loss {'Reaction outcome loss': 0.35893116864486724, 'Total loss': 0.35893116864486724}
2023-01-04 09:23:41,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:41,376 INFO:     Epoch: 36
2023-01-04 09:23:42,927 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45122571190198263, 'Total loss': 0.45122571190198263} | train loss {'Reaction outcome loss': 0.35579178624850316, 'Total loss': 0.35579178624850316}
2023-01-04 09:23:42,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:42,928 INFO:     Epoch: 37
2023-01-04 09:23:44,490 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44196645816167196, 'Total loss': 0.44196645816167196} | train loss {'Reaction outcome loss': 0.35493213296044174, 'Total loss': 0.35493213296044174}
2023-01-04 09:23:44,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:44,490 INFO:     Epoch: 38
2023-01-04 09:23:46,011 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4588399350643158, 'Total loss': 0.4588399350643158} | train loss {'Reaction outcome loss': 0.3491252145666078, 'Total loss': 0.3491252145666078}
2023-01-04 09:23:46,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:46,011 INFO:     Epoch: 39
2023-01-04 09:23:47,514 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45547438561916354, 'Total loss': 0.45547438561916354} | train loss {'Reaction outcome loss': 0.34907739539546656, 'Total loss': 0.34907739539546656}
2023-01-04 09:23:47,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:47,514 INFO:     Epoch: 40
2023-01-04 09:23:49,102 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4257255474726359, 'Total loss': 0.4257255474726359} | train loss {'Reaction outcome loss': 0.3428948861597247, 'Total loss': 0.3428948861597247}
2023-01-04 09:23:49,102 INFO:     Found new best model at epoch 40
2023-01-04 09:23:49,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:49,103 INFO:     Epoch: 41
2023-01-04 09:23:50,669 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4494813839594523, 'Total loss': 0.4494813839594523} | train loss {'Reaction outcome loss': 0.34259854663257566, 'Total loss': 0.34259854663257566}
2023-01-04 09:23:50,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:50,669 INFO:     Epoch: 42
2023-01-04 09:23:52,231 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41132813493410747, 'Total loss': 0.41132813493410747} | train loss {'Reaction outcome loss': 0.3366498407850627, 'Total loss': 0.3366498407850627}
2023-01-04 09:23:52,231 INFO:     Found new best model at epoch 42
2023-01-04 09:23:52,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:52,232 INFO:     Epoch: 43
2023-01-04 09:23:53,794 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4431600471337636, 'Total loss': 0.4431600471337636} | train loss {'Reaction outcome loss': 0.3340436381553485, 'Total loss': 0.3340436381553485}
2023-01-04 09:23:53,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:53,794 INFO:     Epoch: 44
2023-01-04 09:23:55,328 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45144448479016624, 'Total loss': 0.45144448479016624} | train loss {'Reaction outcome loss': 0.33338446842526703, 'Total loss': 0.33338446842526703}
2023-01-04 09:23:55,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:55,329 INFO:     Epoch: 45
2023-01-04 09:23:56,870 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4027316028873126, 'Total loss': 0.4027316028873126} | train loss {'Reaction outcome loss': 0.3328954884345351, 'Total loss': 0.3328954884345351}
2023-01-04 09:23:56,870 INFO:     Found new best model at epoch 45
2023-01-04 09:23:56,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:56,871 INFO:     Epoch: 46
2023-01-04 09:23:58,445 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4250300188859304, 'Total loss': 0.4250300188859304} | train loss {'Reaction outcome loss': 0.33003758265223315, 'Total loss': 0.33003758265223315}
2023-01-04 09:23:58,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:23:58,445 INFO:     Epoch: 47
2023-01-04 09:24:00,047 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46134752134482065, 'Total loss': 0.46134752134482065} | train loss {'Reaction outcome loss': 0.32862705855700947, 'Total loss': 0.32862705855700947}
2023-01-04 09:24:00,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:00,047 INFO:     Epoch: 48
2023-01-04 09:24:01,603 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42047070562839506, 'Total loss': 0.42047070562839506} | train loss {'Reaction outcome loss': 0.31936758958368094, 'Total loss': 0.31936758958368094}
2023-01-04 09:24:01,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:01,604 INFO:     Epoch: 49
2023-01-04 09:24:03,158 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41281672517458595, 'Total loss': 0.41281672517458595} | train loss {'Reaction outcome loss': 0.32288896956813895, 'Total loss': 0.32288896956813895}
2023-01-04 09:24:03,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:03,158 INFO:     Epoch: 50
2023-01-04 09:24:04,688 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43236895004908243, 'Total loss': 0.43236895004908243} | train loss {'Reaction outcome loss': 0.3195020704923554, 'Total loss': 0.3195020704923554}
2023-01-04 09:24:04,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:04,688 INFO:     Epoch: 51
2023-01-04 09:24:06,214 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4471508165200551, 'Total loss': 0.4471508165200551} | train loss {'Reaction outcome loss': 0.31866767940646046, 'Total loss': 0.31866767940646046}
2023-01-04 09:24:06,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:06,215 INFO:     Epoch: 52
2023-01-04 09:24:07,772 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42931817670663197, 'Total loss': 0.42931817670663197} | train loss {'Reaction outcome loss': 0.3170684967660732, 'Total loss': 0.3170684967660732}
2023-01-04 09:24:07,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:07,772 INFO:     Epoch: 53
2023-01-04 09:24:09,336 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.442927411198616, 'Total loss': 0.442927411198616} | train loss {'Reaction outcome loss': 0.3123939250350429, 'Total loss': 0.3123939250350429}
2023-01-04 09:24:09,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:09,336 INFO:     Epoch: 54
2023-01-04 09:24:10,899 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43008332947889966, 'Total loss': 0.43008332947889966} | train loss {'Reaction outcome loss': 0.3128554554192168, 'Total loss': 0.3128554554192168}
2023-01-04 09:24:10,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:10,900 INFO:     Epoch: 55
2023-01-04 09:24:12,471 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4363838901122411, 'Total loss': 0.4363838901122411} | train loss {'Reaction outcome loss': 0.3067439608410377, 'Total loss': 0.3067439608410377}
2023-01-04 09:24:12,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:12,472 INFO:     Epoch: 56
2023-01-04 09:24:14,030 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41949601570765177, 'Total loss': 0.41949601570765177} | train loss {'Reaction outcome loss': 0.311922953985228, 'Total loss': 0.311922953985228}
2023-01-04 09:24:14,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:14,031 INFO:     Epoch: 57
2023-01-04 09:24:15,559 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45092906852563225, 'Total loss': 0.45092906852563225} | train loss {'Reaction outcome loss': 0.3049048469116111, 'Total loss': 0.3049048469116111}
2023-01-04 09:24:15,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:15,559 INFO:     Epoch: 58
2023-01-04 09:24:17,136 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4104013492663701, 'Total loss': 0.4104013492663701} | train loss {'Reaction outcome loss': 0.304705755025256, 'Total loss': 0.304705755025256}
2023-01-04 09:24:17,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:17,136 INFO:     Epoch: 59
2023-01-04 09:24:18,706 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.425920636455218, 'Total loss': 0.425920636455218} | train loss {'Reaction outcome loss': 0.30174395041237667, 'Total loss': 0.30174395041237667}
2023-01-04 09:24:18,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:18,706 INFO:     Epoch: 60
2023-01-04 09:24:20,275 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.431305847565333, 'Total loss': 0.431305847565333} | train loss {'Reaction outcome loss': 0.29585841669287494, 'Total loss': 0.29585841669287494}
2023-01-04 09:24:20,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:20,275 INFO:     Epoch: 61
2023-01-04 09:24:21,811 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.435663648446401, 'Total loss': 0.435663648446401} | train loss {'Reaction outcome loss': 0.30018327382497406, 'Total loss': 0.30018327382497406}
2023-01-04 09:24:21,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:21,812 INFO:     Epoch: 62
2023-01-04 09:24:23,385 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40975177685419717, 'Total loss': 0.40975177685419717} | train loss {'Reaction outcome loss': 0.2951657192694151, 'Total loss': 0.2951657192694151}
2023-01-04 09:24:23,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:23,385 INFO:     Epoch: 63
2023-01-04 09:24:24,924 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3979725251595179, 'Total loss': 0.3979725251595179} | train loss {'Reaction outcome loss': 0.2939371645235413, 'Total loss': 0.2939371645235413}
2023-01-04 09:24:24,924 INFO:     Found new best model at epoch 63
2023-01-04 09:24:24,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:24,925 INFO:     Epoch: 64
2023-01-04 09:24:26,472 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41619510650634767, 'Total loss': 0.41619510650634767} | train loss {'Reaction outcome loss': 0.2926952438395376, 'Total loss': 0.2926952438395376}
2023-01-04 09:24:26,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:26,473 INFO:     Epoch: 65
2023-01-04 09:24:28,023 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4332230508327484, 'Total loss': 0.4332230508327484} | train loss {'Reaction outcome loss': 0.2911983912118075, 'Total loss': 0.2911983912118075}
2023-01-04 09:24:28,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:28,023 INFO:     Epoch: 66
2023-01-04 09:24:29,604 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42684733072916664, 'Total loss': 0.42684733072916664} | train loss {'Reaction outcome loss': 0.28947347730720946, 'Total loss': 0.28947347730720946}
2023-01-04 09:24:29,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:29,604 INFO:     Epoch: 67
2023-01-04 09:24:31,155 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4197827398777008, 'Total loss': 0.4197827398777008} | train loss {'Reaction outcome loss': 0.2832559687001395, 'Total loss': 0.2832559687001395}
2023-01-04 09:24:31,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:31,156 INFO:     Epoch: 68
2023-01-04 09:24:32,705 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45310672322909035, 'Total loss': 0.45310672322909035} | train loss {'Reaction outcome loss': 0.2861262325614368, 'Total loss': 0.2861262325614368}
2023-01-04 09:24:32,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:32,706 INFO:     Epoch: 69
2023-01-04 09:24:34,290 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43424964348475137, 'Total loss': 0.43424964348475137} | train loss {'Reaction outcome loss': 0.2860173772657391, 'Total loss': 0.2860173772657391}
2023-01-04 09:24:34,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:34,291 INFO:     Epoch: 70
2023-01-04 09:24:35,861 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4132784277200699, 'Total loss': 0.4132784277200699} | train loss {'Reaction outcome loss': 0.2860445339595798, 'Total loss': 0.2860445339595798}
2023-01-04 09:24:35,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:35,862 INFO:     Epoch: 71
2023-01-04 09:24:37,443 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4322268724441528, 'Total loss': 0.4322268724441528} | train loss {'Reaction outcome loss': 0.28030185491545967, 'Total loss': 0.28030185491545967}
2023-01-04 09:24:37,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:37,443 INFO:     Epoch: 72
2023-01-04 09:24:39,027 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42612509926160175, 'Total loss': 0.42612509926160175} | train loss {'Reaction outcome loss': 0.2778603246818811, 'Total loss': 0.2778603246818811}
2023-01-04 09:24:39,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:39,027 INFO:     Epoch: 73
2023-01-04 09:24:40,571 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4371127297480901, 'Total loss': 0.4371127297480901} | train loss {'Reaction outcome loss': 0.2816716962719222, 'Total loss': 0.2816716962719222}
2023-01-04 09:24:40,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:40,571 INFO:     Epoch: 74
2023-01-04 09:24:42,116 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.434102996190389, 'Total loss': 0.434102996190389} | train loss {'Reaction outcome loss': 0.2783238563942135, 'Total loss': 0.2783238563942135}
2023-01-04 09:24:42,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:42,117 INFO:     Epoch: 75
2023-01-04 09:24:43,691 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40946679512659706, 'Total loss': 0.40946679512659706} | train loss {'Reaction outcome loss': 0.2755738144962366, 'Total loss': 0.2755738144962366}
2023-01-04 09:24:43,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:43,692 INFO:     Epoch: 76
2023-01-04 09:24:45,278 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4171152671178182, 'Total loss': 0.4171152671178182} | train loss {'Reaction outcome loss': 0.27579097564093474, 'Total loss': 0.27579097564093474}
2023-01-04 09:24:45,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:45,278 INFO:     Epoch: 77
2023-01-04 09:24:46,845 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43943795760472615, 'Total loss': 0.43943795760472615} | train loss {'Reaction outcome loss': 0.2740808795021329, 'Total loss': 0.2740808795021329}
2023-01-04 09:24:46,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:46,846 INFO:     Epoch: 78
2023-01-04 09:24:48,422 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43897310495376585, 'Total loss': 0.43897310495376585} | train loss {'Reaction outcome loss': 0.272314062980861, 'Total loss': 0.272314062980861}
2023-01-04 09:24:48,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:48,423 INFO:     Epoch: 79
2023-01-04 09:24:49,961 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40394752522309624, 'Total loss': 0.40394752522309624} | train loss {'Reaction outcome loss': 0.2741681073224071, 'Total loss': 0.2741681073224071}
2023-01-04 09:24:49,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:49,961 INFO:     Epoch: 80
2023-01-04 09:24:51,497 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41026200652122496, 'Total loss': 0.41026200652122496} | train loss {'Reaction outcome loss': 0.2728792379479116, 'Total loss': 0.2728792379479116}
2023-01-04 09:24:51,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:51,498 INFO:     Epoch: 81
2023-01-04 09:24:53,095 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4145939429601034, 'Total loss': 0.4145939429601034} | train loss {'Reaction outcome loss': 0.27001555912223535, 'Total loss': 0.27001555912223535}
2023-01-04 09:24:53,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:53,095 INFO:     Epoch: 82
2023-01-04 09:24:54,712 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42271455824375154, 'Total loss': 0.42271455824375154} | train loss {'Reaction outcome loss': 0.2727655549718585, 'Total loss': 0.2727655549718585}
2023-01-04 09:24:54,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:54,713 INFO:     Epoch: 83
2023-01-04 09:24:56,332 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42774418592453, 'Total loss': 0.42774418592453} | train loss {'Reaction outcome loss': 0.2656137231024594, 'Total loss': 0.2656137231024594}
2023-01-04 09:24:56,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:56,333 INFO:     Epoch: 84
2023-01-04 09:24:57,956 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42974969347318015, 'Total loss': 0.42974969347318015} | train loss {'Reaction outcome loss': 0.26962350797082973, 'Total loss': 0.26962350797082973}
2023-01-04 09:24:57,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:57,956 INFO:     Epoch: 85
2023-01-04 09:24:59,492 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3845811516046524, 'Total loss': 0.3845811516046524} | train loss {'Reaction outcome loss': 0.2690449872655989, 'Total loss': 0.2690449872655989}
2023-01-04 09:24:59,492 INFO:     Found new best model at epoch 85
2023-01-04 09:24:59,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:24:59,493 INFO:     Epoch: 86
2023-01-04 09:25:01,028 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3956035127242406, 'Total loss': 0.3956035127242406} | train loss {'Reaction outcome loss': 0.2641359631927005, 'Total loss': 0.2641359631927005}
2023-01-04 09:25:01,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:01,028 INFO:     Epoch: 87
2023-01-04 09:25:02,583 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4118631641070048, 'Total loss': 0.4118631641070048} | train loss {'Reaction outcome loss': 0.2633906269331701, 'Total loss': 0.2633906269331701}
2023-01-04 09:25:02,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:02,584 INFO:     Epoch: 88
2023-01-04 09:25:04,144 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4286978721618652, 'Total loss': 0.4286978721618652} | train loss {'Reaction outcome loss': 0.26238616262747494, 'Total loss': 0.26238616262747494}
2023-01-04 09:25:04,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:04,144 INFO:     Epoch: 89
2023-01-04 09:25:05,707 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41376838882764183, 'Total loss': 0.41376838882764183} | train loss {'Reaction outcome loss': 0.26306053041228317, 'Total loss': 0.26306053041228317}
2023-01-04 09:25:05,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:05,708 INFO:     Epoch: 90
2023-01-04 09:25:07,259 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3965530107418696, 'Total loss': 0.3965530107418696} | train loss {'Reaction outcome loss': 0.2602226502305764, 'Total loss': 0.2602226502305764}
2023-01-04 09:25:07,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:07,260 INFO:     Epoch: 91
2023-01-04 09:25:08,817 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42269574105739594, 'Total loss': 0.42269574105739594} | train loss {'Reaction outcome loss': 0.26228060056909325, 'Total loss': 0.26228060056909325}
2023-01-04 09:25:08,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:08,817 INFO:     Epoch: 92
2023-01-04 09:25:10,357 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.387572368979454, 'Total loss': 0.387572368979454} | train loss {'Reaction outcome loss': 0.2635056375112344, 'Total loss': 0.2635056375112344}
2023-01-04 09:25:10,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:10,357 INFO:     Epoch: 93
2023-01-04 09:25:11,933 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4138631562391917, 'Total loss': 0.4138631562391917} | train loss {'Reaction outcome loss': 0.2588083648025344, 'Total loss': 0.2588083648025344}
2023-01-04 09:25:11,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:11,933 INFO:     Epoch: 94
2023-01-04 09:25:13,506 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4322587569554647, 'Total loss': 0.4322587569554647} | train loss {'Reaction outcome loss': 0.26088384872416726, 'Total loss': 0.26088384872416726}
2023-01-04 09:25:13,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:13,506 INFO:     Epoch: 95
2023-01-04 09:25:15,089 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4167849401632945, 'Total loss': 0.4167849401632945} | train loss {'Reaction outcome loss': 0.25978879365626223, 'Total loss': 0.25978879365626223}
2023-01-04 09:25:15,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:15,089 INFO:     Epoch: 96
2023-01-04 09:25:16,639 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43974789381027224, 'Total loss': 0.43974789381027224} | train loss {'Reaction outcome loss': 0.2573665285967156, 'Total loss': 0.2573665285967156}
2023-01-04 09:25:16,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:16,639 INFO:     Epoch: 97
2023-01-04 09:25:18,213 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42524489561716716, 'Total loss': 0.42524489561716716} | train loss {'Reaction outcome loss': 0.25134712807323095, 'Total loss': 0.25134712807323095}
2023-01-04 09:25:18,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:18,213 INFO:     Epoch: 98
2023-01-04 09:25:19,785 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4131830036640167, 'Total loss': 0.4131830036640167} | train loss {'Reaction outcome loss': 0.2542282827332992, 'Total loss': 0.2542282827332992}
2023-01-04 09:25:19,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:19,785 INFO:     Epoch: 99
2023-01-04 09:25:21,372 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3900724912683169, 'Total loss': 0.3900724912683169} | train loss {'Reaction outcome loss': 0.2542416515763486, 'Total loss': 0.2542416515763486}
2023-01-04 09:25:21,372 INFO:     Best model found after epoch 86 of 100.
2023-01-04 09:25:21,372 INFO:   Done with stage: TRAINING
2023-01-04 09:25:21,372 INFO:   Starting stage: EVALUATION
2023-01-04 09:25:21,496 INFO:   Done with stage: EVALUATION
2023-01-04 09:25:21,496 INFO:   Leaving out SEQ value Fold_8
2023-01-04 09:25:21,509 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 09:25:21,509 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:25:22,146 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:25:22,146 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:25:22,212 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:25:22,213 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:25:22,213 INFO:     No hyperparam tuning for this model
2023-01-04 09:25:22,213 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:25:22,213 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:25:22,213 INFO:     None feature selector for col prot
2023-01-04 09:25:22,214 INFO:     None feature selector for col prot
2023-01-04 09:25:22,214 INFO:     None feature selector for col prot
2023-01-04 09:25:22,214 INFO:     None feature selector for col chem
2023-01-04 09:25:22,214 INFO:     None feature selector for col chem
2023-01-04 09:25:22,214 INFO:     None feature selector for col chem
2023-01-04 09:25:22,214 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:25:22,214 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:25:22,215 INFO:     Number of params in model 70111
2023-01-04 09:25:22,219 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:25:22,219 INFO:   Starting stage: TRAINING
2023-01-04 09:25:22,262 INFO:     Val loss before train {'Reaction outcome loss': 1.0625384370485942, 'Total loss': 1.0625384370485942}
2023-01-04 09:25:22,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:22,262 INFO:     Epoch: 0
2023-01-04 09:25:23,805 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7735255738099416, 'Total loss': 0.7735255738099416} | train loss {'Reaction outcome loss': 0.8215843522068345, 'Total loss': 0.8215843522068345}
2023-01-04 09:25:23,806 INFO:     Found new best model at epoch 0
2023-01-04 09:25:23,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:23,807 INFO:     Epoch: 1
2023-01-04 09:25:25,325 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6421962300936381, 'Total loss': 0.6421962300936381} | train loss {'Reaction outcome loss': 0.6628239558729934, 'Total loss': 0.6628239558729934}
2023-01-04 09:25:25,325 INFO:     Found new best model at epoch 1
2023-01-04 09:25:25,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:25,326 INFO:     Epoch: 2
2023-01-04 09:25:26,855 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5393890122572581, 'Total loss': 0.5393890122572581} | train loss {'Reaction outcome loss': 0.5713582972248832, 'Total loss': 0.5713582972248832}
2023-01-04 09:25:26,855 INFO:     Found new best model at epoch 2
2023-01-04 09:25:26,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:26,856 INFO:     Epoch: 3
2023-01-04 09:25:28,393 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5217248678207398, 'Total loss': 0.5217248678207398} | train loss {'Reaction outcome loss': 0.5288538293087439, 'Total loss': 0.5288538293087439}
2023-01-04 09:25:28,394 INFO:     Found new best model at epoch 3
2023-01-04 09:25:28,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:28,394 INFO:     Epoch: 4
2023-01-04 09:25:29,936 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.514146359761556, 'Total loss': 0.514146359761556} | train loss {'Reaction outcome loss': 0.5127459317991585, 'Total loss': 0.5127459317991585}
2023-01-04 09:25:29,937 INFO:     Found new best model at epoch 4
2023-01-04 09:25:29,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:29,938 INFO:     Epoch: 5
2023-01-04 09:25:31,477 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5062143454949061, 'Total loss': 0.5062143454949061} | train loss {'Reaction outcome loss': 0.4989068934441486, 'Total loss': 0.4989068934441486}
2023-01-04 09:25:31,477 INFO:     Found new best model at epoch 5
2023-01-04 09:25:31,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:31,478 INFO:     Epoch: 6
2023-01-04 09:25:33,008 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4795765459537506, 'Total loss': 0.4795765459537506} | train loss {'Reaction outcome loss': 0.48710187308954234, 'Total loss': 0.48710187308954234}
2023-01-04 09:25:33,009 INFO:     Found new best model at epoch 6
2023-01-04 09:25:33,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:33,009 INFO:     Epoch: 7
2023-01-04 09:25:34,513 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45903694530328115, 'Total loss': 0.45903694530328115} | train loss {'Reaction outcome loss': 0.4784638661167997, 'Total loss': 0.4784638661167997}
2023-01-04 09:25:34,513 INFO:     Found new best model at epoch 7
2023-01-04 09:25:34,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:34,514 INFO:     Epoch: 8
2023-01-04 09:25:36,037 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49027484059333803, 'Total loss': 0.49027484059333803} | train loss {'Reaction outcome loss': 0.4708389309081402, 'Total loss': 0.4708389309081402}
2023-01-04 09:25:36,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:36,038 INFO:     Epoch: 9
2023-01-04 09:25:37,583 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45611450672149656, 'Total loss': 0.45611450672149656} | train loss {'Reaction outcome loss': 0.46705257210321044, 'Total loss': 0.46705257210321044}
2023-01-04 09:25:37,583 INFO:     Found new best model at epoch 9
2023-01-04 09:25:37,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:37,584 INFO:     Epoch: 10
2023-01-04 09:25:39,144 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4638756692409515, 'Total loss': 0.4638756692409515} | train loss {'Reaction outcome loss': 0.4600629837085039, 'Total loss': 0.4600629837085039}
2023-01-04 09:25:39,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:39,145 INFO:     Epoch: 11
2023-01-04 09:25:40,675 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4755726387103399, 'Total loss': 0.4755726387103399} | train loss {'Reaction outcome loss': 0.45189434895803643, 'Total loss': 0.45189434895803643}
2023-01-04 09:25:40,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:40,676 INFO:     Epoch: 12
2023-01-04 09:25:42,225 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.455364457766215, 'Total loss': 0.455364457766215} | train loss {'Reaction outcome loss': 0.4489208202222328, 'Total loss': 0.4489208202222328}
2023-01-04 09:25:42,226 INFO:     Found new best model at epoch 12
2023-01-04 09:25:42,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:42,227 INFO:     Epoch: 13
2023-01-04 09:25:43,754 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44590335090955097, 'Total loss': 0.44590335090955097} | train loss {'Reaction outcome loss': 0.4449753914396841, 'Total loss': 0.4449753914396841}
2023-01-04 09:25:43,754 INFO:     Found new best model at epoch 13
2023-01-04 09:25:43,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:43,755 INFO:     Epoch: 14
2023-01-04 09:25:45,268 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45790116985638935, 'Total loss': 0.45790116985638935} | train loss {'Reaction outcome loss': 0.44384098031145314, 'Total loss': 0.44384098031145314}
2023-01-04 09:25:45,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:45,268 INFO:     Epoch: 15
2023-01-04 09:25:46,819 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44222248196601865, 'Total loss': 0.44222248196601865} | train loss {'Reaction outcome loss': 0.43285592184180305, 'Total loss': 0.43285592184180305}
2023-01-04 09:25:46,819 INFO:     Found new best model at epoch 15
2023-01-04 09:25:46,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:46,820 INFO:     Epoch: 16
2023-01-04 09:25:48,377 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4527240912119547, 'Total loss': 0.4527240912119547} | train loss {'Reaction outcome loss': 0.43256023886439565, 'Total loss': 0.43256023886439565}
2023-01-04 09:25:48,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:48,377 INFO:     Epoch: 17
2023-01-04 09:25:49,913 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4360166728496552, 'Total loss': 0.4360166728496552} | train loss {'Reaction outcome loss': 0.42733056930613605, 'Total loss': 0.42733056930613605}
2023-01-04 09:25:49,913 INFO:     Found new best model at epoch 17
2023-01-04 09:25:49,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:49,914 INFO:     Epoch: 18
2023-01-04 09:25:51,456 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4432918310165405, 'Total loss': 0.4432918310165405} | train loss {'Reaction outcome loss': 0.42303345720846575, 'Total loss': 0.42303345720846575}
2023-01-04 09:25:51,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:51,456 INFO:     Epoch: 19
2023-01-04 09:25:52,997 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4312465488910675, 'Total loss': 0.4312465488910675} | train loss {'Reaction outcome loss': 0.4226093739816994, 'Total loss': 0.4226093739816994}
2023-01-04 09:25:52,997 INFO:     Found new best model at epoch 19
2023-01-04 09:25:52,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:52,998 INFO:     Epoch: 20
2023-01-04 09:25:54,546 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4300473203261693, 'Total loss': 0.4300473203261693} | train loss {'Reaction outcome loss': 0.41120746376968564, 'Total loss': 0.41120746376968564}
2023-01-04 09:25:54,547 INFO:     Found new best model at epoch 20
2023-01-04 09:25:54,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:54,548 INFO:     Epoch: 21
2023-01-04 09:25:56,130 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4312508225440979, 'Total loss': 0.4312508225440979} | train loss {'Reaction outcome loss': 0.41746238114196305, 'Total loss': 0.41746238114196305}
2023-01-04 09:25:56,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:56,131 INFO:     Epoch: 22
2023-01-04 09:25:57,699 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4231032520532608, 'Total loss': 0.4231032520532608} | train loss {'Reaction outcome loss': 0.4093890869137132, 'Total loss': 0.4093890869137132}
2023-01-04 09:25:57,699 INFO:     Found new best model at epoch 22
2023-01-04 09:25:57,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:57,699 INFO:     Epoch: 23
2023-01-04 09:25:59,268 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43408558567365013, 'Total loss': 0.43408558567365013} | train loss {'Reaction outcome loss': 0.4035727744137411, 'Total loss': 0.4035727744137411}
2023-01-04 09:25:59,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:25:59,268 INFO:     Epoch: 24
2023-01-04 09:26:00,870 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42189558148384093, 'Total loss': 0.42189558148384093} | train loss {'Reaction outcome loss': 0.3984462067266524, 'Total loss': 0.3984462067266524}
2023-01-04 09:26:00,871 INFO:     Found new best model at epoch 24
2023-01-04 09:26:00,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:00,872 INFO:     Epoch: 25
2023-01-04 09:26:02,445 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4009427393476168, 'Total loss': 0.4009427393476168} | train loss {'Reaction outcome loss': 0.3934861365910415, 'Total loss': 0.3934861365910415}
2023-01-04 09:26:02,445 INFO:     Found new best model at epoch 25
2023-01-04 09:26:02,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:02,446 INFO:     Epoch: 26
2023-01-04 09:26:03,993 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43011588652928673, 'Total loss': 0.43011588652928673} | train loss {'Reaction outcome loss': 0.39146975321429117, 'Total loss': 0.39146975321429117}
2023-01-04 09:26:03,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:03,993 INFO:     Epoch: 27
2023-01-04 09:26:05,608 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4373816877603531, 'Total loss': 0.4373816877603531} | train loss {'Reaction outcome loss': 0.39184966344973104, 'Total loss': 0.39184966344973104}
2023-01-04 09:26:05,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:05,608 INFO:     Epoch: 28
2023-01-04 09:26:07,218 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4172483046849569, 'Total loss': 0.4172483046849569} | train loss {'Reaction outcome loss': 0.3824095166537351, 'Total loss': 0.3824095166537351}
2023-01-04 09:26:07,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:07,218 INFO:     Epoch: 29
2023-01-04 09:26:08,818 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40689800878365834, 'Total loss': 0.40689800878365834} | train loss {'Reaction outcome loss': 0.38412297053105665, 'Total loss': 0.38412297053105665}
2023-01-04 09:26:08,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:08,818 INFO:     Epoch: 30
2023-01-04 09:26:10,411 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40609420438607535, 'Total loss': 0.40609420438607535} | train loss {'Reaction outcome loss': 0.37666264741302846, 'Total loss': 0.37666264741302846}
2023-01-04 09:26:10,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:10,411 INFO:     Epoch: 31
2023-01-04 09:26:11,990 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40004314879576364, 'Total loss': 0.40004314879576364} | train loss {'Reaction outcome loss': 0.38010928670674454, 'Total loss': 0.38010928670674454}
2023-01-04 09:26:11,990 INFO:     Found new best model at epoch 31
2023-01-04 09:26:11,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:11,991 INFO:     Epoch: 32
2023-01-04 09:26:13,524 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40671449999014536, 'Total loss': 0.40671449999014536} | train loss {'Reaction outcome loss': 0.3694298811830007, 'Total loss': 0.3694298811830007}
2023-01-04 09:26:13,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:13,525 INFO:     Epoch: 33
2023-01-04 09:26:15,095 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3912410775820414, 'Total loss': 0.3912410775820414} | train loss {'Reaction outcome loss': 0.3644019118868388, 'Total loss': 0.3644019118868388}
2023-01-04 09:26:15,095 INFO:     Found new best model at epoch 33
2023-01-04 09:26:15,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:15,096 INFO:     Epoch: 34
2023-01-04 09:26:16,641 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38931479056676227, 'Total loss': 0.38931479056676227} | train loss {'Reaction outcome loss': 0.36486555485825833, 'Total loss': 0.36486555485825833}
2023-01-04 09:26:16,641 INFO:     Found new best model at epoch 34
2023-01-04 09:26:16,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:16,642 INFO:     Epoch: 35
2023-01-04 09:26:18,181 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41399754186471305, 'Total loss': 0.41399754186471305} | train loss {'Reaction outcome loss': 0.3607409665490681, 'Total loss': 0.3607409665490681}
2023-01-04 09:26:18,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:18,181 INFO:     Epoch: 36
2023-01-04 09:26:19,698 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3783475379149119, 'Total loss': 0.3783475379149119} | train loss {'Reaction outcome loss': 0.35960849824842517, 'Total loss': 0.35960849824842517}
2023-01-04 09:26:19,698 INFO:     Found new best model at epoch 36
2023-01-04 09:26:19,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:19,699 INFO:     Epoch: 37
2023-01-04 09:26:21,236 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4122425486644109, 'Total loss': 0.4122425486644109} | train loss {'Reaction outcome loss': 0.3548459998799331, 'Total loss': 0.3548459998799331}
2023-01-04 09:26:21,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:21,236 INFO:     Epoch: 38
2023-01-04 09:26:22,749 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38854684829711916, 'Total loss': 0.38854684829711916} | train loss {'Reaction outcome loss': 0.3519372245767614, 'Total loss': 0.3519372245767614}
2023-01-04 09:26:22,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:22,750 INFO:     Epoch: 39
2023-01-04 09:26:24,273 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3933399021625519, 'Total loss': 0.3933399021625519} | train loss {'Reaction outcome loss': 0.3519735787432272, 'Total loss': 0.3519735787432272}
2023-01-04 09:26:24,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:24,273 INFO:     Epoch: 40
2023-01-04 09:26:25,823 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37870575388272604, 'Total loss': 0.37870575388272604} | train loss {'Reaction outcome loss': 0.3512031914113642, 'Total loss': 0.3512031914113642}
2023-01-04 09:26:25,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:25,823 INFO:     Epoch: 41
2023-01-04 09:26:27,392 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3659309426943461, 'Total loss': 0.3659309426943461} | train loss {'Reaction outcome loss': 0.34329154017644053, 'Total loss': 0.34329154017644053}
2023-01-04 09:26:27,392 INFO:     Found new best model at epoch 41
2023-01-04 09:26:27,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:27,392 INFO:     Epoch: 42
2023-01-04 09:26:28,910 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3806617736816406, 'Total loss': 0.3806617736816406} | train loss {'Reaction outcome loss': 0.3463886674670946, 'Total loss': 0.3463886674670946}
2023-01-04 09:26:28,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:28,910 INFO:     Epoch: 43
2023-01-04 09:26:30,445 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39028868774573006, 'Total loss': 0.39028868774573006} | train loss {'Reaction outcome loss': 0.34098666825846874, 'Total loss': 0.34098666825846874}
2023-01-04 09:26:30,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:30,447 INFO:     Epoch: 44
2023-01-04 09:26:31,965 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38973391652107237, 'Total loss': 0.38973391652107237} | train loss {'Reaction outcome loss': 0.34085257645464423, 'Total loss': 0.34085257645464423}
2023-01-04 09:26:31,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:31,965 INFO:     Epoch: 45
2023-01-04 09:26:33,509 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3612679859002431, 'Total loss': 0.3612679859002431} | train loss {'Reaction outcome loss': 0.3358037118346263, 'Total loss': 0.3358037118346263}
2023-01-04 09:26:33,509 INFO:     Found new best model at epoch 45
2023-01-04 09:26:33,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:33,510 INFO:     Epoch: 46
2023-01-04 09:26:35,042 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35954615771770476, 'Total loss': 0.35954615771770476} | train loss {'Reaction outcome loss': 0.3326622505054806, 'Total loss': 0.3326622505054806}
2023-01-04 09:26:35,042 INFO:     Found new best model at epoch 46
2023-01-04 09:26:35,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:35,043 INFO:     Epoch: 47
2023-01-04 09:26:36,612 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3792095343271891, 'Total loss': 0.3792095343271891} | train loss {'Reaction outcome loss': 0.327443436920752, 'Total loss': 0.327443436920752}
2023-01-04 09:26:36,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:36,613 INFO:     Epoch: 48
2023-01-04 09:26:38,147 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39383343954881034, 'Total loss': 0.39383343954881034} | train loss {'Reaction outcome loss': 0.325636353739452, 'Total loss': 0.325636353739452}
2023-01-04 09:26:38,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:38,147 INFO:     Epoch: 49
2023-01-04 09:26:39,670 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38283730248610176, 'Total loss': 0.38283730248610176} | train loss {'Reaction outcome loss': 0.3248441075776523, 'Total loss': 0.3248441075776523}
2023-01-04 09:26:39,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:39,670 INFO:     Epoch: 50
2023-01-04 09:26:41,258 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37255488336086273, 'Total loss': 0.37255488336086273} | train loss {'Reaction outcome loss': 0.32649960516245813, 'Total loss': 0.32649960516245813}
2023-01-04 09:26:41,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:41,258 INFO:     Epoch: 51
2023-01-04 09:26:42,844 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37975176274776457, 'Total loss': 0.37975176274776457} | train loss {'Reaction outcome loss': 0.32145534312495816, 'Total loss': 0.32145534312495816}
2023-01-04 09:26:42,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:42,844 INFO:     Epoch: 52
2023-01-04 09:26:44,439 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35141684909661614, 'Total loss': 0.35141684909661614} | train loss {'Reaction outcome loss': 0.3198472964730892, 'Total loss': 0.3198472964730892}
2023-01-04 09:26:44,439 INFO:     Found new best model at epoch 52
2023-01-04 09:26:44,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:44,440 INFO:     Epoch: 53
2023-01-04 09:26:46,027 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.342015832165877, 'Total loss': 0.342015832165877} | train loss {'Reaction outcome loss': 0.3131288379267022, 'Total loss': 0.3131288379267022}
2023-01-04 09:26:46,027 INFO:     Found new best model at epoch 53
2023-01-04 09:26:46,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:46,027 INFO:     Epoch: 54
2023-01-04 09:26:47,581 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3900165230035782, 'Total loss': 0.3900165230035782} | train loss {'Reaction outcome loss': 0.3206694418421158, 'Total loss': 0.3206694418421158}
2023-01-04 09:26:47,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:47,581 INFO:     Epoch: 55
2023-01-04 09:26:49,102 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36085246602694193, 'Total loss': 0.36085246602694193} | train loss {'Reaction outcome loss': 0.3163223256503706, 'Total loss': 0.3163223256503706}
2023-01-04 09:26:49,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:49,103 INFO:     Epoch: 56
2023-01-04 09:26:50,684 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3600616360704104, 'Total loss': 0.3600616360704104} | train loss {'Reaction outcome loss': 0.3102092377486683, 'Total loss': 0.3102092377486683}
2023-01-04 09:26:50,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:50,684 INFO:     Epoch: 57
2023-01-04 09:26:52,262 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38421740382909775, 'Total loss': 0.38421740382909775} | train loss {'Reaction outcome loss': 0.31000988974130195, 'Total loss': 0.31000988974130195}
2023-01-04 09:26:52,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:52,262 INFO:     Epoch: 58
2023-01-04 09:26:53,823 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38394247194131215, 'Total loss': 0.38394247194131215} | train loss {'Reaction outcome loss': 0.3081987550952932, 'Total loss': 0.3081987550952932}
2023-01-04 09:26:53,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:53,823 INFO:     Epoch: 59
2023-01-04 09:26:55,394 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38882398704687754, 'Total loss': 0.38882398704687754} | train loss {'Reaction outcome loss': 0.3053579487370484, 'Total loss': 0.3053579487370484}
2023-01-04 09:26:55,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:55,395 INFO:     Epoch: 60
2023-01-04 09:26:56,921 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36038391788800556, 'Total loss': 0.36038391788800556} | train loss {'Reaction outcome loss': 0.3068184551438351, 'Total loss': 0.3068184551438351}
2023-01-04 09:26:56,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:56,922 INFO:     Epoch: 61
2023-01-04 09:26:58,463 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.381771320104599, 'Total loss': 0.381771320104599} | train loss {'Reaction outcome loss': 0.30021333345126755, 'Total loss': 0.30021333345126755}
2023-01-04 09:26:58,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:26:58,464 INFO:     Epoch: 62
2023-01-04 09:27:00,029 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4146798680226008, 'Total loss': 0.4146798680226008} | train loss {'Reaction outcome loss': 0.3013336658477783, 'Total loss': 0.3013336658477783}
2023-01-04 09:27:00,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:00,029 INFO:     Epoch: 63
2023-01-04 09:27:01,609 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36027450288335483, 'Total loss': 0.36027450288335483} | train loss {'Reaction outcome loss': 0.2953092423148262, 'Total loss': 0.2953092423148262}
2023-01-04 09:27:01,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:01,609 INFO:     Epoch: 64
2023-01-04 09:27:03,167 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36910006602605183, 'Total loss': 0.36910006602605183} | train loss {'Reaction outcome loss': 0.3003840040647503, 'Total loss': 0.3003840040647503}
2023-01-04 09:27:03,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:03,167 INFO:     Epoch: 65
2023-01-04 09:27:04,749 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39483047326405846, 'Total loss': 0.39483047326405846} | train loss {'Reaction outcome loss': 0.2966620786995678, 'Total loss': 0.2966620786995678}
2023-01-04 09:27:04,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:04,749 INFO:     Epoch: 66
2023-01-04 09:27:06,292 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3491941829522451, 'Total loss': 0.3491941829522451} | train loss {'Reaction outcome loss': 0.29540292754933073, 'Total loss': 0.29540292754933073}
2023-01-04 09:27:06,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:06,293 INFO:     Epoch: 67
2023-01-04 09:27:07,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36072920163472494, 'Total loss': 0.36072920163472494} | train loss {'Reaction outcome loss': 0.29291254104602904, 'Total loss': 0.29291254104602904}
2023-01-04 09:27:07,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:07,839 INFO:     Epoch: 68
2023-01-04 09:27:09,409 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3902255038420359, 'Total loss': 0.3902255038420359} | train loss {'Reaction outcome loss': 0.29107290627810106, 'Total loss': 0.29107290627810106}
2023-01-04 09:27:09,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:09,409 INFO:     Epoch: 69
2023-01-04 09:27:11,006 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38353180785973867, 'Total loss': 0.38353180785973867} | train loss {'Reaction outcome loss': 0.2875889112879505, 'Total loss': 0.2875889112879505}
2023-01-04 09:27:11,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:11,006 INFO:     Epoch: 70
2023-01-04 09:27:12,579 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3435797572135925, 'Total loss': 0.3435797572135925} | train loss {'Reaction outcome loss': 0.28932573179622273, 'Total loss': 0.28932573179622273}
2023-01-04 09:27:12,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:12,580 INFO:     Epoch: 71
2023-01-04 09:27:14,168 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35219277516007425, 'Total loss': 0.35219277516007425} | train loss {'Reaction outcome loss': 0.2879235248999063, 'Total loss': 0.2879235248999063}
2023-01-04 09:27:14,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:14,168 INFO:     Epoch: 72
2023-01-04 09:27:15,279 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3540559152762095, 'Total loss': 0.3540559152762095} | train loss {'Reaction outcome loss': 0.2877738838776564, 'Total loss': 0.2877738838776564}
2023-01-04 09:27:15,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:15,279 INFO:     Epoch: 73
2023-01-04 09:27:16,300 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3877184569835663, 'Total loss': 0.3877184569835663} | train loss {'Reaction outcome loss': 0.28408111058748686, 'Total loss': 0.28408111058748686}
2023-01-04 09:27:16,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:16,300 INFO:     Epoch: 74
2023-01-04 09:27:17,313 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3511688152949015, 'Total loss': 0.3511688152949015} | train loss {'Reaction outcome loss': 0.28117952673208146, 'Total loss': 0.28117952673208146}
2023-01-04 09:27:17,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:17,313 INFO:     Epoch: 75
2023-01-04 09:27:18,331 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3738503669699033, 'Total loss': 0.3738503669699033} | train loss {'Reaction outcome loss': 0.28298030874176777, 'Total loss': 0.28298030874176777}
2023-01-04 09:27:18,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:18,331 INFO:     Epoch: 76
2023-01-04 09:27:19,701 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3640861243009567, 'Total loss': 0.3640861243009567} | train loss {'Reaction outcome loss': 0.2843137677936327, 'Total loss': 0.2843137677936327}
2023-01-04 09:27:19,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:19,702 INFO:     Epoch: 77
2023-01-04 09:27:21,277 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.34382913808027904, 'Total loss': 0.34382913808027904} | train loss {'Reaction outcome loss': 0.27657691660872746, 'Total loss': 0.27657691660872746}
2023-01-04 09:27:21,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:21,277 INFO:     Epoch: 78
2023-01-04 09:27:22,825 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3569983899593353, 'Total loss': 0.3569983899593353} | train loss {'Reaction outcome loss': 0.2792961332442123, 'Total loss': 0.2792961332442123}
2023-01-04 09:27:22,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:22,825 INFO:     Epoch: 79
2023-01-04 09:27:24,377 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3463945445915063, 'Total loss': 0.3463945445915063} | train loss {'Reaction outcome loss': 0.27755860613160954, 'Total loss': 0.27755860613160954}
2023-01-04 09:27:24,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:24,377 INFO:     Epoch: 80
2023-01-04 09:27:25,938 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36764957855145136, 'Total loss': 0.36764957855145136} | train loss {'Reaction outcome loss': 0.27444947373135625, 'Total loss': 0.27444947373135625}
2023-01-04 09:27:25,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:25,939 INFO:     Epoch: 81
2023-01-04 09:27:27,508 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38101100573937097, 'Total loss': 0.38101100573937097} | train loss {'Reaction outcome loss': 0.27641154150222685, 'Total loss': 0.27641154150222685}
2023-01-04 09:27:27,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:27,508 INFO:     Epoch: 82
2023-01-04 09:27:29,053 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3528725693623225, 'Total loss': 0.3528725693623225} | train loss {'Reaction outcome loss': 0.2734787387589177, 'Total loss': 0.2734787387589177}
2023-01-04 09:27:29,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:29,054 INFO:     Epoch: 83
2023-01-04 09:27:30,652 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39385096232096356, 'Total loss': 0.39385096232096356} | train loss {'Reaction outcome loss': 0.27678515633820616, 'Total loss': 0.27678515633820616}
2023-01-04 09:27:30,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:30,653 INFO:     Epoch: 84
2023-01-04 09:27:32,199 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35840495228767394, 'Total loss': 0.35840495228767394} | train loss {'Reaction outcome loss': 0.2748777747918398, 'Total loss': 0.2748777747918398}
2023-01-04 09:27:32,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:32,199 INFO:     Epoch: 85
2023-01-04 09:27:33,775 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.388681294520696, 'Total loss': 0.388681294520696} | train loss {'Reaction outcome loss': 0.2737868502599634, 'Total loss': 0.2737868502599634}
2023-01-04 09:27:33,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:33,775 INFO:     Epoch: 86
2023-01-04 09:27:35,340 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3619457366565863, 'Total loss': 0.3619457366565863} | train loss {'Reaction outcome loss': 0.267991273281857, 'Total loss': 0.267991273281857}
2023-01-04 09:27:35,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:35,341 INFO:     Epoch: 87
2023-01-04 09:27:36,904 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3664972633123398, 'Total loss': 0.3664972633123398} | train loss {'Reaction outcome loss': 0.2687165852015217, 'Total loss': 0.2687165852015217}
2023-01-04 09:27:36,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:36,904 INFO:     Epoch: 88
2023-01-04 09:27:38,460 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3812949299812317, 'Total loss': 0.3812949299812317} | train loss {'Reaction outcome loss': 0.26763319031714083, 'Total loss': 0.26763319031714083}
2023-01-04 09:27:38,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:38,461 INFO:     Epoch: 89
2023-01-04 09:27:40,024 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35650157233079277, 'Total loss': 0.35650157233079277} | train loss {'Reaction outcome loss': 0.2690338339697529, 'Total loss': 0.2690338339697529}
2023-01-04 09:27:40,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:40,024 INFO:     Epoch: 90
2023-01-04 09:27:41,553 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38408943514029187, 'Total loss': 0.38408943514029187} | train loss {'Reaction outcome loss': 0.2662549181790142, 'Total loss': 0.2662549181790142}
2023-01-04 09:27:41,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:41,554 INFO:     Epoch: 91
2023-01-04 09:27:43,125 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37690792679786683, 'Total loss': 0.37690792679786683} | train loss {'Reaction outcome loss': 0.2632185616854565, 'Total loss': 0.2632185616854565}
2023-01-04 09:27:43,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:43,126 INFO:     Epoch: 92
2023-01-04 09:27:44,676 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3445191125075022, 'Total loss': 0.3445191125075022} | train loss {'Reaction outcome loss': 0.25898429741844153, 'Total loss': 0.25898429741844153}
2023-01-04 09:27:44,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:44,676 INFO:     Epoch: 93
2023-01-04 09:27:46,197 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36554253896077477, 'Total loss': 0.36554253896077477} | train loss {'Reaction outcome loss': 0.2626534559842431, 'Total loss': 0.2626534559842431}
2023-01-04 09:27:46,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:46,197 INFO:     Epoch: 94
2023-01-04 09:27:47,776 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3617997705936432, 'Total loss': 0.3617997705936432} | train loss {'Reaction outcome loss': 0.2625400853742446, 'Total loss': 0.2625400853742446}
2023-01-04 09:27:47,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:47,777 INFO:     Epoch: 95
2023-01-04 09:27:49,340 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36687451203664145, 'Total loss': 0.36687451203664145} | train loss {'Reaction outcome loss': 0.2585109765931364, 'Total loss': 0.2585109765931364}
2023-01-04 09:27:49,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:49,340 INFO:     Epoch: 96
2023-01-04 09:27:50,857 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34808265914519626, 'Total loss': 0.34808265914519626} | train loss {'Reaction outcome loss': 0.2567287919831363, 'Total loss': 0.2567287919831363}
2023-01-04 09:27:50,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:50,857 INFO:     Epoch: 97
2023-01-04 09:27:52,387 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3373732795317968, 'Total loss': 0.3373732795317968} | train loss {'Reaction outcome loss': 0.25997730823499815, 'Total loss': 0.25997730823499815}
2023-01-04 09:27:52,387 INFO:     Found new best model at epoch 97
2023-01-04 09:27:52,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:52,387 INFO:     Epoch: 98
2023-01-04 09:27:53,928 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3650827536980311, 'Total loss': 0.3650827536980311} | train loss {'Reaction outcome loss': 0.2565282334474635, 'Total loss': 0.2565282334474635}
2023-01-04 09:27:53,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:53,928 INFO:     Epoch: 99
2023-01-04 09:27:55,426 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3480614940325419, 'Total loss': 0.3480614940325419} | train loss {'Reaction outcome loss': 0.25501818373635576, 'Total loss': 0.25501818373635576}
2023-01-04 09:27:55,426 INFO:     Best model found after epoch 98 of 100.
2023-01-04 09:27:55,426 INFO:   Done with stage: TRAINING
2023-01-04 09:27:55,426 INFO:   Starting stage: EVALUATION
2023-01-04 09:27:55,567 INFO:   Done with stage: EVALUATION
2023-01-04 09:27:55,567 INFO:   Leaving out SEQ value Fold_9
2023-01-04 09:27:55,580 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 09:27:55,580 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:27:56,221 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:27:56,221 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:27:56,289 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:27:56,289 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:27:56,290 INFO:     No hyperparam tuning for this model
2023-01-04 09:27:56,290 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:27:56,290 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:27:56,290 INFO:     None feature selector for col prot
2023-01-04 09:27:56,291 INFO:     None feature selector for col prot
2023-01-04 09:27:56,291 INFO:     None feature selector for col prot
2023-01-04 09:27:56,291 INFO:     None feature selector for col chem
2023-01-04 09:27:56,291 INFO:     None feature selector for col chem
2023-01-04 09:27:56,291 INFO:     None feature selector for col chem
2023-01-04 09:27:56,291 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:27:56,291 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:27:56,292 INFO:     Number of params in model 70111
2023-01-04 09:27:56,295 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:27:56,296 INFO:   Starting stage: TRAINING
2023-01-04 09:27:56,338 INFO:     Val loss before train {'Reaction outcome loss': 0.9971739093462626, 'Total loss': 0.9971739093462626}
2023-01-04 09:27:56,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:56,338 INFO:     Epoch: 0
2023-01-04 09:27:57,905 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6792520344257355, 'Total loss': 0.6792520344257355} | train loss {'Reaction outcome loss': 0.8460279074816928, 'Total loss': 0.8460279074816928}
2023-01-04 09:27:57,905 INFO:     Found new best model at epoch 0
2023-01-04 09:27:57,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:57,906 INFO:     Epoch: 1
2023-01-04 09:27:59,439 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5685936133066813, 'Total loss': 0.5685936133066813} | train loss {'Reaction outcome loss': 0.6684683850741128, 'Total loss': 0.6684683850741128}
2023-01-04 09:27:59,439 INFO:     Found new best model at epoch 1
2023-01-04 09:27:59,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:27:59,440 INFO:     Epoch: 2
2023-01-04 09:28:01,004 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.521514493227005, 'Total loss': 0.521514493227005} | train loss {'Reaction outcome loss': 0.5830349536471419, 'Total loss': 0.5830349536471419}
2023-01-04 09:28:01,004 INFO:     Found new best model at epoch 2
2023-01-04 09:28:01,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:01,005 INFO:     Epoch: 3
2023-01-04 09:28:02,550 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5015565494696299, 'Total loss': 0.5015565494696299} | train loss {'Reaction outcome loss': 0.542935652422991, 'Total loss': 0.542935652422991}
2023-01-04 09:28:02,550 INFO:     Found new best model at epoch 3
2023-01-04 09:28:02,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:02,551 INFO:     Epoch: 4
2023-01-04 09:28:04,066 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.527874082326889, 'Total loss': 0.527874082326889} | train loss {'Reaction outcome loss': 0.5229283329435634, 'Total loss': 0.5229283329435634}
2023-01-04 09:28:04,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:04,067 INFO:     Epoch: 5
2023-01-04 09:28:05,625 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48345651626586916, 'Total loss': 0.48345651626586916} | train loss {'Reaction outcome loss': 0.5107164656750132, 'Total loss': 0.5107164656750132}
2023-01-04 09:28:05,625 INFO:     Found new best model at epoch 5
2023-01-04 09:28:05,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:05,626 INFO:     Epoch: 6
2023-01-04 09:28:07,201 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47088650465011594, 'Total loss': 0.47088650465011594} | train loss {'Reaction outcome loss': 0.5013832995930303, 'Total loss': 0.5013832995930303}
2023-01-04 09:28:07,201 INFO:     Found new best model at epoch 6
2023-01-04 09:28:07,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:07,202 INFO:     Epoch: 7
2023-01-04 09:28:08,728 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45658938189347587, 'Total loss': 0.45658938189347587} | train loss {'Reaction outcome loss': 0.4906173234919779, 'Total loss': 0.4906173234919779}
2023-01-04 09:28:08,728 INFO:     Found new best model at epoch 7
2023-01-04 09:28:08,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:08,729 INFO:     Epoch: 8
2023-01-04 09:28:10,312 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4854316929976145, 'Total loss': 0.4854316929976145} | train loss {'Reaction outcome loss': 0.479484930795883, 'Total loss': 0.479484930795883}
2023-01-04 09:28:10,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:10,312 INFO:     Epoch: 9
2023-01-04 09:28:11,892 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47393774688243867, 'Total loss': 0.47393774688243867} | train loss {'Reaction outcome loss': 0.4756351148823969, 'Total loss': 0.4756351148823969}
2023-01-04 09:28:11,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:11,893 INFO:     Epoch: 10
2023-01-04 09:28:13,437 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45008771618207294, 'Total loss': 0.45008771618207294} | train loss {'Reaction outcome loss': 0.47086086013902395, 'Total loss': 0.47086086013902395}
2023-01-04 09:28:13,437 INFO:     Found new best model at epoch 10
2023-01-04 09:28:13,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:13,438 INFO:     Epoch: 11
2023-01-04 09:28:15,004 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4336651027202606, 'Total loss': 0.4336651027202606} | train loss {'Reaction outcome loss': 0.46042700655193536, 'Total loss': 0.46042700655193536}
2023-01-04 09:28:15,004 INFO:     Found new best model at epoch 11
2023-01-04 09:28:15,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:15,005 INFO:     Epoch: 12
2023-01-04 09:28:16,583 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.455024583141009, 'Total loss': 0.455024583141009} | train loss {'Reaction outcome loss': 0.4579459115163514, 'Total loss': 0.4579459115163514}
2023-01-04 09:28:16,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:16,583 INFO:     Epoch: 13
2023-01-04 09:28:18,125 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.471811044216156, 'Total loss': 0.471811044216156} | train loss {'Reaction outcome loss': 0.4522868558387894, 'Total loss': 0.4522868558387894}
2023-01-04 09:28:18,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:18,126 INFO:     Epoch: 14
2023-01-04 09:28:19,700 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43181570370992023, 'Total loss': 0.43181570370992023} | train loss {'Reaction outcome loss': 0.44898158704545954, 'Total loss': 0.44898158704545954}
2023-01-04 09:28:19,700 INFO:     Found new best model at epoch 14
2023-01-04 09:28:19,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:19,701 INFO:     Epoch: 15
2023-01-04 09:28:21,270 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43534324169158933, 'Total loss': 0.43534324169158933} | train loss {'Reaction outcome loss': 0.44201248265560783, 'Total loss': 0.44201248265560783}
2023-01-04 09:28:21,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:21,270 INFO:     Epoch: 16
2023-01-04 09:28:22,818 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4109580417474111, 'Total loss': 0.4109580417474111} | train loss {'Reaction outcome loss': 0.43899978092108394, 'Total loss': 0.43899978092108394}
2023-01-04 09:28:22,818 INFO:     Found new best model at epoch 16
2023-01-04 09:28:22,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:22,819 INFO:     Epoch: 17
2023-01-04 09:28:24,413 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.427184122800827, 'Total loss': 0.427184122800827} | train loss {'Reaction outcome loss': 0.43521895412933953, 'Total loss': 0.43521895412933953}
2023-01-04 09:28:24,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:24,413 INFO:     Epoch: 18
2023-01-04 09:28:25,995 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4162788341442744, 'Total loss': 0.4162788341442744} | train loss {'Reaction outcome loss': 0.4280193855293391, 'Total loss': 0.4280193855293391}
2023-01-04 09:28:25,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:25,995 INFO:     Epoch: 19
2023-01-04 09:28:27,541 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43583234349886574, 'Total loss': 0.43583234349886574} | train loss {'Reaction outcome loss': 0.42526662804267035, 'Total loss': 0.42526662804267035}
2023-01-04 09:28:27,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:27,541 INFO:     Epoch: 20
2023-01-04 09:28:29,116 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41893925070762633, 'Total loss': 0.41893925070762633} | train loss {'Reaction outcome loss': 0.419162851351478, 'Total loss': 0.419162851351478}
2023-01-04 09:28:29,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:29,116 INFO:     Epoch: 21
2023-01-04 09:28:30,697 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4071028808752696, 'Total loss': 0.4071028808752696} | train loss {'Reaction outcome loss': 0.41542760710423604, 'Total loss': 0.41542760710423604}
2023-01-04 09:28:30,698 INFO:     Found new best model at epoch 21
2023-01-04 09:28:30,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:30,699 INFO:     Epoch: 22
2023-01-04 09:28:32,237 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3987944483757019, 'Total loss': 0.3987944483757019} | train loss {'Reaction outcome loss': 0.4081113909233348, 'Total loss': 0.4081113909233348}
2023-01-04 09:28:32,238 INFO:     Found new best model at epoch 22
2023-01-04 09:28:32,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:32,238 INFO:     Epoch: 23
2023-01-04 09:28:33,818 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4136197745800018, 'Total loss': 0.4136197745800018} | train loss {'Reaction outcome loss': 0.41104305999535085, 'Total loss': 0.41104305999535085}
2023-01-04 09:28:33,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:33,818 INFO:     Epoch: 24
2023-01-04 09:28:35,383 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39628783861796063, 'Total loss': 0.39628783861796063} | train loss {'Reaction outcome loss': 0.4040825263956824, 'Total loss': 0.4040825263956824}
2023-01-04 09:28:35,383 INFO:     Found new best model at epoch 24
2023-01-04 09:28:35,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:35,384 INFO:     Epoch: 25
2023-01-04 09:28:36,937 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3833241124947866, 'Total loss': 0.3833241124947866} | train loss {'Reaction outcome loss': 0.40157681160239966, 'Total loss': 0.40157681160239966}
2023-01-04 09:28:36,938 INFO:     Found new best model at epoch 25
2023-01-04 09:28:36,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:36,938 INFO:     Epoch: 26
2023-01-04 09:28:38,500 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.410092027982076, 'Total loss': 0.410092027982076} | train loss {'Reaction outcome loss': 0.3957333779130602, 'Total loss': 0.3957333779130602}
2023-01-04 09:28:38,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:38,500 INFO:     Epoch: 27
2023-01-04 09:28:40,072 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4045374552408854, 'Total loss': 0.4045374552408854} | train loss {'Reaction outcome loss': 0.3907221724625529, 'Total loss': 0.3907221724625529}
2023-01-04 09:28:40,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:40,072 INFO:     Epoch: 28
2023-01-04 09:28:41,628 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4357548117637634, 'Total loss': 0.4357548117637634} | train loss {'Reaction outcome loss': 0.38582029650895605, 'Total loss': 0.38582029650895605}
2023-01-04 09:28:41,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:41,628 INFO:     Epoch: 29
2023-01-04 09:28:43,223 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40708173712094625, 'Total loss': 0.40708173712094625} | train loss {'Reaction outcome loss': 0.3805598775563688, 'Total loss': 0.3805598775563688}
2023-01-04 09:28:43,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:43,223 INFO:     Epoch: 30
2023-01-04 09:28:44,762 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40575559437274933, 'Total loss': 0.40575559437274933} | train loss {'Reaction outcome loss': 0.3816572768270754, 'Total loss': 0.3816572768270754}
2023-01-04 09:28:44,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:44,763 INFO:     Epoch: 31
2023-01-04 09:28:46,351 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38529319961865743, 'Total loss': 0.38529319961865743} | train loss {'Reaction outcome loss': 0.37804977913195476, 'Total loss': 0.37804977913195476}
2023-01-04 09:28:46,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:46,351 INFO:     Epoch: 32
2023-01-04 09:28:47,950 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38323702216148375, 'Total loss': 0.38323702216148375} | train loss {'Reaction outcome loss': 0.3754056924785948, 'Total loss': 0.3754056924785948}
2023-01-04 09:28:47,952 INFO:     Found new best model at epoch 32
2023-01-04 09:28:47,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:47,952 INFO:     Epoch: 33
2023-01-04 09:28:49,533 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39721669256687164, 'Total loss': 0.39721669256687164} | train loss {'Reaction outcome loss': 0.36808851495761735, 'Total loss': 0.36808851495761735}
2023-01-04 09:28:49,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:49,534 INFO:     Epoch: 34
2023-01-04 09:28:51,120 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3736382822195689, 'Total loss': 0.3736382822195689} | train loss {'Reaction outcome loss': 0.36686087692902836, 'Total loss': 0.36686087692902836}
2023-01-04 09:28:51,120 INFO:     Found new best model at epoch 34
2023-01-04 09:28:51,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:51,121 INFO:     Epoch: 35
2023-01-04 09:28:52,732 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3924071937799454, 'Total loss': 0.3924071937799454} | train loss {'Reaction outcome loss': 0.3614777716596204, 'Total loss': 0.3614777716596204}
2023-01-04 09:28:52,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:52,733 INFO:     Epoch: 36
2023-01-04 09:28:54,297 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3984379470348358, 'Total loss': 0.3984379470348358} | train loss {'Reaction outcome loss': 0.3599359347932175, 'Total loss': 0.3599359347932175}
2023-01-04 09:28:54,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:54,298 INFO:     Epoch: 37
2023-01-04 09:28:55,923 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3756436248620351, 'Total loss': 0.3756436248620351} | train loss {'Reaction outcome loss': 0.3584959435441434, 'Total loss': 0.3584959435441434}
2023-01-04 09:28:55,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:55,923 INFO:     Epoch: 38
2023-01-04 09:28:57,509 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3872914433479309, 'Total loss': 0.3872914433479309} | train loss {'Reaction outcome loss': 0.35186505581282534, 'Total loss': 0.35186505581282534}
2023-01-04 09:28:57,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:57,509 INFO:     Epoch: 39
2023-01-04 09:28:59,080 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3947568823893865, 'Total loss': 0.3947568823893865} | train loss {'Reaction outcome loss': 0.35309972111068477, 'Total loss': 0.35309972111068477}
2023-01-04 09:28:59,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:28:59,081 INFO:     Epoch: 40
2023-01-04 09:29:00,680 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.382623886068662, 'Total loss': 0.382623886068662} | train loss {'Reaction outcome loss': 0.34820282954171244, 'Total loss': 0.34820282954171244}
2023-01-04 09:29:00,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:00,680 INFO:     Epoch: 41
2023-01-04 09:29:02,274 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35288216869036354, 'Total loss': 0.35288216869036354} | train loss {'Reaction outcome loss': 0.35111237333462125, 'Total loss': 0.35111237333462125}
2023-01-04 09:29:02,275 INFO:     Found new best model at epoch 41
2023-01-04 09:29:02,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:02,275 INFO:     Epoch: 42
2023-01-04 09:29:03,780 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3641859625776609, 'Total loss': 0.3641859625776609} | train loss {'Reaction outcome loss': 0.3435381871483386, 'Total loss': 0.3435381871483386}
2023-01-04 09:29:03,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:03,780 INFO:     Epoch: 43
2023-01-04 09:29:05,413 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3675266961256663, 'Total loss': 0.3675266961256663} | train loss {'Reaction outcome loss': 0.34326153617042926, 'Total loss': 0.34326153617042926}
2023-01-04 09:29:05,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:05,413 INFO:     Epoch: 44
2023-01-04 09:29:07,033 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35285205841064454, 'Total loss': 0.35285205841064454} | train loss {'Reaction outcome loss': 0.3349011213609458, 'Total loss': 0.3349011213609458}
2023-01-04 09:29:07,034 INFO:     Found new best model at epoch 44
2023-01-04 09:29:07,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:07,034 INFO:     Epoch: 45
2023-01-04 09:29:08,594 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3715849826733271, 'Total loss': 0.3715849826733271} | train loss {'Reaction outcome loss': 0.33300998921267394, 'Total loss': 0.33300998921267394}
2023-01-04 09:29:08,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:08,594 INFO:     Epoch: 46
2023-01-04 09:29:10,173 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35674282908439636, 'Total loss': 0.35674282908439636} | train loss {'Reaction outcome loss': 0.33249338105697496, 'Total loss': 0.33249338105697496}
2023-01-04 09:29:10,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:10,173 INFO:     Epoch: 47
2023-01-04 09:29:11,765 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3520145277182261, 'Total loss': 0.3520145277182261} | train loss {'Reaction outcome loss': 0.32947416762259896, 'Total loss': 0.32947416762259896}
2023-01-04 09:29:11,765 INFO:     Found new best model at epoch 47
2023-01-04 09:29:11,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:11,766 INFO:     Epoch: 48
2023-01-04 09:29:13,343 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38622249066829684, 'Total loss': 0.38622249066829684} | train loss {'Reaction outcome loss': 0.3289532474770012, 'Total loss': 0.3289532474770012}
2023-01-04 09:29:13,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:13,343 INFO:     Epoch: 49
2023-01-04 09:29:14,955 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37263503074646, 'Total loss': 0.37263503074646} | train loss {'Reaction outcome loss': 0.32996495727059644, 'Total loss': 0.32996495727059644}
2023-01-04 09:29:14,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:14,955 INFO:     Epoch: 50
2023-01-04 09:29:16,571 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3599150061607361, 'Total loss': 0.3599150061607361} | train loss {'Reaction outcome loss': 0.3208199804816866, 'Total loss': 0.3208199804816866}
2023-01-04 09:29:16,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:16,572 INFO:     Epoch: 51
2023-01-04 09:29:18,139 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3585307727257411, 'Total loss': 0.3585307727257411} | train loss {'Reaction outcome loss': 0.31917791302561327, 'Total loss': 0.31917791302561327}
2023-01-04 09:29:18,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:18,139 INFO:     Epoch: 52
2023-01-04 09:29:19,727 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3633942067623138, 'Total loss': 0.3633942067623138} | train loss {'Reaction outcome loss': 0.3196689720242032, 'Total loss': 0.3196689720242032}
2023-01-04 09:29:19,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:19,729 INFO:     Epoch: 53
2023-01-04 09:29:21,285 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36220899820327757, 'Total loss': 0.36220899820327757} | train loss {'Reaction outcome loss': 0.3176024411451946, 'Total loss': 0.3176024411451946}
2023-01-04 09:29:21,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:21,286 INFO:     Epoch: 54
2023-01-04 09:29:22,877 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.35465795795122784, 'Total loss': 0.35465795795122784} | train loss {'Reaction outcome loss': 0.31544419797641704, 'Total loss': 0.31544419797641704}
2023-01-04 09:29:22,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:22,878 INFO:     Epoch: 55
2023-01-04 09:29:24,463 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3604134609301885, 'Total loss': 0.3604134609301885} | train loss {'Reaction outcome loss': 0.3148796476343048, 'Total loss': 0.3148796476343048}
2023-01-04 09:29:24,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:24,463 INFO:     Epoch: 56
2023-01-04 09:29:26,036 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36305861274401346, 'Total loss': 0.36305861274401346} | train loss {'Reaction outcome loss': 0.3123967995066935, 'Total loss': 0.3123967995066935}
2023-01-04 09:29:26,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:26,037 INFO:     Epoch: 57
2023-01-04 09:29:27,615 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3585335562626521, 'Total loss': 0.3585335562626521} | train loss {'Reaction outcome loss': 0.31282080656139427, 'Total loss': 0.31282080656139427}
2023-01-04 09:29:27,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:27,616 INFO:     Epoch: 58
2023-01-04 09:29:29,209 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.33496735046307247, 'Total loss': 0.33496735046307247} | train loss {'Reaction outcome loss': 0.30569165799807124, 'Total loss': 0.30569165799807124}
2023-01-04 09:29:29,209 INFO:     Found new best model at epoch 58
2023-01-04 09:29:29,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:29,210 INFO:     Epoch: 59
2023-01-04 09:29:30,771 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3670931468407313, 'Total loss': 0.3670931468407313} | train loss {'Reaction outcome loss': 0.30874321184084086, 'Total loss': 0.30874321184084086}
2023-01-04 09:29:30,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:30,771 INFO:     Epoch: 60
2023-01-04 09:29:32,348 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3534263988335927, 'Total loss': 0.3534263988335927} | train loss {'Reaction outcome loss': 0.3107538724768678, 'Total loss': 0.3107538724768678}
2023-01-04 09:29:32,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:32,349 INFO:     Epoch: 61
2023-01-04 09:29:33,916 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37220106621583304, 'Total loss': 0.37220106621583304} | train loss {'Reaction outcome loss': 0.30036307774511056, 'Total loss': 0.30036307774511056}
2023-01-04 09:29:33,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:33,916 INFO:     Epoch: 62
2023-01-04 09:29:35,441 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3490369811654091, 'Total loss': 0.3490369811654091} | train loss {'Reaction outcome loss': 0.30381829388412757, 'Total loss': 0.30381829388412757}
2023-01-04 09:29:35,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:35,441 INFO:     Epoch: 63
2023-01-04 09:29:37,002 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3688998639583588, 'Total loss': 0.3688998639583588} | train loss {'Reaction outcome loss': 0.2987307097345913, 'Total loss': 0.2987307097345913}
2023-01-04 09:29:37,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:37,003 INFO:     Epoch: 64
2023-01-04 09:29:38,560 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3569255232810974, 'Total loss': 0.3569255232810974} | train loss {'Reaction outcome loss': 0.2991586392106562, 'Total loss': 0.2991586392106562}
2023-01-04 09:29:38,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:38,561 INFO:     Epoch: 65
2023-01-04 09:29:40,095 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35985438028971356, 'Total loss': 0.35985438028971356} | train loss {'Reaction outcome loss': 0.2983909127729464, 'Total loss': 0.2983909127729464}
2023-01-04 09:29:40,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:40,096 INFO:     Epoch: 66
2023-01-04 09:29:41,675 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3588012526432673, 'Total loss': 0.3588012526432673} | train loss {'Reaction outcome loss': 0.29668598069342034, 'Total loss': 0.29668598069342034}
2023-01-04 09:29:41,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:41,675 INFO:     Epoch: 67
2023-01-04 09:29:43,270 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.33656978805859883, 'Total loss': 0.33656978805859883} | train loss {'Reaction outcome loss': 0.29227444518774426, 'Total loss': 0.29227444518774426}
2023-01-04 09:29:43,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:43,270 INFO:     Epoch: 68
2023-01-04 09:29:44,821 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3420390983422597, 'Total loss': 0.3420390983422597} | train loss {'Reaction outcome loss': 0.2949421112610545, 'Total loss': 0.2949421112610545}
2023-01-04 09:29:44,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:44,821 INFO:     Epoch: 69
2023-01-04 09:29:46,411 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34740651547908785, 'Total loss': 0.34740651547908785} | train loss {'Reaction outcome loss': 0.29563566550128295, 'Total loss': 0.29563566550128295}
2023-01-04 09:29:46,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:46,411 INFO:     Epoch: 70
2023-01-04 09:29:48,002 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3377451181411743, 'Total loss': 0.3377451181411743} | train loss {'Reaction outcome loss': 0.2850048989192028, 'Total loss': 0.2850048989192028}
2023-01-04 09:29:48,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:48,002 INFO:     Epoch: 71
2023-01-04 09:29:49,581 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35441188712914784, 'Total loss': 0.35441188712914784} | train loss {'Reaction outcome loss': 0.28636051216818365, 'Total loss': 0.28636051216818365}
2023-01-04 09:29:49,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:49,581 INFO:     Epoch: 72
2023-01-04 09:29:51,179 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3561248958110809, 'Total loss': 0.3561248958110809} | train loss {'Reaction outcome loss': 0.2875252207371302, 'Total loss': 0.2875252207371302}
2023-01-04 09:29:51,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:51,179 INFO:     Epoch: 73
2023-01-04 09:29:52,767 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35177952647209165, 'Total loss': 0.35177952647209165} | train loss {'Reaction outcome loss': 0.2868645135044298, 'Total loss': 0.2868645135044298}
2023-01-04 09:29:52,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:52,768 INFO:     Epoch: 74
2023-01-04 09:29:54,327 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34623300830523174, 'Total loss': 0.34623300830523174} | train loss {'Reaction outcome loss': 0.2874172110150867, 'Total loss': 0.2874172110150867}
2023-01-04 09:29:54,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:54,328 INFO:     Epoch: 75
2023-01-04 09:29:55,932 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37098134954770406, 'Total loss': 0.37098134954770406} | train loss {'Reaction outcome loss': 0.2841712479825915, 'Total loss': 0.2841712479825915}
2023-01-04 09:29:55,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:55,933 INFO:     Epoch: 76
2023-01-04 09:29:57,489 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34760841925938923, 'Total loss': 0.34760841925938923} | train loss {'Reaction outcome loss': 0.2806476110370581, 'Total loss': 0.2806476110370581}
2023-01-04 09:29:57,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:57,489 INFO:     Epoch: 77
2023-01-04 09:29:59,089 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3503849188486735, 'Total loss': 0.3503849188486735} | train loss {'Reaction outcome loss': 0.28259453432977416, 'Total loss': 0.28259453432977416}
2023-01-04 09:29:59,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:29:59,090 INFO:     Epoch: 78
2023-01-04 09:30:00,682 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.33595837553342184, 'Total loss': 0.33595837553342184} | train loss {'Reaction outcome loss': 0.2794780661402411, 'Total loss': 0.2794780661402411}
2023-01-04 09:30:00,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:00,683 INFO:     Epoch: 79
2023-01-04 09:30:02,299 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3363420367240906, 'Total loss': 0.3363420367240906} | train loss {'Reaction outcome loss': 0.27771214329862853, 'Total loss': 0.27771214329862853}
2023-01-04 09:30:02,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:02,299 INFO:     Epoch: 80
2023-01-04 09:30:03,850 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35593464573224387, 'Total loss': 0.35593464573224387} | train loss {'Reaction outcome loss': 0.2766338552109601, 'Total loss': 0.2766338552109601}
2023-01-04 09:30:03,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:03,850 INFO:     Epoch: 81
2023-01-04 09:30:05,439 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36431489090124763, 'Total loss': 0.36431489090124763} | train loss {'Reaction outcome loss': 0.2719332411723877, 'Total loss': 0.2719332411723877}
2023-01-04 09:30:05,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:05,439 INFO:     Epoch: 82
2023-01-04 09:30:06,995 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35648642083009086, 'Total loss': 0.35648642083009086} | train loss {'Reaction outcome loss': 0.27360589579016725, 'Total loss': 0.27360589579016725}
2023-01-04 09:30:06,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:06,995 INFO:     Epoch: 83
2023-01-04 09:30:08,578 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35511932472387947, 'Total loss': 0.35511932472387947} | train loss {'Reaction outcome loss': 0.2797060530323414, 'Total loss': 0.2797060530323414}
2023-01-04 09:30:08,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:08,578 INFO:     Epoch: 84
2023-01-04 09:30:10,163 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35967968304951986, 'Total loss': 0.35967968304951986} | train loss {'Reaction outcome loss': 0.2653879606659232, 'Total loss': 0.2653879606659232}
2023-01-04 09:30:10,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:10,164 INFO:     Epoch: 85
2023-01-04 09:30:11,708 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37166715363661446, 'Total loss': 0.37166715363661446} | train loss {'Reaction outcome loss': 0.2707036984849062, 'Total loss': 0.2707036984849062}
2023-01-04 09:30:11,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:11,708 INFO:     Epoch: 86
2023-01-04 09:30:13,274 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3415870030721029, 'Total loss': 0.3415870030721029} | train loss {'Reaction outcome loss': 0.26813914626836777, 'Total loss': 0.26813914626836777}
2023-01-04 09:30:13,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:13,274 INFO:     Epoch: 87
2023-01-04 09:30:14,840 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35491180618604024, 'Total loss': 0.35491180618604024} | train loss {'Reaction outcome loss': 0.26775027964842446, 'Total loss': 0.26775027964842446}
2023-01-04 09:30:14,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:14,840 INFO:     Epoch: 88
2023-01-04 09:30:16,373 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3666737178961436, 'Total loss': 0.3666737178961436} | train loss {'Reaction outcome loss': 0.26789279661346427, 'Total loss': 0.26789279661346427}
2023-01-04 09:30:16,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:16,374 INFO:     Epoch: 89
2023-01-04 09:30:17,962 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36626826723416644, 'Total loss': 0.36626826723416644} | train loss {'Reaction outcome loss': 0.26919857885970966, 'Total loss': 0.26919857885970966}
2023-01-04 09:30:17,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:17,963 INFO:     Epoch: 90
2023-01-04 09:30:19,581 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3468868712584178, 'Total loss': 0.3468868712584178} | train loss {'Reaction outcome loss': 0.26924358770950607, 'Total loss': 0.26924358770950607}
2023-01-04 09:30:19,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:19,581 INFO:     Epoch: 91
2023-01-04 09:30:21,156 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35281652212142944, 'Total loss': 0.35281652212142944} | train loss {'Reaction outcome loss': 0.262524787376934, 'Total loss': 0.262524787376934}
2023-01-04 09:30:21,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:21,156 INFO:     Epoch: 92
2023-01-04 09:30:22,756 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3507934272289276, 'Total loss': 0.3507934272289276} | train loss {'Reaction outcome loss': 0.2635442391306915, 'Total loss': 0.2635442391306915}
2023-01-04 09:30:22,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:22,756 INFO:     Epoch: 93
2023-01-04 09:30:24,331 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3609542886416117, 'Total loss': 0.3609542886416117} | train loss {'Reaction outcome loss': 0.26547447054071976, 'Total loss': 0.26547447054071976}
2023-01-04 09:30:24,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:24,332 INFO:     Epoch: 94
2023-01-04 09:30:25,882 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3610518058141073, 'Total loss': 0.3610518058141073} | train loss {'Reaction outcome loss': 0.2632637640010794, 'Total loss': 0.2632637640010794}
2023-01-04 09:30:25,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:25,883 INFO:     Epoch: 95
2023-01-04 09:30:27,452 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3635584950447083, 'Total loss': 0.3635584950447083} | train loss {'Reaction outcome loss': 0.2617572584737509, 'Total loss': 0.2617572584737509}
2023-01-04 09:30:27,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:27,453 INFO:     Epoch: 96
2023-01-04 09:30:29,048 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35422078569730125, 'Total loss': 0.35422078569730125} | train loss {'Reaction outcome loss': 0.25893941057664394, 'Total loss': 0.25893941057664394}
2023-01-04 09:30:29,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:29,048 INFO:     Epoch: 97
2023-01-04 09:30:30,605 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3558859616518021, 'Total loss': 0.3558859616518021} | train loss {'Reaction outcome loss': 0.26251216693394663, 'Total loss': 0.26251216693394663}
2023-01-04 09:30:30,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:30,605 INFO:     Epoch: 98
2023-01-04 09:30:32,208 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3823515514532725, 'Total loss': 0.3823515514532725} | train loss {'Reaction outcome loss': 0.25843472047187793, 'Total loss': 0.25843472047187793}
2023-01-04 09:30:32,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:32,210 INFO:     Epoch: 99
2023-01-04 09:30:33,783 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3410597910483678, 'Total loss': 0.3410597910483678} | train loss {'Reaction outcome loss': 0.2558758590666288, 'Total loss': 0.2558758590666288}
2023-01-04 09:30:33,783 INFO:     Best model found after epoch 59 of 100.
2023-01-04 09:30:33,784 INFO:   Done with stage: TRAINING
2023-01-04 09:30:33,784 INFO:   Starting stage: EVALUATION
2023-01-04 09:30:33,905 INFO:   Done with stage: EVALUATION
2023-01-04 09:30:33,914 INFO:   Leaving out SEQ value Fold_0
2023-01-04 09:30:33,927 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:30:33,927 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:30:34,577 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:30:34,577 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:30:34,644 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:30:34,644 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:30:34,644 INFO:     No hyperparam tuning for this model
2023-01-04 09:30:34,644 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:30:34,644 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:30:34,645 INFO:     None feature selector for col prot
2023-01-04 09:30:34,645 INFO:     None feature selector for col prot
2023-01-04 09:30:34,645 INFO:     None feature selector for col prot
2023-01-04 09:30:34,646 INFO:     None feature selector for col chem
2023-01-04 09:30:34,646 INFO:     None feature selector for col chem
2023-01-04 09:30:34,646 INFO:     None feature selector for col chem
2023-01-04 09:30:34,646 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:30:34,646 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:30:34,647 INFO:     Number of params in model 70111
2023-01-04 09:30:34,650 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:30:34,650 INFO:   Starting stage: TRAINING
2023-01-04 09:30:34,694 INFO:     Val loss before train {'Reaction outcome loss': 0.9463739573955536, 'Total loss': 0.9463739573955536}
2023-01-04 09:30:34,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:34,694 INFO:     Epoch: 0
2023-01-04 09:30:36,301 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6643839279810587, 'Total loss': 0.6643839279810587} | train loss {'Reaction outcome loss': 0.8119436601073308, 'Total loss': 0.8119436601073308}
2023-01-04 09:30:36,301 INFO:     Found new best model at epoch 0
2023-01-04 09:30:36,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:36,302 INFO:     Epoch: 1
2023-01-04 09:30:37,857 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5545353551705678, 'Total loss': 0.5545353551705678} | train loss {'Reaction outcome loss': 0.639006270662598, 'Total loss': 0.639006270662598}
2023-01-04 09:30:37,857 INFO:     Found new best model at epoch 1
2023-01-04 09:30:37,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:37,858 INFO:     Epoch: 2
2023-01-04 09:30:39,398 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.524503622452418, 'Total loss': 0.524503622452418} | train loss {'Reaction outcome loss': 0.5621810056652159, 'Total loss': 0.5621810056652159}
2023-01-04 09:30:39,398 INFO:     Found new best model at epoch 2
2023-01-04 09:30:39,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:39,399 INFO:     Epoch: 3
2023-01-04 09:30:40,979 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5128265857696533, 'Total loss': 0.5128265857696533} | train loss {'Reaction outcome loss': 0.5480209392481956, 'Total loss': 0.5480209392481956}
2023-01-04 09:30:40,980 INFO:     Found new best model at epoch 3
2023-01-04 09:30:40,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:40,980 INFO:     Epoch: 4
2023-01-04 09:30:42,555 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4915496011575063, 'Total loss': 0.4915496011575063} | train loss {'Reaction outcome loss': 0.5232027551112127, 'Total loss': 0.5232027551112127}
2023-01-04 09:30:42,555 INFO:     Found new best model at epoch 4
2023-01-04 09:30:42,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:42,556 INFO:     Epoch: 5
2023-01-04 09:30:44,110 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4794468154509862, 'Total loss': 0.4794468154509862} | train loss {'Reaction outcome loss': 0.49621465327083203, 'Total loss': 0.49621465327083203}
2023-01-04 09:30:44,111 INFO:     Found new best model at epoch 5
2023-01-04 09:30:44,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:44,111 INFO:     Epoch: 6
2023-01-04 09:30:45,702 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4804715871810913, 'Total loss': 0.4804715871810913} | train loss {'Reaction outcome loss': 0.4889496496838072, 'Total loss': 0.4889496496838072}
2023-01-04 09:30:45,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:45,703 INFO:     Epoch: 7
2023-01-04 09:30:47,277 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46128344039122265, 'Total loss': 0.46128344039122265} | train loss {'Reaction outcome loss': 0.4850889593902705, 'Total loss': 0.4850889593902705}
2023-01-04 09:30:47,277 INFO:     Found new best model at epoch 7
2023-01-04 09:30:47,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:47,278 INFO:     Epoch: 8
2023-01-04 09:30:48,835 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4456333965063095, 'Total loss': 0.4456333965063095} | train loss {'Reaction outcome loss': 0.47405294973092776, 'Total loss': 0.47405294973092776}
2023-01-04 09:30:48,835 INFO:     Found new best model at epoch 8
2023-01-04 09:30:48,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:48,836 INFO:     Epoch: 9
2023-01-04 09:30:50,421 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4453406135241191, 'Total loss': 0.4453406135241191} | train loss {'Reaction outcome loss': 0.46512713205273665, 'Total loss': 0.46512713205273665}
2023-01-04 09:30:50,421 INFO:     Found new best model at epoch 9
2023-01-04 09:30:50,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:50,422 INFO:     Epoch: 10
2023-01-04 09:30:51,958 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4552922785282135, 'Total loss': 0.4552922785282135} | train loss {'Reaction outcome loss': 0.46308820308969595, 'Total loss': 0.46308820308969595}
2023-01-04 09:30:51,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:51,958 INFO:     Epoch: 11
2023-01-04 09:30:53,535 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45440083543459575, 'Total loss': 0.45440083543459575} | train loss {'Reaction outcome loss': 0.4553118585009951, 'Total loss': 0.4553118585009951}
2023-01-04 09:30:53,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:53,536 INFO:     Epoch: 12
2023-01-04 09:30:55,114 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44166423281033834, 'Total loss': 0.44166423281033834} | train loss {'Reaction outcome loss': 0.452682628776318, 'Total loss': 0.452682628776318}
2023-01-04 09:30:55,114 INFO:     Found new best model at epoch 12
2023-01-04 09:30:55,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:55,115 INFO:     Epoch: 13
2023-01-04 09:30:56,695 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42424735575914385, 'Total loss': 0.42424735575914385} | train loss {'Reaction outcome loss': 0.4502619299227777, 'Total loss': 0.4502619299227777}
2023-01-04 09:30:56,695 INFO:     Found new best model at epoch 13
2023-01-04 09:30:56,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:56,696 INFO:     Epoch: 14
2023-01-04 09:30:58,252 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4430156946182251, 'Total loss': 0.4430156946182251} | train loss {'Reaction outcome loss': 0.45707264313798235, 'Total loss': 0.45707264313798235}
2023-01-04 09:30:58,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:58,252 INFO:     Epoch: 15
2023-01-04 09:30:59,844 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42549339930216473, 'Total loss': 0.42549339930216473} | train loss {'Reaction outcome loss': 0.4384194895476643, 'Total loss': 0.4384194895476643}
2023-01-04 09:30:59,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:30:59,844 INFO:     Epoch: 16
2023-01-04 09:31:01,378 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43910263081391654, 'Total loss': 0.43910263081391654} | train loss {'Reaction outcome loss': 0.4309745108425293, 'Total loss': 0.4309745108425293}
2023-01-04 09:31:01,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:01,380 INFO:     Epoch: 17
2023-01-04 09:31:02,981 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39626489380995433, 'Total loss': 0.39626489380995433} | train loss {'Reaction outcome loss': 0.4299827252575399, 'Total loss': 0.4299827252575399}
2023-01-04 09:31:02,981 INFO:     Found new best model at epoch 17
2023-01-04 09:31:02,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:02,982 INFO:     Epoch: 18
2023-01-04 09:31:04,587 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40574095249176023, 'Total loss': 0.40574095249176023} | train loss {'Reaction outcome loss': 0.42354463778631896, 'Total loss': 0.42354463778631896}
2023-01-04 09:31:04,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:04,588 INFO:     Epoch: 19
2023-01-04 09:31:06,148 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4528851568698883, 'Total loss': 0.4528851568698883} | train loss {'Reaction outcome loss': 0.4204534061954937, 'Total loss': 0.4204534061954937}
2023-01-04 09:31:06,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:06,148 INFO:     Epoch: 20
2023-01-04 09:31:07,720 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46982668538888295, 'Total loss': 0.46982668538888295} | train loss {'Reaction outcome loss': 0.42339528152260225, 'Total loss': 0.42339528152260225}
2023-01-04 09:31:07,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:07,721 INFO:     Epoch: 21
2023-01-04 09:31:09,275 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.420593457420667, 'Total loss': 0.420593457420667} | train loss {'Reaction outcome loss': 0.4495753510247754, 'Total loss': 0.4495753510247754}
2023-01-04 09:31:09,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:09,276 INFO:     Epoch: 22
2023-01-04 09:31:10,804 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41195069551467894, 'Total loss': 0.41195069551467894} | train loss {'Reaction outcome loss': 0.41247443980139814, 'Total loss': 0.41247443980139814}
2023-01-04 09:31:10,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:10,804 INFO:     Epoch: 23
2023-01-04 09:31:12,365 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4055313597122828, 'Total loss': 0.4055313597122828} | train loss {'Reaction outcome loss': 0.4017798717039219, 'Total loss': 0.4017798717039219}
2023-01-04 09:31:12,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:12,365 INFO:     Epoch: 24
2023-01-04 09:31:13,917 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4450858235359192, 'Total loss': 0.4450858235359192} | train loss {'Reaction outcome loss': 0.40037684040683985, 'Total loss': 0.40037684040683985}
2023-01-04 09:31:13,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:13,917 INFO:     Epoch: 25
2023-01-04 09:31:15,436 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39445977012316386, 'Total loss': 0.39445977012316386} | train loss {'Reaction outcome loss': 0.39480566811128653, 'Total loss': 0.39480566811128653}
2023-01-04 09:31:15,436 INFO:     Found new best model at epoch 25
2023-01-04 09:31:15,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:15,437 INFO:     Epoch: 26
2023-01-04 09:31:16,993 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.421846404671669, 'Total loss': 0.421846404671669} | train loss {'Reaction outcome loss': 0.38903512312706723, 'Total loss': 0.38903512312706723}
2023-01-04 09:31:16,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:16,993 INFO:     Epoch: 27
2023-01-04 09:31:18,558 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3943359394868215, 'Total loss': 0.3943359394868215} | train loss {'Reaction outcome loss': 0.38597656291086174, 'Total loss': 0.38597656291086174}
2023-01-04 09:31:18,558 INFO:     Found new best model at epoch 27
2023-01-04 09:31:18,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:18,559 INFO:     Epoch: 28
2023-01-04 09:31:20,070 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39308968782424925, 'Total loss': 0.39308968782424925} | train loss {'Reaction outcome loss': 0.3804325178950777, 'Total loss': 0.3804325178950777}
2023-01-04 09:31:20,070 INFO:     Found new best model at epoch 28
2023-01-04 09:31:20,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:20,071 INFO:     Epoch: 29
2023-01-04 09:31:21,636 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40451704363028207, 'Total loss': 0.40451704363028207} | train loss {'Reaction outcome loss': 0.38134574981919234, 'Total loss': 0.38134574981919234}
2023-01-04 09:31:21,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:21,636 INFO:     Epoch: 30
2023-01-04 09:31:23,190 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.386335367957751, 'Total loss': 0.386335367957751} | train loss {'Reaction outcome loss': 0.38044444383189513, 'Total loss': 0.38044444383189513}
2023-01-04 09:31:23,190 INFO:     Found new best model at epoch 30
2023-01-04 09:31:23,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:23,191 INFO:     Epoch: 31
2023-01-04 09:31:24,714 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3708367258310318, 'Total loss': 0.3708367258310318} | train loss {'Reaction outcome loss': 0.3711472074906139, 'Total loss': 0.3711472074906139}
2023-01-04 09:31:24,714 INFO:     Found new best model at epoch 31
2023-01-04 09:31:24,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:24,715 INFO:     Epoch: 32
2023-01-04 09:31:26,280 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3990156799554825, 'Total loss': 0.3990156799554825} | train loss {'Reaction outcome loss': 0.3669040803081547, 'Total loss': 0.3669040803081547}
2023-01-04 09:31:26,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:26,280 INFO:     Epoch: 33
2023-01-04 09:31:27,835 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38868549664815266, 'Total loss': 0.38868549664815266} | train loss {'Reaction outcome loss': 0.37022387532625295, 'Total loss': 0.37022387532625295}
2023-01-04 09:31:27,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:27,835 INFO:     Epoch: 34
2023-01-04 09:31:29,354 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4271673907836278, 'Total loss': 0.4271673907836278} | train loss {'Reaction outcome loss': 0.36624349464756856, 'Total loss': 0.36624349464756856}
2023-01-04 09:31:29,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:29,354 INFO:     Epoch: 35
2023-01-04 09:31:30,904 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3895032376050949, 'Total loss': 0.3895032376050949} | train loss {'Reaction outcome loss': 0.3630042625911723, 'Total loss': 0.3630042625911723}
2023-01-04 09:31:30,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:30,904 INFO:     Epoch: 36
2023-01-04 09:31:32,445 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3788432329893112, 'Total loss': 0.3788432329893112} | train loss {'Reaction outcome loss': 0.35397405331394216, 'Total loss': 0.35397405331394216}
2023-01-04 09:31:32,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:32,446 INFO:     Epoch: 37
2023-01-04 09:31:33,952 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39799532294273376, 'Total loss': 0.39799532294273376} | train loss {'Reaction outcome loss': 0.352964582510522, 'Total loss': 0.352964582510522}
2023-01-04 09:31:33,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:33,952 INFO:     Epoch: 38
2023-01-04 09:31:35,515 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3837450792392095, 'Total loss': 0.3837450792392095} | train loss {'Reaction outcome loss': 0.35149353483111423, 'Total loss': 0.35149353483111423}
2023-01-04 09:31:35,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:35,516 INFO:     Epoch: 39
2023-01-04 09:31:37,074 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35643918116887413, 'Total loss': 0.35643918116887413} | train loss {'Reaction outcome loss': 0.340542214653502, 'Total loss': 0.340542214653502}
2023-01-04 09:31:37,074 INFO:     Found new best model at epoch 39
2023-01-04 09:31:37,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:37,075 INFO:     Epoch: 40
2023-01-04 09:31:38,599 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36612189759810765, 'Total loss': 0.36612189759810765} | train loss {'Reaction outcome loss': 0.3436561110821735, 'Total loss': 0.3436561110821735}
2023-01-04 09:31:38,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:38,600 INFO:     Epoch: 41
2023-01-04 09:31:40,158 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38740404695272446, 'Total loss': 0.38740404695272446} | train loss {'Reaction outcome loss': 0.3412997201355039, 'Total loss': 0.3412997201355039}
2023-01-04 09:31:40,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:40,158 INFO:     Epoch: 42
2023-01-04 09:31:41,728 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3831863164901733, 'Total loss': 0.3831863164901733} | train loss {'Reaction outcome loss': 0.3425789442439766, 'Total loss': 0.3425789442439766}
2023-01-04 09:31:41,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:41,729 INFO:     Epoch: 43
2023-01-04 09:31:43,248 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3609462042649587, 'Total loss': 0.3609462042649587} | train loss {'Reaction outcome loss': 0.3376463415182155, 'Total loss': 0.3376463415182155}
2023-01-04 09:31:43,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:43,249 INFO:     Epoch: 44
2023-01-04 09:31:44,806 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35954999923706055, 'Total loss': 0.35954999923706055} | train loss {'Reaction outcome loss': 0.34170664675479784, 'Total loss': 0.34170664675479784}
2023-01-04 09:31:44,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:44,806 INFO:     Epoch: 45
2023-01-04 09:31:46,334 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.356307852268219, 'Total loss': 0.356307852268219} | train loss {'Reaction outcome loss': 0.33231372033712786, 'Total loss': 0.33231372033712786}
2023-01-04 09:31:46,334 INFO:     Found new best model at epoch 45
2023-01-04 09:31:46,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:46,335 INFO:     Epoch: 46
2023-01-04 09:31:47,883 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3878201385339101, 'Total loss': 0.3878201385339101} | train loss {'Reaction outcome loss': 0.32745982922135913, 'Total loss': 0.32745982922135913}
2023-01-04 09:31:47,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:47,883 INFO:     Epoch: 47
2023-01-04 09:31:49,442 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3559427186846733, 'Total loss': 0.3559427186846733} | train loss {'Reaction outcome loss': 0.3249447094732086, 'Total loss': 0.3249447094732086}
2023-01-04 09:31:49,442 INFO:     Found new best model at epoch 47
2023-01-04 09:31:49,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:49,443 INFO:     Epoch: 48
2023-01-04 09:31:51,011 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36002897123495736, 'Total loss': 0.36002897123495736} | train loss {'Reaction outcome loss': 0.3232374688079184, 'Total loss': 0.3232374688079184}
2023-01-04 09:31:51,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:51,012 INFO:     Epoch: 49
2023-01-04 09:31:52,552 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3621143360932668, 'Total loss': 0.3621143360932668} | train loss {'Reaction outcome loss': 0.318453995132586, 'Total loss': 0.318453995132586}
2023-01-04 09:31:52,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:52,552 INFO:     Epoch: 50
2023-01-04 09:31:54,146 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36080268522103626, 'Total loss': 0.36080268522103626} | train loss {'Reaction outcome loss': 0.31925700164899445, 'Total loss': 0.31925700164899445}
2023-01-04 09:31:54,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:54,146 INFO:     Epoch: 51
2023-01-04 09:31:55,697 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3578803171714147, 'Total loss': 0.3578803171714147} | train loss {'Reaction outcome loss': 0.33082928975531156, 'Total loss': 0.33082928975531156}
2023-01-04 09:31:55,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:55,697 INFO:     Epoch: 52
2023-01-04 09:31:57,274 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3605484217405319, 'Total loss': 0.3605484217405319} | train loss {'Reaction outcome loss': 0.3183129435216171, 'Total loss': 0.3183129435216171}
2023-01-04 09:31:57,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:57,275 INFO:     Epoch: 53
2023-01-04 09:31:58,880 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.34575611849625904, 'Total loss': 0.34575611849625904} | train loss {'Reaction outcome loss': 0.317621075561729, 'Total loss': 0.317621075561729}
2023-01-04 09:31:58,880 INFO:     Found new best model at epoch 53
2023-01-04 09:31:58,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:31:58,880 INFO:     Epoch: 54
2023-01-04 09:32:00,441 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.35376202364762627, 'Total loss': 0.35376202364762627} | train loss {'Reaction outcome loss': 0.3177989353807525, 'Total loss': 0.3177989353807525}
2023-01-04 09:32:00,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:00,441 INFO:     Epoch: 55
2023-01-04 09:32:02,034 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3756677160660426, 'Total loss': 0.3756677160660426} | train loss {'Reaction outcome loss': 0.30658027484500106, 'Total loss': 0.30658027484500106}
2023-01-04 09:32:02,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:02,035 INFO:     Epoch: 56
2023-01-04 09:32:03,631 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36491674681504566, 'Total loss': 0.36491674681504566} | train loss {'Reaction outcome loss': 0.3093955397213205, 'Total loss': 0.3093955397213205}
2023-01-04 09:32:03,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:03,631 INFO:     Epoch: 57
2023-01-04 09:32:05,186 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3833327968915304, 'Total loss': 0.3833327968915304} | train loss {'Reaction outcome loss': 0.312823428084021, 'Total loss': 0.312823428084021}
2023-01-04 09:32:05,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:05,187 INFO:     Epoch: 58
2023-01-04 09:32:06,761 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36162651677926383, 'Total loss': 0.36162651677926383} | train loss {'Reaction outcome loss': 0.3827057227060415, 'Total loss': 0.3827057227060415}
2023-01-04 09:32:06,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:06,761 INFO:     Epoch: 59
2023-01-04 09:32:08,347 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3569270064433416, 'Total loss': 0.3569270064433416} | train loss {'Reaction outcome loss': 0.31673960455362615, 'Total loss': 0.31673960455362615}
2023-01-04 09:32:08,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:08,348 INFO:     Epoch: 60
2023-01-04 09:32:09,918 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3535956770181656, 'Total loss': 0.3535956770181656} | train loss {'Reaction outcome loss': 0.3120895588797504, 'Total loss': 0.3120895588797504}
2023-01-04 09:32:09,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:09,918 INFO:     Epoch: 61
2023-01-04 09:32:11,490 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3550149480501811, 'Total loss': 0.3550149480501811} | train loss {'Reaction outcome loss': 0.3282364901890791, 'Total loss': 0.3282364901890791}
2023-01-04 09:32:11,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:11,490 INFO:     Epoch: 62
2023-01-04 09:32:13,059 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.35689013799031577, 'Total loss': 0.35689013799031577} | train loss {'Reaction outcome loss': 0.30278441992835514, 'Total loss': 0.30278441992835514}
2023-01-04 09:32:13,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:13,059 INFO:     Epoch: 63
2023-01-04 09:32:14,613 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36958752473195394, 'Total loss': 0.36958752473195394} | train loss {'Reaction outcome loss': 0.29496569807499484, 'Total loss': 0.29496569807499484}
2023-01-04 09:32:14,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:14,614 INFO:     Epoch: 64
2023-01-04 09:32:16,178 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38413745959599815, 'Total loss': 0.38413745959599815} | train loss {'Reaction outcome loss': 0.3113461421613676, 'Total loss': 0.3113461421613676}
2023-01-04 09:32:16,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:16,179 INFO:     Epoch: 65
2023-01-04 09:32:17,765 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35184922615687053, 'Total loss': 0.35184922615687053} | train loss {'Reaction outcome loss': 0.4251778464413423, 'Total loss': 0.4251778464413423}
2023-01-04 09:32:17,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:17,766 INFO:     Epoch: 66
2023-01-04 09:32:19,338 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3782177212337653, 'Total loss': 0.3782177212337653} | train loss {'Reaction outcome loss': 0.3137466490447548, 'Total loss': 0.3137466490447548}
2023-01-04 09:32:19,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:19,338 INFO:     Epoch: 67
2023-01-04 09:32:20,969 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37108165125052134, 'Total loss': 0.37108165125052134} | train loss {'Reaction outcome loss': 0.30347335841203027, 'Total loss': 0.30347335841203027}
2023-01-04 09:32:20,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:20,969 INFO:     Epoch: 68
2023-01-04 09:32:22,587 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3437751799821854, 'Total loss': 0.3437751799821854} | train loss {'Reaction outcome loss': 0.29791998407681997, 'Total loss': 0.29791998407681997}
2023-01-04 09:32:22,587 INFO:     Found new best model at epoch 68
2023-01-04 09:32:22,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:22,588 INFO:     Epoch: 69
2023-01-04 09:32:24,168 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34964278439680735, 'Total loss': 0.34964278439680735} | train loss {'Reaction outcome loss': 0.29006408961214364, 'Total loss': 0.29006408961214364}
2023-01-04 09:32:24,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:24,168 INFO:     Epoch: 70
2023-01-04 09:32:25,794 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3578238144516945, 'Total loss': 0.3578238144516945} | train loss {'Reaction outcome loss': 0.2855689638647322, 'Total loss': 0.2855689638647322}
2023-01-04 09:32:25,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:25,794 INFO:     Epoch: 71
2023-01-04 09:32:27,412 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34553518891334534, 'Total loss': 0.34553518891334534} | train loss {'Reaction outcome loss': 0.28685070584912825, 'Total loss': 0.28685070584912825}
2023-01-04 09:32:27,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:27,413 INFO:     Epoch: 72
2023-01-04 09:32:29,005 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3788948625326157, 'Total loss': 0.3788948625326157} | train loss {'Reaction outcome loss': 0.2895389562412068, 'Total loss': 0.2895389562412068}
2023-01-04 09:32:29,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:29,005 INFO:     Epoch: 73
2023-01-04 09:32:30,637 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34498670101165774, 'Total loss': 0.34498670101165774} | train loss {'Reaction outcome loss': 0.2839455654426221, 'Total loss': 0.2839455654426221}
2023-01-04 09:32:30,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:30,637 INFO:     Epoch: 74
2023-01-04 09:32:32,217 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.33952858398358027, 'Total loss': 0.33952858398358027} | train loss {'Reaction outcome loss': 0.29011940189461777, 'Total loss': 0.29011940189461777}
2023-01-04 09:32:32,217 INFO:     Found new best model at epoch 74
2023-01-04 09:32:32,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:32,218 INFO:     Epoch: 75
2023-01-04 09:32:33,838 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3703696519136429, 'Total loss': 0.3703696519136429} | train loss {'Reaction outcome loss': 0.29541173770490603, 'Total loss': 0.29541173770490603}
2023-01-04 09:32:33,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:33,838 INFO:     Epoch: 76
2023-01-04 09:32:35,457 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3682820588350296, 'Total loss': 0.3682820588350296} | train loss {'Reaction outcome loss': 0.2795743341515502, 'Total loss': 0.2795743341515502}
2023-01-04 09:32:35,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:35,458 INFO:     Epoch: 77
2023-01-04 09:32:37,026 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3457328009108702, 'Total loss': 0.3457328009108702} | train loss {'Reaction outcome loss': 0.3066443060727223, 'Total loss': 0.3066443060727223}
2023-01-04 09:32:37,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:37,026 INFO:     Epoch: 78
2023-01-04 09:32:38,657 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34969490170478823, 'Total loss': 0.34969490170478823} | train loss {'Reaction outcome loss': 0.29394497770978056, 'Total loss': 0.29394497770978056}
2023-01-04 09:32:38,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:38,657 INFO:     Epoch: 79
2023-01-04 09:32:40,273 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3445329308509827, 'Total loss': 0.3445329308509827} | train loss {'Reaction outcome loss': 0.30891402743957547, 'Total loss': 0.30891402743957547}
2023-01-04 09:32:40,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:40,274 INFO:     Epoch: 80
2023-01-04 09:32:41,833 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3454659680525462, 'Total loss': 0.3454659680525462} | train loss {'Reaction outcome loss': 0.2899760697046208, 'Total loss': 0.2899760697046208}
2023-01-04 09:32:41,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:41,833 INFO:     Epoch: 81
2023-01-04 09:32:43,467 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.34487797021865846, 'Total loss': 0.34487797021865846} | train loss {'Reaction outcome loss': 0.2864017820991309, 'Total loss': 0.2864017820991309}
2023-01-04 09:32:43,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:43,469 INFO:     Epoch: 82
2023-01-04 09:32:45,077 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3692248672246933, 'Total loss': 0.3692248672246933} | train loss {'Reaction outcome loss': 0.27896508603631787, 'Total loss': 0.27896508603631787}
2023-01-04 09:32:45,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:45,077 INFO:     Epoch: 83
2023-01-04 09:32:46,643 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46337649126847585, 'Total loss': 0.46337649126847585} | train loss {'Reaction outcome loss': 0.2847878971285578, 'Total loss': 0.2847878971285578}
2023-01-04 09:32:46,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:46,643 INFO:     Epoch: 84
2023-01-04 09:32:48,247 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.33655291199684145, 'Total loss': 0.33655291199684145} | train loss {'Reaction outcome loss': 0.3261434465621014, 'Total loss': 0.3261434465621014}
2023-01-04 09:32:48,247 INFO:     Found new best model at epoch 84
2023-01-04 09:32:48,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:48,248 INFO:     Epoch: 85
2023-01-04 09:32:49,849 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36187928716341655, 'Total loss': 0.36187928716341655} | train loss {'Reaction outcome loss': 0.2768498092174422, 'Total loss': 0.2768498092174422}
2023-01-04 09:32:49,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:49,850 INFO:     Epoch: 86
2023-01-04 09:32:51,417 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35526733895142876, 'Total loss': 0.35526733895142876} | train loss {'Reaction outcome loss': 0.27016200802788354, 'Total loss': 0.27016200802788354}
2023-01-04 09:32:51,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:51,417 INFO:     Epoch: 87
2023-01-04 09:32:53,035 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3855636219183604, 'Total loss': 0.3855636219183604} | train loss {'Reaction outcome loss': 0.2694369938499353, 'Total loss': 0.2694369938499353}
2023-01-04 09:32:53,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:53,035 INFO:     Epoch: 88
2023-01-04 09:32:54,653 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3812527229388555, 'Total loss': 0.3812527229388555} | train loss {'Reaction outcome loss': 0.26999114079576364, 'Total loss': 0.26999114079576364}
2023-01-04 09:32:54,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:54,653 INFO:     Epoch: 89
2023-01-04 09:32:56,218 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3578101297219594, 'Total loss': 0.3578101297219594} | train loss {'Reaction outcome loss': 0.26678246763217234, 'Total loss': 0.26678246763217234}
2023-01-04 09:32:56,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:56,218 INFO:     Epoch: 90
2023-01-04 09:32:57,794 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3693435549736023, 'Total loss': 0.3693435549736023} | train loss {'Reaction outcome loss': 0.2665863381896971, 'Total loss': 0.2665863381896971}
2023-01-04 09:32:57,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:57,795 INFO:     Epoch: 91
2023-01-04 09:32:59,350 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3682029793659846, 'Total loss': 0.3682029793659846} | train loss {'Reaction outcome loss': 0.2641364691211282, 'Total loss': 0.2641364691211282}
2023-01-04 09:32:59,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:32:59,350 INFO:     Epoch: 92
2023-01-04 09:33:00,970 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35733935236930847, 'Total loss': 0.35733935236930847} | train loss {'Reaction outcome loss': 0.2610109560724147, 'Total loss': 0.2610109560724147}
2023-01-04 09:33:00,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:00,970 INFO:     Epoch: 93
2023-01-04 09:33:02,561 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.33236613074938454, 'Total loss': 0.33236613074938454} | train loss {'Reaction outcome loss': 0.2695200057937325, 'Total loss': 0.2695200057937325}
2023-01-04 09:33:02,562 INFO:     Found new best model at epoch 93
2023-01-04 09:33:02,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:02,563 INFO:     Epoch: 94
2023-01-04 09:33:04,151 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34771465957164766, 'Total loss': 0.34771465957164766} | train loss {'Reaction outcome loss': 0.26523769411642867, 'Total loss': 0.26523769411642867}
2023-01-04 09:33:04,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:04,151 INFO:     Epoch: 95
2023-01-04 09:33:05,756 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3468190332253774, 'Total loss': 0.3468190332253774} | train loss {'Reaction outcome loss': 0.2613347468735731, 'Total loss': 0.2613347468735731}
2023-01-04 09:33:05,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:05,756 INFO:     Epoch: 96
2023-01-04 09:33:07,383 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3357931345701218, 'Total loss': 0.3357931345701218} | train loss {'Reaction outcome loss': 0.2930770655014161, 'Total loss': 0.2930770655014161}
2023-01-04 09:33:07,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:07,383 INFO:     Epoch: 97
2023-01-04 09:33:08,970 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3913961261510849, 'Total loss': 0.3913961261510849} | train loss {'Reaction outcome loss': 0.2924565490389216, 'Total loss': 0.2924565490389216}
2023-01-04 09:33:08,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:08,970 INFO:     Epoch: 98
2023-01-04 09:33:10,584 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33485149244467416, 'Total loss': 0.33485149244467416} | train loss {'Reaction outcome loss': 0.2818416158694637, 'Total loss': 0.2818416158694637}
2023-01-04 09:33:10,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:10,584 INFO:     Epoch: 99
2023-01-04 09:33:12,183 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36292026688655216, 'Total loss': 0.36292026688655216} | train loss {'Reaction outcome loss': 0.2632232192714793, 'Total loss': 0.2632232192714793}
2023-01-04 09:33:12,183 INFO:     Best model found after epoch 94 of 100.
2023-01-04 09:33:12,183 INFO:   Done with stage: TRAINING
2023-01-04 09:33:12,183 INFO:   Starting stage: EVALUATION
2023-01-04 09:33:12,313 INFO:   Done with stage: EVALUATION
2023-01-04 09:33:12,313 INFO:   Leaving out SEQ value Fold_1
2023-01-04 09:33:12,325 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 09:33:12,326 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:33:12,985 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:33:12,985 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:33:13,053 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:33:13,053 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:33:13,053 INFO:     No hyperparam tuning for this model
2023-01-04 09:33:13,053 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:33:13,053 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:33:13,054 INFO:     None feature selector for col prot
2023-01-04 09:33:13,054 INFO:     None feature selector for col prot
2023-01-04 09:33:13,054 INFO:     None feature selector for col prot
2023-01-04 09:33:13,055 INFO:     None feature selector for col chem
2023-01-04 09:33:13,055 INFO:     None feature selector for col chem
2023-01-04 09:33:13,055 INFO:     None feature selector for col chem
2023-01-04 09:33:13,055 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:33:13,055 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:33:13,056 INFO:     Number of params in model 70111
2023-01-04 09:33:13,059 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:33:13,059 INFO:   Starting stage: TRAINING
2023-01-04 09:33:13,103 INFO:     Val loss before train {'Reaction outcome loss': 1.1244267145792644, 'Total loss': 1.1244267145792644}
2023-01-04 09:33:13,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:13,103 INFO:     Epoch: 0
2023-01-04 09:33:14,689 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.853011800845464, 'Total loss': 0.853011800845464} | train loss {'Reaction outcome loss': 0.8347291943111983, 'Total loss': 0.8347291943111983}
2023-01-04 09:33:14,690 INFO:     Found new best model at epoch 0
2023-01-04 09:33:14,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:14,691 INFO:     Epoch: 1
2023-01-04 09:33:16,246 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7137920498847962, 'Total loss': 0.7137920498847962} | train loss {'Reaction outcome loss': 0.6846748479397974, 'Total loss': 0.6846748479397974}
2023-01-04 09:33:16,246 INFO:     Found new best model at epoch 1
2023-01-04 09:33:16,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:16,247 INFO:     Epoch: 2
2023-01-04 09:33:17,774 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5928779800732931, 'Total loss': 0.5928779800732931} | train loss {'Reaction outcome loss': 0.6010633657559258, 'Total loss': 0.6010633657559258}
2023-01-04 09:33:17,774 INFO:     Found new best model at epoch 2
2023-01-04 09:33:17,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:17,775 INFO:     Epoch: 3
2023-01-04 09:33:19,367 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5397619843482971, 'Total loss': 0.5397619843482971} | train loss {'Reaction outcome loss': 0.5581098871917303, 'Total loss': 0.5581098871917303}
2023-01-04 09:33:19,367 INFO:     Found new best model at epoch 3
2023-01-04 09:33:19,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:19,368 INFO:     Epoch: 4
2023-01-04 09:33:20,960 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5477004210154216, 'Total loss': 0.5477004210154216} | train loss {'Reaction outcome loss': 0.5330437872682551, 'Total loss': 0.5330437872682551}
2023-01-04 09:33:20,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:20,960 INFO:     Epoch: 5
2023-01-04 09:33:22,510 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5089254995187124, 'Total loss': 0.5089254995187124} | train loss {'Reaction outcome loss': 0.5142070080301419, 'Total loss': 0.5142070080301419}
2023-01-04 09:33:22,510 INFO:     Found new best model at epoch 5
2023-01-04 09:33:22,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:22,511 INFO:     Epoch: 6
2023-01-04 09:33:24,085 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5849627951780955, 'Total loss': 0.5849627951780955} | train loss {'Reaction outcome loss': 0.5040673251741487, 'Total loss': 0.5040673251741487}
2023-01-04 09:33:24,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:24,085 INFO:     Epoch: 7
2023-01-04 09:33:25,604 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5370471795399984, 'Total loss': 0.5370471795399984} | train loss {'Reaction outcome loss': 0.4925566383833375, 'Total loss': 0.4925566383833375}
2023-01-04 09:33:25,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:25,604 INFO:     Epoch: 8
2023-01-04 09:33:27,098 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49851084450880684, 'Total loss': 0.49851084450880684} | train loss {'Reaction outcome loss': 0.4858154798565755, 'Total loss': 0.4858154798565755}
2023-01-04 09:33:27,099 INFO:     Found new best model at epoch 8
2023-01-04 09:33:27,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:27,099 INFO:     Epoch: 9
2023-01-04 09:33:28,622 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47777055501937865, 'Total loss': 0.47777055501937865} | train loss {'Reaction outcome loss': 0.47767475670774046, 'Total loss': 0.47767475670774046}
2023-01-04 09:33:28,622 INFO:     Found new best model at epoch 9
2023-01-04 09:33:28,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:28,623 INFO:     Epoch: 10
2023-01-04 09:33:30,155 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5012037297089894, 'Total loss': 0.5012037297089894} | train loss {'Reaction outcome loss': 0.46755049248463115, 'Total loss': 0.46755049248463115}
2023-01-04 09:33:30,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:30,155 INFO:     Epoch: 11
2023-01-04 09:33:31,651 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5059641202290853, 'Total loss': 0.5059641202290853} | train loss {'Reaction outcome loss': 0.46260359146498226, 'Total loss': 0.46260359146498226}
2023-01-04 09:33:31,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:31,652 INFO:     Epoch: 12
2023-01-04 09:33:33,192 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5215931177139282, 'Total loss': 0.5215931177139282} | train loss {'Reaction outcome loss': 0.4537989921675397, 'Total loss': 0.4537989921675397}
2023-01-04 09:33:33,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:33,193 INFO:     Epoch: 13
2023-01-04 09:33:34,729 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4966511050860087, 'Total loss': 0.4966511050860087} | train loss {'Reaction outcome loss': 0.4506010227867598, 'Total loss': 0.4506010227867598}
2023-01-04 09:33:34,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:34,730 INFO:     Epoch: 14
2023-01-04 09:33:36,222 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5090842644373575, 'Total loss': 0.5090842644373575} | train loss {'Reaction outcome loss': 0.44918847045555327, 'Total loss': 0.44918847045555327}
2023-01-04 09:33:36,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:36,223 INFO:     Epoch: 15
2023-01-04 09:33:37,764 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4918977717558543, 'Total loss': 0.4918977717558543} | train loss {'Reaction outcome loss': 0.4426456568590829, 'Total loss': 0.4426456568590829}
2023-01-04 09:33:37,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:37,764 INFO:     Epoch: 16
2023-01-04 09:33:39,310 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4863942821820577, 'Total loss': 0.4863942821820577} | train loss {'Reaction outcome loss': 0.4358512825191681, 'Total loss': 0.4358512825191681}
2023-01-04 09:33:39,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:39,310 INFO:     Epoch: 17
2023-01-04 09:33:40,815 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4676620364189148, 'Total loss': 0.4676620364189148} | train loss {'Reaction outcome loss': 0.43073244216917184, 'Total loss': 0.43073244216917184}
2023-01-04 09:33:40,815 INFO:     Found new best model at epoch 17
2023-01-04 09:33:40,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:40,816 INFO:     Epoch: 18
2023-01-04 09:33:42,338 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48987857699394227, 'Total loss': 0.48987857699394227} | train loss {'Reaction outcome loss': 0.42832939406492615, 'Total loss': 0.42832939406492615}
2023-01-04 09:33:42,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:42,338 INFO:     Epoch: 19
2023-01-04 09:33:43,877 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4735929856697718, 'Total loss': 0.4735929856697718} | train loss {'Reaction outcome loss': 0.42253681192538833, 'Total loss': 0.42253681192538833}
2023-01-04 09:33:43,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:43,877 INFO:     Epoch: 20
2023-01-04 09:33:45,376 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47854420443375906, 'Total loss': 0.47854420443375906} | train loss {'Reaction outcome loss': 0.418619002583282, 'Total loss': 0.418619002583282}
2023-01-04 09:33:45,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:45,377 INFO:     Epoch: 21
2023-01-04 09:33:46,915 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4747230112552643, 'Total loss': 0.4747230112552643} | train loss {'Reaction outcome loss': 0.41173445920002855, 'Total loss': 0.41173445920002855}
2023-01-04 09:33:46,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:46,915 INFO:     Epoch: 22
2023-01-04 09:33:48,450 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5286732653776804, 'Total loss': 0.5286732653776804} | train loss {'Reaction outcome loss': 0.41191020245041793, 'Total loss': 0.41191020245041793}
2023-01-04 09:33:48,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:48,451 INFO:     Epoch: 23
2023-01-04 09:33:49,958 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4691133220990499, 'Total loss': 0.4691133220990499} | train loss {'Reaction outcome loss': 0.40993469029774965, 'Total loss': 0.40993469029774965}
2023-01-04 09:33:49,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:49,959 INFO:     Epoch: 24
2023-01-04 09:33:51,519 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4772270063559214, 'Total loss': 0.4772270063559214} | train loss {'Reaction outcome loss': 0.40661214193074907, 'Total loss': 0.40661214193074907}
2023-01-04 09:33:51,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:51,520 INFO:     Epoch: 25
2023-01-04 09:33:53,058 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48572571376959484, 'Total loss': 0.48572571376959484} | train loss {'Reaction outcome loss': 0.3969200933661408, 'Total loss': 0.3969200933661408}
2023-01-04 09:33:53,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:53,058 INFO:     Epoch: 26
2023-01-04 09:33:54,561 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4621235052744547, 'Total loss': 0.4621235052744547} | train loss {'Reaction outcome loss': 0.3955058853014809, 'Total loss': 0.3955058853014809}
2023-01-04 09:33:54,561 INFO:     Found new best model at epoch 26
2023-01-04 09:33:54,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:54,562 INFO:     Epoch: 27
2023-01-04 09:33:56,089 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45409199049075444, 'Total loss': 0.45409199049075444} | train loss {'Reaction outcome loss': 0.38932975832496625, 'Total loss': 0.38932975832496625}
2023-01-04 09:33:56,090 INFO:     Found new best model at epoch 27
2023-01-04 09:33:56,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:56,091 INFO:     Epoch: 28
2023-01-04 09:33:57,630 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4337896962960561, 'Total loss': 0.4337896962960561} | train loss {'Reaction outcome loss': 0.3883337107421727, 'Total loss': 0.3883337107421727}
2023-01-04 09:33:57,631 INFO:     Found new best model at epoch 28
2023-01-04 09:33:57,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:57,631 INFO:     Epoch: 29
2023-01-04 09:33:59,156 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4551501582066218, 'Total loss': 0.4551501582066218} | train loss {'Reaction outcome loss': 0.38530040744046, 'Total loss': 0.38530040744046}
2023-01-04 09:33:59,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:33:59,156 INFO:     Epoch: 30
2023-01-04 09:34:00,714 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4593473474184672, 'Total loss': 0.4593473474184672} | train loss {'Reaction outcome loss': 0.38361786712799567, 'Total loss': 0.38361786712799567}
2023-01-04 09:34:00,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:00,714 INFO:     Epoch: 31
2023-01-04 09:34:02,261 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4425005515416463, 'Total loss': 0.4425005515416463} | train loss {'Reaction outcome loss': 0.37822249075363484, 'Total loss': 0.37822249075363484}
2023-01-04 09:34:02,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:02,261 INFO:     Epoch: 32
2023-01-04 09:34:03,756 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4439470003048579, 'Total loss': 0.4439470003048579} | train loss {'Reaction outcome loss': 0.3747655848845345, 'Total loss': 0.3747655848845345}
2023-01-04 09:34:03,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:03,756 INFO:     Epoch: 33
2023-01-04 09:34:05,277 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45039496223131814, 'Total loss': 0.45039496223131814} | train loss {'Reaction outcome loss': 0.3798330116096018, 'Total loss': 0.3798330116096018}
2023-01-04 09:34:05,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:05,277 INFO:     Epoch: 34
2023-01-04 09:34:06,798 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46380003293355304, 'Total loss': 0.46380003293355304} | train loss {'Reaction outcome loss': 0.36911976980767125, 'Total loss': 0.36911976980767125}
2023-01-04 09:34:06,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:06,798 INFO:     Epoch: 35
2023-01-04 09:34:08,293 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46358491977055866, 'Total loss': 0.46358491977055866} | train loss {'Reaction outcome loss': 0.36086966850660823, 'Total loss': 0.36086966850660823}
2023-01-04 09:34:08,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:08,294 INFO:     Epoch: 36
2023-01-04 09:34:09,815 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43869726955890653, 'Total loss': 0.43869726955890653} | train loss {'Reaction outcome loss': 0.3616690477321948, 'Total loss': 0.3616690477321948}
2023-01-04 09:34:09,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:09,815 INFO:     Epoch: 37
2023-01-04 09:34:11,344 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46368165612220763, 'Total loss': 0.46368165612220763} | train loss {'Reaction outcome loss': 0.3596637244319124, 'Total loss': 0.3596637244319124}
2023-01-04 09:34:11,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:11,344 INFO:     Epoch: 38
2023-01-04 09:34:12,858 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4600317060947418, 'Total loss': 0.4600317060947418} | train loss {'Reaction outcome loss': 0.35882779197059433, 'Total loss': 0.35882779197059433}
2023-01-04 09:34:12,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:12,859 INFO:     Epoch: 39
2023-01-04 09:34:14,384 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5065366148948669, 'Total loss': 0.5065366148948669} | train loss {'Reaction outcome loss': 0.35598748075566167, 'Total loss': 0.35598748075566167}
2023-01-04 09:34:14,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:14,385 INFO:     Epoch: 40
2023-01-04 09:34:15,916 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41966401611765225, 'Total loss': 0.41966401611765225} | train loss {'Reaction outcome loss': 0.34860448943402933, 'Total loss': 0.34860448943402933}
2023-01-04 09:34:15,916 INFO:     Found new best model at epoch 40
2023-01-04 09:34:15,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:15,917 INFO:     Epoch: 41
2023-01-04 09:34:17,420 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4179191062847773, 'Total loss': 0.4179191062847773} | train loss {'Reaction outcome loss': 0.34857986897670035, 'Total loss': 0.34857986897670035}
2023-01-04 09:34:17,420 INFO:     Found new best model at epoch 41
2023-01-04 09:34:17,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:17,421 INFO:     Epoch: 42
2023-01-04 09:34:18,949 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4740041295687358, 'Total loss': 0.4740041295687358} | train loss {'Reaction outcome loss': 0.3439935741334384, 'Total loss': 0.3439935741334384}
2023-01-04 09:34:18,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:18,949 INFO:     Epoch: 43
2023-01-04 09:34:20,478 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45805327196915946, 'Total loss': 0.45805327196915946} | train loss {'Reaction outcome loss': 0.338763066295988, 'Total loss': 0.338763066295988}
2023-01-04 09:34:20,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:20,479 INFO:     Epoch: 44
2023-01-04 09:34:21,970 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.436821906765302, 'Total loss': 0.436821906765302} | train loss {'Reaction outcome loss': 0.3437334737599556, 'Total loss': 0.3437334737599556}
2023-01-04 09:34:21,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:21,970 INFO:     Epoch: 45
2023-01-04 09:34:23,498 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4260420918464661, 'Total loss': 0.4260420918464661} | train loss {'Reaction outcome loss': 0.3371737266433635, 'Total loss': 0.3371737266433635}
2023-01-04 09:34:23,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:23,499 INFO:     Epoch: 46
2023-01-04 09:34:25,016 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4597022612889608, 'Total loss': 0.4597022612889608} | train loss {'Reaction outcome loss': 0.3336572593483538, 'Total loss': 0.3336572593483538}
2023-01-04 09:34:25,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:25,016 INFO:     Epoch: 47
2023-01-04 09:34:26,519 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4278277367353439, 'Total loss': 0.4278277367353439} | train loss {'Reaction outcome loss': 0.32646796428959307, 'Total loss': 0.32646796428959307}
2023-01-04 09:34:26,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:26,520 INFO:     Epoch: 48
2023-01-04 09:34:28,044 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43742879033088683, 'Total loss': 0.43742879033088683} | train loss {'Reaction outcome loss': 0.33455275590239414, 'Total loss': 0.33455275590239414}
2023-01-04 09:34:28,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:28,045 INFO:     Epoch: 49
2023-01-04 09:34:29,567 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46756186385949455, 'Total loss': 0.46756186385949455} | train loss {'Reaction outcome loss': 0.32807801702365663, 'Total loss': 0.32807801702365663}
2023-01-04 09:34:29,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:29,567 INFO:     Epoch: 50
2023-01-04 09:34:31,052 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4624097585678101, 'Total loss': 0.4624097585678101} | train loss {'Reaction outcome loss': 0.3264875449102743, 'Total loss': 0.3264875449102743}
2023-01-04 09:34:31,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:31,052 INFO:     Epoch: 51
2023-01-04 09:34:32,562 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45910561084747314, 'Total loss': 0.45910561084747314} | train loss {'Reaction outcome loss': 0.32279129928438427, 'Total loss': 0.32279129928438427}
2023-01-04 09:34:32,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:32,562 INFO:     Epoch: 52
2023-01-04 09:34:34,102 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42507807513078055, 'Total loss': 0.42507807513078055} | train loss {'Reaction outcome loss': 0.32079876214265823, 'Total loss': 0.32079876214265823}
2023-01-04 09:34:34,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:34,102 INFO:     Epoch: 53
2023-01-04 09:34:35,604 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.432496640086174, 'Total loss': 0.432496640086174} | train loss {'Reaction outcome loss': 0.31729993070183643, 'Total loss': 0.31729993070183643}
2023-01-04 09:34:35,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:35,605 INFO:     Epoch: 54
2023-01-04 09:34:37,144 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4343484570582708, 'Total loss': 0.4343484570582708} | train loss {'Reaction outcome loss': 0.3171616020402785, 'Total loss': 0.3171616020402785}
2023-01-04 09:34:37,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:37,145 INFO:     Epoch: 55
2023-01-04 09:34:38,704 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48391138315200805, 'Total loss': 0.48391138315200805} | train loss {'Reaction outcome loss': 0.3165816660984196, 'Total loss': 0.3165816660984196}
2023-01-04 09:34:38,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:38,705 INFO:     Epoch: 56
2023-01-04 09:34:40,214 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4479725311199824, 'Total loss': 0.4479725311199824} | train loss {'Reaction outcome loss': 0.3150033317368849, 'Total loss': 0.3150033317368849}
2023-01-04 09:34:40,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:40,215 INFO:     Epoch: 57
2023-01-04 09:34:41,767 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49179246624310813, 'Total loss': 0.49179246624310813} | train loss {'Reaction outcome loss': 0.30907749964742204, 'Total loss': 0.30907749964742204}
2023-01-04 09:34:41,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:41,767 INFO:     Epoch: 58
2023-01-04 09:34:43,316 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41660247147083285, 'Total loss': 0.41660247147083285} | train loss {'Reaction outcome loss': 0.3071515325910491, 'Total loss': 0.3071515325910491}
2023-01-04 09:34:43,316 INFO:     Found new best model at epoch 58
2023-01-04 09:34:43,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:43,317 INFO:     Epoch: 59
2023-01-04 09:34:44,844 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4282285283009211, 'Total loss': 0.4282285283009211} | train loss {'Reaction outcome loss': 0.30802500663098376, 'Total loss': 0.30802500663098376}
2023-01-04 09:34:44,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:44,844 INFO:     Epoch: 60
2023-01-04 09:34:46,387 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4324955860773722, 'Total loss': 0.4324955860773722} | train loss {'Reaction outcome loss': 0.3057133044593888, 'Total loss': 0.3057133044593888}
2023-01-04 09:34:46,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:46,387 INFO:     Epoch: 61
2023-01-04 09:34:47,915 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41981254319349925, 'Total loss': 0.41981254319349925} | train loss {'Reaction outcome loss': 0.30285320989100256, 'Total loss': 0.30285320989100256}
2023-01-04 09:34:47,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:47,916 INFO:     Epoch: 62
2023-01-04 09:34:49,450 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4491978238026301, 'Total loss': 0.4491978238026301} | train loss {'Reaction outcome loss': 0.3048234030714334, 'Total loss': 0.3048234030714334}
2023-01-04 09:34:49,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:49,450 INFO:     Epoch: 63
2023-01-04 09:34:51,030 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47975725730260216, 'Total loss': 0.47975725730260216} | train loss {'Reaction outcome loss': 0.295753213697254, 'Total loss': 0.295753213697254}
2023-01-04 09:34:51,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:51,031 INFO:     Epoch: 64
2023-01-04 09:34:52,614 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.436871862411499, 'Total loss': 0.436871862411499} | train loss {'Reaction outcome loss': 0.3019007760550263, 'Total loss': 0.3019007760550263}
2023-01-04 09:34:52,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:52,615 INFO:     Epoch: 65
2023-01-04 09:34:54,133 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4372289498647054, 'Total loss': 0.4372289498647054} | train loss {'Reaction outcome loss': 0.2959957026302594, 'Total loss': 0.2959957026302594}
2023-01-04 09:34:54,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:54,133 INFO:     Epoch: 66
2023-01-04 09:34:55,676 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44605504274368285, 'Total loss': 0.44605504274368285} | train loss {'Reaction outcome loss': 0.29630750023185987, 'Total loss': 0.29630750023185987}
2023-01-04 09:34:55,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:55,677 INFO:     Epoch: 67
2023-01-04 09:34:57,180 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42553675870100655, 'Total loss': 0.42553675870100655} | train loss {'Reaction outcome loss': 0.2923629659183351, 'Total loss': 0.2923629659183351}
2023-01-04 09:34:57,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:57,180 INFO:     Epoch: 68
2023-01-04 09:34:58,708 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4326228559017181, 'Total loss': 0.4326228559017181} | train loss {'Reaction outcome loss': 0.29224072763785663, 'Total loss': 0.29224072763785663}
2023-01-04 09:34:58,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:34:58,708 INFO:     Epoch: 69
2023-01-04 09:35:00,270 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4414576192696889, 'Total loss': 0.4414576192696889} | train loss {'Reaction outcome loss': 0.2927516966618295, 'Total loss': 0.2927516966618295}
2023-01-04 09:35:00,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:00,270 INFO:     Epoch: 70
2023-01-04 09:35:01,817 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4794831156730652, 'Total loss': 0.4794831156730652} | train loss {'Reaction outcome loss': 0.28743793558315595, 'Total loss': 0.28743793558315595}
2023-01-04 09:35:01,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:01,817 INFO:     Epoch: 71
2023-01-04 09:35:03,351 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4623127808173498, 'Total loss': 0.4623127808173498} | train loss {'Reaction outcome loss': 0.28651015229550675, 'Total loss': 0.28651015229550675}
2023-01-04 09:35:03,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:03,351 INFO:     Epoch: 72
2023-01-04 09:35:04,876 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46976992934942247, 'Total loss': 0.46976992934942247} | train loss {'Reaction outcome loss': 0.285801113971485, 'Total loss': 0.285801113971485}
2023-01-04 09:35:04,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:04,877 INFO:     Epoch: 73
2023-01-04 09:35:06,379 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4334170122941335, 'Total loss': 0.4334170122941335} | train loss {'Reaction outcome loss': 0.2854431512116066, 'Total loss': 0.2854431512116066}
2023-01-04 09:35:06,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:06,379 INFO:     Epoch: 74
2023-01-04 09:35:07,905 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43573622504870096, 'Total loss': 0.43573622504870096} | train loss {'Reaction outcome loss': 0.2821062198836645, 'Total loss': 0.2821062198836645}
2023-01-04 09:35:07,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:07,906 INFO:     Epoch: 75
2023-01-04 09:35:09,415 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4624555826187134, 'Total loss': 0.4624555826187134} | train loss {'Reaction outcome loss': 0.2790516654778671, 'Total loss': 0.2790516654778671}
2023-01-04 09:35:09,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:09,416 INFO:     Epoch: 76
2023-01-04 09:35:10,919 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39679259061813354, 'Total loss': 0.39679259061813354} | train loss {'Reaction outcome loss': 0.2818633697624576, 'Total loss': 0.2818633697624576}
2023-01-04 09:35:10,919 INFO:     Found new best model at epoch 76
2023-01-04 09:35:10,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:10,920 INFO:     Epoch: 77
2023-01-04 09:35:12,429 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4505837659041087, 'Total loss': 0.4505837659041087} | train loss {'Reaction outcome loss': 0.27840280296397824, 'Total loss': 0.27840280296397824}
2023-01-04 09:35:12,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:12,429 INFO:     Epoch: 78
2023-01-04 09:35:13,960 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4071692665417989, 'Total loss': 0.4071692665417989} | train loss {'Reaction outcome loss': 0.27649490103620444, 'Total loss': 0.27649490103620444}
2023-01-04 09:35:13,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:13,960 INFO:     Epoch: 79
2023-01-04 09:35:15,449 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43454589148362477, 'Total loss': 0.43454589148362477} | train loss {'Reaction outcome loss': 0.27383478425745594, 'Total loss': 0.27383478425745594}
2023-01-04 09:35:15,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:15,450 INFO:     Epoch: 80
2023-01-04 09:35:16,973 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4344681163628896, 'Total loss': 0.4344681163628896} | train loss {'Reaction outcome loss': 0.2725932401814584, 'Total loss': 0.2725932401814584}
2023-01-04 09:35:16,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:16,973 INFO:     Epoch: 81
2023-01-04 09:35:18,480 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4572681367397308, 'Total loss': 0.4572681367397308} | train loss {'Reaction outcome loss': 0.27146064385606794, 'Total loss': 0.27146064385606794}
2023-01-04 09:35:18,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:18,480 INFO:     Epoch: 82
2023-01-04 09:35:19,997 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4072569320599238, 'Total loss': 0.4072569320599238} | train loss {'Reaction outcome loss': 0.271819837556334, 'Total loss': 0.271819837556334}
2023-01-04 09:35:19,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:19,998 INFO:     Epoch: 83
2023-01-04 09:35:21,522 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.493467386563619, 'Total loss': 0.493467386563619} | train loss {'Reaction outcome loss': 0.2672435087306473, 'Total loss': 0.2672435087306473}
2023-01-04 09:35:21,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:21,522 INFO:     Epoch: 84
2023-01-04 09:35:23,081 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4279301424821218, 'Total loss': 0.4279301424821218} | train loss {'Reaction outcome loss': 0.2713926406199202, 'Total loss': 0.2713926406199202}
2023-01-04 09:35:23,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:23,082 INFO:     Epoch: 85
2023-01-04 09:35:24,604 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4083481748898824, 'Total loss': 0.4083481748898824} | train loss {'Reaction outcome loss': 0.26741040502142205, 'Total loss': 0.26741040502142205}
2023-01-04 09:35:24,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:24,604 INFO:     Epoch: 86
2023-01-04 09:35:26,158 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4538296697040399, 'Total loss': 0.4538296697040399} | train loss {'Reaction outcome loss': 0.2647860575316137, 'Total loss': 0.2647860575316137}
2023-01-04 09:35:26,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:26,158 INFO:     Epoch: 87
2023-01-04 09:35:27,690 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47560555636882784, 'Total loss': 0.47560555636882784} | train loss {'Reaction outcome loss': 0.26539179134247926, 'Total loss': 0.26539179134247926}
2023-01-04 09:35:27,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:27,691 INFO:     Epoch: 88
2023-01-04 09:35:29,201 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4262051781018575, 'Total loss': 0.4262051781018575} | train loss {'Reaction outcome loss': 0.265204906821031, 'Total loss': 0.265204906821031}
2023-01-04 09:35:29,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:29,201 INFO:     Epoch: 89
2023-01-04 09:35:30,729 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4134984036286672, 'Total loss': 0.4134984036286672} | train loss {'Reaction outcome loss': 0.2700037343695595, 'Total loss': 0.2700037343695595}
2023-01-04 09:35:30,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:30,729 INFO:     Epoch: 90
2023-01-04 09:35:32,263 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39286119292179744, 'Total loss': 0.39286119292179744} | train loss {'Reaction outcome loss': 0.2630822418113256, 'Total loss': 0.2630822418113256}
2023-01-04 09:35:32,263 INFO:     Found new best model at epoch 90
2023-01-04 09:35:32,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:32,263 INFO:     Epoch: 91
2023-01-04 09:35:33,763 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4075869540373484, 'Total loss': 0.4075869540373484} | train loss {'Reaction outcome loss': 0.2603242860289077, 'Total loss': 0.2603242860289077}
2023-01-04 09:35:33,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:33,763 INFO:     Epoch: 92
2023-01-04 09:35:35,304 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4107368389765422, 'Total loss': 0.4107368389765422} | train loss {'Reaction outcome loss': 0.2666319431496502, 'Total loss': 0.2666319431496502}
2023-01-04 09:35:35,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:35,305 INFO:     Epoch: 93
2023-01-04 09:35:36,838 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42729821701844534, 'Total loss': 0.42729821701844534} | train loss {'Reaction outcome loss': 0.2582797543506561, 'Total loss': 0.2582797543506561}
2023-01-04 09:35:36,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:36,838 INFO:     Epoch: 94
2023-01-04 09:35:38,346 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4167389661073685, 'Total loss': 0.4167389661073685} | train loss {'Reaction outcome loss': 0.25830986743923484, 'Total loss': 0.25830986743923484}
2023-01-04 09:35:38,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:38,346 INFO:     Epoch: 95
2023-01-04 09:35:39,877 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39677634835243225, 'Total loss': 0.39677634835243225} | train loss {'Reaction outcome loss': 0.2626836264705306, 'Total loss': 0.2626836264705306}
2023-01-04 09:35:39,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:39,877 INFO:     Epoch: 96
2023-01-04 09:35:41,431 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4482230136791865, 'Total loss': 0.4482230136791865} | train loss {'Reaction outcome loss': 0.2557137988205326, 'Total loss': 0.2557137988205326}
2023-01-04 09:35:41,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:41,431 INFO:     Epoch: 97
2023-01-04 09:35:42,942 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4544756501913071, 'Total loss': 0.4544756501913071} | train loss {'Reaction outcome loss': 0.255086277546258, 'Total loss': 0.255086277546258}
2023-01-04 09:35:42,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:42,942 INFO:     Epoch: 98
2023-01-04 09:35:44,505 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42890854279200236, 'Total loss': 0.42890854279200236} | train loss {'Reaction outcome loss': 0.2530072191627043, 'Total loss': 0.2530072191627043}
2023-01-04 09:35:44,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:44,506 INFO:     Epoch: 99
2023-01-04 09:35:46,056 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44676825900872547, 'Total loss': 0.44676825900872547} | train loss {'Reaction outcome loss': 0.24965139248879192, 'Total loss': 0.24965139248879192}
2023-01-04 09:35:46,057 INFO:     Best model found after epoch 91 of 100.
2023-01-04 09:35:46,057 INFO:   Done with stage: TRAINING
2023-01-04 09:35:46,057 INFO:   Starting stage: EVALUATION
2023-01-04 09:35:46,206 INFO:   Done with stage: EVALUATION
2023-01-04 09:35:46,207 INFO:   Leaving out SEQ value Fold_2
2023-01-04 09:35:46,219 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 09:35:46,220 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:35:46,867 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:35:46,867 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:35:46,935 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:35:46,935 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:35:46,935 INFO:     No hyperparam tuning for this model
2023-01-04 09:35:46,935 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:35:46,935 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:35:46,936 INFO:     None feature selector for col prot
2023-01-04 09:35:46,936 INFO:     None feature selector for col prot
2023-01-04 09:35:46,936 INFO:     None feature selector for col prot
2023-01-04 09:35:46,937 INFO:     None feature selector for col chem
2023-01-04 09:35:46,937 INFO:     None feature selector for col chem
2023-01-04 09:35:46,937 INFO:     None feature selector for col chem
2023-01-04 09:35:46,937 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:35:46,937 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:35:46,938 INFO:     Number of params in model 70111
2023-01-04 09:35:46,941 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:35:46,942 INFO:   Starting stage: TRAINING
2023-01-04 09:35:46,982 INFO:     Val loss before train {'Reaction outcome loss': 0.9390897552172343, 'Total loss': 0.9390897552172343}
2023-01-04 09:35:46,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:46,983 INFO:     Epoch: 0
2023-01-04 09:35:48,551 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6730347990989685, 'Total loss': 0.6730347990989685} | train loss {'Reaction outcome loss': 0.8329293778995528, 'Total loss': 0.8329293778995528}
2023-01-04 09:35:48,551 INFO:     Found new best model at epoch 0
2023-01-04 09:35:48,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:48,552 INFO:     Epoch: 1
2023-01-04 09:35:50,137 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5929389337698618, 'Total loss': 0.5929389337698618} | train loss {'Reaction outcome loss': 0.6730088612241466, 'Total loss': 0.6730088612241466}
2023-01-04 09:35:50,137 INFO:     Found new best model at epoch 1
2023-01-04 09:35:50,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:50,138 INFO:     Epoch: 2
2023-01-04 09:35:51,669 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5272091905275981, 'Total loss': 0.5272091905275981} | train loss {'Reaction outcome loss': 0.5943329395712728, 'Total loss': 0.5943329395712728}
2023-01-04 09:35:51,669 INFO:     Found new best model at epoch 2
2023-01-04 09:35:51,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:51,670 INFO:     Epoch: 3
2023-01-04 09:35:53,217 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5299889504909515, 'Total loss': 0.5299889504909515} | train loss {'Reaction outcome loss': 0.5585493678159087, 'Total loss': 0.5585493678159087}
2023-01-04 09:35:53,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:53,217 INFO:     Epoch: 4
2023-01-04 09:35:54,770 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5075314402580261, 'Total loss': 0.5075314402580261} | train loss {'Reaction outcome loss': 0.5342528840159848, 'Total loss': 0.5342528840159848}
2023-01-04 09:35:54,770 INFO:     Found new best model at epoch 4
2023-01-04 09:35:54,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:54,770 INFO:     Epoch: 5
2023-01-04 09:35:56,270 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47684571544329324, 'Total loss': 0.47684571544329324} | train loss {'Reaction outcome loss': 0.5203292620551847, 'Total loss': 0.5203292620551847}
2023-01-04 09:35:56,270 INFO:     Found new best model at epoch 5
2023-01-04 09:35:56,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:56,271 INFO:     Epoch: 6
2023-01-04 09:35:57,807 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48657908936341604, 'Total loss': 0.48657908936341604} | train loss {'Reaction outcome loss': 0.5098659631653424, 'Total loss': 0.5098659631653424}
2023-01-04 09:35:57,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:57,808 INFO:     Epoch: 7
2023-01-04 09:35:59,367 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4826346099376678, 'Total loss': 0.4826346099376678} | train loss {'Reaction outcome loss': 0.4987364663694897, 'Total loss': 0.4987364663694897}
2023-01-04 09:35:59,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:35:59,367 INFO:     Epoch: 8
2023-01-04 09:36:00,887 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4845628986756007, 'Total loss': 0.4845628986756007} | train loss {'Reaction outcome loss': 0.48886141974995606, 'Total loss': 0.48886141974995606}
2023-01-04 09:36:00,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:00,887 INFO:     Epoch: 9
2023-01-04 09:36:02,439 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4843965570131938, 'Total loss': 0.4843965570131938} | train loss {'Reaction outcome loss': 0.4863368345111826, 'Total loss': 0.4863368345111826}
2023-01-04 09:36:02,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:02,439 INFO:     Epoch: 10
2023-01-04 09:36:03,958 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44926129976908363, 'Total loss': 0.44926129976908363} | train loss {'Reaction outcome loss': 0.4787145359237699, 'Total loss': 0.4787145359237699}
2023-01-04 09:36:03,959 INFO:     Found new best model at epoch 10
2023-01-04 09:36:03,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:03,960 INFO:     Epoch: 11
2023-01-04 09:36:05,476 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4752001663049062, 'Total loss': 0.4752001663049062} | train loss {'Reaction outcome loss': 0.4779635854881175, 'Total loss': 0.4779635854881175}
2023-01-04 09:36:05,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:05,476 INFO:     Epoch: 12
2023-01-04 09:36:07,018 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46862095793088276, 'Total loss': 0.46862095793088276} | train loss {'Reaction outcome loss': 0.4666136168215397, 'Total loss': 0.4666136168215397}
2023-01-04 09:36:07,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:07,018 INFO:     Epoch: 13
2023-01-04 09:36:08,560 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4686694045861562, 'Total loss': 0.4686694045861562} | train loss {'Reaction outcome loss': 0.46559639517081913, 'Total loss': 0.46559639517081913}
2023-01-04 09:36:08,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:08,561 INFO:     Epoch: 14
2023-01-04 09:36:10,088 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4665084779262543, 'Total loss': 0.4665084779262543} | train loss {'Reaction outcome loss': 0.45726071893625014, 'Total loss': 0.45726071893625014}
2023-01-04 09:36:10,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:10,088 INFO:     Epoch: 15
2023-01-04 09:36:11,656 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45703011949857075, 'Total loss': 0.45703011949857075} | train loss {'Reaction outcome loss': 0.45476512398815505, 'Total loss': 0.45476512398815505}
2023-01-04 09:36:11,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:11,656 INFO:     Epoch: 16
2023-01-04 09:36:13,207 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4633834809064865, 'Total loss': 0.4633834809064865} | train loss {'Reaction outcome loss': 0.4490946119066572, 'Total loss': 0.4490946119066572}
2023-01-04 09:36:13,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:13,208 INFO:     Epoch: 17
2023-01-04 09:36:14,742 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4752495944499969, 'Total loss': 0.4752495944499969} | train loss {'Reaction outcome loss': 0.4431382180565465, 'Total loss': 0.4431382180565465}
2023-01-04 09:36:14,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:14,743 INFO:     Epoch: 18
2023-01-04 09:36:16,312 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4433772106965383, 'Total loss': 0.4433772106965383} | train loss {'Reaction outcome loss': 0.444728810911196, 'Total loss': 0.444728810911196}
2023-01-04 09:36:16,312 INFO:     Found new best model at epoch 18
2023-01-04 09:36:16,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:16,313 INFO:     Epoch: 19
2023-01-04 09:36:17,881 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46361336509386697, 'Total loss': 0.46361336509386697} | train loss {'Reaction outcome loss': 0.43604973926596396, 'Total loss': 0.43604973926596396}
2023-01-04 09:36:17,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:17,881 INFO:     Epoch: 20
2023-01-04 09:36:19,418 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43448394040266675, 'Total loss': 0.43448394040266675} | train loss {'Reaction outcome loss': 0.4339367124612314, 'Total loss': 0.4339367124612314}
2023-01-04 09:36:19,418 INFO:     Found new best model at epoch 20
2023-01-04 09:36:19,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:19,419 INFO:     Epoch: 21
2023-01-04 09:36:20,978 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.444253679116567, 'Total loss': 0.444253679116567} | train loss {'Reaction outcome loss': 0.4284640145182175, 'Total loss': 0.4284640145182175}
2023-01-04 09:36:20,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:20,978 INFO:     Epoch: 22
2023-01-04 09:36:22,535 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4444572548071543, 'Total loss': 0.4444572548071543} | train loss {'Reaction outcome loss': 0.42436199327998786, 'Total loss': 0.42436199327998786}
2023-01-04 09:36:22,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:22,535 INFO:     Epoch: 23
2023-01-04 09:36:24,063 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42569310863812765, 'Total loss': 0.42569310863812765} | train loss {'Reaction outcome loss': 0.4194648437147593, 'Total loss': 0.4194648437147593}
2023-01-04 09:36:24,063 INFO:     Found new best model at epoch 23
2023-01-04 09:36:24,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:24,063 INFO:     Epoch: 24
2023-01-04 09:36:25,628 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42814414004484813, 'Total loss': 0.42814414004484813} | train loss {'Reaction outcome loss': 0.41719819899023014, 'Total loss': 0.41719819899023014}
2023-01-04 09:36:25,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:25,629 INFO:     Epoch: 25
2023-01-04 09:36:27,195 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43910686175028485, 'Total loss': 0.43910686175028485} | train loss {'Reaction outcome loss': 0.4148358383970539, 'Total loss': 0.4148358383970539}
2023-01-04 09:36:27,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:27,195 INFO:     Epoch: 26
2023-01-04 09:36:28,716 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4287813196579615, 'Total loss': 0.4287813196579615} | train loss {'Reaction outcome loss': 0.4107455627000245, 'Total loss': 0.4107455627000245}
2023-01-04 09:36:28,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:28,717 INFO:     Epoch: 27
2023-01-04 09:36:30,289 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.436646435658137, 'Total loss': 0.436646435658137} | train loss {'Reaction outcome loss': 0.40478621961644096, 'Total loss': 0.40478621961644096}
2023-01-04 09:36:30,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:30,289 INFO:     Epoch: 28
2023-01-04 09:36:31,848 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4608070989449819, 'Total loss': 0.4608070989449819} | train loss {'Reaction outcome loss': 0.4002310822914987, 'Total loss': 0.4002310822914987}
2023-01-04 09:36:31,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:31,848 INFO:     Epoch: 29
2023-01-04 09:36:33,375 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42702058056990305, 'Total loss': 0.42702058056990305} | train loss {'Reaction outcome loss': 0.39743119826282025, 'Total loss': 0.39743119826282025}
2023-01-04 09:36:33,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:33,376 INFO:     Epoch: 30
2023-01-04 09:36:34,944 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42145587702592213, 'Total loss': 0.42145587702592213} | train loss {'Reaction outcome loss': 0.39543235960015416, 'Total loss': 0.39543235960015416}
2023-01-04 09:36:34,945 INFO:     Found new best model at epoch 30
2023-01-04 09:36:34,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:34,946 INFO:     Epoch: 31
2023-01-04 09:36:36,494 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4269526938597361, 'Total loss': 0.4269526938597361} | train loss {'Reaction outcome loss': 0.39034781458169004, 'Total loss': 0.39034781458169004}
2023-01-04 09:36:36,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:36,494 INFO:     Epoch: 32
2023-01-04 09:36:38,055 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41719824274381, 'Total loss': 0.41719824274381} | train loss {'Reaction outcome loss': 0.3886197758090757, 'Total loss': 0.3886197758090757}
2023-01-04 09:36:38,056 INFO:     Found new best model at epoch 32
2023-01-04 09:36:38,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:38,056 INFO:     Epoch: 33
2023-01-04 09:36:39,632 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4453781843185425, 'Total loss': 0.4453781843185425} | train loss {'Reaction outcome loss': 0.38945767416679944, 'Total loss': 0.38945767416679944}
2023-01-04 09:36:39,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:39,632 INFO:     Epoch: 34
2023-01-04 09:36:41,212 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42952185769875845, 'Total loss': 0.42952185769875845} | train loss {'Reaction outcome loss': 0.3857952186117207, 'Total loss': 0.3857952186117207}
2023-01-04 09:36:41,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:41,212 INFO:     Epoch: 35
2023-01-04 09:36:42,759 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43478540182113645, 'Total loss': 0.43478540182113645} | train loss {'Reaction outcome loss': 0.3818807566035403, 'Total loss': 0.3818807566035403}
2023-01-04 09:36:42,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:42,759 INFO:     Epoch: 36
2023-01-04 09:36:44,323 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4326828956604004, 'Total loss': 0.4326828956604004} | train loss {'Reaction outcome loss': 0.37535963751321294, 'Total loss': 0.37535963751321294}
2023-01-04 09:36:44,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:44,323 INFO:     Epoch: 37
2023-01-04 09:36:45,843 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41692681511243185, 'Total loss': 0.41692681511243185} | train loss {'Reaction outcome loss': 0.3707171434903667, 'Total loss': 0.3707171434903667}
2023-01-04 09:36:45,843 INFO:     Found new best model at epoch 37
2023-01-04 09:36:45,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:45,844 INFO:     Epoch: 38
2023-01-04 09:36:47,405 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45830354690551756, 'Total loss': 0.45830354690551756} | train loss {'Reaction outcome loss': 0.36783963827973737, 'Total loss': 0.36783963827973737}
2023-01-04 09:36:47,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:47,405 INFO:     Epoch: 39
2023-01-04 09:36:48,964 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41762071251869204, 'Total loss': 0.41762071251869204} | train loss {'Reaction outcome loss': 0.366245364022516, 'Total loss': 0.366245364022516}
2023-01-04 09:36:48,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:48,964 INFO:     Epoch: 40
2023-01-04 09:36:50,490 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3851073205471039, 'Total loss': 0.3851073205471039} | train loss {'Reaction outcome loss': 0.3624157642361021, 'Total loss': 0.3624157642361021}
2023-01-04 09:36:50,490 INFO:     Found new best model at epoch 40
2023-01-04 09:36:50,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:50,491 INFO:     Epoch: 41
2023-01-04 09:36:52,041 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3979965955018997, 'Total loss': 0.3979965955018997} | train loss {'Reaction outcome loss': 0.3590671507927188, 'Total loss': 0.3590671507927188}
2023-01-04 09:36:52,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:52,042 INFO:     Epoch: 42
2023-01-04 09:36:53,604 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41561673482259115, 'Total loss': 0.41561673482259115} | train loss {'Reaction outcome loss': 0.3642070130003195, 'Total loss': 0.3642070130003195}
2023-01-04 09:36:53,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:53,604 INFO:     Epoch: 43
2023-01-04 09:36:55,148 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4127484252055486, 'Total loss': 0.4127484252055486} | train loss {'Reaction outcome loss': 0.3515545012850831, 'Total loss': 0.3515545012850831}
2023-01-04 09:36:55,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:55,148 INFO:     Epoch: 44
2023-01-04 09:36:56,715 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41636169453461963, 'Total loss': 0.41636169453461963} | train loss {'Reaction outcome loss': 0.3519114682274143, 'Total loss': 0.3519114682274143}
2023-01-04 09:36:56,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:56,715 INFO:     Epoch: 45
2023-01-04 09:36:58,300 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39374968806902566, 'Total loss': 0.39374968806902566} | train loss {'Reaction outcome loss': 0.3443529152032668, 'Total loss': 0.3443529152032668}
2023-01-04 09:36:58,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:58,300 INFO:     Epoch: 46
2023-01-04 09:36:59,850 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3973476231098175, 'Total loss': 0.3973476231098175} | train loss {'Reaction outcome loss': 0.3447451781834999, 'Total loss': 0.3447451781834999}
2023-01-04 09:36:59,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:36:59,851 INFO:     Epoch: 47
2023-01-04 09:37:01,436 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39572630723317465, 'Total loss': 0.39572630723317465} | train loss {'Reaction outcome loss': 0.3500076092670869, 'Total loss': 0.3500076092670869}
2023-01-04 09:37:01,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:01,436 INFO:     Epoch: 48
2023-01-04 09:37:03,031 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42764601012070974, 'Total loss': 0.42764601012070974} | train loss {'Reaction outcome loss': 0.34069598985523203, 'Total loss': 0.34069598985523203}
2023-01-04 09:37:03,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:03,032 INFO:     Epoch: 49
2023-01-04 09:37:04,287 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40746728678544364, 'Total loss': 0.40746728678544364} | train loss {'Reaction outcome loss': 0.33872859950863965, 'Total loss': 0.33872859950863965}
2023-01-04 09:37:04,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:04,287 INFO:     Epoch: 50
2023-01-04 09:37:05,323 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4090144634246826, 'Total loss': 0.4090144634246826} | train loss {'Reaction outcome loss': 0.3367335849108487, 'Total loss': 0.3367335849108487}
2023-01-04 09:37:05,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:05,323 INFO:     Epoch: 51
2023-01-04 09:37:06,348 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4048203517993291, 'Total loss': 0.4048203517993291} | train loss {'Reaction outcome loss': 0.3328201026268249, 'Total loss': 0.3328201026268249}
2023-01-04 09:37:06,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:06,348 INFO:     Epoch: 52
2023-01-04 09:37:07,381 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3967052807410558, 'Total loss': 0.3967052807410558} | train loss {'Reaction outcome loss': 0.33011160600576955, 'Total loss': 0.33011160600576955}
2023-01-04 09:37:07,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:07,381 INFO:     Epoch: 53
2023-01-04 09:37:08,475 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42804497877756753, 'Total loss': 0.42804497877756753} | train loss {'Reaction outcome loss': 0.3305354898890657, 'Total loss': 0.3305354898890657}
2023-01-04 09:37:08,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:08,475 INFO:     Epoch: 54
2023-01-04 09:37:10,080 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.442165466149648, 'Total loss': 0.442165466149648} | train loss {'Reaction outcome loss': 0.3308481196091123, 'Total loss': 0.3308481196091123}
2023-01-04 09:37:10,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:10,080 INFO:     Epoch: 55
2023-01-04 09:37:11,670 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3837603082259496, 'Total loss': 0.3837603082259496} | train loss {'Reaction outcome loss': 0.3251464078678702, 'Total loss': 0.3251464078678702}
2023-01-04 09:37:11,670 INFO:     Found new best model at epoch 55
2023-01-04 09:37:11,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:11,671 INFO:     Epoch: 56
2023-01-04 09:37:13,249 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39761385371287666, 'Total loss': 0.39761385371287666} | train loss {'Reaction outcome loss': 0.32101807940452204, 'Total loss': 0.32101807940452204}
2023-01-04 09:37:13,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:13,249 INFO:     Epoch: 57
2023-01-04 09:37:14,820 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3889758914709091, 'Total loss': 0.3889758914709091} | train loss {'Reaction outcome loss': 0.3224635656895864, 'Total loss': 0.3224635656895864}
2023-01-04 09:37:14,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:14,821 INFO:     Epoch: 58
2023-01-04 09:37:16,356 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.376956715186437, 'Total loss': 0.376956715186437} | train loss {'Reaction outcome loss': 0.32129548781000783, 'Total loss': 0.32129548781000783}
2023-01-04 09:37:16,356 INFO:     Found new best model at epoch 58
2023-01-04 09:37:16,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:16,357 INFO:     Epoch: 59
2023-01-04 09:37:17,900 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3671015086273352, 'Total loss': 0.3671015086273352} | train loss {'Reaction outcome loss': 0.3160785597606297, 'Total loss': 0.3160785597606297}
2023-01-04 09:37:17,900 INFO:     Found new best model at epoch 59
2023-01-04 09:37:17,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:17,901 INFO:     Epoch: 60
2023-01-04 09:37:19,448 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3771322478850683, 'Total loss': 0.3771322478850683} | train loss {'Reaction outcome loss': 0.31368342969213087, 'Total loss': 0.31368342969213087}
2023-01-04 09:37:19,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:19,449 INFO:     Epoch: 61
2023-01-04 09:37:21,011 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3844566876689593, 'Total loss': 0.3844566876689593} | train loss {'Reaction outcome loss': 0.31549614208349347, 'Total loss': 0.31549614208349347}
2023-01-04 09:37:21,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:21,012 INFO:     Epoch: 62
2023-01-04 09:37:22,602 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39459419548511504, 'Total loss': 0.39459419548511504} | train loss {'Reaction outcome loss': 0.3124439703286999, 'Total loss': 0.3124439703286999}
2023-01-04 09:37:22,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:22,602 INFO:     Epoch: 63
2023-01-04 09:37:24,146 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39409935772418975, 'Total loss': 0.39409935772418975} | train loss {'Reaction outcome loss': 0.3057047746205417, 'Total loss': 0.3057047746205417}
2023-01-04 09:37:24,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:24,146 INFO:     Epoch: 64
2023-01-04 09:37:25,726 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38517144074042636, 'Total loss': 0.38517144074042636} | train loss {'Reaction outcome loss': 0.3060850700377113, 'Total loss': 0.3060850700377113}
2023-01-04 09:37:25,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:25,726 INFO:     Epoch: 65
2023-01-04 09:37:27,243 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3896860678990682, 'Total loss': 0.3896860678990682} | train loss {'Reaction outcome loss': 0.3052009162730979, 'Total loss': 0.3052009162730979}
2023-01-04 09:37:27,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:27,244 INFO:     Epoch: 66
2023-01-04 09:37:28,805 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3758156994978587, 'Total loss': 0.3758156994978587} | train loss {'Reaction outcome loss': 0.30919894344941545, 'Total loss': 0.30919894344941545}
2023-01-04 09:37:28,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:28,805 INFO:     Epoch: 67
2023-01-04 09:37:30,372 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38168365781505903, 'Total loss': 0.38168365781505903} | train loss {'Reaction outcome loss': 0.3022065295627082, 'Total loss': 0.3022065295627082}
2023-01-04 09:37:30,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:30,373 INFO:     Epoch: 68
2023-01-04 09:37:31,954 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41677498519420625, 'Total loss': 0.41677498519420625} | train loss {'Reaction outcome loss': 0.30046752681207917, 'Total loss': 0.30046752681207917}
2023-01-04 09:37:31,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:31,954 INFO:     Epoch: 69
2023-01-04 09:37:33,502 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43012534379959105, 'Total loss': 0.43012534379959105} | train loss {'Reaction outcome loss': 0.3028955088153373, 'Total loss': 0.3028955088153373}
2023-01-04 09:37:33,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:33,502 INFO:     Epoch: 70
2023-01-04 09:37:35,059 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3730407093962034, 'Total loss': 0.3730407093962034} | train loss {'Reaction outcome loss': 0.2960137731946298, 'Total loss': 0.2960137731946298}
2023-01-04 09:37:35,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:35,060 INFO:     Epoch: 71
2023-01-04 09:37:36,579 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39790710906187693, 'Total loss': 0.39790710906187693} | train loss {'Reaction outcome loss': 0.29868000840944964, 'Total loss': 0.29868000840944964}
2023-01-04 09:37:36,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:36,580 INFO:     Epoch: 72
2023-01-04 09:37:38,146 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38979761600494384, 'Total loss': 0.38979761600494384} | train loss {'Reaction outcome loss': 0.29376391725220385, 'Total loss': 0.29376391725220385}
2023-01-04 09:37:38,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:38,146 INFO:     Epoch: 73
2023-01-04 09:37:39,708 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3866385281085968, 'Total loss': 0.3866385281085968} | train loss {'Reaction outcome loss': 0.2879816765903774, 'Total loss': 0.2879816765903774}
2023-01-04 09:37:39,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:39,708 INFO:     Epoch: 74
2023-01-04 09:37:41,245 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4057774861653646, 'Total loss': 0.4057774861653646} | train loss {'Reaction outcome loss': 0.2931762629453718, 'Total loss': 0.2931762629453718}
2023-01-04 09:37:41,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:41,245 INFO:     Epoch: 75
2023-01-04 09:37:42,753 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41630430420239767, 'Total loss': 0.41630430420239767} | train loss {'Reaction outcome loss': 0.29319668758361445, 'Total loss': 0.29319668758361445}
2023-01-04 09:37:42,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:42,754 INFO:     Epoch: 76
2023-01-04 09:37:44,308 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3829122056563695, 'Total loss': 0.3829122056563695} | train loss {'Reaction outcome loss': 0.2895904374682773, 'Total loss': 0.2895904374682773}
2023-01-04 09:37:44,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:44,309 INFO:     Epoch: 77
2023-01-04 09:37:45,817 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39823869069417317, 'Total loss': 0.39823869069417317} | train loss {'Reaction outcome loss': 0.28807056678907716, 'Total loss': 0.28807056678907716}
2023-01-04 09:37:45,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:45,817 INFO:     Epoch: 78
2023-01-04 09:37:47,375 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3817034661769867, 'Total loss': 0.3817034661769867} | train loss {'Reaction outcome loss': 0.28753405232934187, 'Total loss': 0.28753405232934187}
2023-01-04 09:37:47,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:47,375 INFO:     Epoch: 79
2023-01-04 09:37:48,912 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39020428955554964, 'Total loss': 0.39020428955554964} | train loss {'Reaction outcome loss': 0.28491237361228816, 'Total loss': 0.28491237361228816}
2023-01-04 09:37:48,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:48,913 INFO:     Epoch: 80
2023-01-04 09:37:50,472 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37589230090379716, 'Total loss': 0.37589230090379716} | train loss {'Reaction outcome loss': 0.2796732589711238, 'Total loss': 0.2796732589711238}
2023-01-04 09:37:50,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:50,473 INFO:     Epoch: 81
2023-01-04 09:37:51,999 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35531056572993597, 'Total loss': 0.35531056572993597} | train loss {'Reaction outcome loss': 0.2831083849398759, 'Total loss': 0.2831083849398759}
2023-01-04 09:37:51,999 INFO:     Found new best model at epoch 81
2023-01-04 09:37:52,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:52,000 INFO:     Epoch: 82
2023-01-04 09:37:53,551 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42346247732639314, 'Total loss': 0.42346247732639314} | train loss {'Reaction outcome loss': 0.2814638640486846, 'Total loss': 0.2814638640486846}
2023-01-04 09:37:53,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:53,552 INFO:     Epoch: 83
2023-01-04 09:37:55,086 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3915418873230616, 'Total loss': 0.3915418873230616} | train loss {'Reaction outcome loss': 0.2778809788861196, 'Total loss': 0.2778809788861196}
2023-01-04 09:37:55,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:55,086 INFO:     Epoch: 84
2023-01-04 09:37:56,631 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4083401362101237, 'Total loss': 0.4083401362101237} | train loss {'Reaction outcome loss': 0.27472533847130565, 'Total loss': 0.27472533847130565}
2023-01-04 09:37:56,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:56,632 INFO:     Epoch: 85
2023-01-04 09:37:58,202 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3887937804063161, 'Total loss': 0.3887937804063161} | train loss {'Reaction outcome loss': 0.2810586790968902, 'Total loss': 0.2810586790968902}
2023-01-04 09:37:58,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:58,202 INFO:     Epoch: 86
2023-01-04 09:37:59,767 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40615331927935283, 'Total loss': 0.40615331927935283} | train loss {'Reaction outcome loss': 0.27501850295132096, 'Total loss': 0.27501850295132096}
2023-01-04 09:37:59,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:37:59,767 INFO:     Epoch: 87
2023-01-04 09:38:01,291 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40021199186642964, 'Total loss': 0.40021199186642964} | train loss {'Reaction outcome loss': 0.2758625926871369, 'Total loss': 0.2758625926871369}
2023-01-04 09:38:01,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:01,292 INFO:     Epoch: 88
2023-01-04 09:38:02,833 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3763641019662221, 'Total loss': 0.3763641019662221} | train loss {'Reaction outcome loss': 0.271892204731159, 'Total loss': 0.271892204731159}
2023-01-04 09:38:02,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:02,833 INFO:     Epoch: 89
2023-01-04 09:38:04,394 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37502611776192984, 'Total loss': 0.37502611776192984} | train loss {'Reaction outcome loss': 0.27165401694330854, 'Total loss': 0.27165401694330854}
2023-01-04 09:38:04,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:04,394 INFO:     Epoch: 90
2023-01-04 09:38:05,966 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3983171527584394, 'Total loss': 0.3983171527584394} | train loss {'Reaction outcome loss': 0.27059783868110965, 'Total loss': 0.27059783868110965}
2023-01-04 09:38:05,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:05,966 INFO:     Epoch: 91
2023-01-04 09:38:07,547 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36998062431812284, 'Total loss': 0.36998062431812284} | train loss {'Reaction outcome loss': 0.27031789263234524, 'Total loss': 0.27031789263234524}
2023-01-04 09:38:07,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:07,548 INFO:     Epoch: 92
2023-01-04 09:38:09,112 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37641713122526804, 'Total loss': 0.37641713122526804} | train loss {'Reaction outcome loss': 0.2694850482971129, 'Total loss': 0.2694850482971129}
2023-01-04 09:38:09,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:09,113 INFO:     Epoch: 93
2023-01-04 09:38:10,642 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.375740721821785, 'Total loss': 0.375740721821785} | train loss {'Reaction outcome loss': 0.2664782547113234, 'Total loss': 0.2664782547113234}
2023-01-04 09:38:10,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:10,643 INFO:     Epoch: 94
2023-01-04 09:38:12,166 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.407247993350029, 'Total loss': 0.407247993350029} | train loss {'Reaction outcome loss': 0.2682954703260512, 'Total loss': 0.2682954703260512}
2023-01-04 09:38:12,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:12,166 INFO:     Epoch: 95
2023-01-04 09:38:13,742 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3621423035860062, 'Total loss': 0.3621423035860062} | train loss {'Reaction outcome loss': 0.2628993560444482, 'Total loss': 0.2628993560444482}
2023-01-04 09:38:13,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:13,742 INFO:     Epoch: 96
2023-01-04 09:38:15,304 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3797280689080556, 'Total loss': 0.3797280689080556} | train loss {'Reaction outcome loss': 0.26435165313908654, 'Total loss': 0.26435165313908654}
2023-01-04 09:38:15,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:15,304 INFO:     Epoch: 97
2023-01-04 09:38:16,864 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39634240915377933, 'Total loss': 0.39634240915377933} | train loss {'Reaction outcome loss': 0.2684955728260705, 'Total loss': 0.2684955728260705}
2023-01-04 09:38:16,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:16,864 INFO:     Epoch: 98
2023-01-04 09:38:18,423 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3788712278008461, 'Total loss': 0.3788712278008461} | train loss {'Reaction outcome loss': 0.2673426297812784, 'Total loss': 0.2673426297812784}
2023-01-04 09:38:18,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:18,424 INFO:     Epoch: 99
2023-01-04 09:38:19,959 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38399557371934256, 'Total loss': 0.38399557371934256} | train loss {'Reaction outcome loss': 0.2667137294137565, 'Total loss': 0.2667137294137565}
2023-01-04 09:38:19,960 INFO:     Best model found after epoch 82 of 100.
2023-01-04 09:38:19,960 INFO:   Done with stage: TRAINING
2023-01-04 09:38:19,960 INFO:   Starting stage: EVALUATION
2023-01-04 09:38:20,096 INFO:   Done with stage: EVALUATION
2023-01-04 09:38:20,096 INFO:   Leaving out SEQ value Fold_3
2023-01-04 09:38:20,109 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 09:38:20,109 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:38:20,746 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:38:20,746 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:38:20,813 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:38:20,813 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:38:20,814 INFO:     No hyperparam tuning for this model
2023-01-04 09:38:20,814 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:38:20,814 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:38:20,814 INFO:     None feature selector for col prot
2023-01-04 09:38:20,815 INFO:     None feature selector for col prot
2023-01-04 09:38:20,815 INFO:     None feature selector for col prot
2023-01-04 09:38:20,815 INFO:     None feature selector for col chem
2023-01-04 09:38:20,815 INFO:     None feature selector for col chem
2023-01-04 09:38:20,815 INFO:     None feature selector for col chem
2023-01-04 09:38:20,815 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:38:20,815 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:38:20,816 INFO:     Number of params in model 70111
2023-01-04 09:38:20,819 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:38:20,820 INFO:   Starting stage: TRAINING
2023-01-04 09:38:20,861 INFO:     Val loss before train {'Reaction outcome loss': 0.9636901179949443, 'Total loss': 0.9636901179949443}
2023-01-04 09:38:20,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:20,862 INFO:     Epoch: 0
2023-01-04 09:38:22,422 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7074988683064779, 'Total loss': 0.7074988683064779} | train loss {'Reaction outcome loss': 0.8398077224727964, 'Total loss': 0.8398077224727964}
2023-01-04 09:38:22,422 INFO:     Found new best model at epoch 0
2023-01-04 09:38:22,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:22,423 INFO:     Epoch: 1
2023-01-04 09:38:23,979 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5815048813819885, 'Total loss': 0.5815048813819885} | train loss {'Reaction outcome loss': 0.6813552653702506, 'Total loss': 0.6813552653702506}
2023-01-04 09:38:23,979 INFO:     Found new best model at epoch 1
2023-01-04 09:38:23,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:23,980 INFO:     Epoch: 2
2023-01-04 09:38:25,541 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5256020943323771, 'Total loss': 0.5256020943323771} | train loss {'Reaction outcome loss': 0.5848864126597008, 'Total loss': 0.5848864126597008}
2023-01-04 09:38:25,541 INFO:     Found new best model at epoch 2
2023-01-04 09:38:25,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:25,542 INFO:     Epoch: 3
2023-01-04 09:38:27,099 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5208160142103831, 'Total loss': 0.5208160142103831} | train loss {'Reaction outcome loss': 0.5455026360650133, 'Total loss': 0.5455026360650133}
2023-01-04 09:38:27,099 INFO:     Found new best model at epoch 3
2023-01-04 09:38:27,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:27,100 INFO:     Epoch: 4
2023-01-04 09:38:28,623 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5087985197703043, 'Total loss': 0.5087985197703043} | train loss {'Reaction outcome loss': 0.5225997640594949, 'Total loss': 0.5225997640594949}
2023-01-04 09:38:28,623 INFO:     Found new best model at epoch 4
2023-01-04 09:38:28,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:28,624 INFO:     Epoch: 5
2023-01-04 09:38:30,139 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5055927455425262, 'Total loss': 0.5055927455425262} | train loss {'Reaction outcome loss': 0.5093658405498867, 'Total loss': 0.5093658405498867}
2023-01-04 09:38:30,139 INFO:     Found new best model at epoch 5
2023-01-04 09:38:30,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:30,140 INFO:     Epoch: 6
2023-01-04 09:38:31,690 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.483484090367953, 'Total loss': 0.483484090367953} | train loss {'Reaction outcome loss': 0.49450024407710474, 'Total loss': 0.49450024407710474}
2023-01-04 09:38:31,691 INFO:     Found new best model at epoch 6
2023-01-04 09:38:31,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:31,692 INFO:     Epoch: 7
2023-01-04 09:38:33,243 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4935297389825185, 'Total loss': 0.4935297389825185} | train loss {'Reaction outcome loss': 0.4891517007329168, 'Total loss': 0.4891517007329168}
2023-01-04 09:38:33,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:33,243 INFO:     Epoch: 8
2023-01-04 09:38:34,779 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48900474707285563, 'Total loss': 0.48900474707285563} | train loss {'Reaction outcome loss': 0.4788179057684258, 'Total loss': 0.4788179057684258}
2023-01-04 09:38:34,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:34,779 INFO:     Epoch: 9
2023-01-04 09:38:36,296 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4461356242497762, 'Total loss': 0.4461356242497762} | train loss {'Reaction outcome loss': 0.47398098139432226, 'Total loss': 0.47398098139432226}
2023-01-04 09:38:36,296 INFO:     Found new best model at epoch 9
2023-01-04 09:38:36,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:36,297 INFO:     Epoch: 10
2023-01-04 09:38:37,841 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4677752166986465, 'Total loss': 0.4677752166986465} | train loss {'Reaction outcome loss': 0.46782029044889184, 'Total loss': 0.46782029044889184}
2023-01-04 09:38:37,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:37,842 INFO:     Epoch: 11
2023-01-04 09:38:39,360 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4593224654595057, 'Total loss': 0.4593224654595057} | train loss {'Reaction outcome loss': 0.45812295246733364, 'Total loss': 0.45812295246733364}
2023-01-04 09:38:39,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:39,360 INFO:     Epoch: 12
2023-01-04 09:38:40,909 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4698874741792679, 'Total loss': 0.4698874741792679} | train loss {'Reaction outcome loss': 0.45090640575563823, 'Total loss': 0.45090640575563823}
2023-01-04 09:38:40,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:40,910 INFO:     Epoch: 13
2023-01-04 09:38:42,480 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4510810077190399, 'Total loss': 0.4510810077190399} | train loss {'Reaction outcome loss': 0.4486078030436578, 'Total loss': 0.4486078030436578}
2023-01-04 09:38:42,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:42,481 INFO:     Epoch: 14
2023-01-04 09:38:44,036 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4416304697593053, 'Total loss': 0.4416304697593053} | train loss {'Reaction outcome loss': 0.4432479883306218, 'Total loss': 0.4432479883306218}
2023-01-04 09:38:44,037 INFO:     Found new best model at epoch 14
2023-01-04 09:38:44,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:44,037 INFO:     Epoch: 15
2023-01-04 09:38:45,551 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4596682151158651, 'Total loss': 0.4596682151158651} | train loss {'Reaction outcome loss': 0.4395190420812064, 'Total loss': 0.4395190420812064}
2023-01-04 09:38:45,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:45,552 INFO:     Epoch: 16
2023-01-04 09:38:47,100 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45172354578971863, 'Total loss': 0.45172354578971863} | train loss {'Reaction outcome loss': 0.43647777153192646, 'Total loss': 0.43647777153192646}
2023-01-04 09:38:47,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:47,100 INFO:     Epoch: 17
2023-01-04 09:38:48,619 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4464463770389557, 'Total loss': 0.4464463770389557} | train loss {'Reaction outcome loss': 0.43204252889556605, 'Total loss': 0.43204252889556605}
2023-01-04 09:38:48,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:48,619 INFO:     Epoch: 18
2023-01-04 09:38:50,157 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43776004811127983, 'Total loss': 0.43776004811127983} | train loss {'Reaction outcome loss': 0.42385706876533746, 'Total loss': 0.42385706876533746}
2023-01-04 09:38:50,158 INFO:     Found new best model at epoch 18
2023-01-04 09:38:50,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:50,158 INFO:     Epoch: 19
2023-01-04 09:38:51,718 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4256598914662997, 'Total loss': 0.4256598914662997} | train loss {'Reaction outcome loss': 0.41865211698043087, 'Total loss': 0.41865211698043087}
2023-01-04 09:38:51,718 INFO:     Found new best model at epoch 19
2023-01-04 09:38:51,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:51,719 INFO:     Epoch: 20
2023-01-04 09:38:53,273 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46025756498177844, 'Total loss': 0.46025756498177844} | train loss {'Reaction outcome loss': 0.4173107072167153, 'Total loss': 0.4173107072167153}
2023-01-04 09:38:53,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:53,273 INFO:     Epoch: 21
2023-01-04 09:38:54,774 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42903447647889453, 'Total loss': 0.42903447647889453} | train loss {'Reaction outcome loss': 0.411368256774697, 'Total loss': 0.411368256774697}
2023-01-04 09:38:54,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:54,774 INFO:     Epoch: 22
2023-01-04 09:38:56,313 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41604970494906107, 'Total loss': 0.41604970494906107} | train loss {'Reaction outcome loss': 0.4075308118532174, 'Total loss': 0.4075308118532174}
2023-01-04 09:38:56,313 INFO:     Found new best model at epoch 22
2023-01-04 09:38:56,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:56,314 INFO:     Epoch: 23
2023-01-04 09:38:57,824 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4323421726624171, 'Total loss': 0.4323421726624171} | train loss {'Reaction outcome loss': 0.4028382942515568, 'Total loss': 0.4028382942515568}
2023-01-04 09:38:57,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:57,825 INFO:     Epoch: 24
2023-01-04 09:38:59,382 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4421486715475718, 'Total loss': 0.4421486715475718} | train loss {'Reaction outcome loss': 0.40145155923427456, 'Total loss': 0.40145155923427456}
2023-01-04 09:38:59,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:38:59,382 INFO:     Epoch: 25
2023-01-04 09:39:00,925 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4452005555232366, 'Total loss': 0.4452005555232366} | train loss {'Reaction outcome loss': 0.3923531308171958, 'Total loss': 0.3923531308171958}
2023-01-04 09:39:00,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:00,925 INFO:     Epoch: 26
2023-01-04 09:39:02,476 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4074371616045634, 'Total loss': 0.4074371616045634} | train loss {'Reaction outcome loss': 0.38979754580633486, 'Total loss': 0.38979754580633486}
2023-01-04 09:39:02,478 INFO:     Found new best model at epoch 26
2023-01-04 09:39:02,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:02,479 INFO:     Epoch: 27
2023-01-04 09:39:04,000 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42463833491007485, 'Total loss': 0.42463833491007485} | train loss {'Reaction outcome loss': 0.38326039739007495, 'Total loss': 0.38326039739007495}
2023-01-04 09:39:04,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:04,000 INFO:     Epoch: 28
2023-01-04 09:39:05,555 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40719169477621714, 'Total loss': 0.40719169477621714} | train loss {'Reaction outcome loss': 0.3770751782087949, 'Total loss': 0.3770751782087949}
2023-01-04 09:39:05,556 INFO:     Found new best model at epoch 28
2023-01-04 09:39:05,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:05,556 INFO:     Epoch: 29
2023-01-04 09:39:07,057 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42311427791913353, 'Total loss': 0.42311427791913353} | train loss {'Reaction outcome loss': 0.37569332595941796, 'Total loss': 0.37569332595941796}
2023-01-04 09:39:07,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:07,057 INFO:     Epoch: 30
2023-01-04 09:39:08,607 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4080790340900421, 'Total loss': 0.4080790340900421} | train loss {'Reaction outcome loss': 0.37221166426247926, 'Total loss': 0.37221166426247926}
2023-01-04 09:39:08,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:08,608 INFO:     Epoch: 31
2023-01-04 09:39:10,159 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43660827974478406, 'Total loss': 0.43660827974478406} | train loss {'Reaction outcome loss': 0.3659777355237599, 'Total loss': 0.3659777355237599}
2023-01-04 09:39:10,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:10,159 INFO:     Epoch: 32
2023-01-04 09:39:11,700 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4077359467744827, 'Total loss': 0.4077359467744827} | train loss {'Reaction outcome loss': 0.36032542477559, 'Total loss': 0.36032542477559}
2023-01-04 09:39:11,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:11,700 INFO:     Epoch: 33
2023-01-04 09:39:13,223 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4024430255095164, 'Total loss': 0.4024430255095164} | train loss {'Reaction outcome loss': 0.36057885714473514, 'Total loss': 0.36057885714473514}
2023-01-04 09:39:13,223 INFO:     Found new best model at epoch 33
2023-01-04 09:39:13,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:13,224 INFO:     Epoch: 34
2023-01-04 09:39:14,769 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39860614836215974, 'Total loss': 0.39860614836215974} | train loss {'Reaction outcome loss': 0.3574998315668454, 'Total loss': 0.3574998315668454}
2023-01-04 09:39:14,769 INFO:     Found new best model at epoch 34
2023-01-04 09:39:14,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:14,770 INFO:     Epoch: 35
2023-01-04 09:39:16,284 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40958850979804995, 'Total loss': 0.40958850979804995} | train loss {'Reaction outcome loss': 0.34910709337487705, 'Total loss': 0.34910709337487705}
2023-01-04 09:39:16,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:16,284 INFO:     Epoch: 36
2023-01-04 09:39:17,848 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4079025387763977, 'Total loss': 0.4079025387763977} | train loss {'Reaction outcome loss': 0.34792227463891906, 'Total loss': 0.34792227463891906}
2023-01-04 09:39:17,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:17,848 INFO:     Epoch: 37
2023-01-04 09:39:19,383 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4189750293890635, 'Total loss': 0.4189750293890635} | train loss {'Reaction outcome loss': 0.3433640159285852, 'Total loss': 0.3433640159285852}
2023-01-04 09:39:19,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:19,383 INFO:     Epoch: 38
2023-01-04 09:39:20,938 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42897150417168933, 'Total loss': 0.42897150417168933} | train loss {'Reaction outcome loss': 0.3394893222100978, 'Total loss': 0.3394893222100978}
2023-01-04 09:39:20,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:20,939 INFO:     Epoch: 39
2023-01-04 09:39:22,452 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3897024949391683, 'Total loss': 0.3897024949391683} | train loss {'Reaction outcome loss': 0.34127965256789305, 'Total loss': 0.34127965256789305}
2023-01-04 09:39:22,452 INFO:     Found new best model at epoch 39
2023-01-04 09:39:22,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:22,453 INFO:     Epoch: 40
2023-01-04 09:39:24,002 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43083800772825875, 'Total loss': 0.43083800772825875} | train loss {'Reaction outcome loss': 0.33568406980620685, 'Total loss': 0.33568406980620685}
2023-01-04 09:39:24,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:24,002 INFO:     Epoch: 41
2023-01-04 09:39:25,536 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40051758885383604, 'Total loss': 0.40051758885383604} | train loss {'Reaction outcome loss': 0.33162778398416337, 'Total loss': 0.33162778398416337}
2023-01-04 09:39:25,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:25,536 INFO:     Epoch: 42
2023-01-04 09:39:27,086 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4167278528213501, 'Total loss': 0.4167278528213501} | train loss {'Reaction outcome loss': 0.3302411224393949, 'Total loss': 0.3302411224393949}
2023-01-04 09:39:27,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:27,087 INFO:     Epoch: 43
2023-01-04 09:39:28,632 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39179723858833315, 'Total loss': 0.39179723858833315} | train loss {'Reaction outcome loss': 0.3252892402021119, 'Total loss': 0.3252892402021119}
2023-01-04 09:39:28,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:28,633 INFO:     Epoch: 44
2023-01-04 09:39:30,194 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4040493547916412, 'Total loss': 0.4040493547916412} | train loss {'Reaction outcome loss': 0.3232547043394433, 'Total loss': 0.3232547043394433}
2023-01-04 09:39:30,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:30,195 INFO:     Epoch: 45
2023-01-04 09:39:31,732 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.398006871342659, 'Total loss': 0.398006871342659} | train loss {'Reaction outcome loss': 0.3215646062073481, 'Total loss': 0.3215646062073481}
2023-01-04 09:39:31,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:31,732 INFO:     Epoch: 46
2023-01-04 09:39:33,264 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4103587677081426, 'Total loss': 0.4103587677081426} | train loss {'Reaction outcome loss': 0.3154628388311741, 'Total loss': 0.3154628388311741}
2023-01-04 09:39:33,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:33,265 INFO:     Epoch: 47
2023-01-04 09:39:34,845 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4173506826162338, 'Total loss': 0.4173506826162338} | train loss {'Reaction outcome loss': 0.3149134706515465, 'Total loss': 0.3149134706515465}
2023-01-04 09:39:34,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:34,845 INFO:     Epoch: 48
2023-01-04 09:39:36,428 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3774034102757772, 'Total loss': 0.3774034102757772} | train loss {'Reaction outcome loss': 0.31477838497690475, 'Total loss': 0.31477838497690475}
2023-01-04 09:39:36,428 INFO:     Found new best model at epoch 48
2023-01-04 09:39:36,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:36,429 INFO:     Epoch: 49
2023-01-04 09:39:37,964 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39395414888858793, 'Total loss': 0.39395414888858793} | train loss {'Reaction outcome loss': 0.31092774870730666, 'Total loss': 0.31092774870730666}
2023-01-04 09:39:37,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:37,964 INFO:     Epoch: 50
2023-01-04 09:39:39,507 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40932595133781435, 'Total loss': 0.40932595133781435} | train loss {'Reaction outcome loss': 0.30714979430619815, 'Total loss': 0.30714979430619815}
2023-01-04 09:39:39,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:39,508 INFO:     Epoch: 51
2023-01-04 09:39:41,013 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3772701541582743, 'Total loss': 0.3772701541582743} | train loss {'Reaction outcome loss': 0.30365219100439633, 'Total loss': 0.30365219100439633}
2023-01-04 09:39:41,013 INFO:     Found new best model at epoch 51
2023-01-04 09:39:41,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:41,013 INFO:     Epoch: 52
2023-01-04 09:39:42,531 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4036119351784388, 'Total loss': 0.4036119351784388} | train loss {'Reaction outcome loss': 0.30204227574876624, 'Total loss': 0.30204227574876624}
2023-01-04 09:39:42,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:42,532 INFO:     Epoch: 53
2023-01-04 09:39:44,068 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40998061498006183, 'Total loss': 0.40998061498006183} | train loss {'Reaction outcome loss': 0.30051369649650406, 'Total loss': 0.30051369649650406}
2023-01-04 09:39:44,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:44,068 INFO:     Epoch: 54
2023-01-04 09:39:45,605 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39181251227855685, 'Total loss': 0.39181251227855685} | train loss {'Reaction outcome loss': 0.29895835794019004, 'Total loss': 0.29895835794019004}
2023-01-04 09:39:45,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:45,605 INFO:     Epoch: 55
2023-01-04 09:39:47,136 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4095206677913666, 'Total loss': 0.4095206677913666} | train loss {'Reaction outcome loss': 0.297194233776009, 'Total loss': 0.297194233776009}
2023-01-04 09:39:47,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:47,137 INFO:     Epoch: 56
2023-01-04 09:39:48,677 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4057764401038488, 'Total loss': 0.4057764401038488} | train loss {'Reaction outcome loss': 0.298752860839132, 'Total loss': 0.298752860839132}
2023-01-04 09:39:48,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:48,677 INFO:     Epoch: 57
2023-01-04 09:39:50,190 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42818769812583923, 'Total loss': 0.42818769812583923} | train loss {'Reaction outcome loss': 0.29307120941905646, 'Total loss': 0.29307120941905646}
2023-01-04 09:39:50,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:50,191 INFO:     Epoch: 58
2023-01-04 09:39:51,700 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39263010323047637, 'Total loss': 0.39263010323047637} | train loss {'Reaction outcome loss': 0.29173875129679694, 'Total loss': 0.29173875129679694}
2023-01-04 09:39:51,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:51,701 INFO:     Epoch: 59
2023-01-04 09:39:53,248 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38782737255096433, 'Total loss': 0.38782737255096433} | train loss {'Reaction outcome loss': 0.29351625284248023, 'Total loss': 0.29351625284248023}
2023-01-04 09:39:53,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:53,248 INFO:     Epoch: 60
2023-01-04 09:39:54,799 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3736463059981664, 'Total loss': 0.3736463059981664} | train loss {'Reaction outcome loss': 0.2894902849284402, 'Total loss': 0.2894902849284402}
2023-01-04 09:39:54,799 INFO:     Found new best model at epoch 60
2023-01-04 09:39:54,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:54,800 INFO:     Epoch: 61
2023-01-04 09:39:56,352 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3990406175454458, 'Total loss': 0.3990406175454458} | train loss {'Reaction outcome loss': 0.2844758957189365, 'Total loss': 0.2844758957189365}
2023-01-04 09:39:56,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:56,352 INFO:     Epoch: 62
2023-01-04 09:39:57,878 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42469994028409325, 'Total loss': 0.42469994028409325} | train loss {'Reaction outcome loss': 0.28243045786218923, 'Total loss': 0.28243045786218923}
2023-01-04 09:39:57,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:57,878 INFO:     Epoch: 63
2023-01-04 09:39:59,423 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4092566063006719, 'Total loss': 0.4092566063006719} | train loss {'Reaction outcome loss': 0.2801153231548132, 'Total loss': 0.2801153231548132}
2023-01-04 09:39:59,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:39:59,423 INFO:     Epoch: 64
2023-01-04 09:40:00,952 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40410746534665426, 'Total loss': 0.40410746534665426} | train loss {'Reaction outcome loss': 0.2805377044613018, 'Total loss': 0.2805377044613018}
2023-01-04 09:40:00,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:00,952 INFO:     Epoch: 65
2023-01-04 09:40:02,524 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4051922152439753, 'Total loss': 0.4051922152439753} | train loss {'Reaction outcome loss': 0.28571543615501727, 'Total loss': 0.28571543615501727}
2023-01-04 09:40:02,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:02,524 INFO:     Epoch: 66
2023-01-04 09:40:04,092 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39287833372751874, 'Total loss': 0.39287833372751874} | train loss {'Reaction outcome loss': 0.27969450969928805, 'Total loss': 0.27969450969928805}
2023-01-04 09:40:04,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:04,093 INFO:     Epoch: 67
2023-01-04 09:40:05,673 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.400229819615682, 'Total loss': 0.400229819615682} | train loss {'Reaction outcome loss': 0.2835826265224575, 'Total loss': 0.2835826265224575}
2023-01-04 09:40:05,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:05,674 INFO:     Epoch: 68
2023-01-04 09:40:07,240 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3867888778448105, 'Total loss': 0.3867888778448105} | train loss {'Reaction outcome loss': 0.2719683036153769, 'Total loss': 0.2719683036153769}
2023-01-04 09:40:07,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:07,240 INFO:     Epoch: 69
2023-01-04 09:40:08,844 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4261736810207367, 'Total loss': 0.4261736810207367} | train loss {'Reaction outcome loss': 0.2726646693301027, 'Total loss': 0.2726646693301027}
2023-01-04 09:40:08,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:08,844 INFO:     Epoch: 70
2023-01-04 09:40:10,405 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3995655318101247, 'Total loss': 0.3995655318101247} | train loss {'Reaction outcome loss': 0.2756867349610059, 'Total loss': 0.2756867349610059}
2023-01-04 09:40:10,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:10,406 INFO:     Epoch: 71
2023-01-04 09:40:11,997 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39645956257979076, 'Total loss': 0.39645956257979076} | train loss {'Reaction outcome loss': 0.27087438566079974, 'Total loss': 0.27087438566079974}
2023-01-04 09:40:11,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:11,997 INFO:     Epoch: 72
2023-01-04 09:40:13,589 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.376637010773023, 'Total loss': 0.376637010773023} | train loss {'Reaction outcome loss': 0.2697905920663454, 'Total loss': 0.2697905920663454}
2023-01-04 09:40:13,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:13,589 INFO:     Epoch: 73
2023-01-04 09:40:15,159 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40603968302408855, 'Total loss': 0.40603968302408855} | train loss {'Reaction outcome loss': 0.2652176391523685, 'Total loss': 0.2652176391523685}
2023-01-04 09:40:15,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:15,159 INFO:     Epoch: 74
2023-01-04 09:40:16,718 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41779423554738365, 'Total loss': 0.41779423554738365} | train loss {'Reaction outcome loss': 0.26881032738916194, 'Total loss': 0.26881032738916194}
2023-01-04 09:40:16,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:16,719 INFO:     Epoch: 75
2023-01-04 09:40:18,322 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3821902771790822, 'Total loss': 0.3821902771790822} | train loss {'Reaction outcome loss': 0.2673795316504301, 'Total loss': 0.2673795316504301}
2023-01-04 09:40:18,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:18,323 INFO:     Epoch: 76
2023-01-04 09:40:19,882 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3752559761206309, 'Total loss': 0.3752559761206309} | train loss {'Reaction outcome loss': 0.268876580344717, 'Total loss': 0.268876580344717}
2023-01-04 09:40:19,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:19,882 INFO:     Epoch: 77
2023-01-04 09:40:21,480 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.400675709048907, 'Total loss': 0.400675709048907} | train loss {'Reaction outcome loss': 0.26610724967870397, 'Total loss': 0.26610724967870397}
2023-01-04 09:40:21,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:21,480 INFO:     Epoch: 78
2023-01-04 09:40:23,095 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4074757993221283, 'Total loss': 0.4074757993221283} | train loss {'Reaction outcome loss': 0.2595138509424716, 'Total loss': 0.2595138509424716}
2023-01-04 09:40:23,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:23,096 INFO:     Epoch: 79
2023-01-04 09:40:24,689 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4065330644448598, 'Total loss': 0.4065330644448598} | train loss {'Reaction outcome loss': 0.26311500707682034, 'Total loss': 0.26311500707682034}
2023-01-04 09:40:24,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:24,689 INFO:     Epoch: 80
2023-01-04 09:40:26,235 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3979165256023407, 'Total loss': 0.3979165256023407} | train loss {'Reaction outcome loss': 0.26157239642347735, 'Total loss': 0.26157239642347735}
2023-01-04 09:40:26,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:26,235 INFO:     Epoch: 81
2023-01-04 09:40:27,786 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38086341818173725, 'Total loss': 0.38086341818173725} | train loss {'Reaction outcome loss': 0.25706245472831446, 'Total loss': 0.25706245472831446}
2023-01-04 09:40:27,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:27,786 INFO:     Epoch: 82
2023-01-04 09:40:29,375 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3798309713602066, 'Total loss': 0.3798309713602066} | train loss {'Reaction outcome loss': 0.26090236870150496, 'Total loss': 0.26090236870150496}
2023-01-04 09:40:29,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:29,375 INFO:     Epoch: 83
2023-01-04 09:40:30,987 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39568800330162046, 'Total loss': 0.39568800330162046} | train loss {'Reaction outcome loss': 0.25809165180055765, 'Total loss': 0.25809165180055765}
2023-01-04 09:40:30,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:30,988 INFO:     Epoch: 84
2023-01-04 09:40:32,602 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40775562872489296, 'Total loss': 0.40775562872489296} | train loss {'Reaction outcome loss': 0.25755588351375, 'Total loss': 0.25755588351375}
2023-01-04 09:40:32,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:32,602 INFO:     Epoch: 85
2023-01-04 09:40:34,191 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3875234564145406, 'Total loss': 0.3875234564145406} | train loss {'Reaction outcome loss': 0.2554496066359273, 'Total loss': 0.2554496066359273}
2023-01-04 09:40:34,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:34,192 INFO:     Epoch: 86
2023-01-04 09:40:35,774 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4050206045309703, 'Total loss': 0.4050206045309703} | train loss {'Reaction outcome loss': 0.2567700777665107, 'Total loss': 0.2567700777665107}
2023-01-04 09:40:35,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:35,774 INFO:     Epoch: 87
2023-01-04 09:40:37,335 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3847052981456121, 'Total loss': 0.3847052981456121} | train loss {'Reaction outcome loss': 0.2519963078445544, 'Total loss': 0.2519963078445544}
2023-01-04 09:40:37,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:37,335 INFO:     Epoch: 88
2023-01-04 09:40:38,943 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4145951171716054, 'Total loss': 0.4145951171716054} | train loss {'Reaction outcome loss': 0.2499472116031786, 'Total loss': 0.2499472116031786}
2023-01-04 09:40:38,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:38,943 INFO:     Epoch: 89
2023-01-04 09:40:40,514 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37106030285358427, 'Total loss': 0.37106030285358427} | train loss {'Reaction outcome loss': 0.2540032178245104, 'Total loss': 0.2540032178245104}
2023-01-04 09:40:40,515 INFO:     Found new best model at epoch 89
2023-01-04 09:40:40,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:40,516 INFO:     Epoch: 90
2023-01-04 09:40:42,080 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42111403743426007, 'Total loss': 0.42111403743426007} | train loss {'Reaction outcome loss': 0.2558484863027604, 'Total loss': 0.2558484863027604}
2023-01-04 09:40:42,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:42,080 INFO:     Epoch: 91
2023-01-04 09:40:43,612 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3837188536922137, 'Total loss': 0.3837188536922137} | train loss {'Reaction outcome loss': 0.2546242915066707, 'Total loss': 0.2546242915066707}
2023-01-04 09:40:43,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:43,612 INFO:     Epoch: 92
2023-01-04 09:40:45,169 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3884945710500081, 'Total loss': 0.3884945710500081} | train loss {'Reaction outcome loss': 0.24923275075309034, 'Total loss': 0.24923275075309034}
2023-01-04 09:40:45,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:45,169 INFO:     Epoch: 93
2023-01-04 09:40:46,710 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3945265730222066, 'Total loss': 0.3945265730222066} | train loss {'Reaction outcome loss': 0.24841733676564953, 'Total loss': 0.24841733676564953}
2023-01-04 09:40:46,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:46,711 INFO:     Epoch: 94
2023-01-04 09:40:48,287 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40674890180428824, 'Total loss': 0.40674890180428824} | train loss {'Reaction outcome loss': 0.24904684776807354, 'Total loss': 0.24904684776807354}
2023-01-04 09:40:48,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:48,287 INFO:     Epoch: 95
2023-01-04 09:40:49,857 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40524115959803264, 'Total loss': 0.40524115959803264} | train loss {'Reaction outcome loss': 0.2451351003544609, 'Total loss': 0.2451351003544609}
2023-01-04 09:40:49,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:49,858 INFO:     Epoch: 96
2023-01-04 09:40:51,432 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4192860265572866, 'Total loss': 0.4192860265572866} | train loss {'Reaction outcome loss': 0.2449076230889254, 'Total loss': 0.2449076230889254}
2023-01-04 09:40:51,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:51,433 INFO:     Epoch: 97
2023-01-04 09:40:52,966 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39717282156149547, 'Total loss': 0.39717282156149547} | train loss {'Reaction outcome loss': 0.2442313614403353, 'Total loss': 0.2442313614403353}
2023-01-04 09:40:52,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:52,967 INFO:     Epoch: 98
2023-01-04 09:40:54,544 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3873667279879252, 'Total loss': 0.3873667279879252} | train loss {'Reaction outcome loss': 0.24784911353222644, 'Total loss': 0.24784911353222644}
2023-01-04 09:40:54,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:54,544 INFO:     Epoch: 99
2023-01-04 09:40:56,084 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3795556475718816, 'Total loss': 0.3795556475718816} | train loss {'Reaction outcome loss': 0.24553881775941291, 'Total loss': 0.24553881775941291}
2023-01-04 09:40:56,084 INFO:     Best model found after epoch 90 of 100.
2023-01-04 09:40:56,084 INFO:   Done with stage: TRAINING
2023-01-04 09:40:56,084 INFO:   Starting stage: EVALUATION
2023-01-04 09:40:56,220 INFO:   Done with stage: EVALUATION
2023-01-04 09:40:56,220 INFO:   Leaving out SEQ value Fold_4
2023-01-04 09:40:56,232 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:40:56,233 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:40:56,879 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:40:56,879 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:40:56,948 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:40:56,948 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:40:56,948 INFO:     No hyperparam tuning for this model
2023-01-04 09:40:56,948 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:40:56,948 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:40:56,949 INFO:     None feature selector for col prot
2023-01-04 09:40:56,949 INFO:     None feature selector for col prot
2023-01-04 09:40:56,949 INFO:     None feature selector for col prot
2023-01-04 09:40:56,950 INFO:     None feature selector for col chem
2023-01-04 09:40:56,950 INFO:     None feature selector for col chem
2023-01-04 09:40:56,950 INFO:     None feature selector for col chem
2023-01-04 09:40:56,950 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:40:56,950 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:40:56,951 INFO:     Number of params in model 70111
2023-01-04 09:40:56,954 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:40:56,954 INFO:   Starting stage: TRAINING
2023-01-04 09:40:56,997 INFO:     Val loss before train {'Reaction outcome loss': 0.9679640750090281, 'Total loss': 0.9679640750090281}
2023-01-04 09:40:56,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:56,997 INFO:     Epoch: 0
2023-01-04 09:40:58,586 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6543743729591369, 'Total loss': 0.6543743729591369} | train loss {'Reaction outcome loss': 0.8479765941375408, 'Total loss': 0.8479765941375408}
2023-01-04 09:40:58,586 INFO:     Found new best model at epoch 0
2023-01-04 09:40:58,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:40:58,587 INFO:     Epoch: 1
2023-01-04 09:41:00,174 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5478712697823842, 'Total loss': 0.5478712697823842} | train loss {'Reaction outcome loss': 0.6808585827981216, 'Total loss': 0.6808585827981216}
2023-01-04 09:41:00,174 INFO:     Found new best model at epoch 1
2023-01-04 09:41:00,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:00,175 INFO:     Epoch: 2
2023-01-04 09:41:01,729 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4970497896273931, 'Total loss': 0.4970497896273931} | train loss {'Reaction outcome loss': 0.5876441605497098, 'Total loss': 0.5876441605497098}
2023-01-04 09:41:01,729 INFO:     Found new best model at epoch 2
2023-01-04 09:41:01,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:01,730 INFO:     Epoch: 3
2023-01-04 09:41:03,304 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4999319016933441, 'Total loss': 0.4999319016933441} | train loss {'Reaction outcome loss': 0.543255398724822, 'Total loss': 0.543255398724822}
2023-01-04 09:41:03,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:03,305 INFO:     Epoch: 4
2023-01-04 09:41:04,831 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.479569274187088, 'Total loss': 0.479569274187088} | train loss {'Reaction outcome loss': 0.5190529546740911, 'Total loss': 0.5190529546740911}
2023-01-04 09:41:04,831 INFO:     Found new best model at epoch 4
2023-01-04 09:41:04,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:04,832 INFO:     Epoch: 5
2023-01-04 09:41:06,420 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4614423116048177, 'Total loss': 0.4614423116048177} | train loss {'Reaction outcome loss': 0.49546885663184564, 'Total loss': 0.49546885663184564}
2023-01-04 09:41:06,420 INFO:     Found new best model at epoch 5
2023-01-04 09:41:06,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:06,421 INFO:     Epoch: 6
2023-01-04 09:41:08,000 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45403780341148375, 'Total loss': 0.45403780341148375} | train loss {'Reaction outcome loss': 0.48503318816538143, 'Total loss': 0.48503318816538143}
2023-01-04 09:41:08,000 INFO:     Found new best model at epoch 6
2023-01-04 09:41:08,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:08,001 INFO:     Epoch: 7
2023-01-04 09:41:09,588 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4715853234132131, 'Total loss': 0.4715853234132131} | train loss {'Reaction outcome loss': 0.4723804437055968, 'Total loss': 0.4723804437055968}
2023-01-04 09:41:09,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:09,588 INFO:     Epoch: 8
2023-01-04 09:41:11,138 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4463060716787974, 'Total loss': 0.4463060716787974} | train loss {'Reaction outcome loss': 0.4676785088427689, 'Total loss': 0.4676785088427689}
2023-01-04 09:41:11,139 INFO:     Found new best model at epoch 8
2023-01-04 09:41:11,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:11,140 INFO:     Epoch: 9
2023-01-04 09:41:12,708 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44900956253210705, 'Total loss': 0.44900956253210705} | train loss {'Reaction outcome loss': 0.45631824630866014, 'Total loss': 0.45631824630866014}
2023-01-04 09:41:12,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:12,708 INFO:     Epoch: 10
2023-01-04 09:41:14,261 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44471652507781984, 'Total loss': 0.44471652507781984} | train loss {'Reaction outcome loss': 0.4546338022025167, 'Total loss': 0.4546338022025167}
2023-01-04 09:41:14,261 INFO:     Found new best model at epoch 10
2023-01-04 09:41:14,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:14,261 INFO:     Epoch: 11
2023-01-04 09:41:15,819 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4261321286360423, 'Total loss': 0.4261321286360423} | train loss {'Reaction outcome loss': 0.4510183378082255, 'Total loss': 0.4510183378082255}
2023-01-04 09:41:15,819 INFO:     Found new best model at epoch 11
2023-01-04 09:41:15,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:15,820 INFO:     Epoch: 12
2023-01-04 09:41:17,396 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4427021046479543, 'Total loss': 0.4427021046479543} | train loss {'Reaction outcome loss': 0.4529735475046344, 'Total loss': 0.4529735475046344}
2023-01-04 09:41:17,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:17,397 INFO:     Epoch: 13
2023-01-04 09:41:18,974 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4381878842910131, 'Total loss': 0.4381878842910131} | train loss {'Reaction outcome loss': 0.43562246615445055, 'Total loss': 0.43562246615445055}
2023-01-04 09:41:18,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:18,974 INFO:     Epoch: 14
2023-01-04 09:41:20,512 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4256212959686915, 'Total loss': 0.4256212959686915} | train loss {'Reaction outcome loss': 0.4323271904648973, 'Total loss': 0.4323271904648973}
2023-01-04 09:41:20,512 INFO:     Found new best model at epoch 14
2023-01-04 09:41:20,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:20,513 INFO:     Epoch: 15
2023-01-04 09:41:22,037 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4247139592965444, 'Total loss': 0.4247139592965444} | train loss {'Reaction outcome loss': 0.42779737595549744, 'Total loss': 0.42779737595549744}
2023-01-04 09:41:22,037 INFO:     Found new best model at epoch 15
2023-01-04 09:41:22,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:22,038 INFO:     Epoch: 16
2023-01-04 09:41:23,618 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4367932359377543, 'Total loss': 0.4367932359377543} | train loss {'Reaction outcome loss': 0.4221271160708241, 'Total loss': 0.4221271160708241}
2023-01-04 09:41:23,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:23,618 INFO:     Epoch: 17
2023-01-04 09:41:25,188 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4581451286872228, 'Total loss': 0.4581451286872228} | train loss {'Reaction outcome loss': 0.4259424524894659, 'Total loss': 0.4259424524894659}
2023-01-04 09:41:25,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:25,189 INFO:     Epoch: 18
2023-01-04 09:41:26,772 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42410387893517815, 'Total loss': 0.42410387893517815} | train loss {'Reaction outcome loss': 0.43912618815396115, 'Total loss': 0.43912618815396115}
2023-01-04 09:41:26,772 INFO:     Found new best model at epoch 18
2023-01-04 09:41:26,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:26,773 INFO:     Epoch: 19
2023-01-04 09:41:28,324 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42157215674718224, 'Total loss': 0.42157215674718224} | train loss {'Reaction outcome loss': 0.4155528196471109, 'Total loss': 0.4155528196471109}
2023-01-04 09:41:28,325 INFO:     Found new best model at epoch 19
2023-01-04 09:41:28,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:28,325 INFO:     Epoch: 20
2023-01-04 09:41:29,906 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41862741112709045, 'Total loss': 0.41862741112709045} | train loss {'Reaction outcome loss': 0.40836813508033537, 'Total loss': 0.40836813508033537}
2023-01-04 09:41:29,907 INFO:     Found new best model at epoch 20
2023-01-04 09:41:29,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:29,908 INFO:     Epoch: 21
2023-01-04 09:41:31,468 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40988173286120094, 'Total loss': 0.40988173286120094} | train loss {'Reaction outcome loss': 0.4054157989288586, 'Total loss': 0.4054157989288586}
2023-01-04 09:41:31,468 INFO:     Found new best model at epoch 21
2023-01-04 09:41:31,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:31,469 INFO:     Epoch: 22
2023-01-04 09:41:33,053 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4100317195057869, 'Total loss': 0.4100317195057869} | train loss {'Reaction outcome loss': 0.3986604126746871, 'Total loss': 0.3986604126746871}
2023-01-04 09:41:33,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:33,054 INFO:     Epoch: 23
2023-01-04 09:41:34,636 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4146656334400177, 'Total loss': 0.4146656334400177} | train loss {'Reaction outcome loss': 0.39446384759714315, 'Total loss': 0.39446384759714315}
2023-01-04 09:41:34,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:34,636 INFO:     Epoch: 24
2023-01-04 09:41:36,212 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4027959277232488, 'Total loss': 0.4027959277232488} | train loss {'Reaction outcome loss': 0.39090727859487134, 'Total loss': 0.39090727859487134}
2023-01-04 09:41:36,213 INFO:     Found new best model at epoch 24
2023-01-04 09:41:36,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:36,213 INFO:     Epoch: 25
2023-01-04 09:41:37,749 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4079281618197759, 'Total loss': 0.4079281618197759} | train loss {'Reaction outcome loss': 0.3903997412805135, 'Total loss': 0.3903997412805135}
2023-01-04 09:41:37,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:37,749 INFO:     Epoch: 26
2023-01-04 09:41:39,313 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3990678399801254, 'Total loss': 0.3990678399801254} | train loss {'Reaction outcome loss': 0.3875407099529685, 'Total loss': 0.3875407099529685}
2023-01-04 09:41:39,314 INFO:     Found new best model at epoch 26
2023-01-04 09:41:39,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:39,314 INFO:     Epoch: 27
2023-01-04 09:41:40,843 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41022361516952516, 'Total loss': 0.41022361516952516} | train loss {'Reaction outcome loss': 0.38427636313650326, 'Total loss': 0.38427636313650326}
2023-01-04 09:41:40,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:40,844 INFO:     Epoch: 28
2023-01-04 09:41:42,423 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39540030583739283, 'Total loss': 0.39540030583739283} | train loss {'Reaction outcome loss': 0.38085375923672976, 'Total loss': 0.38085375923672976}
2023-01-04 09:41:42,423 INFO:     Found new best model at epoch 28
2023-01-04 09:41:42,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:42,424 INFO:     Epoch: 29
2023-01-04 09:41:44,009 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40980467995007835, 'Total loss': 0.40980467995007835} | train loss {'Reaction outcome loss': 0.37794761291023454, 'Total loss': 0.37794761291023454}
2023-01-04 09:41:44,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:44,009 INFO:     Epoch: 30
2023-01-04 09:41:45,570 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4265748927990595, 'Total loss': 0.4265748927990595} | train loss {'Reaction outcome loss': 0.3821345373880172, 'Total loss': 0.3821345373880172}
2023-01-04 09:41:45,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:45,570 INFO:     Epoch: 31
2023-01-04 09:41:47,102 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39575235247612, 'Total loss': 0.39575235247612} | train loss {'Reaction outcome loss': 0.3907254975208122, 'Total loss': 0.3907254975208122}
2023-01-04 09:41:47,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:47,103 INFO:     Epoch: 32
2023-01-04 09:41:48,690 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.407018181681633, 'Total loss': 0.407018181681633} | train loss {'Reaction outcome loss': 0.37182835411226406, 'Total loss': 0.37182835411226406}
2023-01-04 09:41:48,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:48,690 INFO:     Epoch: 33
2023-01-04 09:41:50,244 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38130040069421134, 'Total loss': 0.38130040069421134} | train loss {'Reaction outcome loss': 0.3674274034514699, 'Total loss': 0.3674274034514699}
2023-01-04 09:41:50,244 INFO:     Found new best model at epoch 33
2023-01-04 09:41:50,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:50,245 INFO:     Epoch: 34
2023-01-04 09:41:51,845 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3744863400856654, 'Total loss': 0.3744863400856654} | train loss {'Reaction outcome loss': 0.38656708765505016, 'Total loss': 0.38656708765505016}
2023-01-04 09:41:51,845 INFO:     Found new best model at epoch 34
2023-01-04 09:41:51,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:51,846 INFO:     Epoch: 35
2023-01-04 09:41:53,427 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3905537694692612, 'Total loss': 0.3905537694692612} | train loss {'Reaction outcome loss': 0.36744130309671164, 'Total loss': 0.36744130309671164}
2023-01-04 09:41:53,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:53,428 INFO:     Epoch: 36
2023-01-04 09:41:55,012 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40057956576347353, 'Total loss': 0.40057956576347353} | train loss {'Reaction outcome loss': 0.3633441845683948, 'Total loss': 0.3633441845683948}
2023-01-04 09:41:55,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:55,012 INFO:     Epoch: 37
2023-01-04 09:41:56,557 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.397161078453064, 'Total loss': 0.397161078453064} | train loss {'Reaction outcome loss': 0.36370100709947123, 'Total loss': 0.36370100709947123}
2023-01-04 09:41:56,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:56,557 INFO:     Epoch: 38
2023-01-04 09:41:58,145 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.380853134393692, 'Total loss': 0.380853134393692} | train loss {'Reaction outcome loss': 0.3598998039884213, 'Total loss': 0.3598998039884213}
2023-01-04 09:41:58,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:58,145 INFO:     Epoch: 39
2023-01-04 09:41:59,748 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40345352490743003, 'Total loss': 0.40345352490743003} | train loss {'Reaction outcome loss': 0.35557330618410005, 'Total loss': 0.35557330618410005}
2023-01-04 09:41:59,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:41:59,748 INFO:     Epoch: 40
2023-01-04 09:42:01,365 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3972950577735901, 'Total loss': 0.3972950577735901} | train loss {'Reaction outcome loss': 0.3550075188724567, 'Total loss': 0.3550075188724567}
2023-01-04 09:42:01,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:01,365 INFO:     Epoch: 41
2023-01-04 09:42:02,976 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3841002364953359, 'Total loss': 0.3841002364953359} | train loss {'Reaction outcome loss': 0.34464160669797467, 'Total loss': 0.34464160669797467}
2023-01-04 09:42:02,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:02,976 INFO:     Epoch: 42
2023-01-04 09:42:04,564 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36641150812307993, 'Total loss': 0.36641150812307993} | train loss {'Reaction outcome loss': 0.3475039270908936, 'Total loss': 0.3475039270908936}
2023-01-04 09:42:04,564 INFO:     Found new best model at epoch 42
2023-01-04 09:42:04,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:04,565 INFO:     Epoch: 43
2023-01-04 09:42:06,109 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3807749360799789, 'Total loss': 0.3807749360799789} | train loss {'Reaction outcome loss': 0.3467792630924479, 'Total loss': 0.3467792630924479}
2023-01-04 09:42:06,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:06,110 INFO:     Epoch: 44
2023-01-04 09:42:07,657 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37707077264785765, 'Total loss': 0.37707077264785765} | train loss {'Reaction outcome loss': 0.34182821978153527, 'Total loss': 0.34182821978153527}
2023-01-04 09:42:07,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:07,657 INFO:     Epoch: 45
2023-01-04 09:42:09,248 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3727613141139348, 'Total loss': 0.3727613141139348} | train loss {'Reaction outcome loss': 0.3451594025142528, 'Total loss': 0.3451594025142528}
2023-01-04 09:42:09,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:09,248 INFO:     Epoch: 46
2023-01-04 09:42:10,838 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3698480675617854, 'Total loss': 0.3698480675617854} | train loss {'Reaction outcome loss': 0.3392922556503554, 'Total loss': 0.3392922556503554}
2023-01-04 09:42:10,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:10,838 INFO:     Epoch: 47
2023-01-04 09:42:12,438 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36721155246098836, 'Total loss': 0.36721155246098836} | train loss {'Reaction outcome loss': 0.33708983871991327, 'Total loss': 0.33708983871991327}
2023-01-04 09:42:12,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:12,438 INFO:     Epoch: 48
2023-01-04 09:42:13,985 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3935176784793536, 'Total loss': 0.3935176784793536} | train loss {'Reaction outcome loss': 0.33237823334090627, 'Total loss': 0.33237823334090627}
2023-01-04 09:42:13,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:13,985 INFO:     Epoch: 49
2023-01-04 09:42:15,559 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3761216034491857, 'Total loss': 0.3761216034491857} | train loss {'Reaction outcome loss': 0.33650942986318166, 'Total loss': 0.33650942986318166}
2023-01-04 09:42:15,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:15,559 INFO:     Epoch: 50
2023-01-04 09:42:17,110 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3847913533449173, 'Total loss': 0.3847913533449173} | train loss {'Reaction outcome loss': 0.33530178587829723, 'Total loss': 0.33530178587829723}
2023-01-04 09:42:17,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:17,111 INFO:     Epoch: 51
2023-01-04 09:42:18,696 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3558683385451635, 'Total loss': 0.3558683385451635} | train loss {'Reaction outcome loss': 0.3365854496487241, 'Total loss': 0.3365854496487241}
2023-01-04 09:42:18,696 INFO:     Found new best model at epoch 51
2023-01-04 09:42:18,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:18,697 INFO:     Epoch: 52
2023-01-04 09:42:20,265 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38051628569761914, 'Total loss': 0.38051628569761914} | train loss {'Reaction outcome loss': 0.32655463148072106, 'Total loss': 0.32655463148072106}
2023-01-04 09:42:20,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:20,265 INFO:     Epoch: 53
2023-01-04 09:42:21,849 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.383078204592069, 'Total loss': 0.383078204592069} | train loss {'Reaction outcome loss': 0.32336368962456036, 'Total loss': 0.32336368962456036}
2023-01-04 09:42:21,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:21,850 INFO:     Epoch: 54
2023-01-04 09:42:23,220 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3655529181162516, 'Total loss': 0.3655529181162516} | train loss {'Reaction outcome loss': 0.31957273390530544, 'Total loss': 0.31957273390530544}
2023-01-04 09:42:23,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:23,220 INFO:     Epoch: 55
2023-01-04 09:42:24,246 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36077023645242057, 'Total loss': 0.36077023645242057} | train loss {'Reaction outcome loss': 0.32413653999675013, 'Total loss': 0.32413653999675013}
2023-01-04 09:42:24,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:24,246 INFO:     Epoch: 56
2023-01-04 09:42:25,270 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36086258888244627, 'Total loss': 0.36086258888244627} | train loss {'Reaction outcome loss': 0.31928228060512437, 'Total loss': 0.31928228060512437}
2023-01-04 09:42:25,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:25,270 INFO:     Epoch: 57
2023-01-04 09:42:26,290 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.34937097827593483, 'Total loss': 0.34937097827593483} | train loss {'Reaction outcome loss': 0.32238304210772767, 'Total loss': 0.32238304210772767}
2023-01-04 09:42:26,290 INFO:     Found new best model at epoch 57
2023-01-04 09:42:26,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:26,291 INFO:     Epoch: 58
2023-01-04 09:42:27,455 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36422376831372577, 'Total loss': 0.36422376831372577} | train loss {'Reaction outcome loss': 0.31789636360042717, 'Total loss': 0.31789636360042717}
2023-01-04 09:42:27,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:27,455 INFO:     Epoch: 59
2023-01-04 09:42:29,058 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38584245840708414, 'Total loss': 0.38584245840708414} | train loss {'Reaction outcome loss': 0.31871876466101495, 'Total loss': 0.31871876466101495}
2023-01-04 09:42:29,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:29,059 INFO:     Epoch: 60
2023-01-04 09:42:30,675 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3739504685004552, 'Total loss': 0.3739504685004552} | train loss {'Reaction outcome loss': 0.32885783929647744, 'Total loss': 0.32885783929647744}
2023-01-04 09:42:30,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:30,675 INFO:     Epoch: 61
2023-01-04 09:42:32,264 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3568741063276927, 'Total loss': 0.3568741063276927} | train loss {'Reaction outcome loss': 0.3114293251883414, 'Total loss': 0.3114293251883414}
2023-01-04 09:42:32,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:32,265 INFO:     Epoch: 62
2023-01-04 09:42:33,874 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3660435120264689, 'Total loss': 0.3660435120264689} | train loss {'Reaction outcome loss': 0.31191341956719704, 'Total loss': 0.31191341956719704}
2023-01-04 09:42:33,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:33,874 INFO:     Epoch: 63
2023-01-04 09:42:35,515 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37738564213116965, 'Total loss': 0.37738564213116965} | train loss {'Reaction outcome loss': 0.3092190833033427, 'Total loss': 0.3092190833033427}
2023-01-04 09:42:35,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:35,516 INFO:     Epoch: 64
2023-01-04 09:42:37,108 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3638921469449997, 'Total loss': 0.3638921469449997} | train loss {'Reaction outcome loss': 0.31445162117049313, 'Total loss': 0.31445162117049313}
2023-01-04 09:42:37,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:37,109 INFO:     Epoch: 65
2023-01-04 09:42:38,739 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3763666391372681, 'Total loss': 0.3763666391372681} | train loss {'Reaction outcome loss': 0.3092093576197985, 'Total loss': 0.3092093576197985}
2023-01-04 09:42:38,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:38,739 INFO:     Epoch: 66
2023-01-04 09:42:40,357 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3393879344065984, 'Total loss': 0.3393879344065984} | train loss {'Reaction outcome loss': 0.3060726544102484, 'Total loss': 0.3060726544102484}
2023-01-04 09:42:40,357 INFO:     Found new best model at epoch 66
2023-01-04 09:42:40,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:40,359 INFO:     Epoch: 67
2023-01-04 09:42:41,944 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3296524465084076, 'Total loss': 0.3296524465084076} | train loss {'Reaction outcome loss': 0.2995604380688536, 'Total loss': 0.2995604380688536}
2023-01-04 09:42:41,944 INFO:     Found new best model at epoch 67
2023-01-04 09:42:41,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:41,946 INFO:     Epoch: 68
2023-01-04 09:42:43,548 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3372755656639735, 'Total loss': 0.3372755656639735} | train loss {'Reaction outcome loss': 0.2989379792734952, 'Total loss': 0.2989379792734952}
2023-01-04 09:42:43,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:43,549 INFO:     Epoch: 69
2023-01-04 09:42:45,131 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34875552157560985, 'Total loss': 0.34875552157560985} | train loss {'Reaction outcome loss': 0.29825978208648757, 'Total loss': 0.29825978208648757}
2023-01-04 09:42:45,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:45,131 INFO:     Epoch: 70
2023-01-04 09:42:46,697 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3475460112094879, 'Total loss': 0.3475460112094879} | train loss {'Reaction outcome loss': 0.29808871861061326, 'Total loss': 0.29808871861061326}
2023-01-04 09:42:46,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:46,697 INFO:     Epoch: 71
2023-01-04 09:42:48,312 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3608721529444059, 'Total loss': 0.3608721529444059} | train loss {'Reaction outcome loss': 0.307529764033962, 'Total loss': 0.307529764033962}
2023-01-04 09:42:48,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:48,312 INFO:     Epoch: 72
2023-01-04 09:42:49,943 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36454937358697254, 'Total loss': 0.36454937358697254} | train loss {'Reaction outcome loss': 0.29648513535874477, 'Total loss': 0.29648513535874477}
2023-01-04 09:42:49,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:49,944 INFO:     Epoch: 73
2023-01-04 09:42:51,521 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3638265570004781, 'Total loss': 0.3638265570004781} | train loss {'Reaction outcome loss': 0.3079873883043942, 'Total loss': 0.3079873883043942}
2023-01-04 09:42:51,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:51,521 INFO:     Epoch: 74
2023-01-04 09:42:53,140 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36466351250807444, 'Total loss': 0.36466351250807444} | train loss {'Reaction outcome loss': 0.32160082595098927, 'Total loss': 0.32160082595098927}
2023-01-04 09:42:53,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:53,142 INFO:     Epoch: 75
2023-01-04 09:42:54,718 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3482198566198349, 'Total loss': 0.3482198566198349} | train loss {'Reaction outcome loss': 0.2978121123902594, 'Total loss': 0.2978121123902594}
2023-01-04 09:42:54,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:54,718 INFO:     Epoch: 76
2023-01-04 09:42:56,287 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3709977179765701, 'Total loss': 0.3709977179765701} | train loss {'Reaction outcome loss': 0.29045434341684956, 'Total loss': 0.29045434341684956}
2023-01-04 09:42:56,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:56,287 INFO:     Epoch: 77
2023-01-04 09:42:57,843 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37077339788277947, 'Total loss': 0.37077339788277947} | train loss {'Reaction outcome loss': 0.29731473863880703, 'Total loss': 0.29731473863880703}
2023-01-04 09:42:57,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:57,843 INFO:     Epoch: 78
2023-01-04 09:42:59,415 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3617964506149292, 'Total loss': 0.3617964506149292} | train loss {'Reaction outcome loss': 0.34856957099332975, 'Total loss': 0.34856957099332975}
2023-01-04 09:42:59,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:42:59,416 INFO:     Epoch: 79
2023-01-04 09:43:00,946 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34576327006022134, 'Total loss': 0.34576327006022134} | train loss {'Reaction outcome loss': 0.29999928534395975, 'Total loss': 0.29999928534395975}
2023-01-04 09:43:00,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:00,946 INFO:     Epoch: 80
2023-01-04 09:43:02,513 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4109089195728302, 'Total loss': 0.4109089195728302} | train loss {'Reaction outcome loss': 0.293959525961617, 'Total loss': 0.293959525961617}
2023-01-04 09:43:02,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:02,514 INFO:     Epoch: 81
2023-01-04 09:43:04,003 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3533494641383489, 'Total loss': 0.3533494641383489} | train loss {'Reaction outcome loss': 0.2962602966505548, 'Total loss': 0.2962602966505548}
2023-01-04 09:43:04,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:04,003 INFO:     Epoch: 82
2023-01-04 09:43:05,527 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36769110560417173, 'Total loss': 0.36769110560417173} | train loss {'Reaction outcome loss': 0.31947344148437073, 'Total loss': 0.31947344148437073}
2023-01-04 09:43:05,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:05,527 INFO:     Epoch: 83
2023-01-04 09:43:07,043 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35395190517107644, 'Total loss': 0.35395190517107644} | train loss {'Reaction outcome loss': 0.29168801674983325, 'Total loss': 0.29168801674983325}
2023-01-04 09:43:07,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:07,043 INFO:     Epoch: 84
2023-01-04 09:43:08,568 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3936333904663722, 'Total loss': 0.3936333904663722} | train loss {'Reaction outcome loss': 0.28800889253920026, 'Total loss': 0.28800889253920026}
2023-01-04 09:43:08,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:08,568 INFO:     Epoch: 85
2023-01-04 09:43:10,063 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.34618994891643523, 'Total loss': 0.34618994891643523} | train loss {'Reaction outcome loss': 0.28381521765550133, 'Total loss': 0.28381521765550133}
2023-01-04 09:43:10,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:10,063 INFO:     Epoch: 86
2023-01-04 09:43:11,621 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36486679315567017, 'Total loss': 0.36486679315567017} | train loss {'Reaction outcome loss': 0.2821115777976271, 'Total loss': 0.2821115777976271}
2023-01-04 09:43:11,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:11,622 INFO:     Epoch: 87
2023-01-04 09:43:13,137 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.32506609459718067, 'Total loss': 0.32506609459718067} | train loss {'Reaction outcome loss': 0.27924405069400865, 'Total loss': 0.27924405069400865}
2023-01-04 09:43:13,137 INFO:     Found new best model at epoch 87
2023-01-04 09:43:13,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:13,137 INFO:     Epoch: 88
2023-01-04 09:43:14,700 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.342612295349439, 'Total loss': 0.342612295349439} | train loss {'Reaction outcome loss': 0.27706747745021837, 'Total loss': 0.27706747745021837}
2023-01-04 09:43:14,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:14,700 INFO:     Epoch: 89
2023-01-04 09:43:16,269 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3307907481988271, 'Total loss': 0.3307907481988271} | train loss {'Reaction outcome loss': 0.28165599212482356, 'Total loss': 0.28165599212482356}
2023-01-04 09:43:16,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:16,269 INFO:     Epoch: 90
2023-01-04 09:43:17,829 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36243346631526946, 'Total loss': 0.36243346631526946} | train loss {'Reaction outcome loss': 0.28351973774640454, 'Total loss': 0.28351973774640454}
2023-01-04 09:43:17,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:17,829 INFO:     Epoch: 91
2023-01-04 09:43:19,359 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34200455943743385, 'Total loss': 0.34200455943743385} | train loss {'Reaction outcome loss': 0.2918438930199414, 'Total loss': 0.2918438930199414}
2023-01-04 09:43:19,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:19,359 INFO:     Epoch: 92
2023-01-04 09:43:20,913 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.34355854193369545, 'Total loss': 0.34355854193369545} | train loss {'Reaction outcome loss': 0.2933322553779336, 'Total loss': 0.2933322553779336}
2023-01-04 09:43:20,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:20,913 INFO:     Epoch: 93
2023-01-04 09:43:22,425 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3352444569269816, 'Total loss': 0.3352444569269816} | train loss {'Reaction outcome loss': 0.326562398105718, 'Total loss': 0.326562398105718}
2023-01-04 09:43:22,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:22,426 INFO:     Epoch: 94
2023-01-04 09:43:23,974 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3546974341074626, 'Total loss': 0.3546974341074626} | train loss {'Reaction outcome loss': 0.28313019040945, 'Total loss': 0.28313019040945}
2023-01-04 09:43:23,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:23,975 INFO:     Epoch: 95
2023-01-04 09:43:25,531 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.330093914270401, 'Total loss': 0.330093914270401} | train loss {'Reaction outcome loss': 0.2764620964543597, 'Total loss': 0.2764620964543597}
2023-01-04 09:43:25,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:25,531 INFO:     Epoch: 96
2023-01-04 09:43:27,066 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3381993720928828, 'Total loss': 0.3381993720928828} | train loss {'Reaction outcome loss': 0.2733756671366501, 'Total loss': 0.2733756671366501}
2023-01-04 09:43:27,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:27,067 INFO:     Epoch: 97
2023-01-04 09:43:28,591 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3539992491404215, 'Total loss': 0.3539992491404215} | train loss {'Reaction outcome loss': 0.2721664286516476, 'Total loss': 0.2721664286516476}
2023-01-04 09:43:28,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:28,591 INFO:     Epoch: 98
2023-01-04 09:43:30,143 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34666849772135416, 'Total loss': 0.34666849772135416} | train loss {'Reaction outcome loss': 0.27171328939700334, 'Total loss': 0.27171328939700334}
2023-01-04 09:43:30,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:30,144 INFO:     Epoch: 99
2023-01-04 09:43:31,654 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3418212056159973, 'Total loss': 0.3418212056159973} | train loss {'Reaction outcome loss': 0.2731164088067801, 'Total loss': 0.2731164088067801}
2023-01-04 09:43:31,654 INFO:     Best model found after epoch 88 of 100.
2023-01-04 09:43:31,654 INFO:   Done with stage: TRAINING
2023-01-04 09:43:31,654 INFO:   Starting stage: EVALUATION
2023-01-04 09:43:31,784 INFO:   Done with stage: EVALUATION
2023-01-04 09:43:31,784 INFO:   Leaving out SEQ value Fold_5
2023-01-04 09:43:31,797 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 09:43:31,797 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:43:32,441 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:43:32,441 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:43:32,509 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:43:32,509 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:43:32,510 INFO:     No hyperparam tuning for this model
2023-01-04 09:43:32,510 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:43:32,510 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:43:32,510 INFO:     None feature selector for col prot
2023-01-04 09:43:32,511 INFO:     None feature selector for col prot
2023-01-04 09:43:32,511 INFO:     None feature selector for col prot
2023-01-04 09:43:32,511 INFO:     None feature selector for col chem
2023-01-04 09:43:32,511 INFO:     None feature selector for col chem
2023-01-04 09:43:32,511 INFO:     None feature selector for col chem
2023-01-04 09:43:32,511 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:43:32,511 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:43:32,512 INFO:     Number of params in model 70111
2023-01-04 09:43:32,515 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:43:32,516 INFO:   Starting stage: TRAINING
2023-01-04 09:43:32,558 INFO:     Val loss before train {'Reaction outcome loss': 0.9197257200876872, 'Total loss': 0.9197257200876872}
2023-01-04 09:43:32,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:32,558 INFO:     Epoch: 0
2023-01-04 09:43:34,118 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.719729608297348, 'Total loss': 0.719729608297348} | train loss {'Reaction outcome loss': 0.8348018391468034, 'Total loss': 0.8348018391468034}
2023-01-04 09:43:34,118 INFO:     Found new best model at epoch 0
2023-01-04 09:43:34,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:34,119 INFO:     Epoch: 1
2023-01-04 09:43:35,697 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6330634633700053, 'Total loss': 0.6330634633700053} | train loss {'Reaction outcome loss': 0.6771637227130711, 'Total loss': 0.6771637227130711}
2023-01-04 09:43:35,697 INFO:     Found new best model at epoch 1
2023-01-04 09:43:35,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:35,698 INFO:     Epoch: 2
2023-01-04 09:43:37,245 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5704441209634145, 'Total loss': 0.5704441209634145} | train loss {'Reaction outcome loss': 0.5826119672950855, 'Total loss': 0.5826119672950855}
2023-01-04 09:43:37,245 INFO:     Found new best model at epoch 2
2023-01-04 09:43:37,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:37,246 INFO:     Epoch: 3
2023-01-04 09:43:38,806 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5630149106184642, 'Total loss': 0.5630149106184642} | train loss {'Reaction outcome loss': 0.5370387851869156, 'Total loss': 0.5370387851869156}
2023-01-04 09:43:38,806 INFO:     Found new best model at epoch 3
2023-01-04 09:43:38,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:38,807 INFO:     Epoch: 4
2023-01-04 09:43:40,354 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5149728973706563, 'Total loss': 0.5149728973706563} | train loss {'Reaction outcome loss': 0.5158751015736308, 'Total loss': 0.5158751015736308}
2023-01-04 09:43:40,354 INFO:     Found new best model at epoch 4
2023-01-04 09:43:40,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:40,355 INFO:     Epoch: 5
2023-01-04 09:43:41,935 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.550625479221344, 'Total loss': 0.550625479221344} | train loss {'Reaction outcome loss': 0.5019290467677133, 'Total loss': 0.5019290467677133}
2023-01-04 09:43:41,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:41,936 INFO:     Epoch: 6
2023-01-04 09:43:43,501 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5191855569680531, 'Total loss': 0.5191855569680531} | train loss {'Reaction outcome loss': 0.4884690426101753, 'Total loss': 0.4884690426101753}
2023-01-04 09:43:43,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:43,502 INFO:     Epoch: 7
2023-01-04 09:43:45,063 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5249350905418396, 'Total loss': 0.5249350905418396} | train loss {'Reaction outcome loss': 0.48130627390710023, 'Total loss': 0.48130627390710023}
2023-01-04 09:43:45,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:45,063 INFO:     Epoch: 8
2023-01-04 09:43:46,592 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.507028216123581, 'Total loss': 0.507028216123581} | train loss {'Reaction outcome loss': 0.47171476693144776, 'Total loss': 0.47171476693144776}
2023-01-04 09:43:46,592 INFO:     Found new best model at epoch 8
2023-01-04 09:43:46,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:46,593 INFO:     Epoch: 9
2023-01-04 09:43:48,160 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5010915795962015, 'Total loss': 0.5010915795962015} | train loss {'Reaction outcome loss': 0.46212723447742876, 'Total loss': 0.46212723447742876}
2023-01-04 09:43:48,160 INFO:     Found new best model at epoch 9
2023-01-04 09:43:48,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:48,161 INFO:     Epoch: 10
2023-01-04 09:43:49,694 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5269564429918925, 'Total loss': 0.5269564429918925} | train loss {'Reaction outcome loss': 0.46067920429396714, 'Total loss': 0.46067920429396714}
2023-01-04 09:43:49,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:49,695 INFO:     Epoch: 11
2023-01-04 09:43:51,267 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5102414608001709, 'Total loss': 0.5102414608001709} | train loss {'Reaction outcome loss': 0.45354274598484867, 'Total loss': 0.45354274598484867}
2023-01-04 09:43:51,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:51,267 INFO:     Epoch: 12
2023-01-04 09:43:52,829 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5020812670389811, 'Total loss': 0.5020812670389811} | train loss {'Reaction outcome loss': 0.4465725942639237, 'Total loss': 0.4465725942639237}
2023-01-04 09:43:52,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:52,830 INFO:     Epoch: 13
2023-01-04 09:43:54,405 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4817814201116562, 'Total loss': 0.4817814201116562} | train loss {'Reaction outcome loss': 0.4383999887410054, 'Total loss': 0.4383999887410054}
2023-01-04 09:43:54,405 INFO:     Found new best model at epoch 13
2023-01-04 09:43:54,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:54,406 INFO:     Epoch: 14
2023-01-04 09:43:55,934 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5115371108055115, 'Total loss': 0.5115371108055115} | train loss {'Reaction outcome loss': 0.4339281934908581, 'Total loss': 0.4339281934908581}
2023-01-04 09:43:55,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:55,942 INFO:     Epoch: 15
2023-01-04 09:43:57,531 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4890102694431941, 'Total loss': 0.4890102694431941} | train loss {'Reaction outcome loss': 0.43051296434893077, 'Total loss': 0.43051296434893077}
2023-01-04 09:43:57,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:57,531 INFO:     Epoch: 16
2023-01-04 09:43:59,054 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4959191958109538, 'Total loss': 0.4959191958109538} | train loss {'Reaction outcome loss': 0.42187130790109667, 'Total loss': 0.42187130790109667}
2023-01-04 09:43:59,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:43:59,055 INFO:     Epoch: 17
2023-01-04 09:44:00,634 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49179706573486326, 'Total loss': 0.49179706573486326} | train loss {'Reaction outcome loss': 0.41933603283515475, 'Total loss': 0.41933603283515475}
2023-01-04 09:44:00,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:00,635 INFO:     Epoch: 18
2023-01-04 09:44:02,210 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4774381995201111, 'Total loss': 0.4774381995201111} | train loss {'Reaction outcome loss': 0.41964198810314013, 'Total loss': 0.41964198810314013}
2023-01-04 09:44:02,210 INFO:     Found new best model at epoch 18
2023-01-04 09:44:02,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:02,211 INFO:     Epoch: 19
2023-01-04 09:44:03,786 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49176155229409535, 'Total loss': 0.49176155229409535} | train loss {'Reaction outcome loss': 0.41281599909174743, 'Total loss': 0.41281599909174743}
2023-01-04 09:44:03,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:03,786 INFO:     Epoch: 20
2023-01-04 09:44:05,347 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4825768947601318, 'Total loss': 0.4825768947601318} | train loss {'Reaction outcome loss': 0.40577169585744394, 'Total loss': 0.40577169585744394}
2023-01-04 09:44:05,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:05,348 INFO:     Epoch: 21
2023-01-04 09:44:06,920 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5100856800874074, 'Total loss': 0.5100856800874074} | train loss {'Reaction outcome loss': 0.40461558302602185, 'Total loss': 0.40461558302602185}
2023-01-04 09:44:06,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:06,921 INFO:     Epoch: 22
2023-01-04 09:44:08,485 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4894716461499532, 'Total loss': 0.4894716461499532} | train loss {'Reaction outcome loss': 0.4020607614829222, 'Total loss': 0.4020607614829222}
2023-01-04 09:44:08,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:08,485 INFO:     Epoch: 23
2023-01-04 09:44:10,051 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4841992944478989, 'Total loss': 0.4841992944478989} | train loss {'Reaction outcome loss': 0.39432109435112467, 'Total loss': 0.39432109435112467}
2023-01-04 09:44:10,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:10,052 INFO:     Epoch: 24
2023-01-04 09:44:11,656 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48099220991134645, 'Total loss': 0.48099220991134645} | train loss {'Reaction outcome loss': 0.393841241456111, 'Total loss': 0.393841241456111}
2023-01-04 09:44:11,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:11,657 INFO:     Epoch: 25
2023-01-04 09:44:13,218 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46826151907444, 'Total loss': 0.46826151907444} | train loss {'Reaction outcome loss': 0.38693444823530176, 'Total loss': 0.38693444823530176}
2023-01-04 09:44:13,219 INFO:     Found new best model at epoch 25
2023-01-04 09:44:13,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:13,219 INFO:     Epoch: 26
2023-01-04 09:44:14,788 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49504191080729165, 'Total loss': 0.49504191080729165} | train loss {'Reaction outcome loss': 0.38582421650955395, 'Total loss': 0.38582421650955395}
2023-01-04 09:44:14,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:14,789 INFO:     Epoch: 27
2023-01-04 09:44:16,314 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5233471592267355, 'Total loss': 0.5233471592267355} | train loss {'Reaction outcome loss': 0.38206853015543324, 'Total loss': 0.38206853015543324}
2023-01-04 09:44:16,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:16,315 INFO:     Epoch: 28
2023-01-04 09:44:17,880 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4793548901875814, 'Total loss': 0.4793548901875814} | train loss {'Reaction outcome loss': 0.37670392943848774, 'Total loss': 0.37670392943848774}
2023-01-04 09:44:17,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:17,881 INFO:     Epoch: 29
2023-01-04 09:44:19,451 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49238416651884714, 'Total loss': 0.49238416651884714} | train loss {'Reaction outcome loss': 0.3721811217306323, 'Total loss': 0.3721811217306323}
2023-01-04 09:44:19,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:19,451 INFO:     Epoch: 30
2023-01-04 09:44:21,022 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48094127972920736, 'Total loss': 0.48094127972920736} | train loss {'Reaction outcome loss': 0.36981869653028704, 'Total loss': 0.36981869653028704}
2023-01-04 09:44:21,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:21,022 INFO:     Epoch: 31
2023-01-04 09:44:22,552 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.475104820728302, 'Total loss': 0.475104820728302} | train loss {'Reaction outcome loss': 0.3671757452431999, 'Total loss': 0.3671757452431999}
2023-01-04 09:44:22,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:22,552 INFO:     Epoch: 32
2023-01-04 09:44:24,125 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4624433020750682, 'Total loss': 0.4624433020750682} | train loss {'Reaction outcome loss': 0.36127122077378127, 'Total loss': 0.36127122077378127}
2023-01-04 09:44:24,125 INFO:     Found new best model at epoch 32
2023-01-04 09:44:24,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:24,126 INFO:     Epoch: 33
2023-01-04 09:44:25,681 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4773824503024419, 'Total loss': 0.4773824503024419} | train loss {'Reaction outcome loss': 0.36069748063810464, 'Total loss': 0.36069748063810464}
2023-01-04 09:44:25,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:25,682 INFO:     Epoch: 34
2023-01-04 09:44:27,286 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4895815094312032, 'Total loss': 0.4895815094312032} | train loss {'Reaction outcome loss': 0.3620434639309718, 'Total loss': 0.3620434639309718}
2023-01-04 09:44:27,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:27,287 INFO:     Epoch: 35
2023-01-04 09:44:28,882 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47227755983670555, 'Total loss': 0.47227755983670555} | train loss {'Reaction outcome loss': 0.35637518023863596, 'Total loss': 0.35637518023863596}
2023-01-04 09:44:28,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:28,882 INFO:     Epoch: 36
2023-01-04 09:44:30,481 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45359102487564085, 'Total loss': 0.45359102487564085} | train loss {'Reaction outcome loss': 0.35718192447931757, 'Total loss': 0.35718192447931757}
2023-01-04 09:44:30,482 INFO:     Found new best model at epoch 36
2023-01-04 09:44:30,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:30,483 INFO:     Epoch: 37
2023-01-04 09:44:32,054 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46462941269079844, 'Total loss': 0.46462941269079844} | train loss {'Reaction outcome loss': 0.3520873780715336, 'Total loss': 0.3520873780715336}
2023-01-04 09:44:32,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:32,055 INFO:     Epoch: 38
2023-01-04 09:44:33,661 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46618715723355614, 'Total loss': 0.46618715723355614} | train loss {'Reaction outcome loss': 0.3481275338262642, 'Total loss': 0.3481275338262642}
2023-01-04 09:44:33,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:33,661 INFO:     Epoch: 39
2023-01-04 09:44:35,245 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4967288722594579, 'Total loss': 0.4967288722594579} | train loss {'Reaction outcome loss': 0.3471758256965596, 'Total loss': 0.3471758256965596}
2023-01-04 09:44:35,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:35,245 INFO:     Epoch: 40
2023-01-04 09:44:36,883 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45439648230870566, 'Total loss': 0.45439648230870566} | train loss {'Reaction outcome loss': 0.34297257269117376, 'Total loss': 0.34297257269117376}
2023-01-04 09:44:36,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:36,884 INFO:     Epoch: 41
2023-01-04 09:44:38,507 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47394173641999565, 'Total loss': 0.47394173641999565} | train loss {'Reaction outcome loss': 0.3378108813013841, 'Total loss': 0.3378108813013841}
2023-01-04 09:44:38,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:38,507 INFO:     Epoch: 42
2023-01-04 09:44:40,145 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4450020849704742, 'Total loss': 0.4450020849704742} | train loss {'Reaction outcome loss': 0.3403709454979707, 'Total loss': 0.3403709454979707}
2023-01-04 09:44:40,145 INFO:     Found new best model at epoch 42
2023-01-04 09:44:40,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:40,146 INFO:     Epoch: 43
2023-01-04 09:44:41,718 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4753764351209005, 'Total loss': 0.4753764351209005} | train loss {'Reaction outcome loss': 0.3368799281894945, 'Total loss': 0.3368799281894945}
2023-01-04 09:44:41,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:41,718 INFO:     Epoch: 44
2023-01-04 09:44:43,326 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4801107992728551, 'Total loss': 0.4801107992728551} | train loss {'Reaction outcome loss': 0.33285587488098695, 'Total loss': 0.33285587488098695}
2023-01-04 09:44:43,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:43,326 INFO:     Epoch: 45
2023-01-04 09:44:44,898 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43905656536420185, 'Total loss': 0.43905656536420185} | train loss {'Reaction outcome loss': 0.32881500165815386, 'Total loss': 0.32881500165815386}
2023-01-04 09:44:44,898 INFO:     Found new best model at epoch 45
2023-01-04 09:44:44,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:44,899 INFO:     Epoch: 46
2023-01-04 09:44:46,496 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5051659305890401, 'Total loss': 0.5051659305890401} | train loss {'Reaction outcome loss': 0.32620106424988393, 'Total loss': 0.32620106424988393}
2023-01-04 09:44:46,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:46,496 INFO:     Epoch: 47
2023-01-04 09:44:48,117 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4683835128943125, 'Total loss': 0.4683835128943125} | train loss {'Reaction outcome loss': 0.3246200232621995, 'Total loss': 0.3246200232621995}
2023-01-04 09:44:48,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:48,117 INFO:     Epoch: 48
2023-01-04 09:44:49,733 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4725994035601616, 'Total loss': 0.4725994035601616} | train loss {'Reaction outcome loss': 0.32354576977151395, 'Total loss': 0.32354576977151395}
2023-01-04 09:44:49,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:49,734 INFO:     Epoch: 49
2023-01-04 09:44:51,343 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4460664729277293, 'Total loss': 0.4460664729277293} | train loss {'Reaction outcome loss': 0.3248002266894609, 'Total loss': 0.3248002266894609}
2023-01-04 09:44:51,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:51,343 INFO:     Epoch: 50
2023-01-04 09:44:52,923 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4657470593849818, 'Total loss': 0.4657470593849818} | train loss {'Reaction outcome loss': 0.3204290953461444, 'Total loss': 0.3204290953461444}
2023-01-04 09:44:52,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:52,923 INFO:     Epoch: 51
2023-01-04 09:44:54,483 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4633372197548548, 'Total loss': 0.4633372197548548} | train loss {'Reaction outcome loss': 0.32013741205530477, 'Total loss': 0.32013741205530477}
2023-01-04 09:44:54,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:54,484 INFO:     Epoch: 52
2023-01-04 09:44:56,029 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46710803310076393, 'Total loss': 0.46710803310076393} | train loss {'Reaction outcome loss': 0.31667581448055776, 'Total loss': 0.31667581448055776}
2023-01-04 09:44:56,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:56,029 INFO:     Epoch: 53
2023-01-04 09:44:57,577 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5006957103808721, 'Total loss': 0.5006957103808721} | train loss {'Reaction outcome loss': 0.31417949573012466, 'Total loss': 0.31417949573012466}
2023-01-04 09:44:57,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:57,577 INFO:     Epoch: 54
2023-01-04 09:44:59,116 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4723020911216736, 'Total loss': 0.4723020911216736} | train loss {'Reaction outcome loss': 0.3135636503461896, 'Total loss': 0.3135636503461896}
2023-01-04 09:44:59,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:44:59,116 INFO:     Epoch: 55
2023-01-04 09:45:00,668 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.466862682501475, 'Total loss': 0.466862682501475} | train loss {'Reaction outcome loss': 0.30869352661530464, 'Total loss': 0.30869352661530464}
2023-01-04 09:45:00,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:00,669 INFO:     Epoch: 56
2023-01-04 09:45:02,196 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47714598576227824, 'Total loss': 0.47714598576227824} | train loss {'Reaction outcome loss': 0.30806705713379684, 'Total loss': 0.30806705713379684}
2023-01-04 09:45:02,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:02,196 INFO:     Epoch: 57
2023-01-04 09:45:03,756 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4635689894358317, 'Total loss': 0.4635689894358317} | train loss {'Reaction outcome loss': 0.3068274451076769, 'Total loss': 0.3068274451076769}
2023-01-04 09:45:03,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:03,757 INFO:     Epoch: 58
2023-01-04 09:45:05,301 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4507553160190582, 'Total loss': 0.4507553160190582} | train loss {'Reaction outcome loss': 0.3055232264343582, 'Total loss': 0.3055232264343582}
2023-01-04 09:45:05,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:05,302 INFO:     Epoch: 59
2023-01-04 09:45:06,847 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4655468910932541, 'Total loss': 0.4655468910932541} | train loss {'Reaction outcome loss': 0.30558985092472085, 'Total loss': 0.30558985092472085}
2023-01-04 09:45:06,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:06,848 INFO:     Epoch: 60
2023-01-04 09:45:08,364 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45344649453957875, 'Total loss': 0.45344649453957875} | train loss {'Reaction outcome loss': 0.3045522817259231, 'Total loss': 0.3045522817259231}
2023-01-04 09:45:08,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:08,365 INFO:     Epoch: 61
2023-01-04 09:45:09,922 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43539599478244784, 'Total loss': 0.43539599478244784} | train loss {'Reaction outcome loss': 0.2979597400618374, 'Total loss': 0.2979597400618374}
2023-01-04 09:45:09,922 INFO:     Found new best model at epoch 61
2023-01-04 09:45:09,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:09,923 INFO:     Epoch: 62
2023-01-04 09:45:11,458 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.431233756740888, 'Total loss': 0.431233756740888} | train loss {'Reaction outcome loss': 0.303461466293903, 'Total loss': 0.303461466293903}
2023-01-04 09:45:11,459 INFO:     Found new best model at epoch 62
2023-01-04 09:45:11,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:11,459 INFO:     Epoch: 63
2023-01-04 09:45:13,030 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4524811307589213, 'Total loss': 0.4524811307589213} | train loss {'Reaction outcome loss': 0.29894336466324456, 'Total loss': 0.29894336466324456}
2023-01-04 09:45:13,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:13,030 INFO:     Epoch: 64
2023-01-04 09:45:14,594 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4995587468147278, 'Total loss': 0.4995587468147278} | train loss {'Reaction outcome loss': 0.29642798022673017, 'Total loss': 0.29642798022673017}
2023-01-04 09:45:14,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:14,594 INFO:     Epoch: 65
2023-01-04 09:45:16,168 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4456122636795044, 'Total loss': 0.4456122636795044} | train loss {'Reaction outcome loss': 0.29683525830722457, 'Total loss': 0.29683525830722457}
2023-01-04 09:45:16,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:16,168 INFO:     Epoch: 66
2023-01-04 09:45:17,697 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4869458585977554, 'Total loss': 0.4869458585977554} | train loss {'Reaction outcome loss': 0.29186613389731314, 'Total loss': 0.29186613389731314}
2023-01-04 09:45:17,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:17,698 INFO:     Epoch: 67
2023-01-04 09:45:19,265 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4409738878409068, 'Total loss': 0.4409738878409068} | train loss {'Reaction outcome loss': 0.2909302894927104, 'Total loss': 0.2909302894927104}
2023-01-04 09:45:19,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:19,266 INFO:     Epoch: 68
2023-01-04 09:45:20,787 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48074254890282947, 'Total loss': 0.48074254890282947} | train loss {'Reaction outcome loss': 0.29014881659931224, 'Total loss': 0.29014881659931224}
2023-01-04 09:45:20,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:20,787 INFO:     Epoch: 69
2023-01-04 09:45:22,351 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4648042490084966, 'Total loss': 0.4648042490084966} | train loss {'Reaction outcome loss': 0.28785809449555644, 'Total loss': 0.28785809449555644}
2023-01-04 09:45:22,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:22,351 INFO:     Epoch: 70
2023-01-04 09:45:23,918 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44445841709772743, 'Total loss': 0.44445841709772743} | train loss {'Reaction outcome loss': 0.28550998126879495, 'Total loss': 0.28550998126879495}
2023-01-04 09:45:23,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:23,918 INFO:     Epoch: 71
2023-01-04 09:45:25,495 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4562287578980128, 'Total loss': 0.4562287578980128} | train loss {'Reaction outcome loss': 0.28515248362391865, 'Total loss': 0.28515248362391865}
2023-01-04 09:45:25,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:25,495 INFO:     Epoch: 72
2023-01-04 09:45:27,042 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43284837206204735, 'Total loss': 0.43284837206204735} | train loss {'Reaction outcome loss': 0.285720058054485, 'Total loss': 0.285720058054485}
2023-01-04 09:45:27,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:27,042 INFO:     Epoch: 73
2023-01-04 09:45:28,624 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43790437579154967, 'Total loss': 0.43790437579154967} | train loss {'Reaction outcome loss': 0.2815236987189696, 'Total loss': 0.2815236987189696}
2023-01-04 09:45:28,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:28,624 INFO:     Epoch: 74
2023-01-04 09:45:30,151 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4194793353478114, 'Total loss': 0.4194793353478114} | train loss {'Reaction outcome loss': 0.2820517959658204, 'Total loss': 0.2820517959658204}
2023-01-04 09:45:30,152 INFO:     Found new best model at epoch 74
2023-01-04 09:45:30,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:30,152 INFO:     Epoch: 75
2023-01-04 09:45:31,706 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4367249915997187, 'Total loss': 0.4367249915997187} | train loss {'Reaction outcome loss': 0.277394185078058, 'Total loss': 0.277394185078058}
2023-01-04 09:45:31,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:31,708 INFO:     Epoch: 76
2023-01-04 09:45:33,285 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45267223517100014, 'Total loss': 0.45267223517100014} | train loss {'Reaction outcome loss': 0.27826433686626945, 'Total loss': 0.27826433686626945}
2023-01-04 09:45:33,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:33,285 INFO:     Epoch: 77
2023-01-04 09:45:34,920 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43274521132310234, 'Total loss': 0.43274521132310234} | train loss {'Reaction outcome loss': 0.27633728942285807, 'Total loss': 0.27633728942285807}
2023-01-04 09:45:34,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:34,920 INFO:     Epoch: 78
2023-01-04 09:45:36,481 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4354178388913473, 'Total loss': 0.4354178388913473} | train loss {'Reaction outcome loss': 0.2742016892812958, 'Total loss': 0.2742016892812958}
2023-01-04 09:45:36,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:36,482 INFO:     Epoch: 79
2023-01-04 09:45:38,065 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4718760341405869, 'Total loss': 0.4718760341405869} | train loss {'Reaction outcome loss': 0.27758419597084344, 'Total loss': 0.27758419597084344}
2023-01-04 09:45:38,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:38,065 INFO:     Epoch: 80
2023-01-04 09:45:39,705 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4543845216433207, 'Total loss': 0.4543845216433207} | train loss {'Reaction outcome loss': 0.27169663331299915, 'Total loss': 0.27169663331299915}
2023-01-04 09:45:39,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:39,705 INFO:     Epoch: 81
2023-01-04 09:45:41,337 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4557976543903351, 'Total loss': 0.4557976543903351} | train loss {'Reaction outcome loss': 0.2701114951784215, 'Total loss': 0.2701114951784215}
2023-01-04 09:45:41,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:41,337 INFO:     Epoch: 82
2023-01-04 09:45:42,969 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4568115552266439, 'Total loss': 0.4568115552266439} | train loss {'Reaction outcome loss': 0.2740116617793641, 'Total loss': 0.2740116617793641}
2023-01-04 09:45:42,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:42,969 INFO:     Epoch: 83
2023-01-04 09:45:44,540 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4644599179426829, 'Total loss': 0.4644599179426829} | train loss {'Reaction outcome loss': 0.270639748295722, 'Total loss': 0.270639748295722}
2023-01-04 09:45:44,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:44,540 INFO:     Epoch: 84
2023-01-04 09:45:46,160 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4271361311276754, 'Total loss': 0.4271361311276754} | train loss {'Reaction outcome loss': 0.268034285882535, 'Total loss': 0.268034285882535}
2023-01-04 09:45:46,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:46,160 INFO:     Epoch: 85
2023-01-04 09:45:47,747 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43386305769284567, 'Total loss': 0.43386305769284567} | train loss {'Reaction outcome loss': 0.26487215223725524, 'Total loss': 0.26487215223725524}
2023-01-04 09:45:47,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:47,747 INFO:     Epoch: 86
2023-01-04 09:45:49,382 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4342120627562205, 'Total loss': 0.4342120627562205} | train loss {'Reaction outcome loss': 0.2684289000471146, 'Total loss': 0.2684289000471146}
2023-01-04 09:45:49,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:49,382 INFO:     Epoch: 87
2023-01-04 09:45:51,010 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46849225759506224, 'Total loss': 0.46849225759506224} | train loss {'Reaction outcome loss': 0.2621457252638004, 'Total loss': 0.2621457252638004}
2023-01-04 09:45:51,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:51,011 INFO:     Epoch: 88
2023-01-04 09:45:52,637 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4345586647590001, 'Total loss': 0.4345586647590001} | train loss {'Reaction outcome loss': 0.26374848450564303, 'Total loss': 0.26374848450564303}
2023-01-04 09:45:52,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:52,638 INFO:     Epoch: 89
2023-01-04 09:45:54,212 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4589982827504476, 'Total loss': 0.4589982827504476} | train loss {'Reaction outcome loss': 0.26313197736490507, 'Total loss': 0.26313197736490507}
2023-01-04 09:45:54,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:54,213 INFO:     Epoch: 90
2023-01-04 09:45:55,815 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48016361395517987, 'Total loss': 0.48016361395517987} | train loss {'Reaction outcome loss': 0.2608696523152749, 'Total loss': 0.2608696523152749}
2023-01-04 09:45:55,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:55,815 INFO:     Epoch: 91
2023-01-04 09:45:57,333 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44878392219543456, 'Total loss': 0.44878392219543456} | train loss {'Reaction outcome loss': 0.2685479545152144, 'Total loss': 0.2685479545152144}
2023-01-04 09:45:57,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:57,333 INFO:     Epoch: 92
2023-01-04 09:45:58,892 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47789424657821655, 'Total loss': 0.47789424657821655} | train loss {'Reaction outcome loss': 0.26213746053916454, 'Total loss': 0.26213746053916454}
2023-01-04 09:45:58,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:45:58,892 INFO:     Epoch: 93
2023-01-04 09:46:00,454 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49055324991544086, 'Total loss': 0.49055324991544086} | train loss {'Reaction outcome loss': 0.26215995294092365, 'Total loss': 0.26215995294092365}
2023-01-04 09:46:00,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:00,455 INFO:     Epoch: 94
2023-01-04 09:46:02,014 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44144628445307416, 'Total loss': 0.44144628445307416} | train loss {'Reaction outcome loss': 0.2636205369895761, 'Total loss': 0.2636205369895761}
2023-01-04 09:46:02,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:02,016 INFO:     Epoch: 95
2023-01-04 09:46:03,559 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43628995219866434, 'Total loss': 0.43628995219866434} | train loss {'Reaction outcome loss': 0.26193790424225133, 'Total loss': 0.26193790424225133}
2023-01-04 09:46:03,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:03,560 INFO:     Epoch: 96
2023-01-04 09:46:05,117 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4369987388451894, 'Total loss': 0.4369987388451894} | train loss {'Reaction outcome loss': 0.2616474673232662, 'Total loss': 0.2616474673232662}
2023-01-04 09:46:05,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:05,117 INFO:     Epoch: 97
2023-01-04 09:46:06,648 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45887040297190346, 'Total loss': 0.45887040297190346} | train loss {'Reaction outcome loss': 0.2533981425398524, 'Total loss': 0.2533981425398524}
2023-01-04 09:46:06,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:06,648 INFO:     Epoch: 98
2023-01-04 09:46:08,209 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45956221322218577, 'Total loss': 0.45956221322218577} | train loss {'Reaction outcome loss': 0.2611663277506398, 'Total loss': 0.2611663277506398}
2023-01-04 09:46:08,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:08,210 INFO:     Epoch: 99
2023-01-04 09:46:09,774 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4354933629433314, 'Total loss': 0.4354933629433314} | train loss {'Reaction outcome loss': 0.257009239241965, 'Total loss': 0.257009239241965}
2023-01-04 09:46:09,774 INFO:     Best model found after epoch 75 of 100.
2023-01-04 09:46:09,775 INFO:   Done with stage: TRAINING
2023-01-04 09:46:09,775 INFO:   Starting stage: EVALUATION
2023-01-04 09:46:09,897 INFO:   Done with stage: EVALUATION
2023-01-04 09:46:09,897 INFO:   Leaving out SEQ value Fold_6
2023-01-04 09:46:09,909 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 09:46:09,910 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:46:10,554 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:46:10,554 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:46:10,623 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:46:10,623 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:46:10,623 INFO:     No hyperparam tuning for this model
2023-01-04 09:46:10,623 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:46:10,623 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:46:10,624 INFO:     None feature selector for col prot
2023-01-04 09:46:10,624 INFO:     None feature selector for col prot
2023-01-04 09:46:10,624 INFO:     None feature selector for col prot
2023-01-04 09:46:10,625 INFO:     None feature selector for col chem
2023-01-04 09:46:10,625 INFO:     None feature selector for col chem
2023-01-04 09:46:10,625 INFO:     None feature selector for col chem
2023-01-04 09:46:10,625 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:46:10,625 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:46:10,626 INFO:     Number of params in model 70111
2023-01-04 09:46:10,629 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:46:10,629 INFO:   Starting stage: TRAINING
2023-01-04 09:46:10,671 INFO:     Val loss before train {'Reaction outcome loss': 0.9151159663995106, 'Total loss': 0.9151159663995106}
2023-01-04 09:46:10,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:10,671 INFO:     Epoch: 0
2023-01-04 09:46:12,213 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6986327966054281, 'Total loss': 0.6986327966054281} | train loss {'Reaction outcome loss': 0.8454395355085174, 'Total loss': 0.8454395355085174}
2023-01-04 09:46:12,213 INFO:     Found new best model at epoch 0
2023-01-04 09:46:12,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:12,214 INFO:     Epoch: 1
2023-01-04 09:46:13,766 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5976475814978282, 'Total loss': 0.5976475814978282} | train loss {'Reaction outcome loss': 0.6903196435542743, 'Total loss': 0.6903196435542743}
2023-01-04 09:46:13,766 INFO:     Found new best model at epoch 1
2023-01-04 09:46:13,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:13,767 INFO:     Epoch: 2
2023-01-04 09:46:15,296 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5484389980634053, 'Total loss': 0.5484389980634053} | train loss {'Reaction outcome loss': 0.5950357654679983, 'Total loss': 0.5950357654679983}
2023-01-04 09:46:15,297 INFO:     Found new best model at epoch 2
2023-01-04 09:46:15,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:15,297 INFO:     Epoch: 3
2023-01-04 09:46:16,861 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5226350913445155, 'Total loss': 0.5226350913445155} | train loss {'Reaction outcome loss': 0.5403302494799618, 'Total loss': 0.5403302494799618}
2023-01-04 09:46:16,861 INFO:     Found new best model at epoch 3
2023-01-04 09:46:16,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:16,862 INFO:     Epoch: 4
2023-01-04 09:46:18,441 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5109462320804596, 'Total loss': 0.5109462320804596} | train loss {'Reaction outcome loss': 0.5168792482209981, 'Total loss': 0.5168792482209981}
2023-01-04 09:46:18,441 INFO:     Found new best model at epoch 4
2023-01-04 09:46:18,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:18,442 INFO:     Epoch: 5
2023-01-04 09:46:20,010 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5122890571753184, 'Total loss': 0.5122890571753184} | train loss {'Reaction outcome loss': 0.5010523417366111, 'Total loss': 0.5010523417366111}
2023-01-04 09:46:20,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:20,010 INFO:     Epoch: 6
2023-01-04 09:46:21,554 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5050808171431224, 'Total loss': 0.5050808171431224} | train loss {'Reaction outcome loss': 0.4904048597769617, 'Total loss': 0.4904048597769617}
2023-01-04 09:46:21,555 INFO:     Found new best model at epoch 6
2023-01-04 09:46:21,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:21,556 INFO:     Epoch: 7
2023-01-04 09:46:23,078 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.50802414615949, 'Total loss': 0.50802414615949} | train loss {'Reaction outcome loss': 0.47837928583045297, 'Total loss': 0.47837928583045297}
2023-01-04 09:46:23,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:23,078 INFO:     Epoch: 8
2023-01-04 09:46:24,643 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4998391608397166, 'Total loss': 0.4998391608397166} | train loss {'Reaction outcome loss': 0.47333882539280914, 'Total loss': 0.47333882539280914}
2023-01-04 09:46:24,643 INFO:     Found new best model at epoch 8
2023-01-04 09:46:24,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:24,644 INFO:     Epoch: 9
2023-01-04 09:46:26,204 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4559772253036499, 'Total loss': 0.4559772253036499} | train loss {'Reaction outcome loss': 0.46440501882281116, 'Total loss': 0.46440501882281116}
2023-01-04 09:46:26,204 INFO:     Found new best model at epoch 9
2023-01-04 09:46:26,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:26,205 INFO:     Epoch: 10
2023-01-04 09:46:27,768 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46584518551826476, 'Total loss': 0.46584518551826476} | train loss {'Reaction outcome loss': 0.45566275172500403, 'Total loss': 0.45566275172500403}
2023-01-04 09:46:27,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:27,769 INFO:     Epoch: 11
2023-01-04 09:46:29,283 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.509372212489446, 'Total loss': 0.509372212489446} | train loss {'Reaction outcome loss': 0.4522495685071291, 'Total loss': 0.4522495685071291}
2023-01-04 09:46:29,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:29,283 INFO:     Epoch: 12
2023-01-04 09:46:30,847 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4568033317724864, 'Total loss': 0.4568033317724864} | train loss {'Reaction outcome loss': 0.4486099015181676, 'Total loss': 0.4486099015181676}
2023-01-04 09:46:30,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:30,847 INFO:     Epoch: 13
2023-01-04 09:46:32,380 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4846346298853556, 'Total loss': 0.4846346298853556} | train loss {'Reaction outcome loss': 0.44509496079885574, 'Total loss': 0.44509496079885574}
2023-01-04 09:46:32,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:32,381 INFO:     Epoch: 14
2023-01-04 09:46:33,946 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4472778499126434, 'Total loss': 0.4472778499126434} | train loss {'Reaction outcome loss': 0.4385998051627018, 'Total loss': 0.4385998051627018}
2023-01-04 09:46:33,947 INFO:     Found new best model at epoch 14
2023-01-04 09:46:33,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:33,947 INFO:     Epoch: 15
2023-01-04 09:46:35,525 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45676130553086597, 'Total loss': 0.45676130553086597} | train loss {'Reaction outcome loss': 0.4335997224607192, 'Total loss': 0.4335997224607192}
2023-01-04 09:46:35,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:35,525 INFO:     Epoch: 16
2023-01-04 09:46:37,101 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.460887810587883, 'Total loss': 0.460887810587883} | train loss {'Reaction outcome loss': 0.4298003333139936, 'Total loss': 0.4298003333139936}
2023-01-04 09:46:37,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:37,101 INFO:     Epoch: 17
2023-01-04 09:46:38,648 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.460409610470136, 'Total loss': 0.460409610470136} | train loss {'Reaction outcome loss': 0.4223947776246157, 'Total loss': 0.4223947776246157}
2023-01-04 09:46:38,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:38,649 INFO:     Epoch: 18
2023-01-04 09:46:40,219 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4731992880503337, 'Total loss': 0.4731992880503337} | train loss {'Reaction outcome loss': 0.42242112621288436, 'Total loss': 0.42242112621288436}
2023-01-04 09:46:40,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:40,220 INFO:     Epoch: 19
2023-01-04 09:46:41,752 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.452510533730189, 'Total loss': 0.452510533730189} | train loss {'Reaction outcome loss': 0.4225228865116512, 'Total loss': 0.4225228865116512}
2023-01-04 09:46:41,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:41,752 INFO:     Epoch: 20
2023-01-04 09:46:43,324 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4293123155832291, 'Total loss': 0.4293123155832291} | train loss {'Reaction outcome loss': 0.4118395691959436, 'Total loss': 0.4118395691959436}
2023-01-04 09:46:43,324 INFO:     Found new best model at epoch 20
2023-01-04 09:46:43,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:43,325 INFO:     Epoch: 21
2023-01-04 09:46:44,904 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.438935257991155, 'Total loss': 0.438935257991155} | train loss {'Reaction outcome loss': 0.4090119808481919, 'Total loss': 0.4090119808481919}
2023-01-04 09:46:44,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:44,904 INFO:     Epoch: 22
2023-01-04 09:46:46,477 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4480944176514943, 'Total loss': 0.4480944176514943} | train loss {'Reaction outcome loss': 0.4076007284788879, 'Total loss': 0.4076007284788879}
2023-01-04 09:46:46,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:46,477 INFO:     Epoch: 23
2023-01-04 09:46:48,030 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4392143994569778, 'Total loss': 0.4392143994569778} | train loss {'Reaction outcome loss': 0.4029535675414633, 'Total loss': 0.4029535675414633}
2023-01-04 09:46:48,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:48,031 INFO:     Epoch: 24
2023-01-04 09:46:49,659 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42742155989011127, 'Total loss': 0.42742155989011127} | train loss {'Reaction outcome loss': 0.39782816023710404, 'Total loss': 0.39782816023710404}
2023-01-04 09:46:49,659 INFO:     Found new best model at epoch 24
2023-01-04 09:46:49,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:49,660 INFO:     Epoch: 25
2023-01-04 09:46:51,226 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41587507327397666, 'Total loss': 0.41587507327397666} | train loss {'Reaction outcome loss': 0.39686556440182974, 'Total loss': 0.39686556440182974}
2023-01-04 09:46:51,226 INFO:     Found new best model at epoch 25
2023-01-04 09:46:51,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:51,227 INFO:     Epoch: 26
2023-01-04 09:46:52,788 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4326829671859741, 'Total loss': 0.4326829671859741} | train loss {'Reaction outcome loss': 0.3872410333866677, 'Total loss': 0.3872410333866677}
2023-01-04 09:46:52,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:52,789 INFO:     Epoch: 27
2023-01-04 09:46:54,373 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45209934314092, 'Total loss': 0.45209934314092} | train loss {'Reaction outcome loss': 0.384258073051914, 'Total loss': 0.384258073051914}
2023-01-04 09:46:54,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:54,374 INFO:     Epoch: 28
2023-01-04 09:46:55,937 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41902843217055, 'Total loss': 0.41902843217055} | train loss {'Reaction outcome loss': 0.3823986771089506, 'Total loss': 0.3823986771089506}
2023-01-04 09:46:55,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:55,937 INFO:     Epoch: 29
2023-01-04 09:46:57,457 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45244208971659344, 'Total loss': 0.45244208971659344} | train loss {'Reaction outcome loss': 0.3789079915799389, 'Total loss': 0.3789079915799389}
2023-01-04 09:46:57,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:57,458 INFO:     Epoch: 30
2023-01-04 09:46:59,023 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41243322839339575, 'Total loss': 0.41243322839339575} | train loss {'Reaction outcome loss': 0.37764486237445893, 'Total loss': 0.37764486237445893}
2023-01-04 09:46:59,024 INFO:     Found new best model at epoch 30
2023-01-04 09:46:59,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:46:59,024 INFO:     Epoch: 31
2023-01-04 09:47:00,557 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4128926793734233, 'Total loss': 0.4128926793734233} | train loss {'Reaction outcome loss': 0.3738589043382703, 'Total loss': 0.3738589043382703}
2023-01-04 09:47:00,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:00,557 INFO:     Epoch: 32
2023-01-04 09:47:02,106 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4232241213321686, 'Total loss': 0.4232241213321686} | train loss {'Reaction outcome loss': 0.3694324771796323, 'Total loss': 0.3694324771796323}
2023-01-04 09:47:02,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:02,107 INFO:     Epoch: 33
2023-01-04 09:47:03,657 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42006972630818684, 'Total loss': 0.42006972630818684} | train loss {'Reaction outcome loss': 0.3682404368954445, 'Total loss': 0.3682404368954445}
2023-01-04 09:47:03,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:03,657 INFO:     Epoch: 34
2023-01-04 09:47:05,215 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4317042241493861, 'Total loss': 0.4317042241493861} | train loss {'Reaction outcome loss': 0.3653064143141254, 'Total loss': 0.3653064143141254}
2023-01-04 09:47:05,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:05,216 INFO:     Epoch: 35
2023-01-04 09:47:06,732 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40758026639620465, 'Total loss': 0.40758026639620465} | train loss {'Reaction outcome loss': 0.36252178294779164, 'Total loss': 0.36252178294779164}
2023-01-04 09:47:06,732 INFO:     Found new best model at epoch 35
2023-01-04 09:47:06,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:06,732 INFO:     Epoch: 36
2023-01-04 09:47:08,285 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4327049046754837, 'Total loss': 0.4327049046754837} | train loss {'Reaction outcome loss': 0.3588674530279335, 'Total loss': 0.3588674530279335}
2023-01-04 09:47:08,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:08,285 INFO:     Epoch: 37
2023-01-04 09:47:09,820 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4031946261723836, 'Total loss': 0.4031946261723836} | train loss {'Reaction outcome loss': 0.3532922473947924, 'Total loss': 0.3532922473947924}
2023-01-04 09:47:09,821 INFO:     Found new best model at epoch 37
2023-01-04 09:47:09,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:09,822 INFO:     Epoch: 38
2023-01-04 09:47:11,369 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40433359940846764, 'Total loss': 0.40433359940846764} | train loss {'Reaction outcome loss': 0.3548792830335534, 'Total loss': 0.3548792830335534}
2023-01-04 09:47:11,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:11,369 INFO:     Epoch: 39
2023-01-04 09:47:12,931 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42208903829256694, 'Total loss': 0.42208903829256694} | train loss {'Reaction outcome loss': 0.3474987568300123, 'Total loss': 0.3474987568300123}
2023-01-04 09:47:12,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:12,931 INFO:     Epoch: 40
2023-01-04 09:47:14,482 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40910231272379555, 'Total loss': 0.40910231272379555} | train loss {'Reaction outcome loss': 0.3448405149611325, 'Total loss': 0.3448405149611325}
2023-01-04 09:47:14,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:14,483 INFO:     Epoch: 41
2023-01-04 09:47:16,008 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3963568866252899, 'Total loss': 0.3963568866252899} | train loss {'Reaction outcome loss': 0.34430738694508584, 'Total loss': 0.34430738694508584}
2023-01-04 09:47:16,009 INFO:     Found new best model at epoch 41
2023-01-04 09:47:16,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:16,010 INFO:     Epoch: 42
2023-01-04 09:47:17,533 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39931355118751527, 'Total loss': 0.39931355118751527} | train loss {'Reaction outcome loss': 0.34097272889278424, 'Total loss': 0.34097272889278424}
2023-01-04 09:47:17,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:17,533 INFO:     Epoch: 43
2023-01-04 09:47:19,087 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40343679587046305, 'Total loss': 0.40343679587046305} | train loss {'Reaction outcome loss': 0.34226641526936624, 'Total loss': 0.34226641526936624}
2023-01-04 09:47:19,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:19,088 INFO:     Epoch: 44
2023-01-04 09:47:20,653 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3923661480347315, 'Total loss': 0.3923661480347315} | train loss {'Reaction outcome loss': 0.335791836200208, 'Total loss': 0.335791836200208}
2023-01-04 09:47:20,653 INFO:     Found new best model at epoch 44
2023-01-04 09:47:20,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:20,654 INFO:     Epoch: 45
2023-01-04 09:47:22,200 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.416483137011528, 'Total loss': 0.416483137011528} | train loss {'Reaction outcome loss': 0.3329805518207998, 'Total loss': 0.3329805518207998}
2023-01-04 09:47:22,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:22,200 INFO:     Epoch: 46
2023-01-04 09:47:23,736 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3770904342333476, 'Total loss': 0.3770904342333476} | train loss {'Reaction outcome loss': 0.3291796021674514, 'Total loss': 0.3291796021674514}
2023-01-04 09:47:23,736 INFO:     Found new best model at epoch 46
2023-01-04 09:47:23,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:23,737 INFO:     Epoch: 47
2023-01-04 09:47:25,274 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42270488540331524, 'Total loss': 0.42270488540331524} | train loss {'Reaction outcome loss': 0.32444733596450587, 'Total loss': 0.32444733596450587}
2023-01-04 09:47:25,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:25,274 INFO:     Epoch: 48
2023-01-04 09:47:26,793 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39789412717024486, 'Total loss': 0.39789412717024486} | train loss {'Reaction outcome loss': 0.32477519384144876, 'Total loss': 0.32477519384144876}
2023-01-04 09:47:26,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:26,793 INFO:     Epoch: 49
2023-01-04 09:47:28,348 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39473125636577605, 'Total loss': 0.39473125636577605} | train loss {'Reaction outcome loss': 0.3247953040074786, 'Total loss': 0.3247953040074786}
2023-01-04 09:47:28,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:28,348 INFO:     Epoch: 50
2023-01-04 09:47:29,913 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39352794190247853, 'Total loss': 0.39352794190247853} | train loss {'Reaction outcome loss': 0.3229119896565964, 'Total loss': 0.3229119896565964}
2023-01-04 09:47:29,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:29,913 INFO:     Epoch: 51
2023-01-04 09:47:31,458 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4160715957482656, 'Total loss': 0.4160715957482656} | train loss {'Reaction outcome loss': 0.31744347144227597, 'Total loss': 0.31744347144227597}
2023-01-04 09:47:31,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:31,458 INFO:     Epoch: 52
2023-01-04 09:47:32,974 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41552457710107166, 'Total loss': 0.41552457710107166} | train loss {'Reaction outcome loss': 0.3163715352166431, 'Total loss': 0.3163715352166431}
2023-01-04 09:47:32,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:32,974 INFO:     Epoch: 53
2023-01-04 09:47:34,517 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.419235231479009, 'Total loss': 0.419235231479009} | train loss {'Reaction outcome loss': 0.31412875283818814, 'Total loss': 0.31412875283818814}
2023-01-04 09:47:34,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:34,517 INFO:     Epoch: 54
2023-01-04 09:47:36,043 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42174632251262667, 'Total loss': 0.42174632251262667} | train loss {'Reaction outcome loss': 0.31375257006513513, 'Total loss': 0.31375257006513513}
2023-01-04 09:47:36,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:36,044 INFO:     Epoch: 55
2023-01-04 09:47:37,613 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4057857165733973, 'Total loss': 0.4057857165733973} | train loss {'Reaction outcome loss': 0.31588990652819404, 'Total loss': 0.31588990652819404}
2023-01-04 09:47:37,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:37,613 INFO:     Epoch: 56
2023-01-04 09:47:39,182 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39724389612674715, 'Total loss': 0.39724389612674715} | train loss {'Reaction outcome loss': 0.3042351205157459, 'Total loss': 0.3042351205157459}
2023-01-04 09:47:39,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:39,182 INFO:     Epoch: 57
2023-01-04 09:47:40,763 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39614481925964357, 'Total loss': 0.39614481925964357} | train loss {'Reaction outcome loss': 0.30653722011332907, 'Total loss': 0.30653722011332907}
2023-01-04 09:47:40,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:40,764 INFO:     Epoch: 58
2023-01-04 09:47:42,299 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3991048276424408, 'Total loss': 0.3991048276424408} | train loss {'Reaction outcome loss': 0.30727733666958146, 'Total loss': 0.30727733666958146}
2023-01-04 09:47:42,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:42,299 INFO:     Epoch: 59
2023-01-04 09:47:43,856 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39560546875, 'Total loss': 0.39560546875} | train loss {'Reaction outcome loss': 0.30415492843742403, 'Total loss': 0.30415492843742403}
2023-01-04 09:47:43,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:43,857 INFO:     Epoch: 60
2023-01-04 09:47:45,383 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4012938419977824, 'Total loss': 0.4012938419977824} | train loss {'Reaction outcome loss': 0.3056397898532854, 'Total loss': 0.3056397898532854}
2023-01-04 09:47:45,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:45,384 INFO:     Epoch: 61
2023-01-04 09:47:46,935 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3839824686447779, 'Total loss': 0.3839824686447779} | train loss {'Reaction outcome loss': 0.29560361183937706, 'Total loss': 0.29560361183937706}
2023-01-04 09:47:46,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:46,935 INFO:     Epoch: 62
2023-01-04 09:47:48,490 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4212131381034851, 'Total loss': 0.4212131381034851} | train loss {'Reaction outcome loss': 0.30125007692334455, 'Total loss': 0.30125007692334455}
2023-01-04 09:47:48,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:48,490 INFO:     Epoch: 63
2023-01-04 09:47:50,041 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4168516914049784, 'Total loss': 0.4168516914049784} | train loss {'Reaction outcome loss': 0.3007925803292314, 'Total loss': 0.3007925803292314}
2023-01-04 09:47:50,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:50,041 INFO:     Epoch: 64
2023-01-04 09:47:51,554 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3961809933185577, 'Total loss': 0.3961809933185577} | train loss {'Reaction outcome loss': 0.29850283948307865, 'Total loss': 0.29850283948307865}
2023-01-04 09:47:51,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:51,555 INFO:     Epoch: 65
2023-01-04 09:47:53,107 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39334522783756254, 'Total loss': 0.39334522783756254} | train loss {'Reaction outcome loss': 0.29390096700740204, 'Total loss': 0.29390096700740204}
2023-01-04 09:47:53,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:53,107 INFO:     Epoch: 66
2023-01-04 09:47:54,625 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4206689258416494, 'Total loss': 0.4206689258416494} | train loss {'Reaction outcome loss': 0.2936969145271752, 'Total loss': 0.2936969145271752}
2023-01-04 09:47:54,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:54,625 INFO:     Epoch: 67
2023-01-04 09:47:56,171 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38615455428759254, 'Total loss': 0.38615455428759254} | train loss {'Reaction outcome loss': 0.29436674671052593, 'Total loss': 0.29436674671052593}
2023-01-04 09:47:56,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:56,171 INFO:     Epoch: 68
2023-01-04 09:47:57,722 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3852131485939026, 'Total loss': 0.3852131485939026} | train loss {'Reaction outcome loss': 0.29148793718121974, 'Total loss': 0.29148793718121974}
2023-01-04 09:47:57,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:57,722 INFO:     Epoch: 69
2023-01-04 09:47:59,296 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3820603003104528, 'Total loss': 0.3820603003104528} | train loss {'Reaction outcome loss': 0.2899262207536706, 'Total loss': 0.2899262207536706}
2023-01-04 09:47:59,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:47:59,296 INFO:     Epoch: 70
2023-01-04 09:48:00,809 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39798553188641866, 'Total loss': 0.39798553188641866} | train loss {'Reaction outcome loss': 0.2891958258938488, 'Total loss': 0.2891958258938488}
2023-01-04 09:48:00,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:00,809 INFO:     Epoch: 71
2023-01-04 09:48:02,366 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3931646138429642, 'Total loss': 0.3931646138429642} | train loss {'Reaction outcome loss': 0.28710428899698737, 'Total loss': 0.28710428899698737}
2023-01-04 09:48:02,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:02,367 INFO:     Epoch: 72
2023-01-04 09:48:03,893 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.383993598818779, 'Total loss': 0.383993598818779} | train loss {'Reaction outcome loss': 0.2837907965110097, 'Total loss': 0.2837907965110097}
2023-01-04 09:48:03,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:03,894 INFO:     Epoch: 73
2023-01-04 09:48:05,474 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41119699080785116, 'Total loss': 0.41119699080785116} | train loss {'Reaction outcome loss': 0.28345074195293746, 'Total loss': 0.28345074195293746}
2023-01-04 09:48:05,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:05,474 INFO:     Epoch: 74
2023-01-04 09:48:07,028 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4008451918760935, 'Total loss': 0.4008451918760935} | train loss {'Reaction outcome loss': 0.2881905799361773, 'Total loss': 0.2881905799361773}
2023-01-04 09:48:07,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:07,028 INFO:     Epoch: 75
2023-01-04 09:48:08,585 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4017545521259308, 'Total loss': 0.4017545521259308} | train loss {'Reaction outcome loss': 0.28319483196584755, 'Total loss': 0.28319483196584755}
2023-01-04 09:48:08,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:08,586 INFO:     Epoch: 76
2023-01-04 09:48:10,110 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38127535581588745, 'Total loss': 0.38127535581588745} | train loss {'Reaction outcome loss': 0.28457949340128297, 'Total loss': 0.28457949340128297}
2023-01-04 09:48:10,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:10,110 INFO:     Epoch: 77
2023-01-04 09:48:11,653 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37746594846248627, 'Total loss': 0.37746594846248627} | train loss {'Reaction outcome loss': 0.2786751120798424, 'Total loss': 0.2786751120798424}
2023-01-04 09:48:11,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:11,653 INFO:     Epoch: 78
2023-01-04 09:48:13,172 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38784574866294863, 'Total loss': 0.38784574866294863} | train loss {'Reaction outcome loss': 0.28106080029253927, 'Total loss': 0.28106080029253927}
2023-01-04 09:48:13,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:13,172 INFO:     Epoch: 79
2023-01-04 09:48:14,730 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39664481033881505, 'Total loss': 0.39664481033881505} | train loss {'Reaction outcome loss': 0.27877701749009776, 'Total loss': 0.27877701749009776}
2023-01-04 09:48:14,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:14,730 INFO:     Epoch: 80
2023-01-04 09:48:16,320 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3725999062259992, 'Total loss': 0.3725999062259992} | train loss {'Reaction outcome loss': 0.2781210275978818, 'Total loss': 0.2781210275978818}
2023-01-04 09:48:16,320 INFO:     Found new best model at epoch 80
2023-01-04 09:48:16,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:16,321 INFO:     Epoch: 81
2023-01-04 09:48:17,933 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37820537288983663, 'Total loss': 0.37820537288983663} | train loss {'Reaction outcome loss': 0.2746176470326603, 'Total loss': 0.2746176470326603}
2023-01-04 09:48:17,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:17,934 INFO:     Epoch: 82
2023-01-04 09:48:19,467 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38810882568359373, 'Total loss': 0.38810882568359373} | train loss {'Reaction outcome loss': 0.2773831059167747, 'Total loss': 0.2773831059167747}
2023-01-04 09:48:19,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:19,468 INFO:     Epoch: 83
2023-01-04 09:48:21,055 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3986954460541407, 'Total loss': 0.3986954460541407} | train loss {'Reaction outcome loss': 0.27227526499691423, 'Total loss': 0.27227526499691423}
2023-01-04 09:48:21,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:21,057 INFO:     Epoch: 84
2023-01-04 09:48:22,679 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38516584237416585, 'Total loss': 0.38516584237416585} | train loss {'Reaction outcome loss': 0.2767669498812851, 'Total loss': 0.2767669498812851}
2023-01-04 09:48:22,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:22,679 INFO:     Epoch: 85
2023-01-04 09:48:24,305 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37529035806655886, 'Total loss': 0.37529035806655886} | train loss {'Reaction outcome loss': 0.27172903506764434, 'Total loss': 0.27172903506764434}
2023-01-04 09:48:24,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:24,305 INFO:     Epoch: 86
2023-01-04 09:48:25,914 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3986357813080152, 'Total loss': 0.3986357813080152} | train loss {'Reaction outcome loss': 0.2717453862678273, 'Total loss': 0.2717453862678273}
2023-01-04 09:48:25,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:25,914 INFO:     Epoch: 87
2023-01-04 09:48:27,485 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40285972555478416, 'Total loss': 0.40285972555478416} | train loss {'Reaction outcome loss': 0.2621633317523269, 'Total loss': 0.2621633317523269}
2023-01-04 09:48:27,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:27,486 INFO:     Epoch: 88
2023-01-04 09:48:29,081 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3927696992953618, 'Total loss': 0.3927696992953618} | train loss {'Reaction outcome loss': 0.2716536215012254, 'Total loss': 0.2716536215012254}
2023-01-04 09:48:29,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:29,081 INFO:     Epoch: 89
2023-01-04 09:48:30,653 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43232168157895406, 'Total loss': 0.43232168157895406} | train loss {'Reaction outcome loss': 0.2672248705952606, 'Total loss': 0.2672248705952606}
2023-01-04 09:48:30,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:30,653 INFO:     Epoch: 90
2023-01-04 09:48:32,267 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3968418190876643, 'Total loss': 0.3968418190876643} | train loss {'Reaction outcome loss': 0.2682764983941071, 'Total loss': 0.2682764983941071}
2023-01-04 09:48:32,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:32,267 INFO:     Epoch: 91
2023-01-04 09:48:33,868 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39640886783599855, 'Total loss': 0.39640886783599855} | train loss {'Reaction outcome loss': 0.2623759505712168, 'Total loss': 0.2623759505712168}
2023-01-04 09:48:33,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:33,868 INFO:     Epoch: 92
2023-01-04 09:48:35,452 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39783308108647664, 'Total loss': 0.39783308108647664} | train loss {'Reaction outcome loss': 0.2649116460435657, 'Total loss': 0.2649116460435657}
2023-01-04 09:48:35,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:35,452 INFO:     Epoch: 93
2023-01-04 09:48:36,967 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39910654425621034, 'Total loss': 0.39910654425621034} | train loss {'Reaction outcome loss': 0.2632660366567894, 'Total loss': 0.2632660366567894}
2023-01-04 09:48:36,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:36,967 INFO:     Epoch: 94
2023-01-04 09:48:38,514 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4089685042699178, 'Total loss': 0.4089685042699178} | train loss {'Reaction outcome loss': 0.26104962426348716, 'Total loss': 0.26104962426348716}
2023-01-04 09:48:38,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:38,515 INFO:     Epoch: 95
2023-01-04 09:48:40,037 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3805572400490443, 'Total loss': 0.3805572400490443} | train loss {'Reaction outcome loss': 0.2628450208622626, 'Total loss': 0.2628450208622626}
2023-01-04 09:48:40,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:40,038 INFO:     Epoch: 96
2023-01-04 09:48:41,588 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.400468244155248, 'Total loss': 0.400468244155248} | train loss {'Reaction outcome loss': 0.2626470557350114, 'Total loss': 0.2626470557350114}
2023-01-04 09:48:41,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:41,588 INFO:     Epoch: 97
2023-01-04 09:48:43,157 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3993661383787791, 'Total loss': 0.3993661383787791} | train loss {'Reaction outcome loss': 0.26004618790928635, 'Total loss': 0.26004618790928635}
2023-01-04 09:48:43,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:43,157 INFO:     Epoch: 98
2023-01-04 09:48:44,719 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3895552804072698, 'Total loss': 0.3895552804072698} | train loss {'Reaction outcome loss': 0.2583902538602748, 'Total loss': 0.2583902538602748}
2023-01-04 09:48:44,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:44,719 INFO:     Epoch: 99
2023-01-04 09:48:46,242 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38358880480130514, 'Total loss': 0.38358880480130514} | train loss {'Reaction outcome loss': 0.25629720195374767, 'Total loss': 0.25629720195374767}
2023-01-04 09:48:46,242 INFO:     Best model found after epoch 81 of 100.
2023-01-04 09:48:46,242 INFO:   Done with stage: TRAINING
2023-01-04 09:48:46,242 INFO:   Starting stage: EVALUATION
2023-01-04 09:48:46,365 INFO:   Done with stage: EVALUATION
2023-01-04 09:48:46,365 INFO:   Leaving out SEQ value Fold_7
2023-01-04 09:48:46,377 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:48:46,377 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:48:47,020 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:48:47,021 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:48:47,088 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:48:47,088 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:48:47,088 INFO:     No hyperparam tuning for this model
2023-01-04 09:48:47,089 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:48:47,089 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:48:47,089 INFO:     None feature selector for col prot
2023-01-04 09:48:47,089 INFO:     None feature selector for col prot
2023-01-04 09:48:47,090 INFO:     None feature selector for col prot
2023-01-04 09:48:47,090 INFO:     None feature selector for col chem
2023-01-04 09:48:47,090 INFO:     None feature selector for col chem
2023-01-04 09:48:47,090 INFO:     None feature selector for col chem
2023-01-04 09:48:47,090 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:48:47,090 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:48:47,091 INFO:     Number of params in model 70111
2023-01-04 09:48:47,095 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:48:47,095 INFO:   Starting stage: TRAINING
2023-01-04 09:48:47,137 INFO:     Val loss before train {'Reaction outcome loss': 1.1559360067049662, 'Total loss': 1.1559360067049662}
2023-01-04 09:48:47,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:47,137 INFO:     Epoch: 0
2023-01-04 09:48:48,671 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8693817019462585, 'Total loss': 0.8693817019462585} | train loss {'Reaction outcome loss': 0.8361613474469092, 'Total loss': 0.8361613474469092}
2023-01-04 09:48:48,671 INFO:     Found new best model at epoch 0
2023-01-04 09:48:48,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:48,672 INFO:     Epoch: 1
2023-01-04 09:48:50,225 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7490267276763916, 'Total loss': 0.7490267276763916} | train loss {'Reaction outcome loss': 0.6930457956117132, 'Total loss': 0.6930457956117132}
2023-01-04 09:48:50,225 INFO:     Found new best model at epoch 1
2023-01-04 09:48:50,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:50,226 INFO:     Epoch: 2
2023-01-04 09:48:51,780 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6623381018638611, 'Total loss': 0.6623381018638611} | train loss {'Reaction outcome loss': 0.6289736114550328, 'Total loss': 0.6289736114550328}
2023-01-04 09:48:51,780 INFO:     Found new best model at epoch 2
2023-01-04 09:48:51,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:51,781 INFO:     Epoch: 3
2023-01-04 09:48:53,320 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5937700907389323, 'Total loss': 0.5937700907389323} | train loss {'Reaction outcome loss': 0.5709682677238099, 'Total loss': 0.5709682677238099}
2023-01-04 09:48:53,320 INFO:     Found new best model at epoch 3
2023-01-04 09:48:53,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:53,321 INFO:     Epoch: 4
2023-01-04 09:48:54,823 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5806777715682984, 'Total loss': 0.5806777715682984} | train loss {'Reaction outcome loss': 0.538579415206028, 'Total loss': 0.538579415206028}
2023-01-04 09:48:54,823 INFO:     Found new best model at epoch 4
2023-01-04 09:48:54,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:54,824 INFO:     Epoch: 5
2023-01-04 09:48:56,373 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.577696168422699, 'Total loss': 0.577696168422699} | train loss {'Reaction outcome loss': 0.5266248514180653, 'Total loss': 0.5266248514180653}
2023-01-04 09:48:56,374 INFO:     Found new best model at epoch 5
2023-01-04 09:48:56,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:56,375 INFO:     Epoch: 6
2023-01-04 09:48:57,885 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5457645843426386, 'Total loss': 0.5457645843426386} | train loss {'Reaction outcome loss': 0.5082979998940085, 'Total loss': 0.5082979998940085}
2023-01-04 09:48:57,885 INFO:     Found new best model at epoch 6
2023-01-04 09:48:57,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:57,886 INFO:     Epoch: 7
2023-01-04 09:48:59,430 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5310545901457469, 'Total loss': 0.5310545901457469} | train loss {'Reaction outcome loss': 0.49678956697892357, 'Total loss': 0.49678956697892357}
2023-01-04 09:48:59,430 INFO:     Found new best model at epoch 7
2023-01-04 09:48:59,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:48:59,431 INFO:     Epoch: 8
2023-01-04 09:49:00,976 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5418000181516012, 'Total loss': 0.5418000181516012} | train loss {'Reaction outcome loss': 0.4884192278504075, 'Total loss': 0.4884192278504075}
2023-01-04 09:49:00,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:00,977 INFO:     Epoch: 9
2023-01-04 09:49:02,526 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.570084540049235, 'Total loss': 0.570084540049235} | train loss {'Reaction outcome loss': 0.4819959233096544, 'Total loss': 0.4819959233096544}
2023-01-04 09:49:02,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:02,527 INFO:     Epoch: 10
2023-01-04 09:49:04,045 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5344834993282954, 'Total loss': 0.5344834993282954} | train loss {'Reaction outcome loss': 0.47422735294516105, 'Total loss': 0.47422735294516105}
2023-01-04 09:49:04,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:04,045 INFO:     Epoch: 11
2023-01-04 09:49:05,623 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5176840086778005, 'Total loss': 0.5176840086778005} | train loss {'Reaction outcome loss': 0.4669155013086139, 'Total loss': 0.4669155013086139}
2023-01-04 09:49:05,623 INFO:     Found new best model at epoch 11
2023-01-04 09:49:05,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:05,623 INFO:     Epoch: 12
2023-01-04 09:49:07,199 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5276038428147634, 'Total loss': 0.5276038428147634} | train loss {'Reaction outcome loss': 0.463992521927719, 'Total loss': 0.463992521927719}
2023-01-04 09:49:07,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:07,199 INFO:     Epoch: 13
2023-01-04 09:49:08,807 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.540348219871521, 'Total loss': 0.540348219871521} | train loss {'Reaction outcome loss': 0.46361929928694945, 'Total loss': 0.46361929928694945}
2023-01-04 09:49:08,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:08,807 INFO:     Epoch: 14
2023-01-04 09:49:10,420 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5261231561501821, 'Total loss': 0.5261231561501821} | train loss {'Reaction outcome loss': 0.4697921269883712, 'Total loss': 0.4697921269883712}
2023-01-04 09:49:10,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:10,421 INFO:     Epoch: 15
2023-01-04 09:49:12,032 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5136900087197621, 'Total loss': 0.5136900087197621} | train loss {'Reaction outcome loss': 0.4501660176228261, 'Total loss': 0.4501660176228261}
2023-01-04 09:49:12,032 INFO:     Found new best model at epoch 15
2023-01-04 09:49:12,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:12,033 INFO:     Epoch: 16
2023-01-04 09:49:13,595 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5003159036238988, 'Total loss': 0.5003159036238988} | train loss {'Reaction outcome loss': 0.44727484045037325, 'Total loss': 0.44727484045037325}
2023-01-04 09:49:13,595 INFO:     Found new best model at epoch 16
2023-01-04 09:49:13,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:13,596 INFO:     Epoch: 17
2023-01-04 09:49:15,198 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4962376733620962, 'Total loss': 0.4962376733620962} | train loss {'Reaction outcome loss': 0.43727321063854924, 'Total loss': 0.43727321063854924}
2023-01-04 09:49:15,198 INFO:     Found new best model at epoch 17
2023-01-04 09:49:15,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:15,199 INFO:     Epoch: 18
2023-01-04 09:49:16,804 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5087611198425293, 'Total loss': 0.5087611198425293} | train loss {'Reaction outcome loss': 0.4385221878039664, 'Total loss': 0.4385221878039664}
2023-01-04 09:49:16,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:16,804 INFO:     Epoch: 19
2023-01-04 09:49:18,398 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5114941974480947, 'Total loss': 0.5114941974480947} | train loss {'Reaction outcome loss': 0.4417159758724164, 'Total loss': 0.4417159758724164}
2023-01-04 09:49:18,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:18,398 INFO:     Epoch: 20
2023-01-04 09:49:20,021 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4803011914094289, 'Total loss': 0.4803011914094289} | train loss {'Reaction outcome loss': 0.4465435557607291, 'Total loss': 0.4465435557607291}
2023-01-04 09:49:20,021 INFO:     Found new best model at epoch 20
2023-01-04 09:49:20,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:20,022 INFO:     Epoch: 21
2023-01-04 09:49:21,600 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49092097679773966, 'Total loss': 0.49092097679773966} | train loss {'Reaction outcome loss': 0.44241848102672887, 'Total loss': 0.44241848102672887}
2023-01-04 09:49:21,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:21,600 INFO:     Epoch: 22
2023-01-04 09:49:23,209 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5178150395552318, 'Total loss': 0.5178150395552318} | train loss {'Reaction outcome loss': 0.4250136009614271, 'Total loss': 0.4250136009614271}
2023-01-04 09:49:23,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:23,209 INFO:     Epoch: 23
2023-01-04 09:49:24,791 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4868660847345988, 'Total loss': 0.4868660847345988} | train loss {'Reaction outcome loss': 0.42412543267119623, 'Total loss': 0.42412543267119623}
2023-01-04 09:49:24,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:24,792 INFO:     Epoch: 24
2023-01-04 09:49:26,402 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49886784752209984, 'Total loss': 0.49886784752209984} | train loss {'Reaction outcome loss': 0.4289247936879595, 'Total loss': 0.4289247936879595}
2023-01-04 09:49:26,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:26,402 INFO:     Epoch: 25
2023-01-04 09:49:28,017 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49813593327999117, 'Total loss': 0.49813593327999117} | train loss {'Reaction outcome loss': 0.42403246516334836, 'Total loss': 0.42403246516334836}
2023-01-04 09:49:28,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:28,018 INFO:     Epoch: 26
2023-01-04 09:49:29,637 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49116860230763754, 'Total loss': 0.49116860230763754} | train loss {'Reaction outcome loss': 0.42387659459685284, 'Total loss': 0.42387659459685284}
2023-01-04 09:49:29,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:29,637 INFO:     Epoch: 27
2023-01-04 09:49:31,204 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4920499821503957, 'Total loss': 0.4920499821503957} | train loss {'Reaction outcome loss': 0.4097055391395006, 'Total loss': 0.4097055391395006}
2023-01-04 09:49:31,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:31,204 INFO:     Epoch: 28
2023-01-04 09:49:32,819 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46750357151031496, 'Total loss': 0.46750357151031496} | train loss {'Reaction outcome loss': 0.40190180431565514, 'Total loss': 0.40190180431565514}
2023-01-04 09:49:32,819 INFO:     Found new best model at epoch 28
2023-01-04 09:49:32,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:32,820 INFO:     Epoch: 29
2023-01-04 09:49:34,393 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4856006691853205, 'Total loss': 0.4856006691853205} | train loss {'Reaction outcome loss': 0.401088533045697, 'Total loss': 0.401088533045697}
2023-01-04 09:49:34,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:34,394 INFO:     Epoch: 30
2023-01-04 09:49:36,022 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4745020945866903, 'Total loss': 0.4745020945866903} | train loss {'Reaction outcome loss': 0.3994327354973749, 'Total loss': 0.3994327354973749}
2023-01-04 09:49:36,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:36,022 INFO:     Epoch: 31
2023-01-04 09:49:37,616 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47437629103660583, 'Total loss': 0.47437629103660583} | train loss {'Reaction outcome loss': 0.3934639891326103, 'Total loss': 0.3934639891326103}
2023-01-04 09:49:37,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:37,616 INFO:     Epoch: 32
2023-01-04 09:49:39,232 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47621123790740966, 'Total loss': 0.47621123790740966} | train loss {'Reaction outcome loss': 0.4083871146583039, 'Total loss': 0.4083871146583039}
2023-01-04 09:49:39,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:39,232 INFO:     Epoch: 33
2023-01-04 09:49:40,800 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5143227577209473, 'Total loss': 0.5143227577209473} | train loss {'Reaction outcome loss': 0.4368907145993865, 'Total loss': 0.4368907145993865}
2023-01-04 09:49:40,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:40,801 INFO:     Epoch: 34
2023-01-04 09:49:42,390 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48175393243630726, 'Total loss': 0.48175393243630726} | train loss {'Reaction outcome loss': 0.40068521996221057, 'Total loss': 0.40068521996221057}
2023-01-04 09:49:42,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:42,390 INFO:     Epoch: 35
2023-01-04 09:49:43,973 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4803488035996755, 'Total loss': 0.4803488035996755} | train loss {'Reaction outcome loss': 0.393201939859495, 'Total loss': 0.393201939859495}
2023-01-04 09:49:43,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:43,973 INFO:     Epoch: 36
2023-01-04 09:49:45,592 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.498568469285965, 'Total loss': 0.498568469285965} | train loss {'Reaction outcome loss': 0.3840897490904815, 'Total loss': 0.3840897490904815}
2023-01-04 09:49:45,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:45,592 INFO:     Epoch: 37
2023-01-04 09:49:47,209 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47758497794469196, 'Total loss': 0.47758497794469196} | train loss {'Reaction outcome loss': 0.3762225234637246, 'Total loss': 0.3762225234637246}
2023-01-04 09:49:47,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:47,210 INFO:     Epoch: 38
2023-01-04 09:49:48,821 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47838447590669, 'Total loss': 0.47838447590669} | train loss {'Reaction outcome loss': 0.37315319126735075, 'Total loss': 0.37315319126735075}
2023-01-04 09:49:48,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:48,822 INFO:     Epoch: 39
2023-01-04 09:49:50,391 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48426422476768494, 'Total loss': 0.48426422476768494} | train loss {'Reaction outcome loss': 0.3734775945658971, 'Total loss': 0.3734775945658971}
2023-01-04 09:49:50,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:50,391 INFO:     Epoch: 40
2023-01-04 09:49:51,953 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4802774747212728, 'Total loss': 0.4802774747212728} | train loss {'Reaction outcome loss': 0.36970525329435483, 'Total loss': 0.36970525329435483}
2023-01-04 09:49:51,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:51,953 INFO:     Epoch: 41
2023-01-04 09:49:53,566 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4650927404562632, 'Total loss': 0.4650927404562632} | train loss {'Reaction outcome loss': 0.3650289094817919, 'Total loss': 0.3650289094817919}
2023-01-04 09:49:53,567 INFO:     Found new best model at epoch 41
2023-01-04 09:49:53,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:53,567 INFO:     Epoch: 42
2023-01-04 09:49:55,175 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46056466499964394, 'Total loss': 0.46056466499964394} | train loss {'Reaction outcome loss': 0.36248547370559064, 'Total loss': 0.36248547370559064}
2023-01-04 09:49:55,175 INFO:     Found new best model at epoch 42
2023-01-04 09:49:55,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:55,176 INFO:     Epoch: 43
2023-01-04 09:49:56,781 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45504123767217003, 'Total loss': 0.45504123767217003} | train loss {'Reaction outcome loss': 0.3660841173048644, 'Total loss': 0.3660841173048644}
2023-01-04 09:49:56,781 INFO:     Found new best model at epoch 43
2023-01-04 09:49:56,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:56,782 INFO:     Epoch: 44
2023-01-04 09:49:58,342 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4909461736679077, 'Total loss': 0.4909461736679077} | train loss {'Reaction outcome loss': 0.3761570506553719, 'Total loss': 0.3761570506553719}
2023-01-04 09:49:58,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:58,343 INFO:     Epoch: 45
2023-01-04 09:49:59,937 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4632703105608622, 'Total loss': 0.4632703105608622} | train loss {'Reaction outcome loss': 0.3652408053403369, 'Total loss': 0.3652408053403369}
2023-01-04 09:49:59,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:49:59,938 INFO:     Epoch: 46
2023-01-04 09:50:01,516 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46135690013567604, 'Total loss': 0.46135690013567604} | train loss {'Reaction outcome loss': 0.3504960022974705, 'Total loss': 0.3504960022974705}
2023-01-04 09:50:01,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:01,516 INFO:     Epoch: 47
2023-01-04 09:50:03,131 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4455942749977112, 'Total loss': 0.4455942749977112} | train loss {'Reaction outcome loss': 0.35766830219738727, 'Total loss': 0.35766830219738727}
2023-01-04 09:50:03,132 INFO:     Found new best model at epoch 47
2023-01-04 09:50:03,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:03,132 INFO:     Epoch: 48
2023-01-04 09:50:04,713 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4753928522268931, 'Total loss': 0.4753928522268931} | train loss {'Reaction outcome loss': 0.384842083239388, 'Total loss': 0.384842083239388}
2023-01-04 09:50:04,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:04,713 INFO:     Epoch: 49
2023-01-04 09:50:06,282 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43229737182458244, 'Total loss': 0.43229737182458244} | train loss {'Reaction outcome loss': 0.34720877827264, 'Total loss': 0.34720877827264}
2023-01-04 09:50:06,282 INFO:     Found new best model at epoch 49
2023-01-04 09:50:06,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:06,283 INFO:     Epoch: 50
2023-01-04 09:50:07,836 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4520552734533946, 'Total loss': 0.4520552734533946} | train loss {'Reaction outcome loss': 0.34570868127048016, 'Total loss': 0.34570868127048016}
2023-01-04 09:50:07,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:07,836 INFO:     Epoch: 51
2023-01-04 09:50:09,411 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4872954080502192, 'Total loss': 0.4872954080502192} | train loss {'Reaction outcome loss': 0.3543070843342044, 'Total loss': 0.3543070843342044}
2023-01-04 09:50:09,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:09,411 INFO:     Epoch: 52
2023-01-04 09:50:10,945 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41982110738754275, 'Total loss': 0.41982110738754275} | train loss {'Reaction outcome loss': 0.3425317874930772, 'Total loss': 0.3425317874930772}
2023-01-04 09:50:10,945 INFO:     Found new best model at epoch 52
2023-01-04 09:50:10,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:10,946 INFO:     Epoch: 53
2023-01-04 09:50:12,520 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43994641304016113, 'Total loss': 0.43994641304016113} | train loss {'Reaction outcome loss': 0.33382998346148623, 'Total loss': 0.33382998346148623}
2023-01-04 09:50:12,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:12,520 INFO:     Epoch: 54
2023-01-04 09:50:14,099 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42708964794874194, 'Total loss': 0.42708964794874194} | train loss {'Reaction outcome loss': 0.3327274729052316, 'Total loss': 0.3327274729052316}
2023-01-04 09:50:14,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:14,099 INFO:     Epoch: 55
2023-01-04 09:50:15,669 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4355205178260803, 'Total loss': 0.4355205178260803} | train loss {'Reaction outcome loss': 0.33316277538466715, 'Total loss': 0.33316277538466715}
2023-01-04 09:50:15,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:15,669 INFO:     Epoch: 56
2023-01-04 09:50:17,184 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4110033378005028, 'Total loss': 0.4110033378005028} | train loss {'Reaction outcome loss': 0.3289023927320712, 'Total loss': 0.3289023927320712}
2023-01-04 09:50:17,184 INFO:     Found new best model at epoch 56
2023-01-04 09:50:17,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:17,185 INFO:     Epoch: 57
2023-01-04 09:50:18,739 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44426695505777997, 'Total loss': 0.44426695505777997} | train loss {'Reaction outcome loss': 0.32276269928990875, 'Total loss': 0.32276269928990875}
2023-01-04 09:50:18,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:18,739 INFO:     Epoch: 58
2023-01-04 09:50:20,292 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4286739687124888, 'Total loss': 0.4286739687124888} | train loss {'Reaction outcome loss': 0.3402131766458784, 'Total loss': 0.3402131766458784}
2023-01-04 09:50:20,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:20,293 INFO:     Epoch: 59
2023-01-04 09:50:21,857 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4522526999314626, 'Total loss': 0.4522526999314626} | train loss {'Reaction outcome loss': 0.33786957638095255, 'Total loss': 0.33786957638095255}
2023-01-04 09:50:21,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:21,858 INFO:     Epoch: 60
2023-01-04 09:50:23,413 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44635878602663676, 'Total loss': 0.44635878602663676} | train loss {'Reaction outcome loss': 0.3231538144375562, 'Total loss': 0.3231538144375562}
2023-01-04 09:50:23,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:23,413 INFO:     Epoch: 61
2023-01-04 09:50:24,992 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4107678711414337, 'Total loss': 0.4107678711414337} | train loss {'Reaction outcome loss': 0.31932960628955037, 'Total loss': 0.31932960628955037}
2023-01-04 09:50:24,992 INFO:     Found new best model at epoch 61
2023-01-04 09:50:24,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:24,993 INFO:     Epoch: 62
2023-01-04 09:50:26,541 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44649262030919395, 'Total loss': 0.44649262030919395} | train loss {'Reaction outcome loss': 0.32509086453828256, 'Total loss': 0.32509086453828256}
2023-01-04 09:50:26,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:26,541 INFO:     Epoch: 63
2023-01-04 09:50:28,080 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43246768514315287, 'Total loss': 0.43246768514315287} | train loss {'Reaction outcome loss': 0.3474105635026902, 'Total loss': 0.3474105635026902}
2023-01-04 09:50:28,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:28,080 INFO:     Epoch: 64
2023-01-04 09:50:29,654 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.458534836769104, 'Total loss': 0.458534836769104} | train loss {'Reaction outcome loss': 0.32537625905504264, 'Total loss': 0.32537625905504264}
2023-01-04 09:50:29,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:29,654 INFO:     Epoch: 65
2023-01-04 09:50:31,228 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43336289127667743, 'Total loss': 0.43336289127667743} | train loss {'Reaction outcome loss': 0.3309198503644649, 'Total loss': 0.3309198503644649}
2023-01-04 09:50:31,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:31,229 INFO:     Epoch: 66
2023-01-04 09:50:32,800 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42983537912368774, 'Total loss': 0.42983537912368774} | train loss {'Reaction outcome loss': 0.31064558419756644, 'Total loss': 0.31064558419756644}
2023-01-04 09:50:32,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:32,800 INFO:     Epoch: 67
2023-01-04 09:50:34,335 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42494716147581735, 'Total loss': 0.42494716147581735} | train loss {'Reaction outcome loss': 0.3064827995536768, 'Total loss': 0.3064827995536768}
2023-01-04 09:50:34,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:34,336 INFO:     Epoch: 68
2023-01-04 09:50:35,896 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4483745356400808, 'Total loss': 0.4483745356400808} | train loss {'Reaction outcome loss': 0.3054497794301936, 'Total loss': 0.3054497794301936}
2023-01-04 09:50:35,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:35,896 INFO:     Epoch: 69
2023-01-04 09:50:37,430 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4205946058034897, 'Total loss': 0.4205946058034897} | train loss {'Reaction outcome loss': 0.3051184491402861, 'Total loss': 0.3051184491402861}
2023-01-04 09:50:37,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:37,431 INFO:     Epoch: 70
2023-01-04 09:50:39,017 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4206314543883006, 'Total loss': 0.4206314543883006} | train loss {'Reaction outcome loss': 0.30574820765658567, 'Total loss': 0.30574820765658567}
2023-01-04 09:50:39,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:39,017 INFO:     Epoch: 71
2023-01-04 09:50:40,579 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4061925450960795, 'Total loss': 0.4061925450960795} | train loss {'Reaction outcome loss': 0.3078956658828642, 'Total loss': 0.3078956658828642}
2023-01-04 09:50:40,580 INFO:     Found new best model at epoch 71
2023-01-04 09:50:40,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:40,581 INFO:     Epoch: 72
2023-01-04 09:50:42,159 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41550540228684746, 'Total loss': 0.41550540228684746} | train loss {'Reaction outcome loss': 0.3019772678990325, 'Total loss': 0.3019772678990325}
2023-01-04 09:50:42,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:42,159 INFO:     Epoch: 73
2023-01-04 09:50:43,700 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41724177400271095, 'Total loss': 0.41724177400271095} | train loss {'Reaction outcome loss': 0.30126154536686744, 'Total loss': 0.30126154536686744}
2023-01-04 09:50:43,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:43,700 INFO:     Epoch: 74
2023-01-04 09:50:45,273 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4512567460536957, 'Total loss': 0.4512567460536957} | train loss {'Reaction outcome loss': 0.294395025242525, 'Total loss': 0.294395025242525}
2023-01-04 09:50:45,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:45,273 INFO:     Epoch: 75
2023-01-04 09:50:46,807 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4327259282271067, 'Total loss': 0.4327259282271067} | train loss {'Reaction outcome loss': 0.2996520133970805, 'Total loss': 0.2996520133970805}
2023-01-04 09:50:46,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:46,807 INFO:     Epoch: 76
2023-01-04 09:50:48,391 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42222438057263695, 'Total loss': 0.42222438057263695} | train loss {'Reaction outcome loss': 0.2967831862118581, 'Total loss': 0.2967831862118581}
2023-01-04 09:50:48,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:48,391 INFO:     Epoch: 77
2023-01-04 09:50:49,963 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4223412498831749, 'Total loss': 0.4223412498831749} | train loss {'Reaction outcome loss': 0.29485959547531343, 'Total loss': 0.29485959547531343}
2023-01-04 09:50:49,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:49,963 INFO:     Epoch: 78
2023-01-04 09:50:51,556 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4136859933535258, 'Total loss': 0.4136859933535258} | train loss {'Reaction outcome loss': 0.3068538362943176, 'Total loss': 0.3068538362943176}
2023-01-04 09:50:51,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:51,556 INFO:     Epoch: 79
2023-01-04 09:50:53,091 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4317513704299927, 'Total loss': 0.4317513704299927} | train loss {'Reaction outcome loss': 0.31934712347466976, 'Total loss': 0.31934712347466976}
2023-01-04 09:50:53,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:53,092 INFO:     Epoch: 80
2023-01-04 09:50:54,666 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4336428463459015, 'Total loss': 0.4336428463459015} | train loss {'Reaction outcome loss': 0.295069760767797, 'Total loss': 0.295069760767797}
2023-01-04 09:50:54,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:54,666 INFO:     Epoch: 81
2023-01-04 09:50:56,196 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44534408251444496, 'Total loss': 0.44534408251444496} | train loss {'Reaction outcome loss': 0.2940715785421755, 'Total loss': 0.2940715785421755}
2023-01-04 09:50:56,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:56,196 INFO:     Epoch: 82
2023-01-04 09:50:57,759 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41614493330319724, 'Total loss': 0.41614493330319724} | train loss {'Reaction outcome loss': 0.3021401246820671, 'Total loss': 0.3021401246820671}
2023-01-04 09:50:57,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:57,760 INFO:     Epoch: 83
2023-01-04 09:50:59,344 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42586581110954286, 'Total loss': 0.42586581110954286} | train loss {'Reaction outcome loss': 0.3200361310787823, 'Total loss': 0.3200361310787823}
2023-01-04 09:50:59,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:50:59,344 INFO:     Epoch: 84
2023-01-04 09:51:00,920 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4310181438922882, 'Total loss': 0.4310181438922882} | train loss {'Reaction outcome loss': 0.2952461855324066, 'Total loss': 0.2952461855324066}
2023-01-04 09:51:00,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:00,920 INFO:     Epoch: 85
2023-01-04 09:51:02,467 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43477992713451385, 'Total loss': 0.43477992713451385} | train loss {'Reaction outcome loss': 0.2883582583534113, 'Total loss': 0.2883582583534113}
2023-01-04 09:51:02,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:02,467 INFO:     Epoch: 86
2023-01-04 09:51:04,061 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4058920701344808, 'Total loss': 0.4058920701344808} | train loss {'Reaction outcome loss': 0.28992980541965074, 'Total loss': 0.28992980541965074}
2023-01-04 09:51:04,061 INFO:     Found new best model at epoch 86
2023-01-04 09:51:04,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:04,062 INFO:     Epoch: 87
2023-01-04 09:51:05,612 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41396652658780414, 'Total loss': 0.41396652658780414} | train loss {'Reaction outcome loss': 0.2882150787914145, 'Total loss': 0.2882150787914145}
2023-01-04 09:51:05,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:05,612 INFO:     Epoch: 88
2023-01-04 09:51:07,190 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4146519660949707, 'Total loss': 0.4146519660949707} | train loss {'Reaction outcome loss': 0.2961311979857071, 'Total loss': 0.2961311979857071}
2023-01-04 09:51:07,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:07,190 INFO:     Epoch: 89
2023-01-04 09:51:08,754 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4119256496429443, 'Total loss': 0.4119256496429443} | train loss {'Reaction outcome loss': 0.28608322302824346, 'Total loss': 0.28608322302824346}
2023-01-04 09:51:08,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:08,754 INFO:     Epoch: 90
2023-01-04 09:51:10,336 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4219500343004862, 'Total loss': 0.4219500343004862} | train loss {'Reaction outcome loss': 0.3010309235179338, 'Total loss': 0.3010309235179338}
2023-01-04 09:51:10,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:10,338 INFO:     Epoch: 91
2023-01-04 09:51:11,865 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42131116390228274, 'Total loss': 0.42131116390228274} | train loss {'Reaction outcome loss': 0.29628336737284594, 'Total loss': 0.29628336737284594}
2023-01-04 09:51:11,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:11,866 INFO:     Epoch: 92
2023-01-04 09:51:13,400 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4206767648458481, 'Total loss': 0.4206767648458481} | train loss {'Reaction outcome loss': 0.2858377268936053, 'Total loss': 0.2858377268936053}
2023-01-04 09:51:13,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:13,401 INFO:     Epoch: 93
2023-01-04 09:51:14,967 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4177229354778926, 'Total loss': 0.4177229354778926} | train loss {'Reaction outcome loss': 0.282992553613756, 'Total loss': 0.282992553613756}
2023-01-04 09:51:14,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:14,967 INFO:     Epoch: 94
2023-01-04 09:51:16,539 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44154633084932965, 'Total loss': 0.44154633084932965} | train loss {'Reaction outcome loss': 0.2945181174554687, 'Total loss': 0.2945181174554687}
2023-01-04 09:51:16,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:16,540 INFO:     Epoch: 95
2023-01-04 09:51:18,093 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41397217015425364, 'Total loss': 0.41397217015425364} | train loss {'Reaction outcome loss': 0.2841075642466329, 'Total loss': 0.2841075642466329}
2023-01-04 09:51:18,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:18,094 INFO:     Epoch: 96
2023-01-04 09:51:19,636 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4252915680408478, 'Total loss': 0.4252915680408478} | train loss {'Reaction outcome loss': 0.2982073949499771, 'Total loss': 0.2982073949499771}
2023-01-04 09:51:19,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:19,636 INFO:     Epoch: 97
2023-01-04 09:51:21,190 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3912186801433563, 'Total loss': 0.3912186801433563} | train loss {'Reaction outcome loss': 0.27888440397784003, 'Total loss': 0.27888440397784003}
2023-01-04 09:51:21,190 INFO:     Found new best model at epoch 97
2023-01-04 09:51:21,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:21,191 INFO:     Epoch: 98
2023-01-04 09:51:22,737 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4215848575035731, 'Total loss': 0.4215848575035731} | train loss {'Reaction outcome loss': 0.2771817874893621, 'Total loss': 0.2771817874893621}
2023-01-04 09:51:22,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:22,737 INFO:     Epoch: 99
2023-01-04 09:51:24,309 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43311229546864827, 'Total loss': 0.43311229546864827} | train loss {'Reaction outcome loss': 0.2802498918482224, 'Total loss': 0.2802498918482224}
2023-01-04 09:51:24,309 INFO:     Best model found after epoch 98 of 100.
2023-01-04 09:51:24,309 INFO:   Done with stage: TRAINING
2023-01-04 09:51:24,309 INFO:   Starting stage: EVALUATION
2023-01-04 09:51:24,437 INFO:   Done with stage: EVALUATION
2023-01-04 09:51:24,437 INFO:   Leaving out SEQ value Fold_8
2023-01-04 09:51:24,450 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 09:51:24,450 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:51:25,089 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:51:25,090 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:51:25,158 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:51:25,158 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:51:25,158 INFO:     No hyperparam tuning for this model
2023-01-04 09:51:25,158 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:51:25,158 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:51:25,159 INFO:     None feature selector for col prot
2023-01-04 09:51:25,159 INFO:     None feature selector for col prot
2023-01-04 09:51:25,159 INFO:     None feature selector for col prot
2023-01-04 09:51:25,160 INFO:     None feature selector for col chem
2023-01-04 09:51:25,160 INFO:     None feature selector for col chem
2023-01-04 09:51:25,160 INFO:     None feature selector for col chem
2023-01-04 09:51:25,160 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:51:25,160 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:51:25,161 INFO:     Number of params in model 70111
2023-01-04 09:51:25,164 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:51:25,165 INFO:   Starting stage: TRAINING
2023-01-04 09:51:25,209 INFO:     Val loss before train {'Reaction outcome loss': 0.8482496778170268, 'Total loss': 0.8482496778170268}
2023-01-04 09:51:25,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:25,209 INFO:     Epoch: 0
2023-01-04 09:51:26,781 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6205352564652761, 'Total loss': 0.6205352564652761} | train loss {'Reaction outcome loss': 0.825738964398412, 'Total loss': 0.825738964398412}
2023-01-04 09:51:26,781 INFO:     Found new best model at epoch 0
2023-01-04 09:51:26,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:26,782 INFO:     Epoch: 1
2023-01-04 09:51:28,329 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.550904659430186, 'Total loss': 0.550904659430186} | train loss {'Reaction outcome loss': 0.6625773008287388, 'Total loss': 0.6625773008287388}
2023-01-04 09:51:28,329 INFO:     Found new best model at epoch 1
2023-01-04 09:51:28,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:28,330 INFO:     Epoch: 2
2023-01-04 09:51:29,869 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5230447908242544, 'Total loss': 0.5230447908242544} | train loss {'Reaction outcome loss': 0.5788071126180844, 'Total loss': 0.5788071126180844}
2023-01-04 09:51:29,870 INFO:     Found new best model at epoch 2
2023-01-04 09:51:29,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:29,871 INFO:     Epoch: 3
2023-01-04 09:51:31,407 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5107502857844035, 'Total loss': 0.5107502857844035} | train loss {'Reaction outcome loss': 0.5415629268127636, 'Total loss': 0.5415629268127636}
2023-01-04 09:51:31,407 INFO:     Found new best model at epoch 3
2023-01-04 09:51:31,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:31,408 INFO:     Epoch: 4
2023-01-04 09:51:32,978 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48548810482025145, 'Total loss': 0.48548810482025145} | train loss {'Reaction outcome loss': 0.515131470767686, 'Total loss': 0.515131470767686}
2023-01-04 09:51:32,978 INFO:     Found new best model at epoch 4
2023-01-04 09:51:32,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:32,979 INFO:     Epoch: 5
2023-01-04 09:51:34,562 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48010948598384856, 'Total loss': 0.48010948598384856} | train loss {'Reaction outcome loss': 0.4969764940821341, 'Total loss': 0.4969764940821341}
2023-01-04 09:51:34,563 INFO:     Found new best model at epoch 5
2023-01-04 09:51:34,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:34,563 INFO:     Epoch: 6
2023-01-04 09:51:36,112 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48722731868426006, 'Total loss': 0.48722731868426006} | train loss {'Reaction outcome loss': 0.48828408459242245, 'Total loss': 0.48828408459242245}
2023-01-04 09:51:36,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:36,112 INFO:     Epoch: 7
2023-01-04 09:51:37,628 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4697557222098112, 'Total loss': 0.4697557222098112} | train loss {'Reaction outcome loss': 0.47900086701133826, 'Total loss': 0.47900086701133826}
2023-01-04 09:51:37,628 INFO:     Found new best model at epoch 7
2023-01-04 09:51:37,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:37,629 INFO:     Epoch: 8
2023-01-04 09:51:39,201 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4414680103460948, 'Total loss': 0.4414680103460948} | train loss {'Reaction outcome loss': 0.4708005189351792, 'Total loss': 0.4708005189351792}
2023-01-04 09:51:39,201 INFO:     Found new best model at epoch 8
2023-01-04 09:51:39,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:39,202 INFO:     Epoch: 9
2023-01-04 09:51:40,747 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47213255961736045, 'Total loss': 0.47213255961736045} | train loss {'Reaction outcome loss': 0.4617072003383706, 'Total loss': 0.4617072003383706}
2023-01-04 09:51:40,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:40,748 INFO:     Epoch: 10
2023-01-04 09:51:42,303 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4727173388004303, 'Total loss': 0.4727173388004303} | train loss {'Reaction outcome loss': 0.45367949510360284, 'Total loss': 0.45367949510360284}
2023-01-04 09:51:42,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:42,304 INFO:     Epoch: 11
2023-01-04 09:51:43,840 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43336610595385233, 'Total loss': 0.43336610595385233} | train loss {'Reaction outcome loss': 0.45133186952911153, 'Total loss': 0.45133186952911153}
2023-01-04 09:51:43,840 INFO:     Found new best model at epoch 11
2023-01-04 09:51:43,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:43,841 INFO:     Epoch: 12
2023-01-04 09:51:45,390 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47424775958061216, 'Total loss': 0.47424775958061216} | train loss {'Reaction outcome loss': 0.4452537629943695, 'Total loss': 0.4452537629943695}
2023-01-04 09:51:45,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:45,391 INFO:     Epoch: 13
2023-01-04 09:51:46,919 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4410882850488027, 'Total loss': 0.4410882850488027} | train loss {'Reaction outcome loss': 0.4407446206051068, 'Total loss': 0.4407446206051068}
2023-01-04 09:51:46,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:46,920 INFO:     Epoch: 14
2023-01-04 09:51:48,490 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4537956386804581, 'Total loss': 0.4537956386804581} | train loss {'Reaction outcome loss': 0.42844146549919226, 'Total loss': 0.42844146549919226}
2023-01-04 09:51:48,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:48,490 INFO:     Epoch: 15
2023-01-04 09:51:50,019 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4640587866306305, 'Total loss': 0.4640587866306305} | train loss {'Reaction outcome loss': 0.4297132844472454, 'Total loss': 0.4297132844472454}
2023-01-04 09:51:50,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:50,019 INFO:     Epoch: 16
2023-01-04 09:51:51,579 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4296157568693161, 'Total loss': 0.4296157568693161} | train loss {'Reaction outcome loss': 0.4216492430572092, 'Total loss': 0.4216492430572092}
2023-01-04 09:51:51,580 INFO:     Found new best model at epoch 16
2023-01-04 09:51:51,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:51,580 INFO:     Epoch: 17
2023-01-04 09:51:53,138 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4700019121170044, 'Total loss': 0.4700019121170044} | train loss {'Reaction outcome loss': 0.4198011673279922, 'Total loss': 0.4198011673279922}
2023-01-04 09:51:53,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:53,139 INFO:     Epoch: 18
2023-01-04 09:51:54,680 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4355080087979635, 'Total loss': 0.4355080087979635} | train loss {'Reaction outcome loss': 0.40956499666845714, 'Total loss': 0.40956499666845714}
2023-01-04 09:51:54,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:54,681 INFO:     Epoch: 19
2023-01-04 09:51:56,197 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4727290511131287, 'Total loss': 0.4727290511131287} | train loss {'Reaction outcome loss': 0.40659377642356564, 'Total loss': 0.40659377642356564}
2023-01-04 09:51:56,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:56,197 INFO:     Epoch: 20
2023-01-04 09:51:57,768 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40960437854131065, 'Total loss': 0.40960437854131065} | train loss {'Reaction outcome loss': 0.4031266531206831, 'Total loss': 0.4031266531206831}
2023-01-04 09:51:57,768 INFO:     Found new best model at epoch 20
2023-01-04 09:51:57,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:57,769 INFO:     Epoch: 21
2023-01-04 09:51:59,294 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43109053174654643, 'Total loss': 0.43109053174654643} | train loss {'Reaction outcome loss': 0.396159739063604, 'Total loss': 0.396159739063604}
2023-01-04 09:51:59,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:51:59,294 INFO:     Epoch: 22
2023-01-04 09:52:00,858 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4313988904158274, 'Total loss': 0.4313988904158274} | train loss {'Reaction outcome loss': 0.3960317496726983, 'Total loss': 0.3960317496726983}
2023-01-04 09:52:00,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:00,859 INFO:     Epoch: 23
2023-01-04 09:52:02,416 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4521585355202357, 'Total loss': 0.4521585355202357} | train loss {'Reaction outcome loss': 0.38620548649099623, 'Total loss': 0.38620548649099623}
2023-01-04 09:52:02,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:02,417 INFO:     Epoch: 24
2023-01-04 09:52:03,981 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4280259609222412, 'Total loss': 0.4280259609222412} | train loss {'Reaction outcome loss': 0.39034029751689764, 'Total loss': 0.39034029751689764}
2023-01-04 09:52:03,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:03,982 INFO:     Epoch: 25
2023-01-04 09:52:05,513 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43887213269869485, 'Total loss': 0.43887213269869485} | train loss {'Reaction outcome loss': 0.37822578129542134, 'Total loss': 0.37822578129542134}
2023-01-04 09:52:05,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:05,514 INFO:     Epoch: 26
2023-01-04 09:52:07,071 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.458132204413414, 'Total loss': 0.458132204413414} | train loss {'Reaction outcome loss': 0.3765284576500854, 'Total loss': 0.3765284576500854}
2023-01-04 09:52:07,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:07,071 INFO:     Epoch: 27
2023-01-04 09:52:08,591 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40033474564552307, 'Total loss': 0.40033474564552307} | train loss {'Reaction outcome loss': 0.37310737844583763, 'Total loss': 0.37310737844583763}
2023-01-04 09:52:08,591 INFO:     Found new best model at epoch 27
2023-01-04 09:52:08,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:08,592 INFO:     Epoch: 28
2023-01-04 09:52:10,149 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41970242659250895, 'Total loss': 0.41970242659250895} | train loss {'Reaction outcome loss': 0.37296145643195966, 'Total loss': 0.37296145643195966}
2023-01-04 09:52:10,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:10,149 INFO:     Epoch: 29
2023-01-04 09:52:11,698 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45376111765702565, 'Total loss': 0.45376111765702565} | train loss {'Reaction outcome loss': 0.3658445218618769, 'Total loss': 0.3658445218618769}
2023-01-04 09:52:11,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:11,698 INFO:     Epoch: 30
2023-01-04 09:52:13,268 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42278203964233396, 'Total loss': 0.42278203964233396} | train loss {'Reaction outcome loss': 0.36281146786182467, 'Total loss': 0.36281146786182467}
2023-01-04 09:52:13,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:13,268 INFO:     Epoch: 31
2023-01-04 09:52:14,413 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.424830291668574, 'Total loss': 0.424830291668574} | train loss {'Reaction outcome loss': 0.3601714706279501, 'Total loss': 0.3601714706279501}
2023-01-04 09:52:14,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:14,413 INFO:     Epoch: 32
2023-01-04 09:52:15,437 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43607777655124663, 'Total loss': 0.43607777655124663} | train loss {'Reaction outcome loss': 0.35467644595969333, 'Total loss': 0.35467644595969333}
2023-01-04 09:52:15,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:15,437 INFO:     Epoch: 33
2023-01-04 09:52:16,452 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4153468350569407, 'Total loss': 0.4153468350569407} | train loss {'Reaction outcome loss': 0.35370921449613396, 'Total loss': 0.35370921449613396}
2023-01-04 09:52:16,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:16,453 INFO:     Epoch: 34
2023-01-04 09:52:17,470 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39885475238164264, 'Total loss': 0.39885475238164264} | train loss {'Reaction outcome loss': 0.3521928247880109, 'Total loss': 0.3521928247880109}
2023-01-04 09:52:17,470 INFO:     Found new best model at epoch 34
2023-01-04 09:52:17,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:17,471 INFO:     Epoch: 35
2023-01-04 09:52:18,621 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39864710668722786, 'Total loss': 0.39864710668722786} | train loss {'Reaction outcome loss': 0.35047143477484255, 'Total loss': 0.35047143477484255}
2023-01-04 09:52:18,621 INFO:     Found new best model at epoch 35
2023-01-04 09:52:18,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:18,621 INFO:     Epoch: 36
2023-01-04 09:52:20,182 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3984308073918025, 'Total loss': 0.3984308073918025} | train loss {'Reaction outcome loss': 0.34712044946359893, 'Total loss': 0.34712044946359893}
2023-01-04 09:52:20,182 INFO:     Found new best model at epoch 36
2023-01-04 09:52:20,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:20,182 INFO:     Epoch: 37
2023-01-04 09:52:21,761 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42087147931257884, 'Total loss': 0.42087147931257884} | train loss {'Reaction outcome loss': 0.3408440164405934, 'Total loss': 0.3408440164405934}
2023-01-04 09:52:21,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:21,761 INFO:     Epoch: 38
2023-01-04 09:52:23,277 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42946782807509104, 'Total loss': 0.42946782807509104} | train loss {'Reaction outcome loss': 0.3409889940797848, 'Total loss': 0.3409889940797848}
2023-01-04 09:52:23,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:23,278 INFO:     Epoch: 39
2023-01-04 09:52:24,835 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44397879143555957, 'Total loss': 0.44397879143555957} | train loss {'Reaction outcome loss': 0.3351681763510199, 'Total loss': 0.3351681763510199}
2023-01-04 09:52:24,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:24,835 INFO:     Epoch: 40
2023-01-04 09:52:26,407 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4247665713230769, 'Total loss': 0.4247665713230769} | train loss {'Reaction outcome loss': 0.33315172356410616, 'Total loss': 0.33315172356410616}
2023-01-04 09:52:26,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:26,408 INFO:     Epoch: 41
2023-01-04 09:52:27,934 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41190898021062217, 'Total loss': 0.41190898021062217} | train loss {'Reaction outcome loss': 0.3253816419219884, 'Total loss': 0.3253816419219884}
2023-01-04 09:52:27,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:27,934 INFO:     Epoch: 42
2023-01-04 09:52:29,492 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41811474760373435, 'Total loss': 0.41811474760373435} | train loss {'Reaction outcome loss': 0.3304249181745261, 'Total loss': 0.3304249181745261}
2023-01-04 09:52:29,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:29,492 INFO:     Epoch: 43
2023-01-04 09:52:31,050 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4204017718633016, 'Total loss': 0.4204017718633016} | train loss {'Reaction outcome loss': 0.32760590102768294, 'Total loss': 0.32760590102768294}
2023-01-04 09:52:31,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:31,050 INFO:     Epoch: 44
2023-01-04 09:52:32,569 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4123653034369151, 'Total loss': 0.4123653034369151} | train loss {'Reaction outcome loss': 0.32229891740275124, 'Total loss': 0.32229891740275124}
2023-01-04 09:52:32,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:32,569 INFO:     Epoch: 45
2023-01-04 09:52:34,132 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41305723289648694, 'Total loss': 0.41305723289648694} | train loss {'Reaction outcome loss': 0.32024132864155475, 'Total loss': 0.32024132864155475}
2023-01-04 09:52:34,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:34,132 INFO:     Epoch: 46
2023-01-04 09:52:35,692 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4133858154217402, 'Total loss': 0.4133858154217402} | train loss {'Reaction outcome loss': 0.31986816194805784, 'Total loss': 0.31986816194805784}
2023-01-04 09:52:35,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:35,693 INFO:     Epoch: 47
2023-01-04 09:52:37,212 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3952494740486145, 'Total loss': 0.3952494740486145} | train loss {'Reaction outcome loss': 0.3149440249387365, 'Total loss': 0.3149440249387365}
2023-01-04 09:52:37,213 INFO:     Found new best model at epoch 47
2023-01-04 09:52:37,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:37,213 INFO:     Epoch: 48
2023-01-04 09:52:38,765 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3996072699626287, 'Total loss': 0.3996072699626287} | train loss {'Reaction outcome loss': 0.31151783950354933, 'Total loss': 0.31151783950354933}
2023-01-04 09:52:38,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:38,765 INFO:     Epoch: 49
2023-01-04 09:52:40,305 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4118308196465174, 'Total loss': 0.4118308196465174} | train loss {'Reaction outcome loss': 0.31700296071867873, 'Total loss': 0.31700296071867873}
2023-01-04 09:52:40,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:40,306 INFO:     Epoch: 50
2023-01-04 09:52:41,828 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40549741784731547, 'Total loss': 0.40549741784731547} | train loss {'Reaction outcome loss': 0.30953006440923164, 'Total loss': 0.30953006440923164}
2023-01-04 09:52:41,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:41,828 INFO:     Epoch: 51
2023-01-04 09:52:43,392 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44460175434748334, 'Total loss': 0.44460175434748334} | train loss {'Reaction outcome loss': 0.309488717412209, 'Total loss': 0.309488717412209}
2023-01-04 09:52:43,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:43,392 INFO:     Epoch: 52
2023-01-04 09:52:44,961 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4014152894417445, 'Total loss': 0.4014152894417445} | train loss {'Reaction outcome loss': 0.3104688517314239, 'Total loss': 0.3104688517314239}
2023-01-04 09:52:44,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:44,961 INFO:     Epoch: 53
2023-01-04 09:52:46,497 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4091326355934143, 'Total loss': 0.4091326355934143} | train loss {'Reaction outcome loss': 0.30827398973442344, 'Total loss': 0.30827398973442344}
2023-01-04 09:52:46,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:46,499 INFO:     Epoch: 54
2023-01-04 09:52:48,056 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41488815744717916, 'Total loss': 0.41488815744717916} | train loss {'Reaction outcome loss': 0.3084027144758806, 'Total loss': 0.3084027144758806}
2023-01-04 09:52:48,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:48,056 INFO:     Epoch: 55
2023-01-04 09:52:49,613 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47082133293151857, 'Total loss': 0.47082133293151857} | train loss {'Reaction outcome loss': 0.2977123016314785, 'Total loss': 0.2977123016314785}
2023-01-04 09:52:49,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:49,613 INFO:     Epoch: 56
2023-01-04 09:52:51,136 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4213856001694997, 'Total loss': 0.4213856001694997} | train loss {'Reaction outcome loss': 0.2999337503455416, 'Total loss': 0.2999337503455416}
2023-01-04 09:52:51,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:51,136 INFO:     Epoch: 57
2023-01-04 09:52:52,691 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4198425402243932, 'Total loss': 0.4198425402243932} | train loss {'Reaction outcome loss': 0.29553977905833806, 'Total loss': 0.29553977905833806}
2023-01-04 09:52:52,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:52,692 INFO:     Epoch: 58
2023-01-04 09:52:54,228 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.441692017018795, 'Total loss': 0.441692017018795} | train loss {'Reaction outcome loss': 0.29458105066505663, 'Total loss': 0.29458105066505663}
2023-01-04 09:52:54,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:54,229 INFO:     Epoch: 59
2023-01-04 09:52:55,754 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39790998299916586, 'Total loss': 0.39790998299916586} | train loss {'Reaction outcome loss': 0.2973339676204389, 'Total loss': 0.2973339676204389}
2023-01-04 09:52:55,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:55,754 INFO:     Epoch: 60
2023-01-04 09:52:57,314 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4034134884675344, 'Total loss': 0.4034134884675344} | train loss {'Reaction outcome loss': 0.29411446637589567, 'Total loss': 0.29411446637589567}
2023-01-04 09:52:57,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:57,314 INFO:     Epoch: 61
2023-01-04 09:52:58,852 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41644527912139895, 'Total loss': 0.41644527912139895} | train loss {'Reaction outcome loss': 0.2889215873595137, 'Total loss': 0.2889215873595137}
2023-01-04 09:52:58,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:52:58,852 INFO:     Epoch: 62
2023-01-04 09:53:00,370 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4179277539253235, 'Total loss': 0.4179277539253235} | train loss {'Reaction outcome loss': 0.2872447517775271, 'Total loss': 0.2872447517775271}
2023-01-04 09:53:00,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:00,370 INFO:     Epoch: 63
2023-01-04 09:53:01,934 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39649969538052876, 'Total loss': 0.39649969538052876} | train loss {'Reaction outcome loss': 0.2888095548417229, 'Total loss': 0.2888095548417229}
2023-01-04 09:53:01,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:01,934 INFO:     Epoch: 64
2023-01-04 09:53:03,489 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42196457982063296, 'Total loss': 0.42196457982063296} | train loss {'Reaction outcome loss': 0.28681038706189527, 'Total loss': 0.28681038706189527}
2023-01-04 09:53:03,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:03,489 INFO:     Epoch: 65
2023-01-04 09:53:05,021 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4123842845360438, 'Total loss': 0.4123842845360438} | train loss {'Reaction outcome loss': 0.28511100206660095, 'Total loss': 0.28511100206660095}
2023-01-04 09:53:05,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:05,022 INFO:     Epoch: 66
2023-01-04 09:53:06,591 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43487437069416046, 'Total loss': 0.43487437069416046} | train loss {'Reaction outcome loss': 0.2827986671324194, 'Total loss': 0.2827986671324194}
2023-01-04 09:53:06,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:06,591 INFO:     Epoch: 67
2023-01-04 09:53:08,153 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42444290121396383, 'Total loss': 0.42444290121396383} | train loss {'Reaction outcome loss': 0.27995911836080306, 'Total loss': 0.27995911836080306}
2023-01-04 09:53:08,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:08,154 INFO:     Epoch: 68
2023-01-04 09:53:09,664 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39781660636266075, 'Total loss': 0.39781660636266075} | train loss {'Reaction outcome loss': 0.2798295430839062, 'Total loss': 0.2798295430839062}
2023-01-04 09:53:09,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:09,664 INFO:     Epoch: 69
2023-01-04 09:53:11,223 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40311343868573507, 'Total loss': 0.40311343868573507} | train loss {'Reaction outcome loss': 0.2808396314835026, 'Total loss': 0.2808396314835026}
2023-01-04 09:53:11,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:11,223 INFO:     Epoch: 70
2023-01-04 09:53:12,751 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4089878370364507, 'Total loss': 0.4089878370364507} | train loss {'Reaction outcome loss': 0.2796479106003786, 'Total loss': 0.2796479106003786}
2023-01-04 09:53:12,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:12,751 INFO:     Epoch: 71
2023-01-04 09:53:14,297 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39951947033405305, 'Total loss': 0.39951947033405305} | train loss {'Reaction outcome loss': 0.27233676173227983, 'Total loss': 0.27233676173227983}
2023-01-04 09:53:14,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:14,297 INFO:     Epoch: 72
2023-01-04 09:53:15,856 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43227194994688034, 'Total loss': 0.43227194994688034} | train loss {'Reaction outcome loss': 0.2725410191274255, 'Total loss': 0.2725410191274255}
2023-01-04 09:53:15,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:15,857 INFO:     Epoch: 73
2023-01-04 09:53:17,386 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4402889480193456, 'Total loss': 0.4402889480193456} | train loss {'Reaction outcome loss': 0.27269043569473456, 'Total loss': 0.27269043569473456}
2023-01-04 09:53:17,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:17,387 INFO:     Epoch: 74
2023-01-04 09:53:18,952 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4694513469934464, 'Total loss': 0.4694513469934464} | train loss {'Reaction outcome loss': 0.2694138170756998, 'Total loss': 0.2694138170756998}
2023-01-04 09:53:18,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:18,952 INFO:     Epoch: 75
2023-01-04 09:53:20,509 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4069632331530253, 'Total loss': 0.4069632331530253} | train loss {'Reaction outcome loss': 0.2695789542728967, 'Total loss': 0.2695789542728967}
2023-01-04 09:53:20,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:20,509 INFO:     Epoch: 76
2023-01-04 09:53:22,014 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4050716380278269, 'Total loss': 0.4050716380278269} | train loss {'Reaction outcome loss': 0.27098935967596777, 'Total loss': 0.27098935967596777}
2023-01-04 09:53:22,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:22,014 INFO:     Epoch: 77
2023-01-04 09:53:23,553 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.383333561817805, 'Total loss': 0.383333561817805} | train loss {'Reaction outcome loss': 0.26178633401265544, 'Total loss': 0.26178633401265544}
2023-01-04 09:53:23,554 INFO:     Found new best model at epoch 77
2023-01-04 09:53:23,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:23,554 INFO:     Epoch: 78
2023-01-04 09:53:25,109 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4176912374794483, 'Total loss': 0.4176912374794483} | train loss {'Reaction outcome loss': 0.2687900357057143, 'Total loss': 0.2687900357057143}
2023-01-04 09:53:25,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:25,110 INFO:     Epoch: 79
2023-01-04 09:53:26,626 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4349379688501358, 'Total loss': 0.4349379688501358} | train loss {'Reaction outcome loss': 0.2645315148860869, 'Total loss': 0.2645315148860869}
2023-01-04 09:53:26,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:26,626 INFO:     Epoch: 80
2023-01-04 09:53:28,167 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4223967949549357, 'Total loss': 0.4223967949549357} | train loss {'Reaction outcome loss': 0.27184092367652557, 'Total loss': 0.27184092367652557}
2023-01-04 09:53:28,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:28,167 INFO:     Epoch: 81
2023-01-04 09:53:29,723 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39860042730967205, 'Total loss': 0.39860042730967205} | train loss {'Reaction outcome loss': 0.2656061143825089, 'Total loss': 0.2656061143825089}
2023-01-04 09:53:29,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:29,724 INFO:     Epoch: 82
2023-01-04 09:53:31,257 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3957264766097069, 'Total loss': 0.3957264766097069} | train loss {'Reaction outcome loss': 0.2667635834238825, 'Total loss': 0.2667635834238825}
2023-01-04 09:53:31,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:31,258 INFO:     Epoch: 83
2023-01-04 09:53:32,814 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3713968505462011, 'Total loss': 0.3713968505462011} | train loss {'Reaction outcome loss': 0.26127994253578846, 'Total loss': 0.26127994253578846}
2023-01-04 09:53:32,814 INFO:     Found new best model at epoch 83
2023-01-04 09:53:32,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:32,815 INFO:     Epoch: 84
2023-01-04 09:53:34,367 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4044694701830546, 'Total loss': 0.4044694701830546} | train loss {'Reaction outcome loss': 0.25761143327520714, 'Total loss': 0.25761143327520714}
2023-01-04 09:53:34,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:34,367 INFO:     Epoch: 85
2023-01-04 09:53:35,887 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4116523941357931, 'Total loss': 0.4116523941357931} | train loss {'Reaction outcome loss': 0.26144092623824183, 'Total loss': 0.26144092623824183}
2023-01-04 09:53:35,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:35,888 INFO:     Epoch: 86
2023-01-04 09:53:37,454 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3953924685716629, 'Total loss': 0.3953924685716629} | train loss {'Reaction outcome loss': 0.25591083363133627, 'Total loss': 0.25591083363133627}
2023-01-04 09:53:37,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:37,454 INFO:     Epoch: 87
2023-01-04 09:53:39,029 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40181743204593656, 'Total loss': 0.40181743204593656} | train loss {'Reaction outcome loss': 0.25870717085734773, 'Total loss': 0.25870717085734773}
2023-01-04 09:53:39,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:39,029 INFO:     Epoch: 88
2023-01-04 09:53:40,570 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41575258572896323, 'Total loss': 0.41575258572896323} | train loss {'Reaction outcome loss': 0.25675007526891946, 'Total loss': 0.25675007526891946}
2023-01-04 09:53:40,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:40,571 INFO:     Epoch: 89
2023-01-04 09:53:42,145 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43750479618708293, 'Total loss': 0.43750479618708293} | train loss {'Reaction outcome loss': 0.25736127909354484, 'Total loss': 0.25736127909354484}
2023-01-04 09:53:42,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:42,145 INFO:     Epoch: 90
2023-01-04 09:53:43,720 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3968266064922015, 'Total loss': 0.3968266064922015} | train loss {'Reaction outcome loss': 0.2526128272233653, 'Total loss': 0.2526128272233653}
2023-01-04 09:53:43,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:43,720 INFO:     Epoch: 91
2023-01-04 09:53:45,251 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3883921871582667, 'Total loss': 0.3883921871582667} | train loss {'Reaction outcome loss': 0.25285427343018735, 'Total loss': 0.25285427343018735}
2023-01-04 09:53:45,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:45,251 INFO:     Epoch: 92
2023-01-04 09:53:46,869 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45166320403416954, 'Total loss': 0.45166320403416954} | train loss {'Reaction outcome loss': 0.24936169610243208, 'Total loss': 0.24936169610243208}
2023-01-04 09:53:46,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:46,869 INFO:     Epoch: 93
2023-01-04 09:53:48,470 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4227027406295141, 'Total loss': 0.4227027406295141} | train loss {'Reaction outcome loss': 0.25081929115809665, 'Total loss': 0.25081929115809665}
2023-01-04 09:53:48,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:48,471 INFO:     Epoch: 94
2023-01-04 09:53:50,029 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3909443482756615, 'Total loss': 0.3909443482756615} | train loss {'Reaction outcome loss': 0.25174764422767787, 'Total loss': 0.25174764422767787}
2023-01-04 09:53:50,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:50,029 INFO:     Epoch: 95
2023-01-04 09:53:51,601 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4000844284892082, 'Total loss': 0.4000844284892082} | train loss {'Reaction outcome loss': 0.24984077981462444, 'Total loss': 0.24984077981462444}
2023-01-04 09:53:51,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:51,602 INFO:     Epoch: 96
2023-01-04 09:53:53,196 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41760328809420266, 'Total loss': 0.41760328809420266} | train loss {'Reaction outcome loss': 0.2495828889799814, 'Total loss': 0.2495828889799814}
2023-01-04 09:53:53,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:53,196 INFO:     Epoch: 97
2023-01-04 09:53:54,720 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4179679254690806, 'Total loss': 0.4179679254690806} | train loss {'Reaction outcome loss': 0.24544105382405057, 'Total loss': 0.24544105382405057}
2023-01-04 09:53:54,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:54,721 INFO:     Epoch: 98
2023-01-04 09:53:56,307 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.419870596130689, 'Total loss': 0.419870596130689} | train loss {'Reaction outcome loss': 0.24918849078299354, 'Total loss': 0.24918849078299354}
2023-01-04 09:53:56,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:56,307 INFO:     Epoch: 99
2023-01-04 09:53:57,897 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40776175757249195, 'Total loss': 0.40776175757249195} | train loss {'Reaction outcome loss': 0.25191705085228394, 'Total loss': 0.25191705085228394}
2023-01-04 09:53:57,897 INFO:     Best model found after epoch 84 of 100.
2023-01-04 09:53:57,897 INFO:   Done with stage: TRAINING
2023-01-04 09:53:57,897 INFO:   Starting stage: EVALUATION
2023-01-04 09:53:58,032 INFO:   Done with stage: EVALUATION
2023-01-04 09:53:58,032 INFO:   Leaving out SEQ value Fold_9
2023-01-04 09:53:58,045 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:53:58,045 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:53:58,701 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:53:58,701 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:53:58,770 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:53:58,770 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:53:58,770 INFO:     No hyperparam tuning for this model
2023-01-04 09:53:58,770 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:53:58,770 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:53:58,771 INFO:     None feature selector for col prot
2023-01-04 09:53:58,771 INFO:     None feature selector for col prot
2023-01-04 09:53:58,771 INFO:     None feature selector for col prot
2023-01-04 09:53:58,772 INFO:     None feature selector for col chem
2023-01-04 09:53:58,772 INFO:     None feature selector for col chem
2023-01-04 09:53:58,772 INFO:     None feature selector for col chem
2023-01-04 09:53:58,772 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:53:58,772 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:53:58,773 INFO:     Number of params in model 70111
2023-01-04 09:53:58,776 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:53:58,776 INFO:   Starting stage: TRAINING
2023-01-04 09:53:58,819 INFO:     Val loss before train {'Reaction outcome loss': 1.0396059989929198, 'Total loss': 1.0396059989929198}
2023-01-04 09:53:58,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:53:58,820 INFO:     Epoch: 0
2023-01-04 09:54:00,405 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7758977909882864, 'Total loss': 0.7758977909882864} | train loss {'Reaction outcome loss': 0.8275083735369254, 'Total loss': 0.8275083735369254}
2023-01-04 09:54:00,405 INFO:     Found new best model at epoch 0
2023-01-04 09:54:00,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:00,406 INFO:     Epoch: 1
2023-01-04 09:54:01,990 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6509489754835764, 'Total loss': 0.6509489754835764} | train loss {'Reaction outcome loss': 0.6737238379276317, 'Total loss': 0.6737238379276317}
2023-01-04 09:54:01,990 INFO:     Found new best model at epoch 1
2023-01-04 09:54:01,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:01,991 INFO:     Epoch: 2
2023-01-04 09:54:03,537 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.600590705871582, 'Total loss': 0.600590705871582} | train loss {'Reaction outcome loss': 0.5943810446033899, 'Total loss': 0.5943810446033899}
2023-01-04 09:54:03,537 INFO:     Found new best model at epoch 2
2023-01-04 09:54:03,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:03,538 INFO:     Epoch: 3
2023-01-04 09:54:05,117 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.586986784140269, 'Total loss': 0.586986784140269} | train loss {'Reaction outcome loss': 0.547898036626883, 'Total loss': 0.547898036626883}
2023-01-04 09:54:05,117 INFO:     Found new best model at epoch 3
2023-01-04 09:54:05,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:05,118 INFO:     Epoch: 4
2023-01-04 09:54:06,702 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5604437172412873, 'Total loss': 0.5604437172412873} | train loss {'Reaction outcome loss': 0.5196397371752106, 'Total loss': 0.5196397371752106}
2023-01-04 09:54:06,702 INFO:     Found new best model at epoch 4
2023-01-04 09:54:06,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:06,703 INFO:     Epoch: 5
2023-01-04 09:54:08,260 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5419094532728195, 'Total loss': 0.5419094532728195} | train loss {'Reaction outcome loss': 0.49902359118172224, 'Total loss': 0.49902359118172224}
2023-01-04 09:54:08,261 INFO:     Found new best model at epoch 5
2023-01-04 09:54:08,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:08,262 INFO:     Epoch: 6
2023-01-04 09:54:09,856 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5559704979260762, 'Total loss': 0.5559704979260762} | train loss {'Reaction outcome loss': 0.5053461192958597, 'Total loss': 0.5053461192958597}
2023-01-04 09:54:09,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:09,856 INFO:     Epoch: 7
2023-01-04 09:54:11,447 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5344232062498728, 'Total loss': 0.5344232062498728} | train loss {'Reaction outcome loss': 0.5094320276833099, 'Total loss': 0.5094320276833099}
2023-01-04 09:54:11,447 INFO:     Found new best model at epoch 7
2023-01-04 09:54:11,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:11,448 INFO:     Epoch: 8
2023-01-04 09:54:13,024 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49985838135083516, 'Total loss': 0.49985838135083516} | train loss {'Reaction outcome loss': 0.4999969521152746, 'Total loss': 0.4999969521152746}
2023-01-04 09:54:13,024 INFO:     Found new best model at epoch 8
2023-01-04 09:54:13,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:13,025 INFO:     Epoch: 9
2023-01-04 09:54:14,622 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49871757328510286, 'Total loss': 0.49871757328510286} | train loss {'Reaction outcome loss': 0.4642451742960923, 'Total loss': 0.4642451742960923}
2023-01-04 09:54:14,622 INFO:     Found new best model at epoch 9
2023-01-04 09:54:14,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:14,623 INFO:     Epoch: 10
2023-01-04 09:54:16,151 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5084575394789378, 'Total loss': 0.5084575394789378} | train loss {'Reaction outcome loss': 0.4637900133097571, 'Total loss': 0.4637900133097571}
2023-01-04 09:54:16,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:16,151 INFO:     Epoch: 11
2023-01-04 09:54:17,739 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5207954943180084, 'Total loss': 0.5207954943180084} | train loss {'Reaction outcome loss': 0.462688895104372, 'Total loss': 0.462688895104372}
2023-01-04 09:54:17,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:17,740 INFO:     Epoch: 12
2023-01-04 09:54:19,330 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4807472457488378, 'Total loss': 0.4807472457488378} | train loss {'Reaction outcome loss': 0.47090484434738755, 'Total loss': 0.47090484434738755}
2023-01-04 09:54:19,331 INFO:     Found new best model at epoch 12
2023-01-04 09:54:19,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:19,332 INFO:     Epoch: 13
2023-01-04 09:54:20,921 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4641921937465668, 'Total loss': 0.4641921937465668} | train loss {'Reaction outcome loss': 0.4406681624038712, 'Total loss': 0.4406681624038712}
2023-01-04 09:54:20,921 INFO:     Found new best model at epoch 13
2023-01-04 09:54:20,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:20,922 INFO:     Epoch: 14
2023-01-04 09:54:22,488 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48165417512257896, 'Total loss': 0.48165417512257896} | train loss {'Reaction outcome loss': 0.43449485273626837, 'Total loss': 0.43449485273626837}
2023-01-04 09:54:22,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:22,488 INFO:     Epoch: 15
2023-01-04 09:54:24,077 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46623941461245216, 'Total loss': 0.46623941461245216} | train loss {'Reaction outcome loss': 0.4354595942017825, 'Total loss': 0.4354595942017825}
2023-01-04 09:54:24,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:24,077 INFO:     Epoch: 16
2023-01-04 09:54:25,637 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4605178991953532, 'Total loss': 0.4605178991953532} | train loss {'Reaction outcome loss': 0.43136636723858723, 'Total loss': 0.43136636723858723}
2023-01-04 09:54:25,638 INFO:     Found new best model at epoch 16
2023-01-04 09:54:25,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:25,639 INFO:     Epoch: 17
2023-01-04 09:54:27,273 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4679236312707265, 'Total loss': 0.4679236312707265} | train loss {'Reaction outcome loss': 0.4257274153439895, 'Total loss': 0.4257274153439895}
2023-01-04 09:54:27,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:27,274 INFO:     Epoch: 18
2023-01-04 09:54:28,857 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4983209133148193, 'Total loss': 0.4983209133148193} | train loss {'Reaction outcome loss': 0.42153079661986104, 'Total loss': 0.42153079661986104}
2023-01-04 09:54:28,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:28,857 INFO:     Epoch: 19
2023-01-04 09:54:30,422 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4890535851319631, 'Total loss': 0.4890535851319631} | train loss {'Reaction outcome loss': 0.41662275110560376, 'Total loss': 0.41662275110560376}
2023-01-04 09:54:30,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:30,422 INFO:     Epoch: 20
2023-01-04 09:54:31,971 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4736676037311554, 'Total loss': 0.4736676037311554} | train loss {'Reaction outcome loss': 0.41316675338084285, 'Total loss': 0.41316675338084285}
2023-01-04 09:54:31,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:31,971 INFO:     Epoch: 21
2023-01-04 09:54:33,539 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47559590339660646, 'Total loss': 0.47559590339660646} | train loss {'Reaction outcome loss': 0.42330220430765464, 'Total loss': 0.42330220430765464}
2023-01-04 09:54:33,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:33,539 INFO:     Epoch: 22
2023-01-04 09:54:35,076 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45564154783884686, 'Total loss': 0.45564154783884686} | train loss {'Reaction outcome loss': 0.40629751147175935, 'Total loss': 0.40629751147175935}
2023-01-04 09:54:35,076 INFO:     Found new best model at epoch 22
2023-01-04 09:54:35,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:35,077 INFO:     Epoch: 23
2023-01-04 09:54:36,634 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47136464913686116, 'Total loss': 0.47136464913686116} | train loss {'Reaction outcome loss': 0.40310586390989844, 'Total loss': 0.40310586390989844}
2023-01-04 09:54:36,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:36,634 INFO:     Epoch: 24
2023-01-04 09:54:38,197 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4501128911972046, 'Total loss': 0.4501128911972046} | train loss {'Reaction outcome loss': 0.3987704756791177, 'Total loss': 0.3987704756791177}
2023-01-04 09:54:38,198 INFO:     Found new best model at epoch 24
2023-01-04 09:54:38,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:38,199 INFO:     Epoch: 25
2023-01-04 09:54:39,719 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47600280940532685, 'Total loss': 0.47600280940532685} | train loss {'Reaction outcome loss': 0.39845585274388606, 'Total loss': 0.39845585274388606}
2023-01-04 09:54:39,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:39,719 INFO:     Epoch: 26
2023-01-04 09:54:41,293 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4600172380606333, 'Total loss': 0.4600172380606333} | train loss {'Reaction outcome loss': 0.39133462239228917, 'Total loss': 0.39133462239228917}
2023-01-04 09:54:41,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:41,294 INFO:     Epoch: 27
2023-01-04 09:54:42,864 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4527922441562017, 'Total loss': 0.4527922441562017} | train loss {'Reaction outcome loss': 0.38947402518849983, 'Total loss': 0.38947402518849983}
2023-01-04 09:54:42,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:42,865 INFO:     Epoch: 28
2023-01-04 09:54:44,397 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45324060519536336, 'Total loss': 0.45324060519536336} | train loss {'Reaction outcome loss': 0.3898560713058796, 'Total loss': 0.3898560713058796}
2023-01-04 09:54:44,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:44,397 INFO:     Epoch: 29
2023-01-04 09:54:45,967 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45307539105415345, 'Total loss': 0.45307539105415345} | train loss {'Reaction outcome loss': 0.38394779291037756, 'Total loss': 0.38394779291037756}
2023-01-04 09:54:45,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:45,967 INFO:     Epoch: 30
2023-01-04 09:54:47,535 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4488913039366404, 'Total loss': 0.4488913039366404} | train loss {'Reaction outcome loss': 0.3842878400253645, 'Total loss': 0.3842878400253645}
2023-01-04 09:54:47,535 INFO:     Found new best model at epoch 30
2023-01-04 09:54:47,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:47,536 INFO:     Epoch: 31
2023-01-04 09:54:49,076 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44279215633869173, 'Total loss': 0.44279215633869173} | train loss {'Reaction outcome loss': 0.3813405733511689, 'Total loss': 0.3813405733511689}
2023-01-04 09:54:49,076 INFO:     Found new best model at epoch 31
2023-01-04 09:54:49,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:49,077 INFO:     Epoch: 32
2023-01-04 09:54:50,644 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48613041639328003, 'Total loss': 0.48613041639328003} | train loss {'Reaction outcome loss': 0.3846736505519653, 'Total loss': 0.3846736505519653}
2023-01-04 09:54:50,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:50,645 INFO:     Epoch: 33
2023-01-04 09:54:52,200 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4593888113896052, 'Total loss': 0.4593888113896052} | train loss {'Reaction outcome loss': 0.4117634512849559, 'Total loss': 0.4117634512849559}
2023-01-04 09:54:52,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:52,200 INFO:     Epoch: 34
2023-01-04 09:54:53,774 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4669115424156189, 'Total loss': 0.4669115424156189} | train loss {'Reaction outcome loss': 0.3739823590458136, 'Total loss': 0.3739823590458136}
2023-01-04 09:54:53,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:53,774 INFO:     Epoch: 35
2023-01-04 09:54:55,346 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4499806076288223, 'Total loss': 0.4499806076288223} | train loss {'Reaction outcome loss': 0.3705151476289915, 'Total loss': 0.3705151476289915}
2023-01-04 09:54:55,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:55,346 INFO:     Epoch: 36
2023-01-04 09:54:56,906 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.450682657957077, 'Total loss': 0.450682657957077} | train loss {'Reaction outcome loss': 0.3724387570189825, 'Total loss': 0.3724387570189825}
2023-01-04 09:54:56,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:56,907 INFO:     Epoch: 37
2023-01-04 09:54:58,431 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.442748632033666, 'Total loss': 0.442748632033666} | train loss {'Reaction outcome loss': 0.36194200266280846, 'Total loss': 0.36194200266280846}
2023-01-04 09:54:58,431 INFO:     Found new best model at epoch 37
2023-01-04 09:54:58,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:58,432 INFO:     Epoch: 38
2023-01-04 09:54:59,984 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46769211093584695, 'Total loss': 0.46769211093584695} | train loss {'Reaction outcome loss': 0.3548153296937201, 'Total loss': 0.3548153296937201}
2023-01-04 09:54:59,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:54:59,984 INFO:     Epoch: 39
2023-01-04 09:55:01,523 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4653582731882731, 'Total loss': 0.4653582731882731} | train loss {'Reaction outcome loss': 0.36241905493796733, 'Total loss': 0.36241905493796733}
2023-01-04 09:55:01,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:01,523 INFO:     Epoch: 40
2023-01-04 09:55:03,089 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4549270580212275, 'Total loss': 0.4549270580212275} | train loss {'Reaction outcome loss': 0.37550423509083636, 'Total loss': 0.37550423509083636}
2023-01-04 09:55:03,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:03,089 INFO:     Epoch: 41
2023-01-04 09:55:04,655 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4316255211830139, 'Total loss': 0.4316255211830139} | train loss {'Reaction outcome loss': 0.3526895310463168, 'Total loss': 0.3526895310463168}
2023-01-04 09:55:04,655 INFO:     Found new best model at epoch 41
2023-01-04 09:55:04,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:04,656 INFO:     Epoch: 42
2023-01-04 09:55:06,223 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4607890476783117, 'Total loss': 0.4607890476783117} | train loss {'Reaction outcome loss': 0.352459379080413, 'Total loss': 0.352459379080413}
2023-01-04 09:55:06,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:06,224 INFO:     Epoch: 43
2023-01-04 09:55:07,757 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4402653912703196, 'Total loss': 0.4402653912703196} | train loss {'Reaction outcome loss': 0.34600949794074276, 'Total loss': 0.34600949794074276}
2023-01-04 09:55:07,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:07,758 INFO:     Epoch: 44
2023-01-04 09:55:09,318 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.426341383655866, 'Total loss': 0.426341383655866} | train loss {'Reaction outcome loss': 0.34469355906027055, 'Total loss': 0.34469355906027055}
2023-01-04 09:55:09,319 INFO:     Found new best model at epoch 44
2023-01-04 09:55:09,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:09,320 INFO:     Epoch: 45
2023-01-04 09:55:10,849 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43330515225728355, 'Total loss': 0.43330515225728355} | train loss {'Reaction outcome loss': 0.34236504063955037, 'Total loss': 0.34236504063955037}
2023-01-04 09:55:10,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:10,849 INFO:     Epoch: 46
2023-01-04 09:55:12,423 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4386808047691981, 'Total loss': 0.4386808047691981} | train loss {'Reaction outcome loss': 0.34108875328282645, 'Total loss': 0.34108875328282645}
2023-01-04 09:55:12,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:12,424 INFO:     Epoch: 47
2023-01-04 09:55:13,998 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45949799517790474, 'Total loss': 0.45949799517790474} | train loss {'Reaction outcome loss': 0.3466758494521829, 'Total loss': 0.3466758494521829}
2023-01-04 09:55:13,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:13,999 INFO:     Epoch: 48
2023-01-04 09:55:15,571 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43542139331499735, 'Total loss': 0.43542139331499735} | train loss {'Reaction outcome loss': 0.3808783212831865, 'Total loss': 0.3808783212831865}
2023-01-04 09:55:15,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:15,571 INFO:     Epoch: 49
2023-01-04 09:55:17,124 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4398746649424235, 'Total loss': 0.4398746649424235} | train loss {'Reaction outcome loss': 0.33967234981178807, 'Total loss': 0.33967234981178807}
2023-01-04 09:55:17,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:17,125 INFO:     Epoch: 50
2023-01-04 09:55:18,709 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43703483740488686, 'Total loss': 0.43703483740488686} | train loss {'Reaction outcome loss': 0.33393154171821865, 'Total loss': 0.33393154171821865}
2023-01-04 09:55:18,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:18,709 INFO:     Epoch: 51
2023-01-04 09:55:20,262 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43262874285380043, 'Total loss': 0.43262874285380043} | train loss {'Reaction outcome loss': 0.33103877388318814, 'Total loss': 0.33103877388318814}
2023-01-04 09:55:20,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:20,263 INFO:     Epoch: 52
2023-01-04 09:55:21,849 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41952317555745444, 'Total loss': 0.41952317555745444} | train loss {'Reaction outcome loss': 0.32707616445159016, 'Total loss': 0.32707616445159016}
2023-01-04 09:55:21,849 INFO:     Found new best model at epoch 52
2023-01-04 09:55:21,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:21,850 INFO:     Epoch: 53
2023-01-04 09:55:23,442 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45230795741081237, 'Total loss': 0.45230795741081237} | train loss {'Reaction outcome loss': 0.3350721692963355, 'Total loss': 0.3350721692963355}
2023-01-04 09:55:23,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:23,442 INFO:     Epoch: 54
2023-01-04 09:55:24,996 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44483258326848346, 'Total loss': 0.44483258326848346} | train loss {'Reaction outcome loss': 0.3470387747646242, 'Total loss': 0.3470387747646242}
2023-01-04 09:55:24,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:24,996 INFO:     Epoch: 55
2023-01-04 09:55:26,555 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4272780458132426, 'Total loss': 0.4272780458132426} | train loss {'Reaction outcome loss': 0.3555613455389613, 'Total loss': 0.3555613455389613}
2023-01-04 09:55:26,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:26,557 INFO:     Epoch: 56
2023-01-04 09:55:28,124 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44973981777826944, 'Total loss': 0.44973981777826944} | train loss {'Reaction outcome loss': 0.3258422869325116, 'Total loss': 0.3258422869325116}
2023-01-04 09:55:28,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:28,124 INFO:     Epoch: 57
2023-01-04 09:55:29,673 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4163842146595319, 'Total loss': 0.4163842146595319} | train loss {'Reaction outcome loss': 0.3199792941256116, 'Total loss': 0.3199792941256116}
2023-01-04 09:55:29,673 INFO:     Found new best model at epoch 57
2023-01-04 09:55:29,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:29,674 INFO:     Epoch: 58
2023-01-04 09:55:31,238 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4433218866586685, 'Total loss': 0.4433218866586685} | train loss {'Reaction outcome loss': 0.32015599188921245, 'Total loss': 0.32015599188921245}
2023-01-04 09:55:31,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:31,238 INFO:     Epoch: 59
2023-01-04 09:55:32,816 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4535630861918131, 'Total loss': 0.4535630861918131} | train loss {'Reaction outcome loss': 0.331757264940635, 'Total loss': 0.331757264940635}
2023-01-04 09:55:32,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:32,817 INFO:     Epoch: 60
2023-01-04 09:55:34,362 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4204022099574407, 'Total loss': 0.4204022099574407} | train loss {'Reaction outcome loss': 0.3238320770079567, 'Total loss': 0.3238320770079567}
2023-01-04 09:55:34,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:34,362 INFO:     Epoch: 61
2023-01-04 09:55:35,923 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42936693827311195, 'Total loss': 0.42936693827311195} | train loss {'Reaction outcome loss': 0.31972112691163196, 'Total loss': 0.31972112691163196}
2023-01-04 09:55:35,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:35,923 INFO:     Epoch: 62
2023-01-04 09:55:37,456 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4436423639456431, 'Total loss': 0.4436423639456431} | train loss {'Reaction outcome loss': 0.31577247889894666, 'Total loss': 0.31577247889894666}
2023-01-04 09:55:37,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:37,457 INFO:     Epoch: 63
2023-01-04 09:55:39,037 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46742408672968544, 'Total loss': 0.46742408672968544} | train loss {'Reaction outcome loss': 0.3096452763547134, 'Total loss': 0.3096452763547134}
2023-01-04 09:55:39,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:39,037 INFO:     Epoch: 64
2023-01-04 09:55:40,615 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44716081420580545, 'Total loss': 0.44716081420580545} | train loss {'Reaction outcome loss': 0.31546178047437273, 'Total loss': 0.31546178047437273}
2023-01-04 09:55:40,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:40,615 INFO:     Epoch: 65
2023-01-04 09:55:42,192 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4215292096138, 'Total loss': 0.4215292096138} | train loss {'Reaction outcome loss': 0.307810509161794, 'Total loss': 0.307810509161794}
2023-01-04 09:55:42,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:42,192 INFO:     Epoch: 66
2023-01-04 09:55:43,725 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43646836082140605, 'Total loss': 0.43646836082140605} | train loss {'Reaction outcome loss': 0.3067879008696131, 'Total loss': 0.3067879008696131}
2023-01-04 09:55:43,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:43,725 INFO:     Epoch: 67
2023-01-04 09:55:45,288 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44411409497261045, 'Total loss': 0.44411409497261045} | train loss {'Reaction outcome loss': 0.312488976839012, 'Total loss': 0.312488976839012}
2023-01-04 09:55:45,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:45,289 INFO:     Epoch: 68
2023-01-04 09:55:46,822 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4301956901947657, 'Total loss': 0.4301956901947657} | train loss {'Reaction outcome loss': 0.3132173236614714, 'Total loss': 0.3132173236614714}
2023-01-04 09:55:46,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:46,822 INFO:     Epoch: 69
2023-01-04 09:55:48,383 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4319398562113444, 'Total loss': 0.4319398562113444} | train loss {'Reaction outcome loss': 0.29926145315740554, 'Total loss': 0.29926145315740554}
2023-01-04 09:55:48,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:48,383 INFO:     Epoch: 70
2023-01-04 09:55:49,939 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44398928185304004, 'Total loss': 0.44398928185304004} | train loss {'Reaction outcome loss': 0.3011832729764823, 'Total loss': 0.3011832729764823}
2023-01-04 09:55:49,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:49,939 INFO:     Epoch: 71
2023-01-04 09:55:51,517 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42956364949544273, 'Total loss': 0.42956364949544273} | train loss {'Reaction outcome loss': 0.2986933192633855, 'Total loss': 0.2986933192633855}
2023-01-04 09:55:51,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:51,517 INFO:     Epoch: 72
2023-01-04 09:55:53,055 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4672453701496124, 'Total loss': 0.4672453701496124} | train loss {'Reaction outcome loss': 0.3001554641953629, 'Total loss': 0.3001554641953629}
2023-01-04 09:55:53,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:53,055 INFO:     Epoch: 73
2023-01-04 09:55:54,648 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46500290830930074, 'Total loss': 0.46500290830930074} | train loss {'Reaction outcome loss': 0.3392505163623803, 'Total loss': 0.3392505163623803}
2023-01-04 09:55:54,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:54,648 INFO:     Epoch: 74
2023-01-04 09:55:56,224 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44160266319910685, 'Total loss': 0.44160266319910685} | train loss {'Reaction outcome loss': 0.3210186036670601, 'Total loss': 0.3210186036670601}
2023-01-04 09:55:56,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:56,224 INFO:     Epoch: 75
2023-01-04 09:55:57,853 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4607537239789963, 'Total loss': 0.4607537239789963} | train loss {'Reaction outcome loss': 0.2984800779073418, 'Total loss': 0.2984800779073418}
2023-01-04 09:55:57,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:57,853 INFO:     Epoch: 76
2023-01-04 09:55:59,484 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4310286621252696, 'Total loss': 0.4310286621252696} | train loss {'Reaction outcome loss': 0.29234635099377215, 'Total loss': 0.29234635099377215}
2023-01-04 09:55:59,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:55:59,484 INFO:     Epoch: 77
2023-01-04 09:56:01,103 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5191865225632986, 'Total loss': 0.5191865225632986} | train loss {'Reaction outcome loss': 0.29318130507633305, 'Total loss': 0.29318130507633305}
2023-01-04 09:56:01,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:01,104 INFO:     Epoch: 78
2023-01-04 09:56:02,696 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4185770789782206, 'Total loss': 0.4185770789782206} | train loss {'Reaction outcome loss': 0.3218984152789336, 'Total loss': 0.3218984152789336}
2023-01-04 09:56:02,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:02,697 INFO:     Epoch: 79
2023-01-04 09:56:04,306 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43252949019273124, 'Total loss': 0.43252949019273124} | train loss {'Reaction outcome loss': 0.28265203184286214, 'Total loss': 0.28265203184286214}
2023-01-04 09:56:04,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:04,307 INFO:     Epoch: 80
2023-01-04 09:56:05,870 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41921926513314245, 'Total loss': 0.41921926513314245} | train loss {'Reaction outcome loss': 0.2826343901911784, 'Total loss': 0.2826343901911784}
2023-01-04 09:56:05,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:05,871 INFO:     Epoch: 81
2023-01-04 09:56:07,477 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41997671077648796, 'Total loss': 0.41997671077648796} | train loss {'Reaction outcome loss': 0.28345030223458445, 'Total loss': 0.28345030223458445}
2023-01-04 09:56:07,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:07,478 INFO:     Epoch: 82
2023-01-04 09:56:09,108 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45303745567798615, 'Total loss': 0.45303745567798615} | train loss {'Reaction outcome loss': 0.2838939827515919, 'Total loss': 0.2838939827515919}
2023-01-04 09:56:09,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:09,108 INFO:     Epoch: 83
2023-01-04 09:56:10,687 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4514835556348165, 'Total loss': 0.4514835556348165} | train loss {'Reaction outcome loss': 0.2801467852289046, 'Total loss': 0.2801467852289046}
2023-01-04 09:56:10,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:10,687 INFO:     Epoch: 84
2023-01-04 09:56:12,318 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41560168663660685, 'Total loss': 0.41560168663660685} | train loss {'Reaction outcome loss': 0.2823766003146876, 'Total loss': 0.2823766003146876}
2023-01-04 09:56:12,318 INFO:     Found new best model at epoch 84
2023-01-04 09:56:12,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:12,319 INFO:     Epoch: 85
2023-01-04 09:56:13,875 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42570028950770694, 'Total loss': 0.42570028950770694} | train loss {'Reaction outcome loss': 0.2779354836413826, 'Total loss': 0.2779354836413826}
2023-01-04 09:56:13,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:13,875 INFO:     Epoch: 86
2023-01-04 09:56:15,496 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4472241143385569, 'Total loss': 0.4472241143385569} | train loss {'Reaction outcome loss': 0.28966009219858685, 'Total loss': 0.28966009219858685}
2023-01-04 09:56:15,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:15,496 INFO:     Epoch: 87
2023-01-04 09:56:17,125 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4530638217926025, 'Total loss': 0.4530638217926025} | train loss {'Reaction outcome loss': 0.2797618943091104, 'Total loss': 0.2797618943091104}
2023-01-04 09:56:17,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:17,125 INFO:     Epoch: 88
2023-01-04 09:56:18,738 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46480891307195027, 'Total loss': 0.46480891307195027} | train loss {'Reaction outcome loss': 0.2749405235500898, 'Total loss': 0.2749405235500898}
2023-01-04 09:56:18,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:18,738 INFO:     Epoch: 89
2023-01-04 09:56:20,312 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43924678564071656, 'Total loss': 0.43924678564071656} | train loss {'Reaction outcome loss': 0.27463817104433186, 'Total loss': 0.27463817104433186}
2023-01-04 09:56:20,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:20,313 INFO:     Epoch: 90
2023-01-04 09:56:21,881 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40997520585854846, 'Total loss': 0.40997520585854846} | train loss {'Reaction outcome loss': 0.2725383159434558, 'Total loss': 0.2725383159434558}
2023-01-04 09:56:21,881 INFO:     Found new best model at epoch 90
2023-01-04 09:56:21,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:21,882 INFO:     Epoch: 91
2023-01-04 09:56:23,416 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4408696154753367, 'Total loss': 0.4408696154753367} | train loss {'Reaction outcome loss': 0.270074195341558, 'Total loss': 0.270074195341558}
2023-01-04 09:56:23,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:23,416 INFO:     Epoch: 92
2023-01-04 09:56:24,983 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4350166340668996, 'Total loss': 0.4350166340668996} | train loss {'Reaction outcome loss': 0.26889818054337083, 'Total loss': 0.26889818054337083}
2023-01-04 09:56:24,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:24,983 INFO:     Epoch: 93
2023-01-04 09:56:26,571 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4576115200916926, 'Total loss': 0.4576115200916926} | train loss {'Reaction outcome loss': 0.2687877984515027, 'Total loss': 0.2687877984515027}
2023-01-04 09:56:26,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:26,571 INFO:     Epoch: 94
2023-01-04 09:56:28,112 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42646150290966034, 'Total loss': 0.42646150290966034} | train loss {'Reaction outcome loss': 0.26588344096165634, 'Total loss': 0.26588344096165634}
2023-01-04 09:56:28,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:28,112 INFO:     Epoch: 95
2023-01-04 09:56:29,636 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43330553770065305, 'Total loss': 0.43330553770065305} | train loss {'Reaction outcome loss': 0.284022177124153, 'Total loss': 0.284022177124153}
2023-01-04 09:56:29,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:29,636 INFO:     Epoch: 96
2023-01-04 09:56:31,210 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44946601589520774, 'Total loss': 0.44946601589520774} | train loss {'Reaction outcome loss': 0.27975152501544537, 'Total loss': 0.27975152501544537}
2023-01-04 09:56:31,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:31,210 INFO:     Epoch: 97
2023-01-04 09:56:32,743 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45302392343680065, 'Total loss': 0.45302392343680065} | train loss {'Reaction outcome loss': 0.26245285875789914, 'Total loss': 0.26245285875789914}
2023-01-04 09:56:32,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:32,744 INFO:     Epoch: 98
2023-01-04 09:56:34,326 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4491612379749616, 'Total loss': 0.4491612379749616} | train loss {'Reaction outcome loss': 0.2659011767178342, 'Total loss': 0.2659011767178342}
2023-01-04 09:56:34,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:34,326 INFO:     Epoch: 99
2023-01-04 09:56:35,888 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43145833214124046, 'Total loss': 0.43145833214124046} | train loss {'Reaction outcome loss': 0.2803775585004284, 'Total loss': 0.2803775585004284}
2023-01-04 09:56:35,888 INFO:     Best model found after epoch 91 of 100.
2023-01-04 09:56:35,888 INFO:   Done with stage: TRAINING
2023-01-04 09:56:35,888 INFO:   Starting stage: EVALUATION
2023-01-04 09:56:36,017 INFO:   Done with stage: EVALUATION
2023-01-04 09:56:36,017 INFO: Done with stage: RUNNING SPLITS
2023-01-04 09:56:36,017 INFO: Starting stage: COMPUTE METRICS
2023-01-04 09:56:37,189 INFO: Done with stage: COMPUTE METRICS
2023-01-04 09:56:37,190 INFO: Starting stage: EXPORT RESULTS
2023-01-04 09:56:37,207 INFO:   Final results averaged over 50 folds: 
2023-01-04 09:56:37,211 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.206196           NaN  0.344018       NaN
2023-01-04 09:56:38,880 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-04 09:56:38,893 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-04 09:56:38,894 DEBUG:   interactive is False
2023-01-04 09:56:38,895 DEBUG:   platform is linux
2023-01-04 09:56:38,895 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-04 09:56:39,074 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-04 09:56:39,078 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-04 09:56:39,523 DEBUG:   Loaded backend agg version unknown.
2023-01-04 09:56:39,525 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,527 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 09:56:39,528 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,528 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 09:56:39,565 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,567 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 09:56:39,568 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,568 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 09:56:39,576 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 09:56:39,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 09:56:39,578 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,579 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,579 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 09:56:39,579 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 09:56:39,579 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 09:56:39,579 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 09:56:39,882 INFO: Done with stage: EXPORT RESULTS
2023-01-04 09:56:39,883 INFO: Starting stage: SAVE MODEL
2023-01-04 09:56:39,955 INFO: Done with stage: SAVE MODEL
2023-01-04 09:56:39,955 INFO: Wall time for program:  7798.43 seconds
