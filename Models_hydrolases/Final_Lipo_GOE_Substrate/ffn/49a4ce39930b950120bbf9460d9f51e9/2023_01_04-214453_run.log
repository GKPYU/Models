2023-01-05 10:04:16,042 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/49a4ce39930b950120bbf9460d9f51e9/2023_01_04-214453",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 5,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-05 10:04:16,049 INFO: Starting stage: BUILD FEATURIZERS
2023-01-05 10:04:16,052 INFO:   Creating esm representation model
2023-01-05 10:04:16,052 INFO:   Done esm representation model
2023-01-05 10:04:16,052 INFO: Done with stage: BUILD FEATURIZERS
2023-01-05 10:04:16,052 INFO: Starting stage: BUILDING DATASET
2023-01-05 10:04:16,107 INFO: Done with stage: BUILDING DATASET
2023-01-05 10:04:16,107 INFO: Starting stage: FEATURIZING DATA
2023-01-05 10:04:16,107 INFO:   Featurizing proteins
2023-01-05 10:04:16,109 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-05 10:04:16,147 INFO:   Loaded feature cache of size 489
2023-01-05 10:04:16,148 INFO:   Starting to pool ESM Embeddings
2023-01-05 10:04:16,290 INFO:   Featurizing molecules
2023-01-05 10:04:16,291 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-05 10:04:16,294 INFO:   Loaded feature cache of size 498
2023-01-05 10:04:17,858 INFO: Done with stage: FEATURIZING DATA
2023-01-05 10:04:17,858 INFO: Starting stage: RUNNING SPLITS
2023-01-05 10:04:17,867 INFO:   Leaving out SEQ value Fold_0
2023-01-05 10:04:17,884 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 10:04:17,884 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:04:18,601 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:04:18,601 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:04:18,679 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:04:18,680 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:04:18,680 INFO:     No hyperparam tuning for this model
2023-01-05 10:04:18,680 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:04:18,680 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:04:18,681 INFO:     None feature selector for col prot
2023-01-05 10:04:18,681 INFO:     None feature selector for col prot
2023-01-05 10:04:18,681 INFO:     None feature selector for col prot
2023-01-05 10:04:18,681 INFO:     None feature selector for col chem
2023-01-05 10:04:18,681 INFO:     None feature selector for col chem
2023-01-05 10:04:18,681 INFO:     None feature selector for col chem
2023-01-05 10:04:18,681 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:04:18,682 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:04:18,683 INFO:     Number of params in model 72901
2023-01-05 10:04:18,683 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:04:18,683 INFO:   Starting stage: TRAINING
2023-01-05 10:04:20,321 INFO:     Val loss before train {'Reaction outcome loss': 1.1615991989771526, 'Total loss': 1.1615991989771526}
2023-01-05 10:04:20,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:20,322 INFO:     Epoch: 0
2023-01-05 10:04:22,420 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9142715056737264, 'Total loss': 0.9142715056737264} | train loss {'Reaction outcome loss': 0.9276756098964712, 'Total loss': 0.9276756098964712}
2023-01-05 10:04:22,421 INFO:     Found new best model at epoch 0
2023-01-05 10:04:22,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:22,422 INFO:     Epoch: 1
2023-01-05 10:04:24,502 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.699933260679245, 'Total loss': 0.699933260679245} | train loss {'Reaction outcome loss': 0.7612147789735061, 'Total loss': 0.7612147789735061}
2023-01-05 10:04:24,503 INFO:     Found new best model at epoch 1
2023-01-05 10:04:24,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:24,504 INFO:     Epoch: 2
2023-01-05 10:04:26,584 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5775163630644481, 'Total loss': 0.5775163630644481} | train loss {'Reaction outcome loss': 0.5974984286359815, 'Total loss': 0.5974984286359815}
2023-01-05 10:04:26,585 INFO:     Found new best model at epoch 2
2023-01-05 10:04:26,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:26,586 INFO:     Epoch: 3
2023-01-05 10:04:28,738 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5611474672953288, 'Total loss': 0.5611474672953288} | train loss {'Reaction outcome loss': 0.5427737261131133, 'Total loss': 0.5427737261131133}
2023-01-05 10:04:28,739 INFO:     Found new best model at epoch 3
2023-01-05 10:04:28,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:28,741 INFO:     Epoch: 4
2023-01-05 10:04:30,879 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5497562110424041, 'Total loss': 0.5497562110424041} | train loss {'Reaction outcome loss': 0.5200175284356862, 'Total loss': 0.5200175284356862}
2023-01-05 10:04:30,879 INFO:     Found new best model at epoch 4
2023-01-05 10:04:30,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:30,881 INFO:     Epoch: 5
2023-01-05 10:04:33,130 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5450730979442596, 'Total loss': 0.5450730979442596} | train loss {'Reaction outcome loss': 0.5081102018391256, 'Total loss': 0.5081102018391256}
2023-01-05 10:04:33,130 INFO:     Found new best model at epoch 5
2023-01-05 10:04:33,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:33,132 INFO:     Epoch: 6
2023-01-05 10:04:35,257 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.552125871181488, 'Total loss': 0.552125871181488} | train loss {'Reaction outcome loss': 0.4920792048558211, 'Total loss': 0.4920792048558211}
2023-01-05 10:04:35,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:35,257 INFO:     Epoch: 7
2023-01-05 10:04:37,362 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5433758676052094, 'Total loss': 0.5433758676052094} | train loss {'Reaction outcome loss': 0.4872502462986188, 'Total loss': 0.4872502462986188}
2023-01-05 10:04:37,362 INFO:     Found new best model at epoch 7
2023-01-05 10:04:37,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:37,363 INFO:     Epoch: 8
2023-01-05 10:04:39,469 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5377716024716696, 'Total loss': 0.5377716024716696} | train loss {'Reaction outcome loss': 0.4763916265833509, 'Total loss': 0.4763916265833509}
2023-01-05 10:04:39,469 INFO:     Found new best model at epoch 8
2023-01-05 10:04:39,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:39,471 INFO:     Epoch: 9
2023-01-05 10:04:41,575 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5039436757564545, 'Total loss': 0.5039436757564545} | train loss {'Reaction outcome loss': 0.4698397399304987, 'Total loss': 0.4698397399304987}
2023-01-05 10:04:41,576 INFO:     Found new best model at epoch 9
2023-01-05 10:04:41,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:41,577 INFO:     Epoch: 10
2023-01-05 10:04:43,676 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5115480323632559, 'Total loss': 0.5115480323632559} | train loss {'Reaction outcome loss': 0.462298972757308, 'Total loss': 0.462298972757308}
2023-01-05 10:04:43,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:43,676 INFO:     Epoch: 11
2023-01-05 10:04:45,770 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49915197168787323, 'Total loss': 0.49915197168787323} | train loss {'Reaction outcome loss': 0.4597990155875028, 'Total loss': 0.4597990155875028}
2023-01-05 10:04:45,772 INFO:     Found new best model at epoch 11
2023-01-05 10:04:45,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:45,773 INFO:     Epoch: 12
2023-01-05 10:04:47,892 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5212949057420094, 'Total loss': 0.5212949057420094} | train loss {'Reaction outcome loss': 0.45304906570212744, 'Total loss': 0.45304906570212744}
2023-01-05 10:04:47,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:47,892 INFO:     Epoch: 13
2023-01-05 10:04:49,986 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4967181921005249, 'Total loss': 0.4967181921005249} | train loss {'Reaction outcome loss': 0.4491088689192311, 'Total loss': 0.4491088689192311}
2023-01-05 10:04:49,987 INFO:     Found new best model at epoch 13
2023-01-05 10:04:49,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:49,988 INFO:     Epoch: 14
2023-01-05 10:04:52,095 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5242120424906412, 'Total loss': 0.5242120424906412} | train loss {'Reaction outcome loss': 0.44865271279881724, 'Total loss': 0.44865271279881724}
2023-01-05 10:04:52,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:52,096 INFO:     Epoch: 15
2023-01-05 10:04:54,195 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5123278001944224, 'Total loss': 0.5123278001944224} | train loss {'Reaction outcome loss': 0.43623028253460977, 'Total loss': 0.43623028253460977}
2023-01-05 10:04:54,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:54,195 INFO:     Epoch: 16
2023-01-05 10:04:56,313 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5190255691607794, 'Total loss': 0.5190255691607794} | train loss {'Reaction outcome loss': 0.4395331369214879, 'Total loss': 0.4395331369214879}
2023-01-05 10:04:56,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:56,314 INFO:     Epoch: 17
2023-01-05 10:04:58,418 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4977003693580627, 'Total loss': 0.4977003693580627} | train loss {'Reaction outcome loss': 0.43388703326275063, 'Total loss': 0.43388703326275063}
2023-01-05 10:04:58,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:58,419 INFO:     Epoch: 18
2023-01-05 10:05:00,548 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5154646952946981, 'Total loss': 0.5154646952946981} | train loss {'Reaction outcome loss': 0.42828344108857513, 'Total loss': 0.42828344108857513}
2023-01-05 10:05:00,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:00,549 INFO:     Epoch: 19
2023-01-05 10:05:02,680 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49637841383616127, 'Total loss': 0.49637841383616127} | train loss {'Reaction outcome loss': 0.4267284230980681, 'Total loss': 0.4267284230980681}
2023-01-05 10:05:02,681 INFO:     Found new best model at epoch 19
2023-01-05 10:05:02,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:02,682 INFO:     Epoch: 20
2023-01-05 10:05:04,809 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5136488606532414, 'Total loss': 0.5136488606532414} | train loss {'Reaction outcome loss': 0.42377117434482436, 'Total loss': 0.42377117434482436}
2023-01-05 10:05:04,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:04,809 INFO:     Epoch: 21
2023-01-05 10:05:06,949 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5165647208690644, 'Total loss': 0.5165647208690644} | train loss {'Reaction outcome loss': 0.4188800036579698, 'Total loss': 0.4188800036579698}
2023-01-05 10:05:06,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:06,949 INFO:     Epoch: 22
2023-01-05 10:05:09,061 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.482258473833402, 'Total loss': 0.482258473833402} | train loss {'Reaction outcome loss': 0.4123057389270255, 'Total loss': 0.4123057389270255}
2023-01-05 10:05:09,063 INFO:     Found new best model at epoch 22
2023-01-05 10:05:09,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:09,064 INFO:     Epoch: 23
2023-01-05 10:05:11,179 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47840124169985454, 'Total loss': 0.47840124169985454} | train loss {'Reaction outcome loss': 0.4040534065920355, 'Total loss': 0.4040534065920355}
2023-01-05 10:05:11,179 INFO:     Found new best model at epoch 23
2023-01-05 10:05:11,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:11,180 INFO:     Epoch: 24
2023-01-05 10:05:13,291 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5005205035209656, 'Total loss': 0.5005205035209656} | train loss {'Reaction outcome loss': 0.404136983889254, 'Total loss': 0.404136983889254}
2023-01-05 10:05:13,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:13,292 INFO:     Epoch: 25
2023-01-05 10:05:15,381 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.525767344236374, 'Total loss': 0.525767344236374} | train loss {'Reaction outcome loss': 0.39753947117717275, 'Total loss': 0.39753947117717275}
2023-01-05 10:05:15,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:15,383 INFO:     Epoch: 26
2023-01-05 10:05:17,482 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4872930328051249, 'Total loss': 0.4872930328051249} | train loss {'Reaction outcome loss': 0.39501208721936404, 'Total loss': 0.39501208721936404}
2023-01-05 10:05:17,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:17,482 INFO:     Epoch: 27
2023-01-05 10:05:19,616 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5015101253986358, 'Total loss': 0.5015101253986358} | train loss {'Reaction outcome loss': 0.38546935976534097, 'Total loss': 0.38546935976534097}
2023-01-05 10:05:19,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:19,617 INFO:     Epoch: 28
2023-01-05 10:05:21,708 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.478534468387564, 'Total loss': 0.478534468387564} | train loss {'Reaction outcome loss': 0.3832848199776241, 'Total loss': 0.3832848199776241}
2023-01-05 10:05:21,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:21,709 INFO:     Epoch: 29
2023-01-05 10:05:23,833 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47673517763614653, 'Total loss': 0.47673517763614653} | train loss {'Reaction outcome loss': 0.38352698999228496, 'Total loss': 0.38352698999228496}
2023-01-05 10:05:23,833 INFO:     Found new best model at epoch 29
2023-01-05 10:05:23,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:23,835 INFO:     Epoch: 30
2023-01-05 10:05:25,922 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48049936095873513, 'Total loss': 0.48049936095873513} | train loss {'Reaction outcome loss': 0.381284094500891, 'Total loss': 0.381284094500891}
2023-01-05 10:05:25,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:25,924 INFO:     Epoch: 31
2023-01-05 10:05:28,042 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5083499898513159, 'Total loss': 0.5083499898513159} | train loss {'Reaction outcome loss': 0.37311389360017394, 'Total loss': 0.37311389360017394}
2023-01-05 10:05:28,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:28,042 INFO:     Epoch: 32
2023-01-05 10:05:30,154 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48281613091627756, 'Total loss': 0.48281613091627756} | train loss {'Reaction outcome loss': 0.3674793311091133, 'Total loss': 0.3674793311091133}
2023-01-05 10:05:30,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:30,154 INFO:     Epoch: 33
2023-01-05 10:05:32,266 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49640419085820514, 'Total loss': 0.49640419085820514} | train loss {'Reaction outcome loss': 0.36388179321428793, 'Total loss': 0.36388179321428793}
2023-01-05 10:05:32,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:32,267 INFO:     Epoch: 34
2023-01-05 10:05:34,382 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47204421162605287, 'Total loss': 0.47204421162605287} | train loss {'Reaction outcome loss': 0.36852281442382834, 'Total loss': 0.36852281442382834}
2023-01-05 10:05:34,382 INFO:     Found new best model at epoch 34
2023-01-05 10:05:34,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:34,383 INFO:     Epoch: 35
2023-01-05 10:05:36,499 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4841912349065145, 'Total loss': 0.4841912349065145} | train loss {'Reaction outcome loss': 0.353091703912059, 'Total loss': 0.353091703912059}
2023-01-05 10:05:36,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:36,500 INFO:     Epoch: 36
2023-01-05 10:05:38,603 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4470560520887375, 'Total loss': 0.4470560520887375} | train loss {'Reaction outcome loss': 0.35414987535048753, 'Total loss': 0.35414987535048753}
2023-01-05 10:05:38,603 INFO:     Found new best model at epoch 36
2023-01-05 10:05:38,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:38,604 INFO:     Epoch: 37
2023-01-05 10:05:40,712 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46292671461900076, 'Total loss': 0.46292671461900076} | train loss {'Reaction outcome loss': 0.3473054231468575, 'Total loss': 0.3473054231468575}
2023-01-05 10:05:40,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:40,712 INFO:     Epoch: 38
2023-01-05 10:05:42,826 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48942387104034424, 'Total loss': 0.48942387104034424} | train loss {'Reaction outcome loss': 0.33928911921469285, 'Total loss': 0.33928911921469285}
2023-01-05 10:05:42,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:42,827 INFO:     Epoch: 39
2023-01-05 10:05:44,934 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49775774677594503, 'Total loss': 0.49775774677594503} | train loss {'Reaction outcome loss': 0.33796384927881506, 'Total loss': 0.33796384927881506}
2023-01-05 10:05:44,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:44,934 INFO:     Epoch: 40
2023-01-05 10:05:47,023 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5029932419459026, 'Total loss': 0.5029932419459026} | train loss {'Reaction outcome loss': 0.33458365355328323, 'Total loss': 0.33458365355328323}
2023-01-05 10:05:47,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:47,023 INFO:     Epoch: 41
2023-01-05 10:05:49,122 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4593276788791021, 'Total loss': 0.4593276788791021} | train loss {'Reaction outcome loss': 0.340114920485369, 'Total loss': 0.340114920485369}
2023-01-05 10:05:49,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:49,123 INFO:     Epoch: 42
2023-01-05 10:05:51,236 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4781476298967997, 'Total loss': 0.4781476298967997} | train loss {'Reaction outcome loss': 0.32629144899956475, 'Total loss': 0.32629144899956475}
2023-01-05 10:05:51,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:51,237 INFO:     Epoch: 43
2023-01-05 10:05:53,350 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4472779686252276, 'Total loss': 0.4472779686252276} | train loss {'Reaction outcome loss': 0.3269543620747524, 'Total loss': 0.3269543620747524}
2023-01-05 10:05:53,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:53,351 INFO:     Epoch: 44
2023-01-05 10:05:55,435 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5081157962481181, 'Total loss': 0.5081157962481181} | train loss {'Reaction outcome loss': 0.326229184511162, 'Total loss': 0.326229184511162}
2023-01-05 10:05:55,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:55,435 INFO:     Epoch: 45
2023-01-05 10:05:57,566 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4551448275645574, 'Total loss': 0.4551448275645574} | train loss {'Reaction outcome loss': 0.31788485382611936, 'Total loss': 0.31788485382611936}
2023-01-05 10:05:57,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:57,566 INFO:     Epoch: 46
2023-01-05 10:05:59,715 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4572801689306895, 'Total loss': 0.4572801689306895} | train loss {'Reaction outcome loss': 0.31805710430383244, 'Total loss': 0.31805710430383244}
2023-01-05 10:05:59,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:05:59,716 INFO:     Epoch: 47
2023-01-05 10:06:01,826 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4681784768899282, 'Total loss': 0.4681784768899282} | train loss {'Reaction outcome loss': 0.3048712006964526, 'Total loss': 0.3048712006964526}
2023-01-05 10:06:01,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:01,826 INFO:     Epoch: 48
2023-01-05 10:06:03,946 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4668617198864619, 'Total loss': 0.4668617198864619} | train loss {'Reaction outcome loss': 0.3121431431709192, 'Total loss': 0.3121431431709192}
2023-01-05 10:06:03,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:03,946 INFO:     Epoch: 49
2023-01-05 10:06:06,085 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43709440032641095, 'Total loss': 0.43709440032641095} | train loss {'Reaction outcome loss': 0.3075935254385183, 'Total loss': 0.3075935254385183}
2023-01-05 10:06:06,086 INFO:     Found new best model at epoch 49
2023-01-05 10:06:06,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:06,088 INFO:     Epoch: 50
2023-01-05 10:06:07,983 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46943227052688596, 'Total loss': 0.46943227052688596} | train loss {'Reaction outcome loss': 0.30076521190204025, 'Total loss': 0.30076521190204025}
2023-01-05 10:06:07,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:07,984 INFO:     Epoch: 51
2023-01-05 10:06:10,100 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47591811219851177, 'Total loss': 0.47591811219851177} | train loss {'Reaction outcome loss': 0.2984975324363717, 'Total loss': 0.2984975324363717}
2023-01-05 10:06:10,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:10,102 INFO:     Epoch: 52
2023-01-05 10:06:12,212 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47542844414711, 'Total loss': 0.47542844414711} | train loss {'Reaction outcome loss': 0.30871389759875045, 'Total loss': 0.30871389759875045}
2023-01-05 10:06:12,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:12,212 INFO:     Epoch: 53
2023-01-05 10:06:14,329 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49722851713498434, 'Total loss': 0.49722851713498434} | train loss {'Reaction outcome loss': 0.30035761822929313, 'Total loss': 0.30035761822929313}
2023-01-05 10:06:14,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:14,330 INFO:     Epoch: 54
2023-01-05 10:06:16,448 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5059610108534495, 'Total loss': 0.5059610108534495} | train loss {'Reaction outcome loss': 0.29517547431446256, 'Total loss': 0.29517547431446256}
2023-01-05 10:06:16,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:16,449 INFO:     Epoch: 55
2023-01-05 10:06:18,559 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4667610724767049, 'Total loss': 0.4667610724767049} | train loss {'Reaction outcome loss': 0.2912755614016956, 'Total loss': 0.2912755614016956}
2023-01-05 10:06:18,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:18,560 INFO:     Epoch: 56
2023-01-05 10:06:20,679 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48519126772880555, 'Total loss': 0.48519126772880555} | train loss {'Reaction outcome loss': 0.2955235183757522, 'Total loss': 0.2955235183757522}
2023-01-05 10:06:20,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:20,679 INFO:     Epoch: 57
2023-01-05 10:06:22,775 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49566611349582673, 'Total loss': 0.49566611349582673} | train loss {'Reaction outcome loss': 0.29016702528701815, 'Total loss': 0.29016702528701815}
2023-01-05 10:06:22,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:22,777 INFO:     Epoch: 58
2023-01-05 10:06:24,883 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.510207266608874, 'Total loss': 0.510207266608874} | train loss {'Reaction outcome loss': 0.2895581717892881, 'Total loss': 0.2895581717892881}
2023-01-05 10:06:24,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:24,884 INFO:     Epoch: 59
2023-01-05 10:06:27,009 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5120335161685944, 'Total loss': 0.5120335161685944} | train loss {'Reaction outcome loss': 0.2806175977346443, 'Total loss': 0.2806175977346443}
2023-01-05 10:06:27,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:27,009 INFO:     Epoch: 60
2023-01-05 10:06:29,119 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4692047446966171, 'Total loss': 0.4692047446966171} | train loss {'Reaction outcome loss': 0.2803384691149324, 'Total loss': 0.2803384691149324}
2023-01-05 10:06:29,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:29,120 INFO:     Epoch: 61
2023-01-05 10:06:31,220 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47560375134150185, 'Total loss': 0.47560375134150185} | train loss {'Reaction outcome loss': 0.2771392814787753, 'Total loss': 0.2771392814787753}
2023-01-05 10:06:31,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:31,220 INFO:     Epoch: 62
2023-01-05 10:06:33,341 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5227943003177643, 'Total loss': 0.5227943003177643} | train loss {'Reaction outcome loss': 0.27931598451111345, 'Total loss': 0.27931598451111345}
2023-01-05 10:06:33,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:33,341 INFO:     Epoch: 63
2023-01-05 10:06:35,451 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4755309509734313, 'Total loss': 0.4755309509734313} | train loss {'Reaction outcome loss': 0.2874732762165777, 'Total loss': 0.2874732762165777}
2023-01-05 10:06:35,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:35,452 INFO:     Epoch: 64
2023-01-05 10:06:37,594 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46392787297566734, 'Total loss': 0.46392787297566734} | train loss {'Reaction outcome loss': 0.26591104151674244, 'Total loss': 0.26591104151674244}
2023-01-05 10:06:37,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:37,594 INFO:     Epoch: 65
2023-01-05 10:06:39,736 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4902884066104889, 'Total loss': 0.4902884066104889} | train loss {'Reaction outcome loss': 0.2739298024211393, 'Total loss': 0.2739298024211393}
2023-01-05 10:06:39,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:39,737 INFO:     Epoch: 66
2023-01-05 10:06:41,858 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49204756021499635, 'Total loss': 0.49204756021499635} | train loss {'Reaction outcome loss': 0.2781802023259493, 'Total loss': 0.2781802023259493}
2023-01-05 10:06:41,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:41,860 INFO:     Epoch: 67
2023-01-05 10:06:43,963 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46271410087744397, 'Total loss': 0.46271410087744397} | train loss {'Reaction outcome loss': 0.26816837713907, 'Total loss': 0.26816837713907}
2023-01-05 10:06:43,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:43,963 INFO:     Epoch: 68
2023-01-05 10:06:46,065 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48670491576194763, 'Total loss': 0.48670491576194763} | train loss {'Reaction outcome loss': 0.2603782038903717, 'Total loss': 0.2603782038903717}
2023-01-05 10:06:46,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:46,065 INFO:     Epoch: 69
2023-01-05 10:06:48,182 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4590125620365143, 'Total loss': 0.4590125620365143} | train loss {'Reaction outcome loss': 0.2629329498734448, 'Total loss': 0.2629329498734448}
2023-01-05 10:06:48,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:48,183 INFO:     Epoch: 70
2023-01-05 10:06:50,302 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5045383016268412, 'Total loss': 0.5045383016268412} | train loss {'Reaction outcome loss': 0.26499504902683224, 'Total loss': 0.26499504902683224}
2023-01-05 10:06:50,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:50,302 INFO:     Epoch: 71
2023-01-05 10:06:52,396 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5198496719201405, 'Total loss': 0.5198496719201405} | train loss {'Reaction outcome loss': 0.2718638661061669, 'Total loss': 0.2718638661061669}
2023-01-05 10:06:52,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:52,397 INFO:     Epoch: 72
2023-01-05 10:06:54,492 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.472870409488678, 'Total loss': 0.472870409488678} | train loss {'Reaction outcome loss': 0.26456907946930264, 'Total loss': 0.26456907946930264}
2023-01-05 10:06:54,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:54,493 INFO:     Epoch: 73
2023-01-05 10:06:56,611 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4944823880990346, 'Total loss': 0.4944823880990346} | train loss {'Reaction outcome loss': 0.26965702047414614, 'Total loss': 0.26965702047414614}
2023-01-05 10:06:56,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:56,612 INFO:     Epoch: 74
2023-01-05 10:06:58,747 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4504716773827871, 'Total loss': 0.4504716773827871} | train loss {'Reaction outcome loss': 0.25770370498463346, 'Total loss': 0.25770370498463346}
2023-01-05 10:06:58,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:06:58,749 INFO:     Epoch: 75
2023-01-05 10:07:00,845 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.469594144821167, 'Total loss': 0.469594144821167} | train loss {'Reaction outcome loss': 0.262328977427094, 'Total loss': 0.262328977427094}
2023-01-05 10:07:00,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:00,845 INFO:     Epoch: 76
2023-01-05 10:07:02,959 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4544034995138645, 'Total loss': 0.4544034995138645} | train loss {'Reaction outcome loss': 0.2589333275053309, 'Total loss': 0.2589333275053309}
2023-01-05 10:07:02,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:02,960 INFO:     Epoch: 77
2023-01-05 10:07:05,061 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4900314599275589, 'Total loss': 0.4900314599275589} | train loss {'Reaction outcome loss': 0.2558160395849319, 'Total loss': 0.2558160395849319}
2023-01-05 10:07:05,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:05,063 INFO:     Epoch: 78
2023-01-05 10:07:07,179 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4887846032778422, 'Total loss': 0.4887846032778422} | train loss {'Reaction outcome loss': 0.25875033458674346, 'Total loss': 0.25875033458674346}
2023-01-05 10:07:07,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:07,179 INFO:     Epoch: 79
2023-01-05 10:07:09,303 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45784886678059894, 'Total loss': 0.45784886678059894} | train loss {'Reaction outcome loss': 0.2505231946792058, 'Total loss': 0.2505231946792058}
2023-01-05 10:07:09,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:09,303 INFO:     Epoch: 80
2023-01-05 10:07:11,423 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4528373395403226, 'Total loss': 0.4528373395403226} | train loss {'Reaction outcome loss': 0.2514914476957459, 'Total loss': 0.2514914476957459}
2023-01-05 10:07:11,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:11,425 INFO:     Epoch: 81
2023-01-05 10:07:13,548 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49838467836380007, 'Total loss': 0.49838467836380007} | train loss {'Reaction outcome loss': 0.25499779199703765, 'Total loss': 0.25499779199703765}
2023-01-05 10:07:13,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:13,548 INFO:     Epoch: 82
2023-01-05 10:07:15,652 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4815507590770721, 'Total loss': 0.4815507590770721} | train loss {'Reaction outcome loss': 0.2510009020184859, 'Total loss': 0.2510009020184859}
2023-01-05 10:07:15,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:15,652 INFO:     Epoch: 83
2023-01-05 10:07:17,760 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48401554822921755, 'Total loss': 0.48401554822921755} | train loss {'Reaction outcome loss': 0.25025086843787314, 'Total loss': 0.25025086843787314}
2023-01-05 10:07:17,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:17,761 INFO:     Epoch: 84
2023-01-05 10:07:19,875 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48452492654323576, 'Total loss': 0.48452492654323576} | train loss {'Reaction outcome loss': 0.2443035107818961, 'Total loss': 0.2443035107818961}
2023-01-05 10:07:19,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:19,875 INFO:     Epoch: 85
2023-01-05 10:07:21,984 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5011428872744242, 'Total loss': 0.5011428872744242} | train loss {'Reaction outcome loss': 0.24561861556555545, 'Total loss': 0.24561861556555545}
2023-01-05 10:07:21,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:21,984 INFO:     Epoch: 86
2023-01-05 10:07:24,098 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5182960569858551, 'Total loss': 0.5182960569858551} | train loss {'Reaction outcome loss': 0.25250626829599504, 'Total loss': 0.25250626829599504}
2023-01-05 10:07:24,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:24,099 INFO:     Epoch: 87
2023-01-05 10:07:26,228 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5002518167098363, 'Total loss': 0.5002518167098363} | train loss {'Reaction outcome loss': 0.24199354136874388, 'Total loss': 0.24199354136874388}
2023-01-05 10:07:26,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:26,228 INFO:     Epoch: 88
2023-01-05 10:07:28,350 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47531212866306305, 'Total loss': 0.47531212866306305} | train loss {'Reaction outcome loss': 0.25118117029318116, 'Total loss': 0.25118117029318116}
2023-01-05 10:07:28,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:28,350 INFO:     Epoch: 89
2023-01-05 10:07:30,480 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46887968430916466, 'Total loss': 0.46887968430916466} | train loss {'Reaction outcome loss': 0.24404436378524855, 'Total loss': 0.24404436378524855}
2023-01-05 10:07:30,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:30,481 INFO:     Epoch: 90
2023-01-05 10:07:32,589 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5068440278371175, 'Total loss': 0.5068440278371175} | train loss {'Reaction outcome loss': 0.23774971369476544, 'Total loss': 0.23774971369476544}
2023-01-05 10:07:32,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:32,590 INFO:     Epoch: 91
2023-01-05 10:07:34,696 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48954584648211796, 'Total loss': 0.48954584648211796} | train loss {'Reaction outcome loss': 0.24423843758153446, 'Total loss': 0.24423843758153446}
2023-01-05 10:07:34,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:34,696 INFO:     Epoch: 92
2023-01-05 10:07:36,808 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4546600649754206, 'Total loss': 0.4546600649754206} | train loss {'Reaction outcome loss': 0.2369023138118205, 'Total loss': 0.2369023138118205}
2023-01-05 10:07:36,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:36,809 INFO:     Epoch: 93
2023-01-05 10:07:38,925 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48751637190580366, 'Total loss': 0.48751637190580366} | train loss {'Reaction outcome loss': 0.2349647561108673, 'Total loss': 0.2349647561108673}
2023-01-05 10:07:38,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:38,926 INFO:     Epoch: 94
2023-01-05 10:07:41,042 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.480169947942098, 'Total loss': 0.480169947942098} | train loss {'Reaction outcome loss': 0.24249843505275992, 'Total loss': 0.24249843505275992}
2023-01-05 10:07:41,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:41,043 INFO:     Epoch: 95
2023-01-05 10:07:43,166 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4743932008743286, 'Total loss': 0.4743932008743286} | train loss {'Reaction outcome loss': 0.23939798761418452, 'Total loss': 0.23939798761418452}
2023-01-05 10:07:43,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:43,168 INFO:     Epoch: 96
2023-01-05 10:07:45,304 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5070163766543071, 'Total loss': 0.5070163766543071} | train loss {'Reaction outcome loss': 0.2401519637391135, 'Total loss': 0.2401519637391135}
2023-01-05 10:07:45,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:45,304 INFO:     Epoch: 97
2023-01-05 10:07:47,433 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.481435098250707, 'Total loss': 0.481435098250707} | train loss {'Reaction outcome loss': 0.23611603094599184, 'Total loss': 0.23611603094599184}
2023-01-05 10:07:47,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:47,433 INFO:     Epoch: 98
2023-01-05 10:07:49,564 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47712482810020446, 'Total loss': 0.47712482810020446} | train loss {'Reaction outcome loss': 0.23567256282830795, 'Total loss': 0.23567256282830795}
2023-01-05 10:07:49,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:49,565 INFO:     Epoch: 99
2023-01-05 10:07:51,708 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4959789584080378, 'Total loss': 0.4959789584080378} | train loss {'Reaction outcome loss': 0.2256357897100322, 'Total loss': 0.2256357897100322}
2023-01-05 10:07:51,708 INFO:     Best model found after epoch 50 of 100.
2023-01-05 10:07:51,709 INFO:   Done with stage: TRAINING
2023-01-05 10:07:51,709 INFO:   Starting stage: EVALUATION
2023-01-05 10:07:51,853 INFO:   Done with stage: EVALUATION
2023-01-05 10:07:51,853 INFO:   Leaving out SEQ value Fold_1
2023-01-05 10:07:51,866 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 10:07:51,866 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:07:52,524 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:07:52,524 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:07:52,593 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:07:52,593 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:07:52,593 INFO:     No hyperparam tuning for this model
2023-01-05 10:07:52,593 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:07:52,593 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:07:52,594 INFO:     None feature selector for col prot
2023-01-05 10:07:52,594 INFO:     None feature selector for col prot
2023-01-05 10:07:52,594 INFO:     None feature selector for col prot
2023-01-05 10:07:52,595 INFO:     None feature selector for col chem
2023-01-05 10:07:52,595 INFO:     None feature selector for col chem
2023-01-05 10:07:52,595 INFO:     None feature selector for col chem
2023-01-05 10:07:52,595 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:07:52,595 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:07:52,596 INFO:     Number of params in model 72901
2023-01-05 10:07:52,599 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:07:52,600 INFO:   Starting stage: TRAINING
2023-01-05 10:07:52,660 INFO:     Val loss before train {'Reaction outcome loss': 1.1299622535705567, 'Total loss': 1.1299622535705567}
2023-01-05 10:07:52,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:52,660 INFO:     Epoch: 0
2023-01-05 10:07:54,815 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9255881468454997, 'Total loss': 0.9255881468454997} | train loss {'Reaction outcome loss': 0.9222199631773907, 'Total loss': 0.9222199631773907}
2023-01-05 10:07:54,817 INFO:     Found new best model at epoch 0
2023-01-05 10:07:54,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:54,818 INFO:     Epoch: 1
2023-01-05 10:07:56,963 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7131935477256774, 'Total loss': 0.7131935477256774} | train loss {'Reaction outcome loss': 0.7633713186478944, 'Total loss': 0.7633713186478944}
2023-01-05 10:07:56,963 INFO:     Found new best model at epoch 1
2023-01-05 10:07:56,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:56,964 INFO:     Epoch: 2
2023-01-05 10:07:59,095 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5796116093794504, 'Total loss': 0.5796116093794504} | train loss {'Reaction outcome loss': 0.5960671225211759, 'Total loss': 0.5960671225211759}
2023-01-05 10:07:59,095 INFO:     Found new best model at epoch 2
2023-01-05 10:07:59,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:07:59,096 INFO:     Epoch: 3
2023-01-05 10:08:01,225 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5958489755789439, 'Total loss': 0.5958489755789439} | train loss {'Reaction outcome loss': 0.5440453910201356, 'Total loss': 0.5440453910201356}
2023-01-05 10:08:01,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:01,226 INFO:     Epoch: 4
2023-01-05 10:08:03,328 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5461304326852162, 'Total loss': 0.5461304326852162} | train loss {'Reaction outcome loss': 0.5164941797316398, 'Total loss': 0.5164941797316398}
2023-01-05 10:08:03,328 INFO:     Found new best model at epoch 4
2023-01-05 10:08:03,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:03,330 INFO:     Epoch: 5
2023-01-05 10:08:05,446 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5372292280197144, 'Total loss': 0.5372292280197144} | train loss {'Reaction outcome loss': 0.49944540897991246, 'Total loss': 0.49944540897991246}
2023-01-05 10:08:05,448 INFO:     Found new best model at epoch 5
2023-01-05 10:08:05,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:05,449 INFO:     Epoch: 6
2023-01-05 10:08:07,579 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6183498104413351, 'Total loss': 0.6183498104413351} | train loss {'Reaction outcome loss': 0.4873747783114094, 'Total loss': 0.4873747783114094}
2023-01-05 10:08:07,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:07,579 INFO:     Epoch: 7
2023-01-05 10:08:09,709 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5602060834566752, 'Total loss': 0.5602060834566752} | train loss {'Reaction outcome loss': 0.48629137340501166, 'Total loss': 0.48629137340501166}
2023-01-05 10:08:09,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:09,709 INFO:     Epoch: 8
2023-01-05 10:08:11,829 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5733823657035828, 'Total loss': 0.5733823657035828} | train loss {'Reaction outcome loss': 0.47497039690505766, 'Total loss': 0.47497039690505766}
2023-01-05 10:08:11,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:11,830 INFO:     Epoch: 9
2023-01-05 10:08:13,964 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5392190714677175, 'Total loss': 0.5392190714677175} | train loss {'Reaction outcome loss': 0.47620775727420184, 'Total loss': 0.47620775727420184}
2023-01-05 10:08:13,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:13,964 INFO:     Epoch: 10
2023-01-05 10:08:16,092 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5086372454961141, 'Total loss': 0.5086372454961141} | train loss {'Reaction outcome loss': 0.4661305114302946, 'Total loss': 0.4661305114302946}
2023-01-05 10:08:16,092 INFO:     Found new best model at epoch 10
2023-01-05 10:08:16,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:16,094 INFO:     Epoch: 11
2023-01-05 10:08:18,225 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4935056954622269, 'Total loss': 0.4935056954622269} | train loss {'Reaction outcome loss': 0.4786177820161633, 'Total loss': 0.4786177820161633}
2023-01-05 10:08:18,226 INFO:     Found new best model at epoch 11
2023-01-05 10:08:18,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:18,227 INFO:     Epoch: 12
2023-01-05 10:08:20,379 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5264694591363271, 'Total loss': 0.5264694591363271} | train loss {'Reaction outcome loss': 0.47976937181016, 'Total loss': 0.47976937181016}
2023-01-05 10:08:20,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:20,380 INFO:     Epoch: 13
2023-01-05 10:08:22,512 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.555168158809344, 'Total loss': 0.555168158809344} | train loss {'Reaction outcome loss': 0.45362858514746895, 'Total loss': 0.45362858514746895}
2023-01-05 10:08:22,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:22,512 INFO:     Epoch: 14
2023-01-05 10:08:24,636 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5295547684033711, 'Total loss': 0.5295547684033711} | train loss {'Reaction outcome loss': 0.4462809621219766, 'Total loss': 0.4462809621219766}
2023-01-05 10:08:24,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:24,637 INFO:     Epoch: 15
2023-01-05 10:08:26,764 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5164304355780284, 'Total loss': 0.5164304355780284} | train loss {'Reaction outcome loss': 0.44471786559923837, 'Total loss': 0.44471786559923837}
2023-01-05 10:08:26,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:26,764 INFO:     Epoch: 16
2023-01-05 10:08:28,866 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5270060916741689, 'Total loss': 0.5270060916741689} | train loss {'Reaction outcome loss': 0.4477470792506052, 'Total loss': 0.4477470792506052}
2023-01-05 10:08:28,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:28,866 INFO:     Epoch: 17
2023-01-05 10:08:30,998 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5058109710613886, 'Total loss': 0.5058109710613886} | train loss {'Reaction outcome loss': 0.4806626346822747, 'Total loss': 0.4806626346822747}
2023-01-05 10:08:30,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:30,999 INFO:     Epoch: 18
2023-01-05 10:08:33,160 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4963047961393992, 'Total loss': 0.4963047961393992} | train loss {'Reaction outcome loss': 0.4325735924444482, 'Total loss': 0.4325735924444482}
2023-01-05 10:08:33,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:33,160 INFO:     Epoch: 19
2023-01-05 10:08:35,315 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47995557487010954, 'Total loss': 0.47995557487010954} | train loss {'Reaction outcome loss': 0.43062915239969024, 'Total loss': 0.43062915239969024}
2023-01-05 10:08:35,315 INFO:     Found new best model at epoch 19
2023-01-05 10:08:35,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:35,317 INFO:     Epoch: 20
2023-01-05 10:08:37,446 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5064280778169632, 'Total loss': 0.5064280778169632} | train loss {'Reaction outcome loss': 0.4471831992538511, 'Total loss': 0.4471831992538511}
2023-01-05 10:08:37,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:37,447 INFO:     Epoch: 21
2023-01-05 10:08:39,576 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5176769375801087, 'Total loss': 0.5176769375801087} | train loss {'Reaction outcome loss': 0.4259437886606632, 'Total loss': 0.4259437886606632}
2023-01-05 10:08:39,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:39,576 INFO:     Epoch: 22
2023-01-05 10:08:41,706 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4984333316485087, 'Total loss': 0.4984333316485087} | train loss {'Reaction outcome loss': 0.4190490408733055, 'Total loss': 0.4190490408733055}
2023-01-05 10:08:41,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:41,707 INFO:     Epoch: 23
2023-01-05 10:08:43,810 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5197384556134542, 'Total loss': 0.5197384556134542} | train loss {'Reaction outcome loss': 0.4141954459465932, 'Total loss': 0.4141954459465932}
2023-01-05 10:08:43,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:43,811 INFO:     Epoch: 24
2023-01-05 10:08:45,950 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.491843044757843, 'Total loss': 0.491843044757843} | train loss {'Reaction outcome loss': 0.41348213402881706, 'Total loss': 0.41348213402881706}
2023-01-05 10:08:45,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:45,950 INFO:     Epoch: 25
2023-01-05 10:08:48,101 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5241902510325114, 'Total loss': 0.5241902510325114} | train loss {'Reaction outcome loss': 0.41233913360190566, 'Total loss': 0.41233913360190566}
2023-01-05 10:08:48,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:48,102 INFO:     Epoch: 26
2023-01-05 10:08:50,207 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5199699968099594, 'Total loss': 0.5199699968099594} | train loss {'Reaction outcome loss': 0.4142350913767797, 'Total loss': 0.4142350913767797}
2023-01-05 10:08:50,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:50,207 INFO:     Epoch: 27
2023-01-05 10:08:52,325 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49174482623736065, 'Total loss': 0.49174482623736065} | train loss {'Reaction outcome loss': 0.4063234519334915, 'Total loss': 0.4063234519334915}
2023-01-05 10:08:52,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:52,325 INFO:     Epoch: 28
2023-01-05 10:08:54,465 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5001968731482823, 'Total loss': 0.5001968731482823} | train loss {'Reaction outcome loss': 0.4050947837902746, 'Total loss': 0.4050947837902746}
2023-01-05 10:08:54,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:54,466 INFO:     Epoch: 29
2023-01-05 10:08:56,597 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4742108881473541, 'Total loss': 0.4742108881473541} | train loss {'Reaction outcome loss': 0.3949722506618802, 'Total loss': 0.3949722506618802}
2023-01-05 10:08:56,597 INFO:     Found new best model at epoch 29
2023-01-05 10:08:56,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:56,599 INFO:     Epoch: 30
2023-01-05 10:08:58,759 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48954397638638814, 'Total loss': 0.48954397638638814} | train loss {'Reaction outcome loss': 0.3957172810788388, 'Total loss': 0.3957172810788388}
2023-01-05 10:08:58,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:08:58,759 INFO:     Epoch: 31
2023-01-05 10:09:00,926 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48888890544573466, 'Total loss': 0.48888890544573466} | train loss {'Reaction outcome loss': 0.3963072901942592, 'Total loss': 0.3963072901942592}
2023-01-05 10:09:00,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:00,927 INFO:     Epoch: 32
2023-01-05 10:09:03,035 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48811128437519075, 'Total loss': 0.48811128437519075} | train loss {'Reaction outcome loss': 0.42252196719788987, 'Total loss': 0.42252196719788987}
2023-01-05 10:09:03,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:03,036 INFO:     Epoch: 33
2023-01-05 10:09:05,215 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4785990317662557, 'Total loss': 0.4785990317662557} | train loss {'Reaction outcome loss': 0.3952589301203472, 'Total loss': 0.3952589301203472}
2023-01-05 10:09:05,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:05,215 INFO:     Epoch: 34
2023-01-05 10:09:07,385 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49669297138849894, 'Total loss': 0.49669297138849894} | train loss {'Reaction outcome loss': 0.40550664755637233, 'Total loss': 0.40550664755637233}
2023-01-05 10:09:07,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:07,387 INFO:     Epoch: 35
2023-01-05 10:09:09,526 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45720413128534954, 'Total loss': 0.45720413128534954} | train loss {'Reaction outcome loss': 0.3892887547288252, 'Total loss': 0.3892887547288252}
2023-01-05 10:09:09,526 INFO:     Found new best model at epoch 35
2023-01-05 10:09:09,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:09,527 INFO:     Epoch: 36
2023-01-05 10:09:11,685 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43841579705476763, 'Total loss': 0.43841579705476763} | train loss {'Reaction outcome loss': 0.39142778610297735, 'Total loss': 0.39142778610297735}
2023-01-05 10:09:11,686 INFO:     Found new best model at epoch 36
2023-01-05 10:09:11,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:11,687 INFO:     Epoch: 37
2023-01-05 10:09:13,825 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4665493647257487, 'Total loss': 0.4665493647257487} | train loss {'Reaction outcome loss': 0.38289230787009676, 'Total loss': 0.38289230787009676}
2023-01-05 10:09:13,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:13,825 INFO:     Epoch: 38
2023-01-05 10:09:15,941 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47947491705417633, 'Total loss': 0.47947491705417633} | train loss {'Reaction outcome loss': 0.37659460134918976, 'Total loss': 0.37659460134918976}
2023-01-05 10:09:15,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:15,942 INFO:     Epoch: 39
2023-01-05 10:09:18,051 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5032407144705454, 'Total loss': 0.5032407144705454} | train loss {'Reaction outcome loss': 0.37057293521818635, 'Total loss': 0.37057293521818635}
2023-01-05 10:09:18,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:18,052 INFO:     Epoch: 40
2023-01-05 10:09:20,170 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4922759036223094, 'Total loss': 0.4922759036223094} | train loss {'Reaction outcome loss': 0.3670251889363525, 'Total loss': 0.3670251889363525}
2023-01-05 10:09:20,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:20,170 INFO:     Epoch: 41
2023-01-05 10:09:22,315 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4641307950019836, 'Total loss': 0.4641307950019836} | train loss {'Reaction outcome loss': 0.36988664936085325, 'Total loss': 0.36988664936085325}
2023-01-05 10:09:22,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:22,315 INFO:     Epoch: 42
2023-01-05 10:09:24,445 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45117178559303284, 'Total loss': 0.45117178559303284} | train loss {'Reaction outcome loss': 0.36175353121876286, 'Total loss': 0.36175353121876286}
2023-01-05 10:09:24,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:24,446 INFO:     Epoch: 43
2023-01-05 10:09:26,579 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48424045642217, 'Total loss': 0.48424045642217} | train loss {'Reaction outcome loss': 0.3592732977889735, 'Total loss': 0.3592732977889735}
2023-01-05 10:09:26,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:26,579 INFO:     Epoch: 44
2023-01-05 10:09:28,681 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47316453357537586, 'Total loss': 0.47316453357537586} | train loss {'Reaction outcome loss': 0.3556703911015285, 'Total loss': 0.3556703911015285}
2023-01-05 10:09:28,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:28,682 INFO:     Epoch: 45
2023-01-05 10:09:30,784 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48473182519276936, 'Total loss': 0.48473182519276936} | train loss {'Reaction outcome loss': 0.36553043162153254, 'Total loss': 0.36553043162153254}
2023-01-05 10:09:30,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:30,784 INFO:     Epoch: 46
2023-01-05 10:09:32,917 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44844714005788167, 'Total loss': 0.44844714005788167} | train loss {'Reaction outcome loss': 0.37269953137560596, 'Total loss': 0.37269953137560596}
2023-01-05 10:09:32,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:32,917 INFO:     Epoch: 47
2023-01-05 10:09:35,052 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5050787528355917, 'Total loss': 0.5050787528355917} | train loss {'Reaction outcome loss': 0.3480560909686745, 'Total loss': 0.3480560909686745}
2023-01-05 10:09:35,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:35,053 INFO:     Epoch: 48
2023-01-05 10:09:37,173 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.469178315003713, 'Total loss': 0.469178315003713} | train loss {'Reaction outcome loss': 0.34883273988995916, 'Total loss': 0.34883273988995916}
2023-01-05 10:09:37,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:37,173 INFO:     Epoch: 49
2023-01-05 10:09:39,275 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46490691155195235, 'Total loss': 0.46490691155195235} | train loss {'Reaction outcome loss': 0.3374425748606091, 'Total loss': 0.3374425748606091}
2023-01-05 10:09:39,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:39,275 INFO:     Epoch: 50
2023-01-05 10:09:41,400 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4434482355912526, 'Total loss': 0.4434482355912526} | train loss {'Reaction outcome loss': 0.3497637771523433, 'Total loss': 0.3497637771523433}
2023-01-05 10:09:41,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:41,402 INFO:     Epoch: 51
2023-01-05 10:09:43,532 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44105643530686695, 'Total loss': 0.44105643530686695} | train loss {'Reaction outcome loss': 0.3351753905341299, 'Total loss': 0.3351753905341299}
2023-01-05 10:09:43,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:43,532 INFO:     Epoch: 52
2023-01-05 10:09:45,642 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4275769958893458, 'Total loss': 0.4275769958893458} | train loss {'Reaction outcome loss': 0.32904917592911614, 'Total loss': 0.32904917592911614}
2023-01-05 10:09:45,644 INFO:     Found new best model at epoch 52
2023-01-05 10:09:45,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:45,645 INFO:     Epoch: 53
2023-01-05 10:09:47,743 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47253185013930005, 'Total loss': 0.47253185013930005} | train loss {'Reaction outcome loss': 0.32787485702800145, 'Total loss': 0.32787485702800145}
2023-01-05 10:09:47,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:47,743 INFO:     Epoch: 54
2023-01-05 10:09:49,866 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48351500431696576, 'Total loss': 0.48351500431696576} | train loss {'Reaction outcome loss': 0.3267404161700709, 'Total loss': 0.3267404161700709}
2023-01-05 10:09:49,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:49,866 INFO:     Epoch: 55
2023-01-05 10:09:52,021 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4220375597476959, 'Total loss': 0.4220375597476959} | train loss {'Reaction outcome loss': 0.3209676573532161, 'Total loss': 0.3209676573532161}
2023-01-05 10:09:52,022 INFO:     Found new best model at epoch 55
2023-01-05 10:09:52,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:52,023 INFO:     Epoch: 56
2023-01-05 10:09:54,183 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4359939197699229, 'Total loss': 0.4359939197699229} | train loss {'Reaction outcome loss': 0.32974654389816854, 'Total loss': 0.32974654389816854}
2023-01-05 10:09:54,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:54,184 INFO:     Epoch: 57
2023-01-05 10:09:56,356 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4474993447462718, 'Total loss': 0.4474993447462718} | train loss {'Reaction outcome loss': 0.3262475191672886, 'Total loss': 0.3262475191672886}
2023-01-05 10:09:56,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:56,357 INFO:     Epoch: 58
2023-01-05 10:09:58,517 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4620814780394236, 'Total loss': 0.4620814780394236} | train loss {'Reaction outcome loss': 0.32614601199811266, 'Total loss': 0.32614601199811266}
2023-01-05 10:09:58,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:09:58,518 INFO:     Epoch: 59
2023-01-05 10:10:00,679 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44587967644135157, 'Total loss': 0.44587967644135157} | train loss {'Reaction outcome loss': 0.31844415620941185, 'Total loss': 0.31844415620941185}
2023-01-05 10:10:00,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:00,679 INFO:     Epoch: 60
2023-01-05 10:10:02,805 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47729723652203876, 'Total loss': 0.47729723652203876} | train loss {'Reaction outcome loss': 0.33684193181123695, 'Total loss': 0.33684193181123695}
2023-01-05 10:10:02,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:02,805 INFO:     Epoch: 61
2023-01-05 10:10:04,954 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4536206861337026, 'Total loss': 0.4536206861337026} | train loss {'Reaction outcome loss': 0.31260906870730926, 'Total loss': 0.31260906870730926}
2023-01-05 10:10:04,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:04,955 INFO:     Epoch: 62
2023-01-05 10:10:07,097 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4681234359741211, 'Total loss': 0.4681234359741211} | train loss {'Reaction outcome loss': 0.31219869353842206, 'Total loss': 0.31219869353842206}
2023-01-05 10:10:07,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:07,097 INFO:     Epoch: 63
2023-01-05 10:10:09,057 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45197235941886904, 'Total loss': 0.45197235941886904} | train loss {'Reaction outcome loss': 0.30722168998698285, 'Total loss': 0.30722168998698285}
2023-01-05 10:10:09,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:09,058 INFO:     Epoch: 64
2023-01-05 10:10:11,211 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45241435021162035, 'Total loss': 0.45241435021162035} | train loss {'Reaction outcome loss': 0.30895989021877723, 'Total loss': 0.30895989021877723}
2023-01-05 10:10:11,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:11,212 INFO:     Epoch: 65
2023-01-05 10:10:13,357 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44665758510430653, 'Total loss': 0.44665758510430653} | train loss {'Reaction outcome loss': 0.30585334473626985, 'Total loss': 0.30585334473626985}
2023-01-05 10:10:13,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:13,357 INFO:     Epoch: 66
2023-01-05 10:10:15,519 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46297942598660785, 'Total loss': 0.46297942598660785} | train loss {'Reaction outcome loss': 0.30755601585964987, 'Total loss': 0.30755601585964987}
2023-01-05 10:10:15,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:15,520 INFO:     Epoch: 67
2023-01-05 10:10:17,680 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45534024834632875, 'Total loss': 0.45534024834632875} | train loss {'Reaction outcome loss': 0.2999912312902186, 'Total loss': 0.2999912312902186}
2023-01-05 10:10:17,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:17,681 INFO:     Epoch: 68
2023-01-05 10:10:19,839 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4377630655964216, 'Total loss': 0.4377630655964216} | train loss {'Reaction outcome loss': 0.30258211487249564, 'Total loss': 0.30258211487249564}
2023-01-05 10:10:19,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:19,839 INFO:     Epoch: 69
2023-01-05 10:10:21,980 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4603013813495636, 'Total loss': 0.4603013813495636} | train loss {'Reaction outcome loss': 0.29821847401140933, 'Total loss': 0.29821847401140933}
2023-01-05 10:10:21,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:21,981 INFO:     Epoch: 70
2023-01-05 10:10:24,115 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4534117629130681, 'Total loss': 0.4534117629130681} | train loss {'Reaction outcome loss': 0.29749429740951344, 'Total loss': 0.29749429740951344}
2023-01-05 10:10:24,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:24,115 INFO:     Epoch: 71
2023-01-05 10:10:26,266 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45710742970307666, 'Total loss': 0.45710742970307666} | train loss {'Reaction outcome loss': 0.29851197435156157, 'Total loss': 0.29851197435156157}
2023-01-05 10:10:26,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:26,267 INFO:     Epoch: 72
2023-01-05 10:10:28,407 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4523222744464874, 'Total loss': 0.4523222744464874} | train loss {'Reaction outcome loss': 0.3012718904490981, 'Total loss': 0.3012718904490981}
2023-01-05 10:10:28,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:28,408 INFO:     Epoch: 73
2023-01-05 10:10:30,564 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48258279263973236, 'Total loss': 0.48258279263973236} | train loss {'Reaction outcome loss': 0.2931810147483307, 'Total loss': 0.2931810147483307}
2023-01-05 10:10:30,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:30,564 INFO:     Epoch: 74
2023-01-05 10:10:32,709 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4992695947488149, 'Total loss': 0.4992695947488149} | train loss {'Reaction outcome loss': 0.28998401131821744, 'Total loss': 0.28998401131821744}
2023-01-05 10:10:32,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:32,710 INFO:     Epoch: 75
2023-01-05 10:10:34,860 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46681648095448813, 'Total loss': 0.46681648095448813} | train loss {'Reaction outcome loss': 0.307829103662052, 'Total loss': 0.307829103662052}
2023-01-05 10:10:34,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:34,860 INFO:     Epoch: 76
2023-01-05 10:10:36,991 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49658248325188953, 'Total loss': 0.49658248325188953} | train loss {'Reaction outcome loss': 0.2971535572795656, 'Total loss': 0.2971535572795656}
2023-01-05 10:10:36,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:36,992 INFO:     Epoch: 77
2023-01-05 10:10:39,130 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4248527372876803, 'Total loss': 0.4248527372876803} | train loss {'Reaction outcome loss': 0.29501481401477603, 'Total loss': 0.29501481401477603}
2023-01-05 10:10:39,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:39,131 INFO:     Epoch: 78
2023-01-05 10:10:41,296 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4393779017031193, 'Total loss': 0.4393779017031193} | train loss {'Reaction outcome loss': 0.33477757297172817, 'Total loss': 0.33477757297172817}
2023-01-05 10:10:41,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:41,296 INFO:     Epoch: 79
2023-01-05 10:10:43,458 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45287246704101564, 'Total loss': 0.45287246704101564} | train loss {'Reaction outcome loss': 0.2807956790767502, 'Total loss': 0.2807956790767502}
2023-01-05 10:10:43,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:43,458 INFO:     Epoch: 80
2023-01-05 10:10:45,617 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4768161430954933, 'Total loss': 0.4768161430954933} | train loss {'Reaction outcome loss': 0.28553520455497544, 'Total loss': 0.28553520455497544}
2023-01-05 10:10:45,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:45,618 INFO:     Epoch: 81
2023-01-05 10:10:47,750 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4795747478802999, 'Total loss': 0.4795747478802999} | train loss {'Reaction outcome loss': 0.2819893465519113, 'Total loss': 0.2819893465519113}
2023-01-05 10:10:47,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:47,750 INFO:     Epoch: 82
2023-01-05 10:10:49,874 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4418021728595098, 'Total loss': 0.4418021728595098} | train loss {'Reaction outcome loss': 0.27882330725855275, 'Total loss': 0.27882330725855275}
2023-01-05 10:10:49,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:49,876 INFO:     Epoch: 83
2023-01-05 10:10:52,019 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4660417944192886, 'Total loss': 0.4660417944192886} | train loss {'Reaction outcome loss': 0.27852618897056836, 'Total loss': 0.27852618897056836}
2023-01-05 10:10:52,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:52,019 INFO:     Epoch: 84
2023-01-05 10:10:54,174 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4792656670014063, 'Total loss': 0.4792656670014063} | train loss {'Reaction outcome loss': 0.27725691760955984, 'Total loss': 0.27725691760955984}
2023-01-05 10:10:54,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:54,175 INFO:     Epoch: 85
2023-01-05 10:10:56,323 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4375499536593755, 'Total loss': 0.4375499536593755} | train loss {'Reaction outcome loss': 0.27979078846376226, 'Total loss': 0.27979078846376226}
2023-01-05 10:10:56,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:56,324 INFO:     Epoch: 86
2023-01-05 10:10:58,473 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4269535725315412, 'Total loss': 0.4269535725315412} | train loss {'Reaction outcome loss': 0.2781951388157946, 'Total loss': 0.2781951388157946}
2023-01-05 10:10:58,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:10:58,473 INFO:     Epoch: 87
2023-01-05 10:11:00,600 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46484241088231404, 'Total loss': 0.46484241088231404} | train loss {'Reaction outcome loss': 0.2747963052763911, 'Total loss': 0.2747963052763911}
2023-01-05 10:11:00,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:00,600 INFO:     Epoch: 88
2023-01-05 10:11:02,733 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4910600662231445, 'Total loss': 0.4910600662231445} | train loss {'Reaction outcome loss': 0.29711137501441914, 'Total loss': 0.29711137501441914}
2023-01-05 10:11:02,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:02,734 INFO:     Epoch: 89
2023-01-05 10:11:04,887 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46198728680610657, 'Total loss': 0.46198728680610657} | train loss {'Reaction outcome loss': 0.2745847254367275, 'Total loss': 0.2745847254367275}
2023-01-05 10:11:04,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:04,887 INFO:     Epoch: 90
2023-01-05 10:11:07,032 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41910155216852824, 'Total loss': 0.41910155216852824} | train loss {'Reaction outcome loss': 0.27189706992594176, 'Total loss': 0.27189706992594176}
2023-01-05 10:11:07,033 INFO:     Found new best model at epoch 90
2023-01-05 10:11:07,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:07,034 INFO:     Epoch: 91
2023-01-05 10:11:09,196 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.489531218012174, 'Total loss': 0.489531218012174} | train loss {'Reaction outcome loss': 0.26218859120896354, 'Total loss': 0.26218859120896354}
2023-01-05 10:11:09,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:09,197 INFO:     Epoch: 92
2023-01-05 10:11:11,323 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46717842618624367, 'Total loss': 0.46717842618624367} | train loss {'Reaction outcome loss': 0.26272344228852057, 'Total loss': 0.26272344228852057}
2023-01-05 10:11:11,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:11,323 INFO:     Epoch: 93
2023-01-05 10:11:13,491 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45347673296928404, 'Total loss': 0.45347673296928404} | train loss {'Reaction outcome loss': 0.2754365265811456, 'Total loss': 0.2754365265811456}
2023-01-05 10:11:13,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:13,491 INFO:     Epoch: 94
2023-01-05 10:11:15,628 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4701899518569311, 'Total loss': 0.4701899518569311} | train loss {'Reaction outcome loss': 0.2667582319870986, 'Total loss': 0.2667582319870986}
2023-01-05 10:11:15,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:15,629 INFO:     Epoch: 95
2023-01-05 10:11:17,787 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46711922784646354, 'Total loss': 0.46711922784646354} | train loss {'Reaction outcome loss': 0.26821882221881516, 'Total loss': 0.26821882221881516}
2023-01-05 10:11:17,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:17,787 INFO:     Epoch: 96
2023-01-05 10:11:19,929 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4639288365840912, 'Total loss': 0.4639288365840912} | train loss {'Reaction outcome loss': 0.26416708293486474, 'Total loss': 0.26416708293486474}
2023-01-05 10:11:19,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:19,929 INFO:     Epoch: 97
2023-01-05 10:11:22,084 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4723518242438634, 'Total loss': 0.4723518242438634} | train loss {'Reaction outcome loss': 0.27334797919636755, 'Total loss': 0.27334797919636755}
2023-01-05 10:11:22,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:22,086 INFO:     Epoch: 98
2023-01-05 10:11:24,215 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4805011997620265, 'Total loss': 0.4805011997620265} | train loss {'Reaction outcome loss': 0.2604973000352797, 'Total loss': 0.2604973000352797}
2023-01-05 10:11:24,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:24,215 INFO:     Epoch: 99
2023-01-05 10:11:26,368 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48960355669260025, 'Total loss': 0.48960355669260025} | train loss {'Reaction outcome loss': 0.2740991371616289, 'Total loss': 0.2740991371616289}
2023-01-05 10:11:26,368 INFO:     Best model found after epoch 91 of 100.
2023-01-05 10:11:26,368 INFO:   Done with stage: TRAINING
2023-01-05 10:11:26,368 INFO:   Starting stage: EVALUATION
2023-01-05 10:11:26,502 INFO:   Done with stage: EVALUATION
2023-01-05 10:11:26,502 INFO:   Leaving out SEQ value Fold_2
2023-01-05 10:11:26,515 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 10:11:26,515 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:11:27,169 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:11:27,169 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:11:27,238 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:11:27,238 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:11:27,239 INFO:     No hyperparam tuning for this model
2023-01-05 10:11:27,239 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:11:27,239 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:11:27,239 INFO:     None feature selector for col prot
2023-01-05 10:11:27,240 INFO:     None feature selector for col prot
2023-01-05 10:11:27,240 INFO:     None feature selector for col prot
2023-01-05 10:11:27,240 INFO:     None feature selector for col chem
2023-01-05 10:11:27,240 INFO:     None feature selector for col chem
2023-01-05 10:11:27,240 INFO:     None feature selector for col chem
2023-01-05 10:11:27,240 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:11:27,240 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:11:27,242 INFO:     Number of params in model 72901
2023-01-05 10:11:27,245 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:11:27,245 INFO:   Starting stage: TRAINING
2023-01-05 10:11:27,305 INFO:     Val loss before train {'Reaction outcome loss': 0.8840017080307007, 'Total loss': 0.8840017080307007}
2023-01-05 10:11:27,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:27,305 INFO:     Epoch: 0
2023-01-05 10:11:29,431 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7440781732400258, 'Total loss': 0.7440781732400258} | train loss {'Reaction outcome loss': 0.9420526237600911, 'Total loss': 0.9420526237600911}
2023-01-05 10:11:29,432 INFO:     Found new best model at epoch 0
2023-01-05 10:11:29,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:29,434 INFO:     Epoch: 1
2023-01-05 10:11:31,580 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5720601141452789, 'Total loss': 0.5720601141452789} | train loss {'Reaction outcome loss': 0.745863769611303, 'Total loss': 0.745863769611303}
2023-01-05 10:11:31,580 INFO:     Found new best model at epoch 1
2023-01-05 10:11:31,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:31,581 INFO:     Epoch: 2
2023-01-05 10:11:33,706 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5139675656954448, 'Total loss': 0.5139675656954448} | train loss {'Reaction outcome loss': 0.5890472970739768, 'Total loss': 0.5890472970739768}
2023-01-05 10:11:33,706 INFO:     Found new best model at epoch 2
2023-01-05 10:11:33,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:33,707 INFO:     Epoch: 3
2023-01-05 10:11:35,819 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5002994875113169, 'Total loss': 0.5002994875113169} | train loss {'Reaction outcome loss': 0.5324546446221589, 'Total loss': 0.5324546446221589}
2023-01-05 10:11:35,820 INFO:     Found new best model at epoch 3
2023-01-05 10:11:35,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:35,821 INFO:     Epoch: 4
2023-01-05 10:11:37,941 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4715338408946991, 'Total loss': 0.4715338408946991} | train loss {'Reaction outcome loss': 0.5099129543578538, 'Total loss': 0.5099129543578538}
2023-01-05 10:11:37,941 INFO:     Found new best model at epoch 4
2023-01-05 10:11:37,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:37,942 INFO:     Epoch: 5
2023-01-05 10:11:40,073 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4807817498842875, 'Total loss': 0.4807817498842875} | train loss {'Reaction outcome loss': 0.4964284941445302, 'Total loss': 0.4964284941445302}
2023-01-05 10:11:40,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:40,075 INFO:     Epoch: 6
2023-01-05 10:11:42,196 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45995481411616007, 'Total loss': 0.45995481411616007} | train loss {'Reaction outcome loss': 0.4916479223183472, 'Total loss': 0.4916479223183472}
2023-01-05 10:11:42,196 INFO:     Found new best model at epoch 6
2023-01-05 10:11:42,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:42,197 INFO:     Epoch: 7
2023-01-05 10:11:44,330 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4435956597328186, 'Total loss': 0.4435956597328186} | train loss {'Reaction outcome loss': 0.4804108846851074, 'Total loss': 0.4804108846851074}
2023-01-05 10:11:44,330 INFO:     Found new best model at epoch 7
2023-01-05 10:11:44,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:44,332 INFO:     Epoch: 8
2023-01-05 10:11:46,434 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4456770807504654, 'Total loss': 0.4456770807504654} | train loss {'Reaction outcome loss': 0.47645417532890383, 'Total loss': 0.47645417532890383}
2023-01-05 10:11:46,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:46,435 INFO:     Epoch: 9
2023-01-05 10:11:48,566 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4459587554136912, 'Total loss': 0.4459587554136912} | train loss {'Reaction outcome loss': 0.4699419225110625, 'Total loss': 0.4699419225110625}
2023-01-05 10:11:48,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:48,566 INFO:     Epoch: 10
2023-01-05 10:11:50,701 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46234264175097145, 'Total loss': 0.46234264175097145} | train loss {'Reaction outcome loss': 0.46459760658279825, 'Total loss': 0.46459760658279825}
2023-01-05 10:11:50,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:50,701 INFO:     Epoch: 11
2023-01-05 10:11:52,931 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46412648955980934, 'Total loss': 0.46412648955980934} | train loss {'Reaction outcome loss': 0.4593904644631556, 'Total loss': 0.4593904644631556}
2023-01-05 10:11:52,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:52,932 INFO:     Epoch: 12
2023-01-05 10:11:55,103 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44558059573173525, 'Total loss': 0.44558059573173525} | train loss {'Reaction outcome loss': 0.4611723184259269, 'Total loss': 0.4611723184259269}
2023-01-05 10:11:55,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:55,104 INFO:     Epoch: 13
2023-01-05 10:11:57,243 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40493485033512117, 'Total loss': 0.40493485033512117} | train loss {'Reaction outcome loss': 0.446621908377992, 'Total loss': 0.446621908377992}
2023-01-05 10:11:57,243 INFO:     Found new best model at epoch 13
2023-01-05 10:11:57,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:57,244 INFO:     Epoch: 14
2023-01-05 10:11:59,381 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43378919462362925, 'Total loss': 0.43378919462362925} | train loss {'Reaction outcome loss': 0.44175230831342893, 'Total loss': 0.44175230831342893}
2023-01-05 10:11:59,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:11:59,382 INFO:     Epoch: 15
2023-01-05 10:12:01,531 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4550250838200251, 'Total loss': 0.4550250838200251} | train loss {'Reaction outcome loss': 0.4409371099441591, 'Total loss': 0.4409371099441591}
2023-01-05 10:12:01,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:01,531 INFO:     Epoch: 16
2023-01-05 10:12:03,685 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.440214596192042, 'Total loss': 0.440214596192042} | train loss {'Reaction outcome loss': 0.43338904516214, 'Total loss': 0.43338904516214}
2023-01-05 10:12:03,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:03,686 INFO:     Epoch: 17
2023-01-05 10:12:05,827 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4385798414548238, 'Total loss': 0.4385798414548238} | train loss {'Reaction outcome loss': 0.43430229776749646, 'Total loss': 0.43430229776749646}
2023-01-05 10:12:05,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:05,827 INFO:     Epoch: 18
2023-01-05 10:12:07,980 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42142807443936664, 'Total loss': 0.42142807443936664} | train loss {'Reaction outcome loss': 0.4286272976629055, 'Total loss': 0.4286272976629055}
2023-01-05 10:12:07,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:07,981 INFO:     Epoch: 19
2023-01-05 10:12:10,124 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4167523389061292, 'Total loss': 0.4167523389061292} | train loss {'Reaction outcome loss': 0.4291221434454413, 'Total loss': 0.4291221434454413}
2023-01-05 10:12:10,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:10,125 INFO:     Epoch: 20
2023-01-05 10:12:12,226 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40635609775781634, 'Total loss': 0.40635609775781634} | train loss {'Reaction outcome loss': 0.4219925541185985, 'Total loss': 0.4219925541185985}
2023-01-05 10:12:12,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:12,227 INFO:     Epoch: 21
2023-01-05 10:12:14,337 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4616758406162262, 'Total loss': 0.4616758406162262} | train loss {'Reaction outcome loss': 0.4152262848224083, 'Total loss': 0.4152262848224083}
2023-01-05 10:12:14,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:14,337 INFO:     Epoch: 22
2023-01-05 10:12:16,499 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45342996418476106, 'Total loss': 0.45342996418476106} | train loss {'Reaction outcome loss': 0.4148230783260652, 'Total loss': 0.4148230783260652}
2023-01-05 10:12:16,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:16,501 INFO:     Epoch: 23
2023-01-05 10:12:18,597 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41711083948612215, 'Total loss': 0.41711083948612215} | train loss {'Reaction outcome loss': 0.4053377414489315, 'Total loss': 0.4053377414489315}
2023-01-05 10:12:18,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:18,597 INFO:     Epoch: 24
2023-01-05 10:12:20,720 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4337928871313731, 'Total loss': 0.4337928871313731} | train loss {'Reaction outcome loss': 0.40627142063675137, 'Total loss': 0.40627142063675137}
2023-01-05 10:12:20,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:20,721 INFO:     Epoch: 25
2023-01-05 10:12:22,831 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42581628759702045, 'Total loss': 0.42581628759702045} | train loss {'Reaction outcome loss': 0.4096587096905186, 'Total loss': 0.4096587096905186}
2023-01-05 10:12:22,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:22,831 INFO:     Epoch: 26
2023-01-05 10:12:24,920 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45307697653770446, 'Total loss': 0.45307697653770446} | train loss {'Reaction outcome loss': 0.3939804416829652, 'Total loss': 0.3939804416829652}
2023-01-05 10:12:24,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:24,920 INFO:     Epoch: 27
2023-01-05 10:12:27,006 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40081563144922255, 'Total loss': 0.40081563144922255} | train loss {'Reaction outcome loss': 0.39538596290415223, 'Total loss': 0.39538596290415223}
2023-01-05 10:12:27,007 INFO:     Found new best model at epoch 27
2023-01-05 10:12:27,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:27,008 INFO:     Epoch: 28
2023-01-05 10:12:29,172 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39585618674755096, 'Total loss': 0.39585618674755096} | train loss {'Reaction outcome loss': 0.3948792454371922, 'Total loss': 0.3948792454371922}
2023-01-05 10:12:29,172 INFO:     Found new best model at epoch 28
2023-01-05 10:12:29,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:29,173 INFO:     Epoch: 29
2023-01-05 10:12:31,287 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3978416572014491, 'Total loss': 0.3978416572014491} | train loss {'Reaction outcome loss': 0.3964667657023146, 'Total loss': 0.3964667657023146}
2023-01-05 10:12:31,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:31,287 INFO:     Epoch: 30
2023-01-05 10:12:33,395 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4144024789333344, 'Total loss': 0.4144024789333344} | train loss {'Reaction outcome loss': 0.3901973410380365, 'Total loss': 0.3901973410380365}
2023-01-05 10:12:33,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:33,396 INFO:     Epoch: 31
2023-01-05 10:12:35,541 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4591482400894165, 'Total loss': 0.4591482400894165} | train loss {'Reaction outcome loss': 0.3813460313708243, 'Total loss': 0.3813460313708243}
2023-01-05 10:12:35,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:35,541 INFO:     Epoch: 32
2023-01-05 10:12:37,654 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4235439817110697, 'Total loss': 0.4235439817110697} | train loss {'Reaction outcome loss': 0.37664943066065326, 'Total loss': 0.37664943066065326}
2023-01-05 10:12:37,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:37,655 INFO:     Epoch: 33
2023-01-05 10:12:39,765 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40311625798543294, 'Total loss': 0.40311625798543294} | train loss {'Reaction outcome loss': 0.37980991815400383, 'Total loss': 0.37980991815400383}
2023-01-05 10:12:39,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:39,766 INFO:     Epoch: 34
2023-01-05 10:12:41,900 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3785683314005534, 'Total loss': 0.3785683314005534} | train loss {'Reaction outcome loss': 0.3727586673450296, 'Total loss': 0.3727586673450296}
2023-01-05 10:12:41,900 INFO:     Found new best model at epoch 34
2023-01-05 10:12:41,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:41,902 INFO:     Epoch: 35
2023-01-05 10:12:44,016 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43856316606203716, 'Total loss': 0.43856316606203716} | train loss {'Reaction outcome loss': 0.36985250796279767, 'Total loss': 0.36985250796279767}
2023-01-05 10:12:44,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:44,017 INFO:     Epoch: 36
2023-01-05 10:12:46,125 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4187163432439168, 'Total loss': 0.4187163432439168} | train loss {'Reaction outcome loss': 0.36610184612609176, 'Total loss': 0.36610184612609176}
2023-01-05 10:12:46,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:46,126 INFO:     Epoch: 37
2023-01-05 10:12:48,250 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.383522300918897, 'Total loss': 0.383522300918897} | train loss {'Reaction outcome loss': 0.36703642898232397, 'Total loss': 0.36703642898232397}
2023-01-05 10:12:48,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:48,250 INFO:     Epoch: 38
2023-01-05 10:12:50,370 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3964995384216309, 'Total loss': 0.3964995384216309} | train loss {'Reaction outcome loss': 0.3724520607531941, 'Total loss': 0.3724520607531941}
2023-01-05 10:12:50,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:50,371 INFO:     Epoch: 39
2023-01-05 10:12:52,609 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.406299223502477, 'Total loss': 0.406299223502477} | train loss {'Reaction outcome loss': 0.36089371772904466, 'Total loss': 0.36089371772904466}
2023-01-05 10:12:52,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:52,609 INFO:     Epoch: 40
2023-01-05 10:12:54,838 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44308911859989164, 'Total loss': 0.44308911859989164} | train loss {'Reaction outcome loss': 0.35694362837685284, 'Total loss': 0.35694362837685284}
2023-01-05 10:12:54,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:54,838 INFO:     Epoch: 41
2023-01-05 10:12:57,034 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35868556102116905, 'Total loss': 0.35868556102116905} | train loss {'Reaction outcome loss': 0.3521200551168762, 'Total loss': 0.3521200551168762}
2023-01-05 10:12:57,035 INFO:     Found new best model at epoch 41
2023-01-05 10:12:57,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:57,037 INFO:     Epoch: 42
2023-01-05 10:12:59,270 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40830188741286594, 'Total loss': 0.40830188741286594} | train loss {'Reaction outcome loss': 0.35261689036758276, 'Total loss': 0.35261689036758276}
2023-01-05 10:12:59,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:12:59,271 INFO:     Epoch: 43
2023-01-05 10:13:01,496 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3998783508936564, 'Total loss': 0.3998783508936564} | train loss {'Reaction outcome loss': 0.3490690895131905, 'Total loss': 0.3490690895131905}
2023-01-05 10:13:01,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:01,496 INFO:     Epoch: 44
2023-01-05 10:13:03,714 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37591743220885593, 'Total loss': 0.37591743220885593} | train loss {'Reaction outcome loss': 0.3449601311862034, 'Total loss': 0.3449601311862034}
2023-01-05 10:13:03,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:03,715 INFO:     Epoch: 45
2023-01-05 10:13:05,904 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4167799989382426, 'Total loss': 0.4167799989382426} | train loss {'Reaction outcome loss': 0.3400572753055905, 'Total loss': 0.3400572753055905}
2023-01-05 10:13:05,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:05,905 INFO:     Epoch: 46
2023-01-05 10:13:08,117 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40077475359042486, 'Total loss': 0.40077475359042486} | train loss {'Reaction outcome loss': 0.33772090530145343, 'Total loss': 0.33772090530145343}
2023-01-05 10:13:08,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:08,118 INFO:     Epoch: 47
2023-01-05 10:13:10,234 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39277017613252, 'Total loss': 0.39277017613252} | train loss {'Reaction outcome loss': 0.3455559575019309, 'Total loss': 0.3455559575019309}
2023-01-05 10:13:10,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:10,234 INFO:     Epoch: 48
2023-01-05 10:13:12,339 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3764218010008335, 'Total loss': 0.3764218010008335} | train loss {'Reaction outcome loss': 0.3385796774668198, 'Total loss': 0.3385796774668198}
2023-01-05 10:13:12,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:12,340 INFO:     Epoch: 49
2023-01-05 10:13:14,442 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39657944440841675, 'Total loss': 0.39657944440841675} | train loss {'Reaction outcome loss': 0.3268125811251846, 'Total loss': 0.3268125811251846}
2023-01-05 10:13:14,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:14,443 INFO:     Epoch: 50
2023-01-05 10:13:16,556 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3918933431307475, 'Total loss': 0.3918933431307475} | train loss {'Reaction outcome loss': 0.325977951913637, 'Total loss': 0.325977951913637}
2023-01-05 10:13:16,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:16,556 INFO:     Epoch: 51
2023-01-05 10:13:18,650 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3755353778600693, 'Total loss': 0.3755353778600693} | train loss {'Reaction outcome loss': 0.3250717031327586, 'Total loss': 0.3250717031327586}
2023-01-05 10:13:18,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:18,650 INFO:     Epoch: 52
2023-01-05 10:13:20,761 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38936354021231334, 'Total loss': 0.38936354021231334} | train loss {'Reaction outcome loss': 0.32712297095325743, 'Total loss': 0.32712297095325743}
2023-01-05 10:13:20,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:20,762 INFO:     Epoch: 53
2023-01-05 10:13:22,906 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3863981102903684, 'Total loss': 0.3863981102903684} | train loss {'Reaction outcome loss': 0.3182887257668224, 'Total loss': 0.3182887257668224}
2023-01-05 10:13:22,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:22,906 INFO:     Epoch: 54
2023-01-05 10:13:25,026 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3763438920180003, 'Total loss': 0.3763438920180003} | train loss {'Reaction outcome loss': 0.32527217360036653, 'Total loss': 0.32527217360036653}
2023-01-05 10:13:25,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:25,026 INFO:     Epoch: 55
2023-01-05 10:13:27,165 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3969533622264862, 'Total loss': 0.3969533622264862} | train loss {'Reaction outcome loss': 0.31832258706490923, 'Total loss': 0.31832258706490923}
2023-01-05 10:13:27,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:27,166 INFO:     Epoch: 56
2023-01-05 10:13:29,290 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3748589366674423, 'Total loss': 0.3748589366674423} | train loss {'Reaction outcome loss': 0.3189853009815416, 'Total loss': 0.3189853009815416}
2023-01-05 10:13:29,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:29,291 INFO:     Epoch: 57
2023-01-05 10:13:31,408 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42681140700976056, 'Total loss': 0.42681140700976056} | train loss {'Reaction outcome loss': 0.3189925422252965, 'Total loss': 0.3189925422252965}
2023-01-05 10:13:31,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:31,409 INFO:     Epoch: 58
2023-01-05 10:13:33,524 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37613796442747116, 'Total loss': 0.37613796442747116} | train loss {'Reaction outcome loss': 0.31352179770758987, 'Total loss': 0.31352179770758987}
2023-01-05 10:13:33,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:33,524 INFO:     Epoch: 59
2023-01-05 10:13:35,639 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39624114135901134, 'Total loss': 0.39624114135901134} | train loss {'Reaction outcome loss': 0.3127409148091165, 'Total loss': 0.3127409148091165}
2023-01-05 10:13:35,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:35,639 INFO:     Epoch: 60
2023-01-05 10:13:37,765 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35459778805573783, 'Total loss': 0.35459778805573783} | train loss {'Reaction outcome loss': 0.30801312639004125, 'Total loss': 0.30801312639004125}
2023-01-05 10:13:37,766 INFO:     Found new best model at epoch 60
2023-01-05 10:13:37,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:37,767 INFO:     Epoch: 61
2023-01-05 10:13:39,854 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36496766209602355, 'Total loss': 0.36496766209602355} | train loss {'Reaction outcome loss': 0.3004974868338909, 'Total loss': 0.3004974868338909}
2023-01-05 10:13:39,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:39,855 INFO:     Epoch: 62
2023-01-05 10:13:41,943 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3646326253811518, 'Total loss': 0.3646326253811518} | train loss {'Reaction outcome loss': 0.30661284409626555, 'Total loss': 0.30661284409626555}
2023-01-05 10:13:41,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:41,943 INFO:     Epoch: 63
2023-01-05 10:13:44,074 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3712298115094503, 'Total loss': 0.3712298115094503} | train loss {'Reaction outcome loss': 0.30645669504565043, 'Total loss': 0.30645669504565043}
2023-01-05 10:13:44,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:44,075 INFO:     Epoch: 64
2023-01-05 10:13:46,194 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3623084389915069, 'Total loss': 0.3623084389915069} | train loss {'Reaction outcome loss': 0.2988675880062319, 'Total loss': 0.2988675880062319}
2023-01-05 10:13:46,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:46,195 INFO:     Epoch: 65
2023-01-05 10:13:48,320 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36389033595720927, 'Total loss': 0.36389033595720927} | train loss {'Reaction outcome loss': 0.30573100637454187, 'Total loss': 0.30573100637454187}
2023-01-05 10:13:48,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:48,320 INFO:     Epoch: 66
2023-01-05 10:13:50,446 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37187996581196786, 'Total loss': 0.37187996581196786} | train loss {'Reaction outcome loss': 0.3038987187111247, 'Total loss': 0.3038987187111247}
2023-01-05 10:13:50,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:50,448 INFO:     Epoch: 67
2023-01-05 10:13:52,583 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3715198338031769, 'Total loss': 0.3715198338031769} | train loss {'Reaction outcome loss': 0.2955687141358635, 'Total loss': 0.2955687141358635}
2023-01-05 10:13:52,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:52,583 INFO:     Epoch: 68
2023-01-05 10:13:54,741 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3687805116176605, 'Total loss': 0.3687805116176605} | train loss {'Reaction outcome loss': 0.29111981370153217, 'Total loss': 0.29111981370153217}
2023-01-05 10:13:54,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:54,741 INFO:     Epoch: 69
2023-01-05 10:13:56,856 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3402879789471626, 'Total loss': 0.3402879789471626} | train loss {'Reaction outcome loss': 0.2910166556953731, 'Total loss': 0.2910166556953731}
2023-01-05 10:13:56,857 INFO:     Found new best model at epoch 69
2023-01-05 10:13:56,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:56,859 INFO:     Epoch: 70
2023-01-05 10:13:58,944 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37707806130250293, 'Total loss': 0.37707806130250293} | train loss {'Reaction outcome loss': 0.29353722660754716, 'Total loss': 0.29353722660754716}
2023-01-05 10:13:58,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:13:58,945 INFO:     Epoch: 71
2023-01-05 10:14:01,066 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.386926727493604, 'Total loss': 0.386926727493604} | train loss {'Reaction outcome loss': 0.2912768952031858, 'Total loss': 0.2912768952031858}
2023-01-05 10:14:01,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:01,067 INFO:     Epoch: 72
2023-01-05 10:14:03,182 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37068799237410227, 'Total loss': 0.37068799237410227} | train loss {'Reaction outcome loss': 0.2898703047692993, 'Total loss': 0.2898703047692993}
2023-01-05 10:14:03,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:03,182 INFO:     Epoch: 73
2023-01-05 10:14:05,280 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3693898727496465, 'Total loss': 0.3693898727496465} | train loss {'Reaction outcome loss': 0.2893047320867216, 'Total loss': 0.2893047320867216}
2023-01-05 10:14:05,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:05,280 INFO:     Epoch: 74
2023-01-05 10:14:07,406 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.33703287144502003, 'Total loss': 0.33703287144502003} | train loss {'Reaction outcome loss': 0.28627763589313865, 'Total loss': 0.28627763589313865}
2023-01-05 10:14:07,407 INFO:     Found new best model at epoch 74
2023-01-05 10:14:07,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:07,408 INFO:     Epoch: 75
2023-01-05 10:14:09,426 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4268441259860992, 'Total loss': 0.4268441259860992} | train loss {'Reaction outcome loss': 0.29000580452219415, 'Total loss': 0.29000580452219415}
2023-01-05 10:14:09,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:09,426 INFO:     Epoch: 76
2023-01-05 10:14:11,419 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36713095009326935, 'Total loss': 0.36713095009326935} | train loss {'Reaction outcome loss': 0.2745075406520254, 'Total loss': 0.2745075406520254}
2023-01-05 10:14:11,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:11,420 INFO:     Epoch: 77
2023-01-05 10:14:13,558 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3740303988258044, 'Total loss': 0.3740303988258044} | train loss {'Reaction outcome loss': 0.27893998813781423, 'Total loss': 0.27893998813781423}
2023-01-05 10:14:13,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:13,560 INFO:     Epoch: 78
2023-01-05 10:14:15,683 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3650385864078999, 'Total loss': 0.3650385864078999} | train loss {'Reaction outcome loss': 0.2855858474045339, 'Total loss': 0.2855858474045339}
2023-01-05 10:14:15,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:15,684 INFO:     Epoch: 79
2023-01-05 10:14:17,887 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3779427965482076, 'Total loss': 0.3779427965482076} | train loss {'Reaction outcome loss': 0.2818112560296363, 'Total loss': 0.2818112560296363}
2023-01-05 10:14:17,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:17,887 INFO:     Epoch: 80
2023-01-05 10:14:20,063 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.31608559638261796, 'Total loss': 0.31608559638261796} | train loss {'Reaction outcome loss': 0.2798781384489615, 'Total loss': 0.2798781384489615}
2023-01-05 10:14:20,064 INFO:     Found new best model at epoch 80
2023-01-05 10:14:20,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:20,066 INFO:     Epoch: 81
2023-01-05 10:14:22,256 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4066250383853912, 'Total loss': 0.4066250383853912} | train loss {'Reaction outcome loss': 0.2689932676263317, 'Total loss': 0.2689932676263317}
2023-01-05 10:14:22,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:22,256 INFO:     Epoch: 82
2023-01-05 10:14:24,380 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42529041071732837, 'Total loss': 0.42529041071732837} | train loss {'Reaction outcome loss': 0.28166336288512517, 'Total loss': 0.28166336288512517}
2023-01-05 10:14:24,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:24,381 INFO:     Epoch: 83
2023-01-05 10:14:26,500 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3987443134188652, 'Total loss': 0.3987443134188652} | train loss {'Reaction outcome loss': 0.2738843768440785, 'Total loss': 0.2738843768440785}
2023-01-05 10:14:26,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:26,500 INFO:     Epoch: 84
2023-01-05 10:14:28,595 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36418466567993163, 'Total loss': 0.36418466567993163} | train loss {'Reaction outcome loss': 0.2703442299520991, 'Total loss': 0.2703442299520991}
2023-01-05 10:14:28,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:28,595 INFO:     Epoch: 85
2023-01-05 10:14:30,701 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4001262312134107, 'Total loss': 0.4001262312134107} | train loss {'Reaction outcome loss': 0.27165892795000196, 'Total loss': 0.27165892795000196}
2023-01-05 10:14:30,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:30,703 INFO:     Epoch: 86
2023-01-05 10:14:32,837 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40196181237697604, 'Total loss': 0.40196181237697604} | train loss {'Reaction outcome loss': 0.2769434059405849, 'Total loss': 0.2769434059405849}
2023-01-05 10:14:32,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:32,837 INFO:     Epoch: 87
2023-01-05 10:14:34,939 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3937274714310964, 'Total loss': 0.3937274714310964} | train loss {'Reaction outcome loss': 0.2780197095261873, 'Total loss': 0.2780197095261873}
2023-01-05 10:14:34,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:34,940 INFO:     Epoch: 88
2023-01-05 10:14:37,051 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4428934206565221, 'Total loss': 0.4428934206565221} | train loss {'Reaction outcome loss': 0.2671839033736147, 'Total loss': 0.2671839033736147}
2023-01-05 10:14:37,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:37,053 INFO:     Epoch: 89
2023-01-05 10:14:39,168 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40384250779946645, 'Total loss': 0.40384250779946645} | train loss {'Reaction outcome loss': 0.2604905187159124, 'Total loss': 0.2604905187159124}
2023-01-05 10:14:39,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:39,168 INFO:     Epoch: 90
2023-01-05 10:14:41,293 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38813698987166084, 'Total loss': 0.38813698987166084} | train loss {'Reaction outcome loss': 0.27064658311216067, 'Total loss': 0.27064658311216067}
2023-01-05 10:14:41,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:41,293 INFO:     Epoch: 91
2023-01-05 10:14:43,382 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3868448108434677, 'Total loss': 0.3868448108434677} | train loss {'Reaction outcome loss': 0.27212304887055916, 'Total loss': 0.27212304887055916}
2023-01-05 10:14:43,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:43,383 INFO:     Epoch: 92
2023-01-05 10:14:45,506 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3535666992266973, 'Total loss': 0.3535666992266973} | train loss {'Reaction outcome loss': 0.2647155286594681, 'Total loss': 0.2647155286594681}
2023-01-05 10:14:45,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:45,506 INFO:     Epoch: 93
2023-01-05 10:14:47,623 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3531398514906565, 'Total loss': 0.3531398514906565} | train loss {'Reaction outcome loss': 0.2696158583717842, 'Total loss': 0.2696158583717842}
2023-01-05 10:14:47,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:47,624 INFO:     Epoch: 94
2023-01-05 10:14:49,734 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38030408024787904, 'Total loss': 0.38030408024787904} | train loss {'Reaction outcome loss': 0.26253376957572944, 'Total loss': 0.26253376957572944}
2023-01-05 10:14:49,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:49,734 INFO:     Epoch: 95
2023-01-05 10:14:51,835 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36577829023202263, 'Total loss': 0.36577829023202263} | train loss {'Reaction outcome loss': 0.2553209789559571, 'Total loss': 0.2553209789559571}
2023-01-05 10:14:51,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:51,835 INFO:     Epoch: 96
2023-01-05 10:14:53,924 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3718488536775112, 'Total loss': 0.3718488536775112} | train loss {'Reaction outcome loss': 0.26140800954597276, 'Total loss': 0.26140800954597276}
2023-01-05 10:14:53,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:53,925 INFO:     Epoch: 97
2023-01-05 10:14:56,076 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3621070126692454, 'Total loss': 0.3621070126692454} | train loss {'Reaction outcome loss': 0.265642177911788, 'Total loss': 0.265642177911788}
2023-01-05 10:14:56,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:56,077 INFO:     Epoch: 98
2023-01-05 10:14:58,231 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3930985550085703, 'Total loss': 0.3930985550085703} | train loss {'Reaction outcome loss': 0.2556208836281822, 'Total loss': 0.2556208836281822}
2023-01-05 10:14:58,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:14:58,232 INFO:     Epoch: 99
2023-01-05 10:15:00,396 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3622527380784353, 'Total loss': 0.3622527380784353} | train loss {'Reaction outcome loss': 0.25796549995667745, 'Total loss': 0.25796549995667745}
2023-01-05 10:15:00,398 INFO:     Best model found after epoch 81 of 100.
2023-01-05 10:15:00,398 INFO:   Done with stage: TRAINING
2023-01-05 10:15:00,398 INFO:   Starting stage: EVALUATION
2023-01-05 10:15:00,537 INFO:   Done with stage: EVALUATION
2023-01-05 10:15:00,537 INFO:   Leaving out SEQ value Fold_3
2023-01-05 10:15:00,550 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 10:15:00,550 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:15:01,199 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:15:01,199 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:15:01,269 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:15:01,269 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:15:01,269 INFO:     No hyperparam tuning for this model
2023-01-05 10:15:01,269 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:15:01,269 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:15:01,270 INFO:     None feature selector for col prot
2023-01-05 10:15:01,270 INFO:     None feature selector for col prot
2023-01-05 10:15:01,270 INFO:     None feature selector for col prot
2023-01-05 10:15:01,271 INFO:     None feature selector for col chem
2023-01-05 10:15:01,271 INFO:     None feature selector for col chem
2023-01-05 10:15:01,271 INFO:     None feature selector for col chem
2023-01-05 10:15:01,271 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:15:01,271 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:15:01,272 INFO:     Number of params in model 72901
2023-01-05 10:15:01,276 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:15:01,276 INFO:   Starting stage: TRAINING
2023-01-05 10:15:01,335 INFO:     Val loss before train {'Reaction outcome loss': 0.9578212102254232, 'Total loss': 0.9578212102254232}
2023-01-05 10:15:01,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:01,335 INFO:     Epoch: 0
2023-01-05 10:15:03,494 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.798195892572403, 'Total loss': 0.798195892572403} | train loss {'Reaction outcome loss': 0.9417904034639016, 'Total loss': 0.9417904034639016}
2023-01-05 10:15:03,494 INFO:     Found new best model at epoch 0
2023-01-05 10:15:03,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:03,495 INFO:     Epoch: 1
2023-01-05 10:15:05,637 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.598733764886856, 'Total loss': 0.598733764886856} | train loss {'Reaction outcome loss': 0.7641966140968895, 'Total loss': 0.7641966140968895}
2023-01-05 10:15:05,637 INFO:     Found new best model at epoch 1
2023-01-05 10:15:05,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:05,638 INFO:     Epoch: 2
2023-01-05 10:15:07,781 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4999860008557638, 'Total loss': 0.4999860008557638} | train loss {'Reaction outcome loss': 0.5991345802287915, 'Total loss': 0.5991345802287915}
2023-01-05 10:15:07,782 INFO:     Found new best model at epoch 2
2023-01-05 10:15:07,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:07,784 INFO:     Epoch: 3
2023-01-05 10:15:09,935 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.468614665667216, 'Total loss': 0.468614665667216} | train loss {'Reaction outcome loss': 0.5451445390125771, 'Total loss': 0.5451445390125771}
2023-01-05 10:15:09,935 INFO:     Found new best model at epoch 3
2023-01-05 10:15:09,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:09,937 INFO:     Epoch: 4
2023-01-05 10:15:12,076 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4919526636600494, 'Total loss': 0.4919526636600494} | train loss {'Reaction outcome loss': 0.5206518519274045, 'Total loss': 0.5206518519274045}
2023-01-05 10:15:12,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:12,077 INFO:     Epoch: 5
2023-01-05 10:15:14,148 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44843089977900186, 'Total loss': 0.44843089977900186} | train loss {'Reaction outcome loss': 0.5077697338857057, 'Total loss': 0.5077697338857057}
2023-01-05 10:15:14,148 INFO:     Found new best model at epoch 5
2023-01-05 10:15:14,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:14,149 INFO:     Epoch: 6
2023-01-05 10:15:16,245 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43873392542203266, 'Total loss': 0.43873392542203266} | train loss {'Reaction outcome loss': 0.4976537719423518, 'Total loss': 0.4976537719423518}
2023-01-05 10:15:16,245 INFO:     Found new best model at epoch 6
2023-01-05 10:15:16,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:16,246 INFO:     Epoch: 7
2023-01-05 10:15:18,365 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4510020593802134, 'Total loss': 0.4510020593802134} | train loss {'Reaction outcome loss': 0.49461707052512044, 'Total loss': 0.49461707052512044}
2023-01-05 10:15:18,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:18,366 INFO:     Epoch: 8
2023-01-05 10:15:20,494 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46568798025449115, 'Total loss': 0.46568798025449115} | train loss {'Reaction outcome loss': 0.48885448817368393, 'Total loss': 0.48885448817368393}
2023-01-05 10:15:20,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:20,494 INFO:     Epoch: 9
2023-01-05 10:15:22,586 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43713947931925456, 'Total loss': 0.43713947931925456} | train loss {'Reaction outcome loss': 0.4752198168155038, 'Total loss': 0.4752198168155038}
2023-01-05 10:15:22,586 INFO:     Found new best model at epoch 9
2023-01-05 10:15:22,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:22,587 INFO:     Epoch: 10
2023-01-05 10:15:24,698 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47839967012405393, 'Total loss': 0.47839967012405393} | train loss {'Reaction outcome loss': 0.4707075583137872, 'Total loss': 0.4707075583137872}
2023-01-05 10:15:24,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:24,699 INFO:     Epoch: 11
2023-01-05 10:15:26,816 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45378539760907494, 'Total loss': 0.45378539760907494} | train loss {'Reaction outcome loss': 0.4677687354467727, 'Total loss': 0.4677687354467727}
2023-01-05 10:15:26,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:26,817 INFO:     Epoch: 12
2023-01-05 10:15:28,946 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4447989334662755, 'Total loss': 0.4447989334662755} | train loss {'Reaction outcome loss': 0.45879942306996263, 'Total loss': 0.45879942306996263}
2023-01-05 10:15:28,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:28,948 INFO:     Epoch: 13
2023-01-05 10:15:31,071 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45001658896605173, 'Total loss': 0.45001658896605173} | train loss {'Reaction outcome loss': 0.45575617631767695, 'Total loss': 0.45575617631767695}
2023-01-05 10:15:31,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:31,071 INFO:     Epoch: 14
2023-01-05 10:15:33,169 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48556060989697775, 'Total loss': 0.48556060989697775} | train loss {'Reaction outcome loss': 0.45087021376405445, 'Total loss': 0.45087021376405445}
2023-01-05 10:15:33,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:33,169 INFO:     Epoch: 15
2023-01-05 10:15:35,261 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4413574725389481, 'Total loss': 0.4413574725389481} | train loss {'Reaction outcome loss': 0.44612603937531564, 'Total loss': 0.44612603937531564}
2023-01-05 10:15:35,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:35,262 INFO:     Epoch: 16
2023-01-05 10:15:37,368 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44333606759707134, 'Total loss': 0.44333606759707134} | train loss {'Reaction outcome loss': 0.43922931842860724, 'Total loss': 0.43922931842860724}
2023-01-05 10:15:37,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:37,368 INFO:     Epoch: 17
2023-01-05 10:15:39,479 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4208770483732224, 'Total loss': 0.4208770483732224} | train loss {'Reaction outcome loss': 0.4412967406022243, 'Total loss': 0.4412967406022243}
2023-01-05 10:15:39,479 INFO:     Found new best model at epoch 17
2023-01-05 10:15:39,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:39,480 INFO:     Epoch: 18
2023-01-05 10:15:41,584 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45525925755500796, 'Total loss': 0.45525925755500796} | train loss {'Reaction outcome loss': 0.4354568357978548, 'Total loss': 0.4354568357978548}
2023-01-05 10:15:41,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:41,585 INFO:     Epoch: 19
2023-01-05 10:15:43,694 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4331020404895147, 'Total loss': 0.4331020404895147} | train loss {'Reaction outcome loss': 0.43333008317720323, 'Total loss': 0.43333008317720323}
2023-01-05 10:15:43,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:43,694 INFO:     Epoch: 20
2023-01-05 10:15:45,817 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43500523269176483, 'Total loss': 0.43500523269176483} | train loss {'Reaction outcome loss': 0.41806436750369197, 'Total loss': 0.41806436750369197}
2023-01-05 10:15:45,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:45,818 INFO:     Epoch: 21
2023-01-05 10:15:47,908 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4375136137008667, 'Total loss': 0.4375136137008667} | train loss {'Reaction outcome loss': 0.4223009087008871, 'Total loss': 0.4223009087008871}
2023-01-05 10:15:47,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:47,908 INFO:     Epoch: 22
2023-01-05 10:15:50,040 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43135473132133484, 'Total loss': 0.43135473132133484} | train loss {'Reaction outcome loss': 0.4138120107161693, 'Total loss': 0.4138120107161693}
2023-01-05 10:15:50,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:50,041 INFO:     Epoch: 23
2023-01-05 10:15:52,167 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4216612073282401, 'Total loss': 0.4216612073282401} | train loss {'Reaction outcome loss': 0.41197894765200577, 'Total loss': 0.41197894765200577}
2023-01-05 10:15:52,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:52,169 INFO:     Epoch: 24
2023-01-05 10:15:54,265 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.458584259947141, 'Total loss': 0.458584259947141} | train loss {'Reaction outcome loss': 0.40349108305497045, 'Total loss': 0.40349108305497045}
2023-01-05 10:15:54,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:54,266 INFO:     Epoch: 25
2023-01-05 10:15:56,386 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42179036935170494, 'Total loss': 0.42179036935170494} | train loss {'Reaction outcome loss': 0.4093580174195024, 'Total loss': 0.4093580174195024}
2023-01-05 10:15:56,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:56,386 INFO:     Epoch: 26
2023-01-05 10:15:58,466 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47220725814501446, 'Total loss': 0.47220725814501446} | train loss {'Reaction outcome loss': 0.4013120154048497, 'Total loss': 0.4013120154048497}
2023-01-05 10:15:58,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:15:58,467 INFO:     Epoch: 27
2023-01-05 10:16:00,562 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45424477209647496, 'Total loss': 0.45424477209647496} | train loss {'Reaction outcome loss': 0.39437384270268044, 'Total loss': 0.39437384270268044}
2023-01-05 10:16:00,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:00,562 INFO:     Epoch: 28
2023-01-05 10:16:02,665 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42434298396110537, 'Total loss': 0.42434298396110537} | train loss {'Reaction outcome loss': 0.394652936566662, 'Total loss': 0.394652936566662}
2023-01-05 10:16:02,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:02,666 INFO:     Epoch: 29
2023-01-05 10:16:04,772 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4152089094122251, 'Total loss': 0.4152089094122251} | train loss {'Reaction outcome loss': 0.3890824743679592, 'Total loss': 0.3890824743679592}
2023-01-05 10:16:04,773 INFO:     Found new best model at epoch 29
2023-01-05 10:16:04,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:04,775 INFO:     Epoch: 30
2023-01-05 10:16:06,857 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44355701506137846, 'Total loss': 0.44355701506137846} | train loss {'Reaction outcome loss': 0.3889367811709315, 'Total loss': 0.3889367811709315}
2023-01-05 10:16:06,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:06,858 INFO:     Epoch: 31
2023-01-05 10:16:08,944 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4271568149328232, 'Total loss': 0.4271568149328232} | train loss {'Reaction outcome loss': 0.37957493797108366, 'Total loss': 0.37957493797108366}
2023-01-05 10:16:08,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:08,945 INFO:     Epoch: 32
2023-01-05 10:16:11,038 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4402446101109187, 'Total loss': 0.4402446101109187} | train loss {'Reaction outcome loss': 0.37505941414325444, 'Total loss': 0.37505941414325444}
2023-01-05 10:16:11,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:11,039 INFO:     Epoch: 33
2023-01-05 10:16:13,141 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4205574691295624, 'Total loss': 0.4205574691295624} | train loss {'Reaction outcome loss': 0.3706098318973304, 'Total loss': 0.3706098318973304}
2023-01-05 10:16:13,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:13,141 INFO:     Epoch: 34
2023-01-05 10:16:15,251 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41872118016084037, 'Total loss': 0.41872118016084037} | train loss {'Reaction outcome loss': 0.3712963258417753, 'Total loss': 0.3712963258417753}
2023-01-05 10:16:15,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:15,252 INFO:     Epoch: 35
2023-01-05 10:16:17,346 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4185914253195127, 'Total loss': 0.4185914253195127} | train loss {'Reaction outcome loss': 0.35842474298926935, 'Total loss': 0.35842474298926935}
2023-01-05 10:16:17,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:17,347 INFO:     Epoch: 36
2023-01-05 10:16:19,438 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4100164045890172, 'Total loss': 0.4100164045890172} | train loss {'Reaction outcome loss': 0.3626171381182068, 'Total loss': 0.3626171381182068}
2023-01-05 10:16:19,438 INFO:     Found new best model at epoch 36
2023-01-05 10:16:19,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:19,440 INFO:     Epoch: 37
2023-01-05 10:16:21,534 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.418631441394488, 'Total loss': 0.418631441394488} | train loss {'Reaction outcome loss': 0.36192629794716397, 'Total loss': 0.36192629794716397}
2023-01-05 10:16:21,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:21,534 INFO:     Epoch: 38
2023-01-05 10:16:23,655 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40800405939420065, 'Total loss': 0.40800405939420065} | train loss {'Reaction outcome loss': 0.3624129943795257, 'Total loss': 0.3624129943795257}
2023-01-05 10:16:23,656 INFO:     Found new best model at epoch 38
2023-01-05 10:16:23,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:23,658 INFO:     Epoch: 39
2023-01-05 10:16:25,749 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4244440267483393, 'Total loss': 0.4244440267483393} | train loss {'Reaction outcome loss': 0.35414527254281464, 'Total loss': 0.35414527254281464}
2023-01-05 10:16:25,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:25,749 INFO:     Epoch: 40
2023-01-05 10:16:27,864 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4326827396949132, 'Total loss': 0.4326827396949132} | train loss {'Reaction outcome loss': 0.35100533594906114, 'Total loss': 0.35100533594906114}
2023-01-05 10:16:27,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:27,865 INFO:     Epoch: 41
2023-01-05 10:16:29,944 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41507983605066934, 'Total loss': 0.41507983605066934} | train loss {'Reaction outcome loss': 0.34948064163054304, 'Total loss': 0.34948064163054304}
2023-01-05 10:16:29,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:29,945 INFO:     Epoch: 42
2023-01-05 10:16:32,068 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4309729993343353, 'Total loss': 0.4309729993343353} | train loss {'Reaction outcome loss': 0.3464796918379518, 'Total loss': 0.3464796918379518}
2023-01-05 10:16:32,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:32,069 INFO:     Epoch: 43
2023-01-05 10:16:34,175 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4197150141000748, 'Total loss': 0.4197150141000748} | train loss {'Reaction outcome loss': 0.3377438852147305, 'Total loss': 0.3377438852147305}
2023-01-05 10:16:34,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:34,176 INFO:     Epoch: 44
2023-01-05 10:16:36,252 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43026671012242634, 'Total loss': 0.43026671012242634} | train loss {'Reaction outcome loss': 0.34092254485276563, 'Total loss': 0.34092254485276563}
2023-01-05 10:16:36,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:36,253 INFO:     Epoch: 45
2023-01-05 10:16:38,368 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43359852135181426, 'Total loss': 0.43359852135181426} | train loss {'Reaction outcome loss': 0.3316244817042089, 'Total loss': 0.3316244817042089}
2023-01-05 10:16:38,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:38,368 INFO:     Epoch: 46
2023-01-05 10:16:40,485 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3971944848696391, 'Total loss': 0.3971944848696391} | train loss {'Reaction outcome loss': 0.33181201008868305, 'Total loss': 0.33181201008868305}
2023-01-05 10:16:40,485 INFO:     Found new best model at epoch 46
2023-01-05 10:16:40,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:40,486 INFO:     Epoch: 47
2023-01-05 10:16:42,628 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43542131384213767, 'Total loss': 0.43542131384213767} | train loss {'Reaction outcome loss': 0.320356665035853, 'Total loss': 0.320356665035853}
2023-01-05 10:16:42,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:42,630 INFO:     Epoch: 48
2023-01-05 10:16:44,753 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39207944919665655, 'Total loss': 0.39207944919665655} | train loss {'Reaction outcome loss': 0.3272258085591016, 'Total loss': 0.3272258085591016}
2023-01-05 10:16:44,754 INFO:     Found new best model at epoch 48
2023-01-05 10:16:44,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:44,755 INFO:     Epoch: 49
2023-01-05 10:16:46,863 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4171724324425062, 'Total loss': 0.4171724324425062} | train loss {'Reaction outcome loss': 0.31869213354019893, 'Total loss': 0.31869213354019893}
2023-01-05 10:16:46,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:46,865 INFO:     Epoch: 50
2023-01-05 10:16:48,972 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42108386754989624, 'Total loss': 0.42108386754989624} | train loss {'Reaction outcome loss': 0.31699512080176845, 'Total loss': 0.31699512080176845}
2023-01-05 10:16:48,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:48,972 INFO:     Epoch: 51
2023-01-05 10:16:51,116 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38687645296255746, 'Total loss': 0.38687645296255746} | train loss {'Reaction outcome loss': 0.3170569955538481, 'Total loss': 0.3170569955538481}
2023-01-05 10:16:51,117 INFO:     Found new best model at epoch 51
2023-01-05 10:16:51,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:51,118 INFO:     Epoch: 52
2023-01-05 10:16:53,244 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41460213661193845, 'Total loss': 0.41460213661193845} | train loss {'Reaction outcome loss': 0.31080395489890167, 'Total loss': 0.31080395489890167}
2023-01-05 10:16:53,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:53,245 INFO:     Epoch: 53
2023-01-05 10:16:55,374 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36756223924458026, 'Total loss': 0.36756223924458026} | train loss {'Reaction outcome loss': 0.3129917409530271, 'Total loss': 0.3129917409530271}
2023-01-05 10:16:55,374 INFO:     Found new best model at epoch 53
2023-01-05 10:16:55,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:55,376 INFO:     Epoch: 54
2023-01-05 10:16:57,500 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4432470053434372, 'Total loss': 0.4432470053434372} | train loss {'Reaction outcome loss': 0.3070164483054217, 'Total loss': 0.3070164483054217}
2023-01-05 10:16:57,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:57,500 INFO:     Epoch: 55
2023-01-05 10:16:59,643 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.414755708972613, 'Total loss': 0.414755708972613} | train loss {'Reaction outcome loss': 0.3173099505159008, 'Total loss': 0.3173099505159008}
2023-01-05 10:16:59,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:16:59,644 INFO:     Epoch: 56
2023-01-05 10:17:01,778 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3742271115382512, 'Total loss': 0.3742271115382512} | train loss {'Reaction outcome loss': 0.2974379368385662, 'Total loss': 0.2974379368385662}
2023-01-05 10:17:01,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:01,778 INFO:     Epoch: 57
2023-01-05 10:17:03,895 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3863342703630527, 'Total loss': 0.3863342703630527} | train loss {'Reaction outcome loss': 0.3027531842670434, 'Total loss': 0.3027531842670434}
2023-01-05 10:17:03,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:03,895 INFO:     Epoch: 58
2023-01-05 10:17:06,027 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4640567461649577, 'Total loss': 0.4640567461649577} | train loss {'Reaction outcome loss': 0.2907272284993759, 'Total loss': 0.2907272284993759}
2023-01-05 10:17:06,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:06,028 INFO:     Epoch: 59
2023-01-05 10:17:08,153 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.428316205739975, 'Total loss': 0.428316205739975} | train loss {'Reaction outcome loss': 0.29911927294818474, 'Total loss': 0.29911927294818474}
2023-01-05 10:17:08,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:08,153 INFO:     Epoch: 60
2023-01-05 10:17:10,284 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4164369265238444, 'Total loss': 0.4164369265238444} | train loss {'Reaction outcome loss': 0.30241379923026857, 'Total loss': 0.30241379923026857}
2023-01-05 10:17:10,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:10,285 INFO:     Epoch: 61
2023-01-05 10:17:12,419 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.397601310412089, 'Total loss': 0.397601310412089} | train loss {'Reaction outcome loss': 0.2993821038049219, 'Total loss': 0.2993821038049219}
2023-01-05 10:17:12,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:12,420 INFO:     Epoch: 62
2023-01-05 10:17:14,517 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4008169800043106, 'Total loss': 0.4008169800043106} | train loss {'Reaction outcome loss': 0.2882329873286952, 'Total loss': 0.2882329873286952}
2023-01-05 10:17:14,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:14,518 INFO:     Epoch: 63
2023-01-05 10:17:16,611 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41789327065149945, 'Total loss': 0.41789327065149945} | train loss {'Reaction outcome loss': 0.28690114819304846, 'Total loss': 0.28690114819304846}
2023-01-05 10:17:16,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:16,612 INFO:     Epoch: 64
2023-01-05 10:17:18,726 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4378979126612345, 'Total loss': 0.4378979126612345} | train loss {'Reaction outcome loss': 0.28695260851401766, 'Total loss': 0.28695260851401766}
2023-01-05 10:17:18,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:18,726 INFO:     Epoch: 65
2023-01-05 10:17:20,841 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3675493512302637, 'Total loss': 0.3675493512302637} | train loss {'Reaction outcome loss': 0.28961959123720615, 'Total loss': 0.28961959123720615}
2023-01-05 10:17:20,841 INFO:     Found new best model at epoch 65
2023-01-05 10:17:20,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:20,843 INFO:     Epoch: 66
2023-01-05 10:17:22,984 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4299739271402359, 'Total loss': 0.4299739271402359} | train loss {'Reaction outcome loss': 0.28155023866629864, 'Total loss': 0.28155023866629864}
2023-01-05 10:17:22,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:22,985 INFO:     Epoch: 67
2023-01-05 10:17:25,124 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4591501901547114, 'Total loss': 0.4591501901547114} | train loss {'Reaction outcome loss': 0.2838635198267061, 'Total loss': 0.2838635198267061}
2023-01-05 10:17:25,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:25,124 INFO:     Epoch: 68
2023-01-05 10:17:27,255 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39775254925092063, 'Total loss': 0.39775254925092063} | train loss {'Reaction outcome loss': 0.2818836661553754, 'Total loss': 0.2818836661553754}
2023-01-05 10:17:27,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:27,255 INFO:     Epoch: 69
2023-01-05 10:17:29,345 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44354717135429383, 'Total loss': 0.44354717135429383} | train loss {'Reaction outcome loss': 0.27891802386595654, 'Total loss': 0.27891802386595654}
2023-01-05 10:17:29,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:29,346 INFO:     Epoch: 70
2023-01-05 10:17:31,468 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3759797841310501, 'Total loss': 0.3759797841310501} | train loss {'Reaction outcome loss': 0.28132022791729744, 'Total loss': 0.28132022791729744}
2023-01-05 10:17:31,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:31,468 INFO:     Epoch: 71
2023-01-05 10:17:33,618 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41039061546325684, 'Total loss': 0.41039061546325684} | train loss {'Reaction outcome loss': 0.27732432781012506, 'Total loss': 0.27732432781012506}
2023-01-05 10:17:33,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:33,620 INFO:     Epoch: 72
2023-01-05 10:17:35,754 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4077192177375158, 'Total loss': 0.4077192177375158} | train loss {'Reaction outcome loss': 0.2762074636520593, 'Total loss': 0.2762074636520593}
2023-01-05 10:17:35,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:35,754 INFO:     Epoch: 73
2023-01-05 10:17:37,885 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42231765190760295, 'Total loss': 0.42231765190760295} | train loss {'Reaction outcome loss': 0.2721052604485235, 'Total loss': 0.2721052604485235}
2023-01-05 10:17:37,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:37,886 INFO:     Epoch: 74
2023-01-05 10:17:40,007 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38628788689772287, 'Total loss': 0.38628788689772287} | train loss {'Reaction outcome loss': 0.2700403672796521, 'Total loss': 0.2700403672796521}
2023-01-05 10:17:40,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:40,008 INFO:     Epoch: 75
2023-01-05 10:17:42,128 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4052575925985972, 'Total loss': 0.4052575925985972} | train loss {'Reaction outcome loss': 0.27572893830964634, 'Total loss': 0.27572893830964634}
2023-01-05 10:17:42,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:42,128 INFO:     Epoch: 76
2023-01-05 10:17:44,215 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3976728190978368, 'Total loss': 0.3976728190978368} | train loss {'Reaction outcome loss': 0.2743395444333226, 'Total loss': 0.2743395444333226}
2023-01-05 10:17:44,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:44,215 INFO:     Epoch: 77
2023-01-05 10:17:46,334 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3750830054283142, 'Total loss': 0.3750830054283142} | train loss {'Reaction outcome loss': 0.2658007510361217, 'Total loss': 0.2658007510361217}
2023-01-05 10:17:46,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:46,336 INFO:     Epoch: 78
2023-01-05 10:17:48,484 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4008308216929436, 'Total loss': 0.4008308216929436} | train loss {'Reaction outcome loss': 0.2634161916789991, 'Total loss': 0.2634161916789991}
2023-01-05 10:17:48,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:48,485 INFO:     Epoch: 79
2023-01-05 10:17:50,584 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4158889760573705, 'Total loss': 0.4158889760573705} | train loss {'Reaction outcome loss': 0.27167700259731364, 'Total loss': 0.27167700259731364}
2023-01-05 10:17:50,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:50,586 INFO:     Epoch: 80
2023-01-05 10:17:52,719 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38110871811707814, 'Total loss': 0.38110871811707814} | train loss {'Reaction outcome loss': 0.26096237526572014, 'Total loss': 0.26096237526572014}
2023-01-05 10:17:52,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:52,719 INFO:     Epoch: 81
2023-01-05 10:17:54,822 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3869202514489492, 'Total loss': 0.3869202514489492} | train loss {'Reaction outcome loss': 0.2660432872311263, 'Total loss': 0.2660432872311263}
2023-01-05 10:17:54,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:54,822 INFO:     Epoch: 82
2023-01-05 10:17:56,946 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41103249589602153, 'Total loss': 0.41103249589602153} | train loss {'Reaction outcome loss': 0.2644774083989662, 'Total loss': 0.2644774083989662}
2023-01-05 10:17:56,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:56,948 INFO:     Epoch: 83
2023-01-05 10:17:59,057 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39331463277339934, 'Total loss': 0.39331463277339934} | train loss {'Reaction outcome loss': 0.2610624716941254, 'Total loss': 0.2610624716941254}
2023-01-05 10:17:59,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:17:59,057 INFO:     Epoch: 84
2023-01-05 10:18:01,190 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41450957556565604, 'Total loss': 0.41450957556565604} | train loss {'Reaction outcome loss': 0.25846766938383764, 'Total loss': 0.25846766938383764}
2023-01-05 10:18:01,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:01,191 INFO:     Epoch: 85
2023-01-05 10:18:03,303 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44919377019008, 'Total loss': 0.44919377019008} | train loss {'Reaction outcome loss': 0.24806489287483277, 'Total loss': 0.24806489287483277}
2023-01-05 10:18:03,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:03,305 INFO:     Epoch: 86
2023-01-05 10:18:05,435 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42705773512522377, 'Total loss': 0.42705773512522377} | train loss {'Reaction outcome loss': 0.2602596438213528, 'Total loss': 0.2602596438213528}
2023-01-05 10:18:05,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:05,436 INFO:     Epoch: 87
2023-01-05 10:18:07,531 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4120287676652273, 'Total loss': 0.4120287676652273} | train loss {'Reaction outcome loss': 0.2625403578287407, 'Total loss': 0.2625403578287407}
2023-01-05 10:18:07,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:07,531 INFO:     Epoch: 88
2023-01-05 10:18:09,657 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4315466632445653, 'Total loss': 0.4315466632445653} | train loss {'Reaction outcome loss': 0.2605544179405048, 'Total loss': 0.2605544179405048}
2023-01-05 10:18:09,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:09,659 INFO:     Epoch: 89
2023-01-05 10:18:11,609 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3991615484158198, 'Total loss': 0.3991615484158198} | train loss {'Reaction outcome loss': 0.2597387828215984, 'Total loss': 0.2597387828215984}
2023-01-05 10:18:11,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:11,609 INFO:     Epoch: 90
2023-01-05 10:18:13,744 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49070161680380503, 'Total loss': 0.49070161680380503} | train loss {'Reaction outcome loss': 0.25541409485778965, 'Total loss': 0.25541409485778965}
2023-01-05 10:18:13,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:13,744 INFO:     Epoch: 91
2023-01-05 10:18:15,816 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43402064839998883, 'Total loss': 0.43402064839998883} | train loss {'Reaction outcome loss': 0.25752287213400604, 'Total loss': 0.25752287213400604}
2023-01-05 10:18:15,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:15,817 INFO:     Epoch: 92
2023-01-05 10:18:17,903 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3804642985885342, 'Total loss': 0.3804642985885342} | train loss {'Reaction outcome loss': 0.2515552684855767, 'Total loss': 0.2515552684855767}
2023-01-05 10:18:17,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:17,903 INFO:     Epoch: 93
2023-01-05 10:18:20,022 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38895490268866223, 'Total loss': 0.38895490268866223} | train loss {'Reaction outcome loss': 0.246915177438722, 'Total loss': 0.246915177438722}
2023-01-05 10:18:20,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:20,022 INFO:     Epoch: 94
2023-01-05 10:18:22,133 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38175031542778015, 'Total loss': 0.38175031542778015} | train loss {'Reaction outcome loss': 0.2534134394792847, 'Total loss': 0.2534134394792847}
2023-01-05 10:18:22,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:22,134 INFO:     Epoch: 95
2023-01-05 10:18:24,251 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4189879854520162, 'Total loss': 0.4189879854520162} | train loss {'Reaction outcome loss': 0.24447584976083958, 'Total loss': 0.24447584976083958}
2023-01-05 10:18:24,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:24,251 INFO:     Epoch: 96
2023-01-05 10:18:26,335 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3918144941329956, 'Total loss': 0.3918144941329956} | train loss {'Reaction outcome loss': 0.24231155769346835, 'Total loss': 0.24231155769346835}
2023-01-05 10:18:26,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:26,336 INFO:     Epoch: 97
2023-01-05 10:18:28,458 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40980737109978993, 'Total loss': 0.40980737109978993} | train loss {'Reaction outcome loss': 0.24234304460782163, 'Total loss': 0.24234304460782163}
2023-01-05 10:18:28,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:28,459 INFO:     Epoch: 98
2023-01-05 10:18:30,569 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39886879126230873, 'Total loss': 0.39886879126230873} | train loss {'Reaction outcome loss': 0.24578011634967703, 'Total loss': 0.24578011634967703}
2023-01-05 10:18:30,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:30,569 INFO:     Epoch: 99
2023-01-05 10:18:32,705 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3992217128475507, 'Total loss': 0.3992217128475507} | train loss {'Reaction outcome loss': 0.24196454047160598, 'Total loss': 0.24196454047160598}
2023-01-05 10:18:32,705 INFO:     Best model found after epoch 66 of 100.
2023-01-05 10:18:32,705 INFO:   Done with stage: TRAINING
2023-01-05 10:18:32,705 INFO:   Starting stage: EVALUATION
2023-01-05 10:18:32,851 INFO:   Done with stage: EVALUATION
2023-01-05 10:18:32,851 INFO:   Leaving out SEQ value Fold_4
2023-01-05 10:18:32,863 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 10:18:32,863 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:18:33,518 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:18:33,518 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:18:33,588 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:18:33,589 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:18:33,589 INFO:     No hyperparam tuning for this model
2023-01-05 10:18:33,589 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:18:33,589 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:18:33,590 INFO:     None feature selector for col prot
2023-01-05 10:18:33,590 INFO:     None feature selector for col prot
2023-01-05 10:18:33,590 INFO:     None feature selector for col prot
2023-01-05 10:18:33,591 INFO:     None feature selector for col chem
2023-01-05 10:18:33,591 INFO:     None feature selector for col chem
2023-01-05 10:18:33,591 INFO:     None feature selector for col chem
2023-01-05 10:18:33,591 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:18:33,591 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:18:33,593 INFO:     Number of params in model 72901
2023-01-05 10:18:33,596 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:18:33,596 INFO:   Starting stage: TRAINING
2023-01-05 10:18:33,657 INFO:     Val loss before train {'Reaction outcome loss': 1.0213753779729207, 'Total loss': 1.0213753779729207}
2023-01-05 10:18:33,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:33,657 INFO:     Epoch: 0
2023-01-05 10:18:35,795 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8091744085152944, 'Total loss': 0.8091744085152944} | train loss {'Reaction outcome loss': 0.9311708331323273, 'Total loss': 0.9311708331323273}
2023-01-05 10:18:35,795 INFO:     Found new best model at epoch 0
2023-01-05 10:18:35,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:35,797 INFO:     Epoch: 1
2023-01-05 10:18:37,914 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6564890364805858, 'Total loss': 0.6564890364805858} | train loss {'Reaction outcome loss': 0.759081542707092, 'Total loss': 0.759081542707092}
2023-01-05 10:18:37,914 INFO:     Found new best model at epoch 1
2023-01-05 10:18:37,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:37,915 INFO:     Epoch: 2
2023-01-05 10:18:40,045 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5773622890313467, 'Total loss': 0.5773622890313467} | train loss {'Reaction outcome loss': 0.5961847856156662, 'Total loss': 0.5961847856156662}
2023-01-05 10:18:40,047 INFO:     Found new best model at epoch 2
2023-01-05 10:18:40,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:40,048 INFO:     Epoch: 3
2023-01-05 10:18:42,180 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.521854058901469, 'Total loss': 0.521854058901469} | train loss {'Reaction outcome loss': 0.5355938739187021, 'Total loss': 0.5355938739187021}
2023-01-05 10:18:42,180 INFO:     Found new best model at epoch 3
2023-01-05 10:18:42,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:42,181 INFO:     Epoch: 4
2023-01-05 10:18:44,342 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5169371565183004, 'Total loss': 0.5169371565183004} | train loss {'Reaction outcome loss': 0.5130447593083881, 'Total loss': 0.5130447593083881}
2023-01-05 10:18:44,343 INFO:     Found new best model at epoch 4
2023-01-05 10:18:44,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:44,344 INFO:     Epoch: 5
2023-01-05 10:18:46,446 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.508289909362793, 'Total loss': 0.508289909362793} | train loss {'Reaction outcome loss': 0.5005300510607471, 'Total loss': 0.5005300510607471}
2023-01-05 10:18:46,446 INFO:     Found new best model at epoch 5
2023-01-05 10:18:46,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:46,447 INFO:     Epoch: 6
2023-01-05 10:18:48,550 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4820222000281016, 'Total loss': 0.4820222000281016} | train loss {'Reaction outcome loss': 0.48490414980946894, 'Total loss': 0.48490414980946894}
2023-01-05 10:18:48,550 INFO:     Found new best model at epoch 6
2023-01-05 10:18:48,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:48,552 INFO:     Epoch: 7
2023-01-05 10:18:50,708 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4918788313865662, 'Total loss': 0.4918788313865662} | train loss {'Reaction outcome loss': 0.4833611532346436, 'Total loss': 0.4833611532346436}
2023-01-05 10:18:50,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:50,709 INFO:     Epoch: 8
2023-01-05 10:18:52,837 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4925301641225815, 'Total loss': 0.4925301641225815} | train loss {'Reaction outcome loss': 0.4784789302181251, 'Total loss': 0.4784789302181251}
2023-01-05 10:18:52,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:52,838 INFO:     Epoch: 9
2023-01-05 10:18:54,990 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4897447168827057, 'Total loss': 0.4897447168827057} | train loss {'Reaction outcome loss': 0.4659238425940813, 'Total loss': 0.4659238425940813}
2023-01-05 10:18:54,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:54,991 INFO:     Epoch: 10
2023-01-05 10:18:57,139 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5076317022244136, 'Total loss': 0.5076317022244136} | train loss {'Reaction outcome loss': 0.4600023629970929, 'Total loss': 0.4600023629970929}
2023-01-05 10:18:57,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:57,139 INFO:     Epoch: 11
2023-01-05 10:18:59,297 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48273186286290487, 'Total loss': 0.48273186286290487} | train loss {'Reaction outcome loss': 0.4580844568108824, 'Total loss': 0.4580844568108824}
2023-01-05 10:18:59,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:18:59,298 INFO:     Epoch: 12
2023-01-05 10:19:01,433 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46559338172276815, 'Total loss': 0.46559338172276815} | train loss {'Reaction outcome loss': 0.4506518609203156, 'Total loss': 0.4506518609203156}
2023-01-05 10:19:01,434 INFO:     Found new best model at epoch 12
2023-01-05 10:19:01,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:01,435 INFO:     Epoch: 13
2023-01-05 10:19:03,574 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48786332408587135, 'Total loss': 0.48786332408587135} | train loss {'Reaction outcome loss': 0.4521154959279277, 'Total loss': 0.4521154959279277}
2023-01-05 10:19:03,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:03,574 INFO:     Epoch: 14
2023-01-05 10:19:05,706 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46398245890935264, 'Total loss': 0.46398245890935264} | train loss {'Reaction outcome loss': 0.44228615211020306, 'Total loss': 0.44228615211020306}
2023-01-05 10:19:05,706 INFO:     Found new best model at epoch 14
2023-01-05 10:19:05,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:05,708 INFO:     Epoch: 15
2023-01-05 10:19:07,873 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48427275717258456, 'Total loss': 0.48427275717258456} | train loss {'Reaction outcome loss': 0.43967712880364396, 'Total loss': 0.43967712880364396}
2023-01-05 10:19:07,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:07,875 INFO:     Epoch: 16
2023-01-05 10:19:10,020 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49729524850845336, 'Total loss': 0.49729524850845336} | train loss {'Reaction outcome loss': 0.43785151648284726, 'Total loss': 0.43785151648284726}
2023-01-05 10:19:10,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:10,020 INFO:     Epoch: 17
2023-01-05 10:19:12,227 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47193374037742614, 'Total loss': 0.47193374037742614} | train loss {'Reaction outcome loss': 0.43497055871176804, 'Total loss': 0.43497055871176804}
2023-01-05 10:19:12,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:12,227 INFO:     Epoch: 18
2023-01-05 10:19:14,425 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4785307735204697, 'Total loss': 0.4785307735204697} | train loss {'Reaction outcome loss': 0.42520141146996393, 'Total loss': 0.42520141146996393}
2023-01-05 10:19:14,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:14,426 INFO:     Epoch: 19
2023-01-05 10:19:16,532 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46495670278867085, 'Total loss': 0.46495670278867085} | train loss {'Reaction outcome loss': 0.42865906774136997, 'Total loss': 0.42865906774136997}
2023-01-05 10:19:16,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:16,532 INFO:     Epoch: 20
2023-01-05 10:19:18,674 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45558555523554484, 'Total loss': 0.45558555523554484} | train loss {'Reaction outcome loss': 0.4222653167934194, 'Total loss': 0.4222653167934194}
2023-01-05 10:19:18,675 INFO:     Found new best model at epoch 20
2023-01-05 10:19:18,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:18,676 INFO:     Epoch: 21
2023-01-05 10:19:20,799 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4615154465039571, 'Total loss': 0.4615154465039571} | train loss {'Reaction outcome loss': 0.4209840870613656, 'Total loss': 0.4209840870613656}
2023-01-05 10:19:20,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:20,799 INFO:     Epoch: 22
2023-01-05 10:19:22,910 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4853799601395925, 'Total loss': 0.4853799601395925} | train loss {'Reaction outcome loss': 0.41407866722194725, 'Total loss': 0.41407866722194725}
2023-01-05 10:19:22,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:22,911 INFO:     Epoch: 23
2023-01-05 10:19:25,055 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4454292542611559, 'Total loss': 0.4454292542611559} | train loss {'Reaction outcome loss': 0.40749532839666636, 'Total loss': 0.40749532839666636}
2023-01-05 10:19:25,056 INFO:     Found new best model at epoch 23
2023-01-05 10:19:25,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:25,058 INFO:     Epoch: 24
2023-01-05 10:19:27,183 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46498044232527413, 'Total loss': 0.46498044232527413} | train loss {'Reaction outcome loss': 0.41063037261851, 'Total loss': 0.41063037261851}
2023-01-05 10:19:27,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:27,184 INFO:     Epoch: 25
2023-01-05 10:19:29,292 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45197466810544334, 'Total loss': 0.45197466810544334} | train loss {'Reaction outcome loss': 0.40786302390942075, 'Total loss': 0.40786302390942075}
2023-01-05 10:19:29,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:29,293 INFO:     Epoch: 26
2023-01-05 10:19:31,442 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43617746432622273, 'Total loss': 0.43617746432622273} | train loss {'Reaction outcome loss': 0.40273508795331964, 'Total loss': 0.40273508795331964}
2023-01-05 10:19:31,442 INFO:     Found new best model at epoch 26
2023-01-05 10:19:31,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:31,444 INFO:     Epoch: 27
2023-01-05 10:19:33,602 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46408347686131796, 'Total loss': 0.46408347686131796} | train loss {'Reaction outcome loss': 0.4049265530995944, 'Total loss': 0.4049265530995944}
2023-01-05 10:19:33,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:33,602 INFO:     Epoch: 28
2023-01-05 10:19:35,755 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45287485321362814, 'Total loss': 0.45287485321362814} | train loss {'Reaction outcome loss': 0.39658093465902317, 'Total loss': 0.39658093465902317}
2023-01-05 10:19:35,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:35,756 INFO:     Epoch: 29
2023-01-05 10:19:37,879 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4601504037777583, 'Total loss': 0.4601504037777583} | train loss {'Reaction outcome loss': 0.39257532370273385, 'Total loss': 0.39257532370273385}
2023-01-05 10:19:37,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:37,879 INFO:     Epoch: 30
2023-01-05 10:19:40,017 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4814371854066849, 'Total loss': 0.4814371854066849} | train loss {'Reaction outcome loss': 0.39014644533503356, 'Total loss': 0.39014644533503356}
2023-01-05 10:19:40,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:40,017 INFO:     Epoch: 31
2023-01-05 10:19:42,161 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46377447148164114, 'Total loss': 0.46377447148164114} | train loss {'Reaction outcome loss': 0.3855726698729536, 'Total loss': 0.3855726698729536}
2023-01-05 10:19:42,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:42,162 INFO:     Epoch: 32
2023-01-05 10:19:44,293 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4721547648310661, 'Total loss': 0.4721547648310661} | train loss {'Reaction outcome loss': 0.38540682707667784, 'Total loss': 0.38540682707667784}
2023-01-05 10:19:44,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:44,293 INFO:     Epoch: 33
2023-01-05 10:19:46,415 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45221748650074006, 'Total loss': 0.45221748650074006} | train loss {'Reaction outcome loss': 0.3836759433204086, 'Total loss': 0.3836759433204086}
2023-01-05 10:19:46,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:46,415 INFO:     Epoch: 34
2023-01-05 10:19:48,537 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43848084211349486, 'Total loss': 0.43848084211349486} | train loss {'Reaction outcome loss': 0.38005595667697895, 'Total loss': 0.38005595667697895}
2023-01-05 10:19:48,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:48,538 INFO:     Epoch: 35
2023-01-05 10:19:50,716 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44161434868971505, 'Total loss': 0.44161434868971505} | train loss {'Reaction outcome loss': 0.37552595509733966, 'Total loss': 0.37552595509733966}
2023-01-05 10:19:50,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:50,716 INFO:     Epoch: 36
2023-01-05 10:19:52,818 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4449797511100769, 'Total loss': 0.4449797511100769} | train loss {'Reaction outcome loss': 0.37122189207843065, 'Total loss': 0.37122189207843065}
2023-01-05 10:19:52,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:52,819 INFO:     Epoch: 37
2023-01-05 10:19:54,958 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4650423248608907, 'Total loss': 0.4650423248608907} | train loss {'Reaction outcome loss': 0.36801097794883086, 'Total loss': 0.36801097794883086}
2023-01-05 10:19:54,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:54,958 INFO:     Epoch: 38
2023-01-05 10:19:57,090 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46352847417195636, 'Total loss': 0.46352847417195636} | train loss {'Reaction outcome loss': 0.3655300584188007, 'Total loss': 0.3655300584188007}
2023-01-05 10:19:57,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:57,090 INFO:     Epoch: 39
2023-01-05 10:19:59,221 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4534522662560145, 'Total loss': 0.4534522662560145} | train loss {'Reaction outcome loss': 0.3589405486299673, 'Total loss': 0.3589405486299673}
2023-01-05 10:19:59,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:19:59,223 INFO:     Epoch: 40
2023-01-05 10:20:01,341 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44628782669703165, 'Total loss': 0.44628782669703165} | train loss {'Reaction outcome loss': 0.36127550286721666, 'Total loss': 0.36127550286721666}
2023-01-05 10:20:01,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:01,341 INFO:     Epoch: 41
2023-01-05 10:20:03,478 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44077308575312296, 'Total loss': 0.44077308575312296} | train loss {'Reaction outcome loss': 0.356927447316879, 'Total loss': 0.356927447316879}
2023-01-05 10:20:03,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:03,479 INFO:     Epoch: 42
2023-01-05 10:20:05,597 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43621898293495176, 'Total loss': 0.43621898293495176} | train loss {'Reaction outcome loss': 0.35433625825260523, 'Total loss': 0.35433625825260523}
2023-01-05 10:20:05,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:05,598 INFO:     Epoch: 43
2023-01-05 10:20:07,721 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4614197055498759, 'Total loss': 0.4614197055498759} | train loss {'Reaction outcome loss': 0.3507080527580602, 'Total loss': 0.3507080527580602}
2023-01-05 10:20:07,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:07,721 INFO:     Epoch: 44
2023-01-05 10:20:09,849 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46194118857383726, 'Total loss': 0.46194118857383726} | train loss {'Reaction outcome loss': 0.346687332669858, 'Total loss': 0.346687332669858}
2023-01-05 10:20:09,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:09,849 INFO:     Epoch: 45
2023-01-05 10:20:11,978 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43775961101055144, 'Total loss': 0.43775961101055144} | train loss {'Reaction outcome loss': 0.35018767701589676, 'Total loss': 0.35018767701589676}
2023-01-05 10:20:11,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:11,979 INFO:     Epoch: 46
2023-01-05 10:20:14,091 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4399070094029109, 'Total loss': 0.4399070094029109} | train loss {'Reaction outcome loss': 0.34960919502947735, 'Total loss': 0.34960919502947735}
2023-01-05 10:20:14,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:14,091 INFO:     Epoch: 47
2023-01-05 10:20:16,227 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41317448814709984, 'Total loss': 0.41317448814709984} | train loss {'Reaction outcome loss': 0.3451294062074126, 'Total loss': 0.3451294062074126}
2023-01-05 10:20:16,227 INFO:     Found new best model at epoch 47
2023-01-05 10:20:16,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:16,228 INFO:     Epoch: 48
2023-01-05 10:20:18,352 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4406751662492752, 'Total loss': 0.4406751662492752} | train loss {'Reaction outcome loss': 0.3409860389515596, 'Total loss': 0.3409860389515596}
2023-01-05 10:20:18,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:18,353 INFO:     Epoch: 49
2023-01-05 10:20:20,471 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48752617637316387, 'Total loss': 0.48752617637316387} | train loss {'Reaction outcome loss': 0.3423458865779832, 'Total loss': 0.3423458865779832}
2023-01-05 10:20:20,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:20,471 INFO:     Epoch: 50
2023-01-05 10:20:22,607 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45200263559818266, 'Total loss': 0.45200263559818266} | train loss {'Reaction outcome loss': 0.3382539520248609, 'Total loss': 0.3382539520248609}
2023-01-05 10:20:22,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:22,607 INFO:     Epoch: 51
2023-01-05 10:20:24,738 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44037341376145683, 'Total loss': 0.44037341376145683} | train loss {'Reaction outcome loss': 0.3297739524784286, 'Total loss': 0.3297739524784286}
2023-01-05 10:20:24,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:24,739 INFO:     Epoch: 52
2023-01-05 10:20:26,871 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4400380258758863, 'Total loss': 0.4400380258758863} | train loss {'Reaction outcome loss': 0.33554008765825294, 'Total loss': 0.33554008765825294}
2023-01-05 10:20:26,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:26,872 INFO:     Epoch: 53
2023-01-05 10:20:28,979 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46266623040040333, 'Total loss': 0.46266623040040333} | train loss {'Reaction outcome loss': 0.3324828517996447, 'Total loss': 0.3324828517996447}
2023-01-05 10:20:28,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:28,980 INFO:     Epoch: 54
2023-01-05 10:20:31,099 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4491249362627665, 'Total loss': 0.4491249362627665} | train loss {'Reaction outcome loss': 0.33218424388002404, 'Total loss': 0.33218424388002404}
2023-01-05 10:20:31,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:31,100 INFO:     Epoch: 55
2023-01-05 10:20:33,210 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47273833155632017, 'Total loss': 0.47273833155632017} | train loss {'Reaction outcome loss': 0.32889730578779314, 'Total loss': 0.32889730578779314}
2023-01-05 10:20:33,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:33,210 INFO:     Epoch: 56
2023-01-05 10:20:35,351 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4452723890542984, 'Total loss': 0.4452723890542984} | train loss {'Reaction outcome loss': 0.3315371381461836, 'Total loss': 0.3315371381461836}
2023-01-05 10:20:35,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:35,352 INFO:     Epoch: 57
2023-01-05 10:20:37,513 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4324546178181966, 'Total loss': 0.4324546178181966} | train loss {'Reaction outcome loss': 0.31430947666295167, 'Total loss': 0.31430947666295167}
2023-01-05 10:20:37,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:37,513 INFO:     Epoch: 58
2023-01-05 10:20:39,683 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4536141902208328, 'Total loss': 0.4536141902208328} | train loss {'Reaction outcome loss': 0.326749568852169, 'Total loss': 0.326749568852169}
2023-01-05 10:20:39,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:39,683 INFO:     Epoch: 59
2023-01-05 10:20:41,852 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43700786828994753, 'Total loss': 0.43700786828994753} | train loss {'Reaction outcome loss': 0.32010641616066443, 'Total loss': 0.32010641616066443}
2023-01-05 10:20:41,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:41,853 INFO:     Epoch: 60
2023-01-05 10:20:44,029 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4154470403989156, 'Total loss': 0.4154470403989156} | train loss {'Reaction outcome loss': 0.31108334058028264, 'Total loss': 0.31108334058028264}
2023-01-05 10:20:44,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:44,029 INFO:     Epoch: 61
2023-01-05 10:20:46,198 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4843029965957006, 'Total loss': 0.4843029965957006} | train loss {'Reaction outcome loss': 0.3166929394248806, 'Total loss': 0.3166929394248806}
2023-01-05 10:20:46,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:46,199 INFO:     Epoch: 62
2023-01-05 10:20:48,352 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4374368518590927, 'Total loss': 0.4374368518590927} | train loss {'Reaction outcome loss': 0.3144911412109322, 'Total loss': 0.3144911412109322}
2023-01-05 10:20:48,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:48,353 INFO:     Epoch: 63
2023-01-05 10:20:50,476 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46462502678235373, 'Total loss': 0.46462502678235373} | train loss {'Reaction outcome loss': 0.3092768439074931, 'Total loss': 0.3092768439074931}
2023-01-05 10:20:50,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:50,477 INFO:     Epoch: 64
2023-01-05 10:20:52,594 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4309238930543264, 'Total loss': 0.4309238930543264} | train loss {'Reaction outcome loss': 0.3062711753327709, 'Total loss': 0.3062711753327709}
2023-01-05 10:20:52,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:52,594 INFO:     Epoch: 65
2023-01-05 10:20:54,718 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42401549915472664, 'Total loss': 0.42401549915472664} | train loss {'Reaction outcome loss': 0.306944695513171, 'Total loss': 0.306944695513171}
2023-01-05 10:20:54,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:54,718 INFO:     Epoch: 66
2023-01-05 10:20:56,854 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43008405963579815, 'Total loss': 0.43008405963579815} | train loss {'Reaction outcome loss': 0.30730537676154923, 'Total loss': 0.30730537676154923}
2023-01-05 10:20:56,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:56,854 INFO:     Epoch: 67
2023-01-05 10:20:58,828 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42213179071744283, 'Total loss': 0.42213179071744283} | train loss {'Reaction outcome loss': 0.30108213692311775, 'Total loss': 0.30108213692311775}
2023-01-05 10:20:58,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:20:58,828 INFO:     Epoch: 68
2023-01-05 10:21:00,600 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41770444611708324, 'Total loss': 0.41770444611708324} | train loss {'Reaction outcome loss': 0.29742489449195697, 'Total loss': 0.29742489449195697}
2023-01-05 10:21:00,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:00,601 INFO:     Epoch: 69
2023-01-05 10:21:02,423 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4707234730323156, 'Total loss': 0.4707234730323156} | train loss {'Reaction outcome loss': 0.29734842315154814, 'Total loss': 0.29734842315154814}
2023-01-05 10:21:02,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:02,423 INFO:     Epoch: 70
2023-01-05 10:21:04,540 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4310414721568426, 'Total loss': 0.4310414721568426} | train loss {'Reaction outcome loss': 0.2942947231582786, 'Total loss': 0.2942947231582786}
2023-01-05 10:21:04,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:04,540 INFO:     Epoch: 71
2023-01-05 10:21:06,687 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4430633475383123, 'Total loss': 0.4430633475383123} | train loss {'Reaction outcome loss': 0.29283349162189537, 'Total loss': 0.29283349162189537}
2023-01-05 10:21:06,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:06,687 INFO:     Epoch: 72
2023-01-05 10:21:08,826 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4512156714995702, 'Total loss': 0.4512156714995702} | train loss {'Reaction outcome loss': 0.2920189558827597, 'Total loss': 0.2920189558827597}
2023-01-05 10:21:08,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:08,826 INFO:     Epoch: 73
2023-01-05 10:21:10,960 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41231299539407096, 'Total loss': 0.41231299539407096} | train loss {'Reaction outcome loss': 0.29352658037566964, 'Total loss': 0.29352658037566964}
2023-01-05 10:21:10,961 INFO:     Found new best model at epoch 73
2023-01-05 10:21:10,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:10,962 INFO:     Epoch: 74
2023-01-05 10:21:13,090 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40887260138988496, 'Total loss': 0.40887260138988496} | train loss {'Reaction outcome loss': 0.28876156273839276, 'Total loss': 0.28876156273839276}
2023-01-05 10:21:13,090 INFO:     Found new best model at epoch 74
2023-01-05 10:21:13,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:13,091 INFO:     Epoch: 75
2023-01-05 10:21:15,228 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.416274830698967, 'Total loss': 0.416274830698967} | train loss {'Reaction outcome loss': 0.28981060556233573, 'Total loss': 0.28981060556233573}
2023-01-05 10:21:15,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:15,229 INFO:     Epoch: 76
2023-01-05 10:21:17,335 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43384382128715515, 'Total loss': 0.43384382128715515} | train loss {'Reaction outcome loss': 0.28993208857004393, 'Total loss': 0.28993208857004393}
2023-01-05 10:21:17,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:17,335 INFO:     Epoch: 77
2023-01-05 10:21:19,478 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4115780452887217, 'Total loss': 0.4115780452887217} | train loss {'Reaction outcome loss': 0.2899509491903257, 'Total loss': 0.2899509491903257}
2023-01-05 10:21:19,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:19,479 INFO:     Epoch: 78
2023-01-05 10:21:21,602 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46442211667696637, 'Total loss': 0.46442211667696637} | train loss {'Reaction outcome loss': 0.28049960889137393, 'Total loss': 0.28049960889137393}
2023-01-05 10:21:21,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:21,603 INFO:     Epoch: 79
2023-01-05 10:21:23,742 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3992757280667623, 'Total loss': 0.3992757280667623} | train loss {'Reaction outcome loss': 0.28609360255543076, 'Total loss': 0.28609360255543076}
2023-01-05 10:21:23,742 INFO:     Found new best model at epoch 79
2023-01-05 10:21:23,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:23,744 INFO:     Epoch: 80
2023-01-05 10:21:25,853 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4740361750125885, 'Total loss': 0.4740361750125885} | train loss {'Reaction outcome loss': 0.274300131368508, 'Total loss': 0.274300131368508}
2023-01-05 10:21:25,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:25,854 INFO:     Epoch: 81
2023-01-05 10:21:27,955 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4149939994017283, 'Total loss': 0.4149939994017283} | train loss {'Reaction outcome loss': 0.2796677666907922, 'Total loss': 0.2796677666907922}
2023-01-05 10:21:27,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:27,956 INFO:     Epoch: 82
2023-01-05 10:21:30,089 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43992879390716555, 'Total loss': 0.43992879390716555} | train loss {'Reaction outcome loss': 0.2824317628672407, 'Total loss': 0.2824317628672407}
2023-01-05 10:21:30,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:30,090 INFO:     Epoch: 83
2023-01-05 10:21:32,207 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4612419406572978, 'Total loss': 0.4612419406572978} | train loss {'Reaction outcome loss': 0.2706558452414799, 'Total loss': 0.2706558452414799}
2023-01-05 10:21:32,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:32,208 INFO:     Epoch: 84
2023-01-05 10:21:34,232 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3983548810084661, 'Total loss': 0.3983548810084661} | train loss {'Reaction outcome loss': 0.2770998369472014, 'Total loss': 0.2770998369472014}
2023-01-05 10:21:34,232 INFO:     Found new best model at epoch 84
2023-01-05 10:21:34,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:34,233 INFO:     Epoch: 85
2023-01-05 10:21:35,991 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4182037388285001, 'Total loss': 0.4182037388285001} | train loss {'Reaction outcome loss': 0.27666880463381105, 'Total loss': 0.27666880463381105}
2023-01-05 10:21:35,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:35,992 INFO:     Epoch: 86
2023-01-05 10:21:37,738 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3970654378334681, 'Total loss': 0.3970654378334681} | train loss {'Reaction outcome loss': 0.2730720030002646, 'Total loss': 0.2730720030002646}
2023-01-05 10:21:37,738 INFO:     Found new best model at epoch 86
2023-01-05 10:21:37,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:37,739 INFO:     Epoch: 87
2023-01-05 10:21:39,818 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4038328011830648, 'Total loss': 0.4038328011830648} | train loss {'Reaction outcome loss': 0.26756621658506163, 'Total loss': 0.26756621658506163}
2023-01-05 10:21:39,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:39,819 INFO:     Epoch: 88
2023-01-05 10:21:41,970 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4129518230756124, 'Total loss': 0.4129518230756124} | train loss {'Reaction outcome loss': 0.27670765393800256, 'Total loss': 0.27670765393800256}
2023-01-05 10:21:41,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:41,970 INFO:     Epoch: 89
2023-01-05 10:21:44,093 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40625516275564827, 'Total loss': 0.40625516275564827} | train loss {'Reaction outcome loss': 0.2730896642250059, 'Total loss': 0.2730896642250059}
2023-01-05 10:21:44,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:44,094 INFO:     Epoch: 90
2023-01-05 10:21:46,218 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4040620038906733, 'Total loss': 0.4040620038906733} | train loss {'Reaction outcome loss': 0.27076715278012226, 'Total loss': 0.27076715278012226}
2023-01-05 10:21:46,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:46,218 INFO:     Epoch: 91
2023-01-05 10:21:48,331 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3991003558039665, 'Total loss': 0.3991003558039665} | train loss {'Reaction outcome loss': 0.2653251680468179, 'Total loss': 0.2653251680468179}
2023-01-05 10:21:48,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:48,331 INFO:     Epoch: 92
2023-01-05 10:21:50,440 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4358207861582438, 'Total loss': 0.4358207861582438} | train loss {'Reaction outcome loss': 0.2661018485963237, 'Total loss': 0.2661018485963237}
2023-01-05 10:21:50,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:50,441 INFO:     Epoch: 93
2023-01-05 10:21:52,545 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39877293407917025, 'Total loss': 0.39877293407917025} | train loss {'Reaction outcome loss': 0.2684172526647468, 'Total loss': 0.2684172526647468}
2023-01-05 10:21:52,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:52,546 INFO:     Epoch: 94
2023-01-05 10:21:54,663 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42112946410973867, 'Total loss': 0.42112946410973867} | train loss {'Reaction outcome loss': 0.26228327146775027, 'Total loss': 0.26228327146775027}
2023-01-05 10:21:54,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:54,665 INFO:     Epoch: 95
2023-01-05 10:21:56,788 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3993746921420097, 'Total loss': 0.3993746921420097} | train loss {'Reaction outcome loss': 0.2647767728093729, 'Total loss': 0.2647767728093729}
2023-01-05 10:21:56,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:56,788 INFO:     Epoch: 96
2023-01-05 10:21:58,903 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4232482582330704, 'Total loss': 0.4232482582330704} | train loss {'Reaction outcome loss': 0.26538766257545576, 'Total loss': 0.26538766257545576}
2023-01-05 10:21:58,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:21:58,903 INFO:     Epoch: 97
2023-01-05 10:22:01,081 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3907027045885722, 'Total loss': 0.3907027045885722} | train loss {'Reaction outcome loss': 0.2564918358242038, 'Total loss': 0.2564918358242038}
2023-01-05 10:22:01,081 INFO:     Found new best model at epoch 97
2023-01-05 10:22:01,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:01,083 INFO:     Epoch: 98
2023-01-05 10:22:03,205 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4152467489242554, 'Total loss': 0.4152467489242554} | train loss {'Reaction outcome loss': 0.2572218402009794, 'Total loss': 0.2572218402009794}
2023-01-05 10:22:03,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:03,205 INFO:     Epoch: 99
2023-01-05 10:22:05,340 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42733142574628197, 'Total loss': 0.42733142574628197} | train loss {'Reaction outcome loss': 0.2555407037561766, 'Total loss': 0.2555407037561766}
2023-01-05 10:22:05,341 INFO:     Best model found after epoch 98 of 100.
2023-01-05 10:22:05,341 INFO:   Done with stage: TRAINING
2023-01-05 10:22:05,341 INFO:   Starting stage: EVALUATION
2023-01-05 10:22:05,467 INFO:   Done with stage: EVALUATION
2023-01-05 10:22:05,467 INFO:   Leaving out SEQ value Fold_5
2023-01-05 10:22:05,480 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 10:22:05,480 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:22:06,129 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:22:06,129 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:22:06,199 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:22:06,199 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:22:06,200 INFO:     No hyperparam tuning for this model
2023-01-05 10:22:06,200 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:22:06,200 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:22:06,200 INFO:     None feature selector for col prot
2023-01-05 10:22:06,200 INFO:     None feature selector for col prot
2023-01-05 10:22:06,201 INFO:     None feature selector for col prot
2023-01-05 10:22:06,201 INFO:     None feature selector for col chem
2023-01-05 10:22:06,201 INFO:     None feature selector for col chem
2023-01-05 10:22:06,201 INFO:     None feature selector for col chem
2023-01-05 10:22:06,201 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:22:06,201 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:22:06,203 INFO:     Number of params in model 72901
2023-01-05 10:22:06,206 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:22:06,206 INFO:   Starting stage: TRAINING
2023-01-05 10:22:06,266 INFO:     Val loss before train {'Reaction outcome loss': 0.979206629594167, 'Total loss': 0.979206629594167}
2023-01-05 10:22:06,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:06,266 INFO:     Epoch: 0
2023-01-05 10:22:08,219 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7898430824279785, 'Total loss': 0.7898430824279785} | train loss {'Reaction outcome loss': 0.9260333254664384, 'Total loss': 0.9260333254664384}
2023-01-05 10:22:08,219 INFO:     Found new best model at epoch 0
2023-01-05 10:22:08,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:08,221 INFO:     Epoch: 1
2023-01-05 10:22:10,389 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5916374524434408, 'Total loss': 0.5916374524434408} | train loss {'Reaction outcome loss': 0.7437295629659715, 'Total loss': 0.7437295629659715}
2023-01-05 10:22:10,389 INFO:     Found new best model at epoch 1
2023-01-05 10:22:10,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:10,390 INFO:     Epoch: 2
2023-01-05 10:22:12,530 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4858689735333125, 'Total loss': 0.4858689735333125} | train loss {'Reaction outcome loss': 0.5897052801795815, 'Total loss': 0.5897052801795815}
2023-01-05 10:22:12,530 INFO:     Found new best model at epoch 2
2023-01-05 10:22:12,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:12,531 INFO:     Epoch: 3
2023-01-05 10:22:14,658 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47462576230367026, 'Total loss': 0.47462576230367026} | train loss {'Reaction outcome loss': 0.538770853935166, 'Total loss': 0.538770853935166}
2023-01-05 10:22:14,659 INFO:     Found new best model at epoch 3
2023-01-05 10:22:14,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:14,660 INFO:     Epoch: 4
2023-01-05 10:22:16,820 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4664408047993978, 'Total loss': 0.4664408047993978} | train loss {'Reaction outcome loss': 0.5167930384943201, 'Total loss': 0.5167930384943201}
2023-01-05 10:22:16,821 INFO:     Found new best model at epoch 4
2023-01-05 10:22:16,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:16,822 INFO:     Epoch: 5
2023-01-05 10:22:18,992 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4602449119091034, 'Total loss': 0.4602449119091034} | train loss {'Reaction outcome loss': 0.5034469340252101, 'Total loss': 0.5034469340252101}
2023-01-05 10:22:18,992 INFO:     Found new best model at epoch 5
2023-01-05 10:22:18,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:18,993 INFO:     Epoch: 6
2023-01-05 10:22:21,153 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.459871776898702, 'Total loss': 0.459871776898702} | train loss {'Reaction outcome loss': 0.49557003793088106, 'Total loss': 0.49557003793088106}
2023-01-05 10:22:21,153 INFO:     Found new best model at epoch 6
2023-01-05 10:22:21,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:21,155 INFO:     Epoch: 7
2023-01-05 10:22:23,270 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4603019177913666, 'Total loss': 0.4603019177913666} | train loss {'Reaction outcome loss': 0.49133095973665536, 'Total loss': 0.49133095973665536}
2023-01-05 10:22:23,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:23,270 INFO:     Epoch: 8
2023-01-05 10:22:25,400 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45877524813016257, 'Total loss': 0.45877524813016257} | train loss {'Reaction outcome loss': 0.48019145967082427, 'Total loss': 0.48019145967082427}
2023-01-05 10:22:25,401 INFO:     Found new best model at epoch 8
2023-01-05 10:22:25,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:25,402 INFO:     Epoch: 9
2023-01-05 10:22:27,525 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4485333611567815, 'Total loss': 0.4485333611567815} | train loss {'Reaction outcome loss': 0.4727150451943332, 'Total loss': 0.4727150451943332}
2023-01-05 10:22:27,525 INFO:     Found new best model at epoch 9
2023-01-05 10:22:27,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:27,527 INFO:     Epoch: 10
2023-01-05 10:22:29,652 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.457803675532341, 'Total loss': 0.457803675532341} | train loss {'Reaction outcome loss': 0.4728688147685588, 'Total loss': 0.4728688147685588}
2023-01-05 10:22:29,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:29,653 INFO:     Epoch: 11
2023-01-05 10:22:31,760 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4849906881650289, 'Total loss': 0.4849906881650289} | train loss {'Reaction outcome loss': 0.46481247956356847, 'Total loss': 0.46481247956356847}
2023-01-05 10:22:31,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:31,761 INFO:     Epoch: 12
2023-01-05 10:22:33,896 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4600156525770823, 'Total loss': 0.4600156525770823} | train loss {'Reaction outcome loss': 0.4626880519441749, 'Total loss': 0.4626880519441749}
2023-01-05 10:22:33,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:33,896 INFO:     Epoch: 13
2023-01-05 10:22:36,042 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4486652672290802, 'Total loss': 0.4486652672290802} | train loss {'Reaction outcome loss': 0.4537035928844115, 'Total loss': 0.4537035928844115}
2023-01-05 10:22:36,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:36,042 INFO:     Epoch: 14
2023-01-05 10:22:38,153 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4431295573711395, 'Total loss': 0.4431295573711395} | train loss {'Reaction outcome loss': 0.45003142113720035, 'Total loss': 0.45003142113720035}
2023-01-05 10:22:38,153 INFO:     Found new best model at epoch 14
2023-01-05 10:22:38,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:38,155 INFO:     Epoch: 15
2023-01-05 10:22:40,297 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4445948948462804, 'Total loss': 0.4445948948462804} | train loss {'Reaction outcome loss': 0.4451547663672306, 'Total loss': 0.4451547663672306}
2023-01-05 10:22:40,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:40,297 INFO:     Epoch: 16
2023-01-05 10:22:42,413 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4447685937086741, 'Total loss': 0.4447685937086741} | train loss {'Reaction outcome loss': 0.4415832121557277, 'Total loss': 0.4415832121557277}
2023-01-05 10:22:42,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:42,413 INFO:     Epoch: 17
2023-01-05 10:22:44,528 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42228654188414416, 'Total loss': 0.42228654188414416} | train loss {'Reaction outcome loss': 0.4409396017931859, 'Total loss': 0.4409396017931859}
2023-01-05 10:22:44,528 INFO:     Found new best model at epoch 17
2023-01-05 10:22:44,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:44,530 INFO:     Epoch: 18
2023-01-05 10:22:46,633 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4268907537062963, 'Total loss': 0.4268907537062963} | train loss {'Reaction outcome loss': 0.43503254270080194, 'Total loss': 0.43503254270080194}
2023-01-05 10:22:46,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:46,634 INFO:     Epoch: 19
2023-01-05 10:22:48,760 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46006162563959757, 'Total loss': 0.46006162563959757} | train loss {'Reaction outcome loss': 0.42926522906506537, 'Total loss': 0.42926522906506537}
2023-01-05 10:22:48,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:48,760 INFO:     Epoch: 20
2023-01-05 10:22:50,899 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4510273257891337, 'Total loss': 0.4510273257891337} | train loss {'Reaction outcome loss': 0.42648285748403425, 'Total loss': 0.42648285748403425}
2023-01-05 10:22:50,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:50,899 INFO:     Epoch: 21
2023-01-05 10:22:53,015 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42285336057345074, 'Total loss': 0.42285336057345074} | train loss {'Reaction outcome loss': 0.4286711337011213, 'Total loss': 0.4286711337011213}
2023-01-05 10:22:53,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:53,015 INFO:     Epoch: 22
2023-01-05 10:22:55,139 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42480438351631167, 'Total loss': 0.42480438351631167} | train loss {'Reaction outcome loss': 0.422890436509456, 'Total loss': 0.422890436509456}
2023-01-05 10:22:55,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:55,141 INFO:     Epoch: 23
2023-01-05 10:22:57,256 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4392489969730377, 'Total loss': 0.4392489969730377} | train loss {'Reaction outcome loss': 0.41512273997068405, 'Total loss': 0.41512273997068405}
2023-01-05 10:22:57,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:57,257 INFO:     Epoch: 24
2023-01-05 10:22:59,380 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41873828570048016, 'Total loss': 0.41873828570048016} | train loss {'Reaction outcome loss': 0.41451588558160873, 'Total loss': 0.41451588558160873}
2023-01-05 10:22:59,380 INFO:     Found new best model at epoch 24
2023-01-05 10:22:59,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:22:59,381 INFO:     Epoch: 25
2023-01-05 10:23:01,548 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4299300372600555, 'Total loss': 0.4299300372600555} | train loss {'Reaction outcome loss': 0.4087958797166924, 'Total loss': 0.4087958797166924}
2023-01-05 10:23:01,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:01,549 INFO:     Epoch: 26
2023-01-05 10:23:03,658 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4503204544385274, 'Total loss': 0.4503204544385274} | train loss {'Reaction outcome loss': 0.4116505555512673, 'Total loss': 0.4116505555512673}
2023-01-05 10:23:03,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:03,658 INFO:     Epoch: 27
2023-01-05 10:23:05,772 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42016034622987114, 'Total loss': 0.42016034622987114} | train loss {'Reaction outcome loss': 0.4021928788092162, 'Total loss': 0.4021928788092162}
2023-01-05 10:23:05,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:05,772 INFO:     Epoch: 28
2023-01-05 10:23:07,886 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4428869167963664, 'Total loss': 0.4428869167963664} | train loss {'Reaction outcome loss': 0.39429946460287063, 'Total loss': 0.39429946460287063}
2023-01-05 10:23:07,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:07,886 INFO:     Epoch: 29
2023-01-05 10:23:09,997 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44063446720441185, 'Total loss': 0.44063446720441185} | train loss {'Reaction outcome loss': 0.39944625659324634, 'Total loss': 0.39944625659324634}
2023-01-05 10:23:09,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:09,998 INFO:     Epoch: 30
2023-01-05 10:23:12,086 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4287762254476547, 'Total loss': 0.4287762254476547} | train loss {'Reaction outcome loss': 0.38800674445577477, 'Total loss': 0.38800674445577477}
2023-01-05 10:23:12,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:12,087 INFO:     Epoch: 31
2023-01-05 10:23:14,248 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43994324207305907, 'Total loss': 0.43994324207305907} | train loss {'Reaction outcome loss': 0.39534500469907524, 'Total loss': 0.39534500469907524}
2023-01-05 10:23:14,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:14,249 INFO:     Epoch: 32
2023-01-05 10:23:16,358 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.411749404668808, 'Total loss': 0.411749404668808} | train loss {'Reaction outcome loss': 0.3838327646470672, 'Total loss': 0.3838327646470672}
2023-01-05 10:23:16,358 INFO:     Found new best model at epoch 32
2023-01-05 10:23:16,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:16,360 INFO:     Epoch: 33
2023-01-05 10:23:18,464 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41665842284758886, 'Total loss': 0.41665842284758886} | train loss {'Reaction outcome loss': 0.3817384021645849, 'Total loss': 0.3817384021645849}
2023-01-05 10:23:18,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:18,464 INFO:     Epoch: 34
2023-01-05 10:23:20,568 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4142032186190287, 'Total loss': 0.4142032186190287} | train loss {'Reaction outcome loss': 0.38290151176362264, 'Total loss': 0.38290151176362264}
2023-01-05 10:23:20,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:20,568 INFO:     Epoch: 35
2023-01-05 10:23:22,701 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4553327312072118, 'Total loss': 0.4553327312072118} | train loss {'Reaction outcome loss': 0.3737145158519383, 'Total loss': 0.3737145158519383}
2023-01-05 10:23:22,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:22,702 INFO:     Epoch: 36
2023-01-05 10:23:24,846 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4416266759236654, 'Total loss': 0.4416266759236654} | train loss {'Reaction outcome loss': 0.36927083266448457, 'Total loss': 0.36927083266448457}
2023-01-05 10:23:24,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:24,846 INFO:     Epoch: 37
2023-01-05 10:23:26,962 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.404607625802358, 'Total loss': 0.404607625802358} | train loss {'Reaction outcome loss': 0.3666754510482296, 'Total loss': 0.3666754510482296}
2023-01-05 10:23:26,962 INFO:     Found new best model at epoch 37
2023-01-05 10:23:26,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:26,963 INFO:     Epoch: 38
2023-01-05 10:23:29,114 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4229149386286736, 'Total loss': 0.4229149386286736} | train loss {'Reaction outcome loss': 0.36614093579862955, 'Total loss': 0.36614093579862955}
2023-01-05 10:23:29,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:29,115 INFO:     Epoch: 39
2023-01-05 10:23:31,272 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4015369961659114, 'Total loss': 0.4015369961659114} | train loss {'Reaction outcome loss': 0.36444252850454206, 'Total loss': 0.36444252850454206}
2023-01-05 10:23:31,273 INFO:     Found new best model at epoch 39
2023-01-05 10:23:31,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:31,275 INFO:     Epoch: 40
2023-01-05 10:23:33,424 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4213542858759562, 'Total loss': 0.4213542858759562} | train loss {'Reaction outcome loss': 0.35895563304316697, 'Total loss': 0.35895563304316697}
2023-01-05 10:23:33,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:33,424 INFO:     Epoch: 41
2023-01-05 10:23:35,553 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4319520781437556, 'Total loss': 0.4319520781437556} | train loss {'Reaction outcome loss': 0.36057119671295695, 'Total loss': 0.36057119671295695}
2023-01-05 10:23:35,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:35,553 INFO:     Epoch: 42
2023-01-05 10:23:37,709 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4089616388082504, 'Total loss': 0.4089616388082504} | train loss {'Reaction outcome loss': 0.34973349516357327, 'Total loss': 0.34973349516357327}
2023-01-05 10:23:37,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:37,710 INFO:     Epoch: 43
2023-01-05 10:23:39,867 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4025055388609568, 'Total loss': 0.4025055388609568} | train loss {'Reaction outcome loss': 0.3486081427131319, 'Total loss': 0.3486081427131319}
2023-01-05 10:23:39,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:39,868 INFO:     Epoch: 44
2023-01-05 10:23:41,992 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4348600010077159, 'Total loss': 0.4348600010077159} | train loss {'Reaction outcome loss': 0.34406989522359, 'Total loss': 0.34406989522359}
2023-01-05 10:23:41,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:41,993 INFO:     Epoch: 45
2023-01-05 10:23:44,100 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39049751808245975, 'Total loss': 0.39049751808245975} | train loss {'Reaction outcome loss': 0.3388260645314459, 'Total loss': 0.3388260645314459}
2023-01-05 10:23:44,100 INFO:     Found new best model at epoch 45
2023-01-05 10:23:44,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:44,101 INFO:     Epoch: 46
2023-01-05 10:23:46,206 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4281604826450348, 'Total loss': 0.4281604826450348} | train loss {'Reaction outcome loss': 0.34127449998060505, 'Total loss': 0.34127449998060505}
2023-01-05 10:23:46,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:46,206 INFO:     Epoch: 47
2023-01-05 10:23:48,320 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39928972323735556, 'Total loss': 0.39928972323735556} | train loss {'Reaction outcome loss': 0.33379219175191993, 'Total loss': 0.33379219175191993}
2023-01-05 10:23:48,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:48,321 INFO:     Epoch: 48
2023-01-05 10:23:50,440 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4467138389746348, 'Total loss': 0.4467138389746348} | train loss {'Reaction outcome loss': 0.3337350250204978, 'Total loss': 0.3337350250204978}
2023-01-05 10:23:50,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:50,441 INFO:     Epoch: 49
2023-01-05 10:23:52,575 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42745462656021116, 'Total loss': 0.42745462656021116} | train loss {'Reaction outcome loss': 0.33150572500558106, 'Total loss': 0.33150572500558106}
2023-01-05 10:23:52,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:52,575 INFO:     Epoch: 50
2023-01-05 10:23:54,742 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41484267512957257, 'Total loss': 0.41484267512957257} | train loss {'Reaction outcome loss': 0.32654023327820997, 'Total loss': 0.32654023327820997}
2023-01-05 10:23:54,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:54,742 INFO:     Epoch: 51
2023-01-05 10:23:56,940 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4198089112838109, 'Total loss': 0.4198089112838109} | train loss {'Reaction outcome loss': 0.3229386268674467, 'Total loss': 0.3229386268674467}
2023-01-05 10:23:56,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:56,941 INFO:     Epoch: 52
2023-01-05 10:23:59,151 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4214293330907822, 'Total loss': 0.4214293330907822} | train loss {'Reaction outcome loss': 0.31910295929719396, 'Total loss': 0.31910295929719396}
2023-01-05 10:23:59,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:23:59,151 INFO:     Epoch: 53
2023-01-05 10:24:01,323 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42439879129330316, 'Total loss': 0.42439879129330316} | train loss {'Reaction outcome loss': 0.3192058845224794, 'Total loss': 0.3192058845224794}
2023-01-05 10:24:01,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:01,323 INFO:     Epoch: 54
2023-01-05 10:24:03,514 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.416757137576739, 'Total loss': 0.416757137576739} | train loss {'Reaction outcome loss': 0.3163284293312028, 'Total loss': 0.3163284293312028}
2023-01-05 10:24:03,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:03,515 INFO:     Epoch: 55
2023-01-05 10:24:05,657 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44171032309532166, 'Total loss': 0.44171032309532166} | train loss {'Reaction outcome loss': 0.315384469805319, 'Total loss': 0.315384469805319}
2023-01-05 10:24:05,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:05,657 INFO:     Epoch: 56
2023-01-05 10:24:07,787 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4251655101776123, 'Total loss': 0.4251655101776123} | train loss {'Reaction outcome loss': 0.3151469493708456, 'Total loss': 0.3151469493708456}
2023-01-05 10:24:07,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:07,788 INFO:     Epoch: 57
2023-01-05 10:24:09,904 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4139203205704689, 'Total loss': 0.4139203205704689} | train loss {'Reaction outcome loss': 0.30456874055606364, 'Total loss': 0.30456874055606364}
2023-01-05 10:24:09,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:09,904 INFO:     Epoch: 58
2023-01-05 10:24:12,028 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42020425001780193, 'Total loss': 0.42020425001780193} | train loss {'Reaction outcome loss': 0.3098682821711478, 'Total loss': 0.3098682821711478}
2023-01-05 10:24:12,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:12,028 INFO:     Epoch: 59
2023-01-05 10:24:14,134 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3989059865474701, 'Total loss': 0.3989059865474701} | train loss {'Reaction outcome loss': 0.30893275908291984, 'Total loss': 0.30893275908291984}
2023-01-05 10:24:14,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:14,135 INFO:     Epoch: 60
2023-01-05 10:24:16,252 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41726374824841816, 'Total loss': 0.41726374824841816} | train loss {'Reaction outcome loss': 0.3055441247749845, 'Total loss': 0.3055441247749845}
2023-01-05 10:24:16,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:16,252 INFO:     Epoch: 61
2023-01-05 10:24:18,356 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3983363697926203, 'Total loss': 0.3983363697926203} | train loss {'Reaction outcome loss': 0.315565994554048, 'Total loss': 0.315565994554048}
2023-01-05 10:24:18,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:18,356 INFO:     Epoch: 62
2023-01-05 10:24:20,471 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39359162251154584, 'Total loss': 0.39359162251154584} | train loss {'Reaction outcome loss': 0.2970489598676186, 'Total loss': 0.2970489598676186}
2023-01-05 10:24:20,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:20,471 INFO:     Epoch: 63
2023-01-05 10:24:22,591 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41536434590816496, 'Total loss': 0.41536434590816496} | train loss {'Reaction outcome loss': 0.298370845562069, 'Total loss': 0.298370845562069}
2023-01-05 10:24:22,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:22,591 INFO:     Epoch: 64
2023-01-05 10:24:24,716 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4159696934123834, 'Total loss': 0.4159696934123834} | train loss {'Reaction outcome loss': 0.2984157899387907, 'Total loss': 0.2984157899387907}
2023-01-05 10:24:24,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:24,717 INFO:     Epoch: 65
2023-01-05 10:24:26,844 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42709009647369384, 'Total loss': 0.42709009647369384} | train loss {'Reaction outcome loss': 0.2989452496197895, 'Total loss': 0.2989452496197895}
2023-01-05 10:24:26,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:26,845 INFO:     Epoch: 66
2023-01-05 10:24:28,998 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38819798100739716, 'Total loss': 0.38819798100739716} | train loss {'Reaction outcome loss': 0.29276477021000447, 'Total loss': 0.29276477021000447}
2023-01-05 10:24:28,998 INFO:     Found new best model at epoch 66
2023-01-05 10:24:28,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:29,000 INFO:     Epoch: 67
2023-01-05 10:24:31,151 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40424217929442724, 'Total loss': 0.40424217929442724} | train loss {'Reaction outcome loss': 0.29599560660037755, 'Total loss': 0.29599560660037755}
2023-01-05 10:24:31,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:31,151 INFO:     Epoch: 68
2023-01-05 10:24:33,292 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4103562533855438, 'Total loss': 0.4103562533855438} | train loss {'Reaction outcome loss': 0.2913132892629058, 'Total loss': 0.2913132892629058}
2023-01-05 10:24:33,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:33,292 INFO:     Epoch: 69
2023-01-05 10:24:35,439 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4094690630833308, 'Total loss': 0.4094690630833308} | train loss {'Reaction outcome loss': 0.2831361268105705, 'Total loss': 0.2831361268105705}
2023-01-05 10:24:35,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:35,439 INFO:     Epoch: 70
2023-01-05 10:24:37,550 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4223369320233663, 'Total loss': 0.4223369320233663} | train loss {'Reaction outcome loss': 0.2935897884924059, 'Total loss': 0.2935897884924059}
2023-01-05 10:24:37,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:37,552 INFO:     Epoch: 71
2023-01-05 10:24:39,668 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4156778564055761, 'Total loss': 0.4156778564055761} | train loss {'Reaction outcome loss': 0.2821623863322855, 'Total loss': 0.2821623863322855}
2023-01-05 10:24:39,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:39,668 INFO:     Epoch: 72
2023-01-05 10:24:41,780 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.421674703558286, 'Total loss': 0.421674703558286} | train loss {'Reaction outcome loss': 0.2841905418258927, 'Total loss': 0.2841905418258927}
2023-01-05 10:24:41,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:41,781 INFO:     Epoch: 73
2023-01-05 10:24:43,926 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4308498382568359, 'Total loss': 0.4308498382568359} | train loss {'Reaction outcome loss': 0.28164184829791744, 'Total loss': 0.28164184829791744}
2023-01-05 10:24:43,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:43,927 INFO:     Epoch: 74
2023-01-05 10:24:46,059 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44461627999941505, 'Total loss': 0.44461627999941505} | train loss {'Reaction outcome loss': 0.27838476372055626, 'Total loss': 0.27838476372055626}
2023-01-05 10:24:46,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:46,059 INFO:     Epoch: 75
2023-01-05 10:24:48,201 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45024355947971345, 'Total loss': 0.45024355947971345} | train loss {'Reaction outcome loss': 0.2753751531297119, 'Total loss': 0.2753751531297119}
2023-01-05 10:24:48,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:48,201 INFO:     Epoch: 76
2023-01-05 10:24:50,396 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4378053963184357, 'Total loss': 0.4378053963184357} | train loss {'Reaction outcome loss': 0.27578597983836267, 'Total loss': 0.27578597983836267}
2023-01-05 10:24:50,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:50,397 INFO:     Epoch: 77
2023-01-05 10:24:52,549 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4102170765399933, 'Total loss': 0.4102170765399933} | train loss {'Reaction outcome loss': 0.27813248910574706, 'Total loss': 0.27813248910574706}
2023-01-05 10:24:52,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:52,549 INFO:     Epoch: 78
2023-01-05 10:24:54,695 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41537572840849557, 'Total loss': 0.41537572840849557} | train loss {'Reaction outcome loss': 0.27506985583944443, 'Total loss': 0.27506985583944443}
2023-01-05 10:24:54,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:54,695 INFO:     Epoch: 79
2023-01-05 10:24:56,831 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4398311992486318, 'Total loss': 0.4398311992486318} | train loss {'Reaction outcome loss': 0.2726929050261686, 'Total loss': 0.2726929050261686}
2023-01-05 10:24:56,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:56,831 INFO:     Epoch: 80
2023-01-05 10:24:58,957 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41688287258148193, 'Total loss': 0.41688287258148193} | train loss {'Reaction outcome loss': 0.27104249258360924, 'Total loss': 0.27104249258360924}
2023-01-05 10:24:58,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:24:58,957 INFO:     Epoch: 81
2023-01-05 10:25:01,087 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4085486223300298, 'Total loss': 0.4085486223300298} | train loss {'Reaction outcome loss': 0.2710655796600486, 'Total loss': 0.2710655796600486}
2023-01-05 10:25:01,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:01,087 INFO:     Epoch: 82
2023-01-05 10:25:03,230 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.435022184252739, 'Total loss': 0.435022184252739} | train loss {'Reaction outcome loss': 0.27089538424534704, 'Total loss': 0.27089538424534704}
2023-01-05 10:25:03,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:03,230 INFO:     Epoch: 83
2023-01-05 10:25:05,375 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45833560774723686, 'Total loss': 0.45833560774723686} | train loss {'Reaction outcome loss': 0.2646140974378112, 'Total loss': 0.2646140974378112}
2023-01-05 10:25:05,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:05,375 INFO:     Epoch: 84
2023-01-05 10:25:07,507 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42022030254205067, 'Total loss': 0.42022030254205067} | train loss {'Reaction outcome loss': 0.2653195295442528, 'Total loss': 0.2653195295442528}
2023-01-05 10:25:07,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:07,507 INFO:     Epoch: 85
2023-01-05 10:25:09,612 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4205847332874934, 'Total loss': 0.4205847332874934} | train loss {'Reaction outcome loss': 0.2606688291237888, 'Total loss': 0.2606688291237888}
2023-01-05 10:25:09,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:09,612 INFO:     Epoch: 86
2023-01-05 10:25:11,742 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4251880745093028, 'Total loss': 0.4251880745093028} | train loss {'Reaction outcome loss': 0.26041297262218455, 'Total loss': 0.26041297262218455}
2023-01-05 10:25:11,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:11,742 INFO:     Epoch: 87
2023-01-05 10:25:13,885 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4305070901910464, 'Total loss': 0.4305070901910464} | train loss {'Reaction outcome loss': 0.26040850379352964, 'Total loss': 0.26040850379352964}
2023-01-05 10:25:13,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:13,886 INFO:     Epoch: 88
2023-01-05 10:25:16,013 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.407574583341678, 'Total loss': 0.407574583341678} | train loss {'Reaction outcome loss': 0.2532801047263378, 'Total loss': 0.2532801047263378}
2023-01-05 10:25:16,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:16,014 INFO:     Epoch: 89
2023-01-05 10:25:18,148 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3993197272221247, 'Total loss': 0.3993197272221247} | train loss {'Reaction outcome loss': 0.2577918536476925, 'Total loss': 0.2577918536476925}
2023-01-05 10:25:18,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:18,148 INFO:     Epoch: 90
2023-01-05 10:25:20,288 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4470387230316798, 'Total loss': 0.4470387230316798} | train loss {'Reaction outcome loss': 0.25126247221624165, 'Total loss': 0.25126247221624165}
2023-01-05 10:25:20,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:20,289 INFO:     Epoch: 91
2023-01-05 10:25:22,418 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4207713464895884, 'Total loss': 0.4207713464895884} | train loss {'Reaction outcome loss': 0.2505964325330748, 'Total loss': 0.2505964325330748}
2023-01-05 10:25:22,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:22,419 INFO:     Epoch: 92
2023-01-05 10:25:24,549 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4425399879614512, 'Total loss': 0.4425399879614512} | train loss {'Reaction outcome loss': 0.24650722034006559, 'Total loss': 0.24650722034006559}
2023-01-05 10:25:24,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:24,549 INFO:     Epoch: 93
2023-01-05 10:25:26,669 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.420361024638017, 'Total loss': 0.420361024638017} | train loss {'Reaction outcome loss': 0.25918710214297697, 'Total loss': 0.25918710214297697}
2023-01-05 10:25:26,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:26,669 INFO:     Epoch: 94
2023-01-05 10:25:28,809 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42455300092697146, 'Total loss': 0.42455300092697146} | train loss {'Reaction outcome loss': 0.25040341442323116, 'Total loss': 0.25040341442323116}
2023-01-05 10:25:28,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:28,809 INFO:     Epoch: 95
2023-01-05 10:25:30,953 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41699435661236445, 'Total loss': 0.41699435661236445} | train loss {'Reaction outcome loss': 0.25043478476334136, 'Total loss': 0.25043478476334136}
2023-01-05 10:25:30,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:30,954 INFO:     Epoch: 96
2023-01-05 10:25:33,092 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4498220553000768, 'Total loss': 0.4498220553000768} | train loss {'Reaction outcome loss': 0.2472582299813682, 'Total loss': 0.2472582299813682}
2023-01-05 10:25:33,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:33,093 INFO:     Epoch: 97
2023-01-05 10:25:35,230 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41266293327013653, 'Total loss': 0.41266293327013653} | train loss {'Reaction outcome loss': 0.25284496323619077, 'Total loss': 0.25284496323619077}
2023-01-05 10:25:35,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:35,230 INFO:     Epoch: 98
2023-01-05 10:25:37,344 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43274673422177634, 'Total loss': 0.43274673422177634} | train loss {'Reaction outcome loss': 0.25275638932866523, 'Total loss': 0.25275638932866523}
2023-01-05 10:25:37,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:37,345 INFO:     Epoch: 99
2023-01-05 10:25:39,475 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4177463561296463, 'Total loss': 0.4177463561296463} | train loss {'Reaction outcome loss': 0.2517061587759304, 'Total loss': 0.2517061587759304}
2023-01-05 10:25:39,475 INFO:     Best model found after epoch 67 of 100.
2023-01-05 10:25:39,476 INFO:   Done with stage: TRAINING
2023-01-05 10:25:39,476 INFO:   Starting stage: EVALUATION
2023-01-05 10:25:39,604 INFO:   Done with stage: EVALUATION
2023-01-05 10:25:39,604 INFO:   Leaving out SEQ value Fold_6
2023-01-05 10:25:39,616 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 10:25:39,616 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:25:40,272 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:25:40,272 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:25:40,342 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:25:40,342 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:25:40,342 INFO:     No hyperparam tuning for this model
2023-01-05 10:25:40,342 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:25:40,342 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:25:40,343 INFO:     None feature selector for col prot
2023-01-05 10:25:40,343 INFO:     None feature selector for col prot
2023-01-05 10:25:40,343 INFO:     None feature selector for col prot
2023-01-05 10:25:40,344 INFO:     None feature selector for col chem
2023-01-05 10:25:40,344 INFO:     None feature selector for col chem
2023-01-05 10:25:40,344 INFO:     None feature selector for col chem
2023-01-05 10:25:40,344 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:25:40,344 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:25:40,346 INFO:     Number of params in model 72901
2023-01-05 10:25:40,349 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:25:40,349 INFO:   Starting stage: TRAINING
2023-01-05 10:25:40,408 INFO:     Val loss before train {'Reaction outcome loss': 0.9329765319824219, 'Total loss': 0.9329765319824219}
2023-01-05 10:25:40,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:40,408 INFO:     Epoch: 0
2023-01-05 10:25:42,532 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7860983351866404, 'Total loss': 0.7860983351866404} | train loss {'Reaction outcome loss': 0.9120520941832436, 'Total loss': 0.9120520941832436}
2023-01-05 10:25:42,533 INFO:     Found new best model at epoch 0
2023-01-05 10:25:42,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:42,534 INFO:     Epoch: 1
2023-01-05 10:25:44,674 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5889755427837372, 'Total loss': 0.5889755427837372} | train loss {'Reaction outcome loss': 0.728913159146636, 'Total loss': 0.728913159146636}
2023-01-05 10:25:44,674 INFO:     Found new best model at epoch 1
2023-01-05 10:25:44,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:44,675 INFO:     Epoch: 2
2023-01-05 10:25:46,797 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5005936125914255, 'Total loss': 0.5005936125914255} | train loss {'Reaction outcome loss': 0.5699473660345112, 'Total loss': 0.5699473660345112}
2023-01-05 10:25:46,797 INFO:     Found new best model at epoch 2
2023-01-05 10:25:46,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:46,799 INFO:     Epoch: 3
2023-01-05 10:25:48,905 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4744333902994792, 'Total loss': 0.4744333902994792} | train loss {'Reaction outcome loss': 0.5334149913505957, 'Total loss': 0.5334149913505957}
2023-01-05 10:25:48,906 INFO:     Found new best model at epoch 3
2023-01-05 10:25:48,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:48,907 INFO:     Epoch: 4
2023-01-05 10:25:51,064 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.501271919409434, 'Total loss': 0.501271919409434} | train loss {'Reaction outcome loss': 0.5110850755380809, 'Total loss': 0.5110850755380809}
2023-01-05 10:25:51,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:51,064 INFO:     Epoch: 5
2023-01-05 10:25:53,216 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47175346811612445, 'Total loss': 0.47175346811612445} | train loss {'Reaction outcome loss': 0.49961939362627505, 'Total loss': 0.49961939362627505}
2023-01-05 10:25:53,216 INFO:     Found new best model at epoch 5
2023-01-05 10:25:53,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:53,217 INFO:     Epoch: 6
2023-01-05 10:25:55,353 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46918886303901675, 'Total loss': 0.46918886303901675} | train loss {'Reaction outcome loss': 0.49234515245640753, 'Total loss': 0.49234515245640753}
2023-01-05 10:25:55,354 INFO:     Found new best model at epoch 6
2023-01-05 10:25:55,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:55,355 INFO:     Epoch: 7
2023-01-05 10:25:57,511 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4696727613608042, 'Total loss': 0.4696727613608042} | train loss {'Reaction outcome loss': 0.4931241509501254, 'Total loss': 0.4931241509501254}
2023-01-05 10:25:57,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:57,511 INFO:     Epoch: 8
2023-01-05 10:25:59,653 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4569467157125473, 'Total loss': 0.4569467157125473} | train loss {'Reaction outcome loss': 0.4819521531193695, 'Total loss': 0.4819521531193695}
2023-01-05 10:25:59,653 INFO:     Found new best model at epoch 8
2023-01-05 10:25:59,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:25:59,655 INFO:     Epoch: 9
2023-01-05 10:26:01,776 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4314264496167501, 'Total loss': 0.4314264496167501} | train loss {'Reaction outcome loss': 0.4738131729811968, 'Total loss': 0.4738131729811968}
2023-01-05 10:26:01,776 INFO:     Found new best model at epoch 9
2023-01-05 10:26:01,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:01,777 INFO:     Epoch: 10
2023-01-05 10:26:03,935 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4506345510482788, 'Total loss': 0.4506345510482788} | train loss {'Reaction outcome loss': 0.46944857278455465, 'Total loss': 0.46944857278455465}
2023-01-05 10:26:03,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:03,936 INFO:     Epoch: 11
2023-01-05 10:26:05,871 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4308552145957947, 'Total loss': 0.4308552145957947} | train loss {'Reaction outcome loss': 0.4715684648293881, 'Total loss': 0.4715684648293881}
2023-01-05 10:26:05,871 INFO:     Found new best model at epoch 11
2023-01-05 10:26:05,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:05,872 INFO:     Epoch: 12
2023-01-05 10:26:08,023 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4331936260064443, 'Total loss': 0.4331936260064443} | train loss {'Reaction outcome loss': 0.46131713311809924, 'Total loss': 0.46131713311809924}
2023-01-05 10:26:08,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:08,024 INFO:     Epoch: 13
2023-01-05 10:26:10,192 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44912763436635333, 'Total loss': 0.44912763436635333} | train loss {'Reaction outcome loss': 0.4561967767963341, 'Total loss': 0.4561967767963341}
2023-01-05 10:26:10,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:10,192 INFO:     Epoch: 14
2023-01-05 10:26:12,379 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4244467695554098, 'Total loss': 0.4244467695554098} | train loss {'Reaction outcome loss': 0.4524347863903114, 'Total loss': 0.4524347863903114}
2023-01-05 10:26:12,379 INFO:     Found new best model at epoch 14
2023-01-05 10:26:12,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:12,381 INFO:     Epoch: 15
2023-01-05 10:26:14,544 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44205345809459684, 'Total loss': 0.44205345809459684} | train loss {'Reaction outcome loss': 0.45260554121719804, 'Total loss': 0.45260554121719804}
2023-01-05 10:26:14,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:14,545 INFO:     Epoch: 16
2023-01-05 10:26:16,661 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4563149571418762, 'Total loss': 0.4563149571418762} | train loss {'Reaction outcome loss': 0.4441473952592065, 'Total loss': 0.4441473952592065}
2023-01-05 10:26:16,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:16,662 INFO:     Epoch: 17
2023-01-05 10:26:18,804 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4469064076741536, 'Total loss': 0.4469064076741536} | train loss {'Reaction outcome loss': 0.4364123635182312, 'Total loss': 0.4364123635182312}
2023-01-05 10:26:18,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:18,804 INFO:     Epoch: 18
2023-01-05 10:26:20,935 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4280899852514267, 'Total loss': 0.4280899852514267} | train loss {'Reaction outcome loss': 0.4363032825264259, 'Total loss': 0.4363032825264259}
2023-01-05 10:26:20,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:20,935 INFO:     Epoch: 19
2023-01-05 10:26:23,074 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4162620484828949, 'Total loss': 0.4162620484828949} | train loss {'Reaction outcome loss': 0.4443972355514657, 'Total loss': 0.4443972355514657}
2023-01-05 10:26:23,074 INFO:     Found new best model at epoch 19
2023-01-05 10:26:23,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:23,076 INFO:     Epoch: 20
2023-01-05 10:26:25,230 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41971568365891776, 'Total loss': 0.41971568365891776} | train loss {'Reaction outcome loss': 0.4288068570277321, 'Total loss': 0.4288068570277321}
2023-01-05 10:26:25,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:25,231 INFO:     Epoch: 21
2023-01-05 10:26:27,390 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45051710804303485, 'Total loss': 0.45051710804303485} | train loss {'Reaction outcome loss': 0.42926297880144326, 'Total loss': 0.42926297880144326}
2023-01-05 10:26:27,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:27,390 INFO:     Epoch: 22
2023-01-05 10:26:29,529 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4042043586572011, 'Total loss': 0.4042043586572011} | train loss {'Reaction outcome loss': 0.4247402011917817, 'Total loss': 0.4247402011917817}
2023-01-05 10:26:29,529 INFO:     Found new best model at epoch 22
2023-01-05 10:26:29,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:29,530 INFO:     Epoch: 23
2023-01-05 10:26:31,674 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42258137464523315, 'Total loss': 0.42258137464523315} | train loss {'Reaction outcome loss': 0.41790264032592844, 'Total loss': 0.41790264032592844}
2023-01-05 10:26:31,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:31,675 INFO:     Epoch: 24
2023-01-05 10:26:33,835 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4561513861020406, 'Total loss': 0.4561513861020406} | train loss {'Reaction outcome loss': 0.41936311830467266, 'Total loss': 0.41936311830467266}
2023-01-05 10:26:33,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:33,835 INFO:     Epoch: 25
2023-01-05 10:26:35,984 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4082975933949153, 'Total loss': 0.4082975933949153} | train loss {'Reaction outcome loss': 0.41374167247208016, 'Total loss': 0.41374167247208016}
2023-01-05 10:26:35,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:35,984 INFO:     Epoch: 26
2023-01-05 10:26:38,327 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4045014649629593, 'Total loss': 0.4045014649629593} | train loss {'Reaction outcome loss': 0.4168104214143237, 'Total loss': 0.4168104214143237}
2023-01-05 10:26:38,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:38,327 INFO:     Epoch: 27
2023-01-05 10:26:40,479 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41890822450319926, 'Total loss': 0.41890822450319926} | train loss {'Reaction outcome loss': 0.4082637661630927, 'Total loss': 0.4082637661630927}
2023-01-05 10:26:40,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:40,479 INFO:     Epoch: 28
2023-01-05 10:26:42,638 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41830481092135113, 'Total loss': 0.41830481092135113} | train loss {'Reaction outcome loss': 0.4068122839938432, 'Total loss': 0.4068122839938432}
2023-01-05 10:26:42,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:42,638 INFO:     Epoch: 29
2023-01-05 10:26:44,806 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41477456092834475, 'Total loss': 0.41477456092834475} | train loss {'Reaction outcome loss': 0.39946924187646443, 'Total loss': 0.39946924187646443}
2023-01-05 10:26:44,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:44,807 INFO:     Epoch: 30
2023-01-05 10:26:46,983 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42235358158747355, 'Total loss': 0.42235358158747355} | train loss {'Reaction outcome loss': 0.40160708320377536, 'Total loss': 0.40160708320377536}
2023-01-05 10:26:46,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:46,984 INFO:     Epoch: 31
2023-01-05 10:26:49,143 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4276293655236562, 'Total loss': 0.4276293655236562} | train loss {'Reaction outcome loss': 0.3954805994829977, 'Total loss': 0.3954805994829977}
2023-01-05 10:26:49,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:49,144 INFO:     Epoch: 32
2023-01-05 10:26:51,302 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3854118237892787, 'Total loss': 0.3854118237892787} | train loss {'Reaction outcome loss': 0.39389427552261935, 'Total loss': 0.39389427552261935}
2023-01-05 10:26:51,302 INFO:     Found new best model at epoch 32
2023-01-05 10:26:51,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:51,303 INFO:     Epoch: 33
2023-01-05 10:26:53,456 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39891260067621864, 'Total loss': 0.39891260067621864} | train loss {'Reaction outcome loss': 0.3873749132728749, 'Total loss': 0.3873749132728749}
2023-01-05 10:26:53,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:53,456 INFO:     Epoch: 34
2023-01-05 10:26:55,571 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4142764945824941, 'Total loss': 0.4142764945824941} | train loss {'Reaction outcome loss': 0.3868491045780991, 'Total loss': 0.3868491045780991}
2023-01-05 10:26:55,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:55,572 INFO:     Epoch: 35
2023-01-05 10:26:57,716 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3870601902405421, 'Total loss': 0.3870601902405421} | train loss {'Reaction outcome loss': 0.3813967535588285, 'Total loss': 0.3813967535588285}
2023-01-05 10:26:57,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:57,716 INFO:     Epoch: 36
2023-01-05 10:26:59,876 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3810927758614222, 'Total loss': 0.3810927758614222} | train loss {'Reaction outcome loss': 0.3745939804624349, 'Total loss': 0.3745939804624349}
2023-01-05 10:26:59,876 INFO:     Found new best model at epoch 36
2023-01-05 10:26:59,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:26:59,878 INFO:     Epoch: 37
2023-01-05 10:27:01,980 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39964381357034046, 'Total loss': 0.39964381357034046} | train loss {'Reaction outcome loss': 0.3736847906847508, 'Total loss': 0.3736847906847508}
2023-01-05 10:27:01,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:01,981 INFO:     Epoch: 38
2023-01-05 10:27:04,114 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37011668682098386, 'Total loss': 0.37011668682098386} | train loss {'Reaction outcome loss': 0.37155186554369946, 'Total loss': 0.37155186554369946}
2023-01-05 10:27:04,115 INFO:     Found new best model at epoch 38
2023-01-05 10:27:04,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:04,116 INFO:     Epoch: 39
2023-01-05 10:27:06,257 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39906423290570575, 'Total loss': 0.39906423290570575} | train loss {'Reaction outcome loss': 0.3714067688756471, 'Total loss': 0.3714067688756471}
2023-01-05 10:27:06,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:06,257 INFO:     Epoch: 40
2023-01-05 10:27:08,476 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3825908124446869, 'Total loss': 0.3825908124446869} | train loss {'Reaction outcome loss': 0.36229203119605025, 'Total loss': 0.36229203119605025}
2023-01-05 10:27:08,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:08,477 INFO:     Epoch: 41
2023-01-05 10:27:10,640 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3990289295713107, 'Total loss': 0.3990289295713107} | train loss {'Reaction outcome loss': 0.361006051624725, 'Total loss': 0.361006051624725}
2023-01-05 10:27:10,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:10,641 INFO:     Epoch: 42
2023-01-05 10:27:12,840 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38309579292933144, 'Total loss': 0.38309579292933144} | train loss {'Reaction outcome loss': 0.3622973889166267, 'Total loss': 0.3622973889166267}
2023-01-05 10:27:12,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:12,841 INFO:     Epoch: 43
2023-01-05 10:27:14,984 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3872114380200704, 'Total loss': 0.3872114380200704} | train loss {'Reaction outcome loss': 0.3596739875764623, 'Total loss': 0.3596739875764623}
2023-01-05 10:27:14,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:14,984 INFO:     Epoch: 44
2023-01-05 10:27:17,197 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3659274518489838, 'Total loss': 0.3659274518489838} | train loss {'Reaction outcome loss': 0.3479960625621386, 'Total loss': 0.3479960625621386}
2023-01-05 10:27:17,198 INFO:     Found new best model at epoch 44
2023-01-05 10:27:17,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:17,199 INFO:     Epoch: 45
2023-01-05 10:27:19,372 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3745720664660136, 'Total loss': 0.3745720664660136} | train loss {'Reaction outcome loss': 0.35395451694296587, 'Total loss': 0.35395451694296587}
2023-01-05 10:27:19,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:19,372 INFO:     Epoch: 46
2023-01-05 10:27:21,568 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3936908801396688, 'Total loss': 0.3936908801396688} | train loss {'Reaction outcome loss': 0.34825135140750385, 'Total loss': 0.34825135140750385}
2023-01-05 10:27:21,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:21,569 INFO:     Epoch: 47
2023-01-05 10:27:23,712 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3746430516242981, 'Total loss': 0.3746430516242981} | train loss {'Reaction outcome loss': 0.34835174784656037, 'Total loss': 0.34835174784656037}
2023-01-05 10:27:23,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:23,712 INFO:     Epoch: 48
2023-01-05 10:27:25,894 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40595997671286266, 'Total loss': 0.40595997671286266} | train loss {'Reaction outcome loss': 0.3451319436411565, 'Total loss': 0.3451319436411565}
2023-01-05 10:27:25,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:25,894 INFO:     Epoch: 49
2023-01-05 10:27:28,087 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3770994414885839, 'Total loss': 0.3770994414885839} | train loss {'Reaction outcome loss': 0.34135675091390577, 'Total loss': 0.34135675091390577}
2023-01-05 10:27:28,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:28,087 INFO:     Epoch: 50
2023-01-05 10:27:30,268 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40954598039388657, 'Total loss': 0.40954598039388657} | train loss {'Reaction outcome loss': 0.3325772344904686, 'Total loss': 0.3325772344904686}
2023-01-05 10:27:30,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:30,268 INFO:     Epoch: 51
2023-01-05 10:27:32,452 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36116516093413037, 'Total loss': 0.36116516093413037} | train loss {'Reaction outcome loss': 0.3404747736152759, 'Total loss': 0.3404747736152759}
2023-01-05 10:27:32,453 INFO:     Found new best model at epoch 51
2023-01-05 10:27:32,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:32,454 INFO:     Epoch: 52
2023-01-05 10:27:34,642 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39274214779337246, 'Total loss': 0.39274214779337246} | train loss {'Reaction outcome loss': 0.3280490415190962, 'Total loss': 0.3280490415190962}
2023-01-05 10:27:34,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:34,642 INFO:     Epoch: 53
2023-01-05 10:27:36,764 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39445646305878956, 'Total loss': 0.39445646305878956} | train loss {'Reaction outcome loss': 0.3257182942239386, 'Total loss': 0.3257182942239386}
2023-01-05 10:27:36,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:36,765 INFO:     Epoch: 54
2023-01-05 10:27:38,901 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37315354744593304, 'Total loss': 0.37315354744593304} | train loss {'Reaction outcome loss': 0.3253256035195361, 'Total loss': 0.3253256035195361}
2023-01-05 10:27:38,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:38,902 INFO:     Epoch: 55
2023-01-05 10:27:41,016 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37058013180891675, 'Total loss': 0.37058013180891675} | train loss {'Reaction outcome loss': 0.32619815501334004, 'Total loss': 0.32619815501334004}
2023-01-05 10:27:41,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:41,016 INFO:     Epoch: 56
2023-01-05 10:27:43,179 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.372941059867541, 'Total loss': 0.372941059867541} | train loss {'Reaction outcome loss': 0.32004165833661274, 'Total loss': 0.32004165833661274}
2023-01-05 10:27:43,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:43,179 INFO:     Epoch: 57
2023-01-05 10:27:45,313 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3866742730140686, 'Total loss': 0.3866742730140686} | train loss {'Reaction outcome loss': 0.31782500435756217, 'Total loss': 0.31782500435756217}
2023-01-05 10:27:45,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:45,314 INFO:     Epoch: 58
2023-01-05 10:27:47,440 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38290112614631655, 'Total loss': 0.38290112614631655} | train loss {'Reaction outcome loss': 0.3136749382967983, 'Total loss': 0.3136749382967983}
2023-01-05 10:27:47,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:47,440 INFO:     Epoch: 59
2023-01-05 10:27:49,592 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3915230025847753, 'Total loss': 0.3915230025847753} | train loss {'Reaction outcome loss': 0.31762362145129525, 'Total loss': 0.31762362145129525}
2023-01-05 10:27:49,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:49,592 INFO:     Epoch: 60
2023-01-05 10:27:51,709 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3684136097629865, 'Total loss': 0.3684136097629865} | train loss {'Reaction outcome loss': 0.31633860245347023, 'Total loss': 0.31633860245347023}
2023-01-05 10:27:51,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:51,710 INFO:     Epoch: 61
2023-01-05 10:27:53,809 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.369797956943512, 'Total loss': 0.369797956943512} | train loss {'Reaction outcome loss': 0.30846553209779065, 'Total loss': 0.30846553209779065}
2023-01-05 10:27:53,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:53,809 INFO:     Epoch: 62
2023-01-05 10:27:55,942 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3835536311070124, 'Total loss': 0.3835536311070124} | train loss {'Reaction outcome loss': 0.3070494326685525, 'Total loss': 0.3070494326685525}
2023-01-05 10:27:55,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:55,942 INFO:     Epoch: 63
2023-01-05 10:27:58,063 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37209417919317883, 'Total loss': 0.37209417919317883} | train loss {'Reaction outcome loss': 0.3057741385746734, 'Total loss': 0.3057741385746734}
2023-01-05 10:27:58,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:27:58,064 INFO:     Epoch: 64
2023-01-05 10:28:00,175 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4066442221403122, 'Total loss': 0.4066442221403122} | train loss {'Reaction outcome loss': 0.30817020684480667, 'Total loss': 0.30817020684480667}
2023-01-05 10:28:00,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:00,176 INFO:     Epoch: 65
2023-01-05 10:28:02,405 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3866698741912842, 'Total loss': 0.3866698741912842} | train loss {'Reaction outcome loss': 0.3033250903556063, 'Total loss': 0.3033250903556063}
2023-01-05 10:28:02,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:02,405 INFO:     Epoch: 66
2023-01-05 10:28:04,529 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3936910549799601, 'Total loss': 0.3936910549799601} | train loss {'Reaction outcome loss': 0.30666361431782857, 'Total loss': 0.30666361431782857}
2023-01-05 10:28:04,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:04,529 INFO:     Epoch: 67
2023-01-05 10:28:06,652 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40764209429423015, 'Total loss': 0.40764209429423015} | train loss {'Reaction outcome loss': 0.3024320996732918, 'Total loss': 0.3024320996732918}
2023-01-05 10:28:06,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:06,652 INFO:     Epoch: 68
2023-01-05 10:28:08,774 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3904812643925349, 'Total loss': 0.3904812643925349} | train loss {'Reaction outcome loss': 0.30011686166270973, 'Total loss': 0.30011686166270973}
2023-01-05 10:28:08,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:08,776 INFO:     Epoch: 69
2023-01-05 10:28:10,888 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43327010571956637, 'Total loss': 0.43327010571956637} | train loss {'Reaction outcome loss': 0.29906432130222715, 'Total loss': 0.29906432130222715}
2023-01-05 10:28:10,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:10,889 INFO:     Epoch: 70
2023-01-05 10:28:13,016 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36874799529711405, 'Total loss': 0.36874799529711405} | train loss {'Reaction outcome loss': 0.2948071386342337, 'Total loss': 0.2948071386342337}
2023-01-05 10:28:13,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:13,016 INFO:     Epoch: 71
2023-01-05 10:28:15,122 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39507224907477695, 'Total loss': 0.39507224907477695} | train loss {'Reaction outcome loss': 0.28921128988992223, 'Total loss': 0.28921128988992223}
2023-01-05 10:28:15,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:15,123 INFO:     Epoch: 72
2023-01-05 10:28:17,264 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39806281626224516, 'Total loss': 0.39806281626224516} | train loss {'Reaction outcome loss': 0.2935323597332093, 'Total loss': 0.2935323597332093}
2023-01-05 10:28:17,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:17,264 INFO:     Epoch: 73
2023-01-05 10:28:19,457 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3556520034869512, 'Total loss': 0.3556520034869512} | train loss {'Reaction outcome loss': 0.29561246727805063, 'Total loss': 0.29561246727805063}
2023-01-05 10:28:19,457 INFO:     Found new best model at epoch 73
2023-01-05 10:28:19,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:19,458 INFO:     Epoch: 74
2023-01-05 10:28:21,670 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3746843636035919, 'Total loss': 0.3746843636035919} | train loss {'Reaction outcome loss': 0.29236625323226734, 'Total loss': 0.29236625323226734}
2023-01-05 10:28:21,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:21,671 INFO:     Epoch: 75
2023-01-05 10:28:23,863 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43358612855275475, 'Total loss': 0.43358612855275475} | train loss {'Reaction outcome loss': 0.2879241606899762, 'Total loss': 0.2879241606899762}
2023-01-05 10:28:23,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:23,863 INFO:     Epoch: 76
2023-01-05 10:28:26,079 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37689644992351534, 'Total loss': 0.37689644992351534} | train loss {'Reaction outcome loss': 0.2865289745025256, 'Total loss': 0.2865289745025256}
2023-01-05 10:28:26,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:26,080 INFO:     Epoch: 77
2023-01-05 10:28:28,266 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36022807161013287, 'Total loss': 0.36022807161013287} | train loss {'Reaction outcome loss': 0.28693104816419124, 'Total loss': 0.28693104816419124}
2023-01-05 10:28:28,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:28,267 INFO:     Epoch: 78
2023-01-05 10:28:30,445 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37887687037388484, 'Total loss': 0.37887687037388484} | train loss {'Reaction outcome loss': 0.2850551123895585, 'Total loss': 0.2850551123895585}
2023-01-05 10:28:30,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:30,446 INFO:     Epoch: 79
2023-01-05 10:28:32,590 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3654755453268687, 'Total loss': 0.3654755453268687} | train loss {'Reaction outcome loss': 0.2823409293828673, 'Total loss': 0.2823409293828673}
2023-01-05 10:28:32,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:32,590 INFO:     Epoch: 80
2023-01-05 10:28:34,724 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35339428136746087, 'Total loss': 0.35339428136746087} | train loss {'Reaction outcome loss': 0.288256685548741, 'Total loss': 0.288256685548741}
2023-01-05 10:28:34,725 INFO:     Found new best model at epoch 80
2023-01-05 10:28:34,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:34,726 INFO:     Epoch: 81
2023-01-05 10:28:36,898 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4036978562672933, 'Total loss': 0.4036978562672933} | train loss {'Reaction outcome loss': 0.2798863380999449, 'Total loss': 0.2798863380999449}
2023-01-05 10:28:36,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:36,898 INFO:     Epoch: 82
2023-01-05 10:28:39,047 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4120499938726425, 'Total loss': 0.4120499938726425} | train loss {'Reaction outcome loss': 0.2795790669437673, 'Total loss': 0.2795790669437673}
2023-01-05 10:28:39,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:39,048 INFO:     Epoch: 83
2023-01-05 10:28:41,184 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36335215071837107, 'Total loss': 0.36335215071837107} | train loss {'Reaction outcome loss': 0.2867081177417552, 'Total loss': 0.2867081177417552}
2023-01-05 10:28:41,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:41,185 INFO:     Epoch: 84
2023-01-05 10:28:43,344 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4000348667303721, 'Total loss': 0.4000348667303721} | train loss {'Reaction outcome loss': 0.2736821211874485, 'Total loss': 0.2736821211874485}
2023-01-05 10:28:43,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:43,344 INFO:     Epoch: 85
2023-01-05 10:28:45,483 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3891649583975474, 'Total loss': 0.3891649583975474} | train loss {'Reaction outcome loss': 0.2711587265026268, 'Total loss': 0.2711587265026268}
2023-01-05 10:28:45,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:45,484 INFO:     Epoch: 86
2023-01-05 10:28:47,620 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40857779383659365, 'Total loss': 0.40857779383659365} | train loss {'Reaction outcome loss': 0.27643820039578293, 'Total loss': 0.27643820039578293}
2023-01-05 10:28:47,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:47,620 INFO:     Epoch: 87
2023-01-05 10:28:49,770 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3780580018957456, 'Total loss': 0.3780580018957456} | train loss {'Reaction outcome loss': 0.26912079939773365, 'Total loss': 0.26912079939773365}
2023-01-05 10:28:49,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:49,770 INFO:     Epoch: 88
2023-01-05 10:28:51,921 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40572902659575144, 'Total loss': 0.40572902659575144} | train loss {'Reaction outcome loss': 0.274372771691652, 'Total loss': 0.274372771691652}
2023-01-05 10:28:51,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:51,921 INFO:     Epoch: 89
2023-01-05 10:28:54,079 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3874730254213015, 'Total loss': 0.3874730254213015} | train loss {'Reaction outcome loss': 0.26313488697801257, 'Total loss': 0.26313488697801257}
2023-01-05 10:28:54,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:54,079 INFO:     Epoch: 90
2023-01-05 10:28:56,246 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38539335628350574, 'Total loss': 0.38539335628350574} | train loss {'Reaction outcome loss': 0.268688262225085, 'Total loss': 0.268688262225085}
2023-01-05 10:28:56,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:56,246 INFO:     Epoch: 91
2023-01-05 10:28:58,393 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.410160485903422, 'Total loss': 0.410160485903422} | train loss {'Reaction outcome loss': 0.272587216005321, 'Total loss': 0.272587216005321}
2023-01-05 10:28:58,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:28:58,393 INFO:     Epoch: 92
2023-01-05 10:29:00,555 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.395677787065506, 'Total loss': 0.395677787065506} | train loss {'Reaction outcome loss': 0.2607426513188152, 'Total loss': 0.2607426513188152}
2023-01-05 10:29:00,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:00,555 INFO:     Epoch: 93
2023-01-05 10:29:02,693 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38459108769893646, 'Total loss': 0.38459108769893646} | train loss {'Reaction outcome loss': 0.2611018276373294, 'Total loss': 0.2611018276373294}
2023-01-05 10:29:02,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:02,694 INFO:     Epoch: 94
2023-01-05 10:29:04,847 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3745251332720121, 'Total loss': 0.3745251332720121} | train loss {'Reaction outcome loss': 0.2685506750799258, 'Total loss': 0.2685506750799258}
2023-01-05 10:29:04,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:04,848 INFO:     Epoch: 95
2023-01-05 10:29:06,994 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3828247865041097, 'Total loss': 0.3828247865041097} | train loss {'Reaction outcome loss': 0.2626358650167496, 'Total loss': 0.2626358650167496}
2023-01-05 10:29:06,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:06,995 INFO:     Epoch: 96
2023-01-05 10:29:09,150 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38899783194065096, 'Total loss': 0.38899783194065096} | train loss {'Reaction outcome loss': 0.26283104251061534, 'Total loss': 0.26283104251061534}
2023-01-05 10:29:09,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:09,151 INFO:     Epoch: 97
2023-01-05 10:29:11,286 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3678397282958031, 'Total loss': 0.3678397282958031} | train loss {'Reaction outcome loss': 0.25841403312120415, 'Total loss': 0.25841403312120415}
2023-01-05 10:29:11,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:11,287 INFO:     Epoch: 98
2023-01-05 10:29:13,424 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4410182515780131, 'Total loss': 0.4410182515780131} | train loss {'Reaction outcome loss': 0.2576570065443266, 'Total loss': 0.2576570065443266}
2023-01-05 10:29:13,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:13,424 INFO:     Epoch: 99
2023-01-05 10:29:15,573 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4089023321866989, 'Total loss': 0.4089023321866989} | train loss {'Reaction outcome loss': 0.26102132132337413, 'Total loss': 0.26102132132337413}
2023-01-05 10:29:15,573 INFO:     Best model found after epoch 81 of 100.
2023-01-05 10:29:15,574 INFO:   Done with stage: TRAINING
2023-01-05 10:29:15,574 INFO:   Starting stage: EVALUATION
2023-01-05 10:29:15,699 INFO:   Done with stage: EVALUATION
2023-01-05 10:29:15,699 INFO:   Leaving out SEQ value Fold_7
2023-01-05 10:29:15,712 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 10:29:15,712 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:29:16,351 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:29:16,351 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:29:16,420 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:29:16,420 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:29:16,420 INFO:     No hyperparam tuning for this model
2023-01-05 10:29:16,420 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:29:16,420 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:29:16,421 INFO:     None feature selector for col prot
2023-01-05 10:29:16,421 INFO:     None feature selector for col prot
2023-01-05 10:29:16,421 INFO:     None feature selector for col prot
2023-01-05 10:29:16,422 INFO:     None feature selector for col chem
2023-01-05 10:29:16,422 INFO:     None feature selector for col chem
2023-01-05 10:29:16,422 INFO:     None feature selector for col chem
2023-01-05 10:29:16,422 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:29:16,422 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:29:16,423 INFO:     Number of params in model 72901
2023-01-05 10:29:16,427 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:29:16,427 INFO:   Starting stage: TRAINING
2023-01-05 10:29:16,487 INFO:     Val loss before train {'Reaction outcome loss': 1.0863562941551208, 'Total loss': 1.0863562941551208}
2023-01-05 10:29:16,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:16,487 INFO:     Epoch: 0
2023-01-05 10:29:18,606 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8585386037826538, 'Total loss': 0.8585386037826538} | train loss {'Reaction outcome loss': 0.9036266856141143, 'Total loss': 0.9036266856141143}
2023-01-05 10:29:18,606 INFO:     Found new best model at epoch 0
2023-01-05 10:29:18,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:18,607 INFO:     Epoch: 1
2023-01-05 10:29:20,718 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6213013370831807, 'Total loss': 0.6213013370831807} | train loss {'Reaction outcome loss': 0.7326324450009035, 'Total loss': 0.7326324450009035}
2023-01-05 10:29:20,718 INFO:     Found new best model at epoch 1
2023-01-05 10:29:20,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:20,719 INFO:     Epoch: 2
2023-01-05 10:29:22,825 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5712087174256643, 'Total loss': 0.5712087174256643} | train loss {'Reaction outcome loss': 0.5834927328558632, 'Total loss': 0.5834927328558632}
2023-01-05 10:29:22,825 INFO:     Found new best model at epoch 2
2023-01-05 10:29:22,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:22,827 INFO:     Epoch: 3
2023-01-05 10:29:24,941 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5213079075018565, 'Total loss': 0.5213079075018565} | train loss {'Reaction outcome loss': 0.5293939844483421, 'Total loss': 0.5293939844483421}
2023-01-05 10:29:24,941 INFO:     Found new best model at epoch 3
2023-01-05 10:29:24,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:24,943 INFO:     Epoch: 4
2023-01-05 10:29:27,054 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5221338927745819, 'Total loss': 0.5221338927745819} | train loss {'Reaction outcome loss': 0.5062027557756438, 'Total loss': 0.5062027557756438}
2023-01-05 10:29:27,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:27,055 INFO:     Epoch: 5
2023-01-05 10:29:29,181 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5089117129643758, 'Total loss': 0.5089117129643758} | train loss {'Reaction outcome loss': 0.4953649498167492, 'Total loss': 0.4953649498167492}
2023-01-05 10:29:29,182 INFO:     Found new best model at epoch 5
2023-01-05 10:29:29,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:29,183 INFO:     Epoch: 6
2023-01-05 10:29:31,271 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5373622119426728, 'Total loss': 0.5373622119426728} | train loss {'Reaction outcome loss': 0.4829168636283595, 'Total loss': 0.4829168636283595}
2023-01-05 10:29:31,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:31,271 INFO:     Epoch: 7
2023-01-05 10:29:33,400 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5251669466495514, 'Total loss': 0.5251669466495514} | train loss {'Reaction outcome loss': 0.47090160344546533, 'Total loss': 0.47090160344546533}
2023-01-05 10:29:33,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:33,400 INFO:     Epoch: 8
2023-01-05 10:29:35,514 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5181092441082, 'Total loss': 0.5181092441082} | train loss {'Reaction outcome loss': 0.464307549399334, 'Total loss': 0.464307549399334}
2023-01-05 10:29:35,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:35,514 INFO:     Epoch: 9
2023-01-05 10:29:37,602 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4963441888491313, 'Total loss': 0.4963441888491313} | train loss {'Reaction outcome loss': 0.4612802919887361, 'Total loss': 0.4612802919887361}
2023-01-05 10:29:37,602 INFO:     Found new best model at epoch 9
2023-01-05 10:29:37,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:37,603 INFO:     Epoch: 10
2023-01-05 10:29:39,717 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49352647066116334, 'Total loss': 0.49352647066116334} | train loss {'Reaction outcome loss': 0.4484318868963273, 'Total loss': 0.4484318868963273}
2023-01-05 10:29:39,717 INFO:     Found new best model at epoch 10
2023-01-05 10:29:39,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:39,718 INFO:     Epoch: 11
2023-01-05 10:29:41,835 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5494941115379334, 'Total loss': 0.5494941115379334} | train loss {'Reaction outcome loss': 0.44998858863617475, 'Total loss': 0.44998858863617475}
2023-01-05 10:29:41,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:41,835 INFO:     Epoch: 12
2023-01-05 10:29:43,961 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5071037034193675, 'Total loss': 0.5071037034193675} | train loss {'Reaction outcome loss': 0.44458839078962586, 'Total loss': 0.44458839078962586}
2023-01-05 10:29:43,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:43,962 INFO:     Epoch: 13
2023-01-05 10:29:46,075 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5043999433517456, 'Total loss': 0.5043999433517456} | train loss {'Reaction outcome loss': 0.4334295020871983, 'Total loss': 0.4334295020871983}
2023-01-05 10:29:46,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:46,076 INFO:     Epoch: 14
2023-01-05 10:29:48,193 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48138970534006753, 'Total loss': 0.48138970534006753} | train loss {'Reaction outcome loss': 0.4323299899424389, 'Total loss': 0.4323299899424389}
2023-01-05 10:29:48,193 INFO:     Found new best model at epoch 14
2023-01-05 10:29:48,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:48,194 INFO:     Epoch: 15
2023-01-05 10:29:50,298 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49762016137441, 'Total loss': 0.49762016137441} | train loss {'Reaction outcome loss': 0.4311248367386205, 'Total loss': 0.4311248367386205}
2023-01-05 10:29:50,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:50,298 INFO:     Epoch: 16
2023-01-05 10:29:52,417 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48231614430745445, 'Total loss': 0.48231614430745445} | train loss {'Reaction outcome loss': 0.42363837121170517, 'Total loss': 0.42363837121170517}
2023-01-05 10:29:52,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:52,418 INFO:     Epoch: 17
2023-01-05 10:29:54,519 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.512064931790034, 'Total loss': 0.512064931790034} | train loss {'Reaction outcome loss': 0.42226686716188877, 'Total loss': 0.42226686716188877}
2023-01-05 10:29:54,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:54,519 INFO:     Epoch: 18
2023-01-05 10:29:56,594 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49639015992482505, 'Total loss': 0.49639015992482505} | train loss {'Reaction outcome loss': 0.4136164367417276, 'Total loss': 0.4136164367417276}
2023-01-05 10:29:56,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:56,594 INFO:     Epoch: 19
2023-01-05 10:29:58,729 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4901977817217509, 'Total loss': 0.4901977817217509} | train loss {'Reaction outcome loss': 0.4082930902831065, 'Total loss': 0.4082930902831065}
2023-01-05 10:29:58,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:29:58,730 INFO:     Epoch: 20
2023-01-05 10:30:00,880 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5343130052089691, 'Total loss': 0.5343130052089691} | train loss {'Reaction outcome loss': 0.40516130945512224, 'Total loss': 0.40516130945512224}
2023-01-05 10:30:00,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:00,880 INFO:     Epoch: 21
2023-01-05 10:30:03,003 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47892590761184695, 'Total loss': 0.47892590761184695} | train loss {'Reaction outcome loss': 0.39834089530802474, 'Total loss': 0.39834089530802474}
2023-01-05 10:30:03,003 INFO:     Found new best model at epoch 21
2023-01-05 10:30:03,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:03,005 INFO:     Epoch: 22
2023-01-05 10:30:05,233 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.507433811823527, 'Total loss': 0.507433811823527} | train loss {'Reaction outcome loss': 0.39818656534611524, 'Total loss': 0.39818656534611524}
2023-01-05 10:30:05,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:05,234 INFO:     Epoch: 23
2023-01-05 10:30:07,310 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5185544073581696, 'Total loss': 0.5185544073581696} | train loss {'Reaction outcome loss': 0.3951148762343786, 'Total loss': 0.3951148762343786}
2023-01-05 10:30:07,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:07,311 INFO:     Epoch: 24
2023-01-05 10:30:09,531 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46479773124059043, 'Total loss': 0.46479773124059043} | train loss {'Reaction outcome loss': 0.39290133609876526, 'Total loss': 0.39290133609876526}
2023-01-05 10:30:09,531 INFO:     Found new best model at epoch 24
2023-01-05 10:30:09,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:09,533 INFO:     Epoch: 25
2023-01-05 10:30:11,771 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4901722729206085, 'Total loss': 0.4901722729206085} | train loss {'Reaction outcome loss': 0.38471737782378773, 'Total loss': 0.38471737782378773}
2023-01-05 10:30:11,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:11,771 INFO:     Epoch: 26
2023-01-05 10:30:13,954 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4872760574022929, 'Total loss': 0.4872760574022929} | train loss {'Reaction outcome loss': 0.3824654344346497, 'Total loss': 0.3824654344346497}
2023-01-05 10:30:13,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:13,954 INFO:     Epoch: 27
2023-01-05 10:30:16,076 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4980563799540202, 'Total loss': 0.4980563799540202} | train loss {'Reaction outcome loss': 0.37926701718306804, 'Total loss': 0.37926701718306804}
2023-01-05 10:30:16,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:16,077 INFO:     Epoch: 28
2023-01-05 10:30:18,173 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.500015377998352, 'Total loss': 0.500015377998352} | train loss {'Reaction outcome loss': 0.3795023698891912, 'Total loss': 0.3795023698891912}
2023-01-05 10:30:18,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:18,173 INFO:     Epoch: 29
2023-01-05 10:30:20,265 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4918052901824315, 'Total loss': 0.4918052901824315} | train loss {'Reaction outcome loss': 0.3696452950847236, 'Total loss': 0.3696452950847236}
2023-01-05 10:30:20,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:20,265 INFO:     Epoch: 30
2023-01-05 10:30:22,365 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.506937046845754, 'Total loss': 0.506937046845754} | train loss {'Reaction outcome loss': 0.3661187454894349, 'Total loss': 0.3661187454894349}
2023-01-05 10:30:22,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:22,366 INFO:     Epoch: 31
2023-01-05 10:30:24,478 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47632745405038196, 'Total loss': 0.47632745405038196} | train loss {'Reaction outcome loss': 0.36265153077605006, 'Total loss': 0.36265153077605006}
2023-01-05 10:30:24,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:24,479 INFO:     Epoch: 32
2023-01-05 10:30:26,581 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46764128704865776, 'Total loss': 0.46764128704865776} | train loss {'Reaction outcome loss': 0.36506313131951584, 'Total loss': 0.36506313131951584}
2023-01-05 10:30:26,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:26,581 INFO:     Epoch: 33
2023-01-05 10:30:28,674 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47021278937657673, 'Total loss': 0.47021278937657673} | train loss {'Reaction outcome loss': 0.3596093416104823, 'Total loss': 0.3596093416104823}
2023-01-05 10:30:28,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:28,674 INFO:     Epoch: 34
2023-01-05 10:30:30,776 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48845995763937633, 'Total loss': 0.48845995763937633} | train loss {'Reaction outcome loss': 0.3638288673463759, 'Total loss': 0.3638288673463759}
2023-01-05 10:30:30,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:30,776 INFO:     Epoch: 35
2023-01-05 10:30:32,945 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4692821939786275, 'Total loss': 0.4692821939786275} | train loss {'Reaction outcome loss': 0.3533088158365789, 'Total loss': 0.3533088158365789}
2023-01-05 10:30:32,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:32,945 INFO:     Epoch: 36
2023-01-05 10:30:35,142 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49144046703974403, 'Total loss': 0.49144046703974403} | train loss {'Reaction outcome loss': 0.3504321290241493, 'Total loss': 0.3504321290241493}
2023-01-05 10:30:35,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:35,143 INFO:     Epoch: 37
2023-01-05 10:30:37,282 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46038940946261087, 'Total loss': 0.46038940946261087} | train loss {'Reaction outcome loss': 0.3422114099256503, 'Total loss': 0.3422114099256503}
2023-01-05 10:30:37,282 INFO:     Found new best model at epoch 37
2023-01-05 10:30:37,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:37,283 INFO:     Epoch: 38
2023-01-05 10:30:39,391 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4645969738562902, 'Total loss': 0.4645969738562902} | train loss {'Reaction outcome loss': 0.3449784678171624, 'Total loss': 0.3449784678171624}
2023-01-05 10:30:39,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:39,391 INFO:     Epoch: 39
2023-01-05 10:30:41,512 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4684754729270935, 'Total loss': 0.4684754729270935} | train loss {'Reaction outcome loss': 0.3319070198105805, 'Total loss': 0.3319070198105805}
2023-01-05 10:30:41,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:41,512 INFO:     Epoch: 40
2023-01-05 10:30:43,723 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5179768105347952, 'Total loss': 0.5179768105347952} | train loss {'Reaction outcome loss': 0.34249914372032814, 'Total loss': 0.34249914372032814}
2023-01-05 10:30:43,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:43,723 INFO:     Epoch: 41
2023-01-05 10:30:45,821 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4758085131645203, 'Total loss': 0.4758085131645203} | train loss {'Reaction outcome loss': 0.33557309436819927, 'Total loss': 0.33557309436819927}
2023-01-05 10:30:45,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:45,821 INFO:     Epoch: 42
2023-01-05 10:30:47,994 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4932227353254954, 'Total loss': 0.4932227353254954} | train loss {'Reaction outcome loss': 0.336769084756573, 'Total loss': 0.336769084756573}
2023-01-05 10:30:47,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:47,994 INFO:     Epoch: 43
2023-01-05 10:30:50,103 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45148283839225767, 'Total loss': 0.45148283839225767} | train loss {'Reaction outcome loss': 0.32754182256075925, 'Total loss': 0.32754182256075925}
2023-01-05 10:30:50,103 INFO:     Found new best model at epoch 43
2023-01-05 10:30:50,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:50,104 INFO:     Epoch: 44
2023-01-05 10:30:52,211 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.494406991203626, 'Total loss': 0.494406991203626} | train loss {'Reaction outcome loss': 0.32212789605061215, 'Total loss': 0.32212789605061215}
2023-01-05 10:30:52,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:52,213 INFO:     Epoch: 45
2023-01-05 10:30:54,298 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48162322839101157, 'Total loss': 0.48162322839101157} | train loss {'Reaction outcome loss': 0.32450596054831704, 'Total loss': 0.32450596054831704}
2023-01-05 10:30:54,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:54,299 INFO:     Epoch: 46
2023-01-05 10:30:56,462 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4793320467074712, 'Total loss': 0.4793320467074712} | train loss {'Reaction outcome loss': 0.32114774316221806, 'Total loss': 0.32114774316221806}
2023-01-05 10:30:56,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:56,462 INFO:     Epoch: 47
2023-01-05 10:30:58,610 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46355654001235963, 'Total loss': 0.46355654001235963} | train loss {'Reaction outcome loss': 0.3171722087122145, 'Total loss': 0.3171722087122145}
2023-01-05 10:30:58,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:30:58,611 INFO:     Epoch: 48
2023-01-05 10:31:00,750 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4512716462214788, 'Total loss': 0.4512716462214788} | train loss {'Reaction outcome loss': 0.31727616999284686, 'Total loss': 0.31727616999284686}
2023-01-05 10:31:00,750 INFO:     Found new best model at epoch 48
2023-01-05 10:31:00,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:00,751 INFO:     Epoch: 49
2023-01-05 10:31:02,861 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47555200109879175, 'Total loss': 0.47555200109879175} | train loss {'Reaction outcome loss': 0.3185335661595066, 'Total loss': 0.3185335661595066}
2023-01-05 10:31:02,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:02,861 INFO:     Epoch: 50
2023-01-05 10:31:04,943 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46094290018081663, 'Total loss': 0.46094290018081663} | train loss {'Reaction outcome loss': 0.31183261054503175, 'Total loss': 0.31183261054503175}
2023-01-05 10:31:04,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:04,943 INFO:     Epoch: 51
2023-01-05 10:31:07,059 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4563800225655238, 'Total loss': 0.4563800225655238} | train loss {'Reaction outcome loss': 0.3096855056809855, 'Total loss': 0.3096855056809855}
2023-01-05 10:31:07,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:07,060 INFO:     Epoch: 52
2023-01-05 10:31:09,221 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4773226042588552, 'Total loss': 0.4773226042588552} | train loss {'Reaction outcome loss': 0.3076284685796434, 'Total loss': 0.3076284685796434}
2023-01-05 10:31:09,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:09,221 INFO:     Epoch: 53
2023-01-05 10:31:11,396 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4326449771722158, 'Total loss': 0.4326449771722158} | train loss {'Reaction outcome loss': 0.30435873190070684, 'Total loss': 0.30435873190070684}
2023-01-05 10:31:11,396 INFO:     Found new best model at epoch 53
2023-01-05 10:31:11,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:11,398 INFO:     Epoch: 54
2023-01-05 10:31:13,519 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5185186405976613, 'Total loss': 0.5185186405976613} | train loss {'Reaction outcome loss': 0.2968713846944627, 'Total loss': 0.2968713846944627}
2023-01-05 10:31:13,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:13,519 INFO:     Epoch: 55
2023-01-05 10:31:15,617 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.499325031042099, 'Total loss': 0.499325031042099} | train loss {'Reaction outcome loss': 0.29999679504405885, 'Total loss': 0.29999679504405885}
2023-01-05 10:31:15,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:15,617 INFO:     Epoch: 56
2023-01-05 10:31:17,716 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4545232673486074, 'Total loss': 0.4545232673486074} | train loss {'Reaction outcome loss': 0.2961530524132016, 'Total loss': 0.2961530524132016}
2023-01-05 10:31:17,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:17,717 INFO:     Epoch: 57
2023-01-05 10:31:19,840 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5128603478272756, 'Total loss': 0.5128603478272756} | train loss {'Reaction outcome loss': 0.2918735299627859, 'Total loss': 0.2918735299627859}
2023-01-05 10:31:19,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:19,840 INFO:     Epoch: 58
2023-01-05 10:31:21,940 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44175360004107156, 'Total loss': 0.44175360004107156} | train loss {'Reaction outcome loss': 0.2910286522582992, 'Total loss': 0.2910286522582992}
2023-01-05 10:31:21,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:21,941 INFO:     Epoch: 59
2023-01-05 10:31:24,046 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45916019678115844, 'Total loss': 0.45916019678115844} | train loss {'Reaction outcome loss': 0.29291758174588395, 'Total loss': 0.29291758174588395}
2023-01-05 10:31:24,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:24,046 INFO:     Epoch: 60
2023-01-05 10:31:26,162 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4721518814563751, 'Total loss': 0.4721518814563751} | train loss {'Reaction outcome loss': 0.29203238185399616, 'Total loss': 0.29203238185399616}
2023-01-05 10:31:26,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:26,162 INFO:     Epoch: 61
2023-01-05 10:31:28,291 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46408495754003526, 'Total loss': 0.46408495754003526} | train loss {'Reaction outcome loss': 0.28873309284284876, 'Total loss': 0.28873309284284876}
2023-01-05 10:31:28,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:28,292 INFO:     Epoch: 62
2023-01-05 10:31:30,411 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46371084252993267, 'Total loss': 0.46371084252993267} | train loss {'Reaction outcome loss': 0.28201919768155714, 'Total loss': 0.28201919768155714}
2023-01-05 10:31:30,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:30,411 INFO:     Epoch: 63
2023-01-05 10:31:32,557 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44177349905172986, 'Total loss': 0.44177349905172986} | train loss {'Reaction outcome loss': 0.2857414045517807, 'Total loss': 0.2857414045517807}
2023-01-05 10:31:32,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:32,557 INFO:     Epoch: 64
2023-01-05 10:31:34,702 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44800507376591364, 'Total loss': 0.44800507376591364} | train loss {'Reaction outcome loss': 0.28489758709493357, 'Total loss': 0.28489758709493357}
2023-01-05 10:31:34,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:34,702 INFO:     Epoch: 65
2023-01-05 10:31:36,826 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5074343134959539, 'Total loss': 0.5074343134959539} | train loss {'Reaction outcome loss': 0.2793468176182564, 'Total loss': 0.2793468176182564}
2023-01-05 10:31:36,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:36,827 INFO:     Epoch: 66
2023-01-05 10:31:38,973 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4404672185579936, 'Total loss': 0.4404672185579936} | train loss {'Reaction outcome loss': 0.27319737360301005, 'Total loss': 0.27319737360301005}
2023-01-05 10:31:38,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:38,973 INFO:     Epoch: 67
2023-01-05 10:31:41,099 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48682193557421366, 'Total loss': 0.48682193557421366} | train loss {'Reaction outcome loss': 0.27511167387740737, 'Total loss': 0.27511167387740737}
2023-01-05 10:31:41,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:41,099 INFO:     Epoch: 68
2023-01-05 10:31:43,238 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47725481192270913, 'Total loss': 0.47725481192270913} | train loss {'Reaction outcome loss': 0.27435472884621376, 'Total loss': 0.27435472884621376}
2023-01-05 10:31:43,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:43,238 INFO:     Epoch: 69
2023-01-05 10:31:45,386 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45981608430544535, 'Total loss': 0.45981608430544535} | train loss {'Reaction outcome loss': 0.27225353582438094, 'Total loss': 0.27225353582438094}
2023-01-05 10:31:45,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:45,386 INFO:     Epoch: 70
2023-01-05 10:31:47,500 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44052171111106875, 'Total loss': 0.44052171111106875} | train loss {'Reaction outcome loss': 0.2762959510388173, 'Total loss': 0.2762959510388173}
2023-01-05 10:31:47,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:47,500 INFO:     Epoch: 71
2023-01-05 10:31:49,665 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49374476571877796, 'Total loss': 0.49374476571877796} | train loss {'Reaction outcome loss': 0.2739663723337672, 'Total loss': 0.2739663723337672}
2023-01-05 10:31:49,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:49,665 INFO:     Epoch: 72
2023-01-05 10:31:51,798 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4318662822246552, 'Total loss': 0.4318662822246552} | train loss {'Reaction outcome loss': 0.27071949220074837, 'Total loss': 0.27071949220074837}
2023-01-05 10:31:51,798 INFO:     Found new best model at epoch 72
2023-01-05 10:31:51,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:51,800 INFO:     Epoch: 73
2023-01-05 10:31:53,914 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4667524407307307, 'Total loss': 0.4667524407307307} | train loss {'Reaction outcome loss': 0.2679577528502478, 'Total loss': 0.2679577528502478}
2023-01-05 10:31:53,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:53,914 INFO:     Epoch: 74
2023-01-05 10:31:56,020 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4262759228547414, 'Total loss': 0.4262759228547414} | train loss {'Reaction outcome loss': 0.26684154288659057, 'Total loss': 0.26684154288659057}
2023-01-05 10:31:56,020 INFO:     Found new best model at epoch 74
2023-01-05 10:31:56,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:56,022 INFO:     Epoch: 75
2023-01-05 10:31:58,131 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45600040853023527, 'Total loss': 0.45600040853023527} | train loss {'Reaction outcome loss': 0.26481429795860806, 'Total loss': 0.26481429795860806}
2023-01-05 10:31:58,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:31:58,132 INFO:     Epoch: 76
2023-01-05 10:32:00,230 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4733169148365656, 'Total loss': 0.4733169148365656} | train loss {'Reaction outcome loss': 0.262549879479703, 'Total loss': 0.262549879479703}
2023-01-05 10:32:00,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:00,230 INFO:     Epoch: 77
2023-01-05 10:32:02,347 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47796281973520915, 'Total loss': 0.47796281973520915} | train loss {'Reaction outcome loss': 0.26046424202839313, 'Total loss': 0.26046424202839313}
2023-01-05 10:32:02,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:02,347 INFO:     Epoch: 78
2023-01-05 10:32:04,438 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48414329489072166, 'Total loss': 0.48414329489072166} | train loss {'Reaction outcome loss': 0.2533523782460026, 'Total loss': 0.2533523782460026}
2023-01-05 10:32:04,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:04,439 INFO:     Epoch: 79
2023-01-05 10:32:06,559 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48100985288619996, 'Total loss': 0.48100985288619996} | train loss {'Reaction outcome loss': 0.2575920000808798, 'Total loss': 0.2575920000808798}
2023-01-05 10:32:06,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:06,559 INFO:     Epoch: 80
2023-01-05 10:32:08,681 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4620746453603109, 'Total loss': 0.4620746453603109} | train loss {'Reaction outcome loss': 0.2612021259226642, 'Total loss': 0.2612021259226642}
2023-01-05 10:32:08,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:08,682 INFO:     Epoch: 81
2023-01-05 10:32:10,770 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4868638540307681, 'Total loss': 0.4868638540307681} | train loss {'Reaction outcome loss': 0.2591119988824858, 'Total loss': 0.2591119988824858}
2023-01-05 10:32:10,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:10,770 INFO:     Epoch: 82
2023-01-05 10:32:12,866 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45488841931025187, 'Total loss': 0.45488841931025187} | train loss {'Reaction outcome loss': 0.26117748035384075, 'Total loss': 0.26117748035384075}
2023-01-05 10:32:12,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:12,866 INFO:     Epoch: 83
2023-01-05 10:32:14,957 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45856977701187135, 'Total loss': 0.45856977701187135} | train loss {'Reaction outcome loss': 0.25527647662321074, 'Total loss': 0.25527647662321074}
2023-01-05 10:32:14,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:14,957 INFO:     Epoch: 84
2023-01-05 10:32:17,044 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4314566950624188, 'Total loss': 0.4314566950624188} | train loss {'Reaction outcome loss': 0.25845267548952455, 'Total loss': 0.25845267548952455}
2023-01-05 10:32:17,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:17,045 INFO:     Epoch: 85
2023-01-05 10:32:19,130 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4314503699541092, 'Total loss': 0.4314503699541092} | train loss {'Reaction outcome loss': 0.25037201043668683, 'Total loss': 0.25037201043668683}
2023-01-05 10:32:19,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:19,130 INFO:     Epoch: 86
2023-01-05 10:32:21,231 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45750740468502044, 'Total loss': 0.45750740468502044} | train loss {'Reaction outcome loss': 0.25030490677571776, 'Total loss': 0.25030490677571776}
2023-01-05 10:32:21,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:21,231 INFO:     Epoch: 87
2023-01-05 10:32:23,342 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45204727053642274, 'Total loss': 0.45204727053642274} | train loss {'Reaction outcome loss': 0.2556104564104543, 'Total loss': 0.2556104564104543}
2023-01-05 10:32:23,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:23,342 INFO:     Epoch: 88
2023-01-05 10:32:25,488 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5021377205848694, 'Total loss': 0.5021377205848694} | train loss {'Reaction outcome loss': 0.25389548268974266, 'Total loss': 0.25389548268974266}
2023-01-05 10:32:25,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:25,488 INFO:     Epoch: 89
2023-01-05 10:32:27,613 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4565147573749224, 'Total loss': 0.4565147573749224} | train loss {'Reaction outcome loss': 0.24590180529069988, 'Total loss': 0.24590180529069988}
2023-01-05 10:32:27,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:27,614 INFO:     Epoch: 90
2023-01-05 10:32:29,743 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45688093900680543, 'Total loss': 0.45688093900680543} | train loss {'Reaction outcome loss': 0.246394726782082, 'Total loss': 0.246394726782082}
2023-01-05 10:32:29,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:29,743 INFO:     Epoch: 91
2023-01-05 10:32:31,877 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4761417249838511, 'Total loss': 0.4761417249838511} | train loss {'Reaction outcome loss': 0.25586879650478833, 'Total loss': 0.25586879650478833}
2023-01-05 10:32:31,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:31,877 INFO:     Epoch: 92
2023-01-05 10:32:34,005 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4513341099023819, 'Total loss': 0.4513341099023819} | train loss {'Reaction outcome loss': 0.25402414786455396, 'Total loss': 0.25402414786455396}
2023-01-05 10:32:34,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:34,007 INFO:     Epoch: 93
2023-01-05 10:32:36,136 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4448886315027873, 'Total loss': 0.4448886315027873} | train loss {'Reaction outcome loss': 0.23689873525770483, 'Total loss': 0.23689873525770483}
2023-01-05 10:32:36,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:36,136 INFO:     Epoch: 94
2023-01-05 10:32:38,240 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44639916718006134, 'Total loss': 0.44639916718006134} | train loss {'Reaction outcome loss': 0.24874749647337438, 'Total loss': 0.24874749647337438}
2023-01-05 10:32:38,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:38,240 INFO:     Epoch: 95
2023-01-05 10:32:40,323 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44494198858737943, 'Total loss': 0.44494198858737943} | train loss {'Reaction outcome loss': 0.2523316238007266, 'Total loss': 0.2523316238007266}
2023-01-05 10:32:40,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:40,324 INFO:     Epoch: 96
2023-01-05 10:32:42,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44582145772874354, 'Total loss': 0.44582145772874354} | train loss {'Reaction outcome loss': 0.24275351087852712, 'Total loss': 0.24275351087852712}
2023-01-05 10:32:42,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:42,429 INFO:     Epoch: 97
2023-01-05 10:32:44,500 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45521346827348075, 'Total loss': 0.45521346827348075} | train loss {'Reaction outcome loss': 0.242101285865892, 'Total loss': 0.242101285865892}
2023-01-05 10:32:44,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:44,501 INFO:     Epoch: 98
2023-01-05 10:32:46,587 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4457760771115621, 'Total loss': 0.4457760771115621} | train loss {'Reaction outcome loss': 0.25077639599313667, 'Total loss': 0.25077639599313667}
2023-01-05 10:32:46,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:46,587 INFO:     Epoch: 99
2023-01-05 10:32:48,689 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48996809820334114, 'Total loss': 0.48996809820334114} | train loss {'Reaction outcome loss': 0.23195900855374424, 'Total loss': 0.23195900855374424}
2023-01-05 10:32:48,689 INFO:     Best model found after epoch 75 of 100.
2023-01-05 10:32:48,689 INFO:   Done with stage: TRAINING
2023-01-05 10:32:48,689 INFO:   Starting stage: EVALUATION
2023-01-05 10:32:48,835 INFO:   Done with stage: EVALUATION
2023-01-05 10:32:48,836 INFO:   Leaving out SEQ value Fold_8
2023-01-05 10:32:48,848 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 10:32:48,848 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:32:49,517 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:32:49,517 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:32:49,588 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:32:49,588 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:32:49,588 INFO:     No hyperparam tuning for this model
2023-01-05 10:32:49,588 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:32:49,588 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:32:49,589 INFO:     None feature selector for col prot
2023-01-05 10:32:49,589 INFO:     None feature selector for col prot
2023-01-05 10:32:49,589 INFO:     None feature selector for col prot
2023-01-05 10:32:49,589 INFO:     None feature selector for col chem
2023-01-05 10:32:49,590 INFO:     None feature selector for col chem
2023-01-05 10:32:49,590 INFO:     None feature selector for col chem
2023-01-05 10:32:49,590 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:32:49,590 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:32:49,591 INFO:     Number of params in model 72901
2023-01-05 10:32:49,594 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:32:49,594 INFO:   Starting stage: TRAINING
2023-01-05 10:32:49,653 INFO:     Val loss before train {'Reaction outcome loss': 0.9243086695671081, 'Total loss': 0.9243086695671081}
2023-01-05 10:32:49,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:49,654 INFO:     Epoch: 0
2023-01-05 10:32:51,808 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7781108260154724, 'Total loss': 0.7781108260154724} | train loss {'Reaction outcome loss': 0.9410728653487952, 'Total loss': 0.9410728653487952}
2023-01-05 10:32:51,808 INFO:     Found new best model at epoch 0
2023-01-05 10:32:51,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:51,809 INFO:     Epoch: 1
2023-01-05 10:32:53,962 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6392497420310974, 'Total loss': 0.6392497420310974} | train loss {'Reaction outcome loss': 0.724692203141614, 'Total loss': 0.724692203141614}
2023-01-05 10:32:53,962 INFO:     Found new best model at epoch 1
2023-01-05 10:32:53,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:53,964 INFO:     Epoch: 2
2023-01-05 10:32:56,141 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5097851097583771, 'Total loss': 0.5097851097583771} | train loss {'Reaction outcome loss': 0.5867975758999397, 'Total loss': 0.5867975758999397}
2023-01-05 10:32:56,141 INFO:     Found new best model at epoch 2
2023-01-05 10:32:56,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:56,142 INFO:     Epoch: 3
2023-01-05 10:32:58,312 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48459402322769163, 'Total loss': 0.48459402322769163} | train loss {'Reaction outcome loss': 0.539046835938833, 'Total loss': 0.539046835938833}
2023-01-05 10:32:58,312 INFO:     Found new best model at epoch 3
2023-01-05 10:32:58,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:32:58,313 INFO:     Epoch: 4
2023-01-05 10:33:00,465 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.517103244860967, 'Total loss': 0.517103244860967} | train loss {'Reaction outcome loss': 0.507832456657828, 'Total loss': 0.507832456657828}
2023-01-05 10:33:00,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:00,465 INFO:     Epoch: 5
2023-01-05 10:33:02,609 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5233126004536947, 'Total loss': 0.5233126004536947} | train loss {'Reaction outcome loss': 0.49953517650483525, 'Total loss': 0.49953517650483525}
2023-01-05 10:33:02,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:02,609 INFO:     Epoch: 6
2023-01-05 10:33:04,758 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49565797845522563, 'Total loss': 0.49565797845522563} | train loss {'Reaction outcome loss': 0.4906467638700607, 'Total loss': 0.4906467638700607}
2023-01-05 10:33:04,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:04,758 INFO:     Epoch: 7
2023-01-05 10:33:06,893 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48118577202161156, 'Total loss': 0.48118577202161156} | train loss {'Reaction outcome loss': 0.48152747618682357, 'Total loss': 0.48152747618682357}
2023-01-05 10:33:06,893 INFO:     Found new best model at epoch 7
2023-01-05 10:33:06,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:06,895 INFO:     Epoch: 8
2023-01-05 10:33:09,010 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5231147150198618, 'Total loss': 0.5231147150198618} | train loss {'Reaction outcome loss': 0.4752772517056893, 'Total loss': 0.4752772517056893}
2023-01-05 10:33:09,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:09,010 INFO:     Epoch: 9
2023-01-05 10:33:11,127 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48331720729668937, 'Total loss': 0.48331720729668937} | train loss {'Reaction outcome loss': 0.4691877217450436, 'Total loss': 0.4691877217450436}
2023-01-05 10:33:11,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:11,128 INFO:     Epoch: 10
2023-01-05 10:33:13,250 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46290824711322787, 'Total loss': 0.46290824711322787} | train loss {'Reaction outcome loss': 0.4647025506187608, 'Total loss': 0.4647025506187608}
2023-01-05 10:33:13,250 INFO:     Found new best model at epoch 10
2023-01-05 10:33:13,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:13,251 INFO:     Epoch: 11
2023-01-05 10:33:15,385 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5131650984287262, 'Total loss': 0.5131650984287262} | train loss {'Reaction outcome loss': 0.45963064069265797, 'Total loss': 0.45963064069265797}
2023-01-05 10:33:15,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:15,386 INFO:     Epoch: 12
2023-01-05 10:33:17,540 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4687911142905553, 'Total loss': 0.4687911142905553} | train loss {'Reaction outcome loss': 0.45625717020121176, 'Total loss': 0.45625717020121176}
2023-01-05 10:33:17,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:17,541 INFO:     Epoch: 13
2023-01-05 10:33:19,659 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49592623909314476, 'Total loss': 0.49592623909314476} | train loss {'Reaction outcome loss': 0.44963760436360684, 'Total loss': 0.44963760436360684}
2023-01-05 10:33:19,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:19,659 INFO:     Epoch: 14
2023-01-05 10:33:21,767 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48814698855082195, 'Total loss': 0.48814698855082195} | train loss {'Reaction outcome loss': 0.4455722739812041, 'Total loss': 0.4455722739812041}
2023-01-05 10:33:21,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:21,768 INFO:     Epoch: 15
2023-01-05 10:33:23,879 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47230591873327893, 'Total loss': 0.47230591873327893} | train loss {'Reaction outcome loss': 0.44018953014840034, 'Total loss': 0.44018953014840034}
2023-01-05 10:33:23,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:23,879 INFO:     Epoch: 16
2023-01-05 10:33:26,035 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4675946573416392, 'Total loss': 0.4675946573416392} | train loss {'Reaction outcome loss': 0.43640880551264266, 'Total loss': 0.43640880551264266}
2023-01-05 10:33:26,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:26,035 INFO:     Epoch: 17
2023-01-05 10:33:28,195 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4735761811335882, 'Total loss': 0.4735761811335882} | train loss {'Reaction outcome loss': 0.4466394216524086, 'Total loss': 0.4466394216524086}
2023-01-05 10:33:28,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:28,195 INFO:     Epoch: 18
2023-01-05 10:33:30,355 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48979869882265725, 'Total loss': 0.48979869882265725} | train loss {'Reaction outcome loss': 0.49534093522790656, 'Total loss': 0.49534093522790656}
2023-01-05 10:33:30,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:30,356 INFO:     Epoch: 19
2023-01-05 10:33:32,509 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4727750450372696, 'Total loss': 0.4727750450372696} | train loss {'Reaction outcome loss': 0.4255762709679244, 'Total loss': 0.4255762709679244}
2023-01-05 10:33:32,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:32,509 INFO:     Epoch: 20
2023-01-05 10:33:34,698 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5079502642154694, 'Total loss': 0.5079502642154694} | train loss {'Reaction outcome loss': 0.42167492289150105, 'Total loss': 0.42167492289150105}
2023-01-05 10:33:34,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:34,698 INFO:     Epoch: 21
2023-01-05 10:33:36,843 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44110981822013856, 'Total loss': 0.44110981822013856} | train loss {'Reaction outcome loss': 0.4356134968499343, 'Total loss': 0.4356134968499343}
2023-01-05 10:33:36,843 INFO:     Found new best model at epoch 21
2023-01-05 10:33:36,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:36,844 INFO:     Epoch: 22
2023-01-05 10:33:38,994 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44349037756522497, 'Total loss': 0.44349037756522497} | train loss {'Reaction outcome loss': 0.41177427710668335, 'Total loss': 0.41177427710668335}
2023-01-05 10:33:38,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:38,995 INFO:     Epoch: 23
2023-01-05 10:33:41,140 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4555792987346649, 'Total loss': 0.4555792987346649} | train loss {'Reaction outcome loss': 0.407041194572019, 'Total loss': 0.407041194572019}
2023-01-05 10:33:41,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:41,140 INFO:     Epoch: 24
2023-01-05 10:33:43,287 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4448823024829229, 'Total loss': 0.4448823024829229} | train loss {'Reaction outcome loss': 0.4021510476705389, 'Total loss': 0.4021510476705389}
2023-01-05 10:33:43,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:43,287 INFO:     Epoch: 25
2023-01-05 10:33:45,431 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45800987879435223, 'Total loss': 0.45800987879435223} | train loss {'Reaction outcome loss': 0.4042962456418984, 'Total loss': 0.4042962456418984}
2023-01-05 10:33:45,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:45,432 INFO:     Epoch: 26
2023-01-05 10:33:47,571 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4202807083725929, 'Total loss': 0.4202807083725929} | train loss {'Reaction outcome loss': 0.39576738456220273, 'Total loss': 0.39576738456220273}
2023-01-05 10:33:47,571 INFO:     Found new best model at epoch 26
2023-01-05 10:33:47,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:47,573 INFO:     Epoch: 27
2023-01-05 10:33:49,726 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4427875757217407, 'Total loss': 0.4427875757217407} | train loss {'Reaction outcome loss': 0.39517528401406243, 'Total loss': 0.39517528401406243}
2023-01-05 10:33:49,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:49,727 INFO:     Epoch: 28
2023-01-05 10:33:51,907 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47681540846824644, 'Total loss': 0.47681540846824644} | train loss {'Reaction outcome loss': 0.3875646536521938, 'Total loss': 0.3875646536521938}
2023-01-05 10:33:51,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:51,908 INFO:     Epoch: 29
2023-01-05 10:33:54,094 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45194266239802044, 'Total loss': 0.45194266239802044} | train loss {'Reaction outcome loss': 0.38631834127084835, 'Total loss': 0.38631834127084835}
2023-01-05 10:33:54,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:54,094 INFO:     Epoch: 30
2023-01-05 10:33:56,253 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4455765813589096, 'Total loss': 0.4455765813589096} | train loss {'Reaction outcome loss': 0.37979906802133157, 'Total loss': 0.37979906802133157}
2023-01-05 10:33:56,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:56,253 INFO:     Epoch: 31
2023-01-05 10:33:58,387 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4349337855974833, 'Total loss': 0.4349337855974833} | train loss {'Reaction outcome loss': 0.3802289973861754, 'Total loss': 0.3802289973861754}
2023-01-05 10:33:58,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:33:58,387 INFO:     Epoch: 32
2023-01-05 10:34:00,521 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4533349841833115, 'Total loss': 0.4533349841833115} | train loss {'Reaction outcome loss': 0.3902812305351962, 'Total loss': 0.3902812305351962}
2023-01-05 10:34:00,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:00,521 INFO:     Epoch: 33
2023-01-05 10:34:02,687 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.443116491039594, 'Total loss': 0.443116491039594} | train loss {'Reaction outcome loss': 0.40209622805778583, 'Total loss': 0.40209622805778583}
2023-01-05 10:34:02,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:02,688 INFO:     Epoch: 34
2023-01-05 10:34:04,846 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43929390112559, 'Total loss': 0.43929390112559} | train loss {'Reaction outcome loss': 0.38128329436564684, 'Total loss': 0.38128329436564684}
2023-01-05 10:34:04,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:04,847 INFO:     Epoch: 35
2023-01-05 10:34:07,018 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4285913238922755, 'Total loss': 0.4285913238922755} | train loss {'Reaction outcome loss': 0.3726529171285422, 'Total loss': 0.3726529171285422}
2023-01-05 10:34:07,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:07,018 INFO:     Epoch: 36
2023-01-05 10:34:08,970 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4503613829612732, 'Total loss': 0.4503613829612732} | train loss {'Reaction outcome loss': 0.3905573265510611, 'Total loss': 0.3905573265510611}
2023-01-05 10:34:08,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:08,971 INFO:     Epoch: 37
2023-01-05 10:34:11,123 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4295027792453766, 'Total loss': 0.4295027792453766} | train loss {'Reaction outcome loss': 0.3690446412386508, 'Total loss': 0.3690446412386508}
2023-01-05 10:34:11,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:11,123 INFO:     Epoch: 38
2023-01-05 10:34:13,284 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42811925411224366, 'Total loss': 0.42811925411224366} | train loss {'Reaction outcome loss': 0.35967796877688984, 'Total loss': 0.35967796877688984}
2023-01-05 10:34:13,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:13,284 INFO:     Epoch: 39
2023-01-05 10:34:15,442 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4612435261408488, 'Total loss': 0.4612435261408488} | train loss {'Reaction outcome loss': 0.35674262258512696, 'Total loss': 0.35674262258512696}
2023-01-05 10:34:15,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:15,442 INFO:     Epoch: 40
2023-01-05 10:34:17,589 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4559292326370875, 'Total loss': 0.4559292326370875} | train loss {'Reaction outcome loss': 0.3523193423596609, 'Total loss': 0.3523193423596609}
2023-01-05 10:34:17,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:17,589 INFO:     Epoch: 41
2023-01-05 10:34:19,711 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4731150140364965, 'Total loss': 0.4731150140364965} | train loss {'Reaction outcome loss': 0.3450472842083084, 'Total loss': 0.3450472842083084}
2023-01-05 10:34:19,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:19,711 INFO:     Epoch: 42
2023-01-05 10:34:21,837 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45323802828788756, 'Total loss': 0.45323802828788756} | train loss {'Reaction outcome loss': 0.3477185001103098, 'Total loss': 0.3477185001103098}
2023-01-05 10:34:21,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:21,838 INFO:     Epoch: 43
2023-01-05 10:34:23,935 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43855146765708924, 'Total loss': 0.43855146765708924} | train loss {'Reaction outcome loss': 0.3438806851961577, 'Total loss': 0.3438806851961577}
2023-01-05 10:34:23,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:23,936 INFO:     Epoch: 44
2023-01-05 10:34:26,049 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.459290004769961, 'Total loss': 0.459290004769961} | train loss {'Reaction outcome loss': 0.33800315893882804, 'Total loss': 0.33800315893882804}
2023-01-05 10:34:26,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:26,049 INFO:     Epoch: 45
2023-01-05 10:34:28,164 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4390577216943105, 'Total loss': 0.4390577216943105} | train loss {'Reaction outcome loss': 0.3433791095976367, 'Total loss': 0.3433791095976367}
2023-01-05 10:34:28,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:28,165 INFO:     Epoch: 46
2023-01-05 10:34:30,278 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43241671721140545, 'Total loss': 0.43241671721140545} | train loss {'Reaction outcome loss': 0.33945840077977546, 'Total loss': 0.33945840077977546}
2023-01-05 10:34:30,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:30,278 INFO:     Epoch: 47
2023-01-05 10:34:32,402 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41994009613990785, 'Total loss': 0.41994009613990785} | train loss {'Reaction outcome loss': 0.3376404934603235, 'Total loss': 0.3376404934603235}
2023-01-05 10:34:32,402 INFO:     Found new best model at epoch 47
2023-01-05 10:34:32,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:32,403 INFO:     Epoch: 48
2023-01-05 10:34:34,537 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44090533008178073, 'Total loss': 0.44090533008178073} | train loss {'Reaction outcome loss': 0.3325962471747029, 'Total loss': 0.3325962471747029}
2023-01-05 10:34:34,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:34,537 INFO:     Epoch: 49
2023-01-05 10:34:36,673 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4184657404820124, 'Total loss': 0.4184657404820124} | train loss {'Reaction outcome loss': 0.33292933820284554, 'Total loss': 0.33292933820284554}
2023-01-05 10:34:36,673 INFO:     Found new best model at epoch 49
2023-01-05 10:34:36,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:36,674 INFO:     Epoch: 50
2023-01-05 10:34:38,808 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4344905912876129, 'Total loss': 0.4344905912876129} | train loss {'Reaction outcome loss': 0.32768926878824184, 'Total loss': 0.32768926878824184}
2023-01-05 10:34:38,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:38,808 INFO:     Epoch: 51
2023-01-05 10:34:40,963 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40912722821036973, 'Total loss': 0.40912722821036973} | train loss {'Reaction outcome loss': 0.32984464901728905, 'Total loss': 0.32984464901728905}
2023-01-05 10:34:40,964 INFO:     Found new best model at epoch 51
2023-01-05 10:34:40,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:40,965 INFO:     Epoch: 52
2023-01-05 10:34:43,132 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45933831731478375, 'Total loss': 0.45933831731478375} | train loss {'Reaction outcome loss': 0.321621094691142, 'Total loss': 0.321621094691142}
2023-01-05 10:34:43,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:43,133 INFO:     Epoch: 53
2023-01-05 10:34:45,232 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4251142638425032, 'Total loss': 0.4251142638425032} | train loss {'Reaction outcome loss': 0.3244702534100962, 'Total loss': 0.3244702534100962}
2023-01-05 10:34:45,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:45,232 INFO:     Epoch: 54
2023-01-05 10:34:47,361 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4348235790928205, 'Total loss': 0.4348235790928205} | train loss {'Reaction outcome loss': 0.31422882409854047, 'Total loss': 0.31422882409854047}
2023-01-05 10:34:47,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:47,361 INFO:     Epoch: 55
2023-01-05 10:34:49,504 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4355701376994451, 'Total loss': 0.4355701376994451} | train loss {'Reaction outcome loss': 0.32010929227312707, 'Total loss': 0.32010929227312707}
2023-01-05 10:34:49,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:49,504 INFO:     Epoch: 56
2023-01-05 10:34:51,666 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4104620079199473, 'Total loss': 0.4104620079199473} | train loss {'Reaction outcome loss': 0.3148695757929776, 'Total loss': 0.3148695757929776}
2023-01-05 10:34:51,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:51,667 INFO:     Epoch: 57
2023-01-05 10:34:53,829 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40113649840156235, 'Total loss': 0.40113649840156235} | train loss {'Reaction outcome loss': 0.30789395014730014, 'Total loss': 0.30789395014730014}
2023-01-05 10:34:53,829 INFO:     Found new best model at epoch 57
2023-01-05 10:34:53,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:53,830 INFO:     Epoch: 58
2023-01-05 10:34:55,959 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44282884200414024, 'Total loss': 0.44282884200414024} | train loss {'Reaction outcome loss': 0.31174604050592397, 'Total loss': 0.31174604050592397}
2023-01-05 10:34:55,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:55,960 INFO:     Epoch: 59
2023-01-05 10:34:58,097 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42485258877277376, 'Total loss': 0.42485258877277376} | train loss {'Reaction outcome loss': 0.3014521096711573, 'Total loss': 0.3014521096711573}
2023-01-05 10:34:58,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:34:58,098 INFO:     Epoch: 60
2023-01-05 10:35:00,214 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4588154017925262, 'Total loss': 0.4588154017925262} | train loss {'Reaction outcome loss': 0.3071512553586125, 'Total loss': 0.3071512553586125}
2023-01-05 10:35:00,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:00,214 INFO:     Epoch: 61
2023-01-05 10:35:02,352 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42826226943482953, 'Total loss': 0.42826226943482953} | train loss {'Reaction outcome loss': 0.3020836533316364, 'Total loss': 0.3020836533316364}
2023-01-05 10:35:02,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:02,352 INFO:     Epoch: 62
2023-01-05 10:35:04,508 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44109059472878775, 'Total loss': 0.44109059472878775} | train loss {'Reaction outcome loss': 0.2982101452862085, 'Total loss': 0.2982101452862085}
2023-01-05 10:35:04,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:04,509 INFO:     Epoch: 63
2023-01-05 10:35:06,647 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44252838591734567, 'Total loss': 0.44252838591734567} | train loss {'Reaction outcome loss': 0.299873107706831, 'Total loss': 0.299873107706831}
2023-01-05 10:35:06,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:06,647 INFO:     Epoch: 64
2023-01-05 10:35:08,770 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4137958327929179, 'Total loss': 0.4137958327929179} | train loss {'Reaction outcome loss': 0.3058974419760963, 'Total loss': 0.3058974419760963}
2023-01-05 10:35:08,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:08,770 INFO:     Epoch: 65
2023-01-05 10:35:10,913 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42257935702800753, 'Total loss': 0.42257935702800753} | train loss {'Reaction outcome loss': 0.2954112563842816, 'Total loss': 0.2954112563842816}
2023-01-05 10:35:10,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:10,913 INFO:     Epoch: 66
2023-01-05 10:35:13,031 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4254267156124115, 'Total loss': 0.4254267156124115} | train loss {'Reaction outcome loss': 0.29153495534336654, 'Total loss': 0.29153495534336654}
2023-01-05 10:35:13,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:13,032 INFO:     Epoch: 67
2023-01-05 10:35:15,165 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4321516573429108, 'Total loss': 0.4321516573429108} | train loss {'Reaction outcome loss': 0.2839142706049471, 'Total loss': 0.2839142706049471}
2023-01-05 10:35:15,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:15,166 INFO:     Epoch: 68
2023-01-05 10:35:17,295 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43821032842000324, 'Total loss': 0.43821032842000324} | train loss {'Reaction outcome loss': 0.28915242020182474, 'Total loss': 0.28915242020182474}
2023-01-05 10:35:17,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:17,296 INFO:     Epoch: 69
2023-01-05 10:35:19,403 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3979375531276067, 'Total loss': 0.3979375531276067} | train loss {'Reaction outcome loss': 0.2880513918701225, 'Total loss': 0.2880513918701225}
2023-01-05 10:35:19,403 INFO:     Found new best model at epoch 69
2023-01-05 10:35:19,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:19,405 INFO:     Epoch: 70
2023-01-05 10:35:21,538 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4096123913923899, 'Total loss': 0.4096123913923899} | train loss {'Reaction outcome loss': 0.2850886072023507, 'Total loss': 0.2850886072023507}
2023-01-05 10:35:21,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:21,538 INFO:     Epoch: 71
2023-01-05 10:35:23,641 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4814813474814097, 'Total loss': 0.4814813474814097} | train loss {'Reaction outcome loss': 0.2815820111403203, 'Total loss': 0.2815820111403203}
2023-01-05 10:35:23,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:23,642 INFO:     Epoch: 72
2023-01-05 10:35:25,781 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4370245983203252, 'Total loss': 0.4370245983203252} | train loss {'Reaction outcome loss': 0.28177220170787687, 'Total loss': 0.28177220170787687}
2023-01-05 10:35:25,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:25,781 INFO:     Epoch: 73
2023-01-05 10:35:27,950 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4450092434883118, 'Total loss': 0.4450092434883118} | train loss {'Reaction outcome loss': 0.28030246489789284, 'Total loss': 0.28030246489789284}
2023-01-05 10:35:27,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:27,951 INFO:     Epoch: 74
2023-01-05 10:35:30,108 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42225493292013805, 'Total loss': 0.42225493292013805} | train loss {'Reaction outcome loss': 0.27754288939700084, 'Total loss': 0.27754288939700084}
2023-01-05 10:35:30,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:30,109 INFO:     Epoch: 75
2023-01-05 10:35:32,288 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4258821651339531, 'Total loss': 0.4258821651339531} | train loss {'Reaction outcome loss': 0.2765062026058634, 'Total loss': 0.2765062026058634}
2023-01-05 10:35:32,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:32,289 INFO:     Epoch: 76
2023-01-05 10:35:34,498 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48124365210533143, 'Total loss': 0.48124365210533143} | train loss {'Reaction outcome loss': 0.27747617794227775, 'Total loss': 0.27747617794227775}
2023-01-05 10:35:34,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:34,499 INFO:     Epoch: 77
2023-01-05 10:35:36,642 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.428152788678805, 'Total loss': 0.428152788678805} | train loss {'Reaction outcome loss': 0.31228231973701454, 'Total loss': 0.31228231973701454}
2023-01-05 10:35:36,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:36,642 INFO:     Epoch: 78
2023-01-05 10:35:38,766 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4437548359235128, 'Total loss': 0.4437548359235128} | train loss {'Reaction outcome loss': 0.2769594028038715, 'Total loss': 0.2769594028038715}
2023-01-05 10:35:38,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:38,766 INFO:     Epoch: 79
2023-01-05 10:35:40,890 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4836600919564565, 'Total loss': 0.4836600919564565} | train loss {'Reaction outcome loss': 0.362536955938634, 'Total loss': 0.362536955938634}
2023-01-05 10:35:40,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:40,890 INFO:     Epoch: 80
2023-01-05 10:35:43,047 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4997139036655426, 'Total loss': 0.4997139036655426} | train loss {'Reaction outcome loss': 0.30733414094193257, 'Total loss': 0.30733414094193257}
2023-01-05 10:35:43,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:43,047 INFO:     Epoch: 81
2023-01-05 10:35:45,146 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4925246884425481, 'Total loss': 0.4925246884425481} | train loss {'Reaction outcome loss': 0.29412096157076134, 'Total loss': 0.29412096157076134}
2023-01-05 10:35:45,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:45,146 INFO:     Epoch: 82
2023-01-05 10:35:47,262 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41728119750817616, 'Total loss': 0.41728119750817616} | train loss {'Reaction outcome loss': 0.34594050892696215, 'Total loss': 0.34594050892696215}
2023-01-05 10:35:47,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:47,263 INFO:     Epoch: 83
2023-01-05 10:35:49,424 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45504647890726724, 'Total loss': 0.45504647890726724} | train loss {'Reaction outcome loss': 0.2901073364014535, 'Total loss': 0.2901073364014535}
2023-01-05 10:35:49,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:49,425 INFO:     Epoch: 84
2023-01-05 10:35:51,539 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43112105429172515, 'Total loss': 0.43112105429172515} | train loss {'Reaction outcome loss': 0.2801226142227002, 'Total loss': 0.2801226142227002}
2023-01-05 10:35:51,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:51,539 INFO:     Epoch: 85
2023-01-05 10:35:53,668 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42532349228858946, 'Total loss': 0.42532349228858946} | train loss {'Reaction outcome loss': 0.28817269219713204, 'Total loss': 0.28817269219713204}
2023-01-05 10:35:53,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:53,668 INFO:     Epoch: 86
2023-01-05 10:35:55,769 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4366703941176335, 'Total loss': 0.4366703941176335} | train loss {'Reaction outcome loss': 0.2758411570060728, 'Total loss': 0.2758411570060728}
2023-01-05 10:35:55,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:55,769 INFO:     Epoch: 87
2023-01-05 10:35:57,914 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49193330307801564, 'Total loss': 0.49193330307801564} | train loss {'Reaction outcome loss': 0.2837804235761354, 'Total loss': 0.2837804235761354}
2023-01-05 10:35:57,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:35:57,915 INFO:     Epoch: 88
2023-01-05 10:36:00,042 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4247517466545105, 'Total loss': 0.4247517466545105} | train loss {'Reaction outcome loss': 0.2831089785491265, 'Total loss': 0.2831089785491265}
2023-01-05 10:36:00,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:00,042 INFO:     Epoch: 89
2023-01-05 10:36:02,186 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47524792651335396, 'Total loss': 0.47524792651335396} | train loss {'Reaction outcome loss': 0.2773583152456263, 'Total loss': 0.2773583152456263}
2023-01-05 10:36:02,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:02,186 INFO:     Epoch: 90
2023-01-05 10:36:04,299 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4317486107349396, 'Total loss': 0.4317486107349396} | train loss {'Reaction outcome loss': 0.2712289842800575, 'Total loss': 0.2712289842800575}
2023-01-05 10:36:04,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:04,301 INFO:     Epoch: 91
2023-01-05 10:36:06,414 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4314727584520976, 'Total loss': 0.4314727584520976} | train loss {'Reaction outcome loss': 0.27612905679996114, 'Total loss': 0.27612905679996114}
2023-01-05 10:36:06,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:06,414 INFO:     Epoch: 92
2023-01-05 10:36:08,572 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43205050627390545, 'Total loss': 0.43205050627390545} | train loss {'Reaction outcome loss': 0.262979782610484, 'Total loss': 0.262979782610484}
2023-01-05 10:36:08,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:08,572 INFO:     Epoch: 93
2023-01-05 10:36:10,714 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4344301124413808, 'Total loss': 0.4344301124413808} | train loss {'Reaction outcome loss': 0.2621964028837326, 'Total loss': 0.2621964028837326}
2023-01-05 10:36:10,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:10,715 INFO:     Epoch: 94
2023-01-05 10:36:12,897 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44986727138360344, 'Total loss': 0.44986727138360344} | train loss {'Reaction outcome loss': 0.2653046729873218, 'Total loss': 0.2653046729873218}
2023-01-05 10:36:12,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:12,898 INFO:     Epoch: 95
2023-01-05 10:36:15,060 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.446149676044782, 'Total loss': 0.446149676044782} | train loss {'Reaction outcome loss': 0.2615019848559261, 'Total loss': 0.2615019848559261}
2023-01-05 10:36:15,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:15,061 INFO:     Epoch: 96
2023-01-05 10:36:17,245 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42023113518953326, 'Total loss': 0.42023113518953326} | train loss {'Reaction outcome loss': 0.25564618932801986, 'Total loss': 0.25564618932801986}
2023-01-05 10:36:17,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:17,246 INFO:     Epoch: 97
2023-01-05 10:36:19,369 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4478332708279292, 'Total loss': 0.4478332708279292} | train loss {'Reaction outcome loss': 0.2570193518658398, 'Total loss': 0.2570193518658398}
2023-01-05 10:36:19,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:19,369 INFO:     Epoch: 98
2023-01-05 10:36:21,489 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39148642669121425, 'Total loss': 0.39148642669121425} | train loss {'Reaction outcome loss': 0.2558352118037452, 'Total loss': 0.2558352118037452}
2023-01-05 10:36:21,489 INFO:     Found new best model at epoch 98
2023-01-05 10:36:21,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:21,491 INFO:     Epoch: 99
2023-01-05 10:36:23,595 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45394649704297385, 'Total loss': 0.45394649704297385} | train loss {'Reaction outcome loss': 0.2508331273747372, 'Total loss': 0.2508331273747372}
2023-01-05 10:36:23,596 INFO:     Best model found after epoch 99 of 100.
2023-01-05 10:36:23,596 INFO:   Done with stage: TRAINING
2023-01-05 10:36:23,596 INFO:   Starting stage: EVALUATION
2023-01-05 10:36:23,729 INFO:   Done with stage: EVALUATION
2023-01-05 10:36:23,729 INFO:   Leaving out SEQ value Fold_9
2023-01-05 10:36:23,741 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 10:36:23,741 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:36:24,387 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:36:24,387 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:36:24,456 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:36:24,456 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:36:24,456 INFO:     No hyperparam tuning for this model
2023-01-05 10:36:24,456 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:36:24,456 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:36:24,457 INFO:     None feature selector for col prot
2023-01-05 10:36:24,457 INFO:     None feature selector for col prot
2023-01-05 10:36:24,457 INFO:     None feature selector for col prot
2023-01-05 10:36:24,458 INFO:     None feature selector for col chem
2023-01-05 10:36:24,458 INFO:     None feature selector for col chem
2023-01-05 10:36:24,458 INFO:     None feature selector for col chem
2023-01-05 10:36:24,458 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:36:24,458 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:36:24,460 INFO:     Number of params in model 72901
2023-01-05 10:36:24,463 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:36:24,463 INFO:   Starting stage: TRAINING
2023-01-05 10:36:24,522 INFO:     Val loss before train {'Reaction outcome loss': 1.0470523754755656, 'Total loss': 1.0470523754755656}
2023-01-05 10:36:24,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:24,522 INFO:     Epoch: 0
2023-01-05 10:36:26,652 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8247545679410299, 'Total loss': 0.8247545679410299} | train loss {'Reaction outcome loss': 0.9196889118250945, 'Total loss': 0.9196889118250945}
2023-01-05 10:36:26,652 INFO:     Found new best model at epoch 0
2023-01-05 10:36:26,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:26,654 INFO:     Epoch: 1
2023-01-05 10:36:28,775 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6195581118265788, 'Total loss': 0.6195581118265788} | train loss {'Reaction outcome loss': 0.7386229010138566, 'Total loss': 0.7386229010138566}
2023-01-05 10:36:28,776 INFO:     Found new best model at epoch 1
2023-01-05 10:36:28,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:28,777 INFO:     Epoch: 2
2023-01-05 10:36:30,887 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5148493548234304, 'Total loss': 0.5148493548234304} | train loss {'Reaction outcome loss': 0.580832901898564, 'Total loss': 0.580832901898564}
2023-01-05 10:36:30,887 INFO:     Found new best model at epoch 2
2023-01-05 10:36:30,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:30,888 INFO:     Epoch: 3
2023-01-05 10:36:33,022 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49042821129163106, 'Total loss': 0.49042821129163106} | train loss {'Reaction outcome loss': 0.5234734876010925, 'Total loss': 0.5234734876010925}
2023-01-05 10:36:33,022 INFO:     Found new best model at epoch 3
2023-01-05 10:36:33,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:33,024 INFO:     Epoch: 4
2023-01-05 10:36:35,132 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4852911114692688, 'Total loss': 0.4852911114692688} | train loss {'Reaction outcome loss': 0.5115874202962479, 'Total loss': 0.5115874202962479}
2023-01-05 10:36:35,132 INFO:     Found new best model at epoch 4
2023-01-05 10:36:35,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:35,133 INFO:     Epoch: 5
2023-01-05 10:36:37,246 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4777717967828115, 'Total loss': 0.4777717967828115} | train loss {'Reaction outcome loss': 0.4887991168576738, 'Total loss': 0.4887991168576738}
2023-01-05 10:36:37,246 INFO:     Found new best model at epoch 5
2023-01-05 10:36:37,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:37,247 INFO:     Epoch: 6
2023-01-05 10:36:39,369 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46514928142229717, 'Total loss': 0.46514928142229717} | train loss {'Reaction outcome loss': 0.48793509686568187, 'Total loss': 0.48793509686568187}
2023-01-05 10:36:39,370 INFO:     Found new best model at epoch 6
2023-01-05 10:36:39,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:39,371 INFO:     Epoch: 7
2023-01-05 10:36:41,498 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45217551589012145, 'Total loss': 0.45217551589012145} | train loss {'Reaction outcome loss': 0.47124607188870077, 'Total loss': 0.47124607188870077}
2023-01-05 10:36:41,499 INFO:     Found new best model at epoch 7
2023-01-05 10:36:41,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:41,500 INFO:     Epoch: 8
2023-01-05 10:36:43,628 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44265213906764983, 'Total loss': 0.44265213906764983} | train loss {'Reaction outcome loss': 0.4691276506559315, 'Total loss': 0.4691276506559315}
2023-01-05 10:36:43,628 INFO:     Found new best model at epoch 8
2023-01-05 10:36:43,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:43,630 INFO:     Epoch: 9
2023-01-05 10:36:45,763 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4412202537059784, 'Total loss': 0.4412202537059784} | train loss {'Reaction outcome loss': 0.4628426830513754, 'Total loss': 0.4628426830513754}
2023-01-05 10:36:45,764 INFO:     Found new best model at epoch 9
2023-01-05 10:36:45,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:45,765 INFO:     Epoch: 10
2023-01-05 10:36:47,875 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44723190466562907, 'Total loss': 0.44723190466562907} | train loss {'Reaction outcome loss': 0.45673488357958075, 'Total loss': 0.45673488357958075}
2023-01-05 10:36:47,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:47,876 INFO:     Epoch: 11
2023-01-05 10:36:49,998 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46618120272954305, 'Total loss': 0.46618120272954305} | train loss {'Reaction outcome loss': 0.4718303027684274, 'Total loss': 0.4718303027684274}
2023-01-05 10:36:49,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:49,998 INFO:     Epoch: 12
2023-01-05 10:36:52,126 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47103826800982157, 'Total loss': 0.47103826800982157} | train loss {'Reaction outcome loss': 0.4795520395661394, 'Total loss': 0.4795520395661394}
2023-01-05 10:36:52,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:52,126 INFO:     Epoch: 13
2023-01-05 10:36:54,223 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46868572433789574, 'Total loss': 0.46868572433789574} | train loss {'Reaction outcome loss': 0.44507881913475855, 'Total loss': 0.44507881913475855}
2023-01-05 10:36:54,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:54,223 INFO:     Epoch: 14
2023-01-05 10:36:56,349 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4412274847428004, 'Total loss': 0.4412274847428004} | train loss {'Reaction outcome loss': 0.44211243414927437, 'Total loss': 0.44211243414927437}
2023-01-05 10:36:56,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:56,349 INFO:     Epoch: 15
2023-01-05 10:36:58,473 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4533924241860708, 'Total loss': 0.4533924241860708} | train loss {'Reaction outcome loss': 0.43531112585459714, 'Total loss': 0.43531112585459714}
2023-01-05 10:36:58,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:36:58,474 INFO:     Epoch: 16
2023-01-05 10:37:00,583 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4290566047032674, 'Total loss': 0.4290566047032674} | train loss {'Reaction outcome loss': 0.43343308254523016, 'Total loss': 0.43343308254523016}
2023-01-05 10:37:00,584 INFO:     Found new best model at epoch 16
2023-01-05 10:37:00,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:00,585 INFO:     Epoch: 17
2023-01-05 10:37:02,707 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45637342929840086, 'Total loss': 0.45637342929840086} | train loss {'Reaction outcome loss': 0.4265439734402774, 'Total loss': 0.4265439734402774}
2023-01-05 10:37:02,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:02,707 INFO:     Epoch: 18
2023-01-05 10:37:04,805 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4382420202096303, 'Total loss': 0.4382420202096303} | train loss {'Reaction outcome loss': 0.42613342928065767, 'Total loss': 0.42613342928065767}
2023-01-05 10:37:04,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:04,805 INFO:     Epoch: 19
2023-01-05 10:37:06,943 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46001667976379396, 'Total loss': 0.46001667976379396} | train loss {'Reaction outcome loss': 0.4193788510494177, 'Total loss': 0.4193788510494177}
2023-01-05 10:37:06,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:06,943 INFO:     Epoch: 20
2023-01-05 10:37:09,069 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4340565393368403, 'Total loss': 0.4340565393368403} | train loss {'Reaction outcome loss': 0.41199182553142577, 'Total loss': 0.41199182553142577}
2023-01-05 10:37:09,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:09,069 INFO:     Epoch: 21
2023-01-05 10:37:11,219 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44075282315413156, 'Total loss': 0.44075282315413156} | train loss {'Reaction outcome loss': 0.42475120599071187, 'Total loss': 0.42475120599071187}
2023-01-05 10:37:11,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:11,219 INFO:     Epoch: 22
2023-01-05 10:37:13,377 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42675120333830513, 'Total loss': 0.42675120333830513} | train loss {'Reaction outcome loss': 0.4360835882719097, 'Total loss': 0.4360835882719097}
2023-01-05 10:37:13,377 INFO:     Found new best model at epoch 22
2023-01-05 10:37:13,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:13,378 INFO:     Epoch: 23
2023-01-05 10:37:15,590 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42946043610572815, 'Total loss': 0.42946043610572815} | train loss {'Reaction outcome loss': 0.4066973014205755, 'Total loss': 0.4066973014205755}
2023-01-05 10:37:15,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:15,591 INFO:     Epoch: 24
2023-01-05 10:37:17,695 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4331983009974162, 'Total loss': 0.4331983009974162} | train loss {'Reaction outcome loss': 0.4010198998612527, 'Total loss': 0.4010198998612527}
2023-01-05 10:37:17,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:17,696 INFO:     Epoch: 25
2023-01-05 10:37:19,827 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4591804305712382, 'Total loss': 0.4591804305712382} | train loss {'Reaction outcome loss': 0.400303123466522, 'Total loss': 0.400303123466522}
2023-01-05 10:37:19,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:19,827 INFO:     Epoch: 26
2023-01-05 10:37:21,976 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4013466815153758, 'Total loss': 0.4013466815153758} | train loss {'Reaction outcome loss': 0.39148221662364213, 'Total loss': 0.39148221662364213}
2023-01-05 10:37:21,977 INFO:     Found new best model at epoch 26
2023-01-05 10:37:21,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:21,979 INFO:     Epoch: 27
2023-01-05 10:37:24,106 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4058415959278742, 'Total loss': 0.4058415959278742} | train loss {'Reaction outcome loss': 0.4016481641599018, 'Total loss': 0.4016481641599018}
2023-01-05 10:37:24,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:24,106 INFO:     Epoch: 28
2023-01-05 10:37:26,311 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4170254528522491, 'Total loss': 0.4170254528522491} | train loss {'Reaction outcome loss': 0.39680037874242535, 'Total loss': 0.39680037874242535}
2023-01-05 10:37:26,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:26,311 INFO:     Epoch: 29
2023-01-05 10:37:28,441 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4064485649267832, 'Total loss': 0.4064485649267832} | train loss {'Reaction outcome loss': 0.3857657134370959, 'Total loss': 0.3857657134370959}
2023-01-05 10:37:28,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:28,441 INFO:     Epoch: 30
2023-01-05 10:37:30,659 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4105678687493006, 'Total loss': 0.4105678687493006} | train loss {'Reaction outcome loss': 0.38504920575254853, 'Total loss': 0.38504920575254853}
2023-01-05 10:37:30,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:30,660 INFO:     Epoch: 31
2023-01-05 10:37:32,888 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41375181674957273, 'Total loss': 0.41375181674957273} | train loss {'Reaction outcome loss': 0.37657670251201786, 'Total loss': 0.37657670251201786}
2023-01-05 10:37:32,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:32,888 INFO:     Epoch: 32
2023-01-05 10:37:35,118 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41067606608072915, 'Total loss': 0.41067606608072915} | train loss {'Reaction outcome loss': 0.368536654498725, 'Total loss': 0.368536654498725}
2023-01-05 10:37:35,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:35,119 INFO:     Epoch: 33
2023-01-05 10:37:37,362 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4296179413795471, 'Total loss': 0.4296179413795471} | train loss {'Reaction outcome loss': 0.37995492691255134, 'Total loss': 0.37995492691255134}
2023-01-05 10:37:37,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:37,362 INFO:     Epoch: 34
2023-01-05 10:37:39,575 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45103609263896943, 'Total loss': 0.45103609263896943} | train loss {'Reaction outcome loss': 0.3697857915599277, 'Total loss': 0.3697857915599277}
2023-01-05 10:37:39,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:39,575 INFO:     Epoch: 35
2023-01-05 10:37:41,782 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43148896396160125, 'Total loss': 0.43148896396160125} | train loss {'Reaction outcome loss': 0.39045199823390314, 'Total loss': 0.39045199823390314}
2023-01-05 10:37:41,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:41,783 INFO:     Epoch: 36
2023-01-05 10:37:43,953 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41020879745483396, 'Total loss': 0.41020879745483396} | train loss {'Reaction outcome loss': 0.36540360441701353, 'Total loss': 0.36540360441701353}
2023-01-05 10:37:43,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:43,954 INFO:     Epoch: 37
2023-01-05 10:37:46,077 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.395036647717158, 'Total loss': 0.395036647717158} | train loss {'Reaction outcome loss': 0.3545527092140654, 'Total loss': 0.3545527092140654}
2023-01-05 10:37:46,077 INFO:     Found new best model at epoch 37
2023-01-05 10:37:46,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:46,078 INFO:     Epoch: 38
2023-01-05 10:37:48,177 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39290304283301036, 'Total loss': 0.39290304283301036} | train loss {'Reaction outcome loss': 0.3648665681704069, 'Total loss': 0.3648665681704069}
2023-01-05 10:37:48,177 INFO:     Found new best model at epoch 38
2023-01-05 10:37:48,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:48,178 INFO:     Epoch: 39
2023-01-05 10:37:50,293 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4071884542703629, 'Total loss': 0.4071884542703629} | train loss {'Reaction outcome loss': 0.3525485014779142, 'Total loss': 0.3525485014779142}
2023-01-05 10:37:50,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:50,293 INFO:     Epoch: 40
2023-01-05 10:37:52,401 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40027428964773815, 'Total loss': 0.40027428964773815} | train loss {'Reaction outcome loss': 0.3476356117348389, 'Total loss': 0.3476356117348389}
2023-01-05 10:37:52,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:52,403 INFO:     Epoch: 41
2023-01-05 10:37:54,498 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4101766357819239, 'Total loss': 0.4101766357819239} | train loss {'Reaction outcome loss': 0.342542005902041, 'Total loss': 0.342542005902041}
2023-01-05 10:37:54,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:54,498 INFO:     Epoch: 42
2023-01-05 10:37:56,628 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38603511452674866, 'Total loss': 0.38603511452674866} | train loss {'Reaction outcome loss': 0.3415124485291742, 'Total loss': 0.3415124485291742}
2023-01-05 10:37:56,628 INFO:     Found new best model at epoch 42
2023-01-05 10:37:56,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:56,629 INFO:     Epoch: 43
2023-01-05 10:37:58,765 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3903837025165558, 'Total loss': 0.3903837025165558} | train loss {'Reaction outcome loss': 0.3369487012547535, 'Total loss': 0.3369487012547535}
2023-01-05 10:37:58,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:37:58,765 INFO:     Epoch: 44
2023-01-05 10:38:00,871 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3890787730614344, 'Total loss': 0.3890787730614344} | train loss {'Reaction outcome loss': 0.3372875156385856, 'Total loss': 0.3372875156385856}
2023-01-05 10:38:00,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:00,871 INFO:     Epoch: 45
2023-01-05 10:38:03,003 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3941665530204773, 'Total loss': 0.3941665530204773} | train loss {'Reaction outcome loss': 0.33119176925401256, 'Total loss': 0.33119176925401256}
2023-01-05 10:38:03,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:03,003 INFO:     Epoch: 46
2023-01-05 10:38:05,161 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40105352401733396, 'Total loss': 0.40105352401733396} | train loss {'Reaction outcome loss': 0.33323727494923555, 'Total loss': 0.33323727494923555}
2023-01-05 10:38:05,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:05,161 INFO:     Epoch: 47
2023-01-05 10:38:07,173 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4029357214768728, 'Total loss': 0.4029357214768728} | train loss {'Reaction outcome loss': 0.32382169889543067, 'Total loss': 0.32382169889543067}
2023-01-05 10:38:07,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:07,173 INFO:     Epoch: 48
2023-01-05 10:38:09,268 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36676025837659837, 'Total loss': 0.36676025837659837} | train loss {'Reaction outcome loss': 0.3209682689790708, 'Total loss': 0.3209682689790708}
2023-01-05 10:38:09,268 INFO:     Found new best model at epoch 48
2023-01-05 10:38:09,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:09,270 INFO:     Epoch: 49
2023-01-05 10:38:11,394 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.388869268198808, 'Total loss': 0.388869268198808} | train loss {'Reaction outcome loss': 0.3210997300263008, 'Total loss': 0.3210997300263008}
2023-01-05 10:38:11,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:11,395 INFO:     Epoch: 50
2023-01-05 10:38:13,513 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3609894081950188, 'Total loss': 0.3609894081950188} | train loss {'Reaction outcome loss': 0.31507595656928944, 'Total loss': 0.31507595656928944}
2023-01-05 10:38:13,513 INFO:     Found new best model at epoch 50
2023-01-05 10:38:13,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:13,514 INFO:     Epoch: 51
2023-01-05 10:38:15,634 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3718886723121007, 'Total loss': 0.3718886723121007} | train loss {'Reaction outcome loss': 0.3164781894124974, 'Total loss': 0.3164781894124974}
2023-01-05 10:38:15,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:15,635 INFO:     Epoch: 52
2023-01-05 10:38:17,742 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3855781922737757, 'Total loss': 0.3855781922737757} | train loss {'Reaction outcome loss': 0.3115029640693252, 'Total loss': 0.3115029640693252}
2023-01-05 10:38:17,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:17,743 INFO:     Epoch: 53
2023-01-05 10:38:19,849 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40567132234573366, 'Total loss': 0.40567132234573366} | train loss {'Reaction outcome loss': 0.30814119926377526, 'Total loss': 0.30814119926377526}
2023-01-05 10:38:19,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:19,849 INFO:     Epoch: 54
2023-01-05 10:38:21,984 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3624646425247192, 'Total loss': 0.3624646425247192} | train loss {'Reaction outcome loss': 0.30630206584412034, 'Total loss': 0.30630206584412034}
2023-01-05 10:38:21,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:21,986 INFO:     Epoch: 55
2023-01-05 10:38:24,113 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38603427906831106, 'Total loss': 0.38603427906831106} | train loss {'Reaction outcome loss': 0.3009984497599046, 'Total loss': 0.3009984497599046}
2023-01-05 10:38:24,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:24,113 INFO:     Epoch: 56
2023-01-05 10:38:26,208 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44028218388557433, 'Total loss': 0.44028218388557433} | train loss {'Reaction outcome loss': 0.3151195722402654, 'Total loss': 0.3151195722402654}
2023-01-05 10:38:26,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:26,208 INFO:     Epoch: 57
2023-01-05 10:38:28,315 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4548531353473663, 'Total loss': 0.4548531353473663} | train loss {'Reaction outcome loss': 0.3311430596775186, 'Total loss': 0.3311430596775186}
2023-01-05 10:38:28,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:28,316 INFO:     Epoch: 58
2023-01-05 10:38:30,445 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38630926609039307, 'Total loss': 0.38630926609039307} | train loss {'Reaction outcome loss': 0.30156831777708576, 'Total loss': 0.30156831777708576}
2023-01-05 10:38:30,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:30,445 INFO:     Epoch: 59
2023-01-05 10:38:32,555 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37121174732844037, 'Total loss': 0.37121174732844037} | train loss {'Reaction outcome loss': 0.2941610512053307, 'Total loss': 0.2941610512053307}
2023-01-05 10:38:32,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:32,555 INFO:     Epoch: 60
2023-01-05 10:38:34,706 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35500024606784186, 'Total loss': 0.35500024606784186} | train loss {'Reaction outcome loss': 0.2902791299397443, 'Total loss': 0.2902791299397443}
2023-01-05 10:38:34,707 INFO:     Found new best model at epoch 60
2023-01-05 10:38:34,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:34,708 INFO:     Epoch: 61
2023-01-05 10:38:36,840 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3753647287686666, 'Total loss': 0.3753647287686666} | train loss {'Reaction outcome loss': 0.28847007602082053, 'Total loss': 0.28847007602082053}
2023-01-05 10:38:36,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:36,840 INFO:     Epoch: 62
2023-01-05 10:38:38,963 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.348582727710406, 'Total loss': 0.348582727710406} | train loss {'Reaction outcome loss': 0.29028909226621763, 'Total loss': 0.29028909226621763}
2023-01-05 10:38:38,963 INFO:     Found new best model at epoch 62
2023-01-05 10:38:38,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:38,964 INFO:     Epoch: 63
2023-01-05 10:38:41,086 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36776594519615174, 'Total loss': 0.36776594519615174} | train loss {'Reaction outcome loss': 0.289032897176356, 'Total loss': 0.289032897176356}
2023-01-05 10:38:41,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:41,087 INFO:     Epoch: 64
2023-01-05 10:38:43,218 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36523173103729883, 'Total loss': 0.36523173103729883} | train loss {'Reaction outcome loss': 0.28442730105640635, 'Total loss': 0.28442730105640635}
2023-01-05 10:38:43,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:43,218 INFO:     Epoch: 65
2023-01-05 10:38:45,333 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44642037749290464, 'Total loss': 0.44642037749290464} | train loss {'Reaction outcome loss': 0.2808177136390915, 'Total loss': 0.2808177136390915}
2023-01-05 10:38:45,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:45,333 INFO:     Epoch: 66
2023-01-05 10:38:47,482 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3498196308811506, 'Total loss': 0.3498196308811506} | train loss {'Reaction outcome loss': 0.2894761651430441, 'Total loss': 0.2894761651430441}
2023-01-05 10:38:47,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:47,482 INFO:     Epoch: 67
2023-01-05 10:38:49,607 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37948088397582375, 'Total loss': 0.37948088397582375} | train loss {'Reaction outcome loss': 0.34501299876179814, 'Total loss': 0.34501299876179814}
2023-01-05 10:38:49,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:49,607 INFO:     Epoch: 68
2023-01-05 10:38:51,726 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3885684410730998, 'Total loss': 0.3885684410730998} | train loss {'Reaction outcome loss': 0.293502327633863, 'Total loss': 0.293502327633863}
2023-01-05 10:38:51,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:51,726 INFO:     Epoch: 69
2023-01-05 10:38:53,852 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36059255997339884, 'Total loss': 0.36059255997339884} | train loss {'Reaction outcome loss': 0.28197754070008185, 'Total loss': 0.28197754070008185}
2023-01-05 10:38:53,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:53,852 INFO:     Epoch: 70
2023-01-05 10:38:55,982 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3407772660255432, 'Total loss': 0.3407772660255432} | train loss {'Reaction outcome loss': 0.27423851201614446, 'Total loss': 0.27423851201614446}
2023-01-05 10:38:55,982 INFO:     Found new best model at epoch 70
2023-01-05 10:38:55,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:55,983 INFO:     Epoch: 71
2023-01-05 10:38:58,117 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38151066104571024, 'Total loss': 0.38151066104571024} | train loss {'Reaction outcome loss': 0.28044586134669575, 'Total loss': 0.28044586134669575}
2023-01-05 10:38:58,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:38:58,118 INFO:     Epoch: 72
2023-01-05 10:39:00,262 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3912122418483098, 'Total loss': 0.3912122418483098} | train loss {'Reaction outcome loss': 0.2882317893960609, 'Total loss': 0.2882317893960609}
2023-01-05 10:39:00,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:00,263 INFO:     Epoch: 73
2023-01-05 10:39:02,376 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3494448999563853, 'Total loss': 0.3494448999563853} | train loss {'Reaction outcome loss': 0.273264331784457, 'Total loss': 0.273264331784457}
2023-01-05 10:39:02,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:02,376 INFO:     Epoch: 74
2023-01-05 10:39:04,488 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3647566248973211, 'Total loss': 0.3647566248973211} | train loss {'Reaction outcome loss': 0.2664359300025531, 'Total loss': 0.2664359300025531}
2023-01-05 10:39:04,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:04,488 INFO:     Epoch: 75
2023-01-05 10:39:06,630 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37022281587123873, 'Total loss': 0.37022281587123873} | train loss {'Reaction outcome loss': 0.26839909666855616, 'Total loss': 0.26839909666855616}
2023-01-05 10:39:06,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:06,630 INFO:     Epoch: 76
2023-01-05 10:39:08,756 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3894975756605466, 'Total loss': 0.3894975756605466} | train loss {'Reaction outcome loss': 0.2729964815254156, 'Total loss': 0.2729964815254156}
2023-01-05 10:39:08,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:08,756 INFO:     Epoch: 77
2023-01-05 10:39:10,872 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3830198725064596, 'Total loss': 0.3830198725064596} | train loss {'Reaction outcome loss': 0.2638709856065638, 'Total loss': 0.2638709856065638}
2023-01-05 10:39:10,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:10,872 INFO:     Epoch: 78
2023-01-05 10:39:12,987 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36750268439451855, 'Total loss': 0.36750268439451855} | train loss {'Reaction outcome loss': 0.2625542181085093, 'Total loss': 0.2625542181085093}
2023-01-05 10:39:12,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:12,988 INFO:     Epoch: 79
2023-01-05 10:39:15,095 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36711855928103126, 'Total loss': 0.36711855928103126} | train loss {'Reaction outcome loss': 0.27206433697959426, 'Total loss': 0.27206433697959426}
2023-01-05 10:39:15,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:15,096 INFO:     Epoch: 80
2023-01-05 10:39:17,209 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3819666514794032, 'Total loss': 0.3819666514794032} | train loss {'Reaction outcome loss': 0.26034715889229276, 'Total loss': 0.26034715889229276}
2023-01-05 10:39:17,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:17,210 INFO:     Epoch: 81
2023-01-05 10:39:19,336 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38676597476005553, 'Total loss': 0.38676597476005553} | train loss {'Reaction outcome loss': 0.25007293572433403, 'Total loss': 0.25007293572433403}
2023-01-05 10:39:19,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:19,337 INFO:     Epoch: 82
2023-01-05 10:39:21,468 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3849495033423106, 'Total loss': 0.3849495033423106} | train loss {'Reaction outcome loss': 0.2617626059559964, 'Total loss': 0.2617626059559964}
2023-01-05 10:39:21,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:21,468 INFO:     Epoch: 83
2023-01-05 10:39:23,575 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38215786293148996, 'Total loss': 0.38215786293148996} | train loss {'Reaction outcome loss': 0.25223114502791694, 'Total loss': 0.25223114502791694}
2023-01-05 10:39:23,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:23,575 INFO:     Epoch: 84
2023-01-05 10:39:25,688 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3719817638397217, 'Total loss': 0.3719817638397217} | train loss {'Reaction outcome loss': 0.25329901506209856, 'Total loss': 0.25329901506209856}
2023-01-05 10:39:25,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:25,688 INFO:     Epoch: 85
2023-01-05 10:39:27,821 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42752920612692835, 'Total loss': 0.42752920612692835} | train loss {'Reaction outcome loss': 0.2526392933993876, 'Total loss': 0.2526392933993876}
2023-01-05 10:39:27,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:27,821 INFO:     Epoch: 86
2023-01-05 10:39:29,922 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35401112387577693, 'Total loss': 0.35401112387577693} | train loss {'Reaction outcome loss': 0.2520365414339673, 'Total loss': 0.2520365414339673}
2023-01-05 10:39:29,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:29,922 INFO:     Epoch: 87
2023-01-05 10:39:32,035 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40930998921394346, 'Total loss': 0.40930998921394346} | train loss {'Reaction outcome loss': 0.25442827102091065, 'Total loss': 0.25442827102091065}
2023-01-05 10:39:32,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:32,035 INFO:     Epoch: 88
2023-01-05 10:39:34,234 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4510841985543569, 'Total loss': 0.4510841985543569} | train loss {'Reaction outcome loss': 0.24836290751493612, 'Total loss': 0.24836290751493612}
2023-01-05 10:39:34,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:34,235 INFO:     Epoch: 89
2023-01-05 10:39:36,362 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3935527761777242, 'Total loss': 0.3935527761777242} | train loss {'Reaction outcome loss': 0.25568943692548823, 'Total loss': 0.25568943692548823}
2023-01-05 10:39:36,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:36,362 INFO:     Epoch: 90
2023-01-05 10:39:38,494 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39204691449801127, 'Total loss': 0.39204691449801127} | train loss {'Reaction outcome loss': 0.24186084705634395, 'Total loss': 0.24186084705634395}
2023-01-05 10:39:38,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:38,494 INFO:     Epoch: 91
2023-01-05 10:39:40,604 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3673187593619029, 'Total loss': 0.3673187593619029} | train loss {'Reaction outcome loss': 0.24275805474805395, 'Total loss': 0.24275805474805395}
2023-01-05 10:39:40,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:40,605 INFO:     Epoch: 92
2023-01-05 10:39:42,719 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40828105409940085, 'Total loss': 0.40828105409940085} | train loss {'Reaction outcome loss': 0.24653757594949086, 'Total loss': 0.24653757594949086}
2023-01-05 10:39:42,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:42,720 INFO:     Epoch: 93
2023-01-05 10:39:44,839 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3532963623603185, 'Total loss': 0.3532963623603185} | train loss {'Reaction outcome loss': 0.24409477906537821, 'Total loss': 0.24409477906537821}
2023-01-05 10:39:44,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:44,839 INFO:     Epoch: 94
2023-01-05 10:39:46,975 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3587636927763621, 'Total loss': 0.3587636927763621} | train loss {'Reaction outcome loss': 0.2387389953685182, 'Total loss': 0.2387389953685182}
2023-01-05 10:39:46,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:46,975 INFO:     Epoch: 95
2023-01-05 10:39:49,084 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3851612001657486, 'Total loss': 0.3851612001657486} | train loss {'Reaction outcome loss': 0.24708870350234752, 'Total loss': 0.24708870350234752}
2023-01-05 10:39:49,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:49,084 INFO:     Epoch: 96
2023-01-05 10:39:51,206 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.374988184372584, 'Total loss': 0.374988184372584} | train loss {'Reaction outcome loss': 0.2481144266103055, 'Total loss': 0.2481144266103055}
2023-01-05 10:39:51,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:51,206 INFO:     Epoch: 97
2023-01-05 10:39:53,327 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36514719168966014, 'Total loss': 0.36514719168966014} | train loss {'Reaction outcome loss': 0.2373502356796593, 'Total loss': 0.2373502356796593}
2023-01-05 10:39:53,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:53,328 INFO:     Epoch: 98
2023-01-05 10:39:55,471 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.32946929344907405, 'Total loss': 0.32946929344907405} | train loss {'Reaction outcome loss': 0.23444543068087997, 'Total loss': 0.23444543068087997}
2023-01-05 10:39:55,471 INFO:     Found new best model at epoch 98
2023-01-05 10:39:55,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:55,473 INFO:     Epoch: 99
2023-01-05 10:39:57,612 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3872320642073949, 'Total loss': 0.3872320642073949} | train loss {'Reaction outcome loss': 0.24286655791966832, 'Total loss': 0.24286655791966832}
2023-01-05 10:39:57,612 INFO:     Best model found after epoch 99 of 100.
2023-01-05 10:39:57,612 INFO:   Done with stage: TRAINING
2023-01-05 10:39:57,612 INFO:   Starting stage: EVALUATION
2023-01-05 10:39:57,746 INFO:   Done with stage: EVALUATION
2023-01-05 10:39:57,755 INFO:   Leaving out SEQ value Fold_0
2023-01-05 10:39:57,767 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 10:39:57,767 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:39:58,406 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:39:58,406 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:39:58,476 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:39:58,476 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:39:58,476 INFO:     No hyperparam tuning for this model
2023-01-05 10:39:58,476 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:39:58,476 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:39:58,477 INFO:     None feature selector for col prot
2023-01-05 10:39:58,477 INFO:     None feature selector for col prot
2023-01-05 10:39:58,477 INFO:     None feature selector for col prot
2023-01-05 10:39:58,478 INFO:     None feature selector for col chem
2023-01-05 10:39:58,478 INFO:     None feature selector for col chem
2023-01-05 10:39:58,478 INFO:     None feature selector for col chem
2023-01-05 10:39:58,478 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:39:58,478 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:39:58,479 INFO:     Number of params in model 72901
2023-01-05 10:39:58,482 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:39:58,483 INFO:   Starting stage: TRAINING
2023-01-05 10:39:58,544 INFO:     Val loss before train {'Reaction outcome loss': 1.0217609087626138, 'Total loss': 1.0217609087626138}
2023-01-05 10:39:58,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:39:58,544 INFO:     Epoch: 0
2023-01-05 10:40:00,662 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8495314359664917, 'Total loss': 0.8495314359664917} | train loss {'Reaction outcome loss': 0.9057421792244565, 'Total loss': 0.9057421792244565}
2023-01-05 10:40:00,662 INFO:     Found new best model at epoch 0
2023-01-05 10:40:00,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:00,663 INFO:     Epoch: 1
2023-01-05 10:40:02,794 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6029707590738932, 'Total loss': 0.6029707590738932} | train loss {'Reaction outcome loss': 0.6923785278762596, 'Total loss': 0.6923785278762596}
2023-01-05 10:40:02,794 INFO:     Found new best model at epoch 1
2023-01-05 10:40:02,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:02,795 INFO:     Epoch: 2
2023-01-05 10:40:04,907 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5093207577864329, 'Total loss': 0.5093207577864329} | train loss {'Reaction outcome loss': 0.5580152301252752, 'Total loss': 0.5580152301252752}
2023-01-05 10:40:04,907 INFO:     Found new best model at epoch 2
2023-01-05 10:40:04,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:04,909 INFO:     Epoch: 3
2023-01-05 10:40:07,029 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4450732409954071, 'Total loss': 0.4450732409954071} | train loss {'Reaction outcome loss': 0.5257091496196286, 'Total loss': 0.5257091496196286}
2023-01-05 10:40:07,030 INFO:     Found new best model at epoch 3
2023-01-05 10:40:07,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:07,031 INFO:     Epoch: 4
2023-01-05 10:40:09,149 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46110312938690184, 'Total loss': 0.46110312938690184} | train loss {'Reaction outcome loss': 0.5015765473523272, 'Total loss': 0.5015765473523272}
2023-01-05 10:40:09,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:09,150 INFO:     Epoch: 5
2023-01-05 10:40:11,294 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4741224785645803, 'Total loss': 0.4741224785645803} | train loss {'Reaction outcome loss': 0.48851693751617675, 'Total loss': 0.48851693751617675}
2023-01-05 10:40:11,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:11,294 INFO:     Epoch: 6
2023-01-05 10:40:13,418 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46736600597699485, 'Total loss': 0.46736600597699485} | train loss {'Reaction outcome loss': 0.49139364144724346, 'Total loss': 0.49139364144724346}
2023-01-05 10:40:13,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:13,418 INFO:     Epoch: 7
2023-01-05 10:40:15,545 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48099767764409385, 'Total loss': 0.48099767764409385} | train loss {'Reaction outcome loss': 0.5021048233037868, 'Total loss': 0.5021048233037868}
2023-01-05 10:40:15,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:15,546 INFO:     Epoch: 8
2023-01-05 10:40:17,682 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45363796800374984, 'Total loss': 0.45363796800374984} | train loss {'Reaction outcome loss': 0.46930376227027265, 'Total loss': 0.46930376227027265}
2023-01-05 10:40:17,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:17,683 INFO:     Epoch: 9
2023-01-05 10:40:19,806 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4644255518913269, 'Total loss': 0.4644255518913269} | train loss {'Reaction outcome loss': 0.45896362237618776, 'Total loss': 0.45896362237618776}
2023-01-05 10:40:19,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:19,806 INFO:     Epoch: 10
2023-01-05 10:40:21,928 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4346224044760068, 'Total loss': 0.4346224044760068} | train loss {'Reaction outcome loss': 0.4546810870170188, 'Total loss': 0.4546810870170188}
2023-01-05 10:40:21,929 INFO:     Found new best model at epoch 10
2023-01-05 10:40:21,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:21,930 INFO:     Epoch: 11
2023-01-05 10:40:24,032 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4349434236685435, 'Total loss': 0.4349434236685435} | train loss {'Reaction outcome loss': 0.450701070921175, 'Total loss': 0.450701070921175}
2023-01-05 10:40:24,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:24,033 INFO:     Epoch: 12
2023-01-05 10:40:26,144 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4501955439647039, 'Total loss': 0.4501955439647039} | train loss {'Reaction outcome loss': 0.44477575284553744, 'Total loss': 0.44477575284553744}
2023-01-05 10:40:26,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:26,145 INFO:     Epoch: 13
2023-01-05 10:40:28,243 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4406076818704605, 'Total loss': 0.4406076818704605} | train loss {'Reaction outcome loss': 0.4442820299005109, 'Total loss': 0.4442820299005109}
2023-01-05 10:40:28,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:28,244 INFO:     Epoch: 14
2023-01-05 10:40:30,359 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41606360375881196, 'Total loss': 0.41606360375881196} | train loss {'Reaction outcome loss': 0.4382766755943126, 'Total loss': 0.4382766755943126}
2023-01-05 10:40:30,360 INFO:     Found new best model at epoch 14
2023-01-05 10:40:30,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:30,361 INFO:     Epoch: 15
2023-01-05 10:40:32,486 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43465672234694164, 'Total loss': 0.43465672234694164} | train loss {'Reaction outcome loss': 0.4294517669840243, 'Total loss': 0.4294517669840243}
2023-01-05 10:40:32,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:32,487 INFO:     Epoch: 16
2023-01-05 10:40:34,639 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40991592208544414, 'Total loss': 0.40991592208544414} | train loss {'Reaction outcome loss': 0.4303879035987716, 'Total loss': 0.4303879035987716}
2023-01-05 10:40:34,639 INFO:     Found new best model at epoch 16
2023-01-05 10:40:34,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:34,640 INFO:     Epoch: 17
2023-01-05 10:40:36,553 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44374097386995953, 'Total loss': 0.44374097386995953} | train loss {'Reaction outcome loss': 0.4398001300346484, 'Total loss': 0.4398001300346484}
2023-01-05 10:40:36,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:36,554 INFO:     Epoch: 18
2023-01-05 10:40:38,335 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4216618945201238, 'Total loss': 0.4216618945201238} | train loss {'Reaction outcome loss': 0.4303551279673506, 'Total loss': 0.4303551279673506}
2023-01-05 10:40:38,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:38,335 INFO:     Epoch: 19
2023-01-05 10:40:40,180 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.447226220369339, 'Total loss': 0.447226220369339} | train loss {'Reaction outcome loss': 0.42401188954056745, 'Total loss': 0.42401188954056745}
2023-01-05 10:40:40,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:40,180 INFO:     Epoch: 20
2023-01-05 10:40:42,315 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45476693908373517, 'Total loss': 0.45476693908373517} | train loss {'Reaction outcome loss': 0.4160354183851809, 'Total loss': 0.4160354183851809}
2023-01-05 10:40:42,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:42,316 INFO:     Epoch: 21
2023-01-05 10:40:44,445 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44039508899052937, 'Total loss': 0.44039508899052937} | train loss {'Reaction outcome loss': 0.4081201985604096, 'Total loss': 0.4081201985604096}
2023-01-05 10:40:44,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:44,445 INFO:     Epoch: 22
2023-01-05 10:40:46,575 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4827727774779002, 'Total loss': 0.4827727774779002} | train loss {'Reaction outcome loss': 0.406412281865335, 'Total loss': 0.406412281865335}
2023-01-05 10:40:46,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:46,577 INFO:     Epoch: 23
2023-01-05 10:40:48,696 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4514790634314219, 'Total loss': 0.4514790634314219} | train loss {'Reaction outcome loss': 0.40854155867909075, 'Total loss': 0.40854155867909075}
2023-01-05 10:40:48,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:48,696 INFO:     Epoch: 24
2023-01-05 10:40:50,808 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4180752327044805, 'Total loss': 0.4180752327044805} | train loss {'Reaction outcome loss': 0.39933601584272, 'Total loss': 0.39933601584272}
2023-01-05 10:40:50,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:50,809 INFO:     Epoch: 25
2023-01-05 10:40:52,958 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43660929799079895, 'Total loss': 0.43660929799079895} | train loss {'Reaction outcome loss': 0.396059812579235, 'Total loss': 0.396059812579235}
2023-01-05 10:40:52,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:52,959 INFO:     Epoch: 26
2023-01-05 10:40:55,009 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42946920891602836, 'Total loss': 0.42946920891602836} | train loss {'Reaction outcome loss': 0.3948702493655509, 'Total loss': 0.3948702493655509}
2023-01-05 10:40:55,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:55,010 INFO:     Epoch: 27
2023-01-05 10:40:56,775 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40043401420116426, 'Total loss': 0.40043401420116426} | train loss {'Reaction outcome loss': 0.38754117200016114, 'Total loss': 0.38754117200016114}
2023-01-05 10:40:56,776 INFO:     Found new best model at epoch 27
2023-01-05 10:40:56,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:56,777 INFO:     Epoch: 28
2023-01-05 10:40:58,546 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40313719312349955, 'Total loss': 0.40313719312349955} | train loss {'Reaction outcome loss': 0.3958170284387197, 'Total loss': 0.3958170284387197}
2023-01-05 10:40:58,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:40:58,546 INFO:     Epoch: 29
2023-01-05 10:41:00,661 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39432843824227654, 'Total loss': 0.39432843824227654} | train loss {'Reaction outcome loss': 0.38585915379002655, 'Total loss': 0.38585915379002655}
2023-01-05 10:41:00,661 INFO:     Found new best model at epoch 29
2023-01-05 10:41:00,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:00,663 INFO:     Epoch: 30
2023-01-05 10:41:02,797 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38257606128851573, 'Total loss': 0.38257606128851573} | train loss {'Reaction outcome loss': 0.3814169502668623, 'Total loss': 0.3814169502668623}
2023-01-05 10:41:02,797 INFO:     Found new best model at epoch 30
2023-01-05 10:41:02,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:02,799 INFO:     Epoch: 31
2023-01-05 10:41:04,974 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4168181379636129, 'Total loss': 0.4168181379636129} | train loss {'Reaction outcome loss': 0.3767125292873496, 'Total loss': 0.3767125292873496}
2023-01-05 10:41:04,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:04,975 INFO:     Epoch: 32
2023-01-05 10:41:07,085 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4088612546523412, 'Total loss': 0.4088612546523412} | train loss {'Reaction outcome loss': 0.37815057213310205, 'Total loss': 0.37815057213310205}
2023-01-05 10:41:07,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:07,085 INFO:     Epoch: 33
2023-01-05 10:41:09,217 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3713722119728724, 'Total loss': 0.3713722119728724} | train loss {'Reaction outcome loss': 0.3696244977018431, 'Total loss': 0.3696244977018431}
2023-01-05 10:41:09,217 INFO:     Found new best model at epoch 33
2023-01-05 10:41:09,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:09,218 INFO:     Epoch: 34
2023-01-05 10:41:11,337 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39912617256244026, 'Total loss': 0.39912617256244026} | train loss {'Reaction outcome loss': 0.3710833918539456, 'Total loss': 0.3710833918539456}
2023-01-05 10:41:11,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:11,337 INFO:     Epoch: 35
2023-01-05 10:41:13,471 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4367360234260559, 'Total loss': 0.4367360234260559} | train loss {'Reaction outcome loss': 0.36263654472313117, 'Total loss': 0.36263654472313117}
2023-01-05 10:41:13,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:13,471 INFO:     Epoch: 36
2023-01-05 10:41:15,575 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4251803477605184, 'Total loss': 0.4251803477605184} | train loss {'Reaction outcome loss': 0.3626620790624208, 'Total loss': 0.3626620790624208}
2023-01-05 10:41:15,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:15,577 INFO:     Epoch: 37
2023-01-05 10:41:17,707 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42529690166314443, 'Total loss': 0.42529690166314443} | train loss {'Reaction outcome loss': 0.3564805004431907, 'Total loss': 0.3564805004431907}
2023-01-05 10:41:17,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:17,707 INFO:     Epoch: 38
2023-01-05 10:41:19,810 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43732276757558186, 'Total loss': 0.43732276757558186} | train loss {'Reaction outcome loss': 0.3731675418768672, 'Total loss': 0.3731675418768672}
2023-01-05 10:41:19,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:19,811 INFO:     Epoch: 39
2023-01-05 10:41:21,947 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4455084651708603, 'Total loss': 0.4455084651708603} | train loss {'Reaction outcome loss': 0.3696985278494548, 'Total loss': 0.3696985278494548}
2023-01-05 10:41:21,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:21,948 INFO:     Epoch: 40
2023-01-05 10:41:24,081 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41596890886624655, 'Total loss': 0.41596890886624655} | train loss {'Reaction outcome loss': 0.43142729392275214, 'Total loss': 0.43142729392275214}
2023-01-05 10:41:24,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:24,081 INFO:     Epoch: 41
2023-01-05 10:41:26,195 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4156869848569234, 'Total loss': 0.4156869848569234} | train loss {'Reaction outcome loss': 0.3572660447300776, 'Total loss': 0.3572660447300776}
2023-01-05 10:41:26,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:26,195 INFO:     Epoch: 42
2023-01-05 10:41:28,341 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3998743454615275, 'Total loss': 0.3998743454615275} | train loss {'Reaction outcome loss': 0.37285926599371666, 'Total loss': 0.37285926599371666}
2023-01-05 10:41:28,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:28,341 INFO:     Epoch: 43
2023-01-05 10:41:30,477 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39631079137325287, 'Total loss': 0.39631079137325287} | train loss {'Reaction outcome loss': 0.3505355929331584, 'Total loss': 0.3505355929331584}
2023-01-05 10:41:30,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:30,477 INFO:     Epoch: 44
2023-01-05 10:41:32,635 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38819210131963094, 'Total loss': 0.38819210131963094} | train loss {'Reaction outcome loss': 0.34637626794012805, 'Total loss': 0.34637626794012805}
2023-01-05 10:41:32,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:32,635 INFO:     Epoch: 45
2023-01-05 10:41:34,819 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3852090934912364, 'Total loss': 0.3852090934912364} | train loss {'Reaction outcome loss': 0.3437736748137336, 'Total loss': 0.3437736748137336}
2023-01-05 10:41:34,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:34,820 INFO:     Epoch: 46
2023-01-05 10:41:36,977 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40209774623314537, 'Total loss': 0.40209774623314537} | train loss {'Reaction outcome loss': 0.34716638691885315, 'Total loss': 0.34716638691885315}
2023-01-05 10:41:36,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:36,977 INFO:     Epoch: 47
2023-01-05 10:41:39,138 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3650381435950597, 'Total loss': 0.3650381435950597} | train loss {'Reaction outcome loss': 0.33461187196814496, 'Total loss': 0.33461187196814496}
2023-01-05 10:41:39,138 INFO:     Found new best model at epoch 47
2023-01-05 10:41:39,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:39,139 INFO:     Epoch: 48
2023-01-05 10:41:41,292 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39523619413375854, 'Total loss': 0.39523619413375854} | train loss {'Reaction outcome loss': 0.3313738878485679, 'Total loss': 0.3313738878485679}
2023-01-05 10:41:41,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:41,293 INFO:     Epoch: 49
2023-01-05 10:41:43,447 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38695845305919646, 'Total loss': 0.38695845305919646} | train loss {'Reaction outcome loss': 0.32690461473944393, 'Total loss': 0.32690461473944393}
2023-01-05 10:41:43,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:43,447 INFO:     Epoch: 50
2023-01-05 10:41:45,592 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42711663494507474, 'Total loss': 0.42711663494507474} | train loss {'Reaction outcome loss': 0.32199720511224755, 'Total loss': 0.32199720511224755}
2023-01-05 10:41:45,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:45,592 INFO:     Epoch: 51
2023-01-05 10:41:47,745 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39892658591270447, 'Total loss': 0.39892658591270447} | train loss {'Reaction outcome loss': 0.3219030889264051, 'Total loss': 0.3219030889264051}
2023-01-05 10:41:47,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:47,745 INFO:     Epoch: 52
2023-01-05 10:41:49,844 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38902579148610433, 'Total loss': 0.38902579148610433} | train loss {'Reaction outcome loss': 0.31974777016464784, 'Total loss': 0.31974777016464784}
2023-01-05 10:41:49,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:49,845 INFO:     Epoch: 53
2023-01-05 10:41:51,993 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36293282359838486, 'Total loss': 0.36293282359838486} | train loss {'Reaction outcome loss': 0.32249869635004713, 'Total loss': 0.32249869635004713}
2023-01-05 10:41:51,994 INFO:     Found new best model at epoch 53
2023-01-05 10:41:51,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:51,995 INFO:     Epoch: 54
2023-01-05 10:41:54,174 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3599181190133095, 'Total loss': 0.3599181190133095} | train loss {'Reaction outcome loss': 0.3557186472620663, 'Total loss': 0.3557186472620663}
2023-01-05 10:41:54,175 INFO:     Found new best model at epoch 54
2023-01-05 10:41:54,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:54,176 INFO:     Epoch: 55
2023-01-05 10:41:56,333 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35653935770193734, 'Total loss': 0.35653935770193734} | train loss {'Reaction outcome loss': 0.3168319952748815, 'Total loss': 0.3168319952748815}
2023-01-05 10:41:56,333 INFO:     Found new best model at epoch 55
2023-01-05 10:41:56,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:56,334 INFO:     Epoch: 56
2023-01-05 10:41:58,445 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3923055092493693, 'Total loss': 0.3923055092493693} | train loss {'Reaction outcome loss': 0.3141514987050407, 'Total loss': 0.3141514987050407}
2023-01-05 10:41:58,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:41:58,446 INFO:     Epoch: 57
2023-01-05 10:42:00,608 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3823963125546773, 'Total loss': 0.3823963125546773} | train loss {'Reaction outcome loss': 0.31192333435646485, 'Total loss': 0.31192333435646485}
2023-01-05 10:42:00,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:00,608 INFO:     Epoch: 58
2023-01-05 10:42:02,796 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3345337013403575, 'Total loss': 0.3345337013403575} | train loss {'Reaction outcome loss': 0.3066132137673381, 'Total loss': 0.3066132137673381}
2023-01-05 10:42:02,796 INFO:     Found new best model at epoch 58
2023-01-05 10:42:02,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:02,798 INFO:     Epoch: 59
2023-01-05 10:42:04,733 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3427374616265297, 'Total loss': 0.3427374616265297} | train loss {'Reaction outcome loss': 0.3067929591703907, 'Total loss': 0.3067929591703907}
2023-01-05 10:42:04,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:04,734 INFO:     Epoch: 60
2023-01-05 10:42:06,870 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3587742030620575, 'Total loss': 0.3587742030620575} | train loss {'Reaction outcome loss': 0.30423634290101303, 'Total loss': 0.30423634290101303}
2023-01-05 10:42:06,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:06,871 INFO:     Epoch: 61
2023-01-05 10:42:08,974 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3927847042679787, 'Total loss': 0.3927847042679787} | train loss {'Reaction outcome loss': 0.30055981616665056, 'Total loss': 0.30055981616665056}
2023-01-05 10:42:08,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:08,974 INFO:     Epoch: 62
2023-01-05 10:42:11,087 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3956825410326322, 'Total loss': 0.3956825410326322} | train loss {'Reaction outcome loss': 0.2977665681805445, 'Total loss': 0.2977665681805445}
2023-01-05 10:42:11,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:11,088 INFO:     Epoch: 63
2023-01-05 10:42:13,179 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35065504213174187, 'Total loss': 0.35065504213174187} | train loss {'Reaction outcome loss': 0.30223679524319974, 'Total loss': 0.30223679524319974}
2023-01-05 10:42:13,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:13,180 INFO:     Epoch: 64
2023-01-05 10:42:15,321 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41193827539682387, 'Total loss': 0.41193827539682387} | train loss {'Reaction outcome loss': 0.31290984945025413, 'Total loss': 0.31290984945025413}
2023-01-05 10:42:15,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:15,321 INFO:     Epoch: 65
2023-01-05 10:42:17,440 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3960114508867264, 'Total loss': 0.3960114508867264} | train loss {'Reaction outcome loss': 0.2931048754379963, 'Total loss': 0.2931048754379963}
2023-01-05 10:42:17,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:17,440 INFO:     Epoch: 66
2023-01-05 10:42:19,592 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3527530789375305, 'Total loss': 0.3527530789375305} | train loss {'Reaction outcome loss': 0.28923384230211674, 'Total loss': 0.28923384230211674}
2023-01-05 10:42:19,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:19,592 INFO:     Epoch: 67
2023-01-05 10:42:21,732 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3490395486354828, 'Total loss': 0.3490395486354828} | train loss {'Reaction outcome loss': 0.2886242098647399, 'Total loss': 0.2886242098647399}
2023-01-05 10:42:21,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:21,732 INFO:     Epoch: 68
2023-01-05 10:42:23,880 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3681610020498435, 'Total loss': 0.3681610020498435} | train loss {'Reaction outcome loss': 0.2898287283749306, 'Total loss': 0.2898287283749306}
2023-01-05 10:42:23,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:23,880 INFO:     Epoch: 69
2023-01-05 10:42:26,010 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36248978674411775, 'Total loss': 0.36248978674411775} | train loss {'Reaction outcome loss': 0.28676427126038767, 'Total loss': 0.28676427126038767}
2023-01-05 10:42:26,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:26,010 INFO:     Epoch: 70
2023-01-05 10:42:28,145 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.377544866502285, 'Total loss': 0.377544866502285} | train loss {'Reaction outcome loss': 0.28124188469940936, 'Total loss': 0.28124188469940936}
2023-01-05 10:42:28,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:28,146 INFO:     Epoch: 71
2023-01-05 10:42:30,296 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3643708328406016, 'Total loss': 0.3643708328406016} | train loss {'Reaction outcome loss': 0.2807760269826521, 'Total loss': 0.2807760269826521}
2023-01-05 10:42:30,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:30,296 INFO:     Epoch: 72
2023-01-05 10:42:32,429 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4196670194466909, 'Total loss': 0.4196670194466909} | train loss {'Reaction outcome loss': 0.2771610021458321, 'Total loss': 0.2771610021458321}
2023-01-05 10:42:32,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:32,429 INFO:     Epoch: 73
2023-01-05 10:42:34,583 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4005192091067632, 'Total loss': 0.4005192091067632} | train loss {'Reaction outcome loss': 0.27477253707753413, 'Total loss': 0.27477253707753413}
2023-01-05 10:42:34,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:34,584 INFO:     Epoch: 74
2023-01-05 10:42:36,721 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3805656711260478, 'Total loss': 0.3805656711260478} | train loss {'Reaction outcome loss': 0.27592712077835196, 'Total loss': 0.27592712077835196}
2023-01-05 10:42:36,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:36,721 INFO:     Epoch: 75
2023-01-05 10:42:38,862 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36852161784966786, 'Total loss': 0.36852161784966786} | train loss {'Reaction outcome loss': 0.27447895966263564, 'Total loss': 0.27447895966263564}
2023-01-05 10:42:38,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:38,862 INFO:     Epoch: 76
2023-01-05 10:42:40,990 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.33411417305469515, 'Total loss': 0.33411417305469515} | train loss {'Reaction outcome loss': 0.2736724037078101, 'Total loss': 0.2736724037078101}
2023-01-05 10:42:40,990 INFO:     Found new best model at epoch 76
2023-01-05 10:42:40,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:40,991 INFO:     Epoch: 77
2023-01-05 10:42:43,145 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35731781671444574, 'Total loss': 0.35731781671444574} | train loss {'Reaction outcome loss': 0.2930176663684888, 'Total loss': 0.2930176663684888}
2023-01-05 10:42:43,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:43,145 INFO:     Epoch: 78
2023-01-05 10:42:45,411 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3655998003979524, 'Total loss': 0.3655998003979524} | train loss {'Reaction outcome loss': 0.27439415242954873, 'Total loss': 0.27439415242954873}
2023-01-05 10:42:45,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:45,411 INFO:     Epoch: 79
2023-01-05 10:42:47,545 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3512783646583557, 'Total loss': 0.3512783646583557} | train loss {'Reaction outcome loss': 0.2687727110405567, 'Total loss': 0.2687727110405567}
2023-01-05 10:42:47,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:47,546 INFO:     Epoch: 80
2023-01-05 10:42:49,804 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3576982701818148, 'Total loss': 0.3576982701818148} | train loss {'Reaction outcome loss': 0.2591945985865702, 'Total loss': 0.2591945985865702}
2023-01-05 10:42:49,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:49,804 INFO:     Epoch: 81
2023-01-05 10:42:52,085 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3472724030415217, 'Total loss': 0.3472724030415217} | train loss {'Reaction outcome loss': 0.2743570000014227, 'Total loss': 0.2743570000014227}
2023-01-05 10:42:52,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:52,086 INFO:     Epoch: 82
2023-01-05 10:42:54,303 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3388100266456604, 'Total loss': 0.3388100266456604} | train loss {'Reaction outcome loss': 0.3198979467531477, 'Total loss': 0.3198979467531477}
2023-01-05 10:42:54,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:54,303 INFO:     Epoch: 83
2023-01-05 10:42:56,471 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37085433304309845, 'Total loss': 0.37085433304309845} | train loss {'Reaction outcome loss': 0.32775673320102744, 'Total loss': 0.32775673320102744}
2023-01-05 10:42:56,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:56,472 INFO:     Epoch: 84
2023-01-05 10:42:58,625 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3592021624247233, 'Total loss': 0.3592021624247233} | train loss {'Reaction outcome loss': 0.280814543015499, 'Total loss': 0.280814543015499}
2023-01-05 10:42:58,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:42:58,626 INFO:     Epoch: 85
2023-01-05 10:43:00,764 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38166963259379066, 'Total loss': 0.38166963259379066} | train loss {'Reaction outcome loss': 0.26375339386235597, 'Total loss': 0.26375339386235597}
2023-01-05 10:43:00,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:00,764 INFO:     Epoch: 86
2023-01-05 10:43:02,917 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3421449633936087, 'Total loss': 0.3421449633936087} | train loss {'Reaction outcome loss': 0.2664139643986372, 'Total loss': 0.2664139643986372}
2023-01-05 10:43:02,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:02,917 INFO:     Epoch: 87
2023-01-05 10:43:05,068 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3438558672865232, 'Total loss': 0.3438558672865232} | train loss {'Reaction outcome loss': 0.25611430731325946, 'Total loss': 0.25611430731325946}
2023-01-05 10:43:05,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:05,069 INFO:     Epoch: 88
2023-01-05 10:43:07,188 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37154902815818786, 'Total loss': 0.37154902815818786} | train loss {'Reaction outcome loss': 0.2522730897347345, 'Total loss': 0.2522730897347345}
2023-01-05 10:43:07,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:07,188 INFO:     Epoch: 89
2023-01-05 10:43:09,333 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4090463101863861, 'Total loss': 0.4090463101863861} | train loss {'Reaction outcome loss': 0.25788679435187817, 'Total loss': 0.25788679435187817}
2023-01-05 10:43:09,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:09,334 INFO:     Epoch: 90
2023-01-05 10:43:11,487 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.34842708309491477, 'Total loss': 0.34842708309491477} | train loss {'Reaction outcome loss': 0.2523306621275707, 'Total loss': 0.2523306621275707}
2023-01-05 10:43:11,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:11,488 INFO:     Epoch: 91
2023-01-05 10:43:13,631 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3330786238114039, 'Total loss': 0.3330786238114039} | train loss {'Reaction outcome loss': 0.256076716488072, 'Total loss': 0.256076716488072}
2023-01-05 10:43:13,631 INFO:     Found new best model at epoch 91
2023-01-05 10:43:13,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:13,632 INFO:     Epoch: 92
2023-01-05 10:43:15,737 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.34423415263493856, 'Total loss': 0.34423415263493856} | train loss {'Reaction outcome loss': 0.2502074907651927, 'Total loss': 0.2502074907651927}
2023-01-05 10:43:15,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:15,737 INFO:     Epoch: 93
2023-01-05 10:43:17,893 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3396120801568031, 'Total loss': 0.3396120801568031} | train loss {'Reaction outcome loss': 0.2487787654607783, 'Total loss': 0.2487787654607783}
2023-01-05 10:43:17,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:17,893 INFO:     Epoch: 94
2023-01-05 10:43:20,010 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3532725324233373, 'Total loss': 0.3532725324233373} | train loss {'Reaction outcome loss': 0.2518235278768006, 'Total loss': 0.2518235278768006}
2023-01-05 10:43:20,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:20,011 INFO:     Epoch: 95
2023-01-05 10:43:22,175 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3664171814918518, 'Total loss': 0.3664171814918518} | train loss {'Reaction outcome loss': 0.2466885251013319, 'Total loss': 0.2466885251013319}
2023-01-05 10:43:22,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:22,175 INFO:     Epoch: 96
2023-01-05 10:43:24,309 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37337112724781035, 'Total loss': 0.37337112724781035} | train loss {'Reaction outcome loss': 0.2513873784956967, 'Total loss': 0.2513873784956967}
2023-01-05 10:43:24,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:24,310 INFO:     Epoch: 97
2023-01-05 10:43:26,438 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.33533523976802826, 'Total loss': 0.33533523976802826} | train loss {'Reaction outcome loss': 0.24553653892497465, 'Total loss': 0.24553653892497465}
2023-01-05 10:43:26,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:26,439 INFO:     Epoch: 98
2023-01-05 10:43:28,578 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3286764532327652, 'Total loss': 0.3286764532327652} | train loss {'Reaction outcome loss': 0.2414833509204639, 'Total loss': 0.2414833509204639}
2023-01-05 10:43:28,578 INFO:     Found new best model at epoch 98
2023-01-05 10:43:28,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:28,580 INFO:     Epoch: 99
2023-01-05 10:43:30,718 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.32869368568062785, 'Total loss': 0.32869368568062785} | train loss {'Reaction outcome loss': 0.24203276060575593, 'Total loss': 0.24203276060575593}
2023-01-05 10:43:30,718 INFO:     Best model found after epoch 99 of 100.
2023-01-05 10:43:30,719 INFO:   Done with stage: TRAINING
2023-01-05 10:43:30,719 INFO:   Starting stage: EVALUATION
2023-01-05 10:43:30,854 INFO:   Done with stage: EVALUATION
2023-01-05 10:43:30,854 INFO:   Leaving out SEQ value Fold_1
2023-01-05 10:43:30,867 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 10:43:30,867 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:43:31,515 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:43:31,516 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:43:31,585 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:43:31,585 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:43:31,585 INFO:     No hyperparam tuning for this model
2023-01-05 10:43:31,585 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:43:31,585 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:43:31,586 INFO:     None feature selector for col prot
2023-01-05 10:43:31,586 INFO:     None feature selector for col prot
2023-01-05 10:43:31,586 INFO:     None feature selector for col prot
2023-01-05 10:43:31,587 INFO:     None feature selector for col chem
2023-01-05 10:43:31,587 INFO:     None feature selector for col chem
2023-01-05 10:43:31,587 INFO:     None feature selector for col chem
2023-01-05 10:43:31,587 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:43:31,587 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:43:31,589 INFO:     Number of params in model 72901
2023-01-05 10:43:31,592 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:43:31,592 INFO:   Starting stage: TRAINING
2023-01-05 10:43:31,652 INFO:     Val loss before train {'Reaction outcome loss': 1.0185155193010966, 'Total loss': 1.0185155193010966}
2023-01-05 10:43:31,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:31,652 INFO:     Epoch: 0
2023-01-05 10:43:33,803 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8356821258862813, 'Total loss': 0.8356821258862813} | train loss {'Reaction outcome loss': 0.9158949070184937, 'Total loss': 0.9158949070184937}
2023-01-05 10:43:33,803 INFO:     Found new best model at epoch 0
2023-01-05 10:43:33,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:33,804 INFO:     Epoch: 1
2023-01-05 10:43:35,949 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6203125357627869, 'Total loss': 0.6203125357627869} | train loss {'Reaction outcome loss': 0.7253235950992203, 'Total loss': 0.7253235950992203}
2023-01-05 10:43:35,949 INFO:     Found new best model at epoch 1
2023-01-05 10:43:35,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:35,950 INFO:     Epoch: 2
2023-01-05 10:43:38,099 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5055285612742106, 'Total loss': 0.5055285612742106} | train loss {'Reaction outcome loss': 0.5893397903916817, 'Total loss': 0.5893397903916817}
2023-01-05 10:43:38,099 INFO:     Found new best model at epoch 2
2023-01-05 10:43:38,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:38,101 INFO:     Epoch: 3
2023-01-05 10:43:40,253 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5356397747993469, 'Total loss': 0.5356397747993469} | train loss {'Reaction outcome loss': 0.535659362046146, 'Total loss': 0.535659362046146}
2023-01-05 10:43:40,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:40,254 INFO:     Epoch: 4
2023-01-05 10:43:42,390 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5216893374919891, 'Total loss': 0.5216893374919891} | train loss {'Reaction outcome loss': 0.5215838085218886, 'Total loss': 0.5215838085218886}
2023-01-05 10:43:42,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:42,391 INFO:     Epoch: 5
2023-01-05 10:43:44,603 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.519622411330541, 'Total loss': 0.519622411330541} | train loss {'Reaction outcome loss': 0.5111241910768591, 'Total loss': 0.5111241910768591}
2023-01-05 10:43:44,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:44,603 INFO:     Epoch: 6
2023-01-05 10:43:46,827 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49565325180689496, 'Total loss': 0.49565325180689496} | train loss {'Reaction outcome loss': 0.5353663775098064, 'Total loss': 0.5353663775098064}
2023-01-05 10:43:46,828 INFO:     Found new best model at epoch 6
2023-01-05 10:43:46,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:46,830 INFO:     Epoch: 7
2023-01-05 10:43:49,046 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4547960817813873, 'Total loss': 0.4547960817813873} | train loss {'Reaction outcome loss': 0.4907929573552489, 'Total loss': 0.4907929573552489}
2023-01-05 10:43:49,046 INFO:     Found new best model at epoch 7
2023-01-05 10:43:49,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:49,047 INFO:     Epoch: 8
2023-01-05 10:43:51,235 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4860694706439972, 'Total loss': 0.4860694706439972} | train loss {'Reaction outcome loss': 0.4808539578292951, 'Total loss': 0.4808539578292951}
2023-01-05 10:43:51,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:51,235 INFO:     Epoch: 9
2023-01-05 10:43:53,447 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4660336673259735, 'Total loss': 0.4660336673259735} | train loss {'Reaction outcome loss': 0.47777640787155734, 'Total loss': 0.47777640787155734}
2023-01-05 10:43:53,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:53,448 INFO:     Epoch: 10
2023-01-05 10:43:55,665 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48109379212061565, 'Total loss': 0.48109379212061565} | train loss {'Reaction outcome loss': 0.48441858789411146, 'Total loss': 0.48441858789411146}
2023-01-05 10:43:55,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:55,666 INFO:     Epoch: 11
2023-01-05 10:43:57,896 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47193716367085775, 'Total loss': 0.47193716367085775} | train loss {'Reaction outcome loss': 0.48445946908812376, 'Total loss': 0.48445946908812376}
2023-01-05 10:43:57,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:43:57,896 INFO:     Epoch: 12
2023-01-05 10:44:00,063 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46490272879600525, 'Total loss': 0.46490272879600525} | train loss {'Reaction outcome loss': 0.4729686999572036, 'Total loss': 0.4729686999572036}
2023-01-05 10:44:00,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:00,064 INFO:     Epoch: 13
2023-01-05 10:44:02,167 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.457114440202713, 'Total loss': 0.457114440202713} | train loss {'Reaction outcome loss': 0.4541057519128789, 'Total loss': 0.4541057519128789}
2023-01-05 10:44:02,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:02,168 INFO:     Epoch: 14
2023-01-05 10:44:04,288 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44406300187110903, 'Total loss': 0.44406300187110903} | train loss {'Reaction outcome loss': 0.447753042070384, 'Total loss': 0.447753042070384}
2023-01-05 10:44:04,288 INFO:     Found new best model at epoch 14
2023-01-05 10:44:04,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:04,289 INFO:     Epoch: 15
2023-01-05 10:44:06,438 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4822968622048696, 'Total loss': 0.4822968622048696} | train loss {'Reaction outcome loss': 0.44874650097546587, 'Total loss': 0.44874650097546587}
2023-01-05 10:44:06,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:06,438 INFO:     Epoch: 16
2023-01-05 10:44:08,578 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45417831738789877, 'Total loss': 0.45417831738789877} | train loss {'Reaction outcome loss': 0.44184458887784916, 'Total loss': 0.44184458887784916}
2023-01-05 10:44:08,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:08,579 INFO:     Epoch: 17
2023-01-05 10:44:10,701 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44075523217519125, 'Total loss': 0.44075523217519125} | train loss {'Reaction outcome loss': 0.4405603242525156, 'Total loss': 0.4405603242525156}
2023-01-05 10:44:10,703 INFO:     Found new best model at epoch 17
2023-01-05 10:44:10,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:10,704 INFO:     Epoch: 18
2023-01-05 10:44:12,849 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46881723006566367, 'Total loss': 0.46881723006566367} | train loss {'Reaction outcome loss': 0.43693386574454635, 'Total loss': 0.43693386574454635}
2023-01-05 10:44:12,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:12,849 INFO:     Epoch: 19
2023-01-05 10:44:14,949 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4448638916015625, 'Total loss': 0.4448638916015625} | train loss {'Reaction outcome loss': 0.432619611442467, 'Total loss': 0.432619611442467}
2023-01-05 10:44:14,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:14,949 INFO:     Epoch: 20
2023-01-05 10:44:17,065 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45119458536307017, 'Total loss': 0.45119458536307017} | train loss {'Reaction outcome loss': 0.42494803631300293, 'Total loss': 0.42494803631300293}
2023-01-05 10:44:17,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:17,066 INFO:     Epoch: 21
2023-01-05 10:44:19,222 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4818268577257792, 'Total loss': 0.4818268577257792} | train loss {'Reaction outcome loss': 0.424874099565373, 'Total loss': 0.424874099565373}
2023-01-05 10:44:19,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:19,223 INFO:     Epoch: 22
2023-01-05 10:44:21,383 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46542327404022216, 'Total loss': 0.46542327404022216} | train loss {'Reaction outcome loss': 0.4224754273262975, 'Total loss': 0.4224754273262975}
2023-01-05 10:44:21,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:21,383 INFO:     Epoch: 23
2023-01-05 10:44:23,519 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4614683886369069, 'Total loss': 0.4614683886369069} | train loss {'Reaction outcome loss': 0.4176217031619286, 'Total loss': 0.4176217031619286}
2023-01-05 10:44:23,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:23,520 INFO:     Epoch: 24
2023-01-05 10:44:25,660 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45398370226224266, 'Total loss': 0.45398370226224266} | train loss {'Reaction outcome loss': 0.41092433693204616, 'Total loss': 0.41092433693204616}
2023-01-05 10:44:25,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:25,660 INFO:     Epoch: 25
2023-01-05 10:44:27,806 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.421785627802213, 'Total loss': 0.421785627802213} | train loss {'Reaction outcome loss': 0.4072827935974667, 'Total loss': 0.4072827935974667}
2023-01-05 10:44:27,806 INFO:     Found new best model at epoch 25
2023-01-05 10:44:27,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:27,807 INFO:     Epoch: 26
2023-01-05 10:44:29,918 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43115668892860415, 'Total loss': 0.43115668892860415} | train loss {'Reaction outcome loss': 0.4056573169081526, 'Total loss': 0.4056573169081526}
2023-01-05 10:44:29,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:29,919 INFO:     Epoch: 27
2023-01-05 10:44:32,055 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4143043766419093, 'Total loss': 0.4143043766419093} | train loss {'Reaction outcome loss': 0.4012107430760912, 'Total loss': 0.4012107430760912}
2023-01-05 10:44:32,056 INFO:     Found new best model at epoch 27
2023-01-05 10:44:32,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:32,057 INFO:     Epoch: 28
2023-01-05 10:44:34,209 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4184979816277822, 'Total loss': 0.4184979816277822} | train loss {'Reaction outcome loss': 0.3972591871287728, 'Total loss': 0.3972591871287728}
2023-01-05 10:44:34,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:34,209 INFO:     Epoch: 29
2023-01-05 10:44:36,351 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42972215910752615, 'Total loss': 0.42972215910752615} | train loss {'Reaction outcome loss': 0.40125611413648166, 'Total loss': 0.40125611413648166}
2023-01-05 10:44:36,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:36,351 INFO:     Epoch: 30
2023-01-05 10:44:38,506 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4068311055501302, 'Total loss': 0.4068311055501302} | train loss {'Reaction outcome loss': 0.4550615515327081, 'Total loss': 0.4550615515327081}
2023-01-05 10:44:38,506 INFO:     Found new best model at epoch 30
2023-01-05 10:44:38,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:38,507 INFO:     Epoch: 31
2023-01-05 10:44:40,651 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4160948048035304, 'Total loss': 0.4160948048035304} | train loss {'Reaction outcome loss': 0.3976660368397184, 'Total loss': 0.3976660368397184}
2023-01-05 10:44:40,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:40,651 INFO:     Epoch: 32
2023-01-05 10:44:42,807 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4030729830265045, 'Total loss': 0.4030729830265045} | train loss {'Reaction outcome loss': 0.40584595474428026, 'Total loss': 0.40584595474428026}
2023-01-05 10:44:42,807 INFO:     Found new best model at epoch 32
2023-01-05 10:44:42,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:42,809 INFO:     Epoch: 33
2023-01-05 10:44:44,953 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4218839704990387, 'Total loss': 0.4218839704990387} | train loss {'Reaction outcome loss': 0.38083586207442527, 'Total loss': 0.38083586207442527}
2023-01-05 10:44:44,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:44,953 INFO:     Epoch: 34
2023-01-05 10:44:47,072 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43638867934544884, 'Total loss': 0.43638867934544884} | train loss {'Reaction outcome loss': 0.3810883439677443, 'Total loss': 0.3810883439677443}
2023-01-05 10:44:47,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:47,073 INFO:     Epoch: 35
2023-01-05 10:44:49,203 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4034342795610428, 'Total loss': 0.4034342795610428} | train loss {'Reaction outcome loss': 0.3702398743132991, 'Total loss': 0.3702398743132991}
2023-01-05 10:44:49,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:49,203 INFO:     Epoch: 36
2023-01-05 10:44:51,316 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42014105680088204, 'Total loss': 0.42014105680088204} | train loss {'Reaction outcome loss': 0.3695689035626803, 'Total loss': 0.3695689035626803}
2023-01-05 10:44:51,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:51,317 INFO:     Epoch: 37
2023-01-05 10:44:53,475 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4162357529004415, 'Total loss': 0.4162357529004415} | train loss {'Reaction outcome loss': 0.3638087447354759, 'Total loss': 0.3638087447354759}
2023-01-05 10:44:53,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:53,476 INFO:     Epoch: 38
2023-01-05 10:44:55,633 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3942966401576996, 'Total loss': 0.3942966401576996} | train loss {'Reaction outcome loss': 0.3624525157101216, 'Total loss': 0.3624525157101216}
2023-01-05 10:44:55,633 INFO:     Found new best model at epoch 38
2023-01-05 10:44:55,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:55,634 INFO:     Epoch: 39
2023-01-05 10:44:57,741 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40462182760238646, 'Total loss': 0.40462182760238646} | train loss {'Reaction outcome loss': 0.36128161632813566, 'Total loss': 0.36128161632813566}
2023-01-05 10:44:57,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:57,741 INFO:     Epoch: 40
2023-01-05 10:44:59,910 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4320236434539159, 'Total loss': 0.4320236434539159} | train loss {'Reaction outcome loss': 0.3556732255242093, 'Total loss': 0.3556732255242093}
2023-01-05 10:44:59,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:44:59,910 INFO:     Epoch: 41
2023-01-05 10:45:02,069 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39388446807861327, 'Total loss': 0.39388446807861327} | train loss {'Reaction outcome loss': 0.35337274895995296, 'Total loss': 0.35337274895995296}
2023-01-05 10:45:02,069 INFO:     Found new best model at epoch 41
2023-01-05 10:45:02,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:02,070 INFO:     Epoch: 42
2023-01-05 10:45:04,228 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40230561594168346, 'Total loss': 0.40230561594168346} | train loss {'Reaction outcome loss': 0.3486394325667314, 'Total loss': 0.3486394325667314}
2023-01-05 10:45:04,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:04,228 INFO:     Epoch: 43
2023-01-05 10:45:06,379 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36399176021416985, 'Total loss': 0.36399176021416985} | train loss {'Reaction outcome loss': 0.3481623340344083, 'Total loss': 0.3481623340344083}
2023-01-05 10:45:06,380 INFO:     Found new best model at epoch 43
2023-01-05 10:45:06,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:06,381 INFO:     Epoch: 44
2023-01-05 10:45:08,554 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3958418250083923, 'Total loss': 0.3958418250083923} | train loss {'Reaction outcome loss': 0.3402212436143916, 'Total loss': 0.3402212436143916}
2023-01-05 10:45:08,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:08,554 INFO:     Epoch: 45
2023-01-05 10:45:10,701 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4155322551727295, 'Total loss': 0.4155322551727295} | train loss {'Reaction outcome loss': 0.3392821439471015, 'Total loss': 0.3392821439471015}
2023-01-05 10:45:10,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:10,702 INFO:     Epoch: 46
2023-01-05 10:45:12,868 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4099367747704188, 'Total loss': 0.4099367747704188} | train loss {'Reaction outcome loss': 0.3342295248142403, 'Total loss': 0.3342295248142403}
2023-01-05 10:45:12,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:12,868 INFO:     Epoch: 47
2023-01-05 10:45:14,987 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41632432540257774, 'Total loss': 0.41632432540257774} | train loss {'Reaction outcome loss': 0.3310321240038004, 'Total loss': 0.3310321240038004}
2023-01-05 10:45:14,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:14,987 INFO:     Epoch: 48
2023-01-05 10:45:17,141 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42717039386431377, 'Total loss': 0.42717039386431377} | train loss {'Reaction outcome loss': 0.3265949276856322, 'Total loss': 0.3265949276856322}
2023-01-05 10:45:17,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:17,142 INFO:     Epoch: 49
2023-01-05 10:45:19,302 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4079591582218806, 'Total loss': 0.4079591582218806} | train loss {'Reaction outcome loss': 0.3359789531451774, 'Total loss': 0.3359789531451774}
2023-01-05 10:45:19,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:19,303 INFO:     Epoch: 50
2023-01-05 10:45:21,442 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3990589827299118, 'Total loss': 0.3990589827299118} | train loss {'Reaction outcome loss': 0.3135842151633646, 'Total loss': 0.3135842151633646}
2023-01-05 10:45:21,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:21,443 INFO:     Epoch: 51
2023-01-05 10:45:23,605 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34625495274861656, 'Total loss': 0.34625495274861656} | train loss {'Reaction outcome loss': 0.3250339732157188, 'Total loss': 0.3250339732157188}
2023-01-05 10:45:23,606 INFO:     Found new best model at epoch 51
2023-01-05 10:45:23,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:23,607 INFO:     Epoch: 52
2023-01-05 10:45:25,766 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41790047387282053, 'Total loss': 0.41790047387282053} | train loss {'Reaction outcome loss': 0.31631786888296565, 'Total loss': 0.31631786888296565}
2023-01-05 10:45:25,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:25,767 INFO:     Epoch: 53
2023-01-05 10:45:27,896 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38972560067971546, 'Total loss': 0.38972560067971546} | train loss {'Reaction outcome loss': 0.3135370968510329, 'Total loss': 0.3135370968510329}
2023-01-05 10:45:27,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:27,896 INFO:     Epoch: 54
2023-01-05 10:45:30,043 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39546286364396416, 'Total loss': 0.39546286364396416} | train loss {'Reaction outcome loss': 0.3111738381448431, 'Total loss': 0.3111738381448431}
2023-01-05 10:45:30,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:30,043 INFO:     Epoch: 55
2023-01-05 10:45:32,205 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42275850574175516, 'Total loss': 0.42275850574175516} | train loss {'Reaction outcome loss': 0.30802696486226405, 'Total loss': 0.30802696486226405}
2023-01-05 10:45:32,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:32,205 INFO:     Epoch: 56
2023-01-05 10:45:34,343 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36250571260849634, 'Total loss': 0.36250571260849634} | train loss {'Reaction outcome loss': 0.3031679428506481, 'Total loss': 0.3031679428506481}
2023-01-05 10:45:34,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:34,343 INFO:     Epoch: 57
2023-01-05 10:45:36,486 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3706556210915248, 'Total loss': 0.3706556210915248} | train loss {'Reaction outcome loss': 0.30800896322867577, 'Total loss': 0.30800896322867577}
2023-01-05 10:45:36,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:36,486 INFO:     Epoch: 58
2023-01-05 10:45:38,633 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38355987071990966, 'Total loss': 0.38355987071990966} | train loss {'Reaction outcome loss': 0.3020196328398542, 'Total loss': 0.3020196328398542}
2023-01-05 10:45:38,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:38,634 INFO:     Epoch: 59
2023-01-05 10:45:40,791 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37309262752532957, 'Total loss': 0.37309262752532957} | train loss {'Reaction outcome loss': 0.2959583210741993, 'Total loss': 0.2959583210741993}
2023-01-05 10:45:40,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:40,791 INFO:     Epoch: 60
2023-01-05 10:45:42,957 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41851499676704407, 'Total loss': 0.41851499676704407} | train loss {'Reaction outcome loss': 0.3024014990668798, 'Total loss': 0.3024014990668798}
2023-01-05 10:45:42,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:42,957 INFO:     Epoch: 61
2023-01-05 10:45:45,095 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42593724131584165, 'Total loss': 0.42593724131584165} | train loss {'Reaction outcome loss': 0.3096459156604133, 'Total loss': 0.3096459156604133}
2023-01-05 10:45:45,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:45,096 INFO:     Epoch: 62
2023-01-05 10:45:47,263 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36754176716009773, 'Total loss': 0.36754176716009773} | train loss {'Reaction outcome loss': 0.29604108533521206, 'Total loss': 0.29604108533521206}
2023-01-05 10:45:47,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:47,263 INFO:     Epoch: 63
2023-01-05 10:45:49,393 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3769765357176463, 'Total loss': 0.3769765357176463} | train loss {'Reaction outcome loss': 0.29451724462424483, 'Total loss': 0.29451724462424483}
2023-01-05 10:45:49,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:49,393 INFO:     Epoch: 64
2023-01-05 10:45:51,568 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40420306523640953, 'Total loss': 0.40420306523640953} | train loss {'Reaction outcome loss': 0.28910150591864425, 'Total loss': 0.28910150591864425}
2023-01-05 10:45:51,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:51,568 INFO:     Epoch: 65
2023-01-05 10:45:53,694 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3928995509942373, 'Total loss': 0.3928995509942373} | train loss {'Reaction outcome loss': 0.29360577160411555, 'Total loss': 0.29360577160411555}
2023-01-05 10:45:53,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:53,695 INFO:     Epoch: 66
2023-01-05 10:45:55,830 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.34974010090033214, 'Total loss': 0.34974010090033214} | train loss {'Reaction outcome loss': 0.34514163460150576, 'Total loss': 0.34514163460150576}
2023-01-05 10:45:55,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:55,830 INFO:     Epoch: 67
2023-01-05 10:45:57,945 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4082482943932215, 'Total loss': 0.4082482943932215} | train loss {'Reaction outcome loss': 0.33940622943581716, 'Total loss': 0.33940622943581716}
2023-01-05 10:45:57,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:45:57,945 INFO:     Epoch: 68
2023-01-05 10:46:00,066 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37325301617383955, 'Total loss': 0.37325301617383955} | train loss {'Reaction outcome loss': 0.2962799753818283, 'Total loss': 0.2962799753818283}
2023-01-05 10:46:00,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:00,067 INFO:     Epoch: 69
2023-01-05 10:46:02,186 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36685696641604104, 'Total loss': 0.36685696641604104} | train loss {'Reaction outcome loss': 0.2913428020346347, 'Total loss': 0.2913428020346347}
2023-01-05 10:46:02,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:02,187 INFO:     Epoch: 70
2023-01-05 10:46:04,312 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3841479142506917, 'Total loss': 0.3841479142506917} | train loss {'Reaction outcome loss': 0.28545419833012536, 'Total loss': 0.28545419833012536}
2023-01-05 10:46:04,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:04,313 INFO:     Epoch: 71
2023-01-05 10:46:06,259 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3503975376486778, 'Total loss': 0.3503975376486778} | train loss {'Reaction outcome loss': 0.2952208766457287, 'Total loss': 0.2952208766457287}
2023-01-05 10:46:06,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:06,259 INFO:     Epoch: 72
2023-01-05 10:46:08,383 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35208431382973987, 'Total loss': 0.35208431382973987} | train loss {'Reaction outcome loss': 0.3140653980164142, 'Total loss': 0.3140653980164142}
2023-01-05 10:46:08,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:08,383 INFO:     Epoch: 73
2023-01-05 10:46:10,516 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36384682804346086, 'Total loss': 0.36384682804346086} | train loss {'Reaction outcome loss': 0.2831123545449531, 'Total loss': 0.2831123545449531}
2023-01-05 10:46:10,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:10,516 INFO:     Epoch: 74
2023-01-05 10:46:12,658 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3909814367691676, 'Total loss': 0.3909814367691676} | train loss {'Reaction outcome loss': 0.2757048782621733, 'Total loss': 0.2757048782621733}
2023-01-05 10:46:12,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:12,659 INFO:     Epoch: 75
2023-01-05 10:46:14,808 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35310501729448635, 'Total loss': 0.35310501729448635} | train loss {'Reaction outcome loss': 0.2822869238106237, 'Total loss': 0.2822869238106237}
2023-01-05 10:46:14,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:14,808 INFO:     Epoch: 76
2023-01-05 10:46:16,971 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3808971544106801, 'Total loss': 0.3808971544106801} | train loss {'Reaction outcome loss': 0.276358431031585, 'Total loss': 0.276358431031585}
2023-01-05 10:46:16,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:16,972 INFO:     Epoch: 77
2023-01-05 10:46:19,125 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39124624331792196, 'Total loss': 0.39124624331792196} | train loss {'Reaction outcome loss': 0.2729214624758216, 'Total loss': 0.2729214624758216}
2023-01-05 10:46:19,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:19,126 INFO:     Epoch: 78
2023-01-05 10:46:21,266 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38792693614959717, 'Total loss': 0.38792693614959717} | train loss {'Reaction outcome loss': 0.2995808201342605, 'Total loss': 0.2995808201342605}
2023-01-05 10:46:21,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:21,267 INFO:     Epoch: 79
2023-01-05 10:46:23,402 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3534441818793615, 'Total loss': 0.3534441818793615} | train loss {'Reaction outcome loss': 0.2902660336450039, 'Total loss': 0.2902660336450039}
2023-01-05 10:46:23,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:23,404 INFO:     Epoch: 80
2023-01-05 10:46:25,558 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36862392152349155, 'Total loss': 0.36862392152349155} | train loss {'Reaction outcome loss': 0.26938937733623036, 'Total loss': 0.26938937733623036}
2023-01-05 10:46:25,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:25,558 INFO:     Epoch: 81
2023-01-05 10:46:27,687 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44072099328041076, 'Total loss': 0.44072099328041076} | train loss {'Reaction outcome loss': 0.26972692092438566, 'Total loss': 0.26972692092438566}
2023-01-05 10:46:27,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:27,688 INFO:     Epoch: 82
2023-01-05 10:46:29,789 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3946276972691218, 'Total loss': 0.3946276972691218} | train loss {'Reaction outcome loss': 0.2748410873924065, 'Total loss': 0.2748410873924065}
2023-01-05 10:46:29,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:29,790 INFO:     Epoch: 83
2023-01-05 10:46:31,906 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38212226927280424, 'Total loss': 0.38212226927280424} | train loss {'Reaction outcome loss': 0.2725810667698565, 'Total loss': 0.2725810667698565}
2023-01-05 10:46:31,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:31,906 INFO:     Epoch: 84
2023-01-05 10:46:34,015 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3759297226866086, 'Total loss': 0.3759297226866086} | train loss {'Reaction outcome loss': 0.2715065926110939, 'Total loss': 0.2715065926110939}
2023-01-05 10:46:34,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:34,015 INFO:     Epoch: 85
2023-01-05 10:46:36,136 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3899318302671115, 'Total loss': 0.3899318302671115} | train loss {'Reaction outcome loss': 0.2615076020002311, 'Total loss': 0.2615076020002311}
2023-01-05 10:46:36,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:36,137 INFO:     Epoch: 86
2023-01-05 10:46:38,266 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38340417643388114, 'Total loss': 0.38340417643388114} | train loss {'Reaction outcome loss': 0.2661561173508349, 'Total loss': 0.2661561173508349}
2023-01-05 10:46:38,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:38,267 INFO:     Epoch: 87
2023-01-05 10:46:40,381 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42767007102568944, 'Total loss': 0.42767007102568944} | train loss {'Reaction outcome loss': 0.2674603054428176, 'Total loss': 0.2674603054428176}
2023-01-05 10:46:40,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:40,381 INFO:     Epoch: 88
2023-01-05 10:46:42,497 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39670151670773823, 'Total loss': 0.39670151670773823} | train loss {'Reaction outcome loss': 0.2710199869798616, 'Total loss': 0.2710199869798616}
2023-01-05 10:46:42,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:42,498 INFO:     Epoch: 89
2023-01-05 10:46:44,632 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35367141862710316, 'Total loss': 0.35367141862710316} | train loss {'Reaction outcome loss': 0.26772047659429465, 'Total loss': 0.26772047659429465}
2023-01-05 10:46:44,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:44,633 INFO:     Epoch: 90
2023-01-05 10:46:46,737 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38566281149784726, 'Total loss': 0.38566281149784726} | train loss {'Reaction outcome loss': 0.2585007448181294, 'Total loss': 0.2585007448181294}
2023-01-05 10:46:46,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:46,738 INFO:     Epoch: 91
2023-01-05 10:46:48,859 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3627529184023539, 'Total loss': 0.3627529184023539} | train loss {'Reaction outcome loss': 0.2527665547432675, 'Total loss': 0.2527665547432675}
2023-01-05 10:46:48,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:48,860 INFO:     Epoch: 92
2023-01-05 10:46:50,995 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3955691317717234, 'Total loss': 0.3955691317717234} | train loss {'Reaction outcome loss': 0.2602448500490383, 'Total loss': 0.2602448500490383}
2023-01-05 10:46:50,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:50,995 INFO:     Epoch: 93
2023-01-05 10:46:53,126 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37690087656180066, 'Total loss': 0.37690087656180066} | train loss {'Reaction outcome loss': 0.2531053990271597, 'Total loss': 0.2531053990271597}
2023-01-05 10:46:53,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:53,126 INFO:     Epoch: 94
2023-01-05 10:46:55,239 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3882394323746363, 'Total loss': 0.3882394323746363} | train loss {'Reaction outcome loss': 0.25696940220360126, 'Total loss': 0.25696940220360126}
2023-01-05 10:46:55,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:55,239 INFO:     Epoch: 95
2023-01-05 10:46:57,380 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39193199574947357, 'Total loss': 0.39193199574947357} | train loss {'Reaction outcome loss': 0.26175925467311795, 'Total loss': 0.26175925467311795}
2023-01-05 10:46:57,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:57,381 INFO:     Epoch: 96
2023-01-05 10:46:59,512 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41028988460699717, 'Total loss': 0.41028988460699717} | train loss {'Reaction outcome loss': 0.25175685966235545, 'Total loss': 0.25175685966235545}
2023-01-05 10:46:59,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:46:59,513 INFO:     Epoch: 97
2023-01-05 10:47:01,649 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37051577071348823, 'Total loss': 0.37051577071348823} | train loss {'Reaction outcome loss': 0.24679657858982007, 'Total loss': 0.24679657858982007}
2023-01-05 10:47:01,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:01,650 INFO:     Epoch: 98
2023-01-05 10:47:03,784 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4175986349582672, 'Total loss': 0.4175986349582672} | train loss {'Reaction outcome loss': 0.2480516025241451, 'Total loss': 0.2480516025241451}
2023-01-05 10:47:03,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:03,784 INFO:     Epoch: 99
2023-01-05 10:47:05,943 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41006095012029015, 'Total loss': 0.41006095012029015} | train loss {'Reaction outcome loss': 0.25260157745662215, 'Total loss': 0.25260157745662215}
2023-01-05 10:47:05,944 INFO:     Best model found after epoch 52 of 100.
2023-01-05 10:47:05,944 INFO:   Done with stage: TRAINING
2023-01-05 10:47:05,944 INFO:   Starting stage: EVALUATION
2023-01-05 10:47:06,076 INFO:   Done with stage: EVALUATION
2023-01-05 10:47:06,076 INFO:   Leaving out SEQ value Fold_2
2023-01-05 10:47:06,088 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 10:47:06,089 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:47:06,734 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:47:06,734 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:47:06,802 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:47:06,802 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:47:06,802 INFO:     No hyperparam tuning for this model
2023-01-05 10:47:06,802 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:47:06,802 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:47:06,803 INFO:     None feature selector for col prot
2023-01-05 10:47:06,803 INFO:     None feature selector for col prot
2023-01-05 10:47:06,803 INFO:     None feature selector for col prot
2023-01-05 10:47:06,803 INFO:     None feature selector for col chem
2023-01-05 10:47:06,803 INFO:     None feature selector for col chem
2023-01-05 10:47:06,804 INFO:     None feature selector for col chem
2023-01-05 10:47:06,804 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:47:06,804 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:47:06,805 INFO:     Number of params in model 72901
2023-01-05 10:47:06,808 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:47:06,808 INFO:   Starting stage: TRAINING
2023-01-05 10:47:06,867 INFO:     Val loss before train {'Reaction outcome loss': 1.0455521066983542, 'Total loss': 1.0455521066983542}
2023-01-05 10:47:06,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:06,868 INFO:     Epoch: 0
2023-01-05 10:47:08,997 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8838096459706625, 'Total loss': 0.8838096459706625} | train loss {'Reaction outcome loss': 0.9286535217430129, 'Total loss': 0.9286535217430129}
2023-01-05 10:47:08,997 INFO:     Found new best model at epoch 0
2023-01-05 10:47:08,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:08,998 INFO:     Epoch: 1
2023-01-05 10:47:11,119 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6751034776369731, 'Total loss': 0.6751034776369731} | train loss {'Reaction outcome loss': 0.7392954197012898, 'Total loss': 0.7392954197012898}
2023-01-05 10:47:11,120 INFO:     Found new best model at epoch 1
2023-01-05 10:47:11,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:11,121 INFO:     Epoch: 2
2023-01-05 10:47:13,233 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5825088242689769, 'Total loss': 0.5825088242689769} | train loss {'Reaction outcome loss': 0.6005058993240853, 'Total loss': 0.6005058993240853}
2023-01-05 10:47:13,233 INFO:     Found new best model at epoch 2
2023-01-05 10:47:13,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:13,234 INFO:     Epoch: 3
2023-01-05 10:47:15,362 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5259441196918487, 'Total loss': 0.5259441196918487} | train loss {'Reaction outcome loss': 0.5327747885014985, 'Total loss': 0.5327747885014985}
2023-01-05 10:47:15,362 INFO:     Found new best model at epoch 3
2023-01-05 10:47:15,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:15,364 INFO:     Epoch: 4
2023-01-05 10:47:17,529 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5308015803496043, 'Total loss': 0.5308015803496043} | train loss {'Reaction outcome loss': 0.5227546062006618, 'Total loss': 0.5227546062006618}
2023-01-05 10:47:17,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:17,530 INFO:     Epoch: 5
2023-01-05 10:47:19,662 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5260820041100184, 'Total loss': 0.5260820041100184} | train loss {'Reaction outcome loss': 0.5090511269840129, 'Total loss': 0.5090511269840129}
2023-01-05 10:47:19,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:19,663 INFO:     Epoch: 6
2023-01-05 10:47:21,781 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.546131944656372, 'Total loss': 0.546131944656372} | train loss {'Reaction outcome loss': 0.5013690031792, 'Total loss': 0.5013690031792}
2023-01-05 10:47:21,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:21,781 INFO:     Epoch: 7
2023-01-05 10:47:23,890 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5528624951839447, 'Total loss': 0.5528624951839447} | train loss {'Reaction outcome loss': 0.49170944967986024, 'Total loss': 0.49170944967986024}
2023-01-05 10:47:23,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:23,891 INFO:     Epoch: 8
2023-01-05 10:47:25,989 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.540019549926122, 'Total loss': 0.540019549926122} | train loss {'Reaction outcome loss': 0.48458873750744286, 'Total loss': 0.48458873750744286}
2023-01-05 10:47:25,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:25,989 INFO:     Epoch: 9
2023-01-05 10:47:28,088 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5034296457966169, 'Total loss': 0.5034296457966169} | train loss {'Reaction outcome loss': 0.47833009429903695, 'Total loss': 0.47833009429903695}
2023-01-05 10:47:28,088 INFO:     Found new best model at epoch 9
2023-01-05 10:47:28,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:28,089 INFO:     Epoch: 10
2023-01-05 10:47:30,191 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5294041633605957, 'Total loss': 0.5294041633605957} | train loss {'Reaction outcome loss': 0.47621800234684575, 'Total loss': 0.47621800234684575}
2023-01-05 10:47:30,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:30,192 INFO:     Epoch: 11
2023-01-05 10:47:32,264 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5195399820804596, 'Total loss': 0.5195399820804596} | train loss {'Reaction outcome loss': 0.47285158168046904, 'Total loss': 0.47285158168046904}
2023-01-05 10:47:32,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:32,265 INFO:     Epoch: 12
2023-01-05 10:47:34,351 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5261418581008911, 'Total loss': 0.5261418581008911} | train loss {'Reaction outcome loss': 0.4671649368473025, 'Total loss': 0.4671649368473025}
2023-01-05 10:47:34,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:34,352 INFO:     Epoch: 13
2023-01-05 10:47:36,457 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49938006699085236, 'Total loss': 0.49938006699085236} | train loss {'Reaction outcome loss': 0.46145806486135, 'Total loss': 0.46145806486135}
2023-01-05 10:47:36,458 INFO:     Found new best model at epoch 13
2023-01-05 10:47:36,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:36,460 INFO:     Epoch: 14
2023-01-05 10:47:38,575 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.496494448184967, 'Total loss': 0.496494448184967} | train loss {'Reaction outcome loss': 0.4585049730271865, 'Total loss': 0.4585049730271865}
2023-01-05 10:47:38,575 INFO:     Found new best model at epoch 14
2023-01-05 10:47:38,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:38,576 INFO:     Epoch: 15
2023-01-05 10:47:40,687 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5017131408055623, 'Total loss': 0.5017131408055623} | train loss {'Reaction outcome loss': 0.4553932724418221, 'Total loss': 0.4553932724418221}
2023-01-05 10:47:40,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:40,688 INFO:     Epoch: 16
2023-01-05 10:47:42,816 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.532121088107427, 'Total loss': 0.532121088107427} | train loss {'Reaction outcome loss': 0.44874579909738604, 'Total loss': 0.44874579909738604}
2023-01-05 10:47:42,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:42,817 INFO:     Epoch: 17
2023-01-05 10:47:44,918 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5075120816628138, 'Total loss': 0.5075120816628138} | train loss {'Reaction outcome loss': 0.44912606597820043, 'Total loss': 0.44912606597820043}
2023-01-05 10:47:44,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:44,918 INFO:     Epoch: 18
2023-01-05 10:47:47,047 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5176850875218709, 'Total loss': 0.5176850875218709} | train loss {'Reaction outcome loss': 0.4406632212273804, 'Total loss': 0.4406632212273804}
2023-01-05 10:47:47,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:47,047 INFO:     Epoch: 19
2023-01-05 10:47:49,129 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4866649876038233, 'Total loss': 0.4866649876038233} | train loss {'Reaction outcome loss': 0.43409406704889547, 'Total loss': 0.43409406704889547}
2023-01-05 10:47:49,129 INFO:     Found new best model at epoch 19
2023-01-05 10:47:49,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:49,130 INFO:     Epoch: 20
2023-01-05 10:47:51,224 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49252826571464536, 'Total loss': 0.49252826571464536} | train loss {'Reaction outcome loss': 0.4317774320150906, 'Total loss': 0.4317774320150906}
2023-01-05 10:47:51,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:51,225 INFO:     Epoch: 21
2023-01-05 10:47:53,312 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5036819696426391, 'Total loss': 0.5036819696426391} | train loss {'Reaction outcome loss': 0.42852427807701376, 'Total loss': 0.42852427807701376}
2023-01-05 10:47:53,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:53,312 INFO:     Epoch: 22
2023-01-05 10:47:55,396 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5035708576440812, 'Total loss': 0.5035708576440812} | train loss {'Reaction outcome loss': 0.4331603330788595, 'Total loss': 0.4331603330788595}
2023-01-05 10:47:55,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:55,397 INFO:     Epoch: 23
2023-01-05 10:47:57,506 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4943201740582784, 'Total loss': 0.4943201740582784} | train loss {'Reaction outcome loss': 0.4246414201163547, 'Total loss': 0.4246414201163547}
2023-01-05 10:47:57,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:57,506 INFO:     Epoch: 24
2023-01-05 10:47:59,644 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4813678542772929, 'Total loss': 0.4813678542772929} | train loss {'Reaction outcome loss': 0.424301965714811, 'Total loss': 0.424301965714811}
2023-01-05 10:47:59,644 INFO:     Found new best model at epoch 24
2023-01-05 10:47:59,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:47:59,645 INFO:     Epoch: 25
2023-01-05 10:48:01,762 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4873393774032593, 'Total loss': 0.4873393774032593} | train loss {'Reaction outcome loss': 0.4198597128138001, 'Total loss': 0.4198597128138001}
2023-01-05 10:48:01,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:01,762 INFO:     Epoch: 26
2023-01-05 10:48:03,878 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5063832382361094, 'Total loss': 0.5063832382361094} | train loss {'Reaction outcome loss': 0.4132840381218837, 'Total loss': 0.4132840381218837}
2023-01-05 10:48:03,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:03,878 INFO:     Epoch: 27
2023-01-05 10:48:06,010 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4982582767804464, 'Total loss': 0.4982582767804464} | train loss {'Reaction outcome loss': 0.41706932562611476, 'Total loss': 0.41706932562611476}
2023-01-05 10:48:06,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:06,010 INFO:     Epoch: 28
2023-01-05 10:48:08,176 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4783281852801641, 'Total loss': 0.4783281852801641} | train loss {'Reaction outcome loss': 0.41284954157613574, 'Total loss': 0.41284954157613574}
2023-01-05 10:48:08,176 INFO:     Found new best model at epoch 28
2023-01-05 10:48:08,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:08,177 INFO:     Epoch: 29
2023-01-05 10:48:10,368 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5004559099674225, 'Total loss': 0.5004559099674225} | train loss {'Reaction outcome loss': 0.4106554914361391, 'Total loss': 0.4106554914361391}
2023-01-05 10:48:10,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:10,370 INFO:     Epoch: 30
2023-01-05 10:48:12,549 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5210460623105367, 'Total loss': 0.5210460623105367} | train loss {'Reaction outcome loss': 0.4055889505797472, 'Total loss': 0.4055889505797472}
2023-01-05 10:48:12,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:12,550 INFO:     Epoch: 31
2023-01-05 10:48:14,682 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.501297903060913, 'Total loss': 0.501297903060913} | train loss {'Reaction outcome loss': 0.4007377006086238, 'Total loss': 0.4007377006086238}
2023-01-05 10:48:14,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:14,683 INFO:     Epoch: 32
2023-01-05 10:48:16,846 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47988153298695885, 'Total loss': 0.47988153298695885} | train loss {'Reaction outcome loss': 0.39587220858659716, 'Total loss': 0.39587220858659716}
2023-01-05 10:48:16,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:16,847 INFO:     Epoch: 33
2023-01-05 10:48:19,010 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.500269212325414, 'Total loss': 0.500269212325414} | train loss {'Reaction outcome loss': 0.3940915408588591, 'Total loss': 0.3940915408588591}
2023-01-05 10:48:19,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:19,010 INFO:     Epoch: 34
2023-01-05 10:48:21,201 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5062238176663717, 'Total loss': 0.5062238176663717} | train loss {'Reaction outcome loss': 0.3934718498707691, 'Total loss': 0.3934718498707691}
2023-01-05 10:48:21,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:21,202 INFO:     Epoch: 35
2023-01-05 10:48:23,331 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.475916188955307, 'Total loss': 0.475916188955307} | train loss {'Reaction outcome loss': 0.384047782546653, 'Total loss': 0.384047782546653}
2023-01-05 10:48:23,332 INFO:     Found new best model at epoch 35
2023-01-05 10:48:23,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:23,333 INFO:     Epoch: 36
2023-01-05 10:48:25,510 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46600946684678396, 'Total loss': 0.46600946684678396} | train loss {'Reaction outcome loss': 0.38540153926913884, 'Total loss': 0.38540153926913884}
2023-01-05 10:48:25,510 INFO:     Found new best model at epoch 36
2023-01-05 10:48:25,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:25,511 INFO:     Epoch: 37
2023-01-05 10:48:27,695 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47002666592597964, 'Total loss': 0.47002666592597964} | train loss {'Reaction outcome loss': 0.37957514650546587, 'Total loss': 0.37957514650546587}
2023-01-05 10:48:27,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:27,695 INFO:     Epoch: 38
2023-01-05 10:48:29,784 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48371965090433755, 'Total loss': 0.48371965090433755} | train loss {'Reaction outcome loss': 0.37745238995459274, 'Total loss': 0.37745238995459274}
2023-01-05 10:48:29,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:29,785 INFO:     Epoch: 39
2023-01-05 10:48:31,869 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4799753944079081, 'Total loss': 0.4799753944079081} | train loss {'Reaction outcome loss': 0.3707910901133394, 'Total loss': 0.3707910901133394}
2023-01-05 10:48:31,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:31,870 INFO:     Epoch: 40
2023-01-05 10:48:33,951 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.435262035826842, 'Total loss': 0.435262035826842} | train loss {'Reaction outcome loss': 0.37090023178538994, 'Total loss': 0.37090023178538994}
2023-01-05 10:48:33,951 INFO:     Found new best model at epoch 40
2023-01-05 10:48:33,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:33,952 INFO:     Epoch: 41
2023-01-05 10:48:36,055 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46291453341643013, 'Total loss': 0.46291453341643013} | train loss {'Reaction outcome loss': 0.3641110989691574, 'Total loss': 0.3641110989691574}
2023-01-05 10:48:36,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:36,055 INFO:     Epoch: 42
2023-01-05 10:48:38,183 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47384559412797295, 'Total loss': 0.47384559412797295} | train loss {'Reaction outcome loss': 0.36184150351538924, 'Total loss': 0.36184150351538924}
2023-01-05 10:48:38,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:38,183 INFO:     Epoch: 43
2023-01-05 10:48:40,266 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44736990332603455, 'Total loss': 0.44736990332603455} | train loss {'Reaction outcome loss': 0.3587317790549535, 'Total loss': 0.3587317790549535}
2023-01-05 10:48:40,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:40,266 INFO:     Epoch: 44
2023-01-05 10:48:42,399 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46664356589317324, 'Total loss': 0.46664356589317324} | train loss {'Reaction outcome loss': 0.35730878984207637, 'Total loss': 0.35730878984207637}
2023-01-05 10:48:42,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:42,399 INFO:     Epoch: 45
2023-01-05 10:48:44,589 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4761498212814331, 'Total loss': 0.4761498212814331} | train loss {'Reaction outcome loss': 0.3587419401322092, 'Total loss': 0.3587419401322092}
2023-01-05 10:48:44,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:44,589 INFO:     Epoch: 46
2023-01-05 10:48:46,692 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48891215324401854, 'Total loss': 0.48891215324401854} | train loss {'Reaction outcome loss': 0.35068507424313505, 'Total loss': 0.35068507424313505}
2023-01-05 10:48:46,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:46,694 INFO:     Epoch: 47
2023-01-05 10:48:48,805 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4818647493918737, 'Total loss': 0.4818647493918737} | train loss {'Reaction outcome loss': 0.35485410773546705, 'Total loss': 0.35485410773546705}
2023-01-05 10:48:48,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:48,805 INFO:     Epoch: 48
2023-01-05 10:48:50,895 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4696993390719096, 'Total loss': 0.4696993390719096} | train loss {'Reaction outcome loss': 0.34801382792519997, 'Total loss': 0.34801382792519997}
2023-01-05 10:48:50,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:50,895 INFO:     Epoch: 49
2023-01-05 10:48:53,004 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.503783933321635, 'Total loss': 0.503783933321635} | train loss {'Reaction outcome loss': 0.34007491373317145, 'Total loss': 0.34007491373317145}
2023-01-05 10:48:53,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:53,005 INFO:     Epoch: 50
2023-01-05 10:48:55,097 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46805023153622943, 'Total loss': 0.46805023153622943} | train loss {'Reaction outcome loss': 0.3378601306469449, 'Total loss': 0.3378601306469449}
2023-01-05 10:48:55,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:55,097 INFO:     Epoch: 51
2023-01-05 10:48:57,221 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4869732578595479, 'Total loss': 0.4869732578595479} | train loss {'Reaction outcome loss': 0.3386534214729354, 'Total loss': 0.3386534214729354}
2023-01-05 10:48:57,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:57,221 INFO:     Epoch: 52
2023-01-05 10:48:59,347 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4635825177033742, 'Total loss': 0.4635825177033742} | train loss {'Reaction outcome loss': 0.3392009159529602, 'Total loss': 0.3392009159529602}
2023-01-05 10:48:59,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:48:59,347 INFO:     Epoch: 53
2023-01-05 10:49:01,468 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5129893884062767, 'Total loss': 0.5129893884062767} | train loss {'Reaction outcome loss': 0.33633276562278086, 'Total loss': 0.33633276562278086}
2023-01-05 10:49:01,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:01,468 INFO:     Epoch: 54
2023-01-05 10:49:03,588 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45865876773993175, 'Total loss': 0.45865876773993175} | train loss {'Reaction outcome loss': 0.3388221084170944, 'Total loss': 0.3388221084170944}
2023-01-05 10:49:03,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:03,588 INFO:     Epoch: 55
2023-01-05 10:49:05,722 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5005271633466085, 'Total loss': 0.5005271633466085} | train loss {'Reaction outcome loss': 0.3228024403690855, 'Total loss': 0.3228024403690855}
2023-01-05 10:49:05,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:05,722 INFO:     Epoch: 56
2023-01-05 10:49:07,844 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4640385071436564, 'Total loss': 0.4640385071436564} | train loss {'Reaction outcome loss': 0.3227949048300366, 'Total loss': 0.3227949048300366}
2023-01-05 10:49:07,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:07,845 INFO:     Epoch: 57
2023-01-05 10:49:09,963 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49054076174894967, 'Total loss': 0.49054076174894967} | train loss {'Reaction outcome loss': 0.32029073256931023, 'Total loss': 0.32029073256931023}
2023-01-05 10:49:09,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:09,963 INFO:     Epoch: 58
2023-01-05 10:49:12,053 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49926432768503826, 'Total loss': 0.49926432768503826} | train loss {'Reaction outcome loss': 0.3258765132981779, 'Total loss': 0.3258765132981779}
2023-01-05 10:49:12,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:12,054 INFO:     Epoch: 59
2023-01-05 10:49:14,212 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4869348754485448, 'Total loss': 0.4869348754485448} | train loss {'Reaction outcome loss': 0.3219886716086786, 'Total loss': 0.3219886716086786}
2023-01-05 10:49:14,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:14,213 INFO:     Epoch: 60
2023-01-05 10:49:16,375 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47960541148980457, 'Total loss': 0.47960541148980457} | train loss {'Reaction outcome loss': 0.3169687117821786, 'Total loss': 0.3169687117821786}
2023-01-05 10:49:16,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:16,375 INFO:     Epoch: 61
2023-01-05 10:49:18,471 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4603516340255737, 'Total loss': 0.4603516340255737} | train loss {'Reaction outcome loss': 0.3150170205959252, 'Total loss': 0.3150170205959252}
2023-01-05 10:49:18,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:18,471 INFO:     Epoch: 62
2023-01-05 10:49:20,565 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4551467259724935, 'Total loss': 0.4551467259724935} | train loss {'Reaction outcome loss': 0.3167132398202306, 'Total loss': 0.3167132398202306}
2023-01-05 10:49:20,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:20,565 INFO:     Epoch: 63
2023-01-05 10:49:22,671 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4710124413172404, 'Total loss': 0.4710124413172404} | train loss {'Reaction outcome loss': 0.3104030983556649, 'Total loss': 0.3104030983556649}
2023-01-05 10:49:22,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:22,672 INFO:     Epoch: 64
2023-01-05 10:49:24,752 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4686768611272176, 'Total loss': 0.4686768611272176} | train loss {'Reaction outcome loss': 0.30498506928429064, 'Total loss': 0.30498506928429064}
2023-01-05 10:49:24,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:24,752 INFO:     Epoch: 65
2023-01-05 10:49:26,862 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4562776500980059, 'Total loss': 0.4562776500980059} | train loss {'Reaction outcome loss': 0.30790292296981636, 'Total loss': 0.30790292296981636}
2023-01-05 10:49:26,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:26,863 INFO:     Epoch: 66
2023-01-05 10:49:28,960 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45498892267545066, 'Total loss': 0.45498892267545066} | train loss {'Reaction outcome loss': 0.3011221068300607, 'Total loss': 0.3011221068300607}
2023-01-05 10:49:28,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:28,960 INFO:     Epoch: 67
2023-01-05 10:49:31,037 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4552032689253489, 'Total loss': 0.4552032689253489} | train loss {'Reaction outcome loss': 0.3049731889650935, 'Total loss': 0.3049731889650935}
2023-01-05 10:49:31,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:31,037 INFO:     Epoch: 68
2023-01-05 10:49:33,142 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47844356099764507, 'Total loss': 0.47844356099764507} | train loss {'Reaction outcome loss': 0.295296073451147, 'Total loss': 0.295296073451147}
2023-01-05 10:49:33,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:33,142 INFO:     Epoch: 69
2023-01-05 10:49:35,245 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49934492508570355, 'Total loss': 0.49934492508570355} | train loss {'Reaction outcome loss': 0.2967739171542964, 'Total loss': 0.2967739171542964}
2023-01-05 10:49:35,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:35,245 INFO:     Epoch: 70
2023-01-05 10:49:37,336 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46929576694965364, 'Total loss': 0.46929576694965364} | train loss {'Reaction outcome loss': 0.2896132027737169, 'Total loss': 0.2896132027737169}
2023-01-05 10:49:37,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:37,336 INFO:     Epoch: 71
2023-01-05 10:49:39,435 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44816454549630486, 'Total loss': 0.44816454549630486} | train loss {'Reaction outcome loss': 0.297041673185952, 'Total loss': 0.297041673185952}
2023-01-05 10:49:39,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:39,435 INFO:     Epoch: 72
2023-01-05 10:49:41,554 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47663110693295796, 'Total loss': 0.47663110693295796} | train loss {'Reaction outcome loss': 0.2909228998771954, 'Total loss': 0.2909228998771954}
2023-01-05 10:49:41,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:41,555 INFO:     Epoch: 73
2023-01-05 10:49:43,704 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5133613646030426, 'Total loss': 0.5133613646030426} | train loss {'Reaction outcome loss': 0.2882613539968655, 'Total loss': 0.2882613539968655}
2023-01-05 10:49:43,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:43,705 INFO:     Epoch: 74
2023-01-05 10:49:45,844 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48872334957122804, 'Total loss': 0.48872334957122804} | train loss {'Reaction outcome loss': 0.2926102951169014, 'Total loss': 0.2926102951169014}
2023-01-05 10:49:45,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:45,844 INFO:     Epoch: 75
2023-01-05 10:49:47,987 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4513672669728597, 'Total loss': 0.4513672669728597} | train loss {'Reaction outcome loss': 0.2834109584545041, 'Total loss': 0.2834109584545041}
2023-01-05 10:49:47,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:47,987 INFO:     Epoch: 76
2023-01-05 10:49:50,143 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4235020488500595, 'Total loss': 0.4235020488500595} | train loss {'Reaction outcome loss': 0.28396818457996886, 'Total loss': 0.28396818457996886}
2023-01-05 10:49:50,143 INFO:     Found new best model at epoch 76
2023-01-05 10:49:50,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:50,144 INFO:     Epoch: 77
2023-01-05 10:49:52,278 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4838496367136637, 'Total loss': 0.4838496367136637} | train loss {'Reaction outcome loss': 0.2823612567705986, 'Total loss': 0.2823612567705986}
2023-01-05 10:49:52,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:52,278 INFO:     Epoch: 78
2023-01-05 10:49:54,444 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4676400775710742, 'Total loss': 0.4676400775710742} | train loss {'Reaction outcome loss': 0.2736275429144884, 'Total loss': 0.2736275429144884}
2023-01-05 10:49:54,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:54,444 INFO:     Epoch: 79
2023-01-05 10:49:56,599 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4809519519408544, 'Total loss': 0.4809519519408544} | train loss {'Reaction outcome loss': 0.2787409910161198, 'Total loss': 0.2787409910161198}
2023-01-05 10:49:56,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:56,599 INFO:     Epoch: 80
2023-01-05 10:49:58,748 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4749319702386856, 'Total loss': 0.4749319702386856} | train loss {'Reaction outcome loss': 0.27334099447170457, 'Total loss': 0.27334099447170457}
2023-01-05 10:49:58,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:49:58,749 INFO:     Epoch: 81
2023-01-05 10:50:00,904 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.488837597767512, 'Total loss': 0.488837597767512} | train loss {'Reaction outcome loss': 0.27546707785009467, 'Total loss': 0.27546707785009467}
2023-01-05 10:50:00,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:00,904 INFO:     Epoch: 82
2023-01-05 10:50:03,001 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4579207867383957, 'Total loss': 0.4579207867383957} | train loss {'Reaction outcome loss': 0.28101865340010584, 'Total loss': 0.28101865340010584}
2023-01-05 10:50:03,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:03,001 INFO:     Epoch: 83
2023-01-05 10:50:05,101 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4785891234874725, 'Total loss': 0.4785891234874725} | train loss {'Reaction outcome loss': 0.27197387046265953, 'Total loss': 0.27197387046265953}
2023-01-05 10:50:05,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:05,102 INFO:     Epoch: 84
2023-01-05 10:50:07,028 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4796546190977097, 'Total loss': 0.4796546190977097} | train loss {'Reaction outcome loss': 0.2690413657084599, 'Total loss': 0.2690413657084599}
2023-01-05 10:50:07,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:07,028 INFO:     Epoch: 85
2023-01-05 10:50:09,161 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4633884370326996, 'Total loss': 0.4633884370326996} | train loss {'Reaction outcome loss': 0.27363659623471315, 'Total loss': 0.27363659623471315}
2023-01-05 10:50:09,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:09,161 INFO:     Epoch: 86
2023-01-05 10:50:11,265 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45782708923021953, 'Total loss': 0.45782708923021953} | train loss {'Reaction outcome loss': 0.26434014294119107, 'Total loss': 0.26434014294119107}
2023-01-05 10:50:11,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:11,265 INFO:     Epoch: 87
2023-01-05 10:50:13,342 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49239717721939086, 'Total loss': 0.49239717721939086} | train loss {'Reaction outcome loss': 0.26500515738031366, 'Total loss': 0.26500515738031366}
2023-01-05 10:50:13,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:13,343 INFO:     Epoch: 88
2023-01-05 10:50:15,435 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4682082543770472, 'Total loss': 0.4682082543770472} | train loss {'Reaction outcome loss': 0.25756339547343743, 'Total loss': 0.25756339547343743}
2023-01-05 10:50:15,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:15,435 INFO:     Epoch: 89
2023-01-05 10:50:17,507 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4930651823679606, 'Total loss': 0.4930651823679606} | train loss {'Reaction outcome loss': 0.26356760196851725, 'Total loss': 0.26356760196851725}
2023-01-05 10:50:17,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:17,508 INFO:     Epoch: 90
2023-01-05 10:50:19,603 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.484845111767451, 'Total loss': 0.484845111767451} | train loss {'Reaction outcome loss': 0.258087925749384, 'Total loss': 0.258087925749384}
2023-01-05 10:50:19,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:19,603 INFO:     Epoch: 91
2023-01-05 10:50:21,704 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49995198448499045, 'Total loss': 0.49995198448499045} | train loss {'Reaction outcome loss': 0.24891933782415077, 'Total loss': 0.24891933782415077}
2023-01-05 10:50:21,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:21,704 INFO:     Epoch: 92
2023-01-05 10:50:23,824 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5082143068313598, 'Total loss': 0.5082143068313598} | train loss {'Reaction outcome loss': 0.2591042431555825, 'Total loss': 0.2591042431555825}
2023-01-05 10:50:23,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:23,825 INFO:     Epoch: 93
2023-01-05 10:50:25,964 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4516080568234126, 'Total loss': 0.4516080568234126} | train loss {'Reaction outcome loss': 0.2526158928707406, 'Total loss': 0.2526158928707406}
2023-01-05 10:50:25,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:25,964 INFO:     Epoch: 94
2023-01-05 10:50:28,093 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.472407241165638, 'Total loss': 0.472407241165638} | train loss {'Reaction outcome loss': 0.25484907692093606, 'Total loss': 0.25484907692093606}
2023-01-05 10:50:28,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:28,093 INFO:     Epoch: 95
2023-01-05 10:50:30,247 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4714768722653389, 'Total loss': 0.4714768722653389} | train loss {'Reaction outcome loss': 0.25012753594107245, 'Total loss': 0.25012753594107245}
2023-01-05 10:50:30,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:30,247 INFO:     Epoch: 96
2023-01-05 10:50:32,425 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45782438591122626, 'Total loss': 0.45782438591122626} | train loss {'Reaction outcome loss': 0.24887697795753952, 'Total loss': 0.24887697795753952}
2023-01-05 10:50:32,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:32,425 INFO:     Epoch: 97
2023-01-05 10:50:34,602 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4396147201458613, 'Total loss': 0.4396147201458613} | train loss {'Reaction outcome loss': 0.24872842424245545, 'Total loss': 0.24872842424245545}
2023-01-05 10:50:34,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:34,603 INFO:     Epoch: 98
2023-01-05 10:50:36,793 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44439057062069576, 'Total loss': 0.44439057062069576} | train loss {'Reaction outcome loss': 0.2491434149566915, 'Total loss': 0.2491434149566915}
2023-01-05 10:50:36,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:36,793 INFO:     Epoch: 99
2023-01-05 10:50:38,950 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45957731306552885, 'Total loss': 0.45957731306552885} | train loss {'Reaction outcome loss': 0.24792376816982314, 'Total loss': 0.24792376816982314}
2023-01-05 10:50:38,950 INFO:     Best model found after epoch 77 of 100.
2023-01-05 10:50:38,950 INFO:   Done with stage: TRAINING
2023-01-05 10:50:38,950 INFO:   Starting stage: EVALUATION
2023-01-05 10:50:39,095 INFO:   Done with stage: EVALUATION
2023-01-05 10:50:39,096 INFO:   Leaving out SEQ value Fold_3
2023-01-05 10:50:39,108 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 10:50:39,109 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:50:39,756 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:50:39,756 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:50:39,826 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:50:39,826 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:50:39,826 INFO:     No hyperparam tuning for this model
2023-01-05 10:50:39,826 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:50:39,826 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:50:39,827 INFO:     None feature selector for col prot
2023-01-05 10:50:39,827 INFO:     None feature selector for col prot
2023-01-05 10:50:39,827 INFO:     None feature selector for col prot
2023-01-05 10:50:39,828 INFO:     None feature selector for col chem
2023-01-05 10:50:39,828 INFO:     None feature selector for col chem
2023-01-05 10:50:39,828 INFO:     None feature selector for col chem
2023-01-05 10:50:39,828 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:50:39,828 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:50:39,830 INFO:     Number of params in model 72901
2023-01-05 10:50:39,833 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:50:39,833 INFO:   Starting stage: TRAINING
2023-01-05 10:50:39,891 INFO:     Val loss before train {'Reaction outcome loss': 0.9883139967918396, 'Total loss': 0.9883139967918396}
2023-01-05 10:50:39,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:39,891 INFO:     Epoch: 0
2023-01-05 10:50:42,011 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.831485903263092, 'Total loss': 0.831485903263092} | train loss {'Reaction outcome loss': 0.9366133772108677, 'Total loss': 0.9366133772108677}
2023-01-05 10:50:42,012 INFO:     Found new best model at epoch 0
2023-01-05 10:50:42,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:42,013 INFO:     Epoch: 1
2023-01-05 10:50:44,097 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.628954925139745, 'Total loss': 0.628954925139745} | train loss {'Reaction outcome loss': 0.7662605505681386, 'Total loss': 0.7662605505681386}
2023-01-05 10:50:44,097 INFO:     Found new best model at epoch 1
2023-01-05 10:50:44,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:44,098 INFO:     Epoch: 2
2023-01-05 10:50:46,196 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5353489001592, 'Total loss': 0.5353489001592} | train loss {'Reaction outcome loss': 0.6158264755767627, 'Total loss': 0.6158264755767627}
2023-01-05 10:50:46,196 INFO:     Found new best model at epoch 2
2023-01-05 10:50:46,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:46,197 INFO:     Epoch: 3
2023-01-05 10:50:48,302 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5595470398664475, 'Total loss': 0.5595470398664475} | train loss {'Reaction outcome loss': 0.553425767017107, 'Total loss': 0.553425767017107}
2023-01-05 10:50:48,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:48,302 INFO:     Epoch: 4
2023-01-05 10:50:50,391 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5021234651406606, 'Total loss': 0.5021234651406606} | train loss {'Reaction outcome loss': 0.5332408815513562, 'Total loss': 0.5332408815513562}
2023-01-05 10:50:50,391 INFO:     Found new best model at epoch 4
2023-01-05 10:50:50,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:50,393 INFO:     Epoch: 5
2023-01-05 10:50:52,512 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5255696058273316, 'Total loss': 0.5255696058273316} | train loss {'Reaction outcome loss': 0.5115170271618523, 'Total loss': 0.5115170271618523}
2023-01-05 10:50:52,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:52,512 INFO:     Epoch: 6
2023-01-05 10:50:54,627 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5265355378389358, 'Total loss': 0.5265355378389358} | train loss {'Reaction outcome loss': 0.5040559341763928, 'Total loss': 0.5040559341763928}
2023-01-05 10:50:54,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:54,628 INFO:     Epoch: 7
2023-01-05 10:50:56,741 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4893379251162211, 'Total loss': 0.4893379251162211} | train loss {'Reaction outcome loss': 0.4950698265520326, 'Total loss': 0.4950698265520326}
2023-01-05 10:50:56,741 INFO:     Found new best model at epoch 7
2023-01-05 10:50:56,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:56,743 INFO:     Epoch: 8
2023-01-05 10:50:58,840 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49977041880289713, 'Total loss': 0.49977041880289713} | train loss {'Reaction outcome loss': 0.4862252486067532, 'Total loss': 0.4862252486067532}
2023-01-05 10:50:58,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:50:58,840 INFO:     Epoch: 9
2023-01-05 10:51:00,957 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5146701276302338, 'Total loss': 0.5146701276302338} | train loss {'Reaction outcome loss': 0.4825541455380238, 'Total loss': 0.4825541455380238}
2023-01-05 10:51:00,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:00,957 INFO:     Epoch: 10
2023-01-05 10:51:03,026 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.508294161160787, 'Total loss': 0.508294161160787} | train loss {'Reaction outcome loss': 0.47387827693545903, 'Total loss': 0.47387827693545903}
2023-01-05 10:51:03,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:03,026 INFO:     Epoch: 11
2023-01-05 10:51:05,109 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4955285171667735, 'Total loss': 0.4955285171667735} | train loss {'Reaction outcome loss': 0.4706457140889481, 'Total loss': 0.4706457140889481}
2023-01-05 10:51:05,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:05,109 INFO:     Epoch: 12
2023-01-05 10:51:07,213 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5029451886812846, 'Total loss': 0.5029451886812846} | train loss {'Reaction outcome loss': 0.46573123950375256, 'Total loss': 0.46573123950375256}
2023-01-05 10:51:07,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:07,214 INFO:     Epoch: 13
2023-01-05 10:51:09,300 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4788927177588145, 'Total loss': 0.4788927177588145} | train loss {'Reaction outcome loss': 0.46160699435285407, 'Total loss': 0.46160699435285407}
2023-01-05 10:51:09,300 INFO:     Found new best model at epoch 13
2023-01-05 10:51:09,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:09,302 INFO:     Epoch: 14
2023-01-05 10:51:11,389 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4832549512386322, 'Total loss': 0.4832549512386322} | train loss {'Reaction outcome loss': 0.45763773770227917, 'Total loss': 0.45763773770227917}
2023-01-05 10:51:11,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:11,390 INFO:     Epoch: 15
2023-01-05 10:51:13,491 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49879985948403677, 'Total loss': 0.49879985948403677} | train loss {'Reaction outcome loss': 0.4547290616553195, 'Total loss': 0.4547290616553195}
2023-01-05 10:51:13,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:13,492 INFO:     Epoch: 16
2023-01-05 10:51:15,613 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4827084024747213, 'Total loss': 0.4827084024747213} | train loss {'Reaction outcome loss': 0.4492139072857634, 'Total loss': 0.4492139072857634}
2023-01-05 10:51:15,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:15,613 INFO:     Epoch: 17
2023-01-05 10:51:17,706 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4860872169335683, 'Total loss': 0.4860872169335683} | train loss {'Reaction outcome loss': 0.4468598707857793, 'Total loss': 0.4468598707857793}
2023-01-05 10:51:17,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:17,707 INFO:     Epoch: 18
2023-01-05 10:51:19,829 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48302482267220814, 'Total loss': 0.48302482267220814} | train loss {'Reaction outcome loss': 0.444120429456234, 'Total loss': 0.444120429456234}
2023-01-05 10:51:19,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:19,830 INFO:     Epoch: 19
2023-01-05 10:51:22,002 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5109625677267711, 'Total loss': 0.5109625677267711} | train loss {'Reaction outcome loss': 0.43917748356496333, 'Total loss': 0.43917748356496333}
2023-01-05 10:51:22,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:22,002 INFO:     Epoch: 20
2023-01-05 10:51:24,125 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4529283454020818, 'Total loss': 0.4529283454020818} | train loss {'Reaction outcome loss': 0.44139677819109313, 'Total loss': 0.44139677819109313}
2023-01-05 10:51:24,125 INFO:     Found new best model at epoch 20
2023-01-05 10:51:24,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:24,127 INFO:     Epoch: 21
2023-01-05 10:51:26,228 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48260788917541503, 'Total loss': 0.48260788917541503} | train loss {'Reaction outcome loss': 0.431147981842939, 'Total loss': 0.431147981842939}
2023-01-05 10:51:26,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:26,228 INFO:     Epoch: 22
2023-01-05 10:51:28,366 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4451221605141958, 'Total loss': 0.4451221605141958} | train loss {'Reaction outcome loss': 0.4347662974665635, 'Total loss': 0.4347662974665635}
2023-01-05 10:51:28,366 INFO:     Found new best model at epoch 22
2023-01-05 10:51:28,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:28,367 INFO:     Epoch: 23
2023-01-05 10:51:30,489 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44623048106829327, 'Total loss': 0.44623048106829327} | train loss {'Reaction outcome loss': 0.42824798656532365, 'Total loss': 0.42824798656532365}
2023-01-05 10:51:30,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:30,490 INFO:     Epoch: 24
2023-01-05 10:51:32,599 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4749399264653524, 'Total loss': 0.4749399264653524} | train loss {'Reaction outcome loss': 0.4203616879662893, 'Total loss': 0.4203616879662893}
2023-01-05 10:51:32,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:32,599 INFO:     Epoch: 25
2023-01-05 10:51:34,715 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4594212234020233, 'Total loss': 0.4594212234020233} | train loss {'Reaction outcome loss': 0.4152867414437941, 'Total loss': 0.4152867414437941}
2023-01-05 10:51:34,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:34,715 INFO:     Epoch: 26
2023-01-05 10:51:36,868 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5211839318275452, 'Total loss': 0.5211839318275452} | train loss {'Reaction outcome loss': 0.41528719242145545, 'Total loss': 0.41528719242145545}
2023-01-05 10:51:36,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:36,868 INFO:     Epoch: 27
2023-01-05 10:51:38,956 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43919527530670166, 'Total loss': 0.43919527530670166} | train loss {'Reaction outcome loss': 0.4132497618722655, 'Total loss': 0.4132497618722655}
2023-01-05 10:51:38,956 INFO:     Found new best model at epoch 27
2023-01-05 10:51:38,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:38,957 INFO:     Epoch: 28
2023-01-05 10:51:41,086 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4611684064070384, 'Total loss': 0.4611684064070384} | train loss {'Reaction outcome loss': 0.40966448383609744, 'Total loss': 0.40966448383609744}
2023-01-05 10:51:41,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:41,087 INFO:     Epoch: 29
2023-01-05 10:51:43,177 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4444834192593892, 'Total loss': 0.4444834192593892} | train loss {'Reaction outcome loss': 0.40669846164919166, 'Total loss': 0.40669846164919166}
2023-01-05 10:51:43,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:43,177 INFO:     Epoch: 30
2023-01-05 10:51:45,276 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4909019649028778, 'Total loss': 0.4909019649028778} | train loss {'Reaction outcome loss': 0.4048774530091425, 'Total loss': 0.4048774530091425}
2023-01-05 10:51:45,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:45,277 INFO:     Epoch: 31
2023-01-05 10:51:47,387 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4460730185111364, 'Total loss': 0.4460730185111364} | train loss {'Reaction outcome loss': 0.39828715903045486, 'Total loss': 0.39828715903045486}
2023-01-05 10:51:47,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:47,387 INFO:     Epoch: 32
2023-01-05 10:51:49,467 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4976196885108948, 'Total loss': 0.4976196885108948} | train loss {'Reaction outcome loss': 0.3996965235547863, 'Total loss': 0.3996965235547863}
2023-01-05 10:51:49,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:49,467 INFO:     Epoch: 33
2023-01-05 10:51:51,575 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43261290788650514, 'Total loss': 0.43261290788650514} | train loss {'Reaction outcome loss': 0.40185481220157476, 'Total loss': 0.40185481220157476}
2023-01-05 10:51:51,576 INFO:     Found new best model at epoch 33
2023-01-05 10:51:51,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:51,577 INFO:     Epoch: 34
2023-01-05 10:51:53,684 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4578886826833089, 'Total loss': 0.4578886826833089} | train loss {'Reaction outcome loss': 0.3926012415411699, 'Total loss': 0.3926012415411699}
2023-01-05 10:51:53,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:53,684 INFO:     Epoch: 35
2023-01-05 10:51:55,823 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44619413316249845, 'Total loss': 0.44619413316249845} | train loss {'Reaction outcome loss': 0.38906536762514254, 'Total loss': 0.38906536762514254}
2023-01-05 10:51:55,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:55,823 INFO:     Epoch: 36
2023-01-05 10:51:57,974 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4371209492286046, 'Total loss': 0.4371209492286046} | train loss {'Reaction outcome loss': 0.38741457897381193, 'Total loss': 0.38741457897381193}
2023-01-05 10:51:57,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:51:57,975 INFO:     Epoch: 37
2023-01-05 10:52:00,097 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4930657188097636, 'Total loss': 0.4930657188097636} | train loss {'Reaction outcome loss': 0.38140417872010357, 'Total loss': 0.38140417872010357}
2023-01-05 10:52:00,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:00,097 INFO:     Epoch: 38
2023-01-05 10:52:02,224 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4814558486143748, 'Total loss': 0.4814558486143748} | train loss {'Reaction outcome loss': 0.3775295596161898, 'Total loss': 0.3775295596161898}
2023-01-05 10:52:02,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:02,225 INFO:     Epoch: 39
2023-01-05 10:52:04,364 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4499708573023478, 'Total loss': 0.4499708573023478} | train loss {'Reaction outcome loss': 0.37542421487669875, 'Total loss': 0.37542421487669875}
2023-01-05 10:52:04,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:04,364 INFO:     Epoch: 40
2023-01-05 10:52:06,489 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4645968973636627, 'Total loss': 0.4645968973636627} | train loss {'Reaction outcome loss': 0.3742777642379277, 'Total loss': 0.3742777642379277}
2023-01-05 10:52:06,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:06,489 INFO:     Epoch: 41
2023-01-05 10:52:08,622 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4226218769947688, 'Total loss': 0.4226218769947688} | train loss {'Reaction outcome loss': 0.3727108643655359, 'Total loss': 0.3727108643655359}
2023-01-05 10:52:08,622 INFO:     Found new best model at epoch 41
2023-01-05 10:52:08,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:08,623 INFO:     Epoch: 42
2023-01-05 10:52:10,744 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43172389566898345, 'Total loss': 0.43172389566898345} | train loss {'Reaction outcome loss': 0.36957928523366906, 'Total loss': 0.36957928523366906}
2023-01-05 10:52:10,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:10,744 INFO:     Epoch: 43
2023-01-05 10:52:12,854 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4389589766661326, 'Total loss': 0.4389589766661326} | train loss {'Reaction outcome loss': 0.36222275634751705, 'Total loss': 0.36222275634751705}
2023-01-05 10:52:12,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:12,854 INFO:     Epoch: 44
2023-01-05 10:52:14,983 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4438772737979889, 'Total loss': 0.4438772737979889} | train loss {'Reaction outcome loss': 0.3560090426790671, 'Total loss': 0.3560090426790671}
2023-01-05 10:52:14,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:14,983 INFO:     Epoch: 45
2023-01-05 10:52:17,129 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4660010596116384, 'Total loss': 0.4660010596116384} | train loss {'Reaction outcome loss': 0.35775988943276615, 'Total loss': 0.35775988943276615}
2023-01-05 10:52:17,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:17,130 INFO:     Epoch: 46
2023-01-05 10:52:19,247 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4567560871442159, 'Total loss': 0.4567560871442159} | train loss {'Reaction outcome loss': 0.3574253817218064, 'Total loss': 0.3574253817218064}
2023-01-05 10:52:19,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:19,247 INFO:     Epoch: 47
2023-01-05 10:52:21,350 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44797960519790647, 'Total loss': 0.44797960519790647} | train loss {'Reaction outcome loss': 0.352170912181809, 'Total loss': 0.352170912181809}
2023-01-05 10:52:21,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:21,351 INFO:     Epoch: 48
2023-01-05 10:52:23,451 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.451416943470637, 'Total loss': 0.451416943470637} | train loss {'Reaction outcome loss': 0.3462171909963562, 'Total loss': 0.3462171909963562}
2023-01-05 10:52:23,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:23,451 INFO:     Epoch: 49
2023-01-05 10:52:25,569 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4812017768621445, 'Total loss': 0.4812017768621445} | train loss {'Reaction outcome loss': 0.35194978966330087, 'Total loss': 0.35194978966330087}
2023-01-05 10:52:25,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:25,570 INFO:     Epoch: 50
2023-01-05 10:52:27,705 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.448908065756162, 'Total loss': 0.448908065756162} | train loss {'Reaction outcome loss': 0.34110097796486244, 'Total loss': 0.34110097796486244}
2023-01-05 10:52:27,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:27,706 INFO:     Epoch: 51
2023-01-05 10:52:29,896 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4682822773853938, 'Total loss': 0.4682822773853938} | train loss {'Reaction outcome loss': 0.3368290945289344, 'Total loss': 0.3368290945289344}
2023-01-05 10:52:29,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:29,897 INFO:     Epoch: 52
2023-01-05 10:52:32,102 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.446898078918457, 'Total loss': 0.446898078918457} | train loss {'Reaction outcome loss': 0.33588677595784194, 'Total loss': 0.33588677595784194}
2023-01-05 10:52:32,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:32,102 INFO:     Epoch: 53
2023-01-05 10:52:34,305 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4755587855974833, 'Total loss': 0.4755587855974833} | train loss {'Reaction outcome loss': 0.33535099162781323, 'Total loss': 0.33535099162781323}
2023-01-05 10:52:34,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:34,306 INFO:     Epoch: 54
2023-01-05 10:52:36,444 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4346982816855113, 'Total loss': 0.4346982816855113} | train loss {'Reaction outcome loss': 0.33078986395449533, 'Total loss': 0.33078986395449533}
2023-01-05 10:52:36,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:36,444 INFO:     Epoch: 55
2023-01-05 10:52:38,537 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4141851902008057, 'Total loss': 0.4141851902008057} | train loss {'Reaction outcome loss': 0.3302057773473054, 'Total loss': 0.3302057773473054}
2023-01-05 10:52:38,537 INFO:     Found new best model at epoch 55
2023-01-05 10:52:38,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:38,539 INFO:     Epoch: 56
2023-01-05 10:52:40,650 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4207684655984243, 'Total loss': 0.4207684655984243} | train loss {'Reaction outcome loss': 0.3272212725812501, 'Total loss': 0.3272212725812501}
2023-01-05 10:52:40,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:40,651 INFO:     Epoch: 57
2023-01-05 10:52:42,757 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4434588978687922, 'Total loss': 0.4434588978687922} | train loss {'Reaction outcome loss': 0.3179225095269019, 'Total loss': 0.3179225095269019}
2023-01-05 10:52:42,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:42,757 INFO:     Epoch: 58
2023-01-05 10:52:44,873 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4255393443008264, 'Total loss': 0.4255393443008264} | train loss {'Reaction outcome loss': 0.31620620102723584, 'Total loss': 0.31620620102723584}
2023-01-05 10:52:44,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:44,873 INFO:     Epoch: 59
2023-01-05 10:52:46,990 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4502721856037776, 'Total loss': 0.4502721856037776} | train loss {'Reaction outcome loss': 0.31625126697884426, 'Total loss': 0.31625126697884426}
2023-01-05 10:52:46,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:46,990 INFO:     Epoch: 60
2023-01-05 10:52:49,094 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4191194413229823, 'Total loss': 0.4191194413229823} | train loss {'Reaction outcome loss': 0.31808364418518803, 'Total loss': 0.31808364418518803}
2023-01-05 10:52:49,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:49,094 INFO:     Epoch: 61
2023-01-05 10:52:51,215 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43879792193571726, 'Total loss': 0.43879792193571726} | train loss {'Reaction outcome loss': 0.3144875174782572, 'Total loss': 0.3144875174782572}
2023-01-05 10:52:51,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:51,215 INFO:     Epoch: 62
2023-01-05 10:52:53,331 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44694010615348817, 'Total loss': 0.44694010615348817} | train loss {'Reaction outcome loss': 0.3138138056073311, 'Total loss': 0.3138138056073311}
2023-01-05 10:52:53,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:53,331 INFO:     Epoch: 63
2023-01-05 10:52:55,407 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47133952379226685, 'Total loss': 0.47133952379226685} | train loss {'Reaction outcome loss': 0.31248574139699886, 'Total loss': 0.31248574139699886}
2023-01-05 10:52:55,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:55,407 INFO:     Epoch: 64
2023-01-05 10:52:57,527 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44660250743230184, 'Total loss': 0.44660250743230184} | train loss {'Reaction outcome loss': 0.31137601125740655, 'Total loss': 0.31137601125740655}
2023-01-05 10:52:57,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:57,529 INFO:     Epoch: 65
2023-01-05 10:52:59,622 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47076021631558734, 'Total loss': 0.47076021631558734} | train loss {'Reaction outcome loss': 0.3069003465157138, 'Total loss': 0.3069003465157138}
2023-01-05 10:52:59,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:52:59,622 INFO:     Epoch: 66
2023-01-05 10:53:01,738 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43810856342315674, 'Total loss': 0.43810856342315674} | train loss {'Reaction outcome loss': 0.3023893719566238, 'Total loss': 0.3023893719566238}
2023-01-05 10:53:01,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:01,739 INFO:     Epoch: 67
2023-01-05 10:53:03,878 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41568896969159447, 'Total loss': 0.41568896969159447} | train loss {'Reaction outcome loss': 0.30191183825750856, 'Total loss': 0.30191183825750856}
2023-01-05 10:53:03,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:03,879 INFO:     Epoch: 68
2023-01-05 10:53:05,991 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46941778659820554, 'Total loss': 0.46941778659820554} | train loss {'Reaction outcome loss': 0.3020315521607434, 'Total loss': 0.3020315521607434}
2023-01-05 10:53:05,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:05,991 INFO:     Epoch: 69
2023-01-05 10:53:08,108 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.425332414607207, 'Total loss': 0.425332414607207} | train loss {'Reaction outcome loss': 0.30283996470299734, 'Total loss': 0.30283996470299734}
2023-01-05 10:53:08,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:08,108 INFO:     Epoch: 70
2023-01-05 10:53:10,213 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4299078982323408, 'Total loss': 0.4299078982323408} | train loss {'Reaction outcome loss': 0.3022858752141686, 'Total loss': 0.3022858752141686}
2023-01-05 10:53:10,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:10,214 INFO:     Epoch: 71
2023-01-05 10:53:12,344 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41722023660937946, 'Total loss': 0.41722023660937946} | train loss {'Reaction outcome loss': 0.2895498283642487, 'Total loss': 0.2895498283642487}
2023-01-05 10:53:12,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:12,344 INFO:     Epoch: 72
2023-01-05 10:53:14,437 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47412218153476715, 'Total loss': 0.47412218153476715} | train loss {'Reaction outcome loss': 0.28732223424000025, 'Total loss': 0.28732223424000025}
2023-01-05 10:53:14,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:14,437 INFO:     Epoch: 73
2023-01-05 10:53:16,541 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42496438274780907, 'Total loss': 0.42496438274780907} | train loss {'Reaction outcome loss': 0.2896465812095978, 'Total loss': 0.2896465812095978}
2023-01-05 10:53:16,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:16,542 INFO:     Epoch: 74
2023-01-05 10:53:18,692 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46947057247161866, 'Total loss': 0.46947057247161866} | train loss {'Reaction outcome loss': 0.29226681050321046, 'Total loss': 0.29226681050321046}
2023-01-05 10:53:18,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:18,692 INFO:     Epoch: 75
2023-01-05 10:53:20,806 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4318778375784556, 'Total loss': 0.4318778375784556} | train loss {'Reaction outcome loss': 0.29085750314984876, 'Total loss': 0.29085750314984876}
2023-01-05 10:53:20,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:20,807 INFO:     Epoch: 76
2023-01-05 10:53:22,899 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4463108827670415, 'Total loss': 0.4463108827670415} | train loss {'Reaction outcome loss': 0.2881661471740825, 'Total loss': 0.2881661471740825}
2023-01-05 10:53:22,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:22,899 INFO:     Epoch: 77
2023-01-05 10:53:25,008 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4380460172891617, 'Total loss': 0.4380460172891617} | train loss {'Reaction outcome loss': 0.2846211011174822, 'Total loss': 0.2846211011174822}
2023-01-05 10:53:25,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:25,009 INFO:     Epoch: 78
2023-01-05 10:53:27,130 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46139381527900697, 'Total loss': 0.46139381527900697} | train loss {'Reaction outcome loss': 0.27939555346693873, 'Total loss': 0.27939555346693873}
2023-01-05 10:53:27,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:27,131 INFO:     Epoch: 79
2023-01-05 10:53:29,218 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4735665857791901, 'Total loss': 0.4735665857791901} | train loss {'Reaction outcome loss': 0.2837269432761156, 'Total loss': 0.2837269432761156}
2023-01-05 10:53:29,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:29,218 INFO:     Epoch: 80
2023-01-05 10:53:31,352 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4327233970165253, 'Total loss': 0.4327233970165253} | train loss {'Reaction outcome loss': 0.28580078286166394, 'Total loss': 0.28580078286166394}
2023-01-05 10:53:31,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:31,353 INFO:     Epoch: 81
2023-01-05 10:53:33,467 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4545378545920054, 'Total loss': 0.4545378545920054} | train loss {'Reaction outcome loss': 0.2785649919189023, 'Total loss': 0.2785649919189023}
2023-01-05 10:53:33,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:33,468 INFO:     Epoch: 82
2023-01-05 10:53:35,589 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43131925761699674, 'Total loss': 0.43131925761699674} | train loss {'Reaction outcome loss': 0.2774776660966395, 'Total loss': 0.2774776660966395}
2023-01-05 10:53:35,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:35,589 INFO:     Epoch: 83
2023-01-05 10:53:37,729 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4427724500497182, 'Total loss': 0.4427724500497182} | train loss {'Reaction outcome loss': 0.277903267936985, 'Total loss': 0.277903267936985}
2023-01-05 10:53:37,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:37,729 INFO:     Epoch: 84
2023-01-05 10:53:39,878 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.427629229426384, 'Total loss': 0.427629229426384} | train loss {'Reaction outcome loss': 0.27851111305891163, 'Total loss': 0.27851111305891163}
2023-01-05 10:53:39,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:39,879 INFO:     Epoch: 85
2023-01-05 10:53:41,998 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40925283630688986, 'Total loss': 0.40925283630688986} | train loss {'Reaction outcome loss': 0.27351067264829454, 'Total loss': 0.27351067264829454}
2023-01-05 10:53:41,999 INFO:     Found new best model at epoch 85
2023-01-05 10:53:42,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:42,000 INFO:     Epoch: 86
2023-01-05 10:53:44,117 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4189484139283498, 'Total loss': 0.4189484139283498} | train loss {'Reaction outcome loss': 0.2712365360318744, 'Total loss': 0.2712365360318744}
2023-01-05 10:53:44,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:44,118 INFO:     Epoch: 87
2023-01-05 10:53:46,223 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4211043288310369, 'Total loss': 0.4211043288310369} | train loss {'Reaction outcome loss': 0.26676664631949726, 'Total loss': 0.26676664631949726}
2023-01-05 10:53:46,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:46,223 INFO:     Epoch: 88
2023-01-05 10:53:48,360 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4534392446279526, 'Total loss': 0.4534392446279526} | train loss {'Reaction outcome loss': 0.2667098765934471, 'Total loss': 0.2667098765934471}
2023-01-05 10:53:48,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:48,361 INFO:     Epoch: 89
2023-01-05 10:53:50,507 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4336866875489553, 'Total loss': 0.4336866875489553} | train loss {'Reaction outcome loss': 0.26854575237082523, 'Total loss': 0.26854575237082523}
2023-01-05 10:53:50,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:50,508 INFO:     Epoch: 90
2023-01-05 10:53:52,642 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4493944048881531, 'Total loss': 0.4493944048881531} | train loss {'Reaction outcome loss': 0.2705583206316742, 'Total loss': 0.2705583206316742}
2023-01-05 10:53:52,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:52,643 INFO:     Epoch: 91
2023-01-05 10:53:54,773 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40129814197619756, 'Total loss': 0.40129814197619756} | train loss {'Reaction outcome loss': 0.2675557678606171, 'Total loss': 0.2675557678606171}
2023-01-05 10:53:54,774 INFO:     Found new best model at epoch 91
2023-01-05 10:53:54,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:54,775 INFO:     Epoch: 92
2023-01-05 10:53:56,917 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4473124176263809, 'Total loss': 0.4473124176263809} | train loss {'Reaction outcome loss': 0.2639944327886414, 'Total loss': 0.2639944327886414}
2023-01-05 10:53:56,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:56,918 INFO:     Epoch: 93
2023-01-05 10:53:59,049 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46810746292273203, 'Total loss': 0.46810746292273203} | train loss {'Reaction outcome loss': 0.2631787736050404, 'Total loss': 0.2631787736050404}
2023-01-05 10:53:59,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:53:59,049 INFO:     Epoch: 94
2023-01-05 10:54:01,188 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43025841216246286, 'Total loss': 0.43025841216246286} | train loss {'Reaction outcome loss': 0.2610688211165205, 'Total loss': 0.2610688211165205}
2023-01-05 10:54:01,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:01,188 INFO:     Epoch: 95
2023-01-05 10:54:03,296 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4114341994126638, 'Total loss': 0.4114341994126638} | train loss {'Reaction outcome loss': 0.26169609147919354, 'Total loss': 0.26169609147919354}
2023-01-05 10:54:03,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:03,296 INFO:     Epoch: 96
2023-01-05 10:54:05,211 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4270076538125674, 'Total loss': 0.4270076538125674} | train loss {'Reaction outcome loss': 0.25394868871101933, 'Total loss': 0.25394868871101933}
2023-01-05 10:54:05,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:05,212 INFO:     Epoch: 97
2023-01-05 10:54:07,344 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44991545875867206, 'Total loss': 0.44991545875867206} | train loss {'Reaction outcome loss': 0.2602182813804515, 'Total loss': 0.2602182813804515}
2023-01-05 10:54:07,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:07,345 INFO:     Epoch: 98
2023-01-05 10:54:09,441 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4093066691265752, 'Total loss': 0.4093066691265752} | train loss {'Reaction outcome loss': 0.2546813741095201, 'Total loss': 0.2546813741095201}
2023-01-05 10:54:09,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:09,442 INFO:     Epoch: 99
2023-01-05 10:54:11,538 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4361231764157613, 'Total loss': 0.4361231764157613} | train loss {'Reaction outcome loss': 0.25421156371896064, 'Total loss': 0.25421156371896064}
2023-01-05 10:54:11,538 INFO:     Best model found after epoch 92 of 100.
2023-01-05 10:54:11,538 INFO:   Done with stage: TRAINING
2023-01-05 10:54:11,538 INFO:   Starting stage: EVALUATION
2023-01-05 10:54:11,676 INFO:   Done with stage: EVALUATION
2023-01-05 10:54:11,676 INFO:   Leaving out SEQ value Fold_4
2023-01-05 10:54:11,689 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 10:54:11,689 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:54:12,330 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:54:12,330 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:54:12,399 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:54:12,400 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:54:12,400 INFO:     No hyperparam tuning for this model
2023-01-05 10:54:12,400 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:54:12,400 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:54:12,400 INFO:     None feature selector for col prot
2023-01-05 10:54:12,401 INFO:     None feature selector for col prot
2023-01-05 10:54:12,401 INFO:     None feature selector for col prot
2023-01-05 10:54:12,401 INFO:     None feature selector for col chem
2023-01-05 10:54:12,401 INFO:     None feature selector for col chem
2023-01-05 10:54:12,401 INFO:     None feature selector for col chem
2023-01-05 10:54:12,401 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:54:12,401 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:54:12,403 INFO:     Number of params in model 72901
2023-01-05 10:54:12,406 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:54:12,406 INFO:   Starting stage: TRAINING
2023-01-05 10:54:12,467 INFO:     Val loss before train {'Reaction outcome loss': 1.05351212422053, 'Total loss': 1.05351212422053}
2023-01-05 10:54:12,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:12,468 INFO:     Epoch: 0
2023-01-05 10:54:14,617 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8467413544654846, 'Total loss': 0.8467413544654846} | train loss {'Reaction outcome loss': 0.9282984280067942, 'Total loss': 0.9282984280067942}
2023-01-05 10:54:14,617 INFO:     Found new best model at epoch 0
2023-01-05 10:54:14,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:14,618 INFO:     Epoch: 1
2023-01-05 10:54:16,742 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6205810030301412, 'Total loss': 0.6205810030301412} | train loss {'Reaction outcome loss': 0.7401855237296094, 'Total loss': 0.7401855237296094}
2023-01-05 10:54:16,743 INFO:     Found new best model at epoch 1
2023-01-05 10:54:16,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:16,745 INFO:     Epoch: 2
2023-01-05 10:54:18,863 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4964434504508972, 'Total loss': 0.4964434504508972} | train loss {'Reaction outcome loss': 0.6123658735035122, 'Total loss': 0.6123658735035122}
2023-01-05 10:54:18,863 INFO:     Found new best model at epoch 2
2023-01-05 10:54:18,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:18,864 INFO:     Epoch: 3
2023-01-05 10:54:20,986 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4448850353558858, 'Total loss': 0.4448850353558858} | train loss {'Reaction outcome loss': 0.5608765330913045, 'Total loss': 0.5608765330913045}
2023-01-05 10:54:20,986 INFO:     Found new best model at epoch 3
2023-01-05 10:54:20,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:20,987 INFO:     Epoch: 4
2023-01-05 10:54:23,115 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5073473989963532, 'Total loss': 0.5073473989963532} | train loss {'Reaction outcome loss': 0.5262541968537413, 'Total loss': 0.5262541968537413}
2023-01-05 10:54:23,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:23,116 INFO:     Epoch: 5
2023-01-05 10:54:25,239 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44804060260454814, 'Total loss': 0.44804060260454814} | train loss {'Reaction outcome loss': 0.5221273735438919, 'Total loss': 0.5221273735438919}
2023-01-05 10:54:25,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:25,239 INFO:     Epoch: 6
2023-01-05 10:54:27,360 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4573000689347585, 'Total loss': 0.4573000689347585} | train loss {'Reaction outcome loss': 0.5230218343220759, 'Total loss': 0.5230218343220759}
2023-01-05 10:54:27,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:27,360 INFO:     Epoch: 7
2023-01-05 10:54:29,479 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45111506084601083, 'Total loss': 0.45111506084601083} | train loss {'Reaction outcome loss': 0.49297862362953415, 'Total loss': 0.49297862362953415}
2023-01-05 10:54:29,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:29,480 INFO:     Epoch: 8
2023-01-05 10:54:31,603 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47317272822062173, 'Total loss': 0.47317272822062173} | train loss {'Reaction outcome loss': 0.48402491766382416, 'Total loss': 0.48402491766382416}
2023-01-05 10:54:31,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:31,604 INFO:     Epoch: 9
2023-01-05 10:54:33,743 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4352194905281067, 'Total loss': 0.4352194905281067} | train loss {'Reaction outcome loss': 0.48233159096992534, 'Total loss': 0.48233159096992534}
2023-01-05 10:54:33,743 INFO:     Found new best model at epoch 9
2023-01-05 10:54:33,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:33,745 INFO:     Epoch: 10
2023-01-05 10:54:35,885 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4719229315718015, 'Total loss': 0.4719229315718015} | train loss {'Reaction outcome loss': 0.48240493783943245, 'Total loss': 0.48240493783943245}
2023-01-05 10:54:35,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:35,885 INFO:     Epoch: 11
2023-01-05 10:54:38,015 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3973050018151601, 'Total loss': 0.3973050018151601} | train loss {'Reaction outcome loss': 0.4682027328391627, 'Total loss': 0.4682027328391627}
2023-01-05 10:54:38,015 INFO:     Found new best model at epoch 11
2023-01-05 10:54:38,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:38,016 INFO:     Epoch: 12
2023-01-05 10:54:40,142 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.452705259124438, 'Total loss': 0.452705259124438} | train loss {'Reaction outcome loss': 0.46591302306404797, 'Total loss': 0.46591302306404797}
2023-01-05 10:54:40,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:40,142 INFO:     Epoch: 13
2023-01-05 10:54:42,278 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44491874873638154, 'Total loss': 0.44491874873638154} | train loss {'Reaction outcome loss': 0.47213632683607115, 'Total loss': 0.47213632683607115}
2023-01-05 10:54:42,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:42,279 INFO:     Epoch: 14
2023-01-05 10:54:44,395 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4397523760795593, 'Total loss': 0.4397523760795593} | train loss {'Reaction outcome loss': 0.47612958754146256, 'Total loss': 0.47612958754146256}
2023-01-05 10:54:44,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:44,396 INFO:     Epoch: 15
2023-01-05 10:54:46,537 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4065422942241033, 'Total loss': 0.4065422942241033} | train loss {'Reaction outcome loss': 0.4497922052615795, 'Total loss': 0.4497922052615795}
2023-01-05 10:54:46,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:46,538 INFO:     Epoch: 16
2023-01-05 10:54:48,678 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42514252265294394, 'Total loss': 0.42514252265294394} | train loss {'Reaction outcome loss': 0.4542507963133571, 'Total loss': 0.4542507963133571}
2023-01-05 10:54:48,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:48,679 INFO:     Epoch: 17
2023-01-05 10:54:50,818 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4001358653108279, 'Total loss': 0.4001358653108279} | train loss {'Reaction outcome loss': 0.44916448833933775, 'Total loss': 0.44916448833933775}
2023-01-05 10:54:50,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:50,819 INFO:     Epoch: 18
2023-01-05 10:54:52,944 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44730110963185626, 'Total loss': 0.44730110963185626} | train loss {'Reaction outcome loss': 0.4545871518768262, 'Total loss': 0.4545871518768262}
2023-01-05 10:54:52,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:52,944 INFO:     Epoch: 19
2023-01-05 10:54:55,062 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42585706611474355, 'Total loss': 0.42585706611474355} | train loss {'Reaction outcome loss': 0.44388706812281703, 'Total loss': 0.44388706812281703}
2023-01-05 10:54:55,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:55,062 INFO:     Epoch: 20
2023-01-05 10:54:57,190 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40258809030056, 'Total loss': 0.40258809030056} | train loss {'Reaction outcome loss': 0.43169476216038066, 'Total loss': 0.43169476216038066}
2023-01-05 10:54:57,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:57,190 INFO:     Epoch: 21
2023-01-05 10:54:59,320 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45527986288070676, 'Total loss': 0.45527986288070676} | train loss {'Reaction outcome loss': 0.44075341387719347, 'Total loss': 0.44075341387719347}
2023-01-05 10:54:59,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:54:59,320 INFO:     Epoch: 22
2023-01-05 10:55:01,442 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42564568122227986, 'Total loss': 0.42564568122227986} | train loss {'Reaction outcome loss': 0.49315020660667314, 'Total loss': 0.49315020660667314}
2023-01-05 10:55:01,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:01,442 INFO:     Epoch: 23
2023-01-05 10:55:03,594 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.398371950785319, 'Total loss': 0.398371950785319} | train loss {'Reaction outcome loss': 0.42914722241265985, 'Total loss': 0.42914722241265985}
2023-01-05 10:55:03,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:03,595 INFO:     Epoch: 24
2023-01-05 10:55:05,718 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38051810761292776, 'Total loss': 0.38051810761292776} | train loss {'Reaction outcome loss': 0.42431130416799284, 'Total loss': 0.42431130416799284}
2023-01-05 10:55:05,719 INFO:     Found new best model at epoch 24
2023-01-05 10:55:05,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:05,720 INFO:     Epoch: 25
2023-01-05 10:55:07,856 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4874424159526825, 'Total loss': 0.4874424159526825} | train loss {'Reaction outcome loss': 0.42561736451866833, 'Total loss': 0.42561736451866833}
2023-01-05 10:55:07,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:07,857 INFO:     Epoch: 26
2023-01-05 10:55:09,998 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4656801501909892, 'Total loss': 0.4656801501909892} | train loss {'Reaction outcome loss': 0.4662362868911114, 'Total loss': 0.4662362868911114}
2023-01-05 10:55:09,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:09,998 INFO:     Epoch: 27
2023-01-05 10:55:12,146 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3930697778860728, 'Total loss': 0.3930697778860728} | train loss {'Reaction outcome loss': 0.4511443663201214, 'Total loss': 0.4511443663201214}
2023-01-05 10:55:12,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:12,147 INFO:     Epoch: 28
2023-01-05 10:55:14,293 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3846518248319626, 'Total loss': 0.3846518248319626} | train loss {'Reaction outcome loss': 0.41094460565110913, 'Total loss': 0.41094460565110913}
2023-01-05 10:55:14,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:14,294 INFO:     Epoch: 29
2023-01-05 10:55:16,419 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38370020886262257, 'Total loss': 0.38370020886262257} | train loss {'Reaction outcome loss': 0.40448024188526027, 'Total loss': 0.40448024188526027}
2023-01-05 10:55:16,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:16,419 INFO:     Epoch: 30
2023-01-05 10:55:18,560 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4047214885552724, 'Total loss': 0.4047214885552724} | train loss {'Reaction outcome loss': 0.399157532133108, 'Total loss': 0.399157532133108}
2023-01-05 10:55:18,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:18,560 INFO:     Epoch: 31
2023-01-05 10:55:20,684 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37671613891919453, 'Total loss': 0.37671613891919453} | train loss {'Reaction outcome loss': 0.3947665089879698, 'Total loss': 0.3947665089879698}
2023-01-05 10:55:20,685 INFO:     Found new best model at epoch 31
2023-01-05 10:55:20,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:20,686 INFO:     Epoch: 32
2023-01-05 10:55:22,824 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3838955779870351, 'Total loss': 0.3838955779870351} | train loss {'Reaction outcome loss': 0.3878913223779291, 'Total loss': 0.3878913223779291}
2023-01-05 10:55:22,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:22,824 INFO:     Epoch: 33
2023-01-05 10:55:24,962 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40338901778062186, 'Total loss': 0.40338901778062186} | train loss {'Reaction outcome loss': 0.3852859934238528, 'Total loss': 0.3852859934238528}
2023-01-05 10:55:24,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:24,963 INFO:     Epoch: 34
2023-01-05 10:55:27,094 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3502176493406296, 'Total loss': 0.3502176493406296} | train loss {'Reaction outcome loss': 0.3832061671098505, 'Total loss': 0.3832061671098505}
2023-01-05 10:55:27,095 INFO:     Found new best model at epoch 34
2023-01-05 10:55:27,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:27,096 INFO:     Epoch: 35
2023-01-05 10:55:29,226 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3485196530818939, 'Total loss': 0.3485196530818939} | train loss {'Reaction outcome loss': 0.3825597057827205, 'Total loss': 0.3825597057827205}
2023-01-05 10:55:29,226 INFO:     Found new best model at epoch 35
2023-01-05 10:55:29,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:29,227 INFO:     Epoch: 36
2023-01-05 10:55:31,378 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3795172280321519, 'Total loss': 0.3795172280321519} | train loss {'Reaction outcome loss': 0.39675926271340123, 'Total loss': 0.39675926271340123}
2023-01-05 10:55:31,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:31,378 INFO:     Epoch: 37
2023-01-05 10:55:33,506 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3822209199269613, 'Total loss': 0.3822209199269613} | train loss {'Reaction outcome loss': 0.4106537151307313, 'Total loss': 0.4106537151307313}
2023-01-05 10:55:33,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:33,506 INFO:     Epoch: 38
2023-01-05 10:55:35,644 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38118366052707037, 'Total loss': 0.38118366052707037} | train loss {'Reaction outcome loss': 0.3786139362284988, 'Total loss': 0.3786139362284988}
2023-01-05 10:55:35,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:35,644 INFO:     Epoch: 39
2023-01-05 10:55:37,785 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38866169353326163, 'Total loss': 0.38866169353326163} | train loss {'Reaction outcome loss': 0.3671343674667288, 'Total loss': 0.3671343674667288}
2023-01-05 10:55:37,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:37,785 INFO:     Epoch: 40
2023-01-05 10:55:39,919 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38041239480177563, 'Total loss': 0.38041239480177563} | train loss {'Reaction outcome loss': 0.37584768322066986, 'Total loss': 0.37584768322066986}
2023-01-05 10:55:39,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:39,920 INFO:     Epoch: 41
2023-01-05 10:55:42,047 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4129668176174164, 'Total loss': 0.4129668176174164} | train loss {'Reaction outcome loss': 0.38872036189380765, 'Total loss': 0.38872036189380765}
2023-01-05 10:55:42,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:42,047 INFO:     Epoch: 42
2023-01-05 10:55:44,185 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36812762866417564, 'Total loss': 0.36812762866417564} | train loss {'Reaction outcome loss': 0.3724609295824084, 'Total loss': 0.3724609295824084}
2023-01-05 10:55:44,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:44,185 INFO:     Epoch: 43
2023-01-05 10:55:46,335 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36317281424999237, 'Total loss': 0.36317281424999237} | train loss {'Reaction outcome loss': 0.36149424239588174, 'Total loss': 0.36149424239588174}
2023-01-05 10:55:46,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:46,336 INFO:     Epoch: 44
2023-01-05 10:55:48,479 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39199909567832947, 'Total loss': 0.39199909567832947} | train loss {'Reaction outcome loss': 0.3593610614247998, 'Total loss': 0.3593610614247998}
2023-01-05 10:55:48,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:48,479 INFO:     Epoch: 45
2023-01-05 10:55:50,604 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3662354161341985, 'Total loss': 0.3662354161341985} | train loss {'Reaction outcome loss': 0.3553919640788186, 'Total loss': 0.3553919640788186}
2023-01-05 10:55:50,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:50,604 INFO:     Epoch: 46
2023-01-05 10:55:52,716 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41133066912492117, 'Total loss': 0.41133066912492117} | train loss {'Reaction outcome loss': 0.3479858792637495, 'Total loss': 0.3479858792637495}
2023-01-05 10:55:52,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:52,716 INFO:     Epoch: 47
2023-01-05 10:55:54,835 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36190823117891946, 'Total loss': 0.36190823117891946} | train loss {'Reaction outcome loss': 0.3489407370458745, 'Total loss': 0.3489407370458745}
2023-01-05 10:55:54,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:54,835 INFO:     Epoch: 48
2023-01-05 10:55:57,001 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37611109813054405, 'Total loss': 0.37611109813054405} | train loss {'Reaction outcome loss': 0.3478876486339647, 'Total loss': 0.3478876486339647}
2023-01-05 10:55:57,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:57,002 INFO:     Epoch: 49
2023-01-05 10:55:59,174 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35577316482861837, 'Total loss': 0.35577316482861837} | train loss {'Reaction outcome loss': 0.34132684053843876, 'Total loss': 0.34132684053843876}
2023-01-05 10:55:59,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:55:59,174 INFO:     Epoch: 50
2023-01-05 10:56:01,294 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38784152269363403, 'Total loss': 0.38784152269363403} | train loss {'Reaction outcome loss': 0.3362239210248884, 'Total loss': 0.3362239210248884}
2023-01-05 10:56:01,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:01,295 INFO:     Epoch: 51
2023-01-05 10:56:03,411 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40402578314145404, 'Total loss': 0.40402578314145404} | train loss {'Reaction outcome loss': 0.3393614231676295, 'Total loss': 0.3393614231676295}
2023-01-05 10:56:03,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:03,412 INFO:     Epoch: 52
2023-01-05 10:56:05,541 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3716165741284688, 'Total loss': 0.3716165741284688} | train loss {'Reaction outcome loss': 0.34514163122714864, 'Total loss': 0.34514163122714864}
2023-01-05 10:56:05,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:05,541 INFO:     Epoch: 53
2023-01-05 10:56:07,669 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35138013660907746, 'Total loss': 0.35138013660907746} | train loss {'Reaction outcome loss': 0.3342923494526168, 'Total loss': 0.3342923494526168}
2023-01-05 10:56:07,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:07,669 INFO:     Epoch: 54
2023-01-05 10:56:09,798 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.366848790148894, 'Total loss': 0.366848790148894} | train loss {'Reaction outcome loss': 0.3346236965794494, 'Total loss': 0.3346236965794494}
2023-01-05 10:56:09,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:09,799 INFO:     Epoch: 55
2023-01-05 10:56:11,908 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35880854924519856, 'Total loss': 0.35880854924519856} | train loss {'Reaction outcome loss': 0.3603846971080571, 'Total loss': 0.3603846971080571}
2023-01-05 10:56:11,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:11,908 INFO:     Epoch: 56
2023-01-05 10:56:14,054 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3650203362107277, 'Total loss': 0.3650203362107277} | train loss {'Reaction outcome loss': 0.32265066723946645, 'Total loss': 0.32265066723946645}
2023-01-05 10:56:14,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:14,055 INFO:     Epoch: 57
2023-01-05 10:56:16,178 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37811194906632106, 'Total loss': 0.37811194906632106} | train loss {'Reaction outcome loss': 0.32321710913084395, 'Total loss': 0.32321710913084395}
2023-01-05 10:56:16,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:16,179 INFO:     Epoch: 58
2023-01-05 10:56:18,319 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40388172467549643, 'Total loss': 0.40388172467549643} | train loss {'Reaction outcome loss': 0.31331094876741583, 'Total loss': 0.31331094876741583}
2023-01-05 10:56:18,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:18,320 INFO:     Epoch: 59
2023-01-05 10:56:20,453 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37180460890134176, 'Total loss': 0.37180460890134176} | train loss {'Reaction outcome loss': 0.31980921748175245, 'Total loss': 0.31980921748175245}
2023-01-05 10:56:20,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:20,453 INFO:     Epoch: 60
2023-01-05 10:56:22,578 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3788180594642957, 'Total loss': 0.3788180594642957} | train loss {'Reaction outcome loss': 0.31157759802991297, 'Total loss': 0.31157759802991297}
2023-01-05 10:56:22,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:22,578 INFO:     Epoch: 61
2023-01-05 10:56:24,707 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3990794102350871, 'Total loss': 0.3990794102350871} | train loss {'Reaction outcome loss': 0.3086949387285605, 'Total loss': 0.3086949387285605}
2023-01-05 10:56:24,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:24,708 INFO:     Epoch: 62
2023-01-05 10:56:26,845 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41095155142247675, 'Total loss': 0.41095155142247675} | train loss {'Reaction outcome loss': 0.31234244458239013, 'Total loss': 0.31234244458239013}
2023-01-05 10:56:26,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:26,845 INFO:     Epoch: 63
2023-01-05 10:56:28,983 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36797939439614613, 'Total loss': 0.36797939439614613} | train loss {'Reaction outcome loss': 0.30765397142386064, 'Total loss': 0.30765397142386064}
2023-01-05 10:56:28,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:28,983 INFO:     Epoch: 64
2023-01-05 10:56:31,083 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37447996785243354, 'Total loss': 0.37447996785243354} | train loss {'Reaction outcome loss': 0.3048850532570108, 'Total loss': 0.3048850532570108}
2023-01-05 10:56:31,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:31,083 INFO:     Epoch: 65
2023-01-05 10:56:33,204 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3952751745780309, 'Total loss': 0.3952751745780309} | train loss {'Reaction outcome loss': 0.2945137663467693, 'Total loss': 0.2945137663467693}
2023-01-05 10:56:33,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:33,205 INFO:     Epoch: 66
2023-01-05 10:56:35,390 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3717704584201177, 'Total loss': 0.3717704584201177} | train loss {'Reaction outcome loss': 0.30353926843552315, 'Total loss': 0.30353926843552315}
2023-01-05 10:56:35,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:35,391 INFO:     Epoch: 67
2023-01-05 10:56:37,490 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3772280583779017, 'Total loss': 0.3772280583779017} | train loss {'Reaction outcome loss': 0.29525264011285995, 'Total loss': 0.29525264011285995}
2023-01-05 10:56:37,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:37,490 INFO:     Epoch: 68
2023-01-05 10:56:39,652 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3408189202348391, 'Total loss': 0.3408189202348391} | train loss {'Reaction outcome loss': 0.30307800547756336, 'Total loss': 0.30307800547756336}
2023-01-05 10:56:39,652 INFO:     Found new best model at epoch 68
2023-01-05 10:56:39,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:39,654 INFO:     Epoch: 69
2023-01-05 10:56:41,805 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37392191141843795, 'Total loss': 0.37392191141843795} | train loss {'Reaction outcome loss': 0.2876186740476692, 'Total loss': 0.2876186740476692}
2023-01-05 10:56:41,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:41,806 INFO:     Epoch: 70
2023-01-05 10:56:43,934 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37546641727288566, 'Total loss': 0.37546641727288566} | train loss {'Reaction outcome loss': 0.29573167696614383, 'Total loss': 0.29573167696614383}
2023-01-05 10:56:43,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:43,934 INFO:     Epoch: 71
2023-01-05 10:56:46,079 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3578120008111, 'Total loss': 0.3578120008111} | train loss {'Reaction outcome loss': 0.2957082803146424, 'Total loss': 0.2957082803146424}
2023-01-05 10:56:46,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:46,079 INFO:     Epoch: 72
2023-01-05 10:56:48,229 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.380504409968853, 'Total loss': 0.380504409968853} | train loss {'Reaction outcome loss': 0.31511880308929563, 'Total loss': 0.31511880308929563}
2023-01-05 10:56:48,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:48,229 INFO:     Epoch: 73
2023-01-05 10:56:50,355 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.351729886730512, 'Total loss': 0.351729886730512} | train loss {'Reaction outcome loss': 0.2862553356613532, 'Total loss': 0.2862553356613532}
2023-01-05 10:56:50,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:50,355 INFO:     Epoch: 74
2023-01-05 10:56:52,460 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34390199432770413, 'Total loss': 0.34390199432770413} | train loss {'Reaction outcome loss': 0.28279494371373154, 'Total loss': 0.28279494371373154}
2023-01-05 10:56:52,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:52,461 INFO:     Epoch: 75
2023-01-05 10:56:54,617 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3546808689832687, 'Total loss': 0.3546808689832687} | train loss {'Reaction outcome loss': 0.28239259456345084, 'Total loss': 0.28239259456345084}
2023-01-05 10:56:54,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:54,618 INFO:     Epoch: 76
2023-01-05 10:56:56,708 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4253493696451187, 'Total loss': 0.4253493696451187} | train loss {'Reaction outcome loss': 0.2792459502443439, 'Total loss': 0.2792459502443439}
2023-01-05 10:56:56,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:56,708 INFO:     Epoch: 77
2023-01-05 10:56:58,843 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3398386364181836, 'Total loss': 0.3398386364181836} | train loss {'Reaction outcome loss': 0.27915668445538083, 'Total loss': 0.27915668445538083}
2023-01-05 10:56:58,843 INFO:     Found new best model at epoch 77
2023-01-05 10:56:58,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:56:58,844 INFO:     Epoch: 78
2023-01-05 10:57:00,976 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38608407775561016, 'Total loss': 0.38608407775561016} | train loss {'Reaction outcome loss': 0.28173298881143716, 'Total loss': 0.28173298881143716}
2023-01-05 10:57:00,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:00,976 INFO:     Epoch: 79
2023-01-05 10:57:03,121 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3445967415968577, 'Total loss': 0.3445967415968577} | train loss {'Reaction outcome loss': 0.27561669031865016, 'Total loss': 0.27561669031865016}
2023-01-05 10:57:03,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:03,122 INFO:     Epoch: 80
2023-01-05 10:57:05,248 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3037851999203364, 'Total loss': 0.3037851999203364} | train loss {'Reaction outcome loss': 0.2776888345597663, 'Total loss': 0.2776888345597663}
2023-01-05 10:57:05,248 INFO:     Found new best model at epoch 80
2023-01-05 10:57:05,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:05,249 INFO:     Epoch: 81
2023-01-05 10:57:07,361 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.34475602954626083, 'Total loss': 0.34475602954626083} | train loss {'Reaction outcome loss': 0.27612697997471475, 'Total loss': 0.27612697997471475}
2023-01-05 10:57:07,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:07,361 INFO:     Epoch: 82
2023-01-05 10:57:09,479 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3165881002942721, 'Total loss': 0.3165881002942721} | train loss {'Reaction outcome loss': 0.26755004972084495, 'Total loss': 0.26755004972084495}
2023-01-05 10:57:09,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:09,480 INFO:     Epoch: 83
2023-01-05 10:57:11,617 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35123604933420816, 'Total loss': 0.35123604933420816} | train loss {'Reaction outcome loss': 0.2759425357771102, 'Total loss': 0.2759425357771102}
2023-01-05 10:57:11,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:11,617 INFO:     Epoch: 84
2023-01-05 10:57:13,797 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3507889439662298, 'Total loss': 0.3507889439662298} | train loss {'Reaction outcome loss': 0.2716786870353288, 'Total loss': 0.2716786870353288}
2023-01-05 10:57:13,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:13,797 INFO:     Epoch: 85
2023-01-05 10:57:15,950 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.338831486304601, 'Total loss': 0.338831486304601} | train loss {'Reaction outcome loss': 0.2686098081640143, 'Total loss': 0.2686098081640143}
2023-01-05 10:57:15,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:15,950 INFO:     Epoch: 86
2023-01-05 10:57:18,090 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3463498090704282, 'Total loss': 0.3463498090704282} | train loss {'Reaction outcome loss': 0.26005070419405063, 'Total loss': 0.26005070419405063}
2023-01-05 10:57:18,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:18,090 INFO:     Epoch: 87
2023-01-05 10:57:20,236 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3500202792386214, 'Total loss': 0.3500202792386214} | train loss {'Reaction outcome loss': 0.2646723007562906, 'Total loss': 0.2646723007562906}
2023-01-05 10:57:20,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:20,237 INFO:     Epoch: 88
2023-01-05 10:57:22,371 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4252463012933731, 'Total loss': 0.4252463012933731} | train loss {'Reaction outcome loss': 0.2578976068213798, 'Total loss': 0.2578976068213798}
2023-01-05 10:57:22,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:22,372 INFO:     Epoch: 89
2023-01-05 10:57:24,498 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4184573580821355, 'Total loss': 0.4184573580821355} | train loss {'Reaction outcome loss': 0.2594813385411449, 'Total loss': 0.2594813385411449}
2023-01-05 10:57:24,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:24,498 INFO:     Epoch: 90
2023-01-05 10:57:26,605 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3412411540746689, 'Total loss': 0.3412411540746689} | train loss {'Reaction outcome loss': 0.2848657210209016, 'Total loss': 0.2848657210209016}
2023-01-05 10:57:26,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:26,605 INFO:     Epoch: 91
2023-01-05 10:57:28,744 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3148622443278631, 'Total loss': 0.3148622443278631} | train loss {'Reaction outcome loss': 0.26613764750747604, 'Total loss': 0.26613764750747604}
2023-01-05 10:57:28,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:28,744 INFO:     Epoch: 92
2023-01-05 10:57:30,862 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3492377042770386, 'Total loss': 0.3492377042770386} | train loss {'Reaction outcome loss': 0.2566150258872253, 'Total loss': 0.2566150258872253}
2023-01-05 10:57:30,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:30,863 INFO:     Epoch: 93
2023-01-05 10:57:32,984 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3388866394758224, 'Total loss': 0.3388866394758224} | train loss {'Reaction outcome loss': 0.261508568773802, 'Total loss': 0.261508568773802}
2023-01-05 10:57:32,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:32,985 INFO:     Epoch: 94
2023-01-05 10:57:35,098 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36752209862073265, 'Total loss': 0.36752209862073265} | train loss {'Reaction outcome loss': 0.2493859333242627, 'Total loss': 0.2493859333242627}
2023-01-05 10:57:35,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:35,098 INFO:     Epoch: 95
2023-01-05 10:57:37,229 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.31669351235032084, 'Total loss': 0.31669351235032084} | train loss {'Reaction outcome loss': 0.2561847924677051, 'Total loss': 0.2561847924677051}
2023-01-05 10:57:37,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:37,229 INFO:     Epoch: 96
2023-01-05 10:57:39,375 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37518708109855653, 'Total loss': 0.37518708109855653} | train loss {'Reaction outcome loss': 0.25177217092688964, 'Total loss': 0.25177217092688964}
2023-01-05 10:57:39,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:39,376 INFO:     Epoch: 97
2023-01-05 10:57:41,492 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3579961488644282, 'Total loss': 0.3579961488644282} | train loss {'Reaction outcome loss': 0.2534418119272838, 'Total loss': 0.2534418119272838}
2023-01-05 10:57:41,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:41,492 INFO:     Epoch: 98
2023-01-05 10:57:43,640 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.35653727998336154, 'Total loss': 0.35653727998336154} | train loss {'Reaction outcome loss': 0.24719273807895134, 'Total loss': 0.24719273807895134}
2023-01-05 10:57:43,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:43,640 INFO:     Epoch: 99
2023-01-05 10:57:45,797 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3937158892552058, 'Total loss': 0.3937158892552058} | train loss {'Reaction outcome loss': 0.2464180102814799, 'Total loss': 0.2464180102814799}
2023-01-05 10:57:45,798 INFO:     Best model found after epoch 81 of 100.
2023-01-05 10:57:45,798 INFO:   Done with stage: TRAINING
2023-01-05 10:57:45,798 INFO:   Starting stage: EVALUATION
2023-01-05 10:57:45,931 INFO:   Done with stage: EVALUATION
2023-01-05 10:57:45,931 INFO:   Leaving out SEQ value Fold_5
2023-01-05 10:57:45,943 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 10:57:45,943 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:57:46,593 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:57:46,594 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:57:46,662 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:57:46,662 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:57:46,663 INFO:     No hyperparam tuning for this model
2023-01-05 10:57:46,663 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:57:46,663 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:57:46,663 INFO:     None feature selector for col prot
2023-01-05 10:57:46,663 INFO:     None feature selector for col prot
2023-01-05 10:57:46,664 INFO:     None feature selector for col prot
2023-01-05 10:57:46,664 INFO:     None feature selector for col chem
2023-01-05 10:57:46,664 INFO:     None feature selector for col chem
2023-01-05 10:57:46,664 INFO:     None feature selector for col chem
2023-01-05 10:57:46,664 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:57:46,664 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:57:46,666 INFO:     Number of params in model 72901
2023-01-05 10:57:46,669 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:57:46,669 INFO:   Starting stage: TRAINING
2023-01-05 10:57:46,728 INFO:     Val loss before train {'Reaction outcome loss': 0.8378256301085154, 'Total loss': 0.8378256301085154}
2023-01-05 10:57:46,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:46,728 INFO:     Epoch: 0
2023-01-05 10:57:48,858 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.727689015865326, 'Total loss': 0.727689015865326} | train loss {'Reaction outcome loss': 0.9498761748148646, 'Total loss': 0.9498761748148646}
2023-01-05 10:57:48,858 INFO:     Found new best model at epoch 0
2023-01-05 10:57:48,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:48,859 INFO:     Epoch: 1
2023-01-05 10:57:50,973 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5731907069683075, 'Total loss': 0.5731907069683075} | train loss {'Reaction outcome loss': 0.7710785995967121, 'Total loss': 0.7710785995967121}
2023-01-05 10:57:50,973 INFO:     Found new best model at epoch 1
2023-01-05 10:57:50,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:50,974 INFO:     Epoch: 2
2023-01-05 10:57:53,092 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44414910674095154, 'Total loss': 0.44414910674095154} | train loss {'Reaction outcome loss': 0.5803479037452691, 'Total loss': 0.5803479037452691}
2023-01-05 10:57:53,092 INFO:     Found new best model at epoch 2
2023-01-05 10:57:53,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:53,093 INFO:     Epoch: 3
2023-01-05 10:57:55,232 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4552756945292155, 'Total loss': 0.4552756945292155} | train loss {'Reaction outcome loss': 0.5348537423335258, 'Total loss': 0.5348537423335258}
2023-01-05 10:57:55,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:55,233 INFO:     Epoch: 4
2023-01-05 10:57:57,354 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44221792817115785, 'Total loss': 0.44221792817115785} | train loss {'Reaction outcome loss': 0.5225731695494497, 'Total loss': 0.5225731695494497}
2023-01-05 10:57:57,354 INFO:     Found new best model at epoch 4
2023-01-05 10:57:57,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:57,355 INFO:     Epoch: 5
2023-01-05 10:57:59,493 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41933104197184246, 'Total loss': 0.41933104197184246} | train loss {'Reaction outcome loss': 0.5015202384132771, 'Total loss': 0.5015202384132771}
2023-01-05 10:57:59,493 INFO:     Found new best model at epoch 5
2023-01-05 10:57:59,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:57:59,495 INFO:     Epoch: 6
2023-01-05 10:58:01,628 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43995973070462546, 'Total loss': 0.43995973070462546} | train loss {'Reaction outcome loss': 0.49125422924649415, 'Total loss': 0.49125422924649415}
2023-01-05 10:58:01,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:01,628 INFO:     Epoch: 7
2023-01-05 10:58:03,795 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.402770338455836, 'Total loss': 0.402770338455836} | train loss {'Reaction outcome loss': 0.48855677416501064, 'Total loss': 0.48855677416501064}
2023-01-05 10:58:03,795 INFO:     Found new best model at epoch 7
2023-01-05 10:58:03,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:03,796 INFO:     Epoch: 8
2023-01-05 10:58:05,719 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4168233791987101, 'Total loss': 0.4168233791987101} | train loss {'Reaction outcome loss': 0.47495587541308215, 'Total loss': 0.47495587541308215}
2023-01-05 10:58:05,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:05,719 INFO:     Epoch: 9
2023-01-05 10:58:07,856 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41264205475648247, 'Total loss': 0.41264205475648247} | train loss {'Reaction outcome loss': 0.4771593453006194, 'Total loss': 0.4771593453006194}
2023-01-05 10:58:07,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:07,856 INFO:     Epoch: 10
2023-01-05 10:58:09,989 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39471545616785686, 'Total loss': 0.39471545616785686} | train loss {'Reaction outcome loss': 0.47100450146929884, 'Total loss': 0.47100450146929884}
2023-01-05 10:58:09,989 INFO:     Found new best model at epoch 10
2023-01-05 10:58:09,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:09,991 INFO:     Epoch: 11
2023-01-05 10:58:12,131 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40037203431129453, 'Total loss': 0.40037203431129453} | train loss {'Reaction outcome loss': 0.4662463811868365, 'Total loss': 0.4662463811868365}
2023-01-05 10:58:12,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:12,132 INFO:     Epoch: 12
2023-01-05 10:58:14,276 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40863420367240905, 'Total loss': 0.40863420367240905} | train loss {'Reaction outcome loss': 0.4651568785901534, 'Total loss': 0.4651568785901534}
2023-01-05 10:58:14,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:14,277 INFO:     Epoch: 13
2023-01-05 10:58:16,390 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4047774334748586, 'Total loss': 0.4047774334748586} | train loss {'Reaction outcome loss': 0.4580424907835812, 'Total loss': 0.4580424907835812}
2023-01-05 10:58:16,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:16,391 INFO:     Epoch: 14
2023-01-05 10:58:18,528 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3922316402196884, 'Total loss': 0.3922316402196884} | train loss {'Reaction outcome loss': 0.457701479108325, 'Total loss': 0.457701479108325}
2023-01-05 10:58:18,529 INFO:     Found new best model at epoch 14
2023-01-05 10:58:18,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:18,530 INFO:     Epoch: 15
2023-01-05 10:58:20,648 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38190116981665295, 'Total loss': 0.38190116981665295} | train loss {'Reaction outcome loss': 0.4491507993331885, 'Total loss': 0.4491507993331885}
2023-01-05 10:58:20,648 INFO:     Found new best model at epoch 15
2023-01-05 10:58:20,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:20,649 INFO:     Epoch: 16
2023-01-05 10:58:22,807 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4062586724758148, 'Total loss': 0.4062586724758148} | train loss {'Reaction outcome loss': 0.4446703171364237, 'Total loss': 0.4446703171364237}
2023-01-05 10:58:22,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:22,808 INFO:     Epoch: 17
2023-01-05 10:58:24,976 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39241864035526913, 'Total loss': 0.39241864035526913} | train loss {'Reaction outcome loss': 0.4463783106648965, 'Total loss': 0.4463783106648965}
2023-01-05 10:58:24,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:24,977 INFO:     Epoch: 18
2023-01-05 10:58:27,137 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38972493608792624, 'Total loss': 0.38972493608792624} | train loss {'Reaction outcome loss': 0.4395042324324377, 'Total loss': 0.4395042324324377}
2023-01-05 10:58:27,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:27,137 INFO:     Epoch: 19
2023-01-05 10:58:29,293 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.371199539800485, 'Total loss': 0.371199539800485} | train loss {'Reaction outcome loss': 0.43655803382719466, 'Total loss': 0.43655803382719466}
2023-01-05 10:58:29,293 INFO:     Found new best model at epoch 19
2023-01-05 10:58:29,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:29,294 INFO:     Epoch: 20
2023-01-05 10:58:31,464 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3745595177014669, 'Total loss': 0.3745595177014669} | train loss {'Reaction outcome loss': 0.43624157044323775, 'Total loss': 0.43624157044323775}
2023-01-05 10:58:31,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:31,464 INFO:     Epoch: 21
2023-01-05 10:58:33,606 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3759717722733816, 'Total loss': 0.3759717722733816} | train loss {'Reaction outcome loss': 0.4324103733154841, 'Total loss': 0.4324103733154841}
2023-01-05 10:58:33,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:33,607 INFO:     Epoch: 22
2023-01-05 10:58:35,740 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3782307704289754, 'Total loss': 0.3782307704289754} | train loss {'Reaction outcome loss': 0.4255063795225715, 'Total loss': 0.4255063795225715}
2023-01-05 10:58:35,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:35,741 INFO:     Epoch: 23
2023-01-05 10:58:37,856 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39562229116757713, 'Total loss': 0.39562229116757713} | train loss {'Reaction outcome loss': 0.4214261938626155, 'Total loss': 0.4214261938626155}
2023-01-05 10:58:37,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:37,856 INFO:     Epoch: 24
2023-01-05 10:58:40,009 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40103180408477784, 'Total loss': 0.40103180408477784} | train loss {'Reaction outcome loss': 0.419948089746792, 'Total loss': 0.419948089746792}
2023-01-05 10:58:40,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:40,009 INFO:     Epoch: 25
2023-01-05 10:58:42,133 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.389850523074468, 'Total loss': 0.389850523074468} | train loss {'Reaction outcome loss': 0.4166924296626115, 'Total loss': 0.4166924296626115}
2023-01-05 10:58:42,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:42,134 INFO:     Epoch: 26
2023-01-05 10:58:44,265 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38601118127504985, 'Total loss': 0.38601118127504985} | train loss {'Reaction outcome loss': 0.41448389343406317, 'Total loss': 0.41448389343406317}
2023-01-05 10:58:44,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:44,266 INFO:     Epoch: 27
2023-01-05 10:58:46,371 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39039368033409116, 'Total loss': 0.39039368033409116} | train loss {'Reaction outcome loss': 0.4116506765357854, 'Total loss': 0.4116506765357854}
2023-01-05 10:58:46,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:46,371 INFO:     Epoch: 28
2023-01-05 10:58:48,510 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38865424195925397, 'Total loss': 0.38865424195925397} | train loss {'Reaction outcome loss': 0.4086575391920895, 'Total loss': 0.4086575391920895}
2023-01-05 10:58:48,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:48,510 INFO:     Epoch: 29
2023-01-05 10:58:50,652 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37903291831413904, 'Total loss': 0.37903291831413904} | train loss {'Reaction outcome loss': 0.4089293829316697, 'Total loss': 0.4089293829316697}
2023-01-05 10:58:50,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:50,653 INFO:     Epoch: 30
2023-01-05 10:58:52,770 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4344094475110372, 'Total loss': 0.4344094475110372} | train loss {'Reaction outcome loss': 0.4011816477087, 'Total loss': 0.4011816477087}
2023-01-05 10:58:52,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:52,771 INFO:     Epoch: 31
2023-01-05 10:58:54,940 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3891422152519226, 'Total loss': 0.3891422152519226} | train loss {'Reaction outcome loss': 0.40048809626580145, 'Total loss': 0.40048809626580145}
2023-01-05 10:58:54,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:54,940 INFO:     Epoch: 32
2023-01-05 10:58:57,122 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3660800625880559, 'Total loss': 0.3660800625880559} | train loss {'Reaction outcome loss': 0.3964583458318392, 'Total loss': 0.3964583458318392}
2023-01-05 10:58:57,123 INFO:     Found new best model at epoch 32
2023-01-05 10:58:57,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:57,125 INFO:     Epoch: 33
2023-01-05 10:58:59,238 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36089092592398325, 'Total loss': 0.36089092592398325} | train loss {'Reaction outcome loss': 0.39133629689685706, 'Total loss': 0.39133629689685706}
2023-01-05 10:58:59,238 INFO:     Found new best model at epoch 33
2023-01-05 10:58:59,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:58:59,239 INFO:     Epoch: 34
2023-01-05 10:59:01,349 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39329515894254047, 'Total loss': 0.39329515894254047} | train loss {'Reaction outcome loss': 0.38602248174457776, 'Total loss': 0.38602248174457776}
2023-01-05 10:59:01,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:01,350 INFO:     Epoch: 35
2023-01-05 10:59:03,459 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37917384107907615, 'Total loss': 0.37917384107907615} | train loss {'Reaction outcome loss': 0.3851078255270147, 'Total loss': 0.3851078255270147}
2023-01-05 10:59:03,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:03,460 INFO:     Epoch: 36
2023-01-05 10:59:05,572 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38195047080516814, 'Total loss': 0.38195047080516814} | train loss {'Reaction outcome loss': 0.3777817721186132, 'Total loss': 0.3777817721186132}
2023-01-05 10:59:05,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:05,572 INFO:     Epoch: 37
2023-01-05 10:59:07,692 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38769163489341735, 'Total loss': 0.38769163489341735} | train loss {'Reaction outcome loss': 0.3755209314694043, 'Total loss': 0.3755209314694043}
2023-01-05 10:59:07,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:07,692 INFO:     Epoch: 38
2023-01-05 10:59:09,820 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3866744716962179, 'Total loss': 0.3866744716962179} | train loss {'Reaction outcome loss': 0.37726027701413156, 'Total loss': 0.37726027701413156}
2023-01-05 10:59:09,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:09,821 INFO:     Epoch: 39
2023-01-05 10:59:11,952 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3746812562147776, 'Total loss': 0.3746812562147776} | train loss {'Reaction outcome loss': 0.3722623073183242, 'Total loss': 0.3722623073183242}
2023-01-05 10:59:11,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:11,953 INFO:     Epoch: 40
2023-01-05 10:59:14,054 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39141419579585396, 'Total loss': 0.39141419579585396} | train loss {'Reaction outcome loss': 0.3657521258515141, 'Total loss': 0.3657521258515141}
2023-01-05 10:59:14,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:14,054 INFO:     Epoch: 41
2023-01-05 10:59:16,189 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3847591131925583, 'Total loss': 0.3847591131925583} | train loss {'Reaction outcome loss': 0.36164168905910604, 'Total loss': 0.36164168905910604}
2023-01-05 10:59:16,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:16,189 INFO:     Epoch: 42
2023-01-05 10:59:18,328 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3806787709395091, 'Total loss': 0.3806787709395091} | train loss {'Reaction outcome loss': 0.3549076947736611, 'Total loss': 0.3549076947736611}
2023-01-05 10:59:18,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:18,328 INFO:     Epoch: 43
2023-01-05 10:59:20,464 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37581295197208725, 'Total loss': 0.37581295197208725} | train loss {'Reaction outcome loss': 0.35350203081050935, 'Total loss': 0.35350203081050935}
2023-01-05 10:59:20,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:20,464 INFO:     Epoch: 44
2023-01-05 10:59:22,631 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3770563890536626, 'Total loss': 0.3770563890536626} | train loss {'Reaction outcome loss': 0.3514859331267405, 'Total loss': 0.3514859331267405}
2023-01-05 10:59:22,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:22,631 INFO:     Epoch: 45
2023-01-05 10:59:24,778 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3697666049003601, 'Total loss': 0.3697666049003601} | train loss {'Reaction outcome loss': 0.34983083995778635, 'Total loss': 0.34983083995778635}
2023-01-05 10:59:24,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:24,778 INFO:     Epoch: 46
2023-01-05 10:59:26,930 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36915361483891806, 'Total loss': 0.36915361483891806} | train loss {'Reaction outcome loss': 0.3469051782727672, 'Total loss': 0.3469051782727672}
2023-01-05 10:59:26,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:26,931 INFO:     Epoch: 47
2023-01-05 10:59:29,107 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36759509245554606, 'Total loss': 0.36759509245554606} | train loss {'Reaction outcome loss': 0.33800958715621315, 'Total loss': 0.33800958715621315}
2023-01-05 10:59:29,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:29,108 INFO:     Epoch: 48
2023-01-05 10:59:31,307 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37753457576036453, 'Total loss': 0.37753457576036453} | train loss {'Reaction outcome loss': 0.34151932823098524, 'Total loss': 0.34151932823098524}
2023-01-05 10:59:31,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:31,307 INFO:     Epoch: 49
2023-01-05 10:59:33,414 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40018050173918407, 'Total loss': 0.40018050173918407} | train loss {'Reaction outcome loss': 0.3363010245862851, 'Total loss': 0.3363010245862851}
2023-01-05 10:59:33,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:33,415 INFO:     Epoch: 50
2023-01-05 10:59:35,569 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3541310876607895, 'Total loss': 0.3541310876607895} | train loss {'Reaction outcome loss': 0.3318905227343528, 'Total loss': 0.3318905227343528}
2023-01-05 10:59:35,569 INFO:     Found new best model at epoch 50
2023-01-05 10:59:35,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:35,570 INFO:     Epoch: 51
2023-01-05 10:59:37,712 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35064800878365837, 'Total loss': 0.35064800878365837} | train loss {'Reaction outcome loss': 0.3314615896892892, 'Total loss': 0.3314615896892892}
2023-01-05 10:59:37,712 INFO:     Found new best model at epoch 51
2023-01-05 10:59:37,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:37,713 INFO:     Epoch: 52
2023-01-05 10:59:39,845 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38844133367141087, 'Total loss': 0.38844133367141087} | train loss {'Reaction outcome loss': 0.33298816262922565, 'Total loss': 0.33298816262922565}
2023-01-05 10:59:39,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:39,846 INFO:     Epoch: 53
2023-01-05 10:59:41,976 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3681381116310755, 'Total loss': 0.3681381116310755} | train loss {'Reaction outcome loss': 0.3251495119251499, 'Total loss': 0.3251495119251499}
2023-01-05 10:59:41,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:41,977 INFO:     Epoch: 54
2023-01-05 10:59:44,095 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36037777960300443, 'Total loss': 0.36037777960300443} | train loss {'Reaction outcome loss': 0.3232275440428231, 'Total loss': 0.3232275440428231}
2023-01-05 10:59:44,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:44,095 INFO:     Epoch: 55
2023-01-05 10:59:46,220 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36111581822236377, 'Total loss': 0.36111581822236377} | train loss {'Reaction outcome loss': 0.3174823618658721, 'Total loss': 0.3174823618658721}
2023-01-05 10:59:46,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:46,221 INFO:     Epoch: 56
2023-01-05 10:59:48,339 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3933878501256307, 'Total loss': 0.3933878501256307} | train loss {'Reaction outcome loss': 0.3167757222879449, 'Total loss': 0.3167757222879449}
2023-01-05 10:59:48,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:48,339 INFO:     Epoch: 57
2023-01-05 10:59:50,442 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.350978813568751, 'Total loss': 0.350978813568751} | train loss {'Reaction outcome loss': 0.3105419516052365, 'Total loss': 0.3105419516052365}
2023-01-05 10:59:50,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:50,442 INFO:     Epoch: 58
2023-01-05 10:59:52,568 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39197431604067484, 'Total loss': 0.39197431604067484} | train loss {'Reaction outcome loss': 0.31232974632552385, 'Total loss': 0.31232974632552385}
2023-01-05 10:59:52,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:52,568 INFO:     Epoch: 59
2023-01-05 10:59:54,657 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3715604096651077, 'Total loss': 0.3715604096651077} | train loss {'Reaction outcome loss': 0.30661738624910584, 'Total loss': 0.30661738624910584}
2023-01-05 10:59:54,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:54,657 INFO:     Epoch: 60
2023-01-05 10:59:56,810 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39238347311814625, 'Total loss': 0.39238347311814625} | train loss {'Reaction outcome loss': 0.30610543552665076, 'Total loss': 0.30610543552665076}
2023-01-05 10:59:56,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:56,811 INFO:     Epoch: 61
2023-01-05 10:59:58,958 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3542007873455683, 'Total loss': 0.3542007873455683} | train loss {'Reaction outcome loss': 0.3022490921648831, 'Total loss': 0.3022490921648831}
2023-01-05 10:59:58,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:59:58,958 INFO:     Epoch: 62
2023-01-05 11:00:01,113 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3724401205778122, 'Total loss': 0.3724401205778122} | train loss {'Reaction outcome loss': 0.30341709250523724, 'Total loss': 0.30341709250523724}
2023-01-05 11:00:01,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:01,113 INFO:     Epoch: 63
2023-01-05 11:00:03,207 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37809376219908397, 'Total loss': 0.37809376219908397} | train loss {'Reaction outcome loss': 0.3024071381571921, 'Total loss': 0.3024071381571921}
2023-01-05 11:00:03,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:03,208 INFO:     Epoch: 64
2023-01-05 11:00:05,314 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35900828341643015, 'Total loss': 0.35900828341643015} | train loss {'Reaction outcome loss': 0.2965801747428381, 'Total loss': 0.2965801747428381}
2023-01-05 11:00:05,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:05,314 INFO:     Epoch: 65
2023-01-05 11:00:07,437 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37523572022716206, 'Total loss': 0.37523572022716206} | train loss {'Reaction outcome loss': 0.2987700677560878, 'Total loss': 0.2987700677560878}
2023-01-05 11:00:07,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:07,438 INFO:     Epoch: 66
2023-01-05 11:00:09,568 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37742635707060496, 'Total loss': 0.37742635707060496} | train loss {'Reaction outcome loss': 0.2969486596271234, 'Total loss': 0.2969486596271234}
2023-01-05 11:00:09,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:09,568 INFO:     Epoch: 67
2023-01-05 11:00:11,692 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36781706909338635, 'Total loss': 0.36781706909338635} | train loss {'Reaction outcome loss': 0.2928479589279808, 'Total loss': 0.2928479589279808}
2023-01-05 11:00:11,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:11,693 INFO:     Epoch: 68
2023-01-05 11:00:13,711 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3842998631298542, 'Total loss': 0.3842998631298542} | train loss {'Reaction outcome loss': 0.2890976501043738, 'Total loss': 0.2890976501043738}
2023-01-05 11:00:13,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:13,711 INFO:     Epoch: 69
2023-01-05 11:00:15,498 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38719343741734824, 'Total loss': 0.38719343741734824} | train loss {'Reaction outcome loss': 0.28593705486950033, 'Total loss': 0.28593705486950033}
2023-01-05 11:00:15,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:15,498 INFO:     Epoch: 70
2023-01-05 11:00:17,151 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3965367883443832, 'Total loss': 0.3965367883443832} | train loss {'Reaction outcome loss': 0.2863585869058805, 'Total loss': 0.2863585869058805}
2023-01-05 11:00:17,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:17,151 INFO:     Epoch: 71
2023-01-05 11:00:18,872 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38558305203914645, 'Total loss': 0.38558305203914645} | train loss {'Reaction outcome loss': 0.286748146308781, 'Total loss': 0.286748146308781}
2023-01-05 11:00:18,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:18,872 INFO:     Epoch: 72
2023-01-05 11:00:20,624 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39017395079135897, 'Total loss': 0.39017395079135897} | train loss {'Reaction outcome loss': 0.280415941258415, 'Total loss': 0.280415941258415}
2023-01-05 11:00:20,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:20,624 INFO:     Epoch: 73
2023-01-05 11:00:22,716 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35419611384471256, 'Total loss': 0.35419611384471256} | train loss {'Reaction outcome loss': 0.27839691369434555, 'Total loss': 0.27839691369434555}
2023-01-05 11:00:22,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:22,717 INFO:     Epoch: 74
2023-01-05 11:00:24,896 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35633117308219275, 'Total loss': 0.35633117308219275} | train loss {'Reaction outcome loss': 0.2762851454855518, 'Total loss': 0.2762851454855518}
2023-01-05 11:00:24,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:24,896 INFO:     Epoch: 75
2023-01-05 11:00:27,058 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3910764500498772, 'Total loss': 0.3910764500498772} | train loss {'Reaction outcome loss': 0.27635853344890615, 'Total loss': 0.27635853344890615}
2023-01-05 11:00:27,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:27,059 INFO:     Epoch: 76
2023-01-05 11:00:29,200 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35724368542432783, 'Total loss': 0.35724368542432783} | train loss {'Reaction outcome loss': 0.2722668840082544, 'Total loss': 0.2722668840082544}
2023-01-05 11:00:29,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:29,201 INFO:     Epoch: 77
2023-01-05 11:00:31,370 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39413661460081734, 'Total loss': 0.39413661460081734} | train loss {'Reaction outcome loss': 0.2718311702624125, 'Total loss': 0.2718311702624125}
2023-01-05 11:00:31,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:31,370 INFO:     Epoch: 78
2023-01-05 11:00:33,562 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3937336136897405, 'Total loss': 0.3937336136897405} | train loss {'Reaction outcome loss': 0.2757012668176679, 'Total loss': 0.2757012668176679}
2023-01-05 11:00:33,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:33,563 INFO:     Epoch: 79
2023-01-05 11:00:35,751 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3830559551715851, 'Total loss': 0.3830559551715851} | train loss {'Reaction outcome loss': 0.26270430520284477, 'Total loss': 0.26270430520284477}
2023-01-05 11:00:35,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:35,751 INFO:     Epoch: 80
2023-01-05 11:00:37,917 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3613387922445933, 'Total loss': 0.3613387922445933} | train loss {'Reaction outcome loss': 0.2679248979241194, 'Total loss': 0.2679248979241194}
2023-01-05 11:00:37,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:37,917 INFO:     Epoch: 81
2023-01-05 11:00:40,103 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36360141734282175, 'Total loss': 0.36360141734282175} | train loss {'Reaction outcome loss': 0.2683443407181798, 'Total loss': 0.2683443407181798}
2023-01-05 11:00:40,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:40,104 INFO:     Epoch: 82
2023-01-05 11:00:42,236 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3695490539073944, 'Total loss': 0.3695490539073944} | train loss {'Reaction outcome loss': 0.2610617656435562, 'Total loss': 0.2610617656435562}
2023-01-05 11:00:42,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:42,236 INFO:     Epoch: 83
2023-01-05 11:00:44,369 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4194689015547434, 'Total loss': 0.4194689015547434} | train loss {'Reaction outcome loss': 0.25952168883560794, 'Total loss': 0.25952168883560794}
2023-01-05 11:00:44,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:44,369 INFO:     Epoch: 84
2023-01-05 11:00:46,546 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3944325198729833, 'Total loss': 0.3944325198729833} | train loss {'Reaction outcome loss': 0.26412636250768545, 'Total loss': 0.26412636250768545}
2023-01-05 11:00:46,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:46,546 INFO:     Epoch: 85
2023-01-05 11:00:48,666 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4349367986122767, 'Total loss': 0.4349367986122767} | train loss {'Reaction outcome loss': 0.2674054002106889, 'Total loss': 0.2674054002106889}
2023-01-05 11:00:48,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:48,666 INFO:     Epoch: 86
2023-01-05 11:00:50,831 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40061398843924206, 'Total loss': 0.40061398843924206} | train loss {'Reaction outcome loss': 0.262958008419413, 'Total loss': 0.262958008419413}
2023-01-05 11:00:50,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:50,831 INFO:     Epoch: 87
2023-01-05 11:00:52,968 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3993586053450902, 'Total loss': 0.3993586053450902} | train loss {'Reaction outcome loss': 0.2519805726027015, 'Total loss': 0.2519805726027015}
2023-01-05 11:00:52,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:52,969 INFO:     Epoch: 88
2023-01-05 11:00:55,099 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3981238702932994, 'Total loss': 0.3981238702932994} | train loss {'Reaction outcome loss': 0.2523442556752087, 'Total loss': 0.2523442556752087}
2023-01-05 11:00:55,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:55,099 INFO:     Epoch: 89
2023-01-05 11:00:57,221 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3574220637480418, 'Total loss': 0.3574220637480418} | train loss {'Reaction outcome loss': 0.2550056704894946, 'Total loss': 0.2550056704894946}
2023-01-05 11:00:57,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:57,221 INFO:     Epoch: 90
2023-01-05 11:00:59,345 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36669413521885874, 'Total loss': 0.36669413521885874} | train loss {'Reaction outcome loss': 0.2596045632641561, 'Total loss': 0.2596045632641561}
2023-01-05 11:00:59,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:00:59,345 INFO:     Epoch: 91
2023-01-05 11:01:01,473 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41032978693644206, 'Total loss': 0.41032978693644206} | train loss {'Reaction outcome loss': 0.25020662645409253, 'Total loss': 0.25020662645409253}
2023-01-05 11:01:01,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:01,474 INFO:     Epoch: 92
2023-01-05 11:01:03,600 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3812134693066279, 'Total loss': 0.3812134693066279} | train loss {'Reaction outcome loss': 0.25972895808383445, 'Total loss': 0.25972895808383445}
2023-01-05 11:01:03,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:03,600 INFO:     Epoch: 93
2023-01-05 11:01:05,722 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40741256475448606, 'Total loss': 0.40741256475448606} | train loss {'Reaction outcome loss': 0.25640340146712876, 'Total loss': 0.25640340146712876}
2023-01-05 11:01:05,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:05,722 INFO:     Epoch: 94
2023-01-05 11:01:07,846 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4189566299319267, 'Total loss': 0.4189566299319267} | train loss {'Reaction outcome loss': 0.25907899111186555, 'Total loss': 0.25907899111186555}
2023-01-05 11:01:07,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:07,847 INFO:     Epoch: 95
2023-01-05 11:01:09,994 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4149524082740148, 'Total loss': 0.4149524082740148} | train loss {'Reaction outcome loss': 0.25060712641595934, 'Total loss': 0.25060712641595934}
2023-01-05 11:01:09,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:09,995 INFO:     Epoch: 96
2023-01-05 11:01:12,147 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3773735205332438, 'Total loss': 0.3773735205332438} | train loss {'Reaction outcome loss': 0.24834844989143984, 'Total loss': 0.24834844989143984}
2023-01-05 11:01:12,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:12,148 INFO:     Epoch: 97
2023-01-05 11:01:14,302 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3992996633052826, 'Total loss': 0.3992996633052826} | train loss {'Reaction outcome loss': 0.2504085898937301, 'Total loss': 0.2504085898937301}
2023-01-05 11:01:14,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:14,302 INFO:     Epoch: 98
2023-01-05 11:01:16,457 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36240473290284475, 'Total loss': 0.36240473290284475} | train loss {'Reaction outcome loss': 0.24437063697738984, 'Total loss': 0.24437063697738984}
2023-01-05 11:01:16,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:16,458 INFO:     Epoch: 99
2023-01-05 11:01:18,622 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37498283286889394, 'Total loss': 0.37498283286889394} | train loss {'Reaction outcome loss': 0.24249907919215813, 'Total loss': 0.24249907919215813}
2023-01-05 11:01:18,623 INFO:     Best model found after epoch 52 of 100.
2023-01-05 11:01:18,623 INFO:   Done with stage: TRAINING
2023-01-05 11:01:18,623 INFO:   Starting stage: EVALUATION
2023-01-05 11:01:18,749 INFO:   Done with stage: EVALUATION
2023-01-05 11:01:18,749 INFO:   Leaving out SEQ value Fold_6
2023-01-05 11:01:18,761 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:01:18,761 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:01:19,405 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:01:19,406 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:01:19,474 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:01:19,474 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:01:19,474 INFO:     No hyperparam tuning for this model
2023-01-05 11:01:19,474 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:01:19,474 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:01:19,475 INFO:     None feature selector for col prot
2023-01-05 11:01:19,475 INFO:     None feature selector for col prot
2023-01-05 11:01:19,475 INFO:     None feature selector for col prot
2023-01-05 11:01:19,476 INFO:     None feature selector for col chem
2023-01-05 11:01:19,476 INFO:     None feature selector for col chem
2023-01-05 11:01:19,476 INFO:     None feature selector for col chem
2023-01-05 11:01:19,476 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:01:19,476 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:01:19,477 INFO:     Number of params in model 72901
2023-01-05 11:01:19,481 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:01:19,481 INFO:   Starting stage: TRAINING
2023-01-05 11:01:19,539 INFO:     Val loss before train {'Reaction outcome loss': 0.9312299648920696, 'Total loss': 0.9312299648920696}
2023-01-05 11:01:19,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:19,539 INFO:     Epoch: 0
2023-01-05 11:01:21,657 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7798705538113911, 'Total loss': 0.7798705538113911} | train loss {'Reaction outcome loss': 0.9334198166854191, 'Total loss': 0.9334198166854191}
2023-01-05 11:01:21,658 INFO:     Found new best model at epoch 0
2023-01-05 11:01:21,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:21,659 INFO:     Epoch: 1
2023-01-05 11:01:23,783 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5342863063017528, 'Total loss': 0.5342863063017528} | train loss {'Reaction outcome loss': 0.7259079490917443, 'Total loss': 0.7259079490917443}
2023-01-05 11:01:23,783 INFO:     Found new best model at epoch 1
2023-01-05 11:01:23,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:23,784 INFO:     Epoch: 2
2023-01-05 11:01:25,894 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4452195117870967, 'Total loss': 0.4452195117870967} | train loss {'Reaction outcome loss': 0.5788260919660547, 'Total loss': 0.5788260919660547}
2023-01-05 11:01:25,894 INFO:     Found new best model at epoch 2
2023-01-05 11:01:25,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:25,896 INFO:     Epoch: 3
2023-01-05 11:01:27,999 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45216177105903627, 'Total loss': 0.45216177105903627} | train loss {'Reaction outcome loss': 0.5292119564910005, 'Total loss': 0.5292119564910005}
2023-01-05 11:01:27,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:27,999 INFO:     Epoch: 4
2023-01-05 11:01:30,120 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.449790824453036, 'Total loss': 0.449790824453036} | train loss {'Reaction outcome loss': 0.5077739521099703, 'Total loss': 0.5077739521099703}
2023-01-05 11:01:30,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:30,121 INFO:     Epoch: 5
2023-01-05 11:01:32,240 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43471451103687286, 'Total loss': 0.43471451103687286} | train loss {'Reaction outcome loss': 0.4908498080216185, 'Total loss': 0.4908498080216185}
2023-01-05 11:01:32,240 INFO:     Found new best model at epoch 5
2023-01-05 11:01:32,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:32,242 INFO:     Epoch: 6
2023-01-05 11:01:34,367 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43151995639006296, 'Total loss': 0.43151995639006296} | train loss {'Reaction outcome loss': 0.4826938153183373, 'Total loss': 0.4826938153183373}
2023-01-05 11:01:34,367 INFO:     Found new best model at epoch 6
2023-01-05 11:01:34,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:34,369 INFO:     Epoch: 7
2023-01-05 11:01:36,508 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40962548553943634, 'Total loss': 0.40962548553943634} | train loss {'Reaction outcome loss': 0.4771958296425151, 'Total loss': 0.4771958296425151}
2023-01-05 11:01:36,508 INFO:     Found new best model at epoch 7
2023-01-05 11:01:36,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:36,510 INFO:     Epoch: 8
2023-01-05 11:01:38,629 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4529714862505595, 'Total loss': 0.4529714862505595} | train loss {'Reaction outcome loss': 0.4706475402969513, 'Total loss': 0.4706475402969513}
2023-01-05 11:01:38,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:38,629 INFO:     Epoch: 9
2023-01-05 11:01:40,759 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4143769900004069, 'Total loss': 0.4143769900004069} | train loss {'Reaction outcome loss': 0.466017594221082, 'Total loss': 0.466017594221082}
2023-01-05 11:01:40,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:40,761 INFO:     Epoch: 10
2023-01-05 11:01:42,876 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4067093620697657, 'Total loss': 0.4067093620697657} | train loss {'Reaction outcome loss': 0.4624152758369481, 'Total loss': 0.4624152758369481}
2023-01-05 11:01:42,876 INFO:     Found new best model at epoch 10
2023-01-05 11:01:42,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:42,878 INFO:     Epoch: 11
2023-01-05 11:01:45,029 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4237398475408554, 'Total loss': 0.4237398475408554} | train loss {'Reaction outcome loss': 0.45381275879858185, 'Total loss': 0.45381275879858185}
2023-01-05 11:01:45,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:45,029 INFO:     Epoch: 12
2023-01-05 11:01:47,159 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3915517459313075, 'Total loss': 0.3915517459313075} | train loss {'Reaction outcome loss': 0.44754985094505506, 'Total loss': 0.44754985094505506}
2023-01-05 11:01:47,160 INFO:     Found new best model at epoch 12
2023-01-05 11:01:47,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:47,161 INFO:     Epoch: 13
2023-01-05 11:01:49,295 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38800182143847145, 'Total loss': 0.38800182143847145} | train loss {'Reaction outcome loss': 0.4378867430517273, 'Total loss': 0.4378867430517273}
2023-01-05 11:01:49,295 INFO:     Found new best model at epoch 13
2023-01-05 11:01:49,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:49,297 INFO:     Epoch: 14
2023-01-05 11:01:51,423 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39212173024813335, 'Total loss': 0.39212173024813335} | train loss {'Reaction outcome loss': 0.4395267985434863, 'Total loss': 0.4395267985434863}
2023-01-05 11:01:51,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:51,424 INFO:     Epoch: 15
2023-01-05 11:01:53,552 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37610410451889037, 'Total loss': 0.37610410451889037} | train loss {'Reaction outcome loss': 0.43746499178835946, 'Total loss': 0.43746499178835946}
2023-01-05 11:01:53,552 INFO:     Found new best model at epoch 15
2023-01-05 11:01:53,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:53,554 INFO:     Epoch: 16
2023-01-05 11:01:55,667 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4092241436243057, 'Total loss': 0.4092241436243057} | train loss {'Reaction outcome loss': 0.4323310675303431, 'Total loss': 0.4323310675303431}
2023-01-05 11:01:55,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:55,667 INFO:     Epoch: 17
2023-01-05 11:01:57,782 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41857807636260985, 'Total loss': 0.41857807636260985} | train loss {'Reaction outcome loss': 0.4264742402754126, 'Total loss': 0.4264742402754126}
2023-01-05 11:01:57,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:57,782 INFO:     Epoch: 18
2023-01-05 11:01:59,878 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37243122855822247, 'Total loss': 0.37243122855822247} | train loss {'Reaction outcome loss': 0.4198480343622883, 'Total loss': 0.4198480343622883}
2023-01-05 11:01:59,879 INFO:     Found new best model at epoch 18
2023-01-05 11:01:59,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:01:59,880 INFO:     Epoch: 19
2023-01-05 11:02:01,895 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4006348460912704, 'Total loss': 0.4006348460912704} | train loss {'Reaction outcome loss': 0.4203327051261916, 'Total loss': 0.4203327051261916}
2023-01-05 11:02:01,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:01,896 INFO:     Epoch: 20
2023-01-05 11:02:03,865 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4201740245024363, 'Total loss': 0.4201740245024363} | train loss {'Reaction outcome loss': 0.40899670836481733, 'Total loss': 0.40899670836481733}
2023-01-05 11:02:03,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:03,865 INFO:     Epoch: 21
2023-01-05 11:02:06,003 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35838424662748974, 'Total loss': 0.35838424662748974} | train loss {'Reaction outcome loss': 0.41202321898763195, 'Total loss': 0.41202321898763195}
2023-01-05 11:02:06,003 INFO:     Found new best model at epoch 21
2023-01-05 11:02:06,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:06,004 INFO:     Epoch: 22
2023-01-05 11:02:08,122 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3644559199611346, 'Total loss': 0.3644559199611346} | train loss {'Reaction outcome loss': 0.40227799215455995, 'Total loss': 0.40227799215455995}
2023-01-05 11:02:08,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:08,123 INFO:     Epoch: 23
2023-01-05 11:02:10,217 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3934552103281021, 'Total loss': 0.3934552103281021} | train loss {'Reaction outcome loss': 0.39983751790693206, 'Total loss': 0.39983751790693206}
2023-01-05 11:02:10,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:10,218 INFO:     Epoch: 24
2023-01-05 11:02:12,322 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36670448978741965, 'Total loss': 0.36670448978741965} | train loss {'Reaction outcome loss': 0.3966297659560712, 'Total loss': 0.3966297659560712}
2023-01-05 11:02:12,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:12,322 INFO:     Epoch: 25
2023-01-05 11:02:14,437 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3769326721628507, 'Total loss': 0.3769326721628507} | train loss {'Reaction outcome loss': 0.39251578251158237, 'Total loss': 0.39251578251158237}
2023-01-05 11:02:14,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:14,438 INFO:     Epoch: 26
2023-01-05 11:02:16,568 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3723874181509018, 'Total loss': 0.3723874181509018} | train loss {'Reaction outcome loss': 0.38971344811202835, 'Total loss': 0.38971344811202835}
2023-01-05 11:02:16,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:16,569 INFO:     Epoch: 27
2023-01-05 11:02:18,687 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39231839378674827, 'Total loss': 0.39231839378674827} | train loss {'Reaction outcome loss': 0.3831219749294058, 'Total loss': 0.3831219749294058}
2023-01-05 11:02:18,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:18,687 INFO:     Epoch: 28
2023-01-05 11:02:20,792 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35994533002376555, 'Total loss': 0.35994533002376555} | train loss {'Reaction outcome loss': 0.385005320238806, 'Total loss': 0.385005320238806}
2023-01-05 11:02:20,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:20,793 INFO:     Epoch: 29
2023-01-05 11:02:22,898 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3814689159393311, 'Total loss': 0.3814689159393311} | train loss {'Reaction outcome loss': 0.37801360042534604, 'Total loss': 0.37801360042534604}
2023-01-05 11:02:22,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:22,898 INFO:     Epoch: 30
2023-01-05 11:02:25,005 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36074336667855583, 'Total loss': 0.36074336667855583} | train loss {'Reaction outcome loss': 0.37565292891142144, 'Total loss': 0.37565292891142144}
2023-01-05 11:02:25,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:25,006 INFO:     Epoch: 31
2023-01-05 11:02:27,154 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.34868027170499166, 'Total loss': 0.34868027170499166} | train loss {'Reaction outcome loss': 0.36669541027967945, 'Total loss': 0.36669541027967945}
2023-01-05 11:02:27,155 INFO:     Found new best model at epoch 31
2023-01-05 11:02:27,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:27,156 INFO:     Epoch: 32
2023-01-05 11:02:29,296 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3573273554444313, 'Total loss': 0.3573273554444313} | train loss {'Reaction outcome loss': 0.36941461515252605, 'Total loss': 0.36941461515252605}
2023-01-05 11:02:29,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:29,297 INFO:     Epoch: 33
2023-01-05 11:02:31,460 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3613916973272959, 'Total loss': 0.3613916973272959} | train loss {'Reaction outcome loss': 0.36832250975561837, 'Total loss': 0.36832250975561837}
2023-01-05 11:02:31,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:31,460 INFO:     Epoch: 34
2023-01-05 11:02:33,644 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.34084419409434, 'Total loss': 0.34084419409434} | train loss {'Reaction outcome loss': 0.3577065059955973, 'Total loss': 0.3577065059955973}
2023-01-05 11:02:33,644 INFO:     Found new best model at epoch 34
2023-01-05 11:02:33,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:33,645 INFO:     Epoch: 35
2023-01-05 11:02:35,838 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.34135501583417255, 'Total loss': 0.34135501583417255} | train loss {'Reaction outcome loss': 0.35941133977179107, 'Total loss': 0.35941133977179107}
2023-01-05 11:02:35,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:35,838 INFO:     Epoch: 36
2023-01-05 11:02:37,977 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3310772637526194, 'Total loss': 0.3310772637526194} | train loss {'Reaction outcome loss': 0.3543520736351718, 'Total loss': 0.3543520736351718}
2023-01-05 11:02:37,977 INFO:     Found new best model at epoch 36
2023-01-05 11:02:37,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:37,978 INFO:     Epoch: 37
2023-01-05 11:02:40,105 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3697733109196027, 'Total loss': 0.3697733109196027} | train loss {'Reaction outcome loss': 0.3482866331010404, 'Total loss': 0.3482866331010404}
2023-01-05 11:02:40,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:40,106 INFO:     Epoch: 38
2023-01-05 11:02:42,233 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36283134122689564, 'Total loss': 0.36283134122689564} | train loss {'Reaction outcome loss': 0.3473522102963315, 'Total loss': 0.3473522102963315}
2023-01-05 11:02:42,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:42,233 INFO:     Epoch: 39
2023-01-05 11:02:44,393 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.340801211198171, 'Total loss': 0.340801211198171} | train loss {'Reaction outcome loss': 0.34119803045135344, 'Total loss': 0.34119803045135344}
2023-01-05 11:02:44,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:44,393 INFO:     Epoch: 40
2023-01-05 11:02:46,548 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3640560204784075, 'Total loss': 0.3640560204784075} | train loss {'Reaction outcome loss': 0.34105084338871233, 'Total loss': 0.34105084338871233}
2023-01-05 11:02:46,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:46,549 INFO:     Epoch: 41
2023-01-05 11:02:48,670 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.33932292958100635, 'Total loss': 0.33932292958100635} | train loss {'Reaction outcome loss': 0.34156141786353433, 'Total loss': 0.34156141786353433}
2023-01-05 11:02:48,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:48,670 INFO:     Epoch: 42
2023-01-05 11:02:50,788 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36419510940710703, 'Total loss': 0.36419510940710703} | train loss {'Reaction outcome loss': 0.33209569073778433, 'Total loss': 0.33209569073778433}
2023-01-05 11:02:50,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:50,789 INFO:     Epoch: 43
2023-01-05 11:02:52,934 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3150618347028891, 'Total loss': 0.3150618347028891} | train loss {'Reaction outcome loss': 0.3380836539623076, 'Total loss': 0.3380836539623076}
2023-01-05 11:02:52,935 INFO:     Found new best model at epoch 43
2023-01-05 11:02:52,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:52,936 INFO:     Epoch: 44
2023-01-05 11:02:55,089 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3431912968556086, 'Total loss': 0.3431912968556086} | train loss {'Reaction outcome loss': 0.32206927887062087, 'Total loss': 0.32206927887062087}
2023-01-05 11:02:55,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:55,089 INFO:     Epoch: 45
2023-01-05 11:02:57,239 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.34688588281472527, 'Total loss': 0.34688588281472527} | train loss {'Reaction outcome loss': 0.3324115649137619, 'Total loss': 0.3324115649137619}
2023-01-05 11:02:57,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:57,240 INFO:     Epoch: 46
2023-01-05 11:02:59,389 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35815420548121135, 'Total loss': 0.35815420548121135} | train loss {'Reaction outcome loss': 0.32548833841009295, 'Total loss': 0.32548833841009295}
2023-01-05 11:02:59,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:02:59,389 INFO:     Epoch: 47
2023-01-05 11:03:01,494 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34049303382635115, 'Total loss': 0.34049303382635115} | train loss {'Reaction outcome loss': 0.3182054324089176, 'Total loss': 0.3182054324089176}
2023-01-05 11:03:01,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:01,495 INFO:     Epoch: 48
2023-01-05 11:03:03,616 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3292262233793736, 'Total loss': 0.3292262233793736} | train loss {'Reaction outcome loss': 0.3207844423714781, 'Total loss': 0.3207844423714781}
2023-01-05 11:03:03,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:03,616 INFO:     Epoch: 49
2023-01-05 11:03:05,747 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34896640876928964, 'Total loss': 0.34896640876928964} | train loss {'Reaction outcome loss': 0.314963218504495, 'Total loss': 0.314963218504495}
2023-01-05 11:03:05,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:05,748 INFO:     Epoch: 50
2023-01-05 11:03:07,885 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3407134860754013, 'Total loss': 0.3407134860754013} | train loss {'Reaction outcome loss': 0.31430488774539345, 'Total loss': 0.31430488774539345}
2023-01-05 11:03:07,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:07,886 INFO:     Epoch: 51
2023-01-05 11:03:09,985 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34604641298453015, 'Total loss': 0.34604641298453015} | train loss {'Reaction outcome loss': 0.31251465235530895, 'Total loss': 0.31251465235530895}
2023-01-05 11:03:09,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:09,986 INFO:     Epoch: 52
2023-01-05 11:03:12,084 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.33837233086427054, 'Total loss': 0.33837233086427054} | train loss {'Reaction outcome loss': 0.3145531839589133, 'Total loss': 0.3145531839589133}
2023-01-05 11:03:12,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:12,084 INFO:     Epoch: 53
2023-01-05 11:03:14,218 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36044356524944304, 'Total loss': 0.36044356524944304} | train loss {'Reaction outcome loss': 0.30693477908842753, 'Total loss': 0.30693477908842753}
2023-01-05 11:03:14,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:14,218 INFO:     Epoch: 54
2023-01-05 11:03:16,321 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3405977288881938, 'Total loss': 0.3405977288881938} | train loss {'Reaction outcome loss': 0.30311167115060084, 'Total loss': 0.30311167115060084}
2023-01-05 11:03:16,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:16,321 INFO:     Epoch: 55
2023-01-05 11:03:18,445 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3609062592188517, 'Total loss': 0.3609062592188517} | train loss {'Reaction outcome loss': 0.30465157660417747, 'Total loss': 0.30465157660417747}
2023-01-05 11:03:18,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:18,445 INFO:     Epoch: 56
2023-01-05 11:03:20,544 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.31611308579643566, 'Total loss': 0.31611308579643566} | train loss {'Reaction outcome loss': 0.29920422035629735, 'Total loss': 0.29920422035629735}
2023-01-05 11:03:20,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:20,545 INFO:     Epoch: 57
2023-01-05 11:03:22,688 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3368563920259476, 'Total loss': 0.3368563920259476} | train loss {'Reaction outcome loss': 0.2929325229522303, 'Total loss': 0.2929325229522303}
2023-01-05 11:03:22,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:22,689 INFO:     Epoch: 58
2023-01-05 11:03:24,804 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3517091363668442, 'Total loss': 0.3517091363668442} | train loss {'Reaction outcome loss': 0.2938976724271792, 'Total loss': 0.2938976724271792}
2023-01-05 11:03:24,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:24,804 INFO:     Epoch: 59
2023-01-05 11:03:26,925 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3732286791006724, 'Total loss': 0.3732286791006724} | train loss {'Reaction outcome loss': 0.2904819921270883, 'Total loss': 0.2904819921270883}
2023-01-05 11:03:26,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:26,926 INFO:     Epoch: 60
2023-01-05 11:03:29,058 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3320945866405964, 'Total loss': 0.3320945866405964} | train loss {'Reaction outcome loss': 0.29417236992259965, 'Total loss': 0.29417236992259965}
2023-01-05 11:03:29,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:29,059 INFO:     Epoch: 61
2023-01-05 11:03:31,175 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36660572588443757, 'Total loss': 0.36660572588443757} | train loss {'Reaction outcome loss': 0.2858858646512249, 'Total loss': 0.2858858646512249}
2023-01-05 11:03:31,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:31,176 INFO:     Epoch: 62
2023-01-05 11:03:33,295 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3453118771314621, 'Total loss': 0.3453118771314621} | train loss {'Reaction outcome loss': 0.2889868562674, 'Total loss': 0.2889868562674}
2023-01-05 11:03:33,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:33,295 INFO:     Epoch: 63
2023-01-05 11:03:35,438 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35854910016059877, 'Total loss': 0.35854910016059877} | train loss {'Reaction outcome loss': 0.28205968515036534, 'Total loss': 0.28205968515036534}
2023-01-05 11:03:35,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:35,438 INFO:     Epoch: 64
2023-01-05 11:03:37,566 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3182985949019591, 'Total loss': 0.3182985949019591} | train loss {'Reaction outcome loss': 0.28008387958372594, 'Total loss': 0.28008387958372594}
2023-01-05 11:03:37,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:37,567 INFO:     Epoch: 65
2023-01-05 11:03:39,682 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33411441147327425, 'Total loss': 0.33411441147327425} | train loss {'Reaction outcome loss': 0.2695985819301466, 'Total loss': 0.2695985819301466}
2023-01-05 11:03:39,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:39,682 INFO:     Epoch: 66
2023-01-05 11:03:41,830 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3599240561326345, 'Total loss': 0.3599240561326345} | train loss {'Reaction outcome loss': 0.27673803271222724, 'Total loss': 0.27673803271222724}
2023-01-05 11:03:41,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:41,831 INFO:     Epoch: 67
2023-01-05 11:03:43,945 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36771724273761114, 'Total loss': 0.36771724273761114} | train loss {'Reaction outcome loss': 0.2773549895135373, 'Total loss': 0.2773549895135373}
2023-01-05 11:03:43,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:43,945 INFO:     Epoch: 68
2023-01-05 11:03:46,087 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3302213410536448, 'Total loss': 0.3302213410536448} | train loss {'Reaction outcome loss': 0.27024666761068533, 'Total loss': 0.27024666761068533}
2023-01-05 11:03:46,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:46,087 INFO:     Epoch: 69
2023-01-05 11:03:48,204 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3744433790445328, 'Total loss': 0.3744433790445328} | train loss {'Reaction outcome loss': 0.26768365831039576, 'Total loss': 0.26768365831039576}
2023-01-05 11:03:48,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:48,204 INFO:     Epoch: 70
2023-01-05 11:03:50,338 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34181376695632937, 'Total loss': 0.34181376695632937} | train loss {'Reaction outcome loss': 0.26975889200086356, 'Total loss': 0.26975889200086356}
2023-01-05 11:03:50,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:50,338 INFO:     Epoch: 71
2023-01-05 11:03:52,437 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.33001258273919426, 'Total loss': 0.33001258273919426} | train loss {'Reaction outcome loss': 0.28491939815019607, 'Total loss': 0.28491939815019607}
2023-01-05 11:03:52,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:52,437 INFO:     Epoch: 72
2023-01-05 11:03:54,569 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3597321053345998, 'Total loss': 0.3597321053345998} | train loss {'Reaction outcome loss': 0.27639450235496255, 'Total loss': 0.27639450235496255}
2023-01-05 11:03:54,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:54,569 INFO:     Epoch: 73
2023-01-05 11:03:56,721 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3683114364743233, 'Total loss': 0.3683114364743233} | train loss {'Reaction outcome loss': 0.26275968970391, 'Total loss': 0.26275968970391}
2023-01-05 11:03:56,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:56,722 INFO:     Epoch: 74
2023-01-05 11:03:58,852 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3488359342018763, 'Total loss': 0.3488359342018763} | train loss {'Reaction outcome loss': 0.2688365707405075, 'Total loss': 0.2688365707405075}
2023-01-05 11:03:58,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:03:58,853 INFO:     Epoch: 75
2023-01-05 11:04:00,954 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3360870569944382, 'Total loss': 0.3360870569944382} | train loss {'Reaction outcome loss': 0.2749315197001735, 'Total loss': 0.2749315197001735}
2023-01-05 11:04:00,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:00,955 INFO:     Epoch: 76
2023-01-05 11:04:03,087 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35670370409886043, 'Total loss': 0.35670370409886043} | train loss {'Reaction outcome loss': 0.2709768237070228, 'Total loss': 0.2709768237070228}
2023-01-05 11:04:03,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:03,087 INFO:     Epoch: 77
2023-01-05 11:04:05,202 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3137844502925873, 'Total loss': 0.3137844502925873} | train loss {'Reaction outcome loss': 0.2626310324799405, 'Total loss': 0.2626310324799405}
2023-01-05 11:04:05,203 INFO:     Found new best model at epoch 77
2023-01-05 11:04:05,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:05,204 INFO:     Epoch: 78
2023-01-05 11:04:07,310 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3284654994805654, 'Total loss': 0.3284654994805654} | train loss {'Reaction outcome loss': 0.26376351190010344, 'Total loss': 0.26376351190010344}
2023-01-05 11:04:07,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:07,310 INFO:     Epoch: 79
2023-01-05 11:04:09,426 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.365037751942873, 'Total loss': 0.365037751942873} | train loss {'Reaction outcome loss': 0.2612016070294228, 'Total loss': 0.2612016070294228}
2023-01-05 11:04:09,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:09,426 INFO:     Epoch: 80
2023-01-05 11:04:11,538 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36402580539385476, 'Total loss': 0.36402580539385476} | train loss {'Reaction outcome loss': 0.26087233255596926, 'Total loss': 0.26087233255596926}
2023-01-05 11:04:11,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:11,538 INFO:     Epoch: 81
2023-01-05 11:04:13,657 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.32103854715824126, 'Total loss': 0.32103854715824126} | train loss {'Reaction outcome loss': 0.26053429348054374, 'Total loss': 0.26053429348054374}
2023-01-05 11:04:13,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:13,657 INFO:     Epoch: 82
2023-01-05 11:04:15,769 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3332908106346925, 'Total loss': 0.3332908106346925} | train loss {'Reaction outcome loss': 0.25967270887055754, 'Total loss': 0.25967270887055754}
2023-01-05 11:04:15,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:15,770 INFO:     Epoch: 83
2023-01-05 11:04:17,867 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3491829155633847, 'Total loss': 0.3491829155633847} | train loss {'Reaction outcome loss': 0.25681962828784094, 'Total loss': 0.25681962828784094}
2023-01-05 11:04:17,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:17,868 INFO:     Epoch: 84
2023-01-05 11:04:20,018 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3434590389331182, 'Total loss': 0.3434590389331182} | train loss {'Reaction outcome loss': 0.2532117970450951, 'Total loss': 0.2532117970450951}
2023-01-05 11:04:20,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:20,018 INFO:     Epoch: 85
2023-01-05 11:04:22,146 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3316589723030726, 'Total loss': 0.3316589723030726} | train loss {'Reaction outcome loss': 0.25468762622072094, 'Total loss': 0.25468762622072094}
2023-01-05 11:04:22,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:22,147 INFO:     Epoch: 86
2023-01-05 11:04:24,286 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3078187639514605, 'Total loss': 0.3078187639514605} | train loss {'Reaction outcome loss': 0.2553468201798897, 'Total loss': 0.2553468201798897}
2023-01-05 11:04:24,287 INFO:     Found new best model at epoch 86
2023-01-05 11:04:24,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:24,288 INFO:     Epoch: 87
2023-01-05 11:04:26,429 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3306948076623181, 'Total loss': 0.3306948076623181} | train loss {'Reaction outcome loss': 0.24554291786286084, 'Total loss': 0.24554291786286084}
2023-01-05 11:04:26,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:26,429 INFO:     Epoch: 88
2023-01-05 11:04:28,577 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3182957261800766, 'Total loss': 0.3182957261800766} | train loss {'Reaction outcome loss': 0.247931277535747, 'Total loss': 0.247931277535747}
2023-01-05 11:04:28,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:28,578 INFO:     Epoch: 89
2023-01-05 11:04:30,725 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3604679296414057, 'Total loss': 0.3604679296414057} | train loss {'Reaction outcome loss': 0.24604557871301896, 'Total loss': 0.24604557871301896}
2023-01-05 11:04:30,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:30,725 INFO:     Epoch: 90
2023-01-05 11:04:32,861 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.33698640912771227, 'Total loss': 0.33698640912771227} | train loss {'Reaction outcome loss': 0.24645314020968048, 'Total loss': 0.24645314020968048}
2023-01-05 11:04:32,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:32,861 INFO:     Epoch: 91
2023-01-05 11:04:34,983 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3358424499630928, 'Total loss': 0.3358424499630928} | train loss {'Reaction outcome loss': 0.25083872406016083, 'Total loss': 0.25083872406016083}
2023-01-05 11:04:34,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:34,984 INFO:     Epoch: 92
2023-01-05 11:04:37,124 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3417226493358612, 'Total loss': 0.3417226493358612} | train loss {'Reaction outcome loss': 0.251050068908473, 'Total loss': 0.251050068908473}
2023-01-05 11:04:37,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:37,125 INFO:     Epoch: 93
2023-01-05 11:04:39,264 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36441250940163933, 'Total loss': 0.36441250940163933} | train loss {'Reaction outcome loss': 0.24027768143853784, 'Total loss': 0.24027768143853784}
2023-01-05 11:04:39,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:39,264 INFO:     Epoch: 94
2023-01-05 11:04:41,387 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36499763280153275, 'Total loss': 0.36499763280153275} | train loss {'Reaction outcome loss': 0.24300165020310097, 'Total loss': 0.24300165020310097}
2023-01-05 11:04:41,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:41,387 INFO:     Epoch: 95
2023-01-05 11:04:43,527 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3500858853260676, 'Total loss': 0.3500858853260676} | train loss {'Reaction outcome loss': 0.2449596058033461, 'Total loss': 0.2449596058033461}
2023-01-05 11:04:43,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:43,527 INFO:     Epoch: 96
2023-01-05 11:04:45,688 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.33575958460569383, 'Total loss': 0.33575958460569383} | train loss {'Reaction outcome loss': 0.24572574415237364, 'Total loss': 0.24572574415237364}
2023-01-05 11:04:45,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:45,688 INFO:     Epoch: 97
2023-01-05 11:04:47,822 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.349946794907252, 'Total loss': 0.349946794907252} | train loss {'Reaction outcome loss': 0.243008686120819, 'Total loss': 0.243008686120819}
2023-01-05 11:04:47,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:47,822 INFO:     Epoch: 98
2023-01-05 11:04:49,962 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3284205385794242, 'Total loss': 0.3284205385794242} | train loss {'Reaction outcome loss': 0.2414514724518696, 'Total loss': 0.2414514724518696}
2023-01-05 11:04:49,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:49,962 INFO:     Epoch: 99
2023-01-05 11:04:52,109 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38530207574367525, 'Total loss': 0.38530207574367525} | train loss {'Reaction outcome loss': 0.23725494784540938, 'Total loss': 0.23725494784540938}
2023-01-05 11:04:52,109 INFO:     Best model found after epoch 87 of 100.
2023-01-05 11:04:52,109 INFO:   Done with stage: TRAINING
2023-01-05 11:04:52,109 INFO:   Starting stage: EVALUATION
2023-01-05 11:04:52,249 INFO:   Done with stage: EVALUATION
2023-01-05 11:04:52,249 INFO:   Leaving out SEQ value Fold_7
2023-01-05 11:04:52,261 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:04:52,261 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:04:52,901 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:04:52,901 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:04:52,970 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:04:52,970 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:04:52,970 INFO:     No hyperparam tuning for this model
2023-01-05 11:04:52,970 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:04:52,970 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:04:52,971 INFO:     None feature selector for col prot
2023-01-05 11:04:52,971 INFO:     None feature selector for col prot
2023-01-05 11:04:52,971 INFO:     None feature selector for col prot
2023-01-05 11:04:52,972 INFO:     None feature selector for col chem
2023-01-05 11:04:52,972 INFO:     None feature selector for col chem
2023-01-05 11:04:52,972 INFO:     None feature selector for col chem
2023-01-05 11:04:52,972 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:04:52,972 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:04:52,973 INFO:     Number of params in model 72901
2023-01-05 11:04:52,976 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:04:52,977 INFO:   Starting stage: TRAINING
2023-01-05 11:04:53,035 INFO:     Val loss before train {'Reaction outcome loss': 1.0550787289937338, 'Total loss': 1.0550787289937338}
2023-01-05 11:04:53,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:53,036 INFO:     Epoch: 0
2023-01-05 11:04:55,157 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8399099826812744, 'Total loss': 0.8399099826812744} | train loss {'Reaction outcome loss': 0.9071018399983427, 'Total loss': 0.9071018399983427}
2023-01-05 11:04:55,157 INFO:     Found new best model at epoch 0
2023-01-05 11:04:55,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:55,158 INFO:     Epoch: 1
2023-01-05 11:04:57,300 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6428122023741404, 'Total loss': 0.6428122023741404} | train loss {'Reaction outcome loss': 0.7174770866867399, 'Total loss': 0.7174770866867399}
2023-01-05 11:04:57,300 INFO:     Found new best model at epoch 1
2023-01-05 11:04:57,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:57,301 INFO:     Epoch: 2
2023-01-05 11:04:59,453 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5526458362738291, 'Total loss': 0.5526458362738291} | train loss {'Reaction outcome loss': 0.5814036868349479, 'Total loss': 0.5814036868349479}
2023-01-05 11:04:59,453 INFO:     Found new best model at epoch 2
2023-01-05 11:04:59,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:04:59,454 INFO:     Epoch: 3
2023-01-05 11:05:01,592 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5226637621720632, 'Total loss': 0.5226637621720632} | train loss {'Reaction outcome loss': 0.5281934543465175, 'Total loss': 0.5281934543465175}
2023-01-05 11:05:01,592 INFO:     Found new best model at epoch 3
2023-01-05 11:05:01,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:01,593 INFO:     Epoch: 4
2023-01-05 11:05:03,737 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.498973004023234, 'Total loss': 0.498973004023234} | train loss {'Reaction outcome loss': 0.5076042279383562, 'Total loss': 0.5076042279383562}
2023-01-05 11:05:03,738 INFO:     Found new best model at epoch 4
2023-01-05 11:05:03,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:03,739 INFO:     Epoch: 5
2023-01-05 11:05:05,885 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4990522036949793, 'Total loss': 0.4990522036949793} | train loss {'Reaction outcome loss': 0.49437005061955347, 'Total loss': 0.49437005061955347}
2023-01-05 11:05:05,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:05,886 INFO:     Epoch: 6
2023-01-05 11:05:07,991 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48704442580540974, 'Total loss': 0.48704442580540974} | train loss {'Reaction outcome loss': 0.4874700874525265, 'Total loss': 0.4874700874525265}
2023-01-05 11:05:07,991 INFO:     Found new best model at epoch 6
2023-01-05 11:05:07,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:07,993 INFO:     Epoch: 7
2023-01-05 11:05:10,115 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5128350665171941, 'Total loss': 0.5128350665171941} | train loss {'Reaction outcome loss': 0.48282625134626445, 'Total loss': 0.48282625134626445}
2023-01-05 11:05:10,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:10,115 INFO:     Epoch: 8
2023-01-05 11:05:12,210 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5005191783110301, 'Total loss': 0.5005191783110301} | train loss {'Reaction outcome loss': 0.47821874954622157, 'Total loss': 0.47821874954622157}
2023-01-05 11:05:12,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:12,211 INFO:     Epoch: 9
2023-01-05 11:05:14,313 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4896937708059947, 'Total loss': 0.4896937708059947} | train loss {'Reaction outcome loss': 0.47033333185597925, 'Total loss': 0.47033333185597925}
2023-01-05 11:05:14,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:14,313 INFO:     Epoch: 10
2023-01-05 11:05:16,431 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4901054392258326, 'Total loss': 0.4901054392258326} | train loss {'Reaction outcome loss': 0.46435388857430787, 'Total loss': 0.46435388857430787}
2023-01-05 11:05:16,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:16,431 INFO:     Epoch: 11
2023-01-05 11:05:18,554 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4622309774160385, 'Total loss': 0.4622309774160385} | train loss {'Reaction outcome loss': 0.4567436478542585, 'Total loss': 0.4567436478542585}
2023-01-05 11:05:18,555 INFO:     Found new best model at epoch 11
2023-01-05 11:05:18,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:18,556 INFO:     Epoch: 12
2023-01-05 11:05:20,639 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4771802465120951, 'Total loss': 0.4771802465120951} | train loss {'Reaction outcome loss': 0.4578538568568056, 'Total loss': 0.4578538568568056}
2023-01-05 11:05:20,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:20,639 INFO:     Epoch: 13
2023-01-05 11:05:22,743 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49162818491458893, 'Total loss': 0.49162818491458893} | train loss {'Reaction outcome loss': 0.4533777230412421, 'Total loss': 0.4533777230412421}
2023-01-05 11:05:22,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:22,743 INFO:     Epoch: 14
2023-01-05 11:05:24,845 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47776155968507134, 'Total loss': 0.47776155968507134} | train loss {'Reaction outcome loss': 0.44571707672337546, 'Total loss': 0.44571707672337546}
2023-01-05 11:05:24,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:24,846 INFO:     Epoch: 15
2023-01-05 11:05:26,969 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47209520936012267, 'Total loss': 0.47209520936012267} | train loss {'Reaction outcome loss': 0.4425547329885681, 'Total loss': 0.4425547329885681}
2023-01-05 11:05:26,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:26,969 INFO:     Epoch: 16
2023-01-05 11:05:29,080 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44130874077479043, 'Total loss': 0.44130874077479043} | train loss {'Reaction outcome loss': 0.43367165664251706, 'Total loss': 0.43367165664251706}
2023-01-05 11:05:29,080 INFO:     Found new best model at epoch 16
2023-01-05 11:05:29,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:29,081 INFO:     Epoch: 17
2023-01-05 11:05:31,184 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4694843967755636, 'Total loss': 0.4694843967755636} | train loss {'Reaction outcome loss': 0.43491115037650957, 'Total loss': 0.43491115037650957}
2023-01-05 11:05:31,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:31,184 INFO:     Epoch: 18
2023-01-05 11:05:33,316 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47531519333521527, 'Total loss': 0.47531519333521527} | train loss {'Reaction outcome loss': 0.4298092240236536, 'Total loss': 0.4298092240236536}
2023-01-05 11:05:33,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:33,316 INFO:     Epoch: 19
2023-01-05 11:05:35,449 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47062484323978426, 'Total loss': 0.47062484323978426} | train loss {'Reaction outcome loss': 0.424266538372005, 'Total loss': 0.424266538372005}
2023-01-05 11:05:35,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:35,450 INFO:     Epoch: 20
2023-01-05 11:05:37,566 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47656009495258334, 'Total loss': 0.47656009495258334} | train loss {'Reaction outcome loss': 0.41951997284471554, 'Total loss': 0.41951997284471554}
2023-01-05 11:05:37,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:37,566 INFO:     Epoch: 21
2023-01-05 11:05:39,661 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4712248891592026, 'Total loss': 0.4712248891592026} | train loss {'Reaction outcome loss': 0.42027906989202884, 'Total loss': 0.42027906989202884}
2023-01-05 11:05:39,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:39,661 INFO:     Epoch: 22
2023-01-05 11:05:41,807 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4824800213177999, 'Total loss': 0.4824800213177999} | train loss {'Reaction outcome loss': 0.4134576861767003, 'Total loss': 0.4134576861767003}
2023-01-05 11:05:41,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:41,808 INFO:     Epoch: 23
2023-01-05 11:05:43,945 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4481766988833745, 'Total loss': 0.4481766988833745} | train loss {'Reaction outcome loss': 0.4128328747231595, 'Total loss': 0.4128328747231595}
2023-01-05 11:05:43,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:43,945 INFO:     Epoch: 24
2023-01-05 11:05:46,030 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4505411684513092, 'Total loss': 0.4505411684513092} | train loss {'Reaction outcome loss': 0.4080623618333879, 'Total loss': 0.4080623618333879}
2023-01-05 11:05:46,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:46,030 INFO:     Epoch: 25
2023-01-05 11:05:48,128 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47714684506257377, 'Total loss': 0.47714684506257377} | train loss {'Reaction outcome loss': 0.4091591153049121, 'Total loss': 0.4091591153049121}
2023-01-05 11:05:48,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:48,129 INFO:     Epoch: 26
2023-01-05 11:05:50,229 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4709147612253825, 'Total loss': 0.4709147612253825} | train loss {'Reaction outcome loss': 0.3990571297106952, 'Total loss': 0.3990571297106952}
2023-01-05 11:05:50,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:50,230 INFO:     Epoch: 27
2023-01-05 11:05:52,329 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46399295926094053, 'Total loss': 0.46399295926094053} | train loss {'Reaction outcome loss': 0.3990064503176369, 'Total loss': 0.3990064503176369}
2023-01-05 11:05:52,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:52,329 INFO:     Epoch: 28
2023-01-05 11:05:54,421 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4827536861101786, 'Total loss': 0.4827536861101786} | train loss {'Reaction outcome loss': 0.3968597859905584, 'Total loss': 0.3968597859905584}
2023-01-05 11:05:54,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:54,422 INFO:     Epoch: 29
2023-01-05 11:05:56,518 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4713542799154917, 'Total loss': 0.4713542799154917} | train loss {'Reaction outcome loss': 0.39153553102247035, 'Total loss': 0.39153553102247035}
2023-01-05 11:05:56,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:56,518 INFO:     Epoch: 30
2023-01-05 11:05:58,626 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.454755973815918, 'Total loss': 0.454755973815918} | train loss {'Reaction outcome loss': 0.39129017725804427, 'Total loss': 0.39129017725804427}
2023-01-05 11:05:58,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:05:58,626 INFO:     Epoch: 31
2023-01-05 11:06:00,716 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42559940020243325, 'Total loss': 0.42559940020243325} | train loss {'Reaction outcome loss': 0.38241998916559844, 'Total loss': 0.38241998916559844}
2023-01-05 11:06:00,716 INFO:     Found new best model at epoch 31
2023-01-05 11:06:00,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:00,718 INFO:     Epoch: 32
2023-01-05 11:06:02,646 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45362870395183563, 'Total loss': 0.45362870395183563} | train loss {'Reaction outcome loss': 0.37940042520309014, 'Total loss': 0.37940042520309014}
2023-01-05 11:06:02,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:02,647 INFO:     Epoch: 33
2023-01-05 11:06:04,748 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48213608662287394, 'Total loss': 0.48213608662287394} | train loss {'Reaction outcome loss': 0.3713708849501436, 'Total loss': 0.3713708849501436}
2023-01-05 11:06:04,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:04,749 INFO:     Epoch: 34
2023-01-05 11:06:06,844 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4394627297918002, 'Total loss': 0.4394627297918002} | train loss {'Reaction outcome loss': 0.37609237388972816, 'Total loss': 0.37609237388972816}
2023-01-05 11:06:06,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:06,845 INFO:     Epoch: 35
2023-01-05 11:06:08,948 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47163069744904834, 'Total loss': 0.47163069744904834} | train loss {'Reaction outcome loss': 0.3722437616763976, 'Total loss': 0.3722437616763976}
2023-01-05 11:06:08,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:08,948 INFO:     Epoch: 36
2023-01-05 11:06:11,068 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4473811586697896, 'Total loss': 0.4473811586697896} | train loss {'Reaction outcome loss': 0.3712605965072221, 'Total loss': 0.3712605965072221}
2023-01-05 11:06:11,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:11,069 INFO:     Epoch: 37
2023-01-05 11:06:13,194 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4676733374595642, 'Total loss': 0.4676733374595642} | train loss {'Reaction outcome loss': 0.3639891563921514, 'Total loss': 0.3639891563921514}
2023-01-05 11:06:13,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:13,194 INFO:     Epoch: 38
2023-01-05 11:06:15,315 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4564753661553065, 'Total loss': 0.4564753661553065} | train loss {'Reaction outcome loss': 0.3637583055635438, 'Total loss': 0.3637583055635438}
2023-01-05 11:06:15,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:15,316 INFO:     Epoch: 39
2023-01-05 11:06:17,413 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46070773402849835, 'Total loss': 0.46070773402849835} | train loss {'Reaction outcome loss': 0.3601475443935742, 'Total loss': 0.3601475443935742}
2023-01-05 11:06:17,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:17,414 INFO:     Epoch: 40
2023-01-05 11:06:19,524 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4526432275772095, 'Total loss': 0.4526432275772095} | train loss {'Reaction outcome loss': 0.3615297068481463, 'Total loss': 0.3615297068481463}
2023-01-05 11:06:19,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:19,524 INFO:     Epoch: 41
2023-01-05 11:06:21,606 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43998566567897796, 'Total loss': 0.43998566567897796} | train loss {'Reaction outcome loss': 0.3490748612658821, 'Total loss': 0.3490748612658821}
2023-01-05 11:06:21,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:21,606 INFO:     Epoch: 42
2023-01-05 11:06:23,704 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45245721836884817, 'Total loss': 0.45245721836884817} | train loss {'Reaction outcome loss': 0.3518153837997548, 'Total loss': 0.3518153837997548}
2023-01-05 11:06:23,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:23,704 INFO:     Epoch: 43
2023-01-05 11:06:25,798 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45364458362261456, 'Total loss': 0.45364458362261456} | train loss {'Reaction outcome loss': 0.35156090927385064, 'Total loss': 0.35156090927385064}
2023-01-05 11:06:25,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:25,798 INFO:     Epoch: 44
2023-01-05 11:06:27,917 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43571333835522336, 'Total loss': 0.43571333835522336} | train loss {'Reaction outcome loss': 0.346948460397059, 'Total loss': 0.346948460397059}
2023-01-05 11:06:27,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:27,917 INFO:     Epoch: 45
2023-01-05 11:06:30,011 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4371797869602839, 'Total loss': 0.4371797869602839} | train loss {'Reaction outcome loss': 0.3415462518804265, 'Total loss': 0.3415462518804265}
2023-01-05 11:06:30,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:30,012 INFO:     Epoch: 46
2023-01-05 11:06:32,132 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4443319837252299, 'Total loss': 0.4443319837252299} | train loss {'Reaction outcome loss': 0.3392055542310224, 'Total loss': 0.3392055542310224}
2023-01-05 11:06:32,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:32,133 INFO:     Epoch: 47
2023-01-05 11:06:34,216 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44653220772743224, 'Total loss': 0.44653220772743224} | train loss {'Reaction outcome loss': 0.34328917515919594, 'Total loss': 0.34328917515919594}
2023-01-05 11:06:34,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:34,217 INFO:     Epoch: 48
2023-01-05 11:06:36,327 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39672249754269917, 'Total loss': 0.39672249754269917} | train loss {'Reaction outcome loss': 0.33124615379819905, 'Total loss': 0.33124615379819905}
2023-01-05 11:06:36,327 INFO:     Found new best model at epoch 48
2023-01-05 11:06:36,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:36,329 INFO:     Epoch: 49
2023-01-05 11:06:38,470 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4229123969872793, 'Total loss': 0.4229123969872793} | train loss {'Reaction outcome loss': 0.3360402988283521, 'Total loss': 0.3360402988283521}
2023-01-05 11:06:38,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:38,471 INFO:     Epoch: 50
2023-01-05 11:06:40,574 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44547395904858905, 'Total loss': 0.44547395904858905} | train loss {'Reaction outcome loss': 0.32591720104870137, 'Total loss': 0.32591720104870137}
2023-01-05 11:06:40,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:40,574 INFO:     Epoch: 51
2023-01-05 11:06:42,681 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45134964684645335, 'Total loss': 0.45134964684645335} | train loss {'Reaction outcome loss': 0.32679160439620053, 'Total loss': 0.32679160439620053}
2023-01-05 11:06:42,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:42,681 INFO:     Epoch: 52
2023-01-05 11:06:44,798 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4435086727142334, 'Total loss': 0.4435086727142334} | train loss {'Reaction outcome loss': 0.3201749148595072, 'Total loss': 0.3201749148595072}
2023-01-05 11:06:44,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:44,798 INFO:     Epoch: 53
2023-01-05 11:06:46,895 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43673302680253984, 'Total loss': 0.43673302680253984} | train loss {'Reaction outcome loss': 0.32442538022831846, 'Total loss': 0.32442538022831846}
2023-01-05 11:06:46,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:46,897 INFO:     Epoch: 54
2023-01-05 11:06:49,032 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48862353960673016, 'Total loss': 0.48862353960673016} | train loss {'Reaction outcome loss': 0.3222886291026634, 'Total loss': 0.3222886291026634}
2023-01-05 11:06:49,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:49,032 INFO:     Epoch: 55
2023-01-05 11:06:51,128 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4532604222496351, 'Total loss': 0.4532604222496351} | train loss {'Reaction outcome loss': 0.32078209216196607, 'Total loss': 0.32078209216196607}
2023-01-05 11:06:51,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:51,128 INFO:     Epoch: 56
2023-01-05 11:06:53,268 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4415090590715408, 'Total loss': 0.4415090590715408} | train loss {'Reaction outcome loss': 0.3190504448610718, 'Total loss': 0.3190504448610718}
2023-01-05 11:06:53,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:53,269 INFO:     Epoch: 57
2023-01-05 11:06:55,399 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42720542997121813, 'Total loss': 0.42720542997121813} | train loss {'Reaction outcome loss': 0.30877808569828524, 'Total loss': 0.30877808569828524}
2023-01-05 11:06:55,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:55,399 INFO:     Epoch: 58
2023-01-05 11:06:57,516 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4429477413495382, 'Total loss': 0.4429477413495382} | train loss {'Reaction outcome loss': 0.30804839034150117, 'Total loss': 0.30804839034150117}
2023-01-05 11:06:57,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:57,517 INFO:     Epoch: 59
2023-01-05 11:06:59,621 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4471187228957812, 'Total loss': 0.4471187228957812} | train loss {'Reaction outcome loss': 0.3050660712331751, 'Total loss': 0.3050660712331751}
2023-01-05 11:06:59,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:06:59,621 INFO:     Epoch: 60
2023-01-05 11:07:01,735 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.471928471326828, 'Total loss': 0.471928471326828} | train loss {'Reaction outcome loss': 0.3037939952672833, 'Total loss': 0.3037939952672833}
2023-01-05 11:07:01,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:01,735 INFO:     Epoch: 61
2023-01-05 11:07:03,873 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47836103240648903, 'Total loss': 0.47836103240648903} | train loss {'Reaction outcome loss': 0.29682556532296167, 'Total loss': 0.29682556532296167}
2023-01-05 11:07:03,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:03,874 INFO:     Epoch: 62
2023-01-05 11:07:05,994 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4392533073822657, 'Total loss': 0.4392533073822657} | train loss {'Reaction outcome loss': 0.302216015008353, 'Total loss': 0.302216015008353}
2023-01-05 11:07:05,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:05,995 INFO:     Epoch: 63
2023-01-05 11:07:08,126 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4703517566124598, 'Total loss': 0.4703517566124598} | train loss {'Reaction outcome loss': 0.2995926222090956, 'Total loss': 0.2995926222090956}
2023-01-05 11:07:08,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:08,126 INFO:     Epoch: 64
2023-01-05 11:07:10,251 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40834291695306696, 'Total loss': 0.40834291695306696} | train loss {'Reaction outcome loss': 0.2952055602749116, 'Total loss': 0.2952055602749116}
2023-01-05 11:07:10,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:10,251 INFO:     Epoch: 65
2023-01-05 11:07:12,353 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44835442503293355, 'Total loss': 0.44835442503293355} | train loss {'Reaction outcome loss': 0.29841524934273783, 'Total loss': 0.29841524934273783}
2023-01-05 11:07:12,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:12,353 INFO:     Epoch: 66
2023-01-05 11:07:14,467 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45822131633758545, 'Total loss': 0.45822131633758545} | train loss {'Reaction outcome loss': 0.29131031141065766, 'Total loss': 0.29131031141065766}
2023-01-05 11:07:14,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:14,467 INFO:     Epoch: 67
2023-01-05 11:07:16,592 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42547342330217364, 'Total loss': 0.42547342330217364} | train loss {'Reaction outcome loss': 0.290208364449387, 'Total loss': 0.290208364449387}
2023-01-05 11:07:16,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:16,592 INFO:     Epoch: 68
2023-01-05 11:07:18,681 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45321510136127474, 'Total loss': 0.45321510136127474} | train loss {'Reaction outcome loss': 0.2881994852456298, 'Total loss': 0.2881994852456298}
2023-01-05 11:07:18,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:18,681 INFO:     Epoch: 69
2023-01-05 11:07:20,815 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4758143703142802, 'Total loss': 0.4758143703142802} | train loss {'Reaction outcome loss': 0.28115521537235183, 'Total loss': 0.28115521537235183}
2023-01-05 11:07:20,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:20,816 INFO:     Epoch: 70
2023-01-05 11:07:22,955 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4166871746381124, 'Total loss': 0.4166871746381124} | train loss {'Reaction outcome loss': 0.2784670517256443, 'Total loss': 0.2784670517256443}
2023-01-05 11:07:22,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:22,956 INFO:     Epoch: 71
2023-01-05 11:07:25,043 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4334317594766617, 'Total loss': 0.4334317594766617} | train loss {'Reaction outcome loss': 0.28322763932039485, 'Total loss': 0.28322763932039485}
2023-01-05 11:07:25,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:25,043 INFO:     Epoch: 72
2023-01-05 11:07:27,141 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43665204470356306, 'Total loss': 0.43665204470356306} | train loss {'Reaction outcome loss': 0.2835438707503524, 'Total loss': 0.2835438707503524}
2023-01-05 11:07:27,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:27,141 INFO:     Epoch: 73
2023-01-05 11:07:29,232 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49487318098545074, 'Total loss': 0.49487318098545074} | train loss {'Reaction outcome loss': 0.27272995928451965, 'Total loss': 0.27272995928451965}
2023-01-05 11:07:29,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:29,233 INFO:     Epoch: 74
2023-01-05 11:07:31,309 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44314651290575663, 'Total loss': 0.44314651290575663} | train loss {'Reaction outcome loss': 0.27843979977234434, 'Total loss': 0.27843979977234434}
2023-01-05 11:07:31,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:31,309 INFO:     Epoch: 75
2023-01-05 11:07:33,420 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4632879813512166, 'Total loss': 0.4632879813512166} | train loss {'Reaction outcome loss': 0.26561364233085927, 'Total loss': 0.26561364233085927}
2023-01-05 11:07:33,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:33,420 INFO:     Epoch: 76
2023-01-05 11:07:35,505 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.480124161640803, 'Total loss': 0.480124161640803} | train loss {'Reaction outcome loss': 0.27289286975062244, 'Total loss': 0.27289286975062244}
2023-01-05 11:07:35,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:35,505 INFO:     Epoch: 77
2023-01-05 11:07:37,628 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47585562368233997, 'Total loss': 0.47585562368233997} | train loss {'Reaction outcome loss': 0.27519401660474546, 'Total loss': 0.27519401660474546}
2023-01-05 11:07:37,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:37,628 INFO:     Epoch: 78
2023-01-05 11:07:39,742 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46014782196531695, 'Total loss': 0.46014782196531695} | train loss {'Reaction outcome loss': 0.262181949264703, 'Total loss': 0.262181949264703}
2023-01-05 11:07:39,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:39,742 INFO:     Epoch: 79
2023-01-05 11:07:41,830 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49902281661828357, 'Total loss': 0.49902281661828357} | train loss {'Reaction outcome loss': 0.2699360905255932, 'Total loss': 0.2699360905255932}
2023-01-05 11:07:41,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:41,831 INFO:     Epoch: 80
2023-01-05 11:07:43,959 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4447682494918505, 'Total loss': 0.4447682494918505} | train loss {'Reaction outcome loss': 0.27105494940748615, 'Total loss': 0.27105494940748615}
2023-01-05 11:07:43,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:43,959 INFO:     Epoch: 81
2023-01-05 11:07:46,097 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.405344362060229, 'Total loss': 0.405344362060229} | train loss {'Reaction outcome loss': 0.26845753598060923, 'Total loss': 0.26845753598060923}
2023-01-05 11:07:46,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:46,097 INFO:     Epoch: 82
2023-01-05 11:07:48,252 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4449334591627121, 'Total loss': 0.4449334591627121} | train loss {'Reaction outcome loss': 0.26777903281532933, 'Total loss': 0.26777903281532933}
2023-01-05 11:07:48,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:48,252 INFO:     Epoch: 83
2023-01-05 11:07:50,373 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4919402519861857, 'Total loss': 0.4919402519861857} | train loss {'Reaction outcome loss': 0.2660761665838369, 'Total loss': 0.2660761665838369}
2023-01-05 11:07:50,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:50,373 INFO:     Epoch: 84
2023-01-05 11:07:52,469 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46807295083999634, 'Total loss': 0.46807295083999634} | train loss {'Reaction outcome loss': 0.26083228970286404, 'Total loss': 0.26083228970286404}
2023-01-05 11:07:52,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:52,470 INFO:     Epoch: 85
2023-01-05 11:07:54,576 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4179205576578776, 'Total loss': 0.4179205576578776} | train loss {'Reaction outcome loss': 0.26206162778565484, 'Total loss': 0.26206162778565484}
2023-01-05 11:07:54,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:54,577 INFO:     Epoch: 86
2023-01-05 11:07:56,667 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4630199690659841, 'Total loss': 0.4630199690659841} | train loss {'Reaction outcome loss': 0.2511251639357231, 'Total loss': 0.2511251639357231}
2023-01-05 11:07:56,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:56,668 INFO:     Epoch: 87
2023-01-05 11:07:58,760 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4388182689746221, 'Total loss': 0.4388182689746221} | train loss {'Reaction outcome loss': 0.25932873044516486, 'Total loss': 0.25932873044516486}
2023-01-05 11:07:58,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:07:58,761 INFO:     Epoch: 88
2023-01-05 11:08:00,885 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39611808558305106, 'Total loss': 0.39611808558305106} | train loss {'Reaction outcome loss': 0.254588638962566, 'Total loss': 0.254588638962566}
2023-01-05 11:08:00,885 INFO:     Found new best model at epoch 88
2023-01-05 11:08:00,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:00,887 INFO:     Epoch: 89
2023-01-05 11:08:02,985 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41291088263193765, 'Total loss': 0.41291088263193765} | train loss {'Reaction outcome loss': 0.25339972768930624, 'Total loss': 0.25339972768930624}
2023-01-05 11:08:02,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:02,985 INFO:     Epoch: 90
2023-01-05 11:08:05,091 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42566067179044087, 'Total loss': 0.42566067179044087} | train loss {'Reaction outcome loss': 0.24553795177897397, 'Total loss': 0.24553795177897397}
2023-01-05 11:08:05,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:05,092 INFO:     Epoch: 91
2023-01-05 11:08:07,170 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4318080296119054, 'Total loss': 0.4318080296119054} | train loss {'Reaction outcome loss': 0.2533069211568167, 'Total loss': 0.2533069211568167}
2023-01-05 11:08:07,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:07,171 INFO:     Epoch: 92
2023-01-05 11:08:09,292 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45344422111908594, 'Total loss': 0.45344422111908594} | train loss {'Reaction outcome loss': 0.2446681236317993, 'Total loss': 0.2446681236317993}
2023-01-05 11:08:09,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:09,292 INFO:     Epoch: 93
2023-01-05 11:08:11,384 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.451657435297966, 'Total loss': 0.451657435297966} | train loss {'Reaction outcome loss': 0.24719972695040443, 'Total loss': 0.24719972695040443}
2023-01-05 11:08:11,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:11,385 INFO:     Epoch: 94
2023-01-05 11:08:13,467 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45877820551395415, 'Total loss': 0.45877820551395415} | train loss {'Reaction outcome loss': 0.2462992539670128, 'Total loss': 0.2462992539670128}
2023-01-05 11:08:13,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:13,468 INFO:     Epoch: 95
2023-01-05 11:08:15,616 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46590501765410103, 'Total loss': 0.46590501765410103} | train loss {'Reaction outcome loss': 0.24991907510417002, 'Total loss': 0.24991907510417002}
2023-01-05 11:08:15,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:15,616 INFO:     Epoch: 96
2023-01-05 11:08:17,737 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4278938680887222, 'Total loss': 0.4278938680887222} | train loss {'Reaction outcome loss': 0.24289637886966667, 'Total loss': 0.24289637886966667}
2023-01-05 11:08:17,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:17,738 INFO:     Epoch: 97
2023-01-05 11:08:19,829 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4292842502395312, 'Total loss': 0.4292842502395312} | train loss {'Reaction outcome loss': 0.2494612537786691, 'Total loss': 0.2494612537786691}
2023-01-05 11:08:19,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:19,830 INFO:     Epoch: 98
2023-01-05 11:08:21,934 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42731901903947195, 'Total loss': 0.42731901903947195} | train loss {'Reaction outcome loss': 0.24582300850455344, 'Total loss': 0.24582300850455344}
2023-01-05 11:08:21,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:21,935 INFO:     Epoch: 99
2023-01-05 11:08:24,027 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.447996786236763, 'Total loss': 0.447996786236763} | train loss {'Reaction outcome loss': 0.23547758862552962, 'Total loss': 0.23547758862552962}
2023-01-05 11:08:24,027 INFO:     Best model found after epoch 89 of 100.
2023-01-05 11:08:24,028 INFO:   Done with stage: TRAINING
2023-01-05 11:08:24,028 INFO:   Starting stage: EVALUATION
2023-01-05 11:08:24,169 INFO:   Done with stage: EVALUATION
2023-01-05 11:08:24,169 INFO:   Leaving out SEQ value Fold_8
2023-01-05 11:08:24,182 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 11:08:24,182 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:08:24,840 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:08:24,840 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:08:24,911 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:08:24,911 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:08:24,911 INFO:     No hyperparam tuning for this model
2023-01-05 11:08:24,911 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:08:24,911 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:08:24,912 INFO:     None feature selector for col prot
2023-01-05 11:08:24,912 INFO:     None feature selector for col prot
2023-01-05 11:08:24,912 INFO:     None feature selector for col prot
2023-01-05 11:08:24,913 INFO:     None feature selector for col chem
2023-01-05 11:08:24,913 INFO:     None feature selector for col chem
2023-01-05 11:08:24,913 INFO:     None feature selector for col chem
2023-01-05 11:08:24,913 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:08:24,913 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:08:24,914 INFO:     Number of params in model 72901
2023-01-05 11:08:24,918 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:08:24,918 INFO:   Starting stage: TRAINING
2023-01-05 11:08:24,978 INFO:     Val loss before train {'Reaction outcome loss': 0.841623326142629, 'Total loss': 0.841623326142629}
2023-01-05 11:08:24,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:24,979 INFO:     Epoch: 0
2023-01-05 11:08:27,105 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7154955387115478, 'Total loss': 0.7154955387115478} | train loss {'Reaction outcome loss': 0.9499812389754216, 'Total loss': 0.9499812389754216}
2023-01-05 11:08:27,106 INFO:     Found new best model at epoch 0
2023-01-05 11:08:27,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:27,107 INFO:     Epoch: 1
2023-01-05 11:08:29,252 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5143783787886301, 'Total loss': 0.5143783787886301} | train loss {'Reaction outcome loss': 0.7400813695540928, 'Total loss': 0.7400813695540928}
2023-01-05 11:08:29,252 INFO:     Found new best model at epoch 1
2023-01-05 11:08:29,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:29,253 INFO:     Epoch: 2
2023-01-05 11:08:31,447 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44770658711592354, 'Total loss': 0.44770658711592354} | train loss {'Reaction outcome loss': 0.5836068589764812, 'Total loss': 0.5836068589764812}
2023-01-05 11:08:31,447 INFO:     Found new best model at epoch 2
2023-01-05 11:08:31,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:31,449 INFO:     Epoch: 3
2023-01-05 11:08:33,606 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42737844586372375, 'Total loss': 0.42737844586372375} | train loss {'Reaction outcome loss': 0.5327905234124256, 'Total loss': 0.5327905234124256}
2023-01-05 11:08:33,607 INFO:     Found new best model at epoch 3
2023-01-05 11:08:33,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:33,608 INFO:     Epoch: 4
2023-01-05 11:08:35,728 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43827672203381857, 'Total loss': 0.43827672203381857} | train loss {'Reaction outcome loss': 0.5091630588369679, 'Total loss': 0.5091630588369679}
2023-01-05 11:08:35,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:35,729 INFO:     Epoch: 5
2023-01-05 11:08:37,868 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4429458091656367, 'Total loss': 0.4429458091656367} | train loss {'Reaction outcome loss': 0.49843678733717234, 'Total loss': 0.49843678733717234}
2023-01-05 11:08:37,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:37,868 INFO:     Epoch: 6
2023-01-05 11:08:39,989 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4354567925135295, 'Total loss': 0.4354567925135295} | train loss {'Reaction outcome loss': 0.48950052401219035, 'Total loss': 0.48950052401219035}
2023-01-05 11:08:39,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:39,990 INFO:     Epoch: 7
2023-01-05 11:08:42,186 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4232817620038986, 'Total loss': 0.4232817620038986} | train loss {'Reaction outcome loss': 0.4812488633641697, 'Total loss': 0.4812488633641697}
2023-01-05 11:08:42,187 INFO:     Found new best model at epoch 7
2023-01-05 11:08:42,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:42,188 INFO:     Epoch: 8
2023-01-05 11:08:44,401 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4285206884145737, 'Total loss': 0.4285206884145737} | train loss {'Reaction outcome loss': 0.47390599088871094, 'Total loss': 0.47390599088871094}
2023-01-05 11:08:44,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:44,401 INFO:     Epoch: 9
2023-01-05 11:08:46,569 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.398428883155187, 'Total loss': 0.398428883155187} | train loss {'Reaction outcome loss': 0.4711286484226853, 'Total loss': 0.4711286484226853}
2023-01-05 11:08:46,569 INFO:     Found new best model at epoch 9
2023-01-05 11:08:46,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:46,571 INFO:     Epoch: 10
2023-01-05 11:08:48,697 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.401041712363561, 'Total loss': 0.401041712363561} | train loss {'Reaction outcome loss': 0.4679187968749862, 'Total loss': 0.4679187968749862}
2023-01-05 11:08:48,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:48,697 INFO:     Epoch: 11
2023-01-05 11:08:50,820 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3883649408817291, 'Total loss': 0.3883649408817291} | train loss {'Reaction outcome loss': 0.4561336907669095, 'Total loss': 0.4561336907669095}
2023-01-05 11:08:50,820 INFO:     Found new best model at epoch 11
2023-01-05 11:08:50,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:50,821 INFO:     Epoch: 12
2023-01-05 11:08:52,947 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41371674040953316, 'Total loss': 0.41371674040953316} | train loss {'Reaction outcome loss': 0.450759643574484, 'Total loss': 0.450759643574484}
2023-01-05 11:08:52,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:52,947 INFO:     Epoch: 13
2023-01-05 11:08:55,108 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.406321973601977, 'Total loss': 0.406321973601977} | train loss {'Reaction outcome loss': 0.4431578321147051, 'Total loss': 0.4431578321147051}
2023-01-05 11:08:55,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:55,109 INFO:     Epoch: 14
2023-01-05 11:08:57,266 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40703873137633007, 'Total loss': 0.40703873137633007} | train loss {'Reaction outcome loss': 0.44026147380525027, 'Total loss': 0.44026147380525027}
2023-01-05 11:08:57,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:57,266 INFO:     Epoch: 15
2023-01-05 11:08:59,425 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3961529324452082, 'Total loss': 0.3961529324452082} | train loss {'Reaction outcome loss': 0.43324592392151967, 'Total loss': 0.43324592392151967}
2023-01-05 11:08:59,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:08:59,425 INFO:     Epoch: 16
2023-01-05 11:09:01,586 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40399419963359834, 'Total loss': 0.40399419963359834} | train loss {'Reaction outcome loss': 0.4335769521953397, 'Total loss': 0.4335769521953397}
2023-01-05 11:09:01,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:01,586 INFO:     Epoch: 17
2023-01-05 11:09:03,734 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3964388440052668, 'Total loss': 0.3964388440052668} | train loss {'Reaction outcome loss': 0.4263251130116115, 'Total loss': 0.4263251130116115}
2023-01-05 11:09:03,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:03,735 INFO:     Epoch: 18
2023-01-05 11:09:05,878 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39685629506905873, 'Total loss': 0.39685629506905873} | train loss {'Reaction outcome loss': 0.42684843291659647, 'Total loss': 0.42684843291659647}
2023-01-05 11:09:05,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:05,880 INFO:     Epoch: 19
2023-01-05 11:09:08,050 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4255506416161855, 'Total loss': 0.4255506416161855} | train loss {'Reaction outcome loss': 0.42129064937683647, 'Total loss': 0.42129064937683647}
2023-01-05 11:09:08,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:08,050 INFO:     Epoch: 20
2023-01-05 11:09:10,208 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4003884971141815, 'Total loss': 0.4003884971141815} | train loss {'Reaction outcome loss': 0.4163622126077379, 'Total loss': 0.4163622126077379}
2023-01-05 11:09:10,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:10,208 INFO:     Epoch: 21
2023-01-05 11:09:12,378 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4085400978724162, 'Total loss': 0.4085400978724162} | train loss {'Reaction outcome loss': 0.40665072014400677, 'Total loss': 0.40665072014400677}
2023-01-05 11:09:12,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:12,378 INFO:     Epoch: 22
2023-01-05 11:09:14,538 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3961400846640269, 'Total loss': 0.3961400846640269} | train loss {'Reaction outcome loss': 0.4085288547544273, 'Total loss': 0.4085288547544273}
2023-01-05 11:09:14,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:14,539 INFO:     Epoch: 23
2023-01-05 11:09:16,690 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3891731172800064, 'Total loss': 0.3891731172800064} | train loss {'Reaction outcome loss': 0.40410302864515396, 'Total loss': 0.40410302864515396}
2023-01-05 11:09:16,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:16,691 INFO:     Epoch: 24
2023-01-05 11:09:18,859 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40791573325792946, 'Total loss': 0.40791573325792946} | train loss {'Reaction outcome loss': 0.40020150193668874, 'Total loss': 0.40020150193668874}
2023-01-05 11:09:18,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:18,859 INFO:     Epoch: 25
2023-01-05 11:09:21,021 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39656649927298226, 'Total loss': 0.39656649927298226} | train loss {'Reaction outcome loss': 0.39389971829278375, 'Total loss': 0.39389971829278375}
2023-01-05 11:09:21,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:21,021 INFO:     Epoch: 26
2023-01-05 11:09:23,187 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36567663749059043, 'Total loss': 0.36567663749059043} | train loss {'Reaction outcome loss': 0.39034043763518766, 'Total loss': 0.39034043763518766}
2023-01-05 11:09:23,187 INFO:     Found new best model at epoch 26
2023-01-05 11:09:23,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:23,188 INFO:     Epoch: 27
2023-01-05 11:09:25,354 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38378552595774335, 'Total loss': 0.38378552595774335} | train loss {'Reaction outcome loss': 0.3902204760790732, 'Total loss': 0.3902204760790732}
2023-01-05 11:09:25,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:25,355 INFO:     Epoch: 28
2023-01-05 11:09:27,505 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39046762386957806, 'Total loss': 0.39046762386957806} | train loss {'Reaction outcome loss': 0.3819340355559807, 'Total loss': 0.3819340355559807}
2023-01-05 11:09:27,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:27,505 INFO:     Epoch: 29
2023-01-05 11:09:29,678 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38471637467543285, 'Total loss': 0.38471637467543285} | train loss {'Reaction outcome loss': 0.3804683617521279, 'Total loss': 0.3804683617521279}
2023-01-05 11:09:29,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:29,678 INFO:     Epoch: 30
2023-01-05 11:09:31,841 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3829679101705551, 'Total loss': 0.3829679101705551} | train loss {'Reaction outcome loss': 0.3795814476503792, 'Total loss': 0.3795814476503792}
2023-01-05 11:09:31,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:31,842 INFO:     Epoch: 31
2023-01-05 11:09:33,986 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3661726251244545, 'Total loss': 0.3661726251244545} | train loss {'Reaction outcome loss': 0.3761872358162911, 'Total loss': 0.3761872358162911}
2023-01-05 11:09:33,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:33,987 INFO:     Epoch: 32
2023-01-05 11:09:36,152 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3908217380444209, 'Total loss': 0.3908217380444209} | train loss {'Reaction outcome loss': 0.36531287044394317, 'Total loss': 0.36531287044394317}
2023-01-05 11:09:36,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:36,153 INFO:     Epoch: 33
2023-01-05 11:09:38,284 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3541984995206197, 'Total loss': 0.3541984995206197} | train loss {'Reaction outcome loss': 0.36412296259930416, 'Total loss': 0.36412296259930416}
2023-01-05 11:09:38,285 INFO:     Found new best model at epoch 33
2023-01-05 11:09:38,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:38,286 INFO:     Epoch: 34
2023-01-05 11:09:40,440 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3836953428884347, 'Total loss': 0.3836953428884347} | train loss {'Reaction outcome loss': 0.36318434820601225, 'Total loss': 0.36318434820601225}
2023-01-05 11:09:40,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:40,441 INFO:     Epoch: 35
2023-01-05 11:09:42,581 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4166604846715927, 'Total loss': 0.4166604846715927} | train loss {'Reaction outcome loss': 0.3668456259133153, 'Total loss': 0.3668456259133153}
2023-01-05 11:09:42,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:42,581 INFO:     Epoch: 36
2023-01-05 11:09:44,751 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3715250909328461, 'Total loss': 0.3715250909328461} | train loss {'Reaction outcome loss': 0.3505307007513752, 'Total loss': 0.3505307007513752}
2023-01-05 11:09:44,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:44,752 INFO:     Epoch: 37
2023-01-05 11:09:46,929 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38287081917126975, 'Total loss': 0.38287081917126975} | train loss {'Reaction outcome loss': 0.35304889494438896, 'Total loss': 0.35304889494438896}
2023-01-05 11:09:46,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:46,929 INFO:     Epoch: 38
2023-01-05 11:09:49,091 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36019302705923717, 'Total loss': 0.36019302705923717} | train loss {'Reaction outcome loss': 0.3470348355760428, 'Total loss': 0.3470348355760428}
2023-01-05 11:09:49,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:49,091 INFO:     Epoch: 39
2023-01-05 11:09:51,230 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3828423708677292, 'Total loss': 0.3828423708677292} | train loss {'Reaction outcome loss': 0.3434921102699175, 'Total loss': 0.3434921102699175}
2023-01-05 11:09:51,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:51,231 INFO:     Epoch: 40
2023-01-05 11:09:53,414 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4030094057321548, 'Total loss': 0.4030094057321548} | train loss {'Reaction outcome loss': 0.34458474260805316, 'Total loss': 0.34458474260805316}
2023-01-05 11:09:53,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:53,414 INFO:     Epoch: 41
2023-01-05 11:09:55,584 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3760628253221512, 'Total loss': 0.3760628253221512} | train loss {'Reaction outcome loss': 0.33762844025228, 'Total loss': 0.33762844025228}
2023-01-05 11:09:55,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:55,585 INFO:     Epoch: 42
2023-01-05 11:09:57,754 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3845791598161062, 'Total loss': 0.3845791598161062} | train loss {'Reaction outcome loss': 0.334900627659116, 'Total loss': 0.334900627659116}
2023-01-05 11:09:57,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:57,755 INFO:     Epoch: 43
2023-01-05 11:09:59,930 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3754613697528839, 'Total loss': 0.3754613697528839} | train loss {'Reaction outcome loss': 0.34122522328627236, 'Total loss': 0.34122522328627236}
2023-01-05 11:09:59,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:09:59,930 INFO:     Epoch: 44
2023-01-05 11:10:02,084 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39641941090424854, 'Total loss': 0.39641941090424854} | train loss {'Reaction outcome loss': 0.3325492974491756, 'Total loss': 0.3325492974491756}
2023-01-05 11:10:02,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:02,084 INFO:     Epoch: 45
2023-01-05 11:10:04,065 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38034284561872483, 'Total loss': 0.38034284561872483} | train loss {'Reaction outcome loss': 0.32552795304449456, 'Total loss': 0.32552795304449456}
2023-01-05 11:10:04,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:04,066 INFO:     Epoch: 46
2023-01-05 11:10:06,289 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38868171672026314, 'Total loss': 0.38868171672026314} | train loss {'Reaction outcome loss': 0.3253957373006034, 'Total loss': 0.3253957373006034}
2023-01-05 11:10:06,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:06,290 INFO:     Epoch: 47
2023-01-05 11:10:08,512 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3703883280356725, 'Total loss': 0.3703883280356725} | train loss {'Reaction outcome loss': 0.32068847807036843, 'Total loss': 0.32068847807036843}
2023-01-05 11:10:08,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:08,513 INFO:     Epoch: 48
2023-01-05 11:10:10,737 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3997704178094864, 'Total loss': 0.3997704178094864} | train loss {'Reaction outcome loss': 0.3169636486589048, 'Total loss': 0.3169636486589048}
2023-01-05 11:10:10,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:10,737 INFO:     Epoch: 49
2023-01-05 11:10:12,958 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3903712809085846, 'Total loss': 0.3903712809085846} | train loss {'Reaction outcome loss': 0.3160697167692202, 'Total loss': 0.3160697167692202}
2023-01-05 11:10:12,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:12,959 INFO:     Epoch: 50
2023-01-05 11:10:15,158 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3656597415606181, 'Total loss': 0.3656597415606181} | train loss {'Reaction outcome loss': 0.3129234485570274, 'Total loss': 0.3129234485570274}
2023-01-05 11:10:15,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:15,159 INFO:     Epoch: 51
2023-01-05 11:10:17,376 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3778561611970266, 'Total loss': 0.3778561611970266} | train loss {'Reaction outcome loss': 0.3100578719716425, 'Total loss': 0.3100578719716425}
2023-01-05 11:10:17,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:17,378 INFO:     Epoch: 52
2023-01-05 11:10:19,554 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3615321904420853, 'Total loss': 0.3615321904420853} | train loss {'Reaction outcome loss': 0.3070400529658751, 'Total loss': 0.3070400529658751}
2023-01-05 11:10:19,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:19,554 INFO:     Epoch: 53
2023-01-05 11:10:21,757 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36921909550825754, 'Total loss': 0.36921909550825754} | train loss {'Reaction outcome loss': 0.3041741225720528, 'Total loss': 0.3041741225720528}
2023-01-05 11:10:21,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:21,757 INFO:     Epoch: 54
2023-01-05 11:10:23,935 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4185567140579224, 'Total loss': 0.4185567140579224} | train loss {'Reaction outcome loss': 0.3044280024507631, 'Total loss': 0.3044280024507631}
2023-01-05 11:10:23,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:23,935 INFO:     Epoch: 55
2023-01-05 11:10:26,071 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35933966040611265, 'Total loss': 0.35933966040611265} | train loss {'Reaction outcome loss': 0.30011773280234544, 'Total loss': 0.30011773280234544}
2023-01-05 11:10:26,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:26,072 INFO:     Epoch: 56
2023-01-05 11:10:28,254 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40704377790292107, 'Total loss': 0.40704377790292107} | train loss {'Reaction outcome loss': 0.30149269046846927, 'Total loss': 0.30149269046846927}
2023-01-05 11:10:28,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:28,255 INFO:     Epoch: 57
2023-01-05 11:10:30,453 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3542218148708344, 'Total loss': 0.3542218148708344} | train loss {'Reaction outcome loss': 0.30181639587728554, 'Total loss': 0.30181639587728554}
2023-01-05 11:10:30,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:30,453 INFO:     Epoch: 58
2023-01-05 11:10:32,601 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3691549281279246, 'Total loss': 0.3691549281279246} | train loss {'Reaction outcome loss': 0.29743115423711197, 'Total loss': 0.29743115423711197}
2023-01-05 11:10:32,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:32,601 INFO:     Epoch: 59
2023-01-05 11:10:34,750 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35054123103618623, 'Total loss': 0.35054123103618623} | train loss {'Reaction outcome loss': 0.29416265153067206, 'Total loss': 0.29416265153067206}
2023-01-05 11:10:34,750 INFO:     Found new best model at epoch 59
2023-01-05 11:10:34,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:34,752 INFO:     Epoch: 60
2023-01-05 11:10:36,867 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.33489651878674825, 'Total loss': 0.33489651878674825} | train loss {'Reaction outcome loss': 0.29034622349786415, 'Total loss': 0.29034622349786415}
2023-01-05 11:10:36,867 INFO:     Found new best model at epoch 60
2023-01-05 11:10:36,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:36,869 INFO:     Epoch: 61
2023-01-05 11:10:39,008 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40387180745601653, 'Total loss': 0.40387180745601653} | train loss {'Reaction outcome loss': 0.28423852285888007, 'Total loss': 0.28423852285888007}
2023-01-05 11:10:39,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:39,008 INFO:     Epoch: 62
2023-01-05 11:10:41,131 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3895902544260025, 'Total loss': 0.3895902544260025} | train loss {'Reaction outcome loss': 0.2815981433602447, 'Total loss': 0.2815981433602447}
2023-01-05 11:10:41,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:41,132 INFO:     Epoch: 63
2023-01-05 11:10:43,275 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39155091643333434, 'Total loss': 0.39155091643333434} | train loss {'Reaction outcome loss': 0.2886272996583355, 'Total loss': 0.2886272996583355}
2023-01-05 11:10:43,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:43,276 INFO:     Epoch: 64
2023-01-05 11:10:45,421 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3564031332731247, 'Total loss': 0.3564031332731247} | train loss {'Reaction outcome loss': 0.28103375880699943, 'Total loss': 0.28103375880699943}
2023-01-05 11:10:45,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:45,421 INFO:     Epoch: 65
2023-01-05 11:10:47,553 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3791468491156896, 'Total loss': 0.3791468491156896} | train loss {'Reaction outcome loss': 0.2771232507934639, 'Total loss': 0.2771232507934639}
2023-01-05 11:10:47,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:47,553 INFO:     Epoch: 66
2023-01-05 11:10:49,675 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35356418987115223, 'Total loss': 0.35356418987115223} | train loss {'Reaction outcome loss': 0.2833535016887562, 'Total loss': 0.2833535016887562}
2023-01-05 11:10:49,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:49,676 INFO:     Epoch: 67
2023-01-05 11:10:51,804 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.371839714050293, 'Total loss': 0.371839714050293} | train loss {'Reaction outcome loss': 0.27363496357810413, 'Total loss': 0.27363496357810413}
2023-01-05 11:10:51,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:51,804 INFO:     Epoch: 68
2023-01-05 11:10:53,976 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35763183136781057, 'Total loss': 0.35763183136781057} | train loss {'Reaction outcome loss': 0.2698702632116712, 'Total loss': 0.2698702632116712}
2023-01-05 11:10:53,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:53,978 INFO:     Epoch: 69
2023-01-05 11:10:56,144 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3831522991259893, 'Total loss': 0.3831522991259893} | train loss {'Reaction outcome loss': 0.2720672845410096, 'Total loss': 0.2720672845410096}
2023-01-05 11:10:56,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:56,144 INFO:     Epoch: 70
2023-01-05 11:10:58,246 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.368450399239858, 'Total loss': 0.368450399239858} | train loss {'Reaction outcome loss': 0.2695975378626413, 'Total loss': 0.2695975378626413}
2023-01-05 11:10:58,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:10:58,246 INFO:     Epoch: 71
2023-01-05 11:11:00,377 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36335941857347887, 'Total loss': 0.36335941857347887} | train loss {'Reaction outcome loss': 0.2731797665303795, 'Total loss': 0.2731797665303795}
2023-01-05 11:11:00,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:00,378 INFO:     Epoch: 72
2023-01-05 11:11:02,495 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36923926572004956, 'Total loss': 0.36923926572004956} | train loss {'Reaction outcome loss': 0.26856985076293616, 'Total loss': 0.26856985076293616}
2023-01-05 11:11:02,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:02,495 INFO:     Epoch: 73
2023-01-05 11:11:04,614 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40211386581261954, 'Total loss': 0.40211386581261954} | train loss {'Reaction outcome loss': 0.2610279036558062, 'Total loss': 0.2610279036558062}
2023-01-05 11:11:04,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:04,614 INFO:     Epoch: 74
2023-01-05 11:11:06,729 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3872826397418976, 'Total loss': 0.3872826397418976} | train loss {'Reaction outcome loss': 0.2659634414737513, 'Total loss': 0.2659634414737513}
2023-01-05 11:11:06,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:06,730 INFO:     Epoch: 75
2023-01-05 11:11:08,875 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3983632663885752, 'Total loss': 0.3983632663885752} | train loss {'Reaction outcome loss': 0.2640367432998406, 'Total loss': 0.2640367432998406}
2023-01-05 11:11:08,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:08,876 INFO:     Epoch: 76
2023-01-05 11:11:11,019 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3995459665854772, 'Total loss': 0.3995459665854772} | train loss {'Reaction outcome loss': 0.266349887737621, 'Total loss': 0.266349887737621}
2023-01-05 11:11:11,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:11,019 INFO:     Epoch: 77
2023-01-05 11:11:13,150 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41471315224965416, 'Total loss': 0.41471315224965416} | train loss {'Reaction outcome loss': 0.25666986812672676, 'Total loss': 0.25666986812672676}
2023-01-05 11:11:13,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:13,151 INFO:     Epoch: 78
2023-01-05 11:11:15,272 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3324355686704318, 'Total loss': 0.3324355686704318} | train loss {'Reaction outcome loss': 0.27856795764814, 'Total loss': 0.27856795764814}
2023-01-05 11:11:15,272 INFO:     Found new best model at epoch 78
2023-01-05 11:11:15,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:15,274 INFO:     Epoch: 79
2023-01-05 11:11:17,387 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.366833891471227, 'Total loss': 0.366833891471227} | train loss {'Reaction outcome loss': 0.25552072218662997, 'Total loss': 0.25552072218662997}
2023-01-05 11:11:17,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:17,387 INFO:     Epoch: 80
2023-01-05 11:11:19,517 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3914431800444921, 'Total loss': 0.3914431800444921} | train loss {'Reaction outcome loss': 0.26266765737038655, 'Total loss': 0.26266765737038655}
2023-01-05 11:11:19,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:19,517 INFO:     Epoch: 81
2023-01-05 11:11:21,644 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3420707220832507, 'Total loss': 0.3420707220832507} | train loss {'Reaction outcome loss': 0.26237020310727266, 'Total loss': 0.26237020310727266}
2023-01-05 11:11:21,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:21,644 INFO:     Epoch: 82
2023-01-05 11:11:23,767 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3300704499085744, 'Total loss': 0.3300704499085744} | train loss {'Reaction outcome loss': 0.2570241785638492, 'Total loss': 0.2570241785638492}
2023-01-05 11:11:23,769 INFO:     Found new best model at epoch 82
2023-01-05 11:11:23,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:23,770 INFO:     Epoch: 83
2023-01-05 11:11:25,907 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3175483559568723, 'Total loss': 0.3175483559568723} | train loss {'Reaction outcome loss': 0.2489186944473629, 'Total loss': 0.2489186944473629}
2023-01-05 11:11:25,907 INFO:     Found new best model at epoch 83
2023-01-05 11:11:25,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:25,908 INFO:     Epoch: 84
2023-01-05 11:11:28,114 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3674559573332469, 'Total loss': 0.3674559573332469} | train loss {'Reaction outcome loss': 0.2541541304667934, 'Total loss': 0.2541541304667934}
2023-01-05 11:11:28,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:28,114 INFO:     Epoch: 85
2023-01-05 11:11:30,309 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37044455409049987, 'Total loss': 0.37044455409049987} | train loss {'Reaction outcome loss': 0.25263785395354355, 'Total loss': 0.25263785395354355}
2023-01-05 11:11:30,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:30,310 INFO:     Epoch: 86
2023-01-05 11:11:32,520 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3816790968179703, 'Total loss': 0.3816790968179703} | train loss {'Reaction outcome loss': 0.25057378050195395, 'Total loss': 0.25057378050195395}
2023-01-05 11:11:32,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:32,521 INFO:     Epoch: 87
2023-01-05 11:11:34,716 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3582957863807678, 'Total loss': 0.3582957863807678} | train loss {'Reaction outcome loss': 0.2565043377841315, 'Total loss': 0.2565043377841315}
2023-01-05 11:11:34,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:34,716 INFO:     Epoch: 88
2023-01-05 11:11:36,911 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4141183535257975, 'Total loss': 0.4141183535257975} | train loss {'Reaction outcome loss': 0.2578231872123286, 'Total loss': 0.2578231872123286}
2023-01-05 11:11:36,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:36,912 INFO:     Epoch: 89
2023-01-05 11:11:39,072 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.361055185397466, 'Total loss': 0.361055185397466} | train loss {'Reaction outcome loss': 0.2476252966900003, 'Total loss': 0.2476252966900003}
2023-01-05 11:11:39,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:39,072 INFO:     Epoch: 90
2023-01-05 11:11:41,205 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3580260162552198, 'Total loss': 0.3580260162552198} | train loss {'Reaction outcome loss': 0.23535093091872086, 'Total loss': 0.23535093091872086}
2023-01-05 11:11:41,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:41,205 INFO:     Epoch: 91
2023-01-05 11:11:43,333 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34448166787624357, 'Total loss': 0.34448166787624357} | train loss {'Reaction outcome loss': 0.23853596627362583, 'Total loss': 0.23853596627362583}
2023-01-05 11:11:43,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:43,334 INFO:     Epoch: 92
2023-01-05 11:11:45,444 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3759364813566208, 'Total loss': 0.3759364813566208} | train loss {'Reaction outcome loss': 0.24048512716128723, 'Total loss': 0.24048512716128723}
2023-01-05 11:11:45,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:45,444 INFO:     Epoch: 93
2023-01-05 11:11:47,564 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3760075261195501, 'Total loss': 0.3760075261195501} | train loss {'Reaction outcome loss': 0.24731565511613976, 'Total loss': 0.24731565511613976}
2023-01-05 11:11:47,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:47,565 INFO:     Epoch: 94
2023-01-05 11:11:49,697 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4254457821448644, 'Total loss': 0.4254457821448644} | train loss {'Reaction outcome loss': 0.23811578179712975, 'Total loss': 0.23811578179712975}
2023-01-05 11:11:49,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:49,697 INFO:     Epoch: 95
2023-01-05 11:11:51,824 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3782283286253611, 'Total loss': 0.3782283286253611} | train loss {'Reaction outcome loss': 0.2461955544441293, 'Total loss': 0.2461955544441293}
2023-01-05 11:11:51,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:51,825 INFO:     Epoch: 96
2023-01-05 11:11:53,961 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3660818060239156, 'Total loss': 0.3660818060239156} | train loss {'Reaction outcome loss': 0.2424264416966036, 'Total loss': 0.2424264416966036}
2023-01-05 11:11:53,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:53,961 INFO:     Epoch: 97
2023-01-05 11:11:56,084 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.34419644872347516, 'Total loss': 0.34419644872347516} | train loss {'Reaction outcome loss': 0.23870347288272442, 'Total loss': 0.23870347288272442}
2023-01-05 11:11:56,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:56,085 INFO:     Epoch: 98
2023-01-05 11:11:58,231 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.35996800313393273, 'Total loss': 0.35996800313393273} | train loss {'Reaction outcome loss': 0.24133344062197187, 'Total loss': 0.24133344062197187}
2023-01-05 11:11:58,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:11:58,232 INFO:     Epoch: 99
2023-01-05 11:12:00,378 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37519145558277767, 'Total loss': 0.37519145558277767} | train loss {'Reaction outcome loss': 0.2349141960734979, 'Total loss': 0.2349141960734979}
2023-01-05 11:12:00,379 INFO:     Best model found after epoch 84 of 100.
2023-01-05 11:12:00,380 INFO:   Done with stage: TRAINING
2023-01-05 11:12:00,380 INFO:   Starting stage: EVALUATION
2023-01-05 11:12:00,507 INFO:   Done with stage: EVALUATION
2023-01-05 11:12:00,507 INFO:   Leaving out SEQ value Fold_9
2023-01-05 11:12:00,519 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:12:00,519 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:12:01,163 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:12:01,163 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:12:01,232 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:12:01,232 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:12:01,232 INFO:     No hyperparam tuning for this model
2023-01-05 11:12:01,232 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:12:01,232 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:12:01,233 INFO:     None feature selector for col prot
2023-01-05 11:12:01,233 INFO:     None feature selector for col prot
2023-01-05 11:12:01,233 INFO:     None feature selector for col prot
2023-01-05 11:12:01,233 INFO:     None feature selector for col chem
2023-01-05 11:12:01,233 INFO:     None feature selector for col chem
2023-01-05 11:12:01,233 INFO:     None feature selector for col chem
2023-01-05 11:12:01,234 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:12:01,234 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:12:01,235 INFO:     Number of params in model 72901
2023-01-05 11:12:01,238 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:12:01,238 INFO:   Starting stage: TRAINING
2023-01-05 11:12:01,298 INFO:     Val loss before train {'Reaction outcome loss': 1.0223591685295106, 'Total loss': 1.0223591685295106}
2023-01-05 11:12:01,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:01,298 INFO:     Epoch: 0
2023-01-05 11:12:03,414 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8216784497102102, 'Total loss': 0.8216784497102102} | train loss {'Reaction outcome loss': 0.9364777440137236, 'Total loss': 0.9364777440137236}
2023-01-05 11:12:03,414 INFO:     Found new best model at epoch 0
2023-01-05 11:12:03,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:03,415 INFO:     Epoch: 1
2023-01-05 11:12:05,538 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7356109857559204, 'Total loss': 0.7356109857559204} | train loss {'Reaction outcome loss': 0.7990026737216616, 'Total loss': 0.7990026737216616}
2023-01-05 11:12:05,538 INFO:     Found new best model at epoch 1
2023-01-05 11:12:05,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:05,539 INFO:     Epoch: 2
2023-01-05 11:12:07,630 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5921255588531494, 'Total loss': 0.5921255588531494} | train loss {'Reaction outcome loss': 0.6405759268868578, 'Total loss': 0.6405759268868578}
2023-01-05 11:12:07,631 INFO:     Found new best model at epoch 2
2023-01-05 11:12:07,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:07,632 INFO:     Epoch: 3
2023-01-05 11:12:09,764 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5628167609373729, 'Total loss': 0.5628167609373729} | train loss {'Reaction outcome loss': 0.5473170875415315, 'Total loss': 0.5473170875415315}
2023-01-05 11:12:09,764 INFO:     Found new best model at epoch 3
2023-01-05 11:12:09,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:09,765 INFO:     Epoch: 4
2023-01-05 11:12:11,869 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.537204780181249, 'Total loss': 0.537204780181249} | train loss {'Reaction outcome loss': 0.516580159701135, 'Total loss': 0.516580159701135}
2023-01-05 11:12:11,869 INFO:     Found new best model at epoch 4
2023-01-05 11:12:11,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:11,870 INFO:     Epoch: 5
2023-01-05 11:12:14,013 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5134246667226156, 'Total loss': 0.5134246667226156} | train loss {'Reaction outcome loss': 0.505235783538244, 'Total loss': 0.505235783538244}
2023-01-05 11:12:14,013 INFO:     Found new best model at epoch 5
2023-01-05 11:12:14,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:14,014 INFO:     Epoch: 6
2023-01-05 11:12:16,113 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5699920256932577, 'Total loss': 0.5699920256932577} | train loss {'Reaction outcome loss': 0.48585884882150776, 'Total loss': 0.48585884882150776}
2023-01-05 11:12:16,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:16,114 INFO:     Epoch: 7
2023-01-05 11:12:18,201 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5273076832294464, 'Total loss': 0.5273076832294464} | train loss {'Reaction outcome loss': 0.4838457526843043, 'Total loss': 0.4838457526843043}
2023-01-05 11:12:18,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:18,201 INFO:     Epoch: 8
2023-01-05 11:12:20,324 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5062127014001211, 'Total loss': 0.5062127014001211} | train loss {'Reaction outcome loss': 0.4740055614579333, 'Total loss': 0.4740055614579333}
2023-01-05 11:12:20,324 INFO:     Found new best model at epoch 8
2023-01-05 11:12:20,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:20,326 INFO:     Epoch: 9
2023-01-05 11:12:22,438 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5076595862706502, 'Total loss': 0.5076595862706502} | train loss {'Reaction outcome loss': 0.4657773783933507, 'Total loss': 0.4657773783933507}
2023-01-05 11:12:22,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:22,438 INFO:     Epoch: 10
2023-01-05 11:12:24,563 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49978082776069643, 'Total loss': 0.49978082776069643} | train loss {'Reaction outcome loss': 0.46154902997786984, 'Total loss': 0.46154902997786984}
2023-01-05 11:12:24,564 INFO:     Found new best model at epoch 10
2023-01-05 11:12:24,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:24,565 INFO:     Epoch: 11
2023-01-05 11:12:26,705 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5131702482700348, 'Total loss': 0.5131702482700348} | train loss {'Reaction outcome loss': 0.45190184057629024, 'Total loss': 0.45190184057629024}
2023-01-05 11:12:26,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:26,705 INFO:     Epoch: 12
2023-01-05 11:12:28,837 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5115312258402507, 'Total loss': 0.5115312258402507} | train loss {'Reaction outcome loss': 0.4524042265367334, 'Total loss': 0.4524042265367334}
2023-01-05 11:12:28,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:28,837 INFO:     Epoch: 13
2023-01-05 11:12:30,948 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5217232505480448, 'Total loss': 0.5217232505480448} | train loss {'Reaction outcome loss': 0.4514837489075904, 'Total loss': 0.4514837489075904}
2023-01-05 11:12:30,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:30,949 INFO:     Epoch: 14
2023-01-05 11:12:33,073 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46639190713564554, 'Total loss': 0.46639190713564554} | train loss {'Reaction outcome loss': 0.4448109023871213, 'Total loss': 0.4448109023871213}
2023-01-05 11:12:33,073 INFO:     Found new best model at epoch 14
2023-01-05 11:12:33,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:33,075 INFO:     Epoch: 15
2023-01-05 11:12:35,177 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4921463986237844, 'Total loss': 0.4921463986237844} | train loss {'Reaction outcome loss': 0.4370812296758603, 'Total loss': 0.4370812296758603}
2023-01-05 11:12:35,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:35,177 INFO:     Epoch: 16
2023-01-05 11:12:37,277 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48508166472117104, 'Total loss': 0.48508166472117104} | train loss {'Reaction outcome loss': 0.43290276488248447, 'Total loss': 0.43290276488248447}
2023-01-05 11:12:37,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:37,278 INFO:     Epoch: 17
2023-01-05 11:12:39,378 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5077159345149994, 'Total loss': 0.5077159345149994} | train loss {'Reaction outcome loss': 0.4297945206019565, 'Total loss': 0.4297945206019565}
2023-01-05 11:12:39,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:39,379 INFO:     Epoch: 18
2023-01-05 11:12:41,473 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4955744614203771, 'Total loss': 0.4955744614203771} | train loss {'Reaction outcome loss': 0.42502962455262233, 'Total loss': 0.42502962455262233}
2023-01-05 11:12:41,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:41,473 INFO:     Epoch: 19
2023-01-05 11:12:43,628 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4568740223844846, 'Total loss': 0.4568740223844846} | train loss {'Reaction outcome loss': 0.42022038816753093, 'Total loss': 0.42022038816753093}
2023-01-05 11:12:43,628 INFO:     Found new best model at epoch 19
2023-01-05 11:12:43,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:43,630 INFO:     Epoch: 20
2023-01-05 11:12:45,863 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4578857739766439, 'Total loss': 0.4578857739766439} | train loss {'Reaction outcome loss': 0.41821299455244176, 'Total loss': 0.41821299455244176}
2023-01-05 11:12:45,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:45,863 INFO:     Epoch: 21
2023-01-05 11:12:48,071 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48489834666252135, 'Total loss': 0.48489834666252135} | train loss {'Reaction outcome loss': 0.416129422285696, 'Total loss': 0.416129422285696}
2023-01-05 11:12:48,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:48,072 INFO:     Epoch: 22
2023-01-05 11:12:50,272 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4584910402695338, 'Total loss': 0.4584910402695338} | train loss {'Reaction outcome loss': 0.4124729328238181, 'Total loss': 0.4124729328238181}
2023-01-05 11:12:50,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:50,273 INFO:     Epoch: 23
2023-01-05 11:12:52,356 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4404878854751587, 'Total loss': 0.4404878854751587} | train loss {'Reaction outcome loss': 0.4070820603927557, 'Total loss': 0.4070820603927557}
2023-01-05 11:12:52,356 INFO:     Found new best model at epoch 23
2023-01-05 11:12:52,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:52,358 INFO:     Epoch: 24
2023-01-05 11:12:54,487 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47219178477923074, 'Total loss': 0.47219178477923074} | train loss {'Reaction outcome loss': 0.4059794100857999, 'Total loss': 0.4059794100857999}
2023-01-05 11:12:54,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:54,487 INFO:     Epoch: 25
2023-01-05 11:12:56,590 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47195179959138234, 'Total loss': 0.47195179959138234} | train loss {'Reaction outcome loss': 0.3992738110849457, 'Total loss': 0.3992738110849457}
2023-01-05 11:12:56,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:56,590 INFO:     Epoch: 26
2023-01-05 11:12:58,693 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4754963537057241, 'Total loss': 0.4754963537057241} | train loss {'Reaction outcome loss': 0.4010376014685544, 'Total loss': 0.4010376014685544}
2023-01-05 11:12:58,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:12:58,693 INFO:     Epoch: 27
2023-01-05 11:13:00,786 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45114582975705464, 'Total loss': 0.45114582975705464} | train loss {'Reaction outcome loss': 0.38953562991788787, 'Total loss': 0.38953562991788787}
2023-01-05 11:13:00,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:00,787 INFO:     Epoch: 28
2023-01-05 11:13:02,891 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4226139098405838, 'Total loss': 0.4226139098405838} | train loss {'Reaction outcome loss': 0.38474533553269225, 'Total loss': 0.38474533553269225}
2023-01-05 11:13:02,891 INFO:     Found new best model at epoch 28
2023-01-05 11:13:02,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:02,892 INFO:     Epoch: 29
2023-01-05 11:13:04,989 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4336555431286494, 'Total loss': 0.4336555431286494} | train loss {'Reaction outcome loss': 0.37937388308074355, 'Total loss': 0.37937388308074355}
2023-01-05 11:13:04,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:04,989 INFO:     Epoch: 30
2023-01-05 11:13:07,082 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4694946050643921, 'Total loss': 0.4694946050643921} | train loss {'Reaction outcome loss': 0.3790381595655514, 'Total loss': 0.3790381595655514}
2023-01-05 11:13:07,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:07,083 INFO:     Epoch: 31
2023-01-05 11:13:09,187 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49871392250061036, 'Total loss': 0.49871392250061036} | train loss {'Reaction outcome loss': 0.38082817351839837, 'Total loss': 0.38082817351839837}
2023-01-05 11:13:09,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:09,187 INFO:     Epoch: 32
2023-01-05 11:13:11,289 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48261197010676066, 'Total loss': 0.48261197010676066} | train loss {'Reaction outcome loss': 0.3784857943490909, 'Total loss': 0.3784857943490909}
2023-01-05 11:13:11,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:11,289 INFO:     Epoch: 33
2023-01-05 11:13:13,409 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45052443643411, 'Total loss': 0.45052443643411} | train loss {'Reaction outcome loss': 0.37872914638179933, 'Total loss': 0.37872914638179933}
2023-01-05 11:13:13,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:13,409 INFO:     Epoch: 34
2023-01-05 11:13:15,502 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4403556207815806, 'Total loss': 0.4403556207815806} | train loss {'Reaction outcome loss': 0.3682935489409596, 'Total loss': 0.3682935489409596}
2023-01-05 11:13:15,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:15,502 INFO:     Epoch: 35
2023-01-05 11:13:17,601 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4440625290075938, 'Total loss': 0.4440625290075938} | train loss {'Reaction outcome loss': 0.36161475680279037, 'Total loss': 0.36161475680279037}
2023-01-05 11:13:17,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:17,601 INFO:     Epoch: 36
2023-01-05 11:13:19,711 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42151513397693635, 'Total loss': 0.42151513397693635} | train loss {'Reaction outcome loss': 0.36048110611192935, 'Total loss': 0.36048110611192935}
2023-01-05 11:13:19,712 INFO:     Found new best model at epoch 36
2023-01-05 11:13:19,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:19,713 INFO:     Epoch: 37
2023-01-05 11:13:21,801 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42475727101167043, 'Total loss': 0.42475727101167043} | train loss {'Reaction outcome loss': 0.36106169725475956, 'Total loss': 0.36106169725475956}
2023-01-05 11:13:21,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:21,801 INFO:     Epoch: 38
2023-01-05 11:13:23,906 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4122419645388921, 'Total loss': 0.4122419645388921} | train loss {'Reaction outcome loss': 0.3553263909679695, 'Total loss': 0.3553263909679695}
2023-01-05 11:13:23,906 INFO:     Found new best model at epoch 38
2023-01-05 11:13:23,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:23,907 INFO:     Epoch: 39
2023-01-05 11:13:26,020 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45740440090497336, 'Total loss': 0.45740440090497336} | train loss {'Reaction outcome loss': 0.355579175055027, 'Total loss': 0.355579175055027}
2023-01-05 11:13:26,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:26,021 INFO:     Epoch: 40
2023-01-05 11:13:28,125 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4352406620979309, 'Total loss': 0.4352406620979309} | train loss {'Reaction outcome loss': 0.3544039888049129, 'Total loss': 0.3544039888049129}
2023-01-05 11:13:28,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:28,125 INFO:     Epoch: 41
2023-01-05 11:13:30,242 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4118090252081553, 'Total loss': 0.4118090252081553} | train loss {'Reaction outcome loss': 0.3442799505798051, 'Total loss': 0.3442799505798051}
2023-01-05 11:13:30,242 INFO:     Found new best model at epoch 41
2023-01-05 11:13:30,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:30,243 INFO:     Epoch: 42
2023-01-05 11:13:32,375 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43932126065095267, 'Total loss': 0.43932126065095267} | train loss {'Reaction outcome loss': 0.3445737253684197, 'Total loss': 0.3445737253684197}
2023-01-05 11:13:32,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:32,375 INFO:     Epoch: 43
2023-01-05 11:13:34,495 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42373524606227875, 'Total loss': 0.42373524606227875} | train loss {'Reaction outcome loss': 0.34164075885158385, 'Total loss': 0.34164075885158385}
2023-01-05 11:13:34,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:34,495 INFO:     Epoch: 44
2023-01-05 11:13:36,604 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.460889607667923, 'Total loss': 0.460889607667923} | train loss {'Reaction outcome loss': 0.33241352104466326, 'Total loss': 0.33241352104466326}
2023-01-05 11:13:36,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:36,605 INFO:     Epoch: 45
2023-01-05 11:13:38,706 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4506818652153015, 'Total loss': 0.4506818652153015} | train loss {'Reaction outcome loss': 0.3367788381602642, 'Total loss': 0.3367788381602642}
2023-01-05 11:13:38,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:38,706 INFO:     Epoch: 46
2023-01-05 11:13:40,815 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42238656083742776, 'Total loss': 0.42238656083742776} | train loss {'Reaction outcome loss': 0.3324383767117767, 'Total loss': 0.3324383767117767}
2023-01-05 11:13:40,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:40,815 INFO:     Epoch: 47
2023-01-05 11:13:42,933 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48620456556479136, 'Total loss': 0.48620456556479136} | train loss {'Reaction outcome loss': 0.332583749408487, 'Total loss': 0.332583749408487}
2023-01-05 11:13:42,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:42,934 INFO:     Epoch: 48
2023-01-05 11:13:45,072 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4507542014122009, 'Total loss': 0.4507542014122009} | train loss {'Reaction outcome loss': 0.3252996614705907, 'Total loss': 0.3252996614705907}
2023-01-05 11:13:45,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:45,072 INFO:     Epoch: 49
2023-01-05 11:13:47,219 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4419375330209732, 'Total loss': 0.4419375330209732} | train loss {'Reaction outcome loss': 0.3218370073468146, 'Total loss': 0.3218370073468146}
2023-01-05 11:13:47,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:47,219 INFO:     Epoch: 50
2023-01-05 11:13:49,366 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42275322203834853, 'Total loss': 0.42275322203834853} | train loss {'Reaction outcome loss': 0.32040076950279467, 'Total loss': 0.32040076950279467}
2023-01-05 11:13:49,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:49,366 INFO:     Epoch: 51
2023-01-05 11:13:51,491 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4288219769795736, 'Total loss': 0.4288219769795736} | train loss {'Reaction outcome loss': 0.3176713877758623, 'Total loss': 0.3176713877758623}
2023-01-05 11:13:51,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:51,491 INFO:     Epoch: 52
2023-01-05 11:13:53,631 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4175332983334859, 'Total loss': 0.4175332983334859} | train loss {'Reaction outcome loss': 0.31887929679921073, 'Total loss': 0.31887929679921073}
2023-01-05 11:13:53,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:53,631 INFO:     Epoch: 53
2023-01-05 11:13:55,763 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4502211034297943, 'Total loss': 0.4502211034297943} | train loss {'Reaction outcome loss': 0.31554340648662, 'Total loss': 0.31554340648662}
2023-01-05 11:13:55,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:55,764 INFO:     Epoch: 54
2023-01-05 11:13:57,893 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3997956156730652, 'Total loss': 0.3997956156730652} | train loss {'Reaction outcome loss': 0.3083860743382986, 'Total loss': 0.3083860743382986}
2023-01-05 11:13:57,893 INFO:     Found new best model at epoch 54
2023-01-05 11:13:57,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:13:57,895 INFO:     Epoch: 55
2023-01-05 11:14:00,025 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41002059082190195, 'Total loss': 0.41002059082190195} | train loss {'Reaction outcome loss': 0.30861007041522187, 'Total loss': 0.30861007041522187}
2023-01-05 11:14:00,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:00,025 INFO:     Epoch: 56
2023-01-05 11:14:02,162 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4040057897567749, 'Total loss': 0.4040057897567749} | train loss {'Reaction outcome loss': 0.30649491065066226, 'Total loss': 0.30649491065066226}
2023-01-05 11:14:02,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:02,162 INFO:     Epoch: 57
2023-01-05 11:14:04,080 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4139901672800382, 'Total loss': 0.4139901672800382} | train loss {'Reaction outcome loss': 0.2966763564541827, 'Total loss': 0.2966763564541827}
2023-01-05 11:14:04,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:04,080 INFO:     Epoch: 58
2023-01-05 11:14:06,168 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45372958381970724, 'Total loss': 0.45372958381970724} | train loss {'Reaction outcome loss': 0.2976432732258835, 'Total loss': 0.2976432732258835}
2023-01-05 11:14:06,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:06,168 INFO:     Epoch: 59
2023-01-05 11:14:08,296 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42327138483524324, 'Total loss': 0.42327138483524324} | train loss {'Reaction outcome loss': 0.29882285650139745, 'Total loss': 0.29882285650139745}
2023-01-05 11:14:08,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:08,296 INFO:     Epoch: 60
2023-01-05 11:14:10,390 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.477033398548762, 'Total loss': 0.477033398548762} | train loss {'Reaction outcome loss': 0.2965284081271095, 'Total loss': 0.2965284081271095}
2023-01-05 11:14:10,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:10,390 INFO:     Epoch: 61
2023-01-05 11:14:12,491 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3954288018246492, 'Total loss': 0.3954288018246492} | train loss {'Reaction outcome loss': 0.2933350473533582, 'Total loss': 0.2933350473533582}
2023-01-05 11:14:12,492 INFO:     Found new best model at epoch 61
2023-01-05 11:14:12,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:12,494 INFO:     Epoch: 62
2023-01-05 11:14:14,582 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3895983984073003, 'Total loss': 0.3895983984073003} | train loss {'Reaction outcome loss': 0.2963624268525491, 'Total loss': 0.2963624268525491}
2023-01-05 11:14:14,583 INFO:     Found new best model at epoch 62
2023-01-05 11:14:14,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:14,584 INFO:     Epoch: 63
2023-01-05 11:14:16,727 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4337628086407979, 'Total loss': 0.4337628086407979} | train loss {'Reaction outcome loss': 0.2861299653177279, 'Total loss': 0.2861299653177279}
2023-01-05 11:14:16,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:16,727 INFO:     Epoch: 64
2023-01-05 11:14:18,830 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4057039380073547, 'Total loss': 0.4057039380073547} | train loss {'Reaction outcome loss': 0.28914388795349283, 'Total loss': 0.28914388795349283}
2023-01-05 11:14:18,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:18,831 INFO:     Epoch: 65
2023-01-05 11:14:20,970 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3919049938519796, 'Total loss': 0.3919049938519796} | train loss {'Reaction outcome loss': 0.2808818887497713, 'Total loss': 0.2808818887497713}
2023-01-05 11:14:20,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:20,971 INFO:     Epoch: 66
2023-01-05 11:14:23,137 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41210596561431884, 'Total loss': 0.41210596561431884} | train loss {'Reaction outcome loss': 0.28611989868600873, 'Total loss': 0.28611989868600873}
2023-01-05 11:14:23,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:23,137 INFO:     Epoch: 67
2023-01-05 11:14:25,284 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39119223356246946, 'Total loss': 0.39119223356246946} | train loss {'Reaction outcome loss': 0.279876387344986, 'Total loss': 0.279876387344986}
2023-01-05 11:14:25,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:25,284 INFO:     Epoch: 68
2023-01-05 11:14:27,393 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38655178546905516, 'Total loss': 0.38655178546905516} | train loss {'Reaction outcome loss': 0.2815748313917731, 'Total loss': 0.2815748313917731}
2023-01-05 11:14:27,393 INFO:     Found new best model at epoch 68
2023-01-05 11:14:27,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:27,394 INFO:     Epoch: 69
2023-01-05 11:14:29,535 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3882810225089391, 'Total loss': 0.3882810225089391} | train loss {'Reaction outcome loss': 0.2832046370055989, 'Total loss': 0.2832046370055989}
2023-01-05 11:14:29,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:29,535 INFO:     Epoch: 70
2023-01-05 11:14:31,710 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41313016215960185, 'Total loss': 0.41313016215960185} | train loss {'Reaction outcome loss': 0.279159491378678, 'Total loss': 0.279159491378678}
2023-01-05 11:14:31,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:31,712 INFO:     Epoch: 71
2023-01-05 11:14:33,906 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4012562404076258, 'Total loss': 0.4012562404076258} | train loss {'Reaction outcome loss': 0.26871488390177706, 'Total loss': 0.26871488390177706}
2023-01-05 11:14:33,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:33,906 INFO:     Epoch: 72
2023-01-05 11:14:36,056 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3922340134779612, 'Total loss': 0.3922340134779612} | train loss {'Reaction outcome loss': 0.27529301244194493, 'Total loss': 0.27529301244194493}
2023-01-05 11:14:36,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:36,056 INFO:     Epoch: 73
2023-01-05 11:14:38,194 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3872407207886378, 'Total loss': 0.3872407207886378} | train loss {'Reaction outcome loss': 0.2658811301999066, 'Total loss': 0.2658811301999066}
2023-01-05 11:14:38,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:38,195 INFO:     Epoch: 74
2023-01-05 11:14:40,330 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3949752325812976, 'Total loss': 0.3949752325812976} | train loss {'Reaction outcome loss': 0.26407706427530653, 'Total loss': 0.26407706427530653}
2023-01-05 11:14:40,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:40,331 INFO:     Epoch: 75
2023-01-05 11:14:42,473 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3804395467042923, 'Total loss': 0.3804395467042923} | train loss {'Reaction outcome loss': 0.2669319794479295, 'Total loss': 0.2669319794479295}
2023-01-05 11:14:42,473 INFO:     Found new best model at epoch 75
2023-01-05 11:14:42,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:42,474 INFO:     Epoch: 76
2023-01-05 11:14:44,644 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37766791582107545, 'Total loss': 0.37766791582107545} | train loss {'Reaction outcome loss': 0.2640247201397471, 'Total loss': 0.2640247201397471}
2023-01-05 11:14:44,645 INFO:     Found new best model at epoch 76
2023-01-05 11:14:44,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:44,647 INFO:     Epoch: 77
2023-01-05 11:14:46,800 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4132214198509852, 'Total loss': 0.4132214198509852} | train loss {'Reaction outcome loss': 0.2624765815090959, 'Total loss': 0.2624765815090959}
2023-01-05 11:14:46,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:46,800 INFO:     Epoch: 78
2023-01-05 11:14:48,930 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37811256349086764, 'Total loss': 0.37811256349086764} | train loss {'Reaction outcome loss': 0.2654527693334287, 'Total loss': 0.2654527693334287}
2023-01-05 11:14:48,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:48,931 INFO:     Epoch: 79
2023-01-05 11:14:51,078 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3941815157731374, 'Total loss': 0.3941815157731374} | train loss {'Reaction outcome loss': 0.25425547294073947, 'Total loss': 0.25425547294073947}
2023-01-05 11:14:51,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:51,078 INFO:     Epoch: 80
2023-01-05 11:14:53,236 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43179412285486857, 'Total loss': 0.43179412285486857} | train loss {'Reaction outcome loss': 0.25804743167339234, 'Total loss': 0.25804743167339234}
2023-01-05 11:14:53,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:53,237 INFO:     Epoch: 81
2023-01-05 11:14:55,412 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4085915754238764, 'Total loss': 0.4085915754238764} | train loss {'Reaction outcome loss': 0.25631304271519184, 'Total loss': 0.25631304271519184}
2023-01-05 11:14:55,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:55,413 INFO:     Epoch: 82
2023-01-05 11:14:57,565 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4111505806446075, 'Total loss': 0.4111505806446075} | train loss {'Reaction outcome loss': 0.259252483616617, 'Total loss': 0.259252483616617}
2023-01-05 11:14:57,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:57,566 INFO:     Epoch: 83
2023-01-05 11:14:59,767 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3658277918895086, 'Total loss': 0.3658277918895086} | train loss {'Reaction outcome loss': 0.2596063957597217, 'Total loss': 0.2596063957597217}
2023-01-05 11:14:59,767 INFO:     Found new best model at epoch 83
2023-01-05 11:14:59,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:14:59,768 INFO:     Epoch: 84
2023-01-05 11:15:01,939 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.366851698855559, 'Total loss': 0.366851698855559} | train loss {'Reaction outcome loss': 0.2535273935917738, 'Total loss': 0.2535273935917738}
2023-01-05 11:15:01,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:01,939 INFO:     Epoch: 85
2023-01-05 11:15:04,141 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4103304107983907, 'Total loss': 0.4103304107983907} | train loss {'Reaction outcome loss': 0.25945790621186915, 'Total loss': 0.25945790621186915}
2023-01-05 11:15:04,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:04,142 INFO:     Epoch: 86
2023-01-05 11:15:06,319 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38325362900892895, 'Total loss': 0.38325362900892895} | train loss {'Reaction outcome loss': 0.2548499099475189, 'Total loss': 0.2548499099475189}
2023-01-05 11:15:06,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:06,319 INFO:     Epoch: 87
2023-01-05 11:15:08,482 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38299598495165504, 'Total loss': 0.38299598495165504} | train loss {'Reaction outcome loss': 0.24930726510411413, 'Total loss': 0.24930726510411413}
2023-01-05 11:15:08,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:08,483 INFO:     Epoch: 88
2023-01-05 11:15:10,639 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39316710631052654, 'Total loss': 0.39316710631052654} | train loss {'Reaction outcome loss': 0.2492049346630373, 'Total loss': 0.2492049346630373}
2023-01-05 11:15:10,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:10,639 INFO:     Epoch: 89
2023-01-05 11:15:12,832 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38116812345882256, 'Total loss': 0.38116812345882256} | train loss {'Reaction outcome loss': 0.253422479383158, 'Total loss': 0.253422479383158}
2023-01-05 11:15:12,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:12,832 INFO:     Epoch: 90
2023-01-05 11:15:14,976 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39854654570420583, 'Total loss': 0.39854654570420583} | train loss {'Reaction outcome loss': 0.24634028015399936, 'Total loss': 0.24634028015399936}
2023-01-05 11:15:14,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:14,977 INFO:     Epoch: 91
2023-01-05 11:15:17,117 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3940427412589391, 'Total loss': 0.3940427412589391} | train loss {'Reaction outcome loss': 0.25144395211466797, 'Total loss': 0.25144395211466797}
2023-01-05 11:15:17,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:17,118 INFO:     Epoch: 92
2023-01-05 11:15:19,305 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3801527937253316, 'Total loss': 0.3801527937253316} | train loss {'Reaction outcome loss': 0.241832441929048, 'Total loss': 0.241832441929048}
2023-01-05 11:15:19,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:19,306 INFO:     Epoch: 93
2023-01-05 11:15:21,462 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43466480473677316, 'Total loss': 0.43466480473677316} | train loss {'Reaction outcome loss': 0.24170659489956867, 'Total loss': 0.24170659489956867}
2023-01-05 11:15:21,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:21,462 INFO:     Epoch: 94
2023-01-05 11:15:23,636 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41631432274977365, 'Total loss': 0.41631432274977365} | train loss {'Reaction outcome loss': 0.24348835455403275, 'Total loss': 0.24348835455403275}
2023-01-05 11:15:23,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:23,636 INFO:     Epoch: 95
2023-01-05 11:15:25,793 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38590375110507014, 'Total loss': 0.38590375110507014} | train loss {'Reaction outcome loss': 0.24776293248971448, 'Total loss': 0.24776293248971448}
2023-01-05 11:15:25,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:25,794 INFO:     Epoch: 96
2023-01-05 11:15:27,927 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36626207679510114, 'Total loss': 0.36626207679510114} | train loss {'Reaction outcome loss': 0.24112653256441555, 'Total loss': 0.24112653256441555}
2023-01-05 11:15:27,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:27,928 INFO:     Epoch: 97
2023-01-05 11:15:30,051 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41684215565522514, 'Total loss': 0.41684215565522514} | train loss {'Reaction outcome loss': 0.23378502236624812, 'Total loss': 0.23378502236624812}
2023-01-05 11:15:30,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:30,051 INFO:     Epoch: 98
2023-01-05 11:15:32,145 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.451400891939799, 'Total loss': 0.451400891939799} | train loss {'Reaction outcome loss': 0.24439139420805622, 'Total loss': 0.24439139420805622}
2023-01-05 11:15:32,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:32,145 INFO:     Epoch: 99
2023-01-05 11:15:34,263 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4211536889274915, 'Total loss': 0.4211536889274915} | train loss {'Reaction outcome loss': 0.23518584606094953, 'Total loss': 0.23518584606094953}
2023-01-05 11:15:34,263 INFO:     Best model found after epoch 84 of 100.
2023-01-05 11:15:34,263 INFO:   Done with stage: TRAINING
2023-01-05 11:15:34,263 INFO:   Starting stage: EVALUATION
2023-01-05 11:15:34,404 INFO:   Done with stage: EVALUATION
2023-01-05 11:15:34,412 INFO:   Leaving out SEQ value Fold_0
2023-01-05 11:15:34,425 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 11:15:34,425 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:15:35,065 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:15:35,065 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:15:35,133 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:15:35,133 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:15:35,133 INFO:     No hyperparam tuning for this model
2023-01-05 11:15:35,133 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:15:35,133 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:15:35,134 INFO:     None feature selector for col prot
2023-01-05 11:15:35,134 INFO:     None feature selector for col prot
2023-01-05 11:15:35,134 INFO:     None feature selector for col prot
2023-01-05 11:15:35,135 INFO:     None feature selector for col chem
2023-01-05 11:15:35,135 INFO:     None feature selector for col chem
2023-01-05 11:15:35,135 INFO:     None feature selector for col chem
2023-01-05 11:15:35,135 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:15:35,135 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:15:35,136 INFO:     Number of params in model 72901
2023-01-05 11:15:35,139 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:15:35,140 INFO:   Starting stage: TRAINING
2023-01-05 11:15:35,198 INFO:     Val loss before train {'Reaction outcome loss': 1.032720975081126, 'Total loss': 1.032720975081126}
2023-01-05 11:15:35,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:35,198 INFO:     Epoch: 0
2023-01-05 11:15:37,313 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8455958882967631, 'Total loss': 0.8455958882967631} | train loss {'Reaction outcome loss': 0.9246847809671046, 'Total loss': 0.9246847809671046}
2023-01-05 11:15:37,313 INFO:     Found new best model at epoch 0
2023-01-05 11:15:37,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:37,315 INFO:     Epoch: 1
2023-01-05 11:15:39,445 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6272825936476389, 'Total loss': 0.6272825936476389} | train loss {'Reaction outcome loss': 0.720755764416286, 'Total loss': 0.720755764416286}
2023-01-05 11:15:39,446 INFO:     Found new best model at epoch 1
2023-01-05 11:15:39,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:39,447 INFO:     Epoch: 2
2023-01-05 11:15:41,537 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6018920779228211, 'Total loss': 0.6018920779228211} | train loss {'Reaction outcome loss': 0.5782544205695281, 'Total loss': 0.5782544205695281}
2023-01-05 11:15:41,537 INFO:     Found new best model at epoch 2
2023-01-05 11:15:41,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:41,538 INFO:     Epoch: 3
2023-01-05 11:15:43,664 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5534329136212667, 'Total loss': 0.5534329136212667} | train loss {'Reaction outcome loss': 0.532201967341996, 'Total loss': 0.532201967341996}
2023-01-05 11:15:43,664 INFO:     Found new best model at epoch 3
2023-01-05 11:15:43,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:43,666 INFO:     Epoch: 4
2023-01-05 11:15:45,769 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5699841886758804, 'Total loss': 0.5699841886758804} | train loss {'Reaction outcome loss': 0.5120292161301379, 'Total loss': 0.5120292161301379}
2023-01-05 11:15:45,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:45,769 INFO:     Epoch: 5
2023-01-05 11:15:47,891 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5487990160783132, 'Total loss': 0.5487990160783132} | train loss {'Reaction outcome loss': 0.49989878620966016, 'Total loss': 0.49989878620966016}
2023-01-05 11:15:47,891 INFO:     Found new best model at epoch 5
2023-01-05 11:15:47,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:47,892 INFO:     Epoch: 6
2023-01-05 11:15:50,020 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5580978473027547, 'Total loss': 0.5580978473027547} | train loss {'Reaction outcome loss': 0.4904635177700074, 'Total loss': 0.4904635177700074}
2023-01-05 11:15:50,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:50,021 INFO:     Epoch: 7
2023-01-05 11:15:52,140 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5306173920631408, 'Total loss': 0.5306173920631408} | train loss {'Reaction outcome loss': 0.4801470482851559, 'Total loss': 0.4801470482851559}
2023-01-05 11:15:52,140 INFO:     Found new best model at epoch 7
2023-01-05 11:15:52,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:52,142 INFO:     Epoch: 8
2023-01-05 11:15:54,258 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5305802583694458, 'Total loss': 0.5305802583694458} | train loss {'Reaction outcome loss': 0.4759054938842962, 'Total loss': 0.4759054938842962}
2023-01-05 11:15:54,259 INFO:     Found new best model at epoch 8
2023-01-05 11:15:54,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:54,260 INFO:     Epoch: 9
2023-01-05 11:15:56,383 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5377533336480459, 'Total loss': 0.5377533336480459} | train loss {'Reaction outcome loss': 0.46388078887602346, 'Total loss': 0.46388078887602346}
2023-01-05 11:15:56,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:56,384 INFO:     Epoch: 10
2023-01-05 11:15:58,487 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5191566854715347, 'Total loss': 0.5191566854715347} | train loss {'Reaction outcome loss': 0.4598265089394845, 'Total loss': 0.4598265089394845}
2023-01-05 11:15:58,487 INFO:     Found new best model at epoch 10
2023-01-05 11:15:58,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:15:58,489 INFO:     Epoch: 11
2023-01-05 11:16:00,607 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5607043306032816, 'Total loss': 0.5607043306032816} | train loss {'Reaction outcome loss': 0.4576860106799192, 'Total loss': 0.4576860106799192}
2023-01-05 11:16:00,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:00,608 INFO:     Epoch: 12
2023-01-05 11:16:02,724 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5330870648225149, 'Total loss': 0.5330870648225149} | train loss {'Reaction outcome loss': 0.45185424914181016, 'Total loss': 0.45185424914181016}
2023-01-05 11:16:02,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:02,725 INFO:     Epoch: 13
2023-01-05 11:16:04,823 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5554739604393641, 'Total loss': 0.5554739604393641} | train loss {'Reaction outcome loss': 0.44988940219521084, 'Total loss': 0.44988940219521084}
2023-01-05 11:16:04,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:04,824 INFO:     Epoch: 14
2023-01-05 11:16:06,934 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5077604532241822, 'Total loss': 0.5077604532241822} | train loss {'Reaction outcome loss': 0.44219635841828997, 'Total loss': 0.44219635841828997}
2023-01-05 11:16:06,934 INFO:     Found new best model at epoch 14
2023-01-05 11:16:06,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:06,935 INFO:     Epoch: 15
2023-01-05 11:16:09,052 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5148530264695486, 'Total loss': 0.5148530264695486} | train loss {'Reaction outcome loss': 0.4361683551645104, 'Total loss': 0.4361683551645104}
2023-01-05 11:16:09,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:09,052 INFO:     Epoch: 16
2023-01-05 11:16:11,171 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5030411591132482, 'Total loss': 0.5030411591132482} | train loss {'Reaction outcome loss': 0.43308268858617915, 'Total loss': 0.43308268858617915}
2023-01-05 11:16:11,172 INFO:     Found new best model at epoch 16
2023-01-05 11:16:11,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:11,173 INFO:     Epoch: 17
2023-01-05 11:16:13,298 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49946126888195674, 'Total loss': 0.49946126888195674} | train loss {'Reaction outcome loss': 0.42721313551996215, 'Total loss': 0.42721313551996215}
2023-01-05 11:16:13,299 INFO:     Found new best model at epoch 17
2023-01-05 11:16:13,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:13,300 INFO:     Epoch: 18
2023-01-05 11:16:15,380 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4920904894669851, 'Total loss': 0.4920904894669851} | train loss {'Reaction outcome loss': 0.4317437349767475, 'Total loss': 0.4317437349767475}
2023-01-05 11:16:15,380 INFO:     Found new best model at epoch 18
2023-01-05 11:16:15,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:15,381 INFO:     Epoch: 19
2023-01-05 11:16:17,476 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48063480059305824, 'Total loss': 0.48063480059305824} | train loss {'Reaction outcome loss': 0.4201182364434986, 'Total loss': 0.4201182364434986}
2023-01-05 11:16:17,476 INFO:     Found new best model at epoch 19
2023-01-05 11:16:17,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:17,477 INFO:     Epoch: 20
2023-01-05 11:16:19,567 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4822612146536509, 'Total loss': 0.4822612146536509} | train loss {'Reaction outcome loss': 0.41801702173856586, 'Total loss': 0.41801702173856586}
2023-01-05 11:16:19,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:19,567 INFO:     Epoch: 21
2023-01-05 11:16:21,688 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4939993838469187, 'Total loss': 0.4939993838469187} | train loss {'Reaction outcome loss': 0.4142799224881899, 'Total loss': 0.4142799224881899}
2023-01-05 11:16:21,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:21,688 INFO:     Epoch: 22
2023-01-05 11:16:23,778 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4758099138736725, 'Total loss': 0.4758099138736725} | train loss {'Reaction outcome loss': 0.41151048930791706, 'Total loss': 0.41151048930791706}
2023-01-05 11:16:23,778 INFO:     Found new best model at epoch 22
2023-01-05 11:16:23,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:23,779 INFO:     Epoch: 23
2023-01-05 11:16:25,890 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4968344926834106, 'Total loss': 0.4968344926834106} | train loss {'Reaction outcome loss': 0.40393438596865194, 'Total loss': 0.40393438596865194}
2023-01-05 11:16:25,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:25,890 INFO:     Epoch: 24
2023-01-05 11:16:27,981 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.500078210234642, 'Total loss': 0.500078210234642} | train loss {'Reaction outcome loss': 0.4008977507333179, 'Total loss': 0.4008977507333179}
2023-01-05 11:16:27,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:27,981 INFO:     Epoch: 25
2023-01-05 11:16:30,077 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4825394262870153, 'Total loss': 0.4825394262870153} | train loss {'Reaction outcome loss': 0.4011780603860433, 'Total loss': 0.4011780603860433}
2023-01-05 11:16:30,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:30,079 INFO:     Epoch: 26
2023-01-05 11:16:32,173 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4628202031056086, 'Total loss': 0.4628202031056086} | train loss {'Reaction outcome loss': 0.39375458840594624, 'Total loss': 0.39375458840594624}
2023-01-05 11:16:32,173 INFO:     Found new best model at epoch 26
2023-01-05 11:16:32,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:32,174 INFO:     Epoch: 27
2023-01-05 11:16:34,256 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47454129258791605, 'Total loss': 0.47454129258791605} | train loss {'Reaction outcome loss': 0.39443312751832027, 'Total loss': 0.39443312751832027}
2023-01-05 11:16:34,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:34,257 INFO:     Epoch: 28
2023-01-05 11:16:36,388 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4689308653275172, 'Total loss': 0.4689308653275172} | train loss {'Reaction outcome loss': 0.3824330309180768, 'Total loss': 0.3824330309180768}
2023-01-05 11:16:36,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:36,389 INFO:     Epoch: 29
2023-01-05 11:16:38,537 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4703559090693792, 'Total loss': 0.4703559090693792} | train loss {'Reaction outcome loss': 0.38111440949278436, 'Total loss': 0.38111440949278436}
2023-01-05 11:16:38,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:38,537 INFO:     Epoch: 30
2023-01-05 11:16:40,665 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45167418122291564, 'Total loss': 0.45167418122291564} | train loss {'Reaction outcome loss': 0.3809555764054204, 'Total loss': 0.3809555764054204}
2023-01-05 11:16:40,665 INFO:     Found new best model at epoch 30
2023-01-05 11:16:40,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:40,667 INFO:     Epoch: 31
2023-01-05 11:16:42,772 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.479140959183375, 'Total loss': 0.479140959183375} | train loss {'Reaction outcome loss': 0.3745615377803862, 'Total loss': 0.3745615377803862}
2023-01-05 11:16:42,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:42,772 INFO:     Epoch: 32
2023-01-05 11:16:44,853 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.503386253118515, 'Total loss': 0.503386253118515} | train loss {'Reaction outcome loss': 0.3725021001183506, 'Total loss': 0.3725021001183506}
2023-01-05 11:16:44,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:44,854 INFO:     Epoch: 33
2023-01-05 11:16:46,952 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5066771189371745, 'Total loss': 0.5066771189371745} | train loss {'Reaction outcome loss': 0.3670929632125757, 'Total loss': 0.3670929632125757}
2023-01-05 11:16:46,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:46,953 INFO:     Epoch: 34
2023-01-05 11:16:49,036 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4601077874501546, 'Total loss': 0.4601077874501546} | train loss {'Reaction outcome loss': 0.3696529501196229, 'Total loss': 0.3696529501196229}
2023-01-05 11:16:49,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:49,037 INFO:     Epoch: 35
2023-01-05 11:16:51,129 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4549184779326121, 'Total loss': 0.4549184779326121} | train loss {'Reaction outcome loss': 0.36286905994672913, 'Total loss': 0.36286905994672913}
2023-01-05 11:16:51,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:51,129 INFO:     Epoch: 36
2023-01-05 11:16:53,240 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4504232386747996, 'Total loss': 0.4504232386747996} | train loss {'Reaction outcome loss': 0.35367509680407827, 'Total loss': 0.35367509680407827}
2023-01-05 11:16:53,240 INFO:     Found new best model at epoch 36
2023-01-05 11:16:53,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:53,241 INFO:     Epoch: 37
2023-01-05 11:16:55,341 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47091873933871586, 'Total loss': 0.47091873933871586} | train loss {'Reaction outcome loss': 0.35893592904338906, 'Total loss': 0.35893592904338906}
2023-01-05 11:16:55,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:55,341 INFO:     Epoch: 38
2023-01-05 11:16:57,432 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4750508030255636, 'Total loss': 0.4750508030255636} | train loss {'Reaction outcome loss': 0.35490973443884555, 'Total loss': 0.35490973443884555}
2023-01-05 11:16:57,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:57,432 INFO:     Epoch: 39
2023-01-05 11:16:59,563 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49846624334653217, 'Total loss': 0.49846624334653217} | train loss {'Reaction outcome loss': 0.3523195227369284, 'Total loss': 0.3523195227369284}
2023-01-05 11:16:59,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:16:59,563 INFO:     Epoch: 40
2023-01-05 11:17:01,714 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48431252837181094, 'Total loss': 0.48431252837181094} | train loss {'Reaction outcome loss': 0.341588884605702, 'Total loss': 0.341588884605702}
2023-01-05 11:17:01,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:01,715 INFO:     Epoch: 41
2023-01-05 11:17:03,844 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4803238332271576, 'Total loss': 0.4803238332271576} | train loss {'Reaction outcome loss': 0.34676816216209433, 'Total loss': 0.34676816216209433}
2023-01-05 11:17:03,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:03,845 INFO:     Epoch: 42
2023-01-05 11:17:05,988 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4429231820007165, 'Total loss': 0.4429231820007165} | train loss {'Reaction outcome loss': 0.3365879378353174, 'Total loss': 0.3365879378353174}
2023-01-05 11:17:05,989 INFO:     Found new best model at epoch 42
2023-01-05 11:17:05,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:05,990 INFO:     Epoch: 43
2023-01-05 11:17:08,088 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4391888161500295, 'Total loss': 0.4391888161500295} | train loss {'Reaction outcome loss': 0.34452718095137524, 'Total loss': 0.34452718095137524}
2023-01-05 11:17:08,088 INFO:     Found new best model at epoch 43
2023-01-05 11:17:08,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:08,090 INFO:     Epoch: 44
2023-01-05 11:17:10,203 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45052928328514097, 'Total loss': 0.45052928328514097} | train loss {'Reaction outcome loss': 0.3335015825763509, 'Total loss': 0.3335015825763509}
2023-01-05 11:17:10,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:10,203 INFO:     Epoch: 45
2023-01-05 11:17:12,302 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4657056137919426, 'Total loss': 0.4657056137919426} | train loss {'Reaction outcome loss': 0.3256850572705487, 'Total loss': 0.3256850572705487}
2023-01-05 11:17:12,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:12,303 INFO:     Epoch: 46
2023-01-05 11:17:14,397 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4509870529174805, 'Total loss': 0.4509870529174805} | train loss {'Reaction outcome loss': 0.3253622327354692, 'Total loss': 0.3253622327354692}
2023-01-05 11:17:14,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:14,397 INFO:     Epoch: 47
2023-01-05 11:17:16,486 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4352062910795212, 'Total loss': 0.4352062910795212} | train loss {'Reaction outcome loss': 0.3266427117935467, 'Total loss': 0.3266427117935467}
2023-01-05 11:17:16,486 INFO:     Found new best model at epoch 47
2023-01-05 11:17:16,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:16,488 INFO:     Epoch: 48
2023-01-05 11:17:18,604 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4394268110394478, 'Total loss': 0.4394268110394478} | train loss {'Reaction outcome loss': 0.3267398391041782, 'Total loss': 0.3267398391041782}
2023-01-05 11:17:18,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:18,604 INFO:     Epoch: 49
2023-01-05 11:17:20,707 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4490028987328211, 'Total loss': 0.4490028987328211} | train loss {'Reaction outcome loss': 0.33013545328771676, 'Total loss': 0.33013545328771676}
2023-01-05 11:17:20,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:20,708 INFO:     Epoch: 50
2023-01-05 11:17:22,804 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45112691521644593, 'Total loss': 0.45112691521644593} | train loss {'Reaction outcome loss': 0.3237103144655298, 'Total loss': 0.3237103144655298}
2023-01-05 11:17:22,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:22,804 INFO:     Epoch: 51
2023-01-05 11:17:24,902 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4236916542053223, 'Total loss': 0.4236916542053223} | train loss {'Reaction outcome loss': 0.31797929165455013, 'Total loss': 0.31797929165455013}
2023-01-05 11:17:24,902 INFO:     Found new best model at epoch 51
2023-01-05 11:17:24,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:24,904 INFO:     Epoch: 52
2023-01-05 11:17:27,006 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43759419620037077, 'Total loss': 0.43759419620037077} | train loss {'Reaction outcome loss': 0.3155349528642146, 'Total loss': 0.3155349528642146}
2023-01-05 11:17:27,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:27,006 INFO:     Epoch: 53
2023-01-05 11:17:29,111 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47422697842121125, 'Total loss': 0.47422697842121125} | train loss {'Reaction outcome loss': 0.3138180621268548, 'Total loss': 0.3138180621268548}
2023-01-05 11:17:29,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:29,111 INFO:     Epoch: 54
2023-01-05 11:17:31,211 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4813972373803457, 'Total loss': 0.4813972373803457} | train loss {'Reaction outcome loss': 0.3136065068480733, 'Total loss': 0.3136065068480733}
2023-01-05 11:17:31,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:31,211 INFO:     Epoch: 55
2023-01-05 11:17:33,305 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4364768475294113, 'Total loss': 0.4364768475294113} | train loss {'Reaction outcome loss': 0.311260149374113, 'Total loss': 0.311260149374113}
2023-01-05 11:17:33,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:33,306 INFO:     Epoch: 56
2023-01-05 11:17:35,400 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4396279513835907, 'Total loss': 0.4396279513835907} | train loss {'Reaction outcome loss': 0.3091628399742392, 'Total loss': 0.3091628399742392}
2023-01-05 11:17:35,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:35,400 INFO:     Epoch: 57
2023-01-05 11:17:37,507 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4520400712887446, 'Total loss': 0.4520400712887446} | train loss {'Reaction outcome loss': 0.29127757114464004, 'Total loss': 0.29127757114464004}
2023-01-05 11:17:37,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:37,507 INFO:     Epoch: 58
2023-01-05 11:17:39,607 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.449834876259168, 'Total loss': 0.449834876259168} | train loss {'Reaction outcome loss': 0.3014625205143249, 'Total loss': 0.3014625205143249}
2023-01-05 11:17:39,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:39,607 INFO:     Epoch: 59
2023-01-05 11:17:41,720 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43370943069458007, 'Total loss': 0.43370943069458007} | train loss {'Reaction outcome loss': 0.30079239734786223, 'Total loss': 0.30079239734786223}
2023-01-05 11:17:41,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:41,721 INFO:     Epoch: 60
2023-01-05 11:17:43,828 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4352046330769857, 'Total loss': 0.4352046330769857} | train loss {'Reaction outcome loss': 0.2940833468959008, 'Total loss': 0.2940833468959008}
2023-01-05 11:17:43,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:43,829 INFO:     Epoch: 61
2023-01-05 11:17:45,944 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4513672004143397, 'Total loss': 0.4513672004143397} | train loss {'Reaction outcome loss': 0.2980542065841811, 'Total loss': 0.2980542065841811}
2023-01-05 11:17:45,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:45,945 INFO:     Epoch: 62
2023-01-05 11:17:48,024 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5076391796271006, 'Total loss': 0.5076391796271006} | train loss {'Reaction outcome loss': 0.29654433096216604, 'Total loss': 0.29654433096216604}
2023-01-05 11:17:48,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:48,024 INFO:     Epoch: 63
2023-01-05 11:17:50,112 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4431435565153758, 'Total loss': 0.4431435565153758} | train loss {'Reaction outcome loss': 0.2911042627697681, 'Total loss': 0.2911042627697681}
2023-01-05 11:17:50,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:50,112 INFO:     Epoch: 64
2023-01-05 11:17:52,214 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4456917891899745, 'Total loss': 0.4456917891899745} | train loss {'Reaction outcome loss': 0.288999060298497, 'Total loss': 0.288999060298497}
2023-01-05 11:17:52,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:52,215 INFO:     Epoch: 65
2023-01-05 11:17:54,306 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4551981419324875, 'Total loss': 0.4551981419324875} | train loss {'Reaction outcome loss': 0.2827795642690781, 'Total loss': 0.2827795642690781}
2023-01-05 11:17:54,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:54,306 INFO:     Epoch: 66
2023-01-05 11:17:56,439 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.450829271475474, 'Total loss': 0.450829271475474} | train loss {'Reaction outcome loss': 0.2881324825562782, 'Total loss': 0.2881324825562782}
2023-01-05 11:17:56,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:56,439 INFO:     Epoch: 67
2023-01-05 11:17:58,565 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43388774394989016, 'Total loss': 0.43388774394989016} | train loss {'Reaction outcome loss': 0.28812065075114096, 'Total loss': 0.28812065075114096}
2023-01-05 11:17:58,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:17:58,565 INFO:     Epoch: 68
2023-01-05 11:18:00,663 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4621345460414886, 'Total loss': 0.4621345460414886} | train loss {'Reaction outcome loss': 0.28418826975010253, 'Total loss': 0.28418826975010253}
2023-01-05 11:18:00,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:00,663 INFO:     Epoch: 69
2023-01-05 11:18:02,614 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43538212577501934, 'Total loss': 0.43538212577501934} | train loss {'Reaction outcome loss': 0.28571799491624256, 'Total loss': 0.28571799491624256}
2023-01-05 11:18:02,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:02,615 INFO:     Epoch: 70
2023-01-05 11:18:04,693 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43977299630641936, 'Total loss': 0.43977299630641936} | train loss {'Reaction outcome loss': 0.2798831157604635, 'Total loss': 0.2798831157604635}
2023-01-05 11:18:04,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:04,694 INFO:     Epoch: 71
2023-01-05 11:18:06,806 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46540201008319854, 'Total loss': 0.46540201008319854} | train loss {'Reaction outcome loss': 0.2881029300364383, 'Total loss': 0.2881029300364383}
2023-01-05 11:18:06,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:06,806 INFO:     Epoch: 72
2023-01-05 11:18:08,898 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41620867351690927, 'Total loss': 0.41620867351690927} | train loss {'Reaction outcome loss': 0.2712404259067752, 'Total loss': 0.2712404259067752}
2023-01-05 11:18:08,898 INFO:     Found new best model at epoch 72
2023-01-05 11:18:08,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:08,899 INFO:     Epoch: 73
2023-01-05 11:18:11,030 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4326314856608709, 'Total loss': 0.4326314856608709} | train loss {'Reaction outcome loss': 0.281330878836113, 'Total loss': 0.281330878836113}
2023-01-05 11:18:11,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:11,030 INFO:     Epoch: 74
2023-01-05 11:18:13,160 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45648923392097157, 'Total loss': 0.45648923392097157} | train loss {'Reaction outcome loss': 0.27355892623300515, 'Total loss': 0.27355892623300515}
2023-01-05 11:18:13,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:13,161 INFO:     Epoch: 75
2023-01-05 11:18:15,277 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48072563807169594, 'Total loss': 0.48072563807169594} | train loss {'Reaction outcome loss': 0.2764995026814959, 'Total loss': 0.2764995026814959}
2023-01-05 11:18:15,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:15,277 INFO:     Epoch: 76
2023-01-05 11:18:17,397 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4507888376712799, 'Total loss': 0.4507888376712799} | train loss {'Reaction outcome loss': 0.27562408978904124, 'Total loss': 0.27562408978904124}
2023-01-05 11:18:17,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:17,398 INFO:     Epoch: 77
2023-01-05 11:18:19,516 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.458858448266983, 'Total loss': 0.458858448266983} | train loss {'Reaction outcome loss': 0.2714530991547274, 'Total loss': 0.2714530991547274}
2023-01-05 11:18:19,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:19,518 INFO:     Epoch: 78
2023-01-05 11:18:21,613 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46889314651489256, 'Total loss': 0.46889314651489256} | train loss {'Reaction outcome loss': 0.2675790751537124, 'Total loss': 0.2675790751537124}
2023-01-05 11:18:21,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:21,614 INFO:     Epoch: 79
2023-01-05 11:18:23,729 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4392580986022949, 'Total loss': 0.4392580986022949} | train loss {'Reaction outcome loss': 0.26972594872908495, 'Total loss': 0.26972594872908495}
2023-01-05 11:18:23,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:23,729 INFO:     Epoch: 80
2023-01-05 11:18:25,837 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47338487952947617, 'Total loss': 0.47338487952947617} | train loss {'Reaction outcome loss': 0.2696448231231926, 'Total loss': 0.2696448231231926}
2023-01-05 11:18:25,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:25,838 INFO:     Epoch: 81
2023-01-05 11:18:27,932 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48878492911656696, 'Total loss': 0.48878492911656696} | train loss {'Reaction outcome loss': 0.27363226418093445, 'Total loss': 0.27363226418093445}
2023-01-05 11:18:27,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:27,933 INFO:     Epoch: 82
2023-01-05 11:18:30,036 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4122281109293302, 'Total loss': 0.4122281109293302} | train loss {'Reaction outcome loss': 0.26434983087246455, 'Total loss': 0.26434983087246455}
2023-01-05 11:18:30,036 INFO:     Found new best model at epoch 82
2023-01-05 11:18:30,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:30,037 INFO:     Epoch: 83
2023-01-05 11:18:32,141 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4388973464568456, 'Total loss': 0.4388973464568456} | train loss {'Reaction outcome loss': 0.26663508053336826, 'Total loss': 0.26663508053336826}
2023-01-05 11:18:32,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:32,142 INFO:     Epoch: 84
2023-01-05 11:18:34,236 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46731360753377277, 'Total loss': 0.46731360753377277} | train loss {'Reaction outcome loss': 0.25986067699643717, 'Total loss': 0.25986067699643717}
2023-01-05 11:18:34,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:34,237 INFO:     Epoch: 85
2023-01-05 11:18:36,354 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43312055071194966, 'Total loss': 0.43312055071194966} | train loss {'Reaction outcome loss': 0.25673404049414855, 'Total loss': 0.25673404049414855}
2023-01-05 11:18:36,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:36,355 INFO:     Epoch: 86
2023-01-05 11:18:38,460 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4323424011468887, 'Total loss': 0.4323424011468887} | train loss {'Reaction outcome loss': 0.25794115700100584, 'Total loss': 0.25794115700100584}
2023-01-05 11:18:38,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:38,461 INFO:     Epoch: 87
2023-01-05 11:18:40,565 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4711333413918813, 'Total loss': 0.4711333413918813} | train loss {'Reaction outcome loss': 0.2591056809811802, 'Total loss': 0.2591056809811802}
2023-01-05 11:18:40,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:40,566 INFO:     Epoch: 88
2023-01-05 11:18:42,664 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4355507145325343, 'Total loss': 0.4355507145325343} | train loss {'Reaction outcome loss': 0.258146380555335, 'Total loss': 0.258146380555335}
2023-01-05 11:18:42,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:42,664 INFO:     Epoch: 89
2023-01-05 11:18:44,785 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4320054050534964, 'Total loss': 0.4320054050534964} | train loss {'Reaction outcome loss': 0.25818184159368607, 'Total loss': 0.25818184159368607}
2023-01-05 11:18:44,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:44,785 INFO:     Epoch: 90
2023-01-05 11:18:46,910 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4639052053292592, 'Total loss': 0.4639052053292592} | train loss {'Reaction outcome loss': 0.2579508212432538, 'Total loss': 0.2579508212432538}
2023-01-05 11:18:46,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:46,910 INFO:     Epoch: 91
2023-01-05 11:18:49,047 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45037146508693693, 'Total loss': 0.45037146508693693} | train loss {'Reaction outcome loss': 0.2560293199835625, 'Total loss': 0.2560293199835625}
2023-01-05 11:18:49,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:49,048 INFO:     Epoch: 92
2023-01-05 11:18:51,150 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4523814357817173, 'Total loss': 0.4523814357817173} | train loss {'Reaction outcome loss': 0.2537594453564712, 'Total loss': 0.2537594453564712}
2023-01-05 11:18:51,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:51,150 INFO:     Epoch: 93
2023-01-05 11:18:53,250 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46546947161356605, 'Total loss': 0.46546947161356605} | train loss {'Reaction outcome loss': 0.2599871258350301, 'Total loss': 0.2599871258350301}
2023-01-05 11:18:53,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:53,250 INFO:     Epoch: 94
2023-01-05 11:18:55,374 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4360000987847646, 'Total loss': 0.4360000987847646} | train loss {'Reaction outcome loss': 0.2582348046872096, 'Total loss': 0.2582348046872096}
2023-01-05 11:18:55,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:55,375 INFO:     Epoch: 95
2023-01-05 11:18:57,465 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44572860399881997, 'Total loss': 0.44572860399881997} | train loss {'Reaction outcome loss': 0.2542451935233514, 'Total loss': 0.2542451935233514}
2023-01-05 11:18:57,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:57,466 INFO:     Epoch: 96
2023-01-05 11:18:59,562 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4292941470940908, 'Total loss': 0.4292941470940908} | train loss {'Reaction outcome loss': 0.2518660428596067, 'Total loss': 0.2518660428596067}
2023-01-05 11:18:59,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:18:59,563 INFO:     Epoch: 97
2023-01-05 11:19:01,688 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46391242543856304, 'Total loss': 0.46391242543856304} | train loss {'Reaction outcome loss': 0.2461359659448648, 'Total loss': 0.2461359659448648}
2023-01-05 11:19:01,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:01,688 INFO:     Epoch: 98
2023-01-05 11:19:03,789 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44821865955988566, 'Total loss': 0.44821865955988566} | train loss {'Reaction outcome loss': 0.24913203570950818, 'Total loss': 0.24913203570950818}
2023-01-05 11:19:03,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:03,789 INFO:     Epoch: 99
2023-01-05 11:19:05,909 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44007326165835065, 'Total loss': 0.44007326165835065} | train loss {'Reaction outcome loss': 0.25604270328341167, 'Total loss': 0.25604270328341167}
2023-01-05 11:19:05,909 INFO:     Best model found after epoch 83 of 100.
2023-01-05 11:19:05,909 INFO:   Done with stage: TRAINING
2023-01-05 11:19:05,909 INFO:   Starting stage: EVALUATION
2023-01-05 11:19:06,055 INFO:   Done with stage: EVALUATION
2023-01-05 11:19:06,055 INFO:   Leaving out SEQ value Fold_1
2023-01-05 11:19:06,068 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:19:06,068 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:19:06,702 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:19:06,702 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:19:06,770 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:19:06,771 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:19:06,771 INFO:     No hyperparam tuning for this model
2023-01-05 11:19:06,771 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:19:06,771 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:19:06,771 INFO:     None feature selector for col prot
2023-01-05 11:19:06,772 INFO:     None feature selector for col prot
2023-01-05 11:19:06,772 INFO:     None feature selector for col prot
2023-01-05 11:19:06,772 INFO:     None feature selector for col chem
2023-01-05 11:19:06,772 INFO:     None feature selector for col chem
2023-01-05 11:19:06,772 INFO:     None feature selector for col chem
2023-01-05 11:19:06,772 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:19:06,773 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:19:06,774 INFO:     Number of params in model 72901
2023-01-05 11:19:06,777 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:19:06,777 INFO:   Starting stage: TRAINING
2023-01-05 11:19:06,835 INFO:     Val loss before train {'Reaction outcome loss': 1.046183454990387, 'Total loss': 1.046183454990387}
2023-01-05 11:19:06,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:06,836 INFO:     Epoch: 0
2023-01-05 11:19:08,944 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9190397222836812, 'Total loss': 0.9190397222836812} | train loss {'Reaction outcome loss': 0.9340078594693302, 'Total loss': 0.9340078594693302}
2023-01-05 11:19:08,945 INFO:     Found new best model at epoch 0
2023-01-05 11:19:08,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:08,946 INFO:     Epoch: 1
2023-01-05 11:19:11,100 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6698649485905965, 'Total loss': 0.6698649485905965} | train loss {'Reaction outcome loss': 0.7695968289227382, 'Total loss': 0.7695968289227382}
2023-01-05 11:19:11,100 INFO:     Found new best model at epoch 1
2023-01-05 11:19:11,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:11,101 INFO:     Epoch: 2
2023-01-05 11:19:13,219 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6610569934050242, 'Total loss': 0.6610569934050242} | train loss {'Reaction outcome loss': 0.6071890484895149, 'Total loss': 0.6071890484895149}
2023-01-05 11:19:13,219 INFO:     Found new best model at epoch 2
2023-01-05 11:19:13,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:13,220 INFO:     Epoch: 3
2023-01-05 11:19:15,333 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6195649723211925, 'Total loss': 0.6195649723211925} | train loss {'Reaction outcome loss': 0.5446270433981923, 'Total loss': 0.5446270433981923}
2023-01-05 11:19:15,333 INFO:     Found new best model at epoch 3
2023-01-05 11:19:15,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:15,335 INFO:     Epoch: 4
2023-01-05 11:19:17,414 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5489486555258433, 'Total loss': 0.5489486555258433} | train loss {'Reaction outcome loss': 0.5236164149250427, 'Total loss': 0.5236164149250427}
2023-01-05 11:19:17,414 INFO:     Found new best model at epoch 4
2023-01-05 11:19:17,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:17,415 INFO:     Epoch: 5
2023-01-05 11:19:19,528 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.579252686103185, 'Total loss': 0.579252686103185} | train loss {'Reaction outcome loss': 0.5044510262019007, 'Total loss': 0.5044510262019007}
2023-01-05 11:19:19,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:19,528 INFO:     Epoch: 6
2023-01-05 11:19:21,646 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5782518366972605, 'Total loss': 0.5782518366972605} | train loss {'Reaction outcome loss': 0.49834401339945134, 'Total loss': 0.49834401339945134}
2023-01-05 11:19:21,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:21,646 INFO:     Epoch: 7
2023-01-05 11:19:23,765 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5436517755190532, 'Total loss': 0.5436517755190532} | train loss {'Reaction outcome loss': 0.4902014578182767, 'Total loss': 0.4902014578182767}
2023-01-05 11:19:23,765 INFO:     Found new best model at epoch 7
2023-01-05 11:19:23,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:23,767 INFO:     Epoch: 8
2023-01-05 11:19:25,870 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5258195459842682, 'Total loss': 0.5258195459842682} | train loss {'Reaction outcome loss': 0.4793504956212357, 'Total loss': 0.4793504956212357}
2023-01-05 11:19:25,871 INFO:     Found new best model at epoch 8
2023-01-05 11:19:25,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:25,872 INFO:     Epoch: 9
2023-01-05 11:19:27,989 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5326354444026947, 'Total loss': 0.5326354444026947} | train loss {'Reaction outcome loss': 0.4744955938934845, 'Total loss': 0.4744955938934845}
2023-01-05 11:19:27,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:27,990 INFO:     Epoch: 10
2023-01-05 11:19:30,085 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5430819729963938, 'Total loss': 0.5430819729963938} | train loss {'Reaction outcome loss': 0.4650298303169926, 'Total loss': 0.4650298303169926}
2023-01-05 11:19:30,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:30,086 INFO:     Epoch: 11
2023-01-05 11:19:32,206 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5163607835769654, 'Total loss': 0.5163607835769654} | train loss {'Reaction outcome loss': 0.4643515711718232, 'Total loss': 0.4643515711718232}
2023-01-05 11:19:32,206 INFO:     Found new best model at epoch 11
2023-01-05 11:19:32,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:32,208 INFO:     Epoch: 12
2023-01-05 11:19:34,316 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5202062557140986, 'Total loss': 0.5202062557140986} | train loss {'Reaction outcome loss': 0.45889611561259214, 'Total loss': 0.45889611561259214}
2023-01-05 11:19:34,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:34,316 INFO:     Epoch: 13
2023-01-05 11:19:36,410 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.51906259059906, 'Total loss': 0.51906259059906} | train loss {'Reaction outcome loss': 0.4566890053777364, 'Total loss': 0.4566890053777364}
2023-01-05 11:19:36,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:36,410 INFO:     Epoch: 14
2023-01-05 11:19:38,499 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5242492616176605, 'Total loss': 0.5242492616176605} | train loss {'Reaction outcome loss': 0.45301829196893384, 'Total loss': 0.45301829196893384}
2023-01-05 11:19:38,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:38,500 INFO:     Epoch: 15
2023-01-05 11:19:40,452 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.506757824619611, 'Total loss': 0.506757824619611} | train loss {'Reaction outcome loss': 0.45375949215062344, 'Total loss': 0.45375949215062344}
2023-01-05 11:19:40,452 INFO:     Found new best model at epoch 15
2023-01-05 11:19:40,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:40,453 INFO:     Epoch: 16
2023-01-05 11:19:42,190 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5203476488590241, 'Total loss': 0.5203476488590241} | train loss {'Reaction outcome loss': 0.4438572851193212, 'Total loss': 0.4438572851193212}
2023-01-05 11:19:42,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:42,191 INFO:     Epoch: 17
2023-01-05 11:19:43,932 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5000673691431682, 'Total loss': 0.5000673691431682} | train loss {'Reaction outcome loss': 0.43942904192274507, 'Total loss': 0.43942904192274507}
2023-01-05 11:19:43,932 INFO:     Found new best model at epoch 17
2023-01-05 11:19:43,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:43,933 INFO:     Epoch: 18
2023-01-05 11:19:46,117 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5046798427899678, 'Total loss': 0.5046798427899678} | train loss {'Reaction outcome loss': 0.43708987213181755, 'Total loss': 0.43708987213181755}
2023-01-05 11:19:46,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:46,118 INFO:     Epoch: 19
2023-01-05 11:19:48,186 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.497011070450147, 'Total loss': 0.497011070450147} | train loss {'Reaction outcome loss': 0.42940715765648513, 'Total loss': 0.42940715765648513}
2023-01-05 11:19:48,186 INFO:     Found new best model at epoch 19
2023-01-05 11:19:48,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:48,188 INFO:     Epoch: 20
2023-01-05 11:19:49,943 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5033020734786987, 'Total loss': 0.5033020734786987} | train loss {'Reaction outcome loss': 0.428007152828857, 'Total loss': 0.428007152828857}
2023-01-05 11:19:49,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:49,943 INFO:     Epoch: 21
2023-01-05 11:19:51,699 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.544329063097636, 'Total loss': 0.544329063097636} | train loss {'Reaction outcome loss': 0.4246625346097633, 'Total loss': 0.4246625346097633}
2023-01-05 11:19:51,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:51,699 INFO:     Epoch: 22
2023-01-05 11:19:53,733 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4937959889570872, 'Total loss': 0.4937959889570872} | train loss {'Reaction outcome loss': 0.41786665616244295, 'Total loss': 0.41786665616244295}
2023-01-05 11:19:53,733 INFO:     Found new best model at epoch 22
2023-01-05 11:19:53,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:53,735 INFO:     Epoch: 23
2023-01-05 11:19:55,865 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.505987427632014, 'Total loss': 0.505987427632014} | train loss {'Reaction outcome loss': 0.4133528447336089, 'Total loss': 0.4133528447336089}
2023-01-05 11:19:55,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:55,867 INFO:     Epoch: 24
2023-01-05 11:19:57,977 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49787503480911255, 'Total loss': 0.49787503480911255} | train loss {'Reaction outcome loss': 0.41219064606911077, 'Total loss': 0.41219064606911077}
2023-01-05 11:19:57,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:19:57,977 INFO:     Epoch: 25
2023-01-05 11:20:00,070 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4863480180501938, 'Total loss': 0.4863480180501938} | train loss {'Reaction outcome loss': 0.41354715633783895, 'Total loss': 0.41354715633783895}
2023-01-05 11:20:00,070 INFO:     Found new best model at epoch 25
2023-01-05 11:20:00,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:00,072 INFO:     Epoch: 26
2023-01-05 11:20:02,207 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.490948145588239, 'Total loss': 0.490948145588239} | train loss {'Reaction outcome loss': 0.4070122497849656, 'Total loss': 0.4070122497849656}
2023-01-05 11:20:02,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:02,208 INFO:     Epoch: 27
2023-01-05 11:20:04,327 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5190070450305939, 'Total loss': 0.5190070450305939} | train loss {'Reaction outcome loss': 0.3979033549064702, 'Total loss': 0.3979033549064702}
2023-01-05 11:20:04,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:04,327 INFO:     Epoch: 28
2023-01-05 11:20:06,463 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4935146580139796, 'Total loss': 0.4935146580139796} | train loss {'Reaction outcome loss': 0.3961213451884959, 'Total loss': 0.3961213451884959}
2023-01-05 11:20:06,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:06,464 INFO:     Epoch: 29
2023-01-05 11:20:08,645 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5000887190302213, 'Total loss': 0.5000887190302213} | train loss {'Reaction outcome loss': 0.3970049017102179, 'Total loss': 0.3970049017102179}
2023-01-05 11:20:08,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:08,645 INFO:     Epoch: 30
2023-01-05 11:20:10,836 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4682534863551458, 'Total loss': 0.4682534863551458} | train loss {'Reaction outcome loss': 0.39580077019921184, 'Total loss': 0.39580077019921184}
2023-01-05 11:20:10,836 INFO:     Found new best model at epoch 30
2023-01-05 11:20:10,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:10,837 INFO:     Epoch: 31
2023-01-05 11:20:13,050 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4746317853530248, 'Total loss': 0.4746317853530248} | train loss {'Reaction outcome loss': 0.39049946076243464, 'Total loss': 0.39049946076243464}
2023-01-05 11:20:13,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:13,050 INFO:     Epoch: 32
2023-01-05 11:20:15,265 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4884482830762863, 'Total loss': 0.4884482830762863} | train loss {'Reaction outcome loss': 0.3872586745959129, 'Total loss': 0.3872586745959129}
2023-01-05 11:20:15,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:15,266 INFO:     Epoch: 33
2023-01-05 11:20:17,397 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4872758115331332, 'Total loss': 0.4872758115331332} | train loss {'Reaction outcome loss': 0.38166451232548615, 'Total loss': 0.38166451232548615}
2023-01-05 11:20:17,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:17,397 INFO:     Epoch: 34
2023-01-05 11:20:19,523 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5303488393624624, 'Total loss': 0.5303488393624624} | train loss {'Reaction outcome loss': 0.3845477175157871, 'Total loss': 0.3845477175157871}
2023-01-05 11:20:19,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:19,524 INFO:     Epoch: 35
2023-01-05 11:20:21,643 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4841625541448593, 'Total loss': 0.4841625541448593} | train loss {'Reaction outcome loss': 0.3753754160210599, 'Total loss': 0.3753754160210599}
2023-01-05 11:20:21,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:21,644 INFO:     Epoch: 36
2023-01-05 11:20:23,762 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5011084159215291, 'Total loss': 0.5011084159215291} | train loss {'Reaction outcome loss': 0.3778815978634967, 'Total loss': 0.3778815978634967}
2023-01-05 11:20:23,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:23,762 INFO:     Epoch: 37
2023-01-05 11:20:25,873 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5443558086951573, 'Total loss': 0.5443558086951573} | train loss {'Reaction outcome loss': 0.36507950940706435, 'Total loss': 0.36507950940706435}
2023-01-05 11:20:25,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:25,873 INFO:     Epoch: 38
2023-01-05 11:20:27,998 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4842003087202708, 'Total loss': 0.4842003087202708} | train loss {'Reaction outcome loss': 0.3688366464237227, 'Total loss': 0.3688366464237227}
2023-01-05 11:20:27,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:27,998 INFO:     Epoch: 39
2023-01-05 11:20:30,155 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47592344681421916, 'Total loss': 0.47592344681421916} | train loss {'Reaction outcome loss': 0.3645089679825915, 'Total loss': 0.3645089679825915}
2023-01-05 11:20:30,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:30,155 INFO:     Epoch: 40
2023-01-05 11:20:32,329 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47509769002596536, 'Total loss': 0.47509769002596536} | train loss {'Reaction outcome loss': 0.36079082140413515, 'Total loss': 0.36079082140413515}
2023-01-05 11:20:32,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:32,330 INFO:     Epoch: 41
2023-01-05 11:20:34,475 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5049666126569112, 'Total loss': 0.5049666126569112} | train loss {'Reaction outcome loss': 0.35833241241256686, 'Total loss': 0.35833241241256686}
2023-01-05 11:20:34,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:34,476 INFO:     Epoch: 42
2023-01-05 11:20:36,623 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5170904298623403, 'Total loss': 0.5170904298623403} | train loss {'Reaction outcome loss': 0.36046360199251315, 'Total loss': 0.36046360199251315}
2023-01-05 11:20:36,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:36,623 INFO:     Epoch: 43
2023-01-05 11:20:38,761 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4887813945611318, 'Total loss': 0.4887813945611318} | train loss {'Reaction outcome loss': 0.3580003785254964, 'Total loss': 0.3580003785254964}
2023-01-05 11:20:38,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:38,762 INFO:     Epoch: 44
2023-01-05 11:20:40,860 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.446062966187795, 'Total loss': 0.446062966187795} | train loss {'Reaction outcome loss': 0.3525643789474546, 'Total loss': 0.3525643789474546}
2023-01-05 11:20:40,860 INFO:     Found new best model at epoch 44
2023-01-05 11:20:40,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:40,861 INFO:     Epoch: 45
2023-01-05 11:20:42,964 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45376315812269846, 'Total loss': 0.45376315812269846} | train loss {'Reaction outcome loss': 0.3398345932364464, 'Total loss': 0.3398345932364464}
2023-01-05 11:20:42,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:42,964 INFO:     Epoch: 46
2023-01-05 11:20:45,095 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4622998913129171, 'Total loss': 0.4622998913129171} | train loss {'Reaction outcome loss': 0.34274482932349626, 'Total loss': 0.34274482932349626}
2023-01-05 11:20:45,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:45,095 INFO:     Epoch: 47
2023-01-05 11:20:47,217 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5025540252526601, 'Total loss': 0.5025540252526601} | train loss {'Reaction outcome loss': 0.34267247416568497, 'Total loss': 0.34267247416568497}
2023-01-05 11:20:47,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:47,217 INFO:     Epoch: 48
2023-01-05 11:20:49,311 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46658867100874585, 'Total loss': 0.46658867100874585} | train loss {'Reaction outcome loss': 0.34236898466292087, 'Total loss': 0.34236898466292087}
2023-01-05 11:20:49,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:49,312 INFO:     Epoch: 49
2023-01-05 11:20:51,419 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49765478571256, 'Total loss': 0.49765478571256} | train loss {'Reaction outcome loss': 0.32733482062599084, 'Total loss': 0.32733482062599084}
2023-01-05 11:20:51,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:51,419 INFO:     Epoch: 50
2023-01-05 11:20:53,562 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49238128860791525, 'Total loss': 0.49238128860791525} | train loss {'Reaction outcome loss': 0.3322045860444977, 'Total loss': 0.3322045860444977}
2023-01-05 11:20:53,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:53,562 INFO:     Epoch: 51
2023-01-05 11:20:55,682 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4545745184024175, 'Total loss': 0.4545745184024175} | train loss {'Reaction outcome loss': 0.3276972615969007, 'Total loss': 0.3276972615969007}
2023-01-05 11:20:55,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:55,682 INFO:     Epoch: 52
2023-01-05 11:20:57,856 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48002224465211235, 'Total loss': 0.48002224465211235} | train loss {'Reaction outcome loss': 0.32592387322037325, 'Total loss': 0.32592387322037325}
2023-01-05 11:20:57,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:20:57,856 INFO:     Epoch: 53
2023-01-05 11:21:00,038 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48722068866093954, 'Total loss': 0.48722068866093954} | train loss {'Reaction outcome loss': 0.3204116452838818, 'Total loss': 0.3204116452838818}
2023-01-05 11:21:00,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:00,039 INFO:     Epoch: 54
2023-01-05 11:21:02,182 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46108145713806153, 'Total loss': 0.46108145713806153} | train loss {'Reaction outcome loss': 0.31768989039544204, 'Total loss': 0.31768989039544204}
2023-01-05 11:21:02,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:02,184 INFO:     Epoch: 55
2023-01-05 11:21:04,290 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4891001303990682, 'Total loss': 0.4891001303990682} | train loss {'Reaction outcome loss': 0.31881706772820795, 'Total loss': 0.31881706772820795}
2023-01-05 11:21:04,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:04,291 INFO:     Epoch: 56
2023-01-05 11:21:06,395 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4802421490351359, 'Total loss': 0.4802421490351359} | train loss {'Reaction outcome loss': 0.321004961610493, 'Total loss': 0.321004961610493}
2023-01-05 11:21:06,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:06,395 INFO:     Epoch: 57
2023-01-05 11:21:08,530 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43746771713097893, 'Total loss': 0.43746771713097893} | train loss {'Reaction outcome loss': 0.3113998349103397, 'Total loss': 0.3113998349103397}
2023-01-05 11:21:08,531 INFO:     Found new best model at epoch 57
2023-01-05 11:21:08,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:08,532 INFO:     Epoch: 58
2023-01-05 11:21:10,687 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4659049113591512, 'Total loss': 0.4659049113591512} | train loss {'Reaction outcome loss': 0.31051897975432613, 'Total loss': 0.31051897975432613}
2023-01-05 11:21:10,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:10,688 INFO:     Epoch: 59
2023-01-05 11:21:12,834 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45643176361918447, 'Total loss': 0.45643176361918447} | train loss {'Reaction outcome loss': 0.3038359981601256, 'Total loss': 0.3038359981601256}
2023-01-05 11:21:12,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:12,834 INFO:     Epoch: 60
2023-01-05 11:21:14,956 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4834278186162313, 'Total loss': 0.4834278186162313} | train loss {'Reaction outcome loss': 0.3065182642372203, 'Total loss': 0.3065182642372203}
2023-01-05 11:21:14,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:14,956 INFO:     Epoch: 61
2023-01-05 11:21:17,079 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4846362481514613, 'Total loss': 0.4846362481514613} | train loss {'Reaction outcome loss': 0.2957986742529991, 'Total loss': 0.2957986742529991}
2023-01-05 11:21:17,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:17,080 INFO:     Epoch: 62
2023-01-05 11:21:19,221 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48584681550661724, 'Total loss': 0.48584681550661724} | train loss {'Reaction outcome loss': 0.30607056810799305, 'Total loss': 0.30607056810799305}
2023-01-05 11:21:19,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:19,221 INFO:     Epoch: 63
2023-01-05 11:21:21,375 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45523686011632286, 'Total loss': 0.45523686011632286} | train loss {'Reaction outcome loss': 0.2956397021393271, 'Total loss': 0.2956397021393271}
2023-01-05 11:21:21,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:21,376 INFO:     Epoch: 64
2023-01-05 11:21:23,478 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4924522916475932, 'Total loss': 0.4924522916475932} | train loss {'Reaction outcome loss': 0.2952024857139718, 'Total loss': 0.2952024857139718}
2023-01-05 11:21:23,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:23,479 INFO:     Epoch: 65
2023-01-05 11:21:25,580 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49600695371627807, 'Total loss': 0.49600695371627807} | train loss {'Reaction outcome loss': 0.28951182202809916, 'Total loss': 0.28951182202809916}
2023-01-05 11:21:25,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:25,580 INFO:     Epoch: 66
2023-01-05 11:21:27,668 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4753616432348887, 'Total loss': 0.4753616432348887} | train loss {'Reaction outcome loss': 0.29745961123411235, 'Total loss': 0.29745961123411235}
2023-01-05 11:21:27,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:27,669 INFO:     Epoch: 67
2023-01-05 11:21:29,772 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5055629342794419, 'Total loss': 0.5055629342794419} | train loss {'Reaction outcome loss': 0.28876325879653875, 'Total loss': 0.28876325879653875}
2023-01-05 11:21:29,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:29,772 INFO:     Epoch: 68
2023-01-05 11:21:31,862 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5147601524988811, 'Total loss': 0.5147601524988811} | train loss {'Reaction outcome loss': 0.28706694305976377, 'Total loss': 0.28706694305976377}
2023-01-05 11:21:31,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:31,863 INFO:     Epoch: 69
2023-01-05 11:21:33,961 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4833789000908534, 'Total loss': 0.4833789000908534} | train loss {'Reaction outcome loss': 0.280305943404236, 'Total loss': 0.280305943404236}
2023-01-05 11:21:33,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:33,962 INFO:     Epoch: 70
2023-01-05 11:21:36,062 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4775899728139242, 'Total loss': 0.4775899728139242} | train loss {'Reaction outcome loss': 0.2738023691395991, 'Total loss': 0.2738023691395991}
2023-01-05 11:21:36,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:36,062 INFO:     Epoch: 71
2023-01-05 11:21:38,172 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4721336325009664, 'Total loss': 0.4721336325009664} | train loss {'Reaction outcome loss': 0.2790195178444477, 'Total loss': 0.2790195178444477}
2023-01-05 11:21:38,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:38,174 INFO:     Epoch: 72
2023-01-05 11:21:40,241 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4685154418150584, 'Total loss': 0.4685154418150584} | train loss {'Reaction outcome loss': 0.2760834924631963, 'Total loss': 0.2760834924631963}
2023-01-05 11:21:40,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:40,241 INFO:     Epoch: 73
2023-01-05 11:21:42,351 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47641537586847943, 'Total loss': 0.47641537586847943} | train loss {'Reaction outcome loss': 0.2710048177272734, 'Total loss': 0.2710048177272734}
2023-01-05 11:21:42,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:42,351 INFO:     Epoch: 74
2023-01-05 11:21:44,458 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47897707521915434, 'Total loss': 0.47897707521915434} | train loss {'Reaction outcome loss': 0.2752273528272436, 'Total loss': 0.2752273528272436}
2023-01-05 11:21:44,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:44,459 INFO:     Epoch: 75
2023-01-05 11:21:46,545 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5052594949801763, 'Total loss': 0.5052594949801763} | train loss {'Reaction outcome loss': 0.2718006524182584, 'Total loss': 0.2718006524182584}
2023-01-05 11:21:46,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:46,546 INFO:     Epoch: 76
2023-01-05 11:21:48,682 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4766313672065735, 'Total loss': 0.4766313672065735} | train loss {'Reaction outcome loss': 0.26993694709763477, 'Total loss': 0.26993694709763477}
2023-01-05 11:21:48,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:48,682 INFO:     Epoch: 77
2023-01-05 11:21:50,775 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45940542618433633, 'Total loss': 0.45940542618433633} | train loss {'Reaction outcome loss': 0.26331708104737156, 'Total loss': 0.26331708104737156}
2023-01-05 11:21:50,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:50,775 INFO:     Epoch: 78
2023-01-05 11:21:52,898 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4607665042082469, 'Total loss': 0.4607665042082469} | train loss {'Reaction outcome loss': 0.2708862600236261, 'Total loss': 0.2708862600236261}
2023-01-05 11:21:52,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:52,898 INFO:     Epoch: 79
2023-01-05 11:21:55,012 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5113991558551788, 'Total loss': 0.5113991558551788} | train loss {'Reaction outcome loss': 0.2667107135873206, 'Total loss': 0.2667107135873206}
2023-01-05 11:21:55,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:55,012 INFO:     Epoch: 80
2023-01-05 11:21:57,151 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5306971987088521, 'Total loss': 0.5306971987088521} | train loss {'Reaction outcome loss': 0.25494931942790094, 'Total loss': 0.25494931942790094}
2023-01-05 11:21:57,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:57,152 INFO:     Epoch: 81
2023-01-05 11:21:59,319 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4797615647315979, 'Total loss': 0.4797615647315979} | train loss {'Reaction outcome loss': 0.25797876280589693, 'Total loss': 0.25797876280589693}
2023-01-05 11:21:59,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:21:59,319 INFO:     Epoch: 82
2023-01-05 11:22:01,253 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4557840039332708, 'Total loss': 0.4557840039332708} | train loss {'Reaction outcome loss': 0.2623124507792892, 'Total loss': 0.2623124507792892}
2023-01-05 11:22:01,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:01,253 INFO:     Epoch: 83
2023-01-05 11:22:03,359 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5135971198479334, 'Total loss': 0.5135971198479334} | train loss {'Reaction outcome loss': 0.2624139363476395, 'Total loss': 0.2624139363476395}
2023-01-05 11:22:03,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:03,359 INFO:     Epoch: 84
2023-01-05 11:22:05,437 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5102636297543843, 'Total loss': 0.5102636297543843} | train loss {'Reaction outcome loss': 0.2605517399021472, 'Total loss': 0.2605517399021472}
2023-01-05 11:22:05,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:05,438 INFO:     Epoch: 85
2023-01-05 11:22:07,562 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5005197008450826, 'Total loss': 0.5005197008450826} | train loss {'Reaction outcome loss': 0.2628472736309262, 'Total loss': 0.2628472736309262}
2023-01-05 11:22:07,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:07,562 INFO:     Epoch: 86
2023-01-05 11:22:09,710 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49545503909078736, 'Total loss': 0.49545503909078736} | train loss {'Reaction outcome loss': 0.2573974427162078, 'Total loss': 0.2573974427162078}
2023-01-05 11:22:09,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:09,711 INFO:     Epoch: 87
2023-01-05 11:22:11,847 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5109102686246236, 'Total loss': 0.5109102686246236} | train loss {'Reaction outcome loss': 0.2638343617075334, 'Total loss': 0.2638343617075334}
2023-01-05 11:22:11,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:11,847 INFO:     Epoch: 88
2023-01-05 11:22:13,952 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5416520833969116, 'Total loss': 0.5416520833969116} | train loss {'Reaction outcome loss': 0.24416111384511646, 'Total loss': 0.24416111384511646}
2023-01-05 11:22:13,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:13,954 INFO:     Epoch: 89
2023-01-05 11:22:16,092 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5303445279598236, 'Total loss': 0.5303445279598236} | train loss {'Reaction outcome loss': 0.2575458627955539, 'Total loss': 0.2575458627955539}
2023-01-05 11:22:16,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:16,092 INFO:     Epoch: 90
2023-01-05 11:22:18,211 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4546778211990992, 'Total loss': 0.4546778211990992} | train loss {'Reaction outcome loss': 0.2512698451288208, 'Total loss': 0.2512698451288208}
2023-01-05 11:22:18,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:18,211 INFO:     Epoch: 91
2023-01-05 11:22:20,313 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5418976694345474, 'Total loss': 0.5418976694345474} | train loss {'Reaction outcome loss': 0.2516503967072842, 'Total loss': 0.2516503967072842}
2023-01-05 11:22:20,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:20,313 INFO:     Epoch: 92
2023-01-05 11:22:22,409 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.516434927781423, 'Total loss': 0.516434927781423} | train loss {'Reaction outcome loss': 0.24783325362542685, 'Total loss': 0.24783325362542685}
2023-01-05 11:22:22,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:22,409 INFO:     Epoch: 93
2023-01-05 11:22:24,519 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.521948923667272, 'Total loss': 0.521948923667272} | train loss {'Reaction outcome loss': 0.24811474530937244, 'Total loss': 0.24811474530937244}
2023-01-05 11:22:24,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:24,520 INFO:     Epoch: 94
2023-01-05 11:22:26,633 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4688207308451335, 'Total loss': 0.4688207308451335} | train loss {'Reaction outcome loss': 0.24681848639377604, 'Total loss': 0.24681848639377604}
2023-01-05 11:22:26,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:26,633 INFO:     Epoch: 95
2023-01-05 11:22:28,727 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4595859482263525, 'Total loss': 0.4595859482263525} | train loss {'Reaction outcome loss': 0.24141678617532997, 'Total loss': 0.24141678617532997}
2023-01-05 11:22:28,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:28,728 INFO:     Epoch: 96
2023-01-05 11:22:30,836 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4818207899729411, 'Total loss': 0.4818207899729411} | train loss {'Reaction outcome loss': 0.25176009738369143, 'Total loss': 0.25176009738369143}
2023-01-05 11:22:30,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:30,836 INFO:     Epoch: 97
2023-01-05 11:22:33,001 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5196132640043895, 'Total loss': 0.5196132640043895} | train loss {'Reaction outcome loss': 0.24944705014409374, 'Total loss': 0.24944705014409374}
2023-01-05 11:22:33,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:33,002 INFO:     Epoch: 98
2023-01-05 11:22:35,158 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49688132405281066, 'Total loss': 0.49688132405281066} | train loss {'Reaction outcome loss': 0.24865508902083783, 'Total loss': 0.24865508902083783}
2023-01-05 11:22:35,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:35,158 INFO:     Epoch: 99
2023-01-05 11:22:37,303 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4824416846036911, 'Total loss': 0.4824416846036911} | train loss {'Reaction outcome loss': 0.23931066770731968, 'Total loss': 0.23931066770731968}
2023-01-05 11:22:37,304 INFO:     Best model found after epoch 58 of 100.
2023-01-05 11:22:37,304 INFO:   Done with stage: TRAINING
2023-01-05 11:22:37,304 INFO:   Starting stage: EVALUATION
2023-01-05 11:22:37,441 INFO:   Done with stage: EVALUATION
2023-01-05 11:22:37,441 INFO:   Leaving out SEQ value Fold_2
2023-01-05 11:22:37,454 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 11:22:37,454 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:22:38,095 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:22:38,095 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:22:38,162 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:22:38,163 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:22:38,163 INFO:     No hyperparam tuning for this model
2023-01-05 11:22:38,163 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:22:38,163 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:22:38,163 INFO:     None feature selector for col prot
2023-01-05 11:22:38,164 INFO:     None feature selector for col prot
2023-01-05 11:22:38,164 INFO:     None feature selector for col prot
2023-01-05 11:22:38,164 INFO:     None feature selector for col chem
2023-01-05 11:22:38,164 INFO:     None feature selector for col chem
2023-01-05 11:22:38,164 INFO:     None feature selector for col chem
2023-01-05 11:22:38,164 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:22:38,164 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:22:38,166 INFO:     Number of params in model 72901
2023-01-05 11:22:38,169 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:22:38,169 INFO:   Starting stage: TRAINING
2023-01-05 11:22:38,229 INFO:     Val loss before train {'Reaction outcome loss': 0.9804612676302592, 'Total loss': 0.9804612676302592}
2023-01-05 11:22:38,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:38,229 INFO:     Epoch: 0
2023-01-05 11:22:40,377 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7938379168510437, 'Total loss': 0.7938379168510437} | train loss {'Reaction outcome loss': 0.9244617071998862, 'Total loss': 0.9244617071998862}
2023-01-05 11:22:40,377 INFO:     Found new best model at epoch 0
2023-01-05 11:22:40,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:40,379 INFO:     Epoch: 1
2023-01-05 11:22:42,487 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6199043552080791, 'Total loss': 0.6199043552080791} | train loss {'Reaction outcome loss': 0.7375589695387271, 'Total loss': 0.7375589695387271}
2023-01-05 11:22:42,487 INFO:     Found new best model at epoch 1
2023-01-05 11:22:42,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:42,489 INFO:     Epoch: 2
2023-01-05 11:22:44,588 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5346556703249613, 'Total loss': 0.5346556703249613} | train loss {'Reaction outcome loss': 0.5972356812639551, 'Total loss': 0.5972356812639551}
2023-01-05 11:22:44,588 INFO:     Found new best model at epoch 2
2023-01-05 11:22:44,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:44,590 INFO:     Epoch: 3
2023-01-05 11:22:46,690 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5352104544639588, 'Total loss': 0.5352104544639588} | train loss {'Reaction outcome loss': 0.5399571596047817, 'Total loss': 0.5399571596047817}
2023-01-05 11:22:46,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:46,690 INFO:     Epoch: 4
2023-01-05 11:22:48,771 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5136890371640523, 'Total loss': 0.5136890371640523} | train loss {'Reaction outcome loss': 0.5144393468077803, 'Total loss': 0.5144393468077803}
2023-01-05 11:22:48,772 INFO:     Found new best model at epoch 4
2023-01-05 11:22:48,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:48,773 INFO:     Epoch: 5
2023-01-05 11:22:50,943 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5244195600350697, 'Total loss': 0.5244195600350697} | train loss {'Reaction outcome loss': 0.4996471381558603, 'Total loss': 0.4996471381558603}
2023-01-05 11:22:50,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:50,945 INFO:     Epoch: 6
2023-01-05 11:22:53,077 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47433995008468627, 'Total loss': 0.47433995008468627} | train loss {'Reaction outcome loss': 0.494459127222662, 'Total loss': 0.494459127222662}
2023-01-05 11:22:53,077 INFO:     Found new best model at epoch 6
2023-01-05 11:22:53,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:53,079 INFO:     Epoch: 7
2023-01-05 11:22:55,205 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5030686189730962, 'Total loss': 0.5030686189730962} | train loss {'Reaction outcome loss': 0.4878672974886912, 'Total loss': 0.4878672974886912}
2023-01-05 11:22:55,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:55,205 INFO:     Epoch: 8
2023-01-05 11:22:57,291 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47439415256182355, 'Total loss': 0.47439415256182355} | train loss {'Reaction outcome loss': 0.48263814188403525, 'Total loss': 0.48263814188403525}
2023-01-05 11:22:57,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:57,292 INFO:     Epoch: 9
2023-01-05 11:22:59,374 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.498541126648585, 'Total loss': 0.498541126648585} | train loss {'Reaction outcome loss': 0.47288587547483896, 'Total loss': 0.47288587547483896}
2023-01-05 11:22:59,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:22:59,374 INFO:     Epoch: 10
2023-01-05 11:23:01,475 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48271051049232483, 'Total loss': 0.48271051049232483} | train loss {'Reaction outcome loss': 0.46676821018749975, 'Total loss': 0.46676821018749975}
2023-01-05 11:23:01,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:01,475 INFO:     Epoch: 11
2023-01-05 11:23:03,579 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45718667407830554, 'Total loss': 0.45718667407830554} | train loss {'Reaction outcome loss': 0.462960109660477, 'Total loss': 0.462960109660477}
2023-01-05 11:23:03,579 INFO:     Found new best model at epoch 11
2023-01-05 11:23:03,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:03,580 INFO:     Epoch: 12
2023-01-05 11:23:05,687 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5100784768660863, 'Total loss': 0.5100784768660863} | train loss {'Reaction outcome loss': 0.458613993429439, 'Total loss': 0.458613993429439}
2023-01-05 11:23:05,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:05,687 INFO:     Epoch: 13
2023-01-05 11:23:07,773 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4472728133201599, 'Total loss': 0.4472728133201599} | train loss {'Reaction outcome loss': 0.45317458915404785, 'Total loss': 0.45317458915404785}
2023-01-05 11:23:07,773 INFO:     Found new best model at epoch 13
2023-01-05 11:23:07,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:07,774 INFO:     Epoch: 14
2023-01-05 11:23:09,871 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44655247728029884, 'Total loss': 0.44655247728029884} | train loss {'Reaction outcome loss': 0.44551814448484134, 'Total loss': 0.44551814448484134}
2023-01-05 11:23:09,872 INFO:     Found new best model at epoch 14
2023-01-05 11:23:09,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:09,873 INFO:     Epoch: 15
2023-01-05 11:23:11,948 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44917752941449485, 'Total loss': 0.44917752941449485} | train loss {'Reaction outcome loss': 0.44472002863010646, 'Total loss': 0.44472002863010646}
2023-01-05 11:23:11,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:11,948 INFO:     Epoch: 16
2023-01-05 11:23:14,053 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4789120554924011, 'Total loss': 0.4789120554924011} | train loss {'Reaction outcome loss': 0.4464589081458993, 'Total loss': 0.4464589081458993}
2023-01-05 11:23:14,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:14,053 INFO:     Epoch: 17
2023-01-05 11:23:16,166 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45754934946695963, 'Total loss': 0.45754934946695963} | train loss {'Reaction outcome loss': 0.4372613175120546, 'Total loss': 0.4372613175120546}
2023-01-05 11:23:16,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:16,166 INFO:     Epoch: 18
2023-01-05 11:23:18,298 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.444722064336141, 'Total loss': 0.444722064336141} | train loss {'Reaction outcome loss': 0.4317146777806483, 'Total loss': 0.4317146777806483}
2023-01-05 11:23:18,298 INFO:     Found new best model at epoch 18
2023-01-05 11:23:18,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:18,299 INFO:     Epoch: 19
2023-01-05 11:23:20,415 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46511337757110593, 'Total loss': 0.46511337757110593} | train loss {'Reaction outcome loss': 0.4273287831863641, 'Total loss': 0.4273287831863641}
2023-01-05 11:23:20,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:20,415 INFO:     Epoch: 20
2023-01-05 11:23:22,524 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.457212636868159, 'Total loss': 0.457212636868159} | train loss {'Reaction outcome loss': 0.42410593373434885, 'Total loss': 0.42410593373434885}
2023-01-05 11:23:22,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:22,524 INFO:     Epoch: 21
2023-01-05 11:23:24,619 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44897162516911826, 'Total loss': 0.44897162516911826} | train loss {'Reaction outcome loss': 0.41773967638666376, 'Total loss': 0.41773967638666376}
2023-01-05 11:23:24,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:24,619 INFO:     Epoch: 22
2023-01-05 11:23:26,718 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4478224406639735, 'Total loss': 0.4478224406639735} | train loss {'Reaction outcome loss': 0.4166614319651555, 'Total loss': 0.4166614319651555}
2023-01-05 11:23:26,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:26,720 INFO:     Epoch: 23
2023-01-05 11:23:28,833 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47458508213361106, 'Total loss': 0.47458508213361106} | train loss {'Reaction outcome loss': 0.4130554751325876, 'Total loss': 0.4130554751325876}
2023-01-05 11:23:28,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:28,834 INFO:     Epoch: 24
2023-01-05 11:23:30,946 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.483831532796224, 'Total loss': 0.483831532796224} | train loss {'Reaction outcome loss': 0.4091777409061844, 'Total loss': 0.4091777409061844}
2023-01-05 11:23:30,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:30,946 INFO:     Epoch: 25
2023-01-05 11:23:33,042 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43819188078244525, 'Total loss': 0.43819188078244525} | train loss {'Reaction outcome loss': 0.4093602153407785, 'Total loss': 0.4093602153407785}
2023-01-05 11:23:33,043 INFO:     Found new best model at epoch 25
2023-01-05 11:23:33,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:33,044 INFO:     Epoch: 26
2023-01-05 11:23:35,138 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45034465193748474, 'Total loss': 0.45034465193748474} | train loss {'Reaction outcome loss': 0.4032374939748219, 'Total loss': 0.4032374939748219}
2023-01-05 11:23:35,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:35,139 INFO:     Epoch: 27
2023-01-05 11:23:37,264 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4549970199664434, 'Total loss': 0.4549970199664434} | train loss {'Reaction outcome loss': 0.39691993769346956, 'Total loss': 0.39691993769346956}
2023-01-05 11:23:37,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:37,265 INFO:     Epoch: 28
2023-01-05 11:23:39,364 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43876225302616756, 'Total loss': 0.43876225302616756} | train loss {'Reaction outcome loss': 0.3935664389487151, 'Total loss': 0.3935664389487151}
2023-01-05 11:23:39,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:39,365 INFO:     Epoch: 29
2023-01-05 11:23:41,455 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44567377865314484, 'Total loss': 0.44567377865314484} | train loss {'Reaction outcome loss': 0.399107192107391, 'Total loss': 0.399107192107391}
2023-01-05 11:23:41,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:41,455 INFO:     Epoch: 30
2023-01-05 11:23:43,564 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4531411318729321, 'Total loss': 0.4531411318729321} | train loss {'Reaction outcome loss': 0.38418278362833974, 'Total loss': 0.38418278362833974}
2023-01-05 11:23:43,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:43,564 INFO:     Epoch: 31
2023-01-05 11:23:45,680 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4537507305542628, 'Total loss': 0.4537507305542628} | train loss {'Reaction outcome loss': 0.3848062428635555, 'Total loss': 0.3848062428635555}
2023-01-05 11:23:45,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:45,680 INFO:     Epoch: 32
2023-01-05 11:23:47,765 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4352478524049123, 'Total loss': 0.4352478524049123} | train loss {'Reaction outcome loss': 0.38601525106054524, 'Total loss': 0.38601525106054524}
2023-01-05 11:23:47,765 INFO:     Found new best model at epoch 32
2023-01-05 11:23:47,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:47,767 INFO:     Epoch: 33
2023-01-05 11:23:49,865 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4474495132764181, 'Total loss': 0.4474495132764181} | train loss {'Reaction outcome loss': 0.37477087865382325, 'Total loss': 0.37477087865382325}
2023-01-05 11:23:49,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:49,865 INFO:     Epoch: 34
2023-01-05 11:23:51,982 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4571003218491872, 'Total loss': 0.4571003218491872} | train loss {'Reaction outcome loss': 0.38078624670540456, 'Total loss': 0.38078624670540456}
2023-01-05 11:23:51,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:51,982 INFO:     Epoch: 35
2023-01-05 11:23:54,060 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4262424568335215, 'Total loss': 0.4262424568335215} | train loss {'Reaction outcome loss': 0.36853517496433014, 'Total loss': 0.36853517496433014}
2023-01-05 11:23:54,060 INFO:     Found new best model at epoch 35
2023-01-05 11:23:54,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:54,062 INFO:     Epoch: 36
2023-01-05 11:23:56,154 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44598540862401326, 'Total loss': 0.44598540862401326} | train loss {'Reaction outcome loss': 0.3721727081352756, 'Total loss': 0.3721727081352756}
2023-01-05 11:23:56,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:56,155 INFO:     Epoch: 37
2023-01-05 11:23:58,269 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49390321572621665, 'Total loss': 0.49390321572621665} | train loss {'Reaction outcome loss': 0.3658675811229608, 'Total loss': 0.3658675811229608}
2023-01-05 11:23:58,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:23:58,270 INFO:     Epoch: 38
2023-01-05 11:24:00,372 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44598022997379305, 'Total loss': 0.44598022997379305} | train loss {'Reaction outcome loss': 0.3640020544002781, 'Total loss': 0.3640020544002781}
2023-01-05 11:24:00,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:00,373 INFO:     Epoch: 39
2023-01-05 11:24:02,494 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44183974464734393, 'Total loss': 0.44183974464734393} | train loss {'Reaction outcome loss': 0.35522443538654475, 'Total loss': 0.35522443538654475}
2023-01-05 11:24:02,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:02,496 INFO:     Epoch: 40
2023-01-05 11:24:04,628 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4501123915115992, 'Total loss': 0.4501123915115992} | train loss {'Reaction outcome loss': 0.3610325896150463, 'Total loss': 0.3610325896150463}
2023-01-05 11:24:04,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:04,628 INFO:     Epoch: 41
2023-01-05 11:24:06,759 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4503079354763031, 'Total loss': 0.4503079354763031} | train loss {'Reaction outcome loss': 0.35824470462161545, 'Total loss': 0.35824470462161545}
2023-01-05 11:24:06,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:06,759 INFO:     Epoch: 42
2023-01-05 11:24:08,887 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.454314711689949, 'Total loss': 0.454314711689949} | train loss {'Reaction outcome loss': 0.3495498899465952, 'Total loss': 0.3495498899465952}
2023-01-05 11:24:08,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:08,888 INFO:     Epoch: 43
2023-01-05 11:24:11,025 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4211443642775218, 'Total loss': 0.4211443642775218} | train loss {'Reaction outcome loss': 0.34885474585078574, 'Total loss': 0.34885474585078574}
2023-01-05 11:24:11,025 INFO:     Found new best model at epoch 43
2023-01-05 11:24:11,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:11,026 INFO:     Epoch: 44
2023-01-05 11:24:13,191 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4441210349400838, 'Total loss': 0.4441210349400838} | train loss {'Reaction outcome loss': 0.3465258297902761, 'Total loss': 0.3465258297902761}
2023-01-05 11:24:13,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:13,192 INFO:     Epoch: 45
2023-01-05 11:24:15,301 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4296691303451856, 'Total loss': 0.4296691303451856} | train loss {'Reaction outcome loss': 0.34387094033506765, 'Total loss': 0.34387094033506765}
2023-01-05 11:24:15,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:15,301 INFO:     Epoch: 46
2023-01-05 11:24:17,420 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46171907236178716, 'Total loss': 0.46171907236178716} | train loss {'Reaction outcome loss': 0.342752048820803, 'Total loss': 0.342752048820803}
2023-01-05 11:24:17,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:17,420 INFO:     Epoch: 47
2023-01-05 11:24:19,506 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4322378866374493, 'Total loss': 0.4322378866374493} | train loss {'Reaction outcome loss': 0.3390548078022597, 'Total loss': 0.3390548078022597}
2023-01-05 11:24:19,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:19,507 INFO:     Epoch: 48
2023-01-05 11:24:21,619 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47607523600260415, 'Total loss': 0.47607523600260415} | train loss {'Reaction outcome loss': 0.33409819918456096, 'Total loss': 0.33409819918456096}
2023-01-05 11:24:21,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:21,619 INFO:     Epoch: 49
2023-01-05 11:24:23,713 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.455886247754097, 'Total loss': 0.455886247754097} | train loss {'Reaction outcome loss': 0.32989551994826766, 'Total loss': 0.32989551994826766}
2023-01-05 11:24:23,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:23,713 INFO:     Epoch: 50
2023-01-05 11:24:25,813 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5085431893666585, 'Total loss': 0.5085431893666585} | train loss {'Reaction outcome loss': 0.33532067628461365, 'Total loss': 0.33532067628461365}
2023-01-05 11:24:25,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:25,813 INFO:     Epoch: 51
2023-01-05 11:24:27,927 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.500365287065506, 'Total loss': 0.500365287065506} | train loss {'Reaction outcome loss': 0.3275069585786416, 'Total loss': 0.3275069585786416}
2023-01-05 11:24:27,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:27,928 INFO:     Epoch: 52
2023-01-05 11:24:30,030 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45079531942804657, 'Total loss': 0.45079531942804657} | train loss {'Reaction outcome loss': 0.3279483845191343, 'Total loss': 0.3279483845191343}
2023-01-05 11:24:30,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:30,030 INFO:     Epoch: 53
2023-01-05 11:24:32,117 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4880929410457611, 'Total loss': 0.4880929410457611} | train loss {'Reaction outcome loss': 0.32090569807782826, 'Total loss': 0.32090569807782826}
2023-01-05 11:24:32,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:32,119 INFO:     Epoch: 54
2023-01-05 11:24:34,289 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4680619468291601, 'Total loss': 0.4680619468291601} | train loss {'Reaction outcome loss': 0.3182203949944222, 'Total loss': 0.3182203949944222}
2023-01-05 11:24:34,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:34,289 INFO:     Epoch: 55
2023-01-05 11:24:36,384 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45896331369876864, 'Total loss': 0.45896331369876864} | train loss {'Reaction outcome loss': 0.32020008380033566, 'Total loss': 0.32020008380033566}
2023-01-05 11:24:36,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:36,385 INFO:     Epoch: 56
2023-01-05 11:24:38,499 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5194110204776128, 'Total loss': 0.5194110204776128} | train loss {'Reaction outcome loss': 0.31741341151597297, 'Total loss': 0.31741341151597297}
2023-01-05 11:24:38,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:38,500 INFO:     Epoch: 57
2023-01-05 11:24:40,620 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4455758571624756, 'Total loss': 0.4455758571624756} | train loss {'Reaction outcome loss': 0.31379956071650533, 'Total loss': 0.31379956071650533}
2023-01-05 11:24:40,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:40,620 INFO:     Epoch: 58
2023-01-05 11:24:42,702 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47198669115702313, 'Total loss': 0.47198669115702313} | train loss {'Reaction outcome loss': 0.3180119344630303, 'Total loss': 0.3180119344630303}
2023-01-05 11:24:42,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:42,703 INFO:     Epoch: 59
2023-01-05 11:24:44,815 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41302414387464526, 'Total loss': 0.41302414387464526} | train loss {'Reaction outcome loss': 0.31906985913167946, 'Total loss': 0.31906985913167946}
2023-01-05 11:24:44,815 INFO:     Found new best model at epoch 59
2023-01-05 11:24:44,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:44,817 INFO:     Epoch: 60
2023-01-05 11:24:46,916 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45843241810798646, 'Total loss': 0.45843241810798646} | train loss {'Reaction outcome loss': 0.31277830569899123, 'Total loss': 0.31277830569899123}
2023-01-05 11:24:46,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:46,916 INFO:     Epoch: 61
2023-01-05 11:24:49,035 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4771746575832367, 'Total loss': 0.4771746575832367} | train loss {'Reaction outcome loss': 0.3111529472956072, 'Total loss': 0.3111529472956072}
2023-01-05 11:24:49,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:49,036 INFO:     Epoch: 62
2023-01-05 11:24:51,184 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4229961554209391, 'Total loss': 0.4229961554209391} | train loss {'Reaction outcome loss': 0.3015983393722838, 'Total loss': 0.3015983393722838}
2023-01-05 11:24:51,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:51,184 INFO:     Epoch: 63
2023-01-05 11:24:53,346 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4442233289281527, 'Total loss': 0.4442233289281527} | train loss {'Reaction outcome loss': 0.30684565131862956, 'Total loss': 0.30684565131862956}
2023-01-05 11:24:53,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:53,346 INFO:     Epoch: 64
2023-01-05 11:24:55,508 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4428439219792684, 'Total loss': 0.4428439219792684} | train loss {'Reaction outcome loss': 0.3031112830881234, 'Total loss': 0.3031112830881234}
2023-01-05 11:24:55,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:55,508 INFO:     Epoch: 65
2023-01-05 11:24:57,688 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45821119050184883, 'Total loss': 0.45821119050184883} | train loss {'Reaction outcome loss': 0.29124837532475756, 'Total loss': 0.29124837532475756}
2023-01-05 11:24:57,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:57,688 INFO:     Epoch: 66
2023-01-05 11:24:59,823 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46801381011803944, 'Total loss': 0.46801381011803944} | train loss {'Reaction outcome loss': 0.29496955486771825, 'Total loss': 0.29496955486771825}
2023-01-05 11:24:59,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:24:59,824 INFO:     Epoch: 67
2023-01-05 11:25:01,970 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43522613843282065, 'Total loss': 0.43522613843282065} | train loss {'Reaction outcome loss': 0.2961919756381066, 'Total loss': 0.2961919756381066}
2023-01-05 11:25:01,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:01,970 INFO:     Epoch: 68
2023-01-05 11:25:04,109 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4762702345848083, 'Total loss': 0.4762702345848083} | train loss {'Reaction outcome loss': 0.3002056985097381, 'Total loss': 0.3002056985097381}
2023-01-05 11:25:04,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:04,109 INFO:     Epoch: 69
2023-01-05 11:25:06,253 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4391990820566813, 'Total loss': 0.4391990820566813} | train loss {'Reaction outcome loss': 0.2914673237628116, 'Total loss': 0.2914673237628116}
2023-01-05 11:25:06,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:06,254 INFO:     Epoch: 70
2023-01-05 11:25:08,339 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45399080365896227, 'Total loss': 0.45399080365896227} | train loss {'Reaction outcome loss': 0.2981232862250927, 'Total loss': 0.2981232862250927}
2023-01-05 11:25:08,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:08,340 INFO:     Epoch: 71
2023-01-05 11:25:10,444 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40577517946561176, 'Total loss': 0.40577517946561176} | train loss {'Reaction outcome loss': 0.29192086021951485, 'Total loss': 0.29192086021951485}
2023-01-05 11:25:10,444 INFO:     Found new best model at epoch 71
2023-01-05 11:25:10,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:10,445 INFO:     Epoch: 72
2023-01-05 11:25:12,556 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4163452222943306, 'Total loss': 0.4163452222943306} | train loss {'Reaction outcome loss': 0.29811269459706957, 'Total loss': 0.29811269459706957}
2023-01-05 11:25:12,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:12,557 INFO:     Epoch: 73
2023-01-05 11:25:14,645 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47255325416723887, 'Total loss': 0.47255325416723887} | train loss {'Reaction outcome loss': 0.28951998493009873, 'Total loss': 0.28951998493009873}
2023-01-05 11:25:14,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:14,646 INFO:     Epoch: 74
2023-01-05 11:25:16,760 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4579383214314779, 'Total loss': 0.4579383214314779} | train loss {'Reaction outcome loss': 0.29084419701998926, 'Total loss': 0.29084419701998926}
2023-01-05 11:25:16,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:16,760 INFO:     Epoch: 75
2023-01-05 11:25:18,858 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4185071369012197, 'Total loss': 0.4185071369012197} | train loss {'Reaction outcome loss': 0.2799365815976055, 'Total loss': 0.2799365815976055}
2023-01-05 11:25:18,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:18,858 INFO:     Epoch: 76
2023-01-05 11:25:20,955 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4825403074423472, 'Total loss': 0.4825403074423472} | train loss {'Reaction outcome loss': 0.28796919654959285, 'Total loss': 0.28796919654959285}
2023-01-05 11:25:20,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:20,955 INFO:     Epoch: 77
2023-01-05 11:25:23,029 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45525572697321576, 'Total loss': 0.45525572697321576} | train loss {'Reaction outcome loss': 0.28315796188996495, 'Total loss': 0.28315796188996495}
2023-01-05 11:25:23,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:23,029 INFO:     Epoch: 78
2023-01-05 11:25:25,158 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43168247876067956, 'Total loss': 0.43168247876067956} | train loss {'Reaction outcome loss': 0.28248581514035387, 'Total loss': 0.28248581514035387}
2023-01-05 11:25:25,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:25,158 INFO:     Epoch: 79
2023-01-05 11:25:27,272 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4619252463181814, 'Total loss': 0.4619252463181814} | train loss {'Reaction outcome loss': 0.282541153863782, 'Total loss': 0.282541153863782}
2023-01-05 11:25:27,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:27,273 INFO:     Epoch: 80
2023-01-05 11:25:29,386 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4416428456703822, 'Total loss': 0.4416428456703822} | train loss {'Reaction outcome loss': 0.27988547515192314, 'Total loss': 0.27988547515192314}
2023-01-05 11:25:29,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:29,386 INFO:     Epoch: 81
2023-01-05 11:25:31,470 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40876599301894506, 'Total loss': 0.40876599301894506} | train loss {'Reaction outcome loss': 0.2726479518694646, 'Total loss': 0.2726479518694646}
2023-01-05 11:25:31,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:31,470 INFO:     Epoch: 82
2023-01-05 11:25:33,565 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4072520395119985, 'Total loss': 0.4072520395119985} | train loss {'Reaction outcome loss': 0.2829478881134218, 'Total loss': 0.2829478881134218}
2023-01-05 11:25:33,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:33,566 INFO:     Epoch: 83
2023-01-05 11:25:35,699 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4460345312952995, 'Total loss': 0.4460345312952995} | train loss {'Reaction outcome loss': 0.2724010657464519, 'Total loss': 0.2724010657464519}
2023-01-05 11:25:35,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:35,699 INFO:     Epoch: 84
2023-01-05 11:25:37,867 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4633822719256083, 'Total loss': 0.4633822719256083} | train loss {'Reaction outcome loss': 0.275119184451553, 'Total loss': 0.275119184451553}
2023-01-05 11:25:37,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:37,867 INFO:     Epoch: 85
2023-01-05 11:25:40,040 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44134528040885923, 'Total loss': 0.44134528040885923} | train loss {'Reaction outcome loss': 0.27090930480223435, 'Total loss': 0.27090930480223435}
2023-01-05 11:25:40,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:40,041 INFO:     Epoch: 86
2023-01-05 11:25:42,209 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4469796627759933, 'Total loss': 0.4469796627759933} | train loss {'Reaction outcome loss': 0.26886767063685607, 'Total loss': 0.26886767063685607}
2023-01-05 11:25:42,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:42,209 INFO:     Epoch: 87
2023-01-05 11:25:44,317 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4588028530279795, 'Total loss': 0.4588028530279795} | train loss {'Reaction outcome loss': 0.2808392355866703, 'Total loss': 0.2808392355866703}
2023-01-05 11:25:44,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:44,318 INFO:     Epoch: 88
2023-01-05 11:25:46,474 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4444550457100073, 'Total loss': 0.4444550457100073} | train loss {'Reaction outcome loss': 0.2726756721775938, 'Total loss': 0.2726756721775938}
2023-01-05 11:25:46,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:46,475 INFO:     Epoch: 89
2023-01-05 11:25:48,593 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44923331985870996, 'Total loss': 0.44923331985870996} | train loss {'Reaction outcome loss': 0.27237257847883106, 'Total loss': 0.27237257847883106}
2023-01-05 11:25:48,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:48,594 INFO:     Epoch: 90
2023-01-05 11:25:50,689 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4416261831919352, 'Total loss': 0.4416261831919352} | train loss {'Reaction outcome loss': 0.2714324309302992, 'Total loss': 0.2714324309302992}
2023-01-05 11:25:50,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:50,690 INFO:     Epoch: 91
2023-01-05 11:25:52,796 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4247010121742884, 'Total loss': 0.4247010121742884} | train loss {'Reaction outcome loss': 0.2625711134877124, 'Total loss': 0.2625711134877124}
2023-01-05 11:25:52,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:52,797 INFO:     Epoch: 92
2023-01-05 11:25:54,902 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42320545117060343, 'Total loss': 0.42320545117060343} | train loss {'Reaction outcome loss': 0.2654936808492347, 'Total loss': 0.2654936808492347}
2023-01-05 11:25:54,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:54,903 INFO:     Epoch: 93
2023-01-05 11:25:57,022 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44739534258842467, 'Total loss': 0.44739534258842467} | train loss {'Reaction outcome loss': 0.26365195410564923, 'Total loss': 0.26365195410564923}
2023-01-05 11:25:57,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:57,023 INFO:     Epoch: 94
2023-01-05 11:25:59,114 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4269673988223076, 'Total loss': 0.4269673988223076} | train loss {'Reaction outcome loss': 0.2654018589865157, 'Total loss': 0.2654018589865157}
2023-01-05 11:25:59,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:25:59,115 INFO:     Epoch: 95
2023-01-05 11:26:01,012 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42932312389214833, 'Total loss': 0.42932312389214833} | train loss {'Reaction outcome loss': 0.2670630477778204, 'Total loss': 0.2670630477778204}
2023-01-05 11:26:01,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:01,013 INFO:     Epoch: 96
2023-01-05 11:26:03,097 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43322268724441526, 'Total loss': 0.43322268724441526} | train loss {'Reaction outcome loss': 0.26920419415602315, 'Total loss': 0.26920419415602315}
2023-01-05 11:26:03,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:03,098 INFO:     Epoch: 97
2023-01-05 11:26:05,181 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46596562266349795, 'Total loss': 0.46596562266349795} | train loss {'Reaction outcome loss': 0.26141768822194017, 'Total loss': 0.26141768822194017}
2023-01-05 11:26:05,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:05,181 INFO:     Epoch: 98
2023-01-05 11:26:07,330 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4416160116593043, 'Total loss': 0.4416160116593043} | train loss {'Reaction outcome loss': 0.2580392273490901, 'Total loss': 0.2580392273490901}
2023-01-05 11:26:07,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:07,331 INFO:     Epoch: 99
2023-01-05 11:26:09,436 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4375559958318869, 'Total loss': 0.4375559958318869} | train loss {'Reaction outcome loss': 0.2611702803058393, 'Total loss': 0.2611702803058393}
2023-01-05 11:26:09,437 INFO:     Best model found after epoch 72 of 100.
2023-01-05 11:26:09,437 INFO:   Done with stage: TRAINING
2023-01-05 11:26:09,437 INFO:   Starting stage: EVALUATION
2023-01-05 11:26:09,580 INFO:   Done with stage: EVALUATION
2023-01-05 11:26:09,580 INFO:   Leaving out SEQ value Fold_3
2023-01-05 11:26:09,593 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:26:09,593 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:26:10,229 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:26:10,229 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:26:10,296 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:26:10,296 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:26:10,297 INFO:     No hyperparam tuning for this model
2023-01-05 11:26:10,297 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:26:10,297 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:26:10,297 INFO:     None feature selector for col prot
2023-01-05 11:26:10,297 INFO:     None feature selector for col prot
2023-01-05 11:26:10,298 INFO:     None feature selector for col prot
2023-01-05 11:26:10,298 INFO:     None feature selector for col chem
2023-01-05 11:26:10,298 INFO:     None feature selector for col chem
2023-01-05 11:26:10,298 INFO:     None feature selector for col chem
2023-01-05 11:26:10,298 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:26:10,298 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:26:10,300 INFO:     Number of params in model 72901
2023-01-05 11:26:10,303 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:26:10,303 INFO:   Starting stage: TRAINING
2023-01-05 11:26:10,359 INFO:     Val loss before train {'Reaction outcome loss': 1.0638052185376485, 'Total loss': 1.0638052185376485}
2023-01-05 11:26:10,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:10,359 INFO:     Epoch: 0
2023-01-05 11:26:12,466 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8681150555610657, 'Total loss': 0.8681150555610657} | train loss {'Reaction outcome loss': 0.9334155474483532, 'Total loss': 0.9334155474483532}
2023-01-05 11:26:12,466 INFO:     Found new best model at epoch 0
2023-01-05 11:26:12,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:12,468 INFO:     Epoch: 1
2023-01-05 11:26:14,610 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6117981811364491, 'Total loss': 0.6117981811364491} | train loss {'Reaction outcome loss': 0.724204861769711, 'Total loss': 0.724204861769711}
2023-01-05 11:26:14,612 INFO:     Found new best model at epoch 1
2023-01-05 11:26:14,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:14,613 INFO:     Epoch: 2
2023-01-05 11:26:16,691 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5945428768793742, 'Total loss': 0.5945428768793742} | train loss {'Reaction outcome loss': 0.5818390259723158, 'Total loss': 0.5818390259723158}
2023-01-05 11:26:16,691 INFO:     Found new best model at epoch 2
2023-01-05 11:26:16,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:16,692 INFO:     Epoch: 3
2023-01-05 11:26:18,809 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5201535125573477, 'Total loss': 0.5201535125573477} | train loss {'Reaction outcome loss': 0.5369738930985876, 'Total loss': 0.5369738930985876}
2023-01-05 11:26:18,809 INFO:     Found new best model at epoch 3
2023-01-05 11:26:18,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:18,810 INFO:     Epoch: 4
2023-01-05 11:26:20,903 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5002171546220779, 'Total loss': 0.5002171546220779} | train loss {'Reaction outcome loss': 0.5131093194014835, 'Total loss': 0.5131093194014835}
2023-01-05 11:26:20,904 INFO:     Found new best model at epoch 4
2023-01-05 11:26:20,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:20,905 INFO:     Epoch: 5
2023-01-05 11:26:23,017 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49412795702616374, 'Total loss': 0.49412795702616374} | train loss {'Reaction outcome loss': 0.5019181167339757, 'Total loss': 0.5019181167339757}
2023-01-05 11:26:23,017 INFO:     Found new best model at epoch 5
2023-01-05 11:26:23,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:23,018 INFO:     Epoch: 6
2023-01-05 11:26:25,167 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5070163935422898, 'Total loss': 0.5070163935422898} | train loss {'Reaction outcome loss': 0.49753354913996956, 'Total loss': 0.49753354913996956}
2023-01-05 11:26:25,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:25,167 INFO:     Epoch: 7
2023-01-05 11:26:27,251 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.479093990723292, 'Total loss': 0.479093990723292} | train loss {'Reaction outcome loss': 0.48620368184073126, 'Total loss': 0.48620368184073126}
2023-01-05 11:26:27,251 INFO:     Found new best model at epoch 7
2023-01-05 11:26:27,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:27,253 INFO:     Epoch: 8
2023-01-05 11:26:29,443 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48103557974100114, 'Total loss': 0.48103557974100114} | train loss {'Reaction outcome loss': 0.48256082854566784, 'Total loss': 0.48256082854566784}
2023-01-05 11:26:29,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:29,443 INFO:     Epoch: 9
2023-01-05 11:26:31,577 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4805535753568014, 'Total loss': 0.4805535753568014} | train loss {'Reaction outcome loss': 0.47625767700646043, 'Total loss': 0.47625767700646043}
2023-01-05 11:26:31,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:31,578 INFO:     Epoch: 10
2023-01-05 11:26:33,710 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4872308949629466, 'Total loss': 0.4872308949629466} | train loss {'Reaction outcome loss': 0.4689428829146128, 'Total loss': 0.4689428829146128}
2023-01-05 11:26:33,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:33,711 INFO:     Epoch: 11
2023-01-05 11:26:35,849 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.458529665072759, 'Total loss': 0.458529665072759} | train loss {'Reaction outcome loss': 0.46085692224276326, 'Total loss': 0.46085692224276326}
2023-01-05 11:26:35,849 INFO:     Found new best model at epoch 11
2023-01-05 11:26:35,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:35,850 INFO:     Epoch: 12
2023-01-05 11:26:37,994 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4627298951148987, 'Total loss': 0.4627298951148987} | train loss {'Reaction outcome loss': 0.4581530843011654, 'Total loss': 0.4581530843011654}
2023-01-05 11:26:37,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:37,995 INFO:     Epoch: 13
2023-01-05 11:26:40,117 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45622608860333763, 'Total loss': 0.45622608860333763} | train loss {'Reaction outcome loss': 0.45631931852685276, 'Total loss': 0.45631931852685276}
2023-01-05 11:26:40,117 INFO:     Found new best model at epoch 13
2023-01-05 11:26:40,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:40,118 INFO:     Epoch: 14
2023-01-05 11:26:42,237 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4463280220826467, 'Total loss': 0.4463280220826467} | train loss {'Reaction outcome loss': 0.4489674729424237, 'Total loss': 0.4489674729424237}
2023-01-05 11:26:42,237 INFO:     Found new best model at epoch 14
2023-01-05 11:26:42,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:42,238 INFO:     Epoch: 15
2023-01-05 11:26:44,356 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46069652239481607, 'Total loss': 0.46069652239481607} | train loss {'Reaction outcome loss': 0.44071073729517685, 'Total loss': 0.44071073729517685}
2023-01-05 11:26:44,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:44,357 INFO:     Epoch: 16
2023-01-05 11:26:46,499 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48047191500663755, 'Total loss': 0.48047191500663755} | train loss {'Reaction outcome loss': 0.43786127280688636, 'Total loss': 0.43786127280688636}
2023-01-05 11:26:46,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:46,499 INFO:     Epoch: 17
2023-01-05 11:26:48,630 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4603078365325928, 'Total loss': 0.4603078365325928} | train loss {'Reaction outcome loss': 0.4375084554300691, 'Total loss': 0.4375084554300691}
2023-01-05 11:26:48,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:48,630 INFO:     Epoch: 18
2023-01-05 11:26:50,737 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4532537599404653, 'Total loss': 0.4532537599404653} | train loss {'Reaction outcome loss': 0.42534371481759703, 'Total loss': 0.42534371481759703}
2023-01-05 11:26:50,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:50,738 INFO:     Epoch: 19
2023-01-05 11:26:52,830 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4166835238536199, 'Total loss': 0.4166835238536199} | train loss {'Reaction outcome loss': 0.42442865593590007, 'Total loss': 0.42442865593590007}
2023-01-05 11:26:52,830 INFO:     Found new best model at epoch 19
2023-01-05 11:26:52,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:52,832 INFO:     Epoch: 20
2023-01-05 11:26:54,951 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4330175300439199, 'Total loss': 0.4330175300439199} | train loss {'Reaction outcome loss': 0.4278165668140363, 'Total loss': 0.4278165668140363}
2023-01-05 11:26:54,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:54,951 INFO:     Epoch: 21
2023-01-05 11:26:57,069 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4445137252410253, 'Total loss': 0.4445137252410253} | train loss {'Reaction outcome loss': 0.4155874092430964, 'Total loss': 0.4155874092430964}
2023-01-05 11:26:57,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:57,070 INFO:     Epoch: 22
2023-01-05 11:26:59,216 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4026482125123342, 'Total loss': 0.4026482125123342} | train loss {'Reaction outcome loss': 0.41522041123605125, 'Total loss': 0.41522041123605125}
2023-01-05 11:26:59,216 INFO:     Found new best model at epoch 22
2023-01-05 11:26:59,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:26:59,217 INFO:     Epoch: 23
2023-01-05 11:27:01,331 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4363654891649882, 'Total loss': 0.4363654891649882} | train loss {'Reaction outcome loss': 0.41054249304707036, 'Total loss': 0.41054249304707036}
2023-01-05 11:27:01,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:01,331 INFO:     Epoch: 24
2023-01-05 11:27:03,435 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43094747761885327, 'Total loss': 0.43094747761885327} | train loss {'Reaction outcome loss': 0.408510930210787, 'Total loss': 0.408510930210787}
2023-01-05 11:27:03,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:03,435 INFO:     Epoch: 25
2023-01-05 11:27:05,557 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42810033857822416, 'Total loss': 0.42810033857822416} | train loss {'Reaction outcome loss': 0.3982832785015994, 'Total loss': 0.3982832785015994}
2023-01-05 11:27:05,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:05,557 INFO:     Epoch: 26
2023-01-05 11:27:07,678 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4284277548392614, 'Total loss': 0.4284277548392614} | train loss {'Reaction outcome loss': 0.3948073484492998, 'Total loss': 0.3948073484492998}
2023-01-05 11:27:07,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:07,678 INFO:     Epoch: 27
2023-01-05 11:27:09,818 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4432526965936025, 'Total loss': 0.4432526965936025} | train loss {'Reaction outcome loss': 0.3899383485099695, 'Total loss': 0.3899383485099695}
2023-01-05 11:27:09,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:09,819 INFO:     Epoch: 28
2023-01-05 11:27:11,966 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4026687448223432, 'Total loss': 0.4026687448223432} | train loss {'Reaction outcome loss': 0.3953470070812389, 'Total loss': 0.3953470070812389}
2023-01-05 11:27:11,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:11,966 INFO:     Epoch: 29
2023-01-05 11:27:14,105 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42291332681973776, 'Total loss': 0.42291332681973776} | train loss {'Reaction outcome loss': 0.38311348159382813, 'Total loss': 0.38311348159382813}
2023-01-05 11:27:14,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:14,105 INFO:     Epoch: 30
2023-01-05 11:27:16,243 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45537539223829904, 'Total loss': 0.45537539223829904} | train loss {'Reaction outcome loss': 0.38099317655076076, 'Total loss': 0.38099317655076076}
2023-01-05 11:27:16,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:16,243 INFO:     Epoch: 31
2023-01-05 11:27:18,380 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44728014469146726, 'Total loss': 0.44728014469146726} | train loss {'Reaction outcome loss': 0.38033699350309197, 'Total loss': 0.38033699350309197}
2023-01-05 11:27:18,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:18,381 INFO:     Epoch: 32
2023-01-05 11:27:20,504 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4075631300608317, 'Total loss': 0.4075631300608317} | train loss {'Reaction outcome loss': 0.38068364334911325, 'Total loss': 0.38068364334911325}
2023-01-05 11:27:20,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:20,505 INFO:     Epoch: 33
2023-01-05 11:27:22,647 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4159591833750407, 'Total loss': 0.4159591833750407} | train loss {'Reaction outcome loss': 0.37523744467401154, 'Total loss': 0.37523744467401154}
2023-01-05 11:27:22,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:22,647 INFO:     Epoch: 34
2023-01-05 11:27:24,768 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42134724954764047, 'Total loss': 0.42134724954764047} | train loss {'Reaction outcome loss': 0.3730514417708355, 'Total loss': 0.3730514417708355}
2023-01-05 11:27:24,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:24,768 INFO:     Epoch: 35
2023-01-05 11:27:26,900 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4079574714104334, 'Total loss': 0.4079574714104334} | train loss {'Reaction outcome loss': 0.3640408787849176, 'Total loss': 0.3640408787849176}
2023-01-05 11:27:26,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:26,901 INFO:     Epoch: 36
2023-01-05 11:27:29,023 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4115734398365021, 'Total loss': 0.4115734398365021} | train loss {'Reaction outcome loss': 0.3646053466538008, 'Total loss': 0.3646053466538008}
2023-01-05 11:27:29,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:29,023 INFO:     Epoch: 37
2023-01-05 11:27:31,131 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43216002856691677, 'Total loss': 0.43216002856691677} | train loss {'Reaction outcome loss': 0.3566484419479422, 'Total loss': 0.3566484419479422}
2023-01-05 11:27:31,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:31,131 INFO:     Epoch: 38
2023-01-05 11:27:33,263 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41796458065509795, 'Total loss': 0.41796458065509795} | train loss {'Reaction outcome loss': 0.3525674131828068, 'Total loss': 0.3525674131828068}
2023-01-05 11:27:33,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:33,264 INFO:     Epoch: 39
2023-01-05 11:27:35,385 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42579198082288106, 'Total loss': 0.42579198082288106} | train loss {'Reaction outcome loss': 0.35013430791288397, 'Total loss': 0.35013430791288397}
2023-01-05 11:27:35,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:35,385 INFO:     Epoch: 40
2023-01-05 11:27:37,488 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41076512038707735, 'Total loss': 0.41076512038707735} | train loss {'Reaction outcome loss': 0.3524979759333995, 'Total loss': 0.3524979759333995}
2023-01-05 11:27:37,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:37,488 INFO:     Epoch: 41
2023-01-05 11:27:39,621 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4180390536785126, 'Total loss': 0.4180390536785126} | train loss {'Reaction outcome loss': 0.35049332071938655, 'Total loss': 0.35049332071938655}
2023-01-05 11:27:39,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:39,621 INFO:     Epoch: 42
2023-01-05 11:27:41,719 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4247690985600154, 'Total loss': 0.4247690985600154} | train loss {'Reaction outcome loss': 0.3494150824844837, 'Total loss': 0.3494150824844837}
2023-01-05 11:27:41,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:41,720 INFO:     Epoch: 43
2023-01-05 11:27:43,835 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4271149734656016, 'Total loss': 0.4271149734656016} | train loss {'Reaction outcome loss': 0.34275934543379033, 'Total loss': 0.34275934543379033}
2023-01-05 11:27:43,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:43,835 INFO:     Epoch: 44
2023-01-05 11:27:45,964 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41575226982434593, 'Total loss': 0.41575226982434593} | train loss {'Reaction outcome loss': 0.3368700393033724, 'Total loss': 0.3368700393033724}
2023-01-05 11:27:45,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:45,965 INFO:     Epoch: 45
2023-01-05 11:27:48,092 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42349184652169547, 'Total loss': 0.42349184652169547} | train loss {'Reaction outcome loss': 0.3344398123096593, 'Total loss': 0.3344398123096593}
2023-01-05 11:27:48,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:48,092 INFO:     Epoch: 46
2023-01-05 11:27:50,231 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4304024209578832, 'Total loss': 0.4304024209578832} | train loss {'Reaction outcome loss': 0.33904169293215675, 'Total loss': 0.33904169293215675}
2023-01-05 11:27:50,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:50,231 INFO:     Epoch: 47
2023-01-05 11:27:52,350 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4297441323598226, 'Total loss': 0.4297441323598226} | train loss {'Reaction outcome loss': 0.3327145493269837, 'Total loss': 0.3327145493269837}
2023-01-05 11:27:52,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:52,350 INFO:     Epoch: 48
2023-01-05 11:27:54,471 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4078645666440328, 'Total loss': 0.4078645666440328} | train loss {'Reaction outcome loss': 0.334032989739284, 'Total loss': 0.334032989739284}
2023-01-05 11:27:54,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:54,471 INFO:     Epoch: 49
2023-01-05 11:27:56,616 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4261921306451162, 'Total loss': 0.4261921306451162} | train loss {'Reaction outcome loss': 0.3183590703691444, 'Total loss': 0.3183590703691444}
2023-01-05 11:27:56,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:56,618 INFO:     Epoch: 50
2023-01-05 11:27:58,745 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4253145883480708, 'Total loss': 0.4253145883480708} | train loss {'Reaction outcome loss': 0.3142705146685569, 'Total loss': 0.3142705146685569}
2023-01-05 11:27:58,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:27:58,745 INFO:     Epoch: 51
2023-01-05 11:28:00,844 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4417862673600515, 'Total loss': 0.4417862673600515} | train loss {'Reaction outcome loss': 0.3134045217009465, 'Total loss': 0.3134045217009465}
2023-01-05 11:28:00,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:00,844 INFO:     Epoch: 52
2023-01-05 11:28:02,965 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4107050021489461, 'Total loss': 0.4107050021489461} | train loss {'Reaction outcome loss': 0.31870931583409107, 'Total loss': 0.31870931583409107}
2023-01-05 11:28:02,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:02,966 INFO:     Epoch: 53
2023-01-05 11:28:05,087 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4175620769460996, 'Total loss': 0.4175620769460996} | train loss {'Reaction outcome loss': 0.3091875974625947, 'Total loss': 0.3091875974625947}
2023-01-05 11:28:05,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:05,087 INFO:     Epoch: 54
2023-01-05 11:28:07,196 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39704535802205404, 'Total loss': 0.39704535802205404} | train loss {'Reaction outcome loss': 0.30912565494323296, 'Total loss': 0.30912565494323296}
2023-01-05 11:28:07,196 INFO:     Found new best model at epoch 54
2023-01-05 11:28:07,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:07,198 INFO:     Epoch: 55
2023-01-05 11:28:09,301 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42731180985768635, 'Total loss': 0.42731180985768635} | train loss {'Reaction outcome loss': 0.307373346502546, 'Total loss': 0.307373346502546}
2023-01-05 11:28:09,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:09,301 INFO:     Epoch: 56
2023-01-05 11:28:11,419 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43363641401131947, 'Total loss': 0.43363641401131947} | train loss {'Reaction outcome loss': 0.30626677876732644, 'Total loss': 0.30626677876732644}
2023-01-05 11:28:11,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:11,420 INFO:     Epoch: 57
2023-01-05 11:28:13,541 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45738566666841507, 'Total loss': 0.45738566666841507} | train loss {'Reaction outcome loss': 0.2998642379241268, 'Total loss': 0.2998642379241268}
2023-01-05 11:28:13,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:13,541 INFO:     Epoch: 58
2023-01-05 11:28:15,671 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4578659892082214, 'Total loss': 0.4578659892082214} | train loss {'Reaction outcome loss': 0.30418641102520655, 'Total loss': 0.30418641102520655}
2023-01-05 11:28:15,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:15,672 INFO:     Epoch: 59
2023-01-05 11:28:17,784 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42354508439699806, 'Total loss': 0.42354508439699806} | train loss {'Reaction outcome loss': 0.298192051150938, 'Total loss': 0.298192051150938}
2023-01-05 11:28:17,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:17,785 INFO:     Epoch: 60
2023-01-05 11:28:19,905 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44440327485402426, 'Total loss': 0.44440327485402426} | train loss {'Reaction outcome loss': 0.2905643935294917, 'Total loss': 0.2905643935294917}
2023-01-05 11:28:19,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:19,905 INFO:     Epoch: 61
2023-01-05 11:28:22,027 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44736377398173016, 'Total loss': 0.44736377398173016} | train loss {'Reaction outcome loss': 0.29882762279959707, 'Total loss': 0.29882762279959707}
2023-01-05 11:28:22,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:22,028 INFO:     Epoch: 62
2023-01-05 11:28:24,128 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4609137425820033, 'Total loss': 0.4609137425820033} | train loss {'Reaction outcome loss': 0.2972017453752295, 'Total loss': 0.2972017453752295}
2023-01-05 11:28:24,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:24,129 INFO:     Epoch: 63
2023-01-05 11:28:26,257 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4358792285124461, 'Total loss': 0.4358792285124461} | train loss {'Reaction outcome loss': 0.28817032501237455, 'Total loss': 0.28817032501237455}
2023-01-05 11:28:26,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:26,257 INFO:     Epoch: 64
2023-01-05 11:28:28,371 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43878505130608875, 'Total loss': 0.43878505130608875} | train loss {'Reaction outcome loss': 0.2932093965610231, 'Total loss': 0.2932093965610231}
2023-01-05 11:28:28,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:28,371 INFO:     Epoch: 65
2023-01-05 11:28:30,485 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4031812046964963, 'Total loss': 0.4031812046964963} | train loss {'Reaction outcome loss': 0.2997441413084956, 'Total loss': 0.2997441413084956}
2023-01-05 11:28:30,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:30,486 INFO:     Epoch: 66
2023-01-05 11:28:32,609 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45395815968513487, 'Total loss': 0.45395815968513487} | train loss {'Reaction outcome loss': 0.28113739264544346, 'Total loss': 0.28113739264544346}
2023-01-05 11:28:32,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:32,610 INFO:     Epoch: 67
2023-01-05 11:28:34,714 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4301332741975784, 'Total loss': 0.4301332741975784} | train loss {'Reaction outcome loss': 0.28240712229026493, 'Total loss': 0.28240712229026493}
2023-01-05 11:28:34,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:34,715 INFO:     Epoch: 68
2023-01-05 11:28:36,823 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39908421635627744, 'Total loss': 0.39908421635627744} | train loss {'Reaction outcome loss': 0.2880180774759637, 'Total loss': 0.2880180774759637}
2023-01-05 11:28:36,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:36,823 INFO:     Epoch: 69
2023-01-05 11:28:38,950 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42321025927861533, 'Total loss': 0.42321025927861533} | train loss {'Reaction outcome loss': 0.2724979694823932, 'Total loss': 0.2724979694823932}
2023-01-05 11:28:38,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:38,951 INFO:     Epoch: 70
2023-01-05 11:28:41,067 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4262329856554667, 'Total loss': 0.4262329856554667} | train loss {'Reaction outcome loss': 0.273961624864788, 'Total loss': 0.273961624864788}
2023-01-05 11:28:41,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:41,068 INFO:     Epoch: 71
2023-01-05 11:28:43,213 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42504773338635765, 'Total loss': 0.42504773338635765} | train loss {'Reaction outcome loss': 0.2807360462450089, 'Total loss': 0.2807360462450089}
2023-01-05 11:28:43,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:43,214 INFO:     Epoch: 72
2023-01-05 11:28:45,325 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41637176771958667, 'Total loss': 0.41637176771958667} | train loss {'Reaction outcome loss': 0.2748200958254781, 'Total loss': 0.2748200958254781}
2023-01-05 11:28:45,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:45,325 INFO:     Epoch: 73
2023-01-05 11:28:47,416 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44986890455087025, 'Total loss': 0.44986890455087025} | train loss {'Reaction outcome loss': 0.27431040636542503, 'Total loss': 0.27431040636542503}
2023-01-05 11:28:47,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:47,416 INFO:     Epoch: 74
2023-01-05 11:28:49,541 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44154447118441265, 'Total loss': 0.44154447118441265} | train loss {'Reaction outcome loss': 0.27433878278536517, 'Total loss': 0.27433878278536517}
2023-01-05 11:28:49,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:49,541 INFO:     Epoch: 75
2023-01-05 11:28:51,678 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45098449985186256, 'Total loss': 0.45098449985186256} | train loss {'Reaction outcome loss': 0.27389014103742193, 'Total loss': 0.27389014103742193}
2023-01-05 11:28:51,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:51,679 INFO:     Epoch: 76
2023-01-05 11:28:53,797 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4452999432881673, 'Total loss': 0.4452999432881673} | train loss {'Reaction outcome loss': 0.27341783428768607, 'Total loss': 0.27341783428768607}
2023-01-05 11:28:53,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:53,797 INFO:     Epoch: 77
2023-01-05 11:28:55,910 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4501136382420858, 'Total loss': 0.4501136382420858} | train loss {'Reaction outcome loss': 0.2710077493947788, 'Total loss': 0.2710077493947788}
2023-01-05 11:28:55,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:55,910 INFO:     Epoch: 78
2023-01-05 11:28:58,007 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4239909147222837, 'Total loss': 0.4239909147222837} | train loss {'Reaction outcome loss': 0.2709037233144045, 'Total loss': 0.2709037233144045}
2023-01-05 11:28:58,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:28:58,008 INFO:     Epoch: 79
2023-01-05 11:29:00,122 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43760913610458374, 'Total loss': 0.43760913610458374} | train loss {'Reaction outcome loss': 0.2687574058336063, 'Total loss': 0.2687574058336063}
2023-01-05 11:29:00,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:00,122 INFO:     Epoch: 80
2023-01-05 11:29:02,257 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44885280529658, 'Total loss': 0.44885280529658} | train loss {'Reaction outcome loss': 0.25641017097871016, 'Total loss': 0.25641017097871016}
2023-01-05 11:29:02,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:02,257 INFO:     Epoch: 81
2023-01-05 11:29:04,365 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4096149762471517, 'Total loss': 0.4096149762471517} | train loss {'Reaction outcome loss': 0.2631498402949885, 'Total loss': 0.2631498402949885}
2023-01-05 11:29:04,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:04,365 INFO:     Epoch: 82
2023-01-05 11:29:06,476 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4249281048774719, 'Total loss': 0.4249281048774719} | train loss {'Reaction outcome loss': 0.2628919886098835, 'Total loss': 0.2628919886098835}
2023-01-05 11:29:06,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:06,476 INFO:     Epoch: 83
2023-01-05 11:29:08,610 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4350903411706289, 'Total loss': 0.4350903411706289} | train loss {'Reaction outcome loss': 0.2600322196899104, 'Total loss': 0.2600322196899104}
2023-01-05 11:29:08,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:08,611 INFO:     Epoch: 84
2023-01-05 11:29:10,726 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4318912148475647, 'Total loss': 0.4318912148475647} | train loss {'Reaction outcome loss': 0.2531690832200277, 'Total loss': 0.2531690832200277}
2023-01-05 11:29:10,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:10,727 INFO:     Epoch: 85
2023-01-05 11:29:12,866 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4074219028155009, 'Total loss': 0.4074219028155009} | train loss {'Reaction outcome loss': 0.25817082028319366, 'Total loss': 0.25817082028319366}
2023-01-05 11:29:12,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:12,867 INFO:     Epoch: 86
2023-01-05 11:29:14,995 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3735366895794868, 'Total loss': 0.3735366895794868} | train loss {'Reaction outcome loss': 0.2572626246421523, 'Total loss': 0.2572626246421523}
2023-01-05 11:29:14,996 INFO:     Found new best model at epoch 86
2023-01-05 11:29:14,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:14,997 INFO:     Epoch: 87
2023-01-05 11:29:17,088 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42167740563551587, 'Total loss': 0.42167740563551587} | train loss {'Reaction outcome loss': 0.2602635358603005, 'Total loss': 0.2602635358603005}
2023-01-05 11:29:17,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:17,088 INFO:     Epoch: 88
2023-01-05 11:29:19,214 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40733538071314496, 'Total loss': 0.40733538071314496} | train loss {'Reaction outcome loss': 0.2600755829459233, 'Total loss': 0.2600755829459233}
2023-01-05 11:29:19,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:19,214 INFO:     Epoch: 89
2023-01-05 11:29:21,326 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43864709039529165, 'Total loss': 0.43864709039529165} | train loss {'Reaction outcome loss': 0.25607436384162763, 'Total loss': 0.25607436384162763}
2023-01-05 11:29:21,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:21,326 INFO:     Epoch: 90
2023-01-05 11:29:23,448 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.381306650241216, 'Total loss': 0.381306650241216} | train loss {'Reaction outcome loss': 0.2569790097551733, 'Total loss': 0.2569790097551733}
2023-01-05 11:29:23,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:23,448 INFO:     Epoch: 91
2023-01-05 11:29:25,577 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4083868702252706, 'Total loss': 0.4083868702252706} | train loss {'Reaction outcome loss': 0.25454100264902535, 'Total loss': 0.25454100264902535}
2023-01-05 11:29:25,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:25,578 INFO:     Epoch: 92
2023-01-05 11:29:27,699 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4229145067433516, 'Total loss': 0.4229145067433516} | train loss {'Reaction outcome loss': 0.2511854738296166, 'Total loss': 0.2511854738296166}
2023-01-05 11:29:27,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:27,700 INFO:     Epoch: 93
2023-01-05 11:29:29,826 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42648089627424873, 'Total loss': 0.42648089627424873} | train loss {'Reaction outcome loss': 0.251055824787893, 'Total loss': 0.251055824787893}
2023-01-05 11:29:29,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:29,826 INFO:     Epoch: 94
2023-01-05 11:29:31,949 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4109474708636602, 'Total loss': 0.4109474708636602} | train loss {'Reaction outcome loss': 0.25001986362176004, 'Total loss': 0.25001986362176004}
2023-01-05 11:29:31,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:31,949 INFO:     Epoch: 95
2023-01-05 11:29:34,078 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4577495068311691, 'Total loss': 0.4577495068311691} | train loss {'Reaction outcome loss': 0.24791310420667712, 'Total loss': 0.24791310420667712}
2023-01-05 11:29:34,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:34,078 INFO:     Epoch: 96
2023-01-05 11:29:36,208 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4299602429072062, 'Total loss': 0.4299602429072062} | train loss {'Reaction outcome loss': 0.24443026740158344, 'Total loss': 0.24443026740158344}
2023-01-05 11:29:36,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:36,208 INFO:     Epoch: 97
2023-01-05 11:29:38,354 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4482187867164612, 'Total loss': 0.4482187867164612} | train loss {'Reaction outcome loss': 0.23911044624273795, 'Total loss': 0.23911044624273795}
2023-01-05 11:29:38,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:38,355 INFO:     Epoch: 98
2023-01-05 11:29:40,486 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44133175412813824, 'Total loss': 0.44133175412813824} | train loss {'Reaction outcome loss': 0.2480261371450594, 'Total loss': 0.2480261371450594}
2023-01-05 11:29:40,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:40,486 INFO:     Epoch: 99
2023-01-05 11:29:42,613 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4893127183119456, 'Total loss': 0.4893127183119456} | train loss {'Reaction outcome loss': 0.2519285319590547, 'Total loss': 0.2519285319590547}
2023-01-05 11:29:42,613 INFO:     Best model found after epoch 87 of 100.
2023-01-05 11:29:42,613 INFO:   Done with stage: TRAINING
2023-01-05 11:29:42,613 INFO:   Starting stage: EVALUATION
2023-01-05 11:29:42,753 INFO:   Done with stage: EVALUATION
2023-01-05 11:29:42,753 INFO:   Leaving out SEQ value Fold_4
2023-01-05 11:29:42,766 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 11:29:42,766 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:29:43,412 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:29:43,412 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:29:43,481 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:29:43,481 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:29:43,481 INFO:     No hyperparam tuning for this model
2023-01-05 11:29:43,481 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:29:43,481 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:29:43,482 INFO:     None feature selector for col prot
2023-01-05 11:29:43,482 INFO:     None feature selector for col prot
2023-01-05 11:29:43,482 INFO:     None feature selector for col prot
2023-01-05 11:29:43,483 INFO:     None feature selector for col chem
2023-01-05 11:29:43,483 INFO:     None feature selector for col chem
2023-01-05 11:29:43,483 INFO:     None feature selector for col chem
2023-01-05 11:29:43,483 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:29:43,483 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:29:43,485 INFO:     Number of params in model 72901
2023-01-05 11:29:43,488 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:29:43,488 INFO:   Starting stage: TRAINING
2023-01-05 11:29:43,545 INFO:     Val loss before train {'Reaction outcome loss': 0.9813084522883098, 'Total loss': 0.9813084522883098}
2023-01-05 11:29:43,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:43,546 INFO:     Epoch: 0
2023-01-05 11:29:45,680 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8119028766949972, 'Total loss': 0.8119028766949972} | train loss {'Reaction outcome loss': 0.9405476195548755, 'Total loss': 0.9405476195548755}
2023-01-05 11:29:45,681 INFO:     Found new best model at epoch 0
2023-01-05 11:29:45,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:45,683 INFO:     Epoch: 1
2023-01-05 11:29:47,822 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5757009088993073, 'Total loss': 0.5757009088993073} | train loss {'Reaction outcome loss': 0.7522274806447651, 'Total loss': 0.7522274806447651}
2023-01-05 11:29:47,822 INFO:     Found new best model at epoch 1
2023-01-05 11:29:47,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:47,823 INFO:     Epoch: 2
2023-01-05 11:29:49,979 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5076346774895986, 'Total loss': 0.5076346774895986} | train loss {'Reaction outcome loss': 0.57972266977194, 'Total loss': 0.57972266977194}
2023-01-05 11:29:49,980 INFO:     Found new best model at epoch 2
2023-01-05 11:29:49,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:49,981 INFO:     Epoch: 3
2023-01-05 11:29:52,111 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5070194313923518, 'Total loss': 0.5070194313923518} | train loss {'Reaction outcome loss': 0.531709595023236, 'Total loss': 0.531709595023236}
2023-01-05 11:29:52,112 INFO:     Found new best model at epoch 3
2023-01-05 11:29:52,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:52,113 INFO:     Epoch: 4
2023-01-05 11:29:54,250 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5217372139294942, 'Total loss': 0.5217372139294942} | train loss {'Reaction outcome loss': 0.5080670351226877, 'Total loss': 0.5080670351226877}
2023-01-05 11:29:54,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:54,251 INFO:     Epoch: 5
2023-01-05 11:29:56,394 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.465912452340126, 'Total loss': 0.465912452340126} | train loss {'Reaction outcome loss': 0.4973620398213034, 'Total loss': 0.4973620398213034}
2023-01-05 11:29:56,395 INFO:     Found new best model at epoch 5
2023-01-05 11:29:56,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:56,396 INFO:     Epoch: 6
2023-01-05 11:29:58,519 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49004010955492655, 'Total loss': 0.49004010955492655} | train loss {'Reaction outcome loss': 0.48731194582164195, 'Total loss': 0.48731194582164195}
2023-01-05 11:29:58,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:29:58,519 INFO:     Epoch: 7
2023-01-05 11:30:00,661 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4787417769432068, 'Total loss': 0.4787417769432068} | train loss {'Reaction outcome loss': 0.4741614949450815, 'Total loss': 0.4741614949450815}
2023-01-05 11:30:00,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:00,662 INFO:     Epoch: 8
2023-01-05 11:30:02,612 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4532396554946899, 'Total loss': 0.4532396554946899} | train loss {'Reaction outcome loss': 0.4682051776047877, 'Total loss': 0.4682051776047877}
2023-01-05 11:30:02,612 INFO:     Found new best model at epoch 8
2023-01-05 11:30:02,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:02,613 INFO:     Epoch: 9
2023-01-05 11:30:04,789 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48907671372095746, 'Total loss': 0.48907671372095746} | train loss {'Reaction outcome loss': 0.4625429408894717, 'Total loss': 0.4625429408894717}
2023-01-05 11:30:04,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:04,790 INFO:     Epoch: 10
2023-01-05 11:30:06,888 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4601946840683619, 'Total loss': 0.4601946840683619} | train loss {'Reaction outcome loss': 0.45868351618232933, 'Total loss': 0.45868351618232933}
2023-01-05 11:30:06,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:06,889 INFO:     Epoch: 11
2023-01-05 11:30:09,052 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4530107577641805, 'Total loss': 0.4530107577641805} | train loss {'Reaction outcome loss': 0.46049306633463805, 'Total loss': 0.46049306633463805}
2023-01-05 11:30:09,053 INFO:     Found new best model at epoch 11
2023-01-05 11:30:09,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:09,054 INFO:     Epoch: 12
2023-01-05 11:30:11,150 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46675077080726624, 'Total loss': 0.46675077080726624} | train loss {'Reaction outcome loss': 0.4626620256028179, 'Total loss': 0.4626620256028179}
2023-01-05 11:30:11,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:11,150 INFO:     Epoch: 13
2023-01-05 11:30:13,271 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49164025982220966, 'Total loss': 0.49164025982220966} | train loss {'Reaction outcome loss': 0.4530918792268072, 'Total loss': 0.4530918792268072}
2023-01-05 11:30:13,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:13,271 INFO:     Epoch: 14
2023-01-05 11:30:15,383 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4495149175326029, 'Total loss': 0.4495149175326029} | train loss {'Reaction outcome loss': 0.4828215921517003, 'Total loss': 0.4828215921517003}
2023-01-05 11:30:15,384 INFO:     Found new best model at epoch 14
2023-01-05 11:30:15,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:15,385 INFO:     Epoch: 15
2023-01-05 11:30:17,508 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.485620712240537, 'Total loss': 0.485620712240537} | train loss {'Reaction outcome loss': 0.442872011244459, 'Total loss': 0.442872011244459}
2023-01-05 11:30:17,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:17,508 INFO:     Epoch: 16
2023-01-05 11:30:19,628 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44874879519144695, 'Total loss': 0.44874879519144695} | train loss {'Reaction outcome loss': 0.43216892732037365, 'Total loss': 0.43216892732037365}
2023-01-05 11:30:19,629 INFO:     Found new best model at epoch 16
2023-01-05 11:30:19,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:19,631 INFO:     Epoch: 17
2023-01-05 11:30:21,790 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4394691864649455, 'Total loss': 0.4394691864649455} | train loss {'Reaction outcome loss': 0.4276113778190768, 'Total loss': 0.4276113778190768}
2023-01-05 11:30:21,790 INFO:     Found new best model at epoch 17
2023-01-05 11:30:21,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:21,791 INFO:     Epoch: 18
2023-01-05 11:30:23,902 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.445033339659373, 'Total loss': 0.445033339659373} | train loss {'Reaction outcome loss': 0.4256977899189013, 'Total loss': 0.4256977899189013}
2023-01-05 11:30:23,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:23,902 INFO:     Epoch: 19
2023-01-05 11:30:25,998 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45280624826749166, 'Total loss': 0.45280624826749166} | train loss {'Reaction outcome loss': 0.4206397744584019, 'Total loss': 0.4206397744584019}
2023-01-05 11:30:25,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:25,999 INFO:     Epoch: 20
2023-01-05 11:30:28,152 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45048136115074155, 'Total loss': 0.45048136115074155} | train loss {'Reaction outcome loss': 0.41707765250311757, 'Total loss': 0.41707765250311757}
2023-01-05 11:30:28,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:28,152 INFO:     Epoch: 21
2023-01-05 11:30:30,250 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44616305033365883, 'Total loss': 0.44616305033365883} | train loss {'Reaction outcome loss': 0.4149257082465118, 'Total loss': 0.4149257082465118}
2023-01-05 11:30:30,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:30,250 INFO:     Epoch: 22
2023-01-05 11:30:32,365 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4875295877456665, 'Total loss': 0.4875295877456665} | train loss {'Reaction outcome loss': 0.4051833881260962, 'Total loss': 0.4051833881260962}
2023-01-05 11:30:32,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:32,366 INFO:     Epoch: 23
2023-01-05 11:30:34,505 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45348535974820453, 'Total loss': 0.45348535974820453} | train loss {'Reaction outcome loss': 0.4087984953345596, 'Total loss': 0.4087984953345596}
2023-01-05 11:30:34,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:34,506 INFO:     Epoch: 24
2023-01-05 11:30:36,608 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4440422068039576, 'Total loss': 0.4440422068039576} | train loss {'Reaction outcome loss': 0.40179612454992003, 'Total loss': 0.40179612454992003}
2023-01-05 11:30:36,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:36,608 INFO:     Epoch: 25
2023-01-05 11:30:38,728 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4225902358690898, 'Total loss': 0.4225902358690898} | train loss {'Reaction outcome loss': 0.42603212125275447, 'Total loss': 0.42603212125275447}
2023-01-05 11:30:38,729 INFO:     Found new best model at epoch 25
2023-01-05 11:30:38,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:38,730 INFO:     Epoch: 26
2023-01-05 11:30:40,861 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4620148738225301, 'Total loss': 0.4620148738225301} | train loss {'Reaction outcome loss': 0.4019513061114897, 'Total loss': 0.4019513061114897}
2023-01-05 11:30:40,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:40,862 INFO:     Epoch: 27
2023-01-05 11:30:42,991 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45480363368988036, 'Total loss': 0.45480363368988036} | train loss {'Reaction outcome loss': 0.39090178695092304, 'Total loss': 0.39090178695092304}
2023-01-05 11:30:42,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:42,992 INFO:     Epoch: 28
2023-01-05 11:30:45,109 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44939316511154176, 'Total loss': 0.44939316511154176} | train loss {'Reaction outcome loss': 0.38709043005677074, 'Total loss': 0.38709043005677074}
2023-01-05 11:30:45,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:45,110 INFO:     Epoch: 29
2023-01-05 11:30:47,262 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42354676177104317, 'Total loss': 0.42354676177104317} | train loss {'Reaction outcome loss': 0.3891999507677215, 'Total loss': 0.3891999507677215}
2023-01-05 11:30:47,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:47,263 INFO:     Epoch: 30
2023-01-05 11:30:49,415 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4384234537680944, 'Total loss': 0.4384234537680944} | train loss {'Reaction outcome loss': 0.38666842103112437, 'Total loss': 0.38666842103112437}
2023-01-05 11:30:49,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:49,415 INFO:     Epoch: 31
2023-01-05 11:30:51,546 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42155514359474183, 'Total loss': 0.42155514359474183} | train loss {'Reaction outcome loss': 0.4113602279719181, 'Total loss': 0.4113602279719181}
2023-01-05 11:30:51,546 INFO:     Found new best model at epoch 31
2023-01-05 11:30:51,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:51,547 INFO:     Epoch: 32
2023-01-05 11:30:53,668 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4143883228302002, 'Total loss': 0.4143883228302002} | train loss {'Reaction outcome loss': 0.3759310005934558, 'Total loss': 0.3759310005934558}
2023-01-05 11:30:53,668 INFO:     Found new best model at epoch 32
2023-01-05 11:30:53,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:53,670 INFO:     Epoch: 33
2023-01-05 11:30:55,787 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44766216576099394, 'Total loss': 0.44766216576099394} | train loss {'Reaction outcome loss': 0.36738891218619363, 'Total loss': 0.36738891218619363}
2023-01-05 11:30:55,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:55,789 INFO:     Epoch: 34
2023-01-05 11:30:57,899 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46328947246074675, 'Total loss': 0.46328947246074675} | train loss {'Reaction outcome loss': 0.3641764485545486, 'Total loss': 0.3641764485545486}
2023-01-05 11:30:57,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:57,899 INFO:     Epoch: 35
2023-01-05 11:30:59,998 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4240606427192688, 'Total loss': 0.4240606427192688} | train loss {'Reaction outcome loss': 0.36275767709088064, 'Total loss': 0.36275767709088064}
2023-01-05 11:30:59,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:30:59,998 INFO:     Epoch: 36
2023-01-05 11:31:02,115 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4281331777572632, 'Total loss': 0.4281331777572632} | train loss {'Reaction outcome loss': 0.3623321098551231, 'Total loss': 0.3623321098551231}
2023-01-05 11:31:02,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:02,116 INFO:     Epoch: 37
2023-01-05 11:31:04,300 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42175492346286775, 'Total loss': 0.42175492346286775} | train loss {'Reaction outcome loss': 0.3562852188985309, 'Total loss': 0.3562852188985309}
2023-01-05 11:31:04,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:04,300 INFO:     Epoch: 38
2023-01-05 11:31:06,454 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4280677626530329, 'Total loss': 0.4280677626530329} | train loss {'Reaction outcome loss': 0.3504154695015725, 'Total loss': 0.3504154695015725}
2023-01-05 11:31:06,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:06,454 INFO:     Epoch: 39
2023-01-05 11:31:08,590 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43969214558601377, 'Total loss': 0.43969214558601377} | train loss {'Reaction outcome loss': 0.3485832582371296, 'Total loss': 0.3485832582371296}
2023-01-05 11:31:08,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:08,590 INFO:     Epoch: 40
2023-01-05 11:31:10,731 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4207804977893829, 'Total loss': 0.4207804977893829} | train loss {'Reaction outcome loss': 0.34672284101817646, 'Total loss': 0.34672284101817646}
2023-01-05 11:31:10,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:10,731 INFO:     Epoch: 41
2023-01-05 11:31:12,856 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.431945256392161, 'Total loss': 0.431945256392161} | train loss {'Reaction outcome loss': 0.34369233312537434, 'Total loss': 0.34369233312537434}
2023-01-05 11:31:12,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:12,856 INFO:     Epoch: 42
2023-01-05 11:31:15,004 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5106185346841812, 'Total loss': 0.5106185346841812} | train loss {'Reaction outcome loss': 0.34247499535643106, 'Total loss': 0.34247499535643106}
2023-01-05 11:31:15,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:15,005 INFO:     Epoch: 43
2023-01-05 11:31:17,146 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.431888539592425, 'Total loss': 0.431888539592425} | train loss {'Reaction outcome loss': 0.3941735970228088, 'Total loss': 0.3941735970228088}
2023-01-05 11:31:17,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:17,146 INFO:     Epoch: 44
2023-01-05 11:31:19,297 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45249880452950797, 'Total loss': 0.45249880452950797} | train loss {'Reaction outcome loss': 0.34954223109146015, 'Total loss': 0.34954223109146015}
2023-01-05 11:31:19,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:19,297 INFO:     Epoch: 45
2023-01-05 11:31:21,443 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44706010619799297, 'Total loss': 0.44706010619799297} | train loss {'Reaction outcome loss': 0.33496210076744953, 'Total loss': 0.33496210076744953}
2023-01-05 11:31:21,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:21,443 INFO:     Epoch: 46
2023-01-05 11:31:23,607 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4337761054436366, 'Total loss': 0.4337761054436366} | train loss {'Reaction outcome loss': 0.33246650917420123, 'Total loss': 0.33246650917420123}
2023-01-05 11:31:23,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:23,607 INFO:     Epoch: 47
2023-01-05 11:31:25,763 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42318668762842815, 'Total loss': 0.42318668762842815} | train loss {'Reaction outcome loss': 0.3303575974223086, 'Total loss': 0.3303575974223086}
2023-01-05 11:31:25,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:25,763 INFO:     Epoch: 48
2023-01-05 11:31:27,901 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41069858173529306, 'Total loss': 0.41069858173529306} | train loss {'Reaction outcome loss': 0.32380363118389377, 'Total loss': 0.32380363118389377}
2023-01-05 11:31:27,901 INFO:     Found new best model at epoch 48
2023-01-05 11:31:27,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:27,903 INFO:     Epoch: 49
2023-01-05 11:31:30,056 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4555811603864034, 'Total loss': 0.4555811603864034} | train loss {'Reaction outcome loss': 0.3226241437900487, 'Total loss': 0.3226241437900487}
2023-01-05 11:31:30,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:30,056 INFO:     Epoch: 50
2023-01-05 11:31:32,168 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4139705051978429, 'Total loss': 0.4139705051978429} | train loss {'Reaction outcome loss': 0.32047455346184794, 'Total loss': 0.32047455346184794}
2023-01-05 11:31:32,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:32,169 INFO:     Epoch: 51
2023-01-05 11:31:34,278 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41153520022829376, 'Total loss': 0.41153520022829376} | train loss {'Reaction outcome loss': 0.3236956915184303, 'Total loss': 0.3236956915184303}
2023-01-05 11:31:34,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:34,278 INFO:     Epoch: 52
2023-01-05 11:31:36,401 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4063281585772832, 'Total loss': 0.4063281585772832} | train loss {'Reaction outcome loss': 0.3200260532895049, 'Total loss': 0.3200260532895049}
2023-01-05 11:31:36,401 INFO:     Found new best model at epoch 52
2023-01-05 11:31:36,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:36,402 INFO:     Epoch: 53
2023-01-05 11:31:38,548 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4030018955469131, 'Total loss': 0.4030018955469131} | train loss {'Reaction outcome loss': 0.31089100154602656, 'Total loss': 0.31089100154602656}
2023-01-05 11:31:38,549 INFO:     Found new best model at epoch 53
2023-01-05 11:31:38,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:38,550 INFO:     Epoch: 54
2023-01-05 11:31:40,691 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3915221571922302, 'Total loss': 0.3915221571922302} | train loss {'Reaction outcome loss': 0.3090080584608942, 'Total loss': 0.3090080584608942}
2023-01-05 11:31:40,692 INFO:     Found new best model at epoch 54
2023-01-05 11:31:40,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:40,693 INFO:     Epoch: 55
2023-01-05 11:31:42,855 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39338983794053395, 'Total loss': 0.39338983794053395} | train loss {'Reaction outcome loss': 0.3099721325063687, 'Total loss': 0.3099721325063687}
2023-01-05 11:31:42,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:42,855 INFO:     Epoch: 56
2023-01-05 11:31:44,989 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42878963276743887, 'Total loss': 0.42878963276743887} | train loss {'Reaction outcome loss': 0.3037345091982296, 'Total loss': 0.3037345091982296}
2023-01-05 11:31:44,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:44,989 INFO:     Epoch: 57
2023-01-05 11:31:47,110 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39882742762565615, 'Total loss': 0.39882742762565615} | train loss {'Reaction outcome loss': 0.3101539616270558, 'Total loss': 0.3101539616270558}
2023-01-05 11:31:47,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:47,110 INFO:     Epoch: 58
2023-01-05 11:31:49,237 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4198605914910634, 'Total loss': 0.4198605914910634} | train loss {'Reaction outcome loss': 0.3286971624441229, 'Total loss': 0.3286971624441229}
2023-01-05 11:31:49,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:49,237 INFO:     Epoch: 59
2023-01-05 11:31:51,385 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38867791642745336, 'Total loss': 0.38867791642745336} | train loss {'Reaction outcome loss': 0.3020779193392482, 'Total loss': 0.3020779193392482}
2023-01-05 11:31:51,386 INFO:     Found new best model at epoch 59
2023-01-05 11:31:51,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:51,387 INFO:     Epoch: 60
2023-01-05 11:31:53,589 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42287030021349586, 'Total loss': 0.42287030021349586} | train loss {'Reaction outcome loss': 0.3063233459327856, 'Total loss': 0.3063233459327856}
2023-01-05 11:31:53,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:53,589 INFO:     Epoch: 61
2023-01-05 11:31:55,790 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4599956274032593, 'Total loss': 0.4599956274032593} | train loss {'Reaction outcome loss': 0.2969739585305038, 'Total loss': 0.2969739585305038}
2023-01-05 11:31:55,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:55,791 INFO:     Epoch: 62
2023-01-05 11:31:57,976 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4470246583223343, 'Total loss': 0.4470246583223343} | train loss {'Reaction outcome loss': 0.29683236238897603, 'Total loss': 0.29683236238897603}
2023-01-05 11:31:57,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:31:57,976 INFO:     Epoch: 63
2023-01-05 11:32:00,161 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4302032858133316, 'Total loss': 0.4302032858133316} | train loss {'Reaction outcome loss': 0.2951985569392412, 'Total loss': 0.2951985569392412}
2023-01-05 11:32:00,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:00,161 INFO:     Epoch: 64
2023-01-05 11:32:02,350 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43406996776660284, 'Total loss': 0.43406996776660284} | train loss {'Reaction outcome loss': 0.2913568857112441, 'Total loss': 0.2913568857112441}
2023-01-05 11:32:02,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:02,350 INFO:     Epoch: 65
2023-01-05 11:32:04,522 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4408259586741527, 'Total loss': 0.4408259586741527} | train loss {'Reaction outcome loss': 0.2925208704537658, 'Total loss': 0.2925208704537658}
2023-01-05 11:32:04,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:04,523 INFO:     Epoch: 66
2023-01-05 11:32:06,692 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44131485422452293, 'Total loss': 0.44131485422452293} | train loss {'Reaction outcome loss': 0.28484896761938877, 'Total loss': 0.28484896761938877}
2023-01-05 11:32:06,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:06,692 INFO:     Epoch: 67
2023-01-05 11:32:08,833 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4074571251869202, 'Total loss': 0.4074571251869202} | train loss {'Reaction outcome loss': 0.28569990979110405, 'Total loss': 0.28569990979110405}
2023-01-05 11:32:08,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:08,834 INFO:     Epoch: 68
2023-01-05 11:32:10,987 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4069837008913358, 'Total loss': 0.4069837008913358} | train loss {'Reaction outcome loss': 0.28709940827895375, 'Total loss': 0.28709940827895375}
2023-01-05 11:32:10,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:10,987 INFO:     Epoch: 69
2023-01-05 11:32:13,130 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4235229442516963, 'Total loss': 0.4235229442516963} | train loss {'Reaction outcome loss': 0.2883375405934572, 'Total loss': 0.2883375405934572}
2023-01-05 11:32:13,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:13,130 INFO:     Epoch: 70
2023-01-05 11:32:15,262 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3935458223025004, 'Total loss': 0.3935458223025004} | train loss {'Reaction outcome loss': 0.2744847023151005, 'Total loss': 0.2744847023151005}
2023-01-05 11:32:15,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:15,263 INFO:     Epoch: 71
2023-01-05 11:32:17,398 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4213922922809919, 'Total loss': 0.4213922922809919} | train loss {'Reaction outcome loss': 0.2826162179041168, 'Total loss': 0.2826162179041168}
2023-01-05 11:32:17,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:17,398 INFO:     Epoch: 72
2023-01-05 11:32:19,532 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4110450804233551, 'Total loss': 0.4110450804233551} | train loss {'Reaction outcome loss': 0.33296745501212316, 'Total loss': 0.33296745501212316}
2023-01-05 11:32:19,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:19,532 INFO:     Epoch: 73
2023-01-05 11:32:21,643 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4317618191242218, 'Total loss': 0.4317618191242218} | train loss {'Reaction outcome loss': 0.2932193347023449, 'Total loss': 0.2932193347023449}
2023-01-05 11:32:21,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:21,643 INFO:     Epoch: 74
2023-01-05 11:32:23,789 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44425450364748637, 'Total loss': 0.44425450364748637} | train loss {'Reaction outcome loss': 0.3571249528991441, 'Total loss': 0.3571249528991441}
2023-01-05 11:32:23,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:23,789 INFO:     Epoch: 75
2023-01-05 11:32:25,935 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4012041240930557, 'Total loss': 0.4012041240930557} | train loss {'Reaction outcome loss': 0.3011130742067336, 'Total loss': 0.3011130742067336}
2023-01-05 11:32:25,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:25,935 INFO:     Epoch: 76
2023-01-05 11:32:28,043 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3872689445813497, 'Total loss': 0.3872689445813497} | train loss {'Reaction outcome loss': 0.2765581859389583, 'Total loss': 0.2765581859389583}
2023-01-05 11:32:28,043 INFO:     Found new best model at epoch 76
2023-01-05 11:32:28,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:28,045 INFO:     Epoch: 77
2023-01-05 11:32:30,166 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42175037463506065, 'Total loss': 0.42175037463506065} | train loss {'Reaction outcome loss': 0.27141258022005577, 'Total loss': 0.27141258022005577}
2023-01-05 11:32:30,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:30,166 INFO:     Epoch: 78
2023-01-05 11:32:32,318 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3975877210497856, 'Total loss': 0.3975877210497856} | train loss {'Reaction outcome loss': 0.2719240516046251, 'Total loss': 0.2719240516046251}
2023-01-05 11:32:32,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:32,319 INFO:     Epoch: 79
2023-01-05 11:32:34,463 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4568553328514099, 'Total loss': 0.4568553328514099} | train loss {'Reaction outcome loss': 0.27671248140488414, 'Total loss': 0.27671248140488414}
2023-01-05 11:32:34,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:34,463 INFO:     Epoch: 80
2023-01-05 11:32:36,601 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4113693654537201, 'Total loss': 0.4113693654537201} | train loss {'Reaction outcome loss': 0.2844936884610671, 'Total loss': 0.2844936884610671}
2023-01-05 11:32:36,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:36,601 INFO:     Epoch: 81
2023-01-05 11:32:38,750 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3928168351451556, 'Total loss': 0.3928168351451556} | train loss {'Reaction outcome loss': 0.2966338769276289, 'Total loss': 0.2966338769276289}
2023-01-05 11:32:38,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:38,751 INFO:     Epoch: 82
2023-01-05 11:32:40,903 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4159783144791921, 'Total loss': 0.4159783144791921} | train loss {'Reaction outcome loss': 0.26363037242655357, 'Total loss': 0.26363037242655357}
2023-01-05 11:32:40,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:40,904 INFO:     Epoch: 83
2023-01-05 11:32:43,027 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4199681452165047, 'Total loss': 0.4199681452165047} | train loss {'Reaction outcome loss': 0.26860868890324363, 'Total loss': 0.26860868890324363}
2023-01-05 11:32:43,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:43,027 INFO:     Epoch: 84
2023-01-05 11:32:45,190 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43191735645135243, 'Total loss': 0.43191735645135243} | train loss {'Reaction outcome loss': 0.25922064720214333, 'Total loss': 0.25922064720214333}
2023-01-05 11:32:45,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:45,191 INFO:     Epoch: 85
2023-01-05 11:32:47,321 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41524496525526045, 'Total loss': 0.41524496525526045} | train loss {'Reaction outcome loss': 0.2584327331375486, 'Total loss': 0.2584327331375486}
2023-01-05 11:32:47,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:47,321 INFO:     Epoch: 86
2023-01-05 11:32:49,456 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41897329886754353, 'Total loss': 0.41897329886754353} | train loss {'Reaction outcome loss': 0.2578151700174625, 'Total loss': 0.2578151700174625}
2023-01-05 11:32:49,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:49,457 INFO:     Epoch: 87
2023-01-05 11:32:51,587 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4516177296638489, 'Total loss': 0.4516177296638489} | train loss {'Reaction outcome loss': 0.2647735565340659, 'Total loss': 0.2647735565340659}
2023-01-05 11:32:51,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:51,587 INFO:     Epoch: 88
2023-01-05 11:32:53,716 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4519471893707911, 'Total loss': 0.4519471893707911} | train loss {'Reaction outcome loss': 0.2566846961432231, 'Total loss': 0.2566846961432231}
2023-01-05 11:32:53,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:53,716 INFO:     Epoch: 89
2023-01-05 11:32:55,879 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41256844699382783, 'Total loss': 0.41256844699382783} | train loss {'Reaction outcome loss': 0.2548671295086894, 'Total loss': 0.2548671295086894}
2023-01-05 11:32:55,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:55,880 INFO:     Epoch: 90
2023-01-05 11:32:57,998 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40732052326202395, 'Total loss': 0.40732052326202395} | train loss {'Reaction outcome loss': 0.2611248692238418, 'Total loss': 0.2611248692238418}
2023-01-05 11:32:57,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:32:57,998 INFO:     Epoch: 91
2023-01-05 11:33:00,171 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.435741713643074, 'Total loss': 0.435741713643074} | train loss {'Reaction outcome loss': 0.25820115945606487, 'Total loss': 0.25820115945606487}
2023-01-05 11:33:00,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:00,171 INFO:     Epoch: 92
2023-01-05 11:33:02,352 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38843499663441133, 'Total loss': 0.38843499663441133} | train loss {'Reaction outcome loss': 0.2570512814820994, 'Total loss': 0.2570512814820994}
2023-01-05 11:33:02,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:02,352 INFO:     Epoch: 93
2023-01-05 11:33:04,544 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4133147622148196, 'Total loss': 0.4133147622148196} | train loss {'Reaction outcome loss': 0.25065908502332657, 'Total loss': 0.25065908502332657}
2023-01-05 11:33:04,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:04,544 INFO:     Epoch: 94
2023-01-05 11:33:06,692 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44256722231705986, 'Total loss': 0.44256722231705986} | train loss {'Reaction outcome loss': 0.24440889830103793, 'Total loss': 0.24440889830103793}
2023-01-05 11:33:06,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:06,693 INFO:     Epoch: 95
2023-01-05 11:33:08,802 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40822291870911914, 'Total loss': 0.40822291870911914} | train loss {'Reaction outcome loss': 0.25750489479843597, 'Total loss': 0.25750489479843597}
2023-01-05 11:33:08,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:08,803 INFO:     Epoch: 96
2023-01-05 11:33:10,928 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38823421895503996, 'Total loss': 0.38823421895503996} | train loss {'Reaction outcome loss': 0.25018331975139596, 'Total loss': 0.25018331975139596}
2023-01-05 11:33:10,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:10,928 INFO:     Epoch: 97
2023-01-05 11:33:13,048 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4400059998035431, 'Total loss': 0.4400059998035431} | train loss {'Reaction outcome loss': 0.24703067230354686, 'Total loss': 0.24703067230354686}
2023-01-05 11:33:13,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:13,048 INFO:     Epoch: 98
2023-01-05 11:33:15,157 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4229294697443644, 'Total loss': 0.4229294697443644} | train loss {'Reaction outcome loss': 0.25131029985926073, 'Total loss': 0.25131029985926073}
2023-01-05 11:33:15,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:15,159 INFO:     Epoch: 99
2023-01-05 11:33:17,291 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43191606799761456, 'Total loss': 0.43191606799761456} | train loss {'Reaction outcome loss': 0.29310260217973494, 'Total loss': 0.29310260217973494}
2023-01-05 11:33:17,291 INFO:     Best model found after epoch 77 of 100.
2023-01-05 11:33:17,291 INFO:   Done with stage: TRAINING
2023-01-05 11:33:17,291 INFO:   Starting stage: EVALUATION
2023-01-05 11:33:17,422 INFO:   Done with stage: EVALUATION
2023-01-05 11:33:17,423 INFO:   Leaving out SEQ value Fold_5
2023-01-05 11:33:17,435 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 11:33:17,435 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:33:18,080 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:33:18,080 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:33:18,148 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:33:18,148 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:33:18,148 INFO:     No hyperparam tuning for this model
2023-01-05 11:33:18,148 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:33:18,148 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:33:18,149 INFO:     None feature selector for col prot
2023-01-05 11:33:18,149 INFO:     None feature selector for col prot
2023-01-05 11:33:18,149 INFO:     None feature selector for col prot
2023-01-05 11:33:18,149 INFO:     None feature selector for col chem
2023-01-05 11:33:18,150 INFO:     None feature selector for col chem
2023-01-05 11:33:18,150 INFO:     None feature selector for col chem
2023-01-05 11:33:18,150 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:33:18,150 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:33:18,151 INFO:     Number of params in model 72901
2023-01-05 11:33:18,154 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:33:18,154 INFO:   Starting stage: TRAINING
2023-01-05 11:33:18,214 INFO:     Val loss before train {'Reaction outcome loss': 1.0402899344762166, 'Total loss': 1.0402899344762166}
2023-01-05 11:33:18,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:18,215 INFO:     Epoch: 0
2023-01-05 11:33:20,373 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8513069033622742, 'Total loss': 0.8513069033622742} | train loss {'Reaction outcome loss': 0.914696072474581, 'Total loss': 0.914696072474581}
2023-01-05 11:33:20,373 INFO:     Found new best model at epoch 0
2023-01-05 11:33:20,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:20,374 INFO:     Epoch: 1
2023-01-05 11:33:22,516 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6199692130088806, 'Total loss': 0.6199692130088806} | train loss {'Reaction outcome loss': 0.7075237818273202, 'Total loss': 0.7075237818273202}
2023-01-05 11:33:22,517 INFO:     Found new best model at epoch 1
2023-01-05 11:33:22,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:22,518 INFO:     Epoch: 2
2023-01-05 11:33:24,620 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5300018827120463, 'Total loss': 0.5300018827120463} | train loss {'Reaction outcome loss': 0.5678879422676814, 'Total loss': 0.5678879422676814}
2023-01-05 11:33:24,620 INFO:     Found new best model at epoch 2
2023-01-05 11:33:24,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:24,621 INFO:     Epoch: 3
2023-01-05 11:33:26,734 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5411726375420888, 'Total loss': 0.5411726375420888} | train loss {'Reaction outcome loss': 0.5213162452286191, 'Total loss': 0.5213162452286191}
2023-01-05 11:33:26,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:26,734 INFO:     Epoch: 4
2023-01-05 11:33:28,856 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5510217050711314, 'Total loss': 0.5510217050711314} | train loss {'Reaction outcome loss': 0.5260570294399193, 'Total loss': 0.5260570294399193}
2023-01-05 11:33:28,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:28,856 INFO:     Epoch: 5
2023-01-05 11:33:30,967 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5149863223234813, 'Total loss': 0.5149863223234813} | train loss {'Reaction outcome loss': 0.4886504891396001, 'Total loss': 0.4886504891396001}
2023-01-05 11:33:30,968 INFO:     Found new best model at epoch 5
2023-01-05 11:33:30,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:30,969 INFO:     Epoch: 6
2023-01-05 11:33:33,090 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5105303267637888, 'Total loss': 0.5105303267637888} | train loss {'Reaction outcome loss': 0.48384037561228743, 'Total loss': 0.48384037561228743}
2023-01-05 11:33:33,090 INFO:     Found new best model at epoch 6
2023-01-05 11:33:33,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:33,091 INFO:     Epoch: 7
2023-01-05 11:33:35,223 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5137683282295863, 'Total loss': 0.5137683282295863} | train loss {'Reaction outcome loss': 0.47904022405113, 'Total loss': 0.47904022405113}
2023-01-05 11:33:35,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:35,223 INFO:     Epoch: 8
2023-01-05 11:33:37,376 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5319389045238495, 'Total loss': 0.5319389045238495} | train loss {'Reaction outcome loss': 0.4748727668994579, 'Total loss': 0.4748727668994579}
2023-01-05 11:33:37,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:37,376 INFO:     Epoch: 9
2023-01-05 11:33:39,534 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5108724584182104, 'Total loss': 0.5108724584182104} | train loss {'Reaction outcome loss': 0.46877614747854357, 'Total loss': 0.46877614747854357}
2023-01-05 11:33:39,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:39,534 INFO:     Epoch: 10
2023-01-05 11:33:41,675 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5287856956322988, 'Total loss': 0.5287856956322988} | train loss {'Reaction outcome loss': 0.4612988682579337, 'Total loss': 0.4612988682579337}
2023-01-05 11:33:41,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:41,675 INFO:     Epoch: 11
2023-01-05 11:33:43,767 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5187990725040436, 'Total loss': 0.5187990725040436} | train loss {'Reaction outcome loss': 0.4605129026052094, 'Total loss': 0.4605129026052094}
2023-01-05 11:33:43,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:43,767 INFO:     Epoch: 12
2023-01-05 11:33:45,857 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.500183125336965, 'Total loss': 0.500183125336965} | train loss {'Reaction outcome loss': 0.4531032994424965, 'Total loss': 0.4531032994424965}
2023-01-05 11:33:45,858 INFO:     Found new best model at epoch 12
2023-01-05 11:33:45,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:45,859 INFO:     Epoch: 13
2023-01-05 11:33:47,979 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5021932065486908, 'Total loss': 0.5021932065486908} | train loss {'Reaction outcome loss': 0.44870219755566854, 'Total loss': 0.44870219755566854}
2023-01-05 11:33:47,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:47,979 INFO:     Epoch: 14
2023-01-05 11:33:50,090 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5153810600439708, 'Total loss': 0.5153810600439708} | train loss {'Reaction outcome loss': 0.4438129066307422, 'Total loss': 0.4438129066307422}
2023-01-05 11:33:50,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:50,090 INFO:     Epoch: 15
2023-01-05 11:33:52,214 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4840730587641398, 'Total loss': 0.4840730587641398} | train loss {'Reaction outcome loss': 0.4437838119009267, 'Total loss': 0.4437838119009267}
2023-01-05 11:33:52,215 INFO:     Found new best model at epoch 15
2023-01-05 11:33:52,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:52,216 INFO:     Epoch: 16
2023-01-05 11:33:54,337 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49939472079277036, 'Total loss': 0.49939472079277036} | train loss {'Reaction outcome loss': 0.4482423346557155, 'Total loss': 0.4482423346557155}
2023-01-05 11:33:54,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:54,338 INFO:     Epoch: 17
2023-01-05 11:33:56,433 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49661149779955543, 'Total loss': 0.49661149779955543} | train loss {'Reaction outcome loss': 0.4349554365608787, 'Total loss': 0.4349554365608787}
2023-01-05 11:33:56,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:56,434 INFO:     Epoch: 18
2023-01-05 11:33:58,556 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4711509148279826, 'Total loss': 0.4711509148279826} | train loss {'Reaction outcome loss': 0.43120515134195675, 'Total loss': 0.43120515134195675}
2023-01-05 11:33:58,556 INFO:     Found new best model at epoch 18
2023-01-05 11:33:58,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:33:58,557 INFO:     Epoch: 19
2023-01-05 11:34:00,593 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48596241474151614, 'Total loss': 0.48596241474151614} | train loss {'Reaction outcome loss': 0.4214829812130304, 'Total loss': 0.4214829812130304}
2023-01-05 11:34:00,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:00,593 INFO:     Epoch: 20
2023-01-05 11:34:02,611 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48427172501881915, 'Total loss': 0.48427172501881915} | train loss {'Reaction outcome loss': 0.4268706330752837, 'Total loss': 0.4268706330752837}
2023-01-05 11:34:02,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:02,611 INFO:     Epoch: 21
2023-01-05 11:34:04,723 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4780856281518936, 'Total loss': 0.4780856281518936} | train loss {'Reaction outcome loss': 0.4196040937035898, 'Total loss': 0.4196040937035898}
2023-01-05 11:34:04,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:04,724 INFO:     Epoch: 22
2023-01-05 11:34:06,875 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49146503607432046, 'Total loss': 0.49146503607432046} | train loss {'Reaction outcome loss': 0.42169202344519074, 'Total loss': 0.42169202344519074}
2023-01-05 11:34:06,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:06,875 INFO:     Epoch: 23
2023-01-05 11:34:09,003 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5126647502183914, 'Total loss': 0.5126647502183914} | train loss {'Reaction outcome loss': 0.41979527319884824, 'Total loss': 0.41979527319884824}
2023-01-05 11:34:09,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:09,003 INFO:     Epoch: 24
2023-01-05 11:34:11,122 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4947415808836619, 'Total loss': 0.4947415808836619} | train loss {'Reaction outcome loss': 0.41235599492379615, 'Total loss': 0.41235599492379615}
2023-01-05 11:34:11,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:11,122 INFO:     Epoch: 25
2023-01-05 11:34:13,231 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4621970613797506, 'Total loss': 0.4621970613797506} | train loss {'Reaction outcome loss': 0.4125909101271975, 'Total loss': 0.4125909101271975}
2023-01-05 11:34:13,231 INFO:     Found new best model at epoch 25
2023-01-05 11:34:13,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:13,233 INFO:     Epoch: 26
2023-01-05 11:34:15,319 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5012974202632904, 'Total loss': 0.5012974202632904} | train loss {'Reaction outcome loss': 0.40482658163333934, 'Total loss': 0.40482658163333934}
2023-01-05 11:34:15,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:15,321 INFO:     Epoch: 27
2023-01-05 11:34:17,420 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5034544507662455, 'Total loss': 0.5034544507662455} | train loss {'Reaction outcome loss': 0.39777662991073687, 'Total loss': 0.39777662991073687}
2023-01-05 11:34:17,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:17,420 INFO:     Epoch: 28
2023-01-05 11:34:19,521 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4751736432313919, 'Total loss': 0.4751736432313919} | train loss {'Reaction outcome loss': 0.4175418840478296, 'Total loss': 0.4175418840478296}
2023-01-05 11:34:19,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:19,522 INFO:     Epoch: 29
2023-01-05 11:34:21,626 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46837754050890607, 'Total loss': 0.46837754050890607} | train loss {'Reaction outcome loss': 0.41696829827961285, 'Total loss': 0.41696829827961285}
2023-01-05 11:34:21,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:21,627 INFO:     Epoch: 30
2023-01-05 11:34:23,737 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48178210655848186, 'Total loss': 0.48178210655848186} | train loss {'Reaction outcome loss': 0.3957228363505092, 'Total loss': 0.3957228363505092}
2023-01-05 11:34:23,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:23,738 INFO:     Epoch: 31
2023-01-05 11:34:25,864 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48628714283307395, 'Total loss': 0.48628714283307395} | train loss {'Reaction outcome loss': 0.40724015446460765, 'Total loss': 0.40724015446460765}
2023-01-05 11:34:25,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:25,865 INFO:     Epoch: 32
2023-01-05 11:34:27,977 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48107619285583497, 'Total loss': 0.48107619285583497} | train loss {'Reaction outcome loss': 0.41504105547415826, 'Total loss': 0.41504105547415826}
2023-01-05 11:34:27,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:27,977 INFO:     Epoch: 33
2023-01-05 11:34:30,109 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4652272939682007, 'Total loss': 0.4652272939682007} | train loss {'Reaction outcome loss': 0.3852748362730473, 'Total loss': 0.3852748362730473}
2023-01-05 11:34:30,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:30,110 INFO:     Epoch: 34
2023-01-05 11:34:32,233 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5051169149577618, 'Total loss': 0.5051169149577618} | train loss {'Reaction outcome loss': 0.38386010902299394, 'Total loss': 0.38386010902299394}
2023-01-05 11:34:32,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:32,233 INFO:     Epoch: 35
2023-01-05 11:34:34,359 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5008994330962498, 'Total loss': 0.5008994330962498} | train loss {'Reaction outcome loss': 0.38522918149491475, 'Total loss': 0.38522918149491475}
2023-01-05 11:34:34,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:34,360 INFO:     Epoch: 36
2023-01-05 11:34:36,514 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49806819558143617, 'Total loss': 0.49806819558143617} | train loss {'Reaction outcome loss': 0.37991517765550414, 'Total loss': 0.37991517765550414}
2023-01-05 11:34:36,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:36,515 INFO:     Epoch: 37
2023-01-05 11:34:38,675 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49853002627690635, 'Total loss': 0.49853002627690635} | train loss {'Reaction outcome loss': 0.39197421932350035, 'Total loss': 0.39197421932350035}
2023-01-05 11:34:38,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:38,675 INFO:     Epoch: 38
2023-01-05 11:34:40,802 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5051466862360636, 'Total loss': 0.5051466862360636} | train loss {'Reaction outcome loss': 0.3874982305316497, 'Total loss': 0.3874982305316497}
2023-01-05 11:34:40,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:40,803 INFO:     Epoch: 39
2023-01-05 11:34:42,945 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4549829562505086, 'Total loss': 0.4549829562505086} | train loss {'Reaction outcome loss': 0.366511440815647, 'Total loss': 0.366511440815647}
2023-01-05 11:34:42,945 INFO:     Found new best model at epoch 39
2023-01-05 11:34:42,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:42,947 INFO:     Epoch: 40
2023-01-05 11:34:45,056 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4865991652011871, 'Total loss': 0.4865991652011871} | train loss {'Reaction outcome loss': 0.36120790895665117, 'Total loss': 0.36120790895665117}
2023-01-05 11:34:45,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:45,056 INFO:     Epoch: 41
2023-01-05 11:34:47,247 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49357522825400035, 'Total loss': 0.49357522825400035} | train loss {'Reaction outcome loss': 0.35832641633082263, 'Total loss': 0.35832641633082263}
2023-01-05 11:34:47,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:47,247 INFO:     Epoch: 42
2023-01-05 11:34:49,417 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46981426775455476, 'Total loss': 0.46981426775455476} | train loss {'Reaction outcome loss': 0.36338540547243925, 'Total loss': 0.36338540547243925}
2023-01-05 11:34:49,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:49,417 INFO:     Epoch: 43
2023-01-05 11:34:51,576 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46243434846401216, 'Total loss': 0.46243434846401216} | train loss {'Reaction outcome loss': 0.3638631599428861, 'Total loss': 0.3638631599428861}
2023-01-05 11:34:51,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:51,577 INFO:     Epoch: 44
2023-01-05 11:34:53,732 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49857211112976074, 'Total loss': 0.49857211112976074} | train loss {'Reaction outcome loss': 0.3547423075668622, 'Total loss': 0.3547423075668622}
2023-01-05 11:34:53,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:53,732 INFO:     Epoch: 45
2023-01-05 11:34:55,872 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4736662964026133, 'Total loss': 0.4736662964026133} | train loss {'Reaction outcome loss': 0.36071992429661687, 'Total loss': 0.36071992429661687}
2023-01-05 11:34:55,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:55,872 INFO:     Epoch: 46
2023-01-05 11:34:58,023 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4716654380162557, 'Total loss': 0.4716654380162557} | train loss {'Reaction outcome loss': 0.3455564821616871, 'Total loss': 0.3455564821616871}
2023-01-05 11:34:58,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:34:58,024 INFO:     Epoch: 47
2023-01-05 11:35:00,192 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4850103457768758, 'Total loss': 0.4850103457768758} | train loss {'Reaction outcome loss': 0.342630246060266, 'Total loss': 0.342630246060266}
2023-01-05 11:35:00,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:00,192 INFO:     Epoch: 48
2023-01-05 11:35:02,341 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4795966019233068, 'Total loss': 0.4795966019233068} | train loss {'Reaction outcome loss': 0.35852656314618536, 'Total loss': 0.35852656314618536}
2023-01-05 11:35:02,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:02,342 INFO:     Epoch: 49
2023-01-05 11:35:04,502 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43688290417194364, 'Total loss': 0.43688290417194364} | train loss {'Reaction outcome loss': 0.3399354183792362, 'Total loss': 0.3399354183792362}
2023-01-05 11:35:04,502 INFO:     Found new best model at epoch 49
2023-01-05 11:35:04,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:04,504 INFO:     Epoch: 50
2023-01-05 11:35:06,669 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44865263303120934, 'Total loss': 0.44865263303120934} | train loss {'Reaction outcome loss': 0.33939537662587577, 'Total loss': 0.33939537662587577}
2023-01-05 11:35:06,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:06,669 INFO:     Epoch: 51
2023-01-05 11:35:08,841 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4857802867889404, 'Total loss': 0.4857802867889404} | train loss {'Reaction outcome loss': 0.3393584095123831, 'Total loss': 0.3393584095123831}
2023-01-05 11:35:08,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:08,841 INFO:     Epoch: 52
2023-01-05 11:35:11,006 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5179241557916006, 'Total loss': 0.5179241557916006} | train loss {'Reaction outcome loss': 0.33091356123433163, 'Total loss': 0.33091356123433163}
2023-01-05 11:35:11,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:11,007 INFO:     Epoch: 53
2023-01-05 11:35:13,172 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4598287671804428, 'Total loss': 0.4598287671804428} | train loss {'Reaction outcome loss': 0.3290318694856504, 'Total loss': 0.3290318694856504}
2023-01-05 11:35:13,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:13,172 INFO:     Epoch: 54
2023-01-05 11:35:15,316 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4692445745070775, 'Total loss': 0.4692445745070775} | train loss {'Reaction outcome loss': 0.33163905805111793, 'Total loss': 0.33163905805111793}
2023-01-05 11:35:15,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:15,316 INFO:     Epoch: 55
2023-01-05 11:35:17,484 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46297177573045095, 'Total loss': 0.46297177573045095} | train loss {'Reaction outcome loss': 0.3225462984536653, 'Total loss': 0.3225462984536653}
2023-01-05 11:35:17,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:17,484 INFO:     Epoch: 56
2023-01-05 11:35:19,648 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47526768445968626, 'Total loss': 0.47526768445968626} | train loss {'Reaction outcome loss': 0.3213309044801555, 'Total loss': 0.3213309044801555}
2023-01-05 11:35:19,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:19,649 INFO:     Epoch: 57
2023-01-05 11:35:21,845 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48776052991549174, 'Total loss': 0.48776052991549174} | train loss {'Reaction outcome loss': 0.32841374123297323, 'Total loss': 0.32841374123297323}
2023-01-05 11:35:21,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:21,845 INFO:     Epoch: 58
2023-01-05 11:35:24,053 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.480594398578008, 'Total loss': 0.480594398578008} | train loss {'Reaction outcome loss': 0.3281022802373205, 'Total loss': 0.3281022802373205}
2023-01-05 11:35:24,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:24,053 INFO:     Epoch: 59
2023-01-05 11:35:26,280 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.469219841559728, 'Total loss': 0.469219841559728} | train loss {'Reaction outcome loss': 0.3497323281180402, 'Total loss': 0.3497323281180402}
2023-01-05 11:35:26,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:26,280 INFO:     Epoch: 60
2023-01-05 11:35:28,497 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4638636271158854, 'Total loss': 0.4638636271158854} | train loss {'Reaction outcome loss': 0.3118019594498353, 'Total loss': 0.3118019594498353}
2023-01-05 11:35:28,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:28,498 INFO:     Epoch: 61
2023-01-05 11:35:30,674 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49282917579015095, 'Total loss': 0.49282917579015095} | train loss {'Reaction outcome loss': 0.3182141891743083, 'Total loss': 0.3182141891743083}
2023-01-05 11:35:30,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:30,674 INFO:     Epoch: 62
2023-01-05 11:35:32,810 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47134204109509786, 'Total loss': 0.47134204109509786} | train loss {'Reaction outcome loss': 0.30798755724664667, 'Total loss': 0.30798755724664667}
2023-01-05 11:35:32,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:32,810 INFO:     Epoch: 63
2023-01-05 11:35:34,935 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47389546036720276, 'Total loss': 0.47389546036720276} | train loss {'Reaction outcome loss': 0.30317389608219103, 'Total loss': 0.30317389608219103}
2023-01-05 11:35:34,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:34,936 INFO:     Epoch: 64
2023-01-05 11:35:37,041 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4358252892891566, 'Total loss': 0.4358252892891566} | train loss {'Reaction outcome loss': 0.30005511648251093, 'Total loss': 0.30005511648251093}
2023-01-05 11:35:37,041 INFO:     Found new best model at epoch 64
2023-01-05 11:35:37,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:37,042 INFO:     Epoch: 65
2023-01-05 11:35:39,175 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47188467780749005, 'Total loss': 0.47188467780749005} | train loss {'Reaction outcome loss': 0.30110856381825346, 'Total loss': 0.30110856381825346}
2023-01-05 11:35:39,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:39,175 INFO:     Epoch: 66
2023-01-05 11:35:41,339 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47579285701115925, 'Total loss': 0.47579285701115925} | train loss {'Reaction outcome loss': 0.3068344586444373, 'Total loss': 0.3068344586444373}
2023-01-05 11:35:41,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:41,339 INFO:     Epoch: 67
2023-01-05 11:35:43,449 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4462885747353236, 'Total loss': 0.4462885747353236} | train loss {'Reaction outcome loss': 0.3004365584740721, 'Total loss': 0.3004365584740721}
2023-01-05 11:35:43,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:43,449 INFO:     Epoch: 68
2023-01-05 11:35:45,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5026483615239461, 'Total loss': 0.5026483615239461} | train loss {'Reaction outcome loss': 0.2957003026954687, 'Total loss': 0.2957003026954687}
2023-01-05 11:35:45,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:45,577 INFO:     Epoch: 69
2023-01-05 11:35:47,704 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45403952797253927, 'Total loss': 0.45403952797253927} | train loss {'Reaction outcome loss': 0.302381936874514, 'Total loss': 0.302381936874514}
2023-01-05 11:35:47,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:47,704 INFO:     Epoch: 70
2023-01-05 11:35:49,835 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48089269498984016, 'Total loss': 0.48089269498984016} | train loss {'Reaction outcome loss': 0.2952946665447097, 'Total loss': 0.2952946665447097}
2023-01-05 11:35:49,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:49,835 INFO:     Epoch: 71
2023-01-05 11:35:51,953 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4884962459405263, 'Total loss': 0.4884962459405263} | train loss {'Reaction outcome loss': 0.31509440030524694, 'Total loss': 0.31509440030524694}
2023-01-05 11:35:51,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:51,954 INFO:     Epoch: 72
2023-01-05 11:35:54,079 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4927881548802058, 'Total loss': 0.4927881548802058} | train loss {'Reaction outcome loss': 0.30353043833747506, 'Total loss': 0.30353043833747506}
2023-01-05 11:35:54,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:54,079 INFO:     Epoch: 73
2023-01-05 11:35:56,206 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4861175626516342, 'Total loss': 0.4861175626516342} | train loss {'Reaction outcome loss': 0.28758677953663975, 'Total loss': 0.28758677953663975}
2023-01-05 11:35:56,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:56,206 INFO:     Epoch: 74
2023-01-05 11:35:58,310 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4980043758948644, 'Total loss': 0.4980043758948644} | train loss {'Reaction outcome loss': 0.29162191262846626, 'Total loss': 0.29162191262846626}
2023-01-05 11:35:58,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:35:58,311 INFO:     Epoch: 75
2023-01-05 11:36:00,464 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47215546369552613, 'Total loss': 0.47215546369552613} | train loss {'Reaction outcome loss': 0.28425241114598687, 'Total loss': 0.28425241114598687}
2023-01-05 11:36:00,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:00,464 INFO:     Epoch: 76
2023-01-05 11:36:02,598 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5017658154169718, 'Total loss': 0.5017658154169718} | train loss {'Reaction outcome loss': 0.28767015794985284, 'Total loss': 0.28767015794985284}
2023-01-05 11:36:02,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:02,598 INFO:     Epoch: 77
2023-01-05 11:36:04,738 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4498267889022827, 'Total loss': 0.4498267889022827} | train loss {'Reaction outcome loss': 0.28260019528787106, 'Total loss': 0.28260019528787106}
2023-01-05 11:36:04,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:04,738 INFO:     Epoch: 78
2023-01-05 11:36:06,869 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4648234635591507, 'Total loss': 0.4648234635591507} | train loss {'Reaction outcome loss': 0.27827043693084136, 'Total loss': 0.27827043693084136}
2023-01-05 11:36:06,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:06,869 INFO:     Epoch: 79
2023-01-05 11:36:08,985 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4405313774943352, 'Total loss': 0.4405313774943352} | train loss {'Reaction outcome loss': 0.288265772568369, 'Total loss': 0.288265772568369}
2023-01-05 11:36:08,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:08,986 INFO:     Epoch: 80
2023-01-05 11:36:11,081 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45762990017731986, 'Total loss': 0.45762990017731986} | train loss {'Reaction outcome loss': 0.2727567950636697, 'Total loss': 0.2727567950636697}
2023-01-05 11:36:11,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:11,082 INFO:     Epoch: 81
2023-01-05 11:36:13,234 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4886014054218928, 'Total loss': 0.4886014054218928} | train loss {'Reaction outcome loss': 0.27321114822921844, 'Total loss': 0.27321114822921844}
2023-01-05 11:36:13,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:13,234 INFO:     Epoch: 82
2023-01-05 11:36:15,346 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4600689113140106, 'Total loss': 0.4600689113140106} | train loss {'Reaction outcome loss': 0.27580955102946947, 'Total loss': 0.27580955102946947}
2023-01-05 11:36:15,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:15,346 INFO:     Epoch: 83
2023-01-05 11:36:17,458 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4925064335266749, 'Total loss': 0.4925064335266749} | train loss {'Reaction outcome loss': 0.2661426390345762, 'Total loss': 0.2661426390345762}
2023-01-05 11:36:17,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:17,459 INFO:     Epoch: 84
2023-01-05 11:36:19,565 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47011289099852244, 'Total loss': 0.47011289099852244} | train loss {'Reaction outcome loss': 0.270967650858148, 'Total loss': 0.270967650858148}
2023-01-05 11:36:19,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:19,565 INFO:     Epoch: 85
2023-01-05 11:36:21,686 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4724387347698212, 'Total loss': 0.4724387347698212} | train loss {'Reaction outcome loss': 0.2738472299879768, 'Total loss': 0.2738472299879768}
2023-01-05 11:36:21,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:21,686 INFO:     Epoch: 86
2023-01-05 11:36:23,792 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47875917454560596, 'Total loss': 0.47875917454560596} | train loss {'Reaction outcome loss': 0.2709447815921495, 'Total loss': 0.2709447815921495}
2023-01-05 11:36:23,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:23,792 INFO:     Epoch: 87
2023-01-05 11:36:25,899 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45395571291446685, 'Total loss': 0.45395571291446685} | train loss {'Reaction outcome loss': 0.2605184972416137, 'Total loss': 0.2605184972416137}
2023-01-05 11:36:25,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:25,899 INFO:     Epoch: 88
2023-01-05 11:36:28,058 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4585001508394877, 'Total loss': 0.4585001508394877} | train loss {'Reaction outcome loss': 0.2685792232877102, 'Total loss': 0.2685792232877102}
2023-01-05 11:36:28,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:28,058 INFO:     Epoch: 89
2023-01-05 11:36:30,181 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4751110911369324, 'Total loss': 0.4751110911369324} | train loss {'Reaction outcome loss': 0.26154008873508894, 'Total loss': 0.26154008873508894}
2023-01-05 11:36:30,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:30,181 INFO:     Epoch: 90
2023-01-05 11:36:32,345 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48895238240559896, 'Total loss': 0.48895238240559896} | train loss {'Reaction outcome loss': 0.26092779301309393, 'Total loss': 0.26092779301309393}
2023-01-05 11:36:32,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:32,346 INFO:     Epoch: 91
2023-01-05 11:36:34,494 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4922549664974213, 'Total loss': 0.4922549664974213} | train loss {'Reaction outcome loss': 0.2642733383252272, 'Total loss': 0.2642733383252272}
2023-01-05 11:36:34,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:34,495 INFO:     Epoch: 92
2023-01-05 11:36:36,638 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48044830362002056, 'Total loss': 0.48044830362002056} | train loss {'Reaction outcome loss': 0.26323981387047196, 'Total loss': 0.26323981387047196}
2023-01-05 11:36:36,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:36,638 INFO:     Epoch: 93
2023-01-05 11:36:38,759 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47128154039382936, 'Total loss': 0.47128154039382936} | train loss {'Reaction outcome loss': 0.2544927743480345, 'Total loss': 0.2544927743480345}
2023-01-05 11:36:38,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:38,759 INFO:     Epoch: 94
2023-01-05 11:36:40,896 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5012095073858897, 'Total loss': 0.5012095073858897} | train loss {'Reaction outcome loss': 0.26294432829598774, 'Total loss': 0.26294432829598774}
2023-01-05 11:36:40,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:40,897 INFO:     Epoch: 95
2023-01-05 11:36:43,056 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5102396667003631, 'Total loss': 0.5102396667003631} | train loss {'Reaction outcome loss': 0.260221742346429, 'Total loss': 0.260221742346429}
2023-01-05 11:36:43,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:43,056 INFO:     Epoch: 96
2023-01-05 11:36:45,194 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4623935088515282, 'Total loss': 0.4623935088515282} | train loss {'Reaction outcome loss': 0.25785327224575405, 'Total loss': 0.25785327224575405}
2023-01-05 11:36:45,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:45,194 INFO:     Epoch: 97
2023-01-05 11:36:47,341 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45501916805903114, 'Total loss': 0.45501916805903114} | train loss {'Reaction outcome loss': 0.24939604264437693, 'Total loss': 0.24939604264437693}
2023-01-05 11:36:47,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:47,341 INFO:     Epoch: 98
2023-01-05 11:36:49,475 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4735509549578031, 'Total loss': 0.4735509549578031} | train loss {'Reaction outcome loss': 0.25005078427932237, 'Total loss': 0.25005078427932237}
2023-01-05 11:36:49,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:49,475 INFO:     Epoch: 99
2023-01-05 11:36:51,575 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45963087330261865, 'Total loss': 0.45963087330261865} | train loss {'Reaction outcome loss': 0.25263748737726954, 'Total loss': 0.25263748737726954}
2023-01-05 11:36:51,575 INFO:     Best model found after epoch 65 of 100.
2023-01-05 11:36:51,575 INFO:   Done with stage: TRAINING
2023-01-05 11:36:51,575 INFO:   Starting stage: EVALUATION
2023-01-05 11:36:51,709 INFO:   Done with stage: EVALUATION
2023-01-05 11:36:51,709 INFO:   Leaving out SEQ value Fold_6
2023-01-05 11:36:51,721 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 11:36:51,721 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:36:52,363 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:36:52,364 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:36:52,433 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:36:52,433 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:36:52,433 INFO:     No hyperparam tuning for this model
2023-01-05 11:36:52,433 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:36:52,433 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:36:52,434 INFO:     None feature selector for col prot
2023-01-05 11:36:52,434 INFO:     None feature selector for col prot
2023-01-05 11:36:52,434 INFO:     None feature selector for col prot
2023-01-05 11:36:52,435 INFO:     None feature selector for col chem
2023-01-05 11:36:52,435 INFO:     None feature selector for col chem
2023-01-05 11:36:52,435 INFO:     None feature selector for col chem
2023-01-05 11:36:52,435 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:36:52,435 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:36:52,436 INFO:     Number of params in model 72901
2023-01-05 11:36:52,439 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:36:52,440 INFO:   Starting stage: TRAINING
2023-01-05 11:36:52,498 INFO:     Val loss before train {'Reaction outcome loss': 0.9564998428026835, 'Total loss': 0.9564998428026835}
2023-01-05 11:36:52,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:52,499 INFO:     Epoch: 0
2023-01-05 11:36:54,625 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8249759197235107, 'Total loss': 0.8249759197235107} | train loss {'Reaction outcome loss': 0.9170859411950576, 'Total loss': 0.9170859411950576}
2023-01-05 11:36:54,626 INFO:     Found new best model at epoch 0
2023-01-05 11:36:54,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:54,627 INFO:     Epoch: 1
2023-01-05 11:36:56,771 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6362583100795746, 'Total loss': 0.6362583100795746} | train loss {'Reaction outcome loss': 0.7295780217927286, 'Total loss': 0.7295780217927286}
2023-01-05 11:36:56,771 INFO:     Found new best model at epoch 1
2023-01-05 11:36:56,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:56,772 INFO:     Epoch: 2
2023-01-05 11:36:58,884 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5473505864540736, 'Total loss': 0.5473505864540736} | train loss {'Reaction outcome loss': 0.5755307338190423, 'Total loss': 0.5755307338190423}
2023-01-05 11:36:58,884 INFO:     Found new best model at epoch 2
2023-01-05 11:36:58,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:36:58,885 INFO:     Epoch: 3
2023-01-05 11:37:01,018 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5692931612332662, 'Total loss': 0.5692931612332662} | train loss {'Reaction outcome loss': 0.5334073211527043, 'Total loss': 0.5334073211527043}
2023-01-05 11:37:01,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:01,018 INFO:     Epoch: 4
2023-01-05 11:37:03,140 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5018037855625153, 'Total loss': 0.5018037855625153} | train loss {'Reaction outcome loss': 0.5096233527475316, 'Total loss': 0.5096233527475316}
2023-01-05 11:37:03,141 INFO:     Found new best model at epoch 4
2023-01-05 11:37:03,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:03,142 INFO:     Epoch: 5
2023-01-05 11:37:05,273 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48012575109799704, 'Total loss': 0.48012575109799704} | train loss {'Reaction outcome loss': 0.4967560803900987, 'Total loss': 0.4967560803900987}
2023-01-05 11:37:05,273 INFO:     Found new best model at epoch 5
2023-01-05 11:37:05,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:05,274 INFO:     Epoch: 6
2023-01-05 11:37:07,401 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4604053477446238, 'Total loss': 0.4604053477446238} | train loss {'Reaction outcome loss': 0.49173470320254026, 'Total loss': 0.49173470320254026}
2023-01-05 11:37:07,401 INFO:     Found new best model at epoch 6
2023-01-05 11:37:07,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:07,403 INFO:     Epoch: 7
2023-01-05 11:37:09,529 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4896221995353699, 'Total loss': 0.4896221995353699} | train loss {'Reaction outcome loss': 0.4848314351755251, 'Total loss': 0.4848314351755251}
2023-01-05 11:37:09,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:09,530 INFO:     Epoch: 8
2023-01-05 11:37:11,669 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48613195220629374, 'Total loss': 0.48613195220629374} | train loss {'Reaction outcome loss': 0.47160137651844575, 'Total loss': 0.47160137651844575}
2023-01-05 11:37:11,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:11,669 INFO:     Epoch: 9
2023-01-05 11:37:13,822 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47789034446080525, 'Total loss': 0.47789034446080525} | train loss {'Reaction outcome loss': 0.4665673687139573, 'Total loss': 0.4665673687139573}
2023-01-05 11:37:13,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:13,823 INFO:     Epoch: 10
2023-01-05 11:37:15,942 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47244955201943717, 'Total loss': 0.47244955201943717} | train loss {'Reaction outcome loss': 0.4578844482206911, 'Total loss': 0.4578844482206911}
2023-01-05 11:37:15,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:15,943 INFO:     Epoch: 11
2023-01-05 11:37:18,055 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4678474406401316, 'Total loss': 0.4678474406401316} | train loss {'Reaction outcome loss': 0.4543425364668619, 'Total loss': 0.4543425364668619}
2023-01-05 11:37:18,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:18,055 INFO:     Epoch: 12
2023-01-05 11:37:20,176 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4631299595038096, 'Total loss': 0.4631299595038096} | train loss {'Reaction outcome loss': 0.45223483644990714, 'Total loss': 0.45223483644990714}
2023-01-05 11:37:20,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:20,176 INFO:     Epoch: 13
2023-01-05 11:37:22,322 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4492969294389089, 'Total loss': 0.4492969294389089} | train loss {'Reaction outcome loss': 0.4459951296717682, 'Total loss': 0.4459951296717682}
2023-01-05 11:37:22,322 INFO:     Found new best model at epoch 13
2023-01-05 11:37:22,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:22,323 INFO:     Epoch: 14
2023-01-05 11:37:24,500 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4605015297730764, 'Total loss': 0.4605015297730764} | train loss {'Reaction outcome loss': 0.4445406681578943, 'Total loss': 0.4445406681578943}
2023-01-05 11:37:24,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:24,500 INFO:     Epoch: 15
2023-01-05 11:37:26,670 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45456490516662595, 'Total loss': 0.45456490516662595} | train loss {'Reaction outcome loss': 0.435240796111551, 'Total loss': 0.435240796111551}
2023-01-05 11:37:26,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:26,671 INFO:     Epoch: 16
2023-01-05 11:37:28,819 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45621571242809295, 'Total loss': 0.45621571242809295} | train loss {'Reaction outcome loss': 0.4297758880666447, 'Total loss': 0.4297758880666447}
2023-01-05 11:37:28,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:28,820 INFO:     Epoch: 17
2023-01-05 11:37:31,037 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4586185812950134, 'Total loss': 0.4586185812950134} | train loss {'Reaction outcome loss': 0.42810394410514657, 'Total loss': 0.42810394410514657}
2023-01-05 11:37:31,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:31,037 INFO:     Epoch: 18
2023-01-05 11:37:33,237 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4297136555115382, 'Total loss': 0.4297136555115382} | train loss {'Reaction outcome loss': 0.4280592976709566, 'Total loss': 0.4280592976709566}
2023-01-05 11:37:33,237 INFO:     Found new best model at epoch 18
2023-01-05 11:37:33,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:33,238 INFO:     Epoch: 19
2023-01-05 11:37:35,413 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47542294263839724, 'Total loss': 0.47542294263839724} | train loss {'Reaction outcome loss': 0.41304730411471013, 'Total loss': 0.41304730411471013}
2023-01-05 11:37:35,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:35,413 INFO:     Epoch: 20
2023-01-05 11:37:37,609 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43075063029925026, 'Total loss': 0.43075063029925026} | train loss {'Reaction outcome loss': 0.41369027523357516, 'Total loss': 0.41369027523357516}
2023-01-05 11:37:37,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:37,609 INFO:     Epoch: 21
2023-01-05 11:37:39,759 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4414811372756958, 'Total loss': 0.4414811372756958} | train loss {'Reaction outcome loss': 0.40383738004989145, 'Total loss': 0.40383738004989145}
2023-01-05 11:37:39,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:39,759 INFO:     Epoch: 22
2023-01-05 11:37:41,900 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4485760033130646, 'Total loss': 0.4485760033130646} | train loss {'Reaction outcome loss': 0.4051977558202692, 'Total loss': 0.4051977558202692}
2023-01-05 11:37:41,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:41,900 INFO:     Epoch: 23
2023-01-05 11:37:44,104 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4186649126311143, 'Total loss': 0.4186649126311143} | train loss {'Reaction outcome loss': 0.40020517340528405, 'Total loss': 0.40020517340528405}
2023-01-05 11:37:44,104 INFO:     Found new best model at epoch 23
2023-01-05 11:37:44,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:44,106 INFO:     Epoch: 24
2023-01-05 11:37:46,291 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4421071410179138, 'Total loss': 0.4421071410179138} | train loss {'Reaction outcome loss': 0.3912225288981135, 'Total loss': 0.3912225288981135}
2023-01-05 11:37:46,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:46,292 INFO:     Epoch: 25
2023-01-05 11:37:48,468 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44470040301481883, 'Total loss': 0.44470040301481883} | train loss {'Reaction outcome loss': 0.38655495971764037, 'Total loss': 0.38655495971764037}
2023-01-05 11:37:48,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:48,468 INFO:     Epoch: 26
2023-01-05 11:37:50,648 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4392141580581665, 'Total loss': 0.4392141580581665} | train loss {'Reaction outcome loss': 0.38823121525212745, 'Total loss': 0.38823121525212745}
2023-01-05 11:37:50,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:50,648 INFO:     Epoch: 27
2023-01-05 11:37:52,821 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43988341093063354, 'Total loss': 0.43988341093063354} | train loss {'Reaction outcome loss': 0.38723091530993525, 'Total loss': 0.38723091530993525}
2023-01-05 11:37:52,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:52,822 INFO:     Epoch: 28
2023-01-05 11:37:55,009 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4229508419831594, 'Total loss': 0.4229508419831594} | train loss {'Reaction outcome loss': 0.3811899178294929, 'Total loss': 0.3811899178294929}
2023-01-05 11:37:55,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:55,010 INFO:     Epoch: 29
2023-01-05 11:37:57,153 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4339279303948084, 'Total loss': 0.4339279303948084} | train loss {'Reaction outcome loss': 0.3789400408037733, 'Total loss': 0.3789400408037733}
2023-01-05 11:37:57,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:57,154 INFO:     Epoch: 30
2023-01-05 11:37:59,282 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40476977626482646, 'Total loss': 0.40476977626482646} | train loss {'Reaction outcome loss': 0.38167485347293345, 'Total loss': 0.38167485347293345}
2023-01-05 11:37:59,282 INFO:     Found new best model at epoch 30
2023-01-05 11:37:59,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:37:59,284 INFO:     Epoch: 31
2023-01-05 11:38:01,247 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47918939689795176, 'Total loss': 0.47918939689795176} | train loss {'Reaction outcome loss': 0.36917431239670795, 'Total loss': 0.36917431239670795}
2023-01-05 11:38:01,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:01,247 INFO:     Epoch: 32
2023-01-05 11:38:03,398 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43144739071528115, 'Total loss': 0.43144739071528115} | train loss {'Reaction outcome loss': 0.3690073016748532, 'Total loss': 0.3690073016748532}
2023-01-05 11:38:03,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:03,398 INFO:     Epoch: 33
2023-01-05 11:38:05,554 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44101638793945314, 'Total loss': 0.44101638793945314} | train loss {'Reaction outcome loss': 0.36371044957142873, 'Total loss': 0.36371044957142873}
2023-01-05 11:38:05,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:05,555 INFO:     Epoch: 34
2023-01-05 11:38:07,682 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4341062605381012, 'Total loss': 0.4341062605381012} | train loss {'Reaction outcome loss': 0.36715214750611824, 'Total loss': 0.36715214750611824}
2023-01-05 11:38:07,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:07,682 INFO:     Epoch: 35
2023-01-05 11:38:09,821 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40459558765093484, 'Total loss': 0.40459558765093484} | train loss {'Reaction outcome loss': 0.36166523518007154, 'Total loss': 0.36166523518007154}
2023-01-05 11:38:09,821 INFO:     Found new best model at epoch 35
2023-01-05 11:38:09,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:09,822 INFO:     Epoch: 36
2023-01-05 11:38:11,925 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4170818080504735, 'Total loss': 0.4170818080504735} | train loss {'Reaction outcome loss': 0.3570886005240657, 'Total loss': 0.3570886005240657}
2023-01-05 11:38:11,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:11,926 INFO:     Epoch: 37
2023-01-05 11:38:14,077 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44606709480285645, 'Total loss': 0.44606709480285645} | train loss {'Reaction outcome loss': 0.3542303533599265, 'Total loss': 0.3542303533599265}
2023-01-05 11:38:14,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:14,078 INFO:     Epoch: 38
2023-01-05 11:38:16,209 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45422067791223525, 'Total loss': 0.45422067791223525} | train loss {'Reaction outcome loss': 0.3510826349608089, 'Total loss': 0.3510826349608089}
2023-01-05 11:38:16,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:16,209 INFO:     Epoch: 39
2023-01-05 11:38:18,326 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41618856688340505, 'Total loss': 0.41618856688340505} | train loss {'Reaction outcome loss': 0.34544668066910456, 'Total loss': 0.34544668066910456}
2023-01-05 11:38:18,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:18,326 INFO:     Epoch: 40
2023-01-05 11:38:20,455 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4157084385553996, 'Total loss': 0.4157084385553996} | train loss {'Reaction outcome loss': 0.354217207765321, 'Total loss': 0.354217207765321}
2023-01-05 11:38:20,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:20,456 INFO:     Epoch: 41
2023-01-05 11:38:22,610 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43756136496861775, 'Total loss': 0.43756136496861775} | train loss {'Reaction outcome loss': 0.3419236554781022, 'Total loss': 0.3419236554781022}
2023-01-05 11:38:22,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:22,611 INFO:     Epoch: 42
2023-01-05 11:38:24,761 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4261743058760961, 'Total loss': 0.4261743058760961} | train loss {'Reaction outcome loss': 0.34308022147696804, 'Total loss': 0.34308022147696804}
2023-01-05 11:38:24,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:24,761 INFO:     Epoch: 43
2023-01-05 11:38:26,903 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4315671642621358, 'Total loss': 0.4315671642621358} | train loss {'Reaction outcome loss': 0.3393201607175252, 'Total loss': 0.3393201607175252}
2023-01-05 11:38:26,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:26,903 INFO:     Epoch: 44
2023-01-05 11:38:29,049 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4210485597451528, 'Total loss': 0.4210485597451528} | train loss {'Reaction outcome loss': 0.339052600308661, 'Total loss': 0.339052600308661}
2023-01-05 11:38:29,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:29,050 INFO:     Epoch: 45
2023-01-05 11:38:31,206 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44279069900512696, 'Total loss': 0.44279069900512696} | train loss {'Reaction outcome loss': 0.33416889387347637, 'Total loss': 0.33416889387347637}
2023-01-05 11:38:31,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:31,207 INFO:     Epoch: 46
2023-01-05 11:38:33,359 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43010983367760974, 'Total loss': 0.43010983367760974} | train loss {'Reaction outcome loss': 0.33803665315201137, 'Total loss': 0.33803665315201137}
2023-01-05 11:38:33,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:33,360 INFO:     Epoch: 47
2023-01-05 11:38:35,510 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44074755907058716, 'Total loss': 0.44074755907058716} | train loss {'Reaction outcome loss': 0.33092652094493274, 'Total loss': 0.33092652094493274}
2023-01-05 11:38:35,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:35,510 INFO:     Epoch: 48
2023-01-05 11:38:37,654 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4195144603649775, 'Total loss': 0.4195144603649775} | train loss {'Reaction outcome loss': 0.3258115858888583, 'Total loss': 0.3258115858888583}
2023-01-05 11:38:37,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:37,654 INFO:     Epoch: 49
2023-01-05 11:38:39,803 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4204329977432887, 'Total loss': 0.4204329977432887} | train loss {'Reaction outcome loss': 0.3218535690665891, 'Total loss': 0.3218535690665891}
2023-01-05 11:38:39,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:39,803 INFO:     Epoch: 50
2023-01-05 11:38:41,962 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39763865967591605, 'Total loss': 0.39763865967591605} | train loss {'Reaction outcome loss': 0.3260797982369735, 'Total loss': 0.3260797982369735}
2023-01-05 11:38:41,962 INFO:     Found new best model at epoch 50
2023-01-05 11:38:41,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:41,964 INFO:     Epoch: 51
2023-01-05 11:38:44,137 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4282313788930575, 'Total loss': 0.4282313788930575} | train loss {'Reaction outcome loss': 0.31573407370798856, 'Total loss': 0.31573407370798856}
2023-01-05 11:38:44,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:44,137 INFO:     Epoch: 52
2023-01-05 11:38:46,274 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41142884294191995, 'Total loss': 0.41142884294191995} | train loss {'Reaction outcome loss': 0.3139078147736267, 'Total loss': 0.3139078147736267}
2023-01-05 11:38:46,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:46,274 INFO:     Epoch: 53
2023-01-05 11:38:48,414 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39542107383410136, 'Total loss': 0.39542107383410136} | train loss {'Reaction outcome loss': 0.3192760947594143, 'Total loss': 0.3192760947594143}
2023-01-05 11:38:48,414 INFO:     Found new best model at epoch 53
2023-01-05 11:38:48,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:48,415 INFO:     Epoch: 54
2023-01-05 11:38:50,563 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40621583759784696, 'Total loss': 0.40621583759784696} | train loss {'Reaction outcome loss': 0.3127944630298374, 'Total loss': 0.3127944630298374}
2023-01-05 11:38:50,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:50,563 INFO:     Epoch: 55
2023-01-05 11:38:52,721 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42425672014554344, 'Total loss': 0.42425672014554344} | train loss {'Reaction outcome loss': 0.3098330802085813, 'Total loss': 0.3098330802085813}
2023-01-05 11:38:52,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:52,722 INFO:     Epoch: 56
2023-01-05 11:38:54,875 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.418201486269633, 'Total loss': 0.418201486269633} | train loss {'Reaction outcome loss': 0.31020368249676716, 'Total loss': 0.31020368249676716}
2023-01-05 11:38:54,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:54,875 INFO:     Epoch: 57
2023-01-05 11:38:57,021 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4054527133703232, 'Total loss': 0.4054527133703232} | train loss {'Reaction outcome loss': 0.3055410824769886, 'Total loss': 0.3055410824769886}
2023-01-05 11:38:57,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:57,021 INFO:     Epoch: 58
2023-01-05 11:38:59,227 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4205467422803243, 'Total loss': 0.4205467422803243} | train loss {'Reaction outcome loss': 0.30245298671700893, 'Total loss': 0.30245298671700893}
2023-01-05 11:38:59,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:38:59,228 INFO:     Epoch: 59
2023-01-05 11:39:01,069 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3938280334075292, 'Total loss': 0.3938280334075292} | train loss {'Reaction outcome loss': 0.3039512000843506, 'Total loss': 0.3039512000843506}
2023-01-05 11:39:01,069 INFO:     Found new best model at epoch 59
2023-01-05 11:39:01,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:01,070 INFO:     Epoch: 60
2023-01-05 11:39:02,831 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39202440281709033, 'Total loss': 0.39202440281709033} | train loss {'Reaction outcome loss': 0.304771572606981, 'Total loss': 0.304771572606981}
2023-01-05 11:39:02,831 INFO:     Found new best model at epoch 60
2023-01-05 11:39:02,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:02,833 INFO:     Epoch: 61
2023-01-05 11:39:04,791 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42509695887565613, 'Total loss': 0.42509695887565613} | train loss {'Reaction outcome loss': 0.30041264994103556, 'Total loss': 0.30041264994103556}
2023-01-05 11:39:04,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:04,791 INFO:     Epoch: 62
2023-01-05 11:39:06,968 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4102143744627635, 'Total loss': 0.4102143744627635} | train loss {'Reaction outcome loss': 0.2951538420621884, 'Total loss': 0.2951538420621884}
2023-01-05 11:39:06,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:06,968 INFO:     Epoch: 63
2023-01-05 11:39:09,124 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40995745559533436, 'Total loss': 0.40995745559533436} | train loss {'Reaction outcome loss': 0.2943979368145016, 'Total loss': 0.2943979368145016}
2023-01-05 11:39:09,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:09,124 INFO:     Epoch: 64
2023-01-05 11:39:11,294 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40525043904781344, 'Total loss': 0.40525043904781344} | train loss {'Reaction outcome loss': 0.2932581419952294, 'Total loss': 0.2932581419952294}
2023-01-05 11:39:11,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:11,295 INFO:     Epoch: 65
2023-01-05 11:39:13,454 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38656312227249146, 'Total loss': 0.38656312227249146} | train loss {'Reaction outcome loss': 0.29335922776092693, 'Total loss': 0.29335922776092693}
2023-01-05 11:39:13,454 INFO:     Found new best model at epoch 65
2023-01-05 11:39:13,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:13,456 INFO:     Epoch: 66
2023-01-05 11:39:15,616 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39868839730819067, 'Total loss': 0.39868839730819067} | train loss {'Reaction outcome loss': 0.2888524977201159, 'Total loss': 0.2888524977201159}
2023-01-05 11:39:15,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:15,616 INFO:     Epoch: 67
2023-01-05 11:39:17,794 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3774135152498881, 'Total loss': 0.3774135152498881} | train loss {'Reaction outcome loss': 0.28849232740807834, 'Total loss': 0.28849232740807834}
2023-01-05 11:39:17,794 INFO:     Found new best model at epoch 67
2023-01-05 11:39:17,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:17,795 INFO:     Epoch: 68
2023-01-05 11:39:19,972 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36190558448433874, 'Total loss': 0.36190558448433874} | train loss {'Reaction outcome loss': 0.2892482449108943, 'Total loss': 0.2892482449108943}
2023-01-05 11:39:19,972 INFO:     Found new best model at epoch 68
2023-01-05 11:39:19,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:19,973 INFO:     Epoch: 69
2023-01-05 11:39:22,138 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3901509712139765, 'Total loss': 0.3901509712139765} | train loss {'Reaction outcome loss': 0.29114938129264095, 'Total loss': 0.29114938129264095}
2023-01-05 11:39:22,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:22,138 INFO:     Epoch: 70
2023-01-05 11:39:24,301 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43381951153278353, 'Total loss': 0.43381951153278353} | train loss {'Reaction outcome loss': 0.2806632271581178, 'Total loss': 0.2806632271581178}
2023-01-05 11:39:24,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:24,302 INFO:     Epoch: 71
2023-01-05 11:39:26,166 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4092031548420588, 'Total loss': 0.4092031548420588} | train loss {'Reaction outcome loss': 0.28460744281538125, 'Total loss': 0.28460744281538125}
2023-01-05 11:39:26,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:26,166 INFO:     Epoch: 72
2023-01-05 11:39:27,927 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43008216718832654, 'Total loss': 0.43008216718832654} | train loss {'Reaction outcome loss': 0.28056084321616787, 'Total loss': 0.28056084321616787}
2023-01-05 11:39:27,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:27,928 INFO:     Epoch: 73
2023-01-05 11:39:29,859 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4013009011745453, 'Total loss': 0.4013009011745453} | train loss {'Reaction outcome loss': 0.27444632624407106, 'Total loss': 0.27444632624407106}
2023-01-05 11:39:29,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:29,859 INFO:     Epoch: 74
2023-01-05 11:39:32,030 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4229856590429942, 'Total loss': 0.4229856590429942} | train loss {'Reaction outcome loss': 0.2759653661494221, 'Total loss': 0.2759653661494221}
2023-01-05 11:39:32,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:32,030 INFO:     Epoch: 75
2023-01-05 11:39:34,201 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4065093994140625, 'Total loss': 0.4065093994140625} | train loss {'Reaction outcome loss': 0.27711742232799097, 'Total loss': 0.27711742232799097}
2023-01-05 11:39:34,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:34,202 INFO:     Epoch: 76
2023-01-05 11:39:36,371 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38681566566228864, 'Total loss': 0.38681566566228864} | train loss {'Reaction outcome loss': 0.2803466704132755, 'Total loss': 0.2803466704132755}
2023-01-05 11:39:36,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:36,371 INFO:     Epoch: 77
2023-01-05 11:39:38,525 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40435852855443954, 'Total loss': 0.40435852855443954} | train loss {'Reaction outcome loss': 0.278675027864074, 'Total loss': 0.278675027864074}
2023-01-05 11:39:38,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:38,526 INFO:     Epoch: 78
2023-01-05 11:39:40,690 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4179654176036517, 'Total loss': 0.4179654176036517} | train loss {'Reaction outcome loss': 0.28119213950386546, 'Total loss': 0.28119213950386546}
2023-01-05 11:39:40,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:40,690 INFO:     Epoch: 79
2023-01-05 11:39:42,811 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4352555473645528, 'Total loss': 0.4352555473645528} | train loss {'Reaction outcome loss': 0.27671035217786955, 'Total loss': 0.27671035217786955}
2023-01-05 11:39:42,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:42,811 INFO:     Epoch: 80
2023-01-05 11:39:44,958 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4179906686147054, 'Total loss': 0.4179906686147054} | train loss {'Reaction outcome loss': 0.2780244598023943, 'Total loss': 0.2780244598023943}
2023-01-05 11:39:44,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:44,958 INFO:     Epoch: 81
2023-01-05 11:39:47,072 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38668464521567025, 'Total loss': 0.38668464521567025} | train loss {'Reaction outcome loss': 0.26712113308521923, 'Total loss': 0.26712113308521923}
2023-01-05 11:39:47,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:47,073 INFO:     Epoch: 82
2023-01-05 11:39:49,204 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4322732716798782, 'Total loss': 0.4322732716798782} | train loss {'Reaction outcome loss': 0.2705313438072209, 'Total loss': 0.2705313438072209}
2023-01-05 11:39:49,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:49,205 INFO:     Epoch: 83
2023-01-05 11:39:51,348 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40649953186511995, 'Total loss': 0.40649953186511995} | train loss {'Reaction outcome loss': 0.2675317864636437, 'Total loss': 0.2675317864636437}
2023-01-05 11:39:51,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:51,348 INFO:     Epoch: 84
2023-01-05 11:39:53,487 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3898932228485743, 'Total loss': 0.3898932228485743} | train loss {'Reaction outcome loss': 0.2677686642922649, 'Total loss': 0.2677686642922649}
2023-01-05 11:39:53,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:53,487 INFO:     Epoch: 85
2023-01-05 11:39:55,643 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4223210602998734, 'Total loss': 0.4223210602998734} | train loss {'Reaction outcome loss': 0.2737186033789754, 'Total loss': 0.2737186033789754}
2023-01-05 11:39:55,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:55,644 INFO:     Epoch: 86
2023-01-05 11:39:57,798 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4518912583589554, 'Total loss': 0.4518912583589554} | train loss {'Reaction outcome loss': 0.26087420405517414, 'Total loss': 0.26087420405517414}
2023-01-05 11:39:57,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:57,798 INFO:     Epoch: 87
2023-01-05 11:39:59,940 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.388948854804039, 'Total loss': 0.388948854804039} | train loss {'Reaction outcome loss': 0.2679540986322969, 'Total loss': 0.2679540986322969}
2023-01-05 11:39:59,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:39:59,940 INFO:     Epoch: 88
2023-01-05 11:40:02,093 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44903998970985415, 'Total loss': 0.44903998970985415} | train loss {'Reaction outcome loss': 0.2737236424729174, 'Total loss': 0.2737236424729174}
2023-01-05 11:40:02,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:02,093 INFO:     Epoch: 89
2023-01-05 11:40:04,233 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40150172760089237, 'Total loss': 0.40150172760089237} | train loss {'Reaction outcome loss': 0.2703623820889728, 'Total loss': 0.2703623820889728}
2023-01-05 11:40:04,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:04,234 INFO:     Epoch: 90
2023-01-05 11:40:06,380 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3872553363442421, 'Total loss': 0.3872553363442421} | train loss {'Reaction outcome loss': 0.2572427617742374, 'Total loss': 0.2572427617742374}
2023-01-05 11:40:06,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:06,380 INFO:     Epoch: 91
2023-01-05 11:40:08,539 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4054093509912491, 'Total loss': 0.4054093509912491} | train loss {'Reaction outcome loss': 0.26115646045856744, 'Total loss': 0.26115646045856744}
2023-01-05 11:40:08,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:08,539 INFO:     Epoch: 92
2023-01-05 11:40:10,684 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4722249915202459, 'Total loss': 0.4722249915202459} | train loss {'Reaction outcome loss': 0.26673145013918514, 'Total loss': 0.26673145013918514}
2023-01-05 11:40:10,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:10,685 INFO:     Epoch: 93
2023-01-05 11:40:12,834 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4057453602552414, 'Total loss': 0.4057453602552414} | train loss {'Reaction outcome loss': 0.2599286253863293, 'Total loss': 0.2599286253863293}
2023-01-05 11:40:12,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:12,835 INFO:     Epoch: 94
2023-01-05 11:40:14,979 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41500645180543266, 'Total loss': 0.41500645180543266} | train loss {'Reaction outcome loss': 0.2654230849891363, 'Total loss': 0.2654230849891363}
2023-01-05 11:40:14,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:14,979 INFO:     Epoch: 95
2023-01-05 11:40:17,111 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41110990146795906, 'Total loss': 0.41110990146795906} | train loss {'Reaction outcome loss': 0.25777952305784296, 'Total loss': 0.25777952305784296}
2023-01-05 11:40:17,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:17,111 INFO:     Epoch: 96
2023-01-05 11:40:19,261 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4337735732396444, 'Total loss': 0.4337735732396444} | train loss {'Reaction outcome loss': 0.2556356933868964, 'Total loss': 0.2556356933868964}
2023-01-05 11:40:19,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:19,262 INFO:     Epoch: 97
2023-01-05 11:40:21,406 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4148901104927063, 'Total loss': 0.4148901104927063} | train loss {'Reaction outcome loss': 0.2625815479306753, 'Total loss': 0.2625815479306753}
2023-01-05 11:40:21,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:21,406 INFO:     Epoch: 98
2023-01-05 11:40:23,524 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37088711460431417, 'Total loss': 0.37088711460431417} | train loss {'Reaction outcome loss': 0.265485814325377, 'Total loss': 0.265485814325377}
2023-01-05 11:40:23,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:23,525 INFO:     Epoch: 99
2023-01-05 11:40:25,659 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4126522290830811, 'Total loss': 0.4126522290830811} | train loss {'Reaction outcome loss': 0.25514410733369713, 'Total loss': 0.25514410733369713}
2023-01-05 11:40:25,659 INFO:     Best model found after epoch 69 of 100.
2023-01-05 11:40:25,659 INFO:   Done with stage: TRAINING
2023-01-05 11:40:25,659 INFO:   Starting stage: EVALUATION
2023-01-05 11:40:25,787 INFO:   Done with stage: EVALUATION
2023-01-05 11:40:25,787 INFO:   Leaving out SEQ value Fold_7
2023-01-05 11:40:25,799 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 11:40:25,799 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:40:26,444 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:40:26,444 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:40:26,513 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:40:26,513 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:40:26,513 INFO:     No hyperparam tuning for this model
2023-01-05 11:40:26,513 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:40:26,513 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:40:26,514 INFO:     None feature selector for col prot
2023-01-05 11:40:26,514 INFO:     None feature selector for col prot
2023-01-05 11:40:26,514 INFO:     None feature selector for col prot
2023-01-05 11:40:26,515 INFO:     None feature selector for col chem
2023-01-05 11:40:26,515 INFO:     None feature selector for col chem
2023-01-05 11:40:26,515 INFO:     None feature selector for col chem
2023-01-05 11:40:26,515 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:40:26,515 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:40:26,517 INFO:     Number of params in model 72901
2023-01-05 11:40:26,520 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:40:26,520 INFO:   Starting stage: TRAINING
2023-01-05 11:40:26,578 INFO:     Val loss before train {'Reaction outcome loss': 1.035998264948527, 'Total loss': 1.035998264948527}
2023-01-05 11:40:26,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:26,578 INFO:     Epoch: 0
2023-01-05 11:40:28,729 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.872118616104126, 'Total loss': 0.872118616104126} | train loss {'Reaction outcome loss': 0.9222591602199774, 'Total loss': 0.9222591602199774}
2023-01-05 11:40:28,729 INFO:     Found new best model at epoch 0
2023-01-05 11:40:28,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:28,731 INFO:     Epoch: 1
2023-01-05 11:40:30,893 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6651291906833648, 'Total loss': 0.6651291906833648} | train loss {'Reaction outcome loss': 0.7453746194228369, 'Total loss': 0.7453746194228369}
2023-01-05 11:40:30,893 INFO:     Found new best model at epoch 1
2023-01-05 11:40:30,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:30,894 INFO:     Epoch: 2
2023-01-05 11:40:33,063 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5763999501864115, 'Total loss': 0.5763999501864115} | train loss {'Reaction outcome loss': 0.5893356873240282, 'Total loss': 0.5893356873240282}
2023-01-05 11:40:33,063 INFO:     Found new best model at epoch 2
2023-01-05 11:40:33,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:33,065 INFO:     Epoch: 3
2023-01-05 11:40:35,206 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5836199780305227, 'Total loss': 0.5836199780305227} | train loss {'Reaction outcome loss': 0.5325617763324765, 'Total loss': 0.5325617763324765}
2023-01-05 11:40:35,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:35,207 INFO:     Epoch: 4
2023-01-05 11:40:37,357 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.540613145629565, 'Total loss': 0.540613145629565} | train loss {'Reaction outcome loss': 0.5097598309228567, 'Total loss': 0.5097598309228567}
2023-01-05 11:40:37,357 INFO:     Found new best model at epoch 4
2023-01-05 11:40:37,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:37,359 INFO:     Epoch: 5
2023-01-05 11:40:39,505 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5512091636657714, 'Total loss': 0.5512091636657714} | train loss {'Reaction outcome loss': 0.4992229799178533, 'Total loss': 0.4992229799178533}
2023-01-05 11:40:39,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:39,506 INFO:     Epoch: 6
2023-01-05 11:40:41,680 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5712850689888, 'Total loss': 0.5712850689888} | train loss {'Reaction outcome loss': 0.4896673251360332, 'Total loss': 0.4896673251360332}
2023-01-05 11:40:41,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:41,680 INFO:     Epoch: 7
2023-01-05 11:40:43,818 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5498741606871287, 'Total loss': 0.5498741606871287} | train loss {'Reaction outcome loss': 0.47785425761761646, 'Total loss': 0.47785425761761646}
2023-01-05 11:40:43,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:43,818 INFO:     Epoch: 8
2023-01-05 11:40:45,983 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5426330218712488, 'Total loss': 0.5426330218712488} | train loss {'Reaction outcome loss': 0.47197720107188723, 'Total loss': 0.47197720107188723}
2023-01-05 11:40:45,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:45,984 INFO:     Epoch: 9
2023-01-05 11:40:48,120 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5456727385520935, 'Total loss': 0.5456727385520935} | train loss {'Reaction outcome loss': 0.46402140542703413, 'Total loss': 0.46402140542703413}
2023-01-05 11:40:48,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:48,121 INFO:     Epoch: 10
2023-01-05 11:40:50,304 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5556969543298086, 'Total loss': 0.5556969543298086} | train loss {'Reaction outcome loss': 0.4601981473098163, 'Total loss': 0.4601981473098163}
2023-01-05 11:40:50,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:50,304 INFO:     Epoch: 11
2023-01-05 11:40:52,456 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5371484021345775, 'Total loss': 0.5371484021345775} | train loss {'Reaction outcome loss': 0.45793286928846516, 'Total loss': 0.45793286928846516}
2023-01-05 11:40:52,456 INFO:     Found new best model at epoch 11
2023-01-05 11:40:52,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:52,457 INFO:     Epoch: 12
2023-01-05 11:40:54,634 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5562209288279215, 'Total loss': 0.5562209288279215} | train loss {'Reaction outcome loss': 0.45188984807432775, 'Total loss': 0.45188984807432775}
2023-01-05 11:40:54,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:54,634 INFO:     Epoch: 13
2023-01-05 11:40:56,809 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5626660068829854, 'Total loss': 0.5626660068829854} | train loss {'Reaction outcome loss': 0.44678852478519676, 'Total loss': 0.44678852478519676}
2023-01-05 11:40:56,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:56,809 INFO:     Epoch: 14
2023-01-05 11:40:58,953 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5405596494674683, 'Total loss': 0.5405596494674683} | train loss {'Reaction outcome loss': 0.43726121034432835, 'Total loss': 0.43726121034432835}
2023-01-05 11:40:58,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:40:58,954 INFO:     Epoch: 15
2023-01-05 11:41:01,122 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5277807305256526, 'Total loss': 0.5277807305256526} | train loss {'Reaction outcome loss': 0.43463499706897496, 'Total loss': 0.43463499706897496}
2023-01-05 11:41:01,122 INFO:     Found new best model at epoch 15
2023-01-05 11:41:01,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:01,123 INFO:     Epoch: 16
2023-01-05 11:41:03,273 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.532880977789561, 'Total loss': 0.532880977789561} | train loss {'Reaction outcome loss': 0.42940035435482055, 'Total loss': 0.42940035435482055}
2023-01-05 11:41:03,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:03,274 INFO:     Epoch: 17
2023-01-05 11:41:05,423 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5206400752067566, 'Total loss': 0.5206400752067566} | train loss {'Reaction outcome loss': 0.4333477140495063, 'Total loss': 0.4333477140495063}
2023-01-05 11:41:05,424 INFO:     Found new best model at epoch 17
2023-01-05 11:41:05,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:05,425 INFO:     Epoch: 18
2023-01-05 11:41:07,599 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5192301978667577, 'Total loss': 0.5192301978667577} | train loss {'Reaction outcome loss': 0.42562854758023355, 'Total loss': 0.42562854758023355}
2023-01-05 11:41:07,599 INFO:     Found new best model at epoch 18
2023-01-05 11:41:07,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:07,600 INFO:     Epoch: 19
2023-01-05 11:41:09,751 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.521293572584788, 'Total loss': 0.521293572584788} | train loss {'Reaction outcome loss': 0.42278881118185685, 'Total loss': 0.42278881118185685}
2023-01-05 11:41:09,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:09,751 INFO:     Epoch: 20
2023-01-05 11:41:11,904 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5126629451910655, 'Total loss': 0.5126629451910655} | train loss {'Reaction outcome loss': 0.419664888578847, 'Total loss': 0.419664888578847}
2023-01-05 11:41:11,904 INFO:     Found new best model at epoch 20
2023-01-05 11:41:11,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:11,906 INFO:     Epoch: 21
2023-01-05 11:41:14,072 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5305653790632884, 'Total loss': 0.5305653790632884} | train loss {'Reaction outcome loss': 0.41206423378808404, 'Total loss': 0.41206423378808404}
2023-01-05 11:41:14,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:14,072 INFO:     Epoch: 22
2023-01-05 11:41:16,222 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5051349361737569, 'Total loss': 0.5051349361737569} | train loss {'Reaction outcome loss': 0.40871438494335444, 'Total loss': 0.40871438494335444}
2023-01-05 11:41:16,223 INFO:     Found new best model at epoch 22
2023-01-05 11:41:16,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:16,225 INFO:     Epoch: 23
2023-01-05 11:41:18,347 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5031588604052861, 'Total loss': 0.5031588604052861} | train loss {'Reaction outcome loss': 0.40473643773729623, 'Total loss': 0.40473643773729623}
2023-01-05 11:41:18,347 INFO:     Found new best model at epoch 23
2023-01-05 11:41:18,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:18,349 INFO:     Epoch: 24
2023-01-05 11:41:20,509 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5013553420702617, 'Total loss': 0.5013553420702617} | train loss {'Reaction outcome loss': 0.4029524450590464, 'Total loss': 0.4029524450590464}
2023-01-05 11:41:20,509 INFO:     Found new best model at epoch 24
2023-01-05 11:41:20,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:20,511 INFO:     Epoch: 25
2023-01-05 11:41:22,653 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5493660906950633, 'Total loss': 0.5493660906950633} | train loss {'Reaction outcome loss': 0.39578185714646796, 'Total loss': 0.39578185714646796}
2023-01-05 11:41:22,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:22,654 INFO:     Epoch: 26
2023-01-05 11:41:24,776 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5160927146673202, 'Total loss': 0.5160927146673202} | train loss {'Reaction outcome loss': 0.39569312194194173, 'Total loss': 0.39569312194194173}
2023-01-05 11:41:24,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:24,777 INFO:     Epoch: 27
2023-01-05 11:41:26,920 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.495283172527949, 'Total loss': 0.495283172527949} | train loss {'Reaction outcome loss': 0.38936353867557505, 'Total loss': 0.38936353867557505}
2023-01-05 11:41:26,920 INFO:     Found new best model at epoch 27
2023-01-05 11:41:26,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:26,921 INFO:     Epoch: 28
2023-01-05 11:41:29,069 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5312776704629262, 'Total loss': 0.5312776704629262} | train loss {'Reaction outcome loss': 0.38478119378163067, 'Total loss': 0.38478119378163067}
2023-01-05 11:41:29,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:29,070 INFO:     Epoch: 29
2023-01-05 11:41:31,211 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4939477811257044, 'Total loss': 0.4939477811257044} | train loss {'Reaction outcome loss': 0.38697441667318344, 'Total loss': 0.38697441667318344}
2023-01-05 11:41:31,211 INFO:     Found new best model at epoch 29
2023-01-05 11:41:31,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:31,212 INFO:     Epoch: 30
2023-01-05 11:41:33,362 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49611111283302306, 'Total loss': 0.49611111283302306} | train loss {'Reaction outcome loss': 0.3832404942719084, 'Total loss': 0.3832404942719084}
2023-01-05 11:41:33,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:33,362 INFO:     Epoch: 31
2023-01-05 11:41:35,494 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4902324279149373, 'Total loss': 0.4902324279149373} | train loss {'Reaction outcome loss': 0.3758935895664382, 'Total loss': 0.3758935895664382}
2023-01-05 11:41:35,495 INFO:     Found new best model at epoch 31
2023-01-05 11:41:35,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:35,496 INFO:     Epoch: 32
2023-01-05 11:41:37,629 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5022923747698466, 'Total loss': 0.5022923747698466} | train loss {'Reaction outcome loss': 0.3660010944258435, 'Total loss': 0.3660010944258435}
2023-01-05 11:41:37,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:37,630 INFO:     Epoch: 33
2023-01-05 11:41:39,751 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.489485989511013, 'Total loss': 0.489485989511013} | train loss {'Reaction outcome loss': 0.37240107283534124, 'Total loss': 0.37240107283534124}
2023-01-05 11:41:39,751 INFO:     Found new best model at epoch 33
2023-01-05 11:41:39,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:39,753 INFO:     Epoch: 34
2023-01-05 11:41:41,896 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5130737205346425, 'Total loss': 0.5130737205346425} | train loss {'Reaction outcome loss': 0.3683773189621712, 'Total loss': 0.3683773189621712}
2023-01-05 11:41:41,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:41,896 INFO:     Epoch: 35
2023-01-05 11:41:44,045 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.500543189048767, 'Total loss': 0.500543189048767} | train loss {'Reaction outcome loss': 0.3636484520798986, 'Total loss': 0.3636484520798986}
2023-01-05 11:41:44,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:44,046 INFO:     Epoch: 36
2023-01-05 11:41:46,175 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48436338603496554, 'Total loss': 0.48436338603496554} | train loss {'Reaction outcome loss': 0.36249968156702683, 'Total loss': 0.36249968156702683}
2023-01-05 11:41:46,176 INFO:     Found new best model at epoch 36
2023-01-05 11:41:46,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:46,178 INFO:     Epoch: 37
2023-01-05 11:41:48,338 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5103472391764323, 'Total loss': 0.5103472391764323} | train loss {'Reaction outcome loss': 0.35941334894525445, 'Total loss': 0.35941334894525445}
2023-01-05 11:41:48,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:48,338 INFO:     Epoch: 38
2023-01-05 11:41:50,457 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48430783351262413, 'Total loss': 0.48430783351262413} | train loss {'Reaction outcome loss': 0.3557735573944202, 'Total loss': 0.3557735573944202}
2023-01-05 11:41:50,457 INFO:     Found new best model at epoch 38
2023-01-05 11:41:50,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:50,459 INFO:     Epoch: 39
2023-01-05 11:41:52,627 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5028940707445144, 'Total loss': 0.5028940707445144} | train loss {'Reaction outcome loss': 0.34619225359888284, 'Total loss': 0.34619225359888284}
2023-01-05 11:41:52,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:52,628 INFO:     Epoch: 40
2023-01-05 11:41:54,721 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4893280694882075, 'Total loss': 0.4893280694882075} | train loss {'Reaction outcome loss': 0.351220788494667, 'Total loss': 0.351220788494667}
2023-01-05 11:41:54,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:54,721 INFO:     Epoch: 41
2023-01-05 11:41:56,850 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5085584302743276, 'Total loss': 0.5085584302743276} | train loss {'Reaction outcome loss': 0.342931953097428, 'Total loss': 0.342931953097428}
2023-01-05 11:41:56,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:56,850 INFO:     Epoch: 42
2023-01-05 11:41:58,984 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4819669743378957, 'Total loss': 0.4819669743378957} | train loss {'Reaction outcome loss': 0.3363522602117449, 'Total loss': 0.3363522602117449}
2023-01-05 11:41:58,985 INFO:     Found new best model at epoch 42
2023-01-05 11:41:58,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:41:58,986 INFO:     Epoch: 43
2023-01-05 11:42:00,935 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48511437475681307, 'Total loss': 0.48511437475681307} | train loss {'Reaction outcome loss': 0.33873212875441955, 'Total loss': 0.33873212875441955}
2023-01-05 11:42:00,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:00,935 INFO:     Epoch: 44
2023-01-05 11:42:03,047 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.509469731648763, 'Total loss': 0.509469731648763} | train loss {'Reaction outcome loss': 0.3362979434349907, 'Total loss': 0.3362979434349907}
2023-01-05 11:42:03,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:03,047 INFO:     Epoch: 45
2023-01-05 11:42:05,182 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46189607282479606, 'Total loss': 0.46189607282479606} | train loss {'Reaction outcome loss': 0.331743141723669, 'Total loss': 0.331743141723669}
2023-01-05 11:42:05,183 INFO:     Found new best model at epoch 45
2023-01-05 11:42:05,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:05,185 INFO:     Epoch: 46
2023-01-05 11:42:07,317 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49070356488227845, 'Total loss': 0.49070356488227845} | train loss {'Reaction outcome loss': 0.32668940295273646, 'Total loss': 0.32668940295273646}
2023-01-05 11:42:07,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:07,317 INFO:     Epoch: 47
2023-01-05 11:42:09,474 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47645846803983055, 'Total loss': 0.47645846803983055} | train loss {'Reaction outcome loss': 0.32984546240459495, 'Total loss': 0.32984546240459495}
2023-01-05 11:42:09,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:09,474 INFO:     Epoch: 48
2023-01-05 11:42:11,588 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5216205298900605, 'Total loss': 0.5216205298900605} | train loss {'Reaction outcome loss': 0.32376313041424926, 'Total loss': 0.32376313041424926}
2023-01-05 11:42:11,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:11,589 INFO:     Epoch: 49
2023-01-05 11:42:13,710 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49099163015683495, 'Total loss': 0.49099163015683495} | train loss {'Reaction outcome loss': 0.32689479018968365, 'Total loss': 0.32689479018968365}
2023-01-05 11:42:13,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:13,711 INFO:     Epoch: 50
2023-01-05 11:42:15,866 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4710630098978678, 'Total loss': 0.4710630098978678} | train loss {'Reaction outcome loss': 0.3283188366448836, 'Total loss': 0.3283188366448836}
2023-01-05 11:42:15,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:15,867 INFO:     Epoch: 51
2023-01-05 11:42:18,021 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4771503915389379, 'Total loss': 0.4771503915389379} | train loss {'Reaction outcome loss': 0.3232270968331542, 'Total loss': 0.3232270968331542}
2023-01-05 11:42:18,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:18,022 INFO:     Epoch: 52
2023-01-05 11:42:20,170 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4463021258513133, 'Total loss': 0.4463021258513133} | train loss {'Reaction outcome loss': 0.31788936648047145, 'Total loss': 0.31788936648047145}
2023-01-05 11:42:20,170 INFO:     Found new best model at epoch 52
2023-01-05 11:42:20,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:20,171 INFO:     Epoch: 53
2023-01-05 11:42:22,329 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4725753664970398, 'Total loss': 0.4725753664970398} | train loss {'Reaction outcome loss': 0.3119059252529153, 'Total loss': 0.3119059252529153}
2023-01-05 11:42:22,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:22,330 INFO:     Epoch: 54
2023-01-05 11:42:24,493 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48936307926972705, 'Total loss': 0.48936307926972705} | train loss {'Reaction outcome loss': 0.31098518544801307, 'Total loss': 0.31098518544801307}
2023-01-05 11:42:24,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:24,494 INFO:     Epoch: 55
2023-01-05 11:42:26,673 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47355918685595194, 'Total loss': 0.47355918685595194} | train loss {'Reaction outcome loss': 0.3086082149929088, 'Total loss': 0.3086082149929088}
2023-01-05 11:42:26,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:26,674 INFO:     Epoch: 56
2023-01-05 11:42:28,837 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46345720092455545, 'Total loss': 0.46345720092455545} | train loss {'Reaction outcome loss': 0.30741398660499697, 'Total loss': 0.30741398660499697}
2023-01-05 11:42:28,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:28,838 INFO:     Epoch: 57
2023-01-05 11:42:31,037 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4258811116218567, 'Total loss': 0.4258811116218567} | train loss {'Reaction outcome loss': 0.30989814462267967, 'Total loss': 0.30989814462267967}
2023-01-05 11:42:31,037 INFO:     Found new best model at epoch 57
2023-01-05 11:42:31,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:31,039 INFO:     Epoch: 58
2023-01-05 11:42:33,224 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4508175333340963, 'Total loss': 0.4508175333340963} | train loss {'Reaction outcome loss': 0.3020771569320226, 'Total loss': 0.3020771569320226}
2023-01-05 11:42:33,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:33,224 INFO:     Epoch: 59
2023-01-05 11:42:35,409 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48861673573652903, 'Total loss': 0.48861673573652903} | train loss {'Reaction outcome loss': 0.3011865370809386, 'Total loss': 0.3011865370809386}
2023-01-05 11:42:35,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:35,409 INFO:     Epoch: 60
2023-01-05 11:42:37,574 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45019051333268484, 'Total loss': 0.45019051333268484} | train loss {'Reaction outcome loss': 0.3004638259080558, 'Total loss': 0.3004638259080558}
2023-01-05 11:42:37,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:37,574 INFO:     Epoch: 61
2023-01-05 11:42:39,724 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4784075379371643, 'Total loss': 0.4784075379371643} | train loss {'Reaction outcome loss': 0.3005713355266876, 'Total loss': 0.3005713355266876}
2023-01-05 11:42:39,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:39,724 INFO:     Epoch: 62
2023-01-05 11:42:41,875 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46838917831579846, 'Total loss': 0.46838917831579846} | train loss {'Reaction outcome loss': 0.3074292344602652, 'Total loss': 0.3074292344602652}
2023-01-05 11:42:41,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:41,876 INFO:     Epoch: 63
2023-01-05 11:42:44,025 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4763362209002177, 'Total loss': 0.4763362209002177} | train loss {'Reaction outcome loss': 0.29325504810801484, 'Total loss': 0.29325504810801484}
2023-01-05 11:42:44,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:44,025 INFO:     Epoch: 64
2023-01-05 11:42:46,151 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4898154775301615, 'Total loss': 0.4898154775301615} | train loss {'Reaction outcome loss': 0.2953644537565295, 'Total loss': 0.2953644537565295}
2023-01-05 11:42:46,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:46,152 INFO:     Epoch: 65
2023-01-05 11:42:48,261 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4935790538787842, 'Total loss': 0.4935790538787842} | train loss {'Reaction outcome loss': 0.28510964235512787, 'Total loss': 0.28510964235512787}
2023-01-05 11:42:48,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:48,262 INFO:     Epoch: 66
2023-01-05 11:42:50,408 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4941356837749481, 'Total loss': 0.4941356837749481} | train loss {'Reaction outcome loss': 0.2911389499149598, 'Total loss': 0.2911389499149598}
2023-01-05 11:42:50,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:50,408 INFO:     Epoch: 67
2023-01-05 11:42:52,550 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.487376469373703, 'Total loss': 0.487376469373703} | train loss {'Reaction outcome loss': 0.28983259818345203, 'Total loss': 0.28983259818345203}
2023-01-05 11:42:52,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:52,550 INFO:     Epoch: 68
2023-01-05 11:42:54,695 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48566133677959444, 'Total loss': 0.48566133677959444} | train loss {'Reaction outcome loss': 0.28315586298838635, 'Total loss': 0.28315586298838635}
2023-01-05 11:42:54,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:54,696 INFO:     Epoch: 69
2023-01-05 11:42:56,841 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4741919348637263, 'Total loss': 0.4741919348637263} | train loss {'Reaction outcome loss': 0.27965358775176297, 'Total loss': 0.27965358775176297}
2023-01-05 11:42:56,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:56,841 INFO:     Epoch: 70
2023-01-05 11:42:59,007 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4893576165040334, 'Total loss': 0.4893576165040334} | train loss {'Reaction outcome loss': 0.2853417547708814, 'Total loss': 0.2853417547708814}
2023-01-05 11:42:59,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:42:59,008 INFO:     Epoch: 71
2023-01-05 11:43:01,155 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4753131295243899, 'Total loss': 0.4753131295243899} | train loss {'Reaction outcome loss': 0.2822045171330767, 'Total loss': 0.2822045171330767}
2023-01-05 11:43:01,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:01,156 INFO:     Epoch: 72
2023-01-05 11:43:03,284 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4698211540778478, 'Total loss': 0.4698211540778478} | train loss {'Reaction outcome loss': 0.27337400289756725, 'Total loss': 0.27337400289756725}
2023-01-05 11:43:03,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:03,285 INFO:     Epoch: 73
2023-01-05 11:43:05,448 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45821085572242737, 'Total loss': 0.45821085572242737} | train loss {'Reaction outcome loss': 0.28035541274836995, 'Total loss': 0.28035541274836995}
2023-01-05 11:43:05,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:05,450 INFO:     Epoch: 74
2023-01-05 11:43:07,553 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4780538618564606, 'Total loss': 0.4780538618564606} | train loss {'Reaction outcome loss': 0.2842200807958088, 'Total loss': 0.2842200807958088}
2023-01-05 11:43:07,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:07,554 INFO:     Epoch: 75
2023-01-05 11:43:09,686 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4745099077622096, 'Total loss': 0.4745099077622096} | train loss {'Reaction outcome loss': 0.27458815308899653, 'Total loss': 0.27458815308899653}
2023-01-05 11:43:09,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:09,687 INFO:     Epoch: 76
2023-01-05 11:43:11,794 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49140804608662925, 'Total loss': 0.49140804608662925} | train loss {'Reaction outcome loss': 0.2690932600748883, 'Total loss': 0.2690932600748883}
2023-01-05 11:43:11,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:11,795 INFO:     Epoch: 77
2023-01-05 11:43:13,908 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.478526646643877, 'Total loss': 0.478526646643877} | train loss {'Reaction outcome loss': 0.27334401663729, 'Total loss': 0.27334401663729}
2023-01-05 11:43:13,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:13,908 INFO:     Epoch: 78
2023-01-05 11:43:16,034 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4765353153149287, 'Total loss': 0.4765353153149287} | train loss {'Reaction outcome loss': 0.27168259035379017, 'Total loss': 0.27168259035379017}
2023-01-05 11:43:16,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:16,034 INFO:     Epoch: 79
2023-01-05 11:43:18,165 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45621185302734374, 'Total loss': 0.45621185302734374} | train loss {'Reaction outcome loss': 0.2697367188033214, 'Total loss': 0.2697367188033214}
2023-01-05 11:43:18,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:18,166 INFO:     Epoch: 80
2023-01-05 11:43:20,288 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4545784165461858, 'Total loss': 0.4545784165461858} | train loss {'Reaction outcome loss': 0.26843574226225325, 'Total loss': 0.26843574226225325}
2023-01-05 11:43:20,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:20,289 INFO:     Epoch: 81
2023-01-05 11:43:22,437 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47306275367736816, 'Total loss': 0.47306275367736816} | train loss {'Reaction outcome loss': 0.26591949120486685, 'Total loss': 0.26591949120486685}
2023-01-05 11:43:22,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:22,437 INFO:     Epoch: 82
2023-01-05 11:43:24,542 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4616395672162374, 'Total loss': 0.4616395672162374} | train loss {'Reaction outcome loss': 0.2685373512765776, 'Total loss': 0.2685373512765776}
2023-01-05 11:43:24,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:24,543 INFO:     Epoch: 83
2023-01-05 11:43:26,650 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.466996493935585, 'Total loss': 0.466996493935585} | train loss {'Reaction outcome loss': 0.2621414734114513, 'Total loss': 0.2621414734114513}
2023-01-05 11:43:26,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:26,651 INFO:     Epoch: 84
2023-01-05 11:43:28,793 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49486030737559, 'Total loss': 0.49486030737559} | train loss {'Reaction outcome loss': 0.25823695545457975, 'Total loss': 0.25823695545457975}
2023-01-05 11:43:28,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:28,794 INFO:     Epoch: 85
2023-01-05 11:43:31,036 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46295874416828153, 'Total loss': 0.46295874416828153} | train loss {'Reaction outcome loss': 0.2643972430647173, 'Total loss': 0.2643972430647173}
2023-01-05 11:43:31,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:31,036 INFO:     Epoch: 86
2023-01-05 11:43:33,186 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47461954653263094, 'Total loss': 0.47461954653263094} | train loss {'Reaction outcome loss': 0.2641994356033174, 'Total loss': 0.2641994356033174}
2023-01-05 11:43:33,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:33,186 INFO:     Epoch: 87
2023-01-05 11:43:35,322 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47415084938208263, 'Total loss': 0.47415084938208263} | train loss {'Reaction outcome loss': 0.25228244343954087, 'Total loss': 0.25228244343954087}
2023-01-05 11:43:35,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:35,323 INFO:     Epoch: 88
2023-01-05 11:43:37,453 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48573168317476906, 'Total loss': 0.48573168317476906} | train loss {'Reaction outcome loss': 0.25453041239712215, 'Total loss': 0.25453041239712215}
2023-01-05 11:43:37,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:37,453 INFO:     Epoch: 89
2023-01-05 11:43:39,582 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48537053167819977, 'Total loss': 0.48537053167819977} | train loss {'Reaction outcome loss': 0.25592150995070756, 'Total loss': 0.25592150995070756}
2023-01-05 11:43:39,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:39,582 INFO:     Epoch: 90
2023-01-05 11:43:41,707 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46763962010542554, 'Total loss': 0.46763962010542554} | train loss {'Reaction outcome loss': 0.2537865901318806, 'Total loss': 0.2537865901318806}
2023-01-05 11:43:41,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:41,708 INFO:     Epoch: 91
2023-01-05 11:43:43,857 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5075084090232849, 'Total loss': 0.5075084090232849} | train loss {'Reaction outcome loss': 0.2614310088463208, 'Total loss': 0.2614310088463208}
2023-01-05 11:43:43,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:43,857 INFO:     Epoch: 92
2023-01-05 11:43:45,987 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47219471335411073, 'Total loss': 0.47219471335411073} | train loss {'Reaction outcome loss': 0.24673669399955858, 'Total loss': 0.24673669399955858}
2023-01-05 11:43:45,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:45,987 INFO:     Epoch: 93
2023-01-05 11:43:48,115 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4772471288839976, 'Total loss': 0.4772471288839976} | train loss {'Reaction outcome loss': 0.2502981812393945, 'Total loss': 0.2502981812393945}
2023-01-05 11:43:48,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:48,116 INFO:     Epoch: 94
2023-01-05 11:43:50,247 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4795136968294779, 'Total loss': 0.4795136968294779} | train loss {'Reaction outcome loss': 0.25296086530850037, 'Total loss': 0.25296086530850037}
2023-01-05 11:43:50,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:50,247 INFO:     Epoch: 95
2023-01-05 11:43:52,388 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47639873524506887, 'Total loss': 0.47639873524506887} | train loss {'Reaction outcome loss': 0.24333322344731123, 'Total loss': 0.24333322344731123}
2023-01-05 11:43:52,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:52,388 INFO:     Epoch: 96
2023-01-05 11:43:54,511 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.451953853170077, 'Total loss': 0.451953853170077} | train loss {'Reaction outcome loss': 0.2491824481676632, 'Total loss': 0.2491824481676632}
2023-01-05 11:43:54,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:54,511 INFO:     Epoch: 97
2023-01-05 11:43:56,656 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49850760300954183, 'Total loss': 0.49850760300954183} | train loss {'Reaction outcome loss': 0.2412975100053992, 'Total loss': 0.2412975100053992}
2023-01-05 11:43:56,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:56,656 INFO:     Epoch: 98
2023-01-05 11:43:58,774 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45682729184627535, 'Total loss': 0.45682729184627535} | train loss {'Reaction outcome loss': 0.2558457774886801, 'Total loss': 0.2558457774886801}
2023-01-05 11:43:58,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:43:58,775 INFO:     Epoch: 99
2023-01-05 11:44:00,909 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4341290831565857, 'Total loss': 0.4341290831565857} | train loss {'Reaction outcome loss': 0.24813749323790685, 'Total loss': 0.24813749323790685}
2023-01-05 11:44:00,910 INFO:     Best model found after epoch 58 of 100.
2023-01-05 11:44:00,910 INFO:   Done with stage: TRAINING
2023-01-05 11:44:00,910 INFO:   Starting stage: EVALUATION
2023-01-05 11:44:01,036 INFO:   Done with stage: EVALUATION
2023-01-05 11:44:01,036 INFO:   Leaving out SEQ value Fold_8
2023-01-05 11:44:01,048 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 11:44:01,048 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:44:01,699 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:44:01,699 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:44:01,767 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:44:01,767 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:44:01,767 INFO:     No hyperparam tuning for this model
2023-01-05 11:44:01,767 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:44:01,767 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:44:01,768 INFO:     None feature selector for col prot
2023-01-05 11:44:01,768 INFO:     None feature selector for col prot
2023-01-05 11:44:01,768 INFO:     None feature selector for col prot
2023-01-05 11:44:01,769 INFO:     None feature selector for col chem
2023-01-05 11:44:01,769 INFO:     None feature selector for col chem
2023-01-05 11:44:01,769 INFO:     None feature selector for col chem
2023-01-05 11:44:01,769 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:44:01,769 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:44:01,771 INFO:     Number of params in model 72901
2023-01-05 11:44:01,774 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:44:01,774 INFO:   Starting stage: TRAINING
2023-01-05 11:44:01,834 INFO:     Val loss before train {'Reaction outcome loss': 0.9736821929613749, 'Total loss': 0.9736821929613749}
2023-01-05 11:44:01,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:01,834 INFO:     Epoch: 0
2023-01-05 11:44:03,962 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7770070731639862, 'Total loss': 0.7770070731639862} | train loss {'Reaction outcome loss': 0.926828619805484, 'Total loss': 0.926828619805484}
2023-01-05 11:44:03,963 INFO:     Found new best model at epoch 0
2023-01-05 11:44:03,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:03,965 INFO:     Epoch: 1
2023-01-05 11:44:06,194 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6421195248762767, 'Total loss': 0.6421195248762767} | train loss {'Reaction outcome loss': 0.7469933198677504, 'Total loss': 0.7469933198677504}
2023-01-05 11:44:06,194 INFO:     Found new best model at epoch 1
2023-01-05 11:44:06,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:06,195 INFO:     Epoch: 2
2023-01-05 11:44:08,342 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5316952725251516, 'Total loss': 0.5316952725251516} | train loss {'Reaction outcome loss': 0.5917322837381156, 'Total loss': 0.5917322837381156}
2023-01-05 11:44:08,342 INFO:     Found new best model at epoch 2
2023-01-05 11:44:08,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:08,344 INFO:     Epoch: 3
2023-01-05 11:44:10,458 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49959222277005516, 'Total loss': 0.49959222277005516} | train loss {'Reaction outcome loss': 0.5354301912259539, 'Total loss': 0.5354301912259539}
2023-01-05 11:44:10,459 INFO:     Found new best model at epoch 3
2023-01-05 11:44:10,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:10,460 INFO:     Epoch: 4
2023-01-05 11:44:12,575 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5112893104553222, 'Total loss': 0.5112893104553222} | train loss {'Reaction outcome loss': 0.5154429563869207, 'Total loss': 0.5154429563869207}
2023-01-05 11:44:12,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:12,576 INFO:     Epoch: 5
2023-01-05 11:44:14,702 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46925506393114724, 'Total loss': 0.46925506393114724} | train loss {'Reaction outcome loss': 0.5042579899195729, 'Total loss': 0.5042579899195729}
2023-01-05 11:44:14,702 INFO:     Found new best model at epoch 5
2023-01-05 11:44:14,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:14,703 INFO:     Epoch: 6
2023-01-05 11:44:16,830 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4936116913954417, 'Total loss': 0.4936116913954417} | train loss {'Reaction outcome loss': 0.4942738018956856, 'Total loss': 0.4942738018956856}
2023-01-05 11:44:16,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:16,830 INFO:     Epoch: 7
2023-01-05 11:44:18,946 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48179765244325, 'Total loss': 0.48179765244325} | train loss {'Reaction outcome loss': 0.49080308327713595, 'Total loss': 0.49080308327713595}
2023-01-05 11:44:18,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:18,946 INFO:     Epoch: 8
2023-01-05 11:44:21,082 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4837779651085536, 'Total loss': 0.4837779651085536} | train loss {'Reaction outcome loss': 0.4855837136883598, 'Total loss': 0.4855837136883598}
2023-01-05 11:44:21,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:21,082 INFO:     Epoch: 9
2023-01-05 11:44:23,204 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4772984226544698, 'Total loss': 0.4772984226544698} | train loss {'Reaction outcome loss': 0.4733358579637342, 'Total loss': 0.4733358579637342}
2023-01-05 11:44:23,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:23,205 INFO:     Epoch: 10
2023-01-05 11:44:25,365 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45457378923892977, 'Total loss': 0.45457378923892977} | train loss {'Reaction outcome loss': 0.4670774902785298, 'Total loss': 0.4670774902785298}
2023-01-05 11:44:25,365 INFO:     Found new best model at epoch 10
2023-01-05 11:44:25,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:25,367 INFO:     Epoch: 11
2023-01-05 11:44:27,507 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46475569208463036, 'Total loss': 0.46475569208463036} | train loss {'Reaction outcome loss': 0.46647009748414103, 'Total loss': 0.46647009748414103}
2023-01-05 11:44:27,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:27,507 INFO:     Epoch: 12
2023-01-05 11:44:29,625 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45015379587809246, 'Total loss': 0.45015379587809246} | train loss {'Reaction outcome loss': 0.45996506565959877, 'Total loss': 0.45996506565959877}
2023-01-05 11:44:29,625 INFO:     Found new best model at epoch 12
2023-01-05 11:44:29,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:29,627 INFO:     Epoch: 13
2023-01-05 11:44:31,776 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4579705794652303, 'Total loss': 0.4579705794652303} | train loss {'Reaction outcome loss': 0.4526287509861406, 'Total loss': 0.4526287509861406}
2023-01-05 11:44:31,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:31,776 INFO:     Epoch: 14
2023-01-05 11:44:33,899 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4765566607316335, 'Total loss': 0.4765566607316335} | train loss {'Reaction outcome loss': 0.4513322756178543, 'Total loss': 0.4513322756178543}
2023-01-05 11:44:33,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:33,899 INFO:     Epoch: 15
2023-01-05 11:44:36,031 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48499799966812135, 'Total loss': 0.48499799966812135} | train loss {'Reaction outcome loss': 0.4507555618935974, 'Total loss': 0.4507555618935974}
2023-01-05 11:44:36,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:36,032 INFO:     Epoch: 16
2023-01-05 11:44:38,151 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4502566715081533, 'Total loss': 0.4502566715081533} | train loss {'Reaction outcome loss': 0.44428515808139035, 'Total loss': 0.44428515808139035}
2023-01-05 11:44:38,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:38,152 INFO:     Epoch: 17
2023-01-05 11:44:40,261 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4679115613301595, 'Total loss': 0.4679115613301595} | train loss {'Reaction outcome loss': 0.4413124040468505, 'Total loss': 0.4413124040468505}
2023-01-05 11:44:40,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:40,261 INFO:     Epoch: 18
2023-01-05 11:44:42,361 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47300162017345426, 'Total loss': 0.47300162017345426} | train loss {'Reaction outcome loss': 0.4396339722165993, 'Total loss': 0.4396339722165993}
2023-01-05 11:44:42,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:42,361 INFO:     Epoch: 19
2023-01-05 11:44:44,498 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4895653039216995, 'Total loss': 0.4895653039216995} | train loss {'Reaction outcome loss': 0.4333491329144054, 'Total loss': 0.4333491329144054}
2023-01-05 11:44:44,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:44,498 INFO:     Epoch: 20
2023-01-05 11:44:46,613 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43739469051361085, 'Total loss': 0.43739469051361085} | train loss {'Reaction outcome loss': 0.43390082341992037, 'Total loss': 0.43390082341992037}
2023-01-05 11:44:46,613 INFO:     Found new best model at epoch 20
2023-01-05 11:44:46,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:46,614 INFO:     Epoch: 21
2023-01-05 11:44:48,741 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46841437220573423, 'Total loss': 0.46841437220573423} | train loss {'Reaction outcome loss': 0.4260336016489711, 'Total loss': 0.4260336016489711}
2023-01-05 11:44:48,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:48,742 INFO:     Epoch: 22
2023-01-05 11:44:50,857 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45898385842641193, 'Total loss': 0.45898385842641193} | train loss {'Reaction outcome loss': 0.4226976378891442, 'Total loss': 0.4226976378891442}
2023-01-05 11:44:50,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:50,858 INFO:     Epoch: 23
2023-01-05 11:44:53,008 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45563867340485253, 'Total loss': 0.45563867340485253} | train loss {'Reaction outcome loss': 0.4221374095831107, 'Total loss': 0.4221374095831107}
2023-01-05 11:44:53,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:53,008 INFO:     Epoch: 24
2023-01-05 11:44:55,143 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4220098853111267, 'Total loss': 0.4220098853111267} | train loss {'Reaction outcome loss': 0.4132832509838717, 'Total loss': 0.4132832509838717}
2023-01-05 11:44:55,144 INFO:     Found new best model at epoch 24
2023-01-05 11:44:55,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:55,146 INFO:     Epoch: 25
2023-01-05 11:44:57,289 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46651107470194497, 'Total loss': 0.46651107470194497} | train loss {'Reaction outcome loss': 0.4120737236759723, 'Total loss': 0.4120737236759723}
2023-01-05 11:44:57,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:57,290 INFO:     Epoch: 26
2023-01-05 11:44:59,462 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44515723586082456, 'Total loss': 0.44515723586082456} | train loss {'Reaction outcome loss': 0.41523414016415494, 'Total loss': 0.41523414016415494}
2023-01-05 11:44:59,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:44:59,462 INFO:     Epoch: 27
2023-01-05 11:45:01,607 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4316447099049886, 'Total loss': 0.4316447099049886} | train loss {'Reaction outcome loss': 0.4053644048124014, 'Total loss': 0.4053644048124014}
2023-01-05 11:45:01,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:01,608 INFO:     Epoch: 28
2023-01-05 11:45:03,744 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44341313242912295, 'Total loss': 0.44341313242912295} | train loss {'Reaction outcome loss': 0.4049799255892258, 'Total loss': 0.4049799255892258}
2023-01-05 11:45:03,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:03,744 INFO:     Epoch: 29
2023-01-05 11:45:05,949 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4385841369628906, 'Total loss': 0.4385841369628906} | train loss {'Reaction outcome loss': 0.3980610068309178, 'Total loss': 0.3980610068309178}
2023-01-05 11:45:05,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:05,950 INFO:     Epoch: 30
2023-01-05 11:45:08,140 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4440959443648656, 'Total loss': 0.4440959443648656} | train loss {'Reaction outcome loss': 0.3950052579145354, 'Total loss': 0.3950052579145354}
2023-01-05 11:45:08,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:08,140 INFO:     Epoch: 31
2023-01-05 11:45:10,308 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4267492532730103, 'Total loss': 0.4267492532730103} | train loss {'Reaction outcome loss': 0.3949631289562163, 'Total loss': 0.3949631289562163}
2023-01-05 11:45:10,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:10,308 INFO:     Epoch: 32
2023-01-05 11:45:12,461 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43992807070414225, 'Total loss': 0.43992807070414225} | train loss {'Reaction outcome loss': 0.3875320367111626, 'Total loss': 0.3875320367111626}
2023-01-05 11:45:12,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:12,462 INFO:     Epoch: 33
2023-01-05 11:45:14,608 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43626954505840937, 'Total loss': 0.43626954505840937} | train loss {'Reaction outcome loss': 0.3840864938196292, 'Total loss': 0.3840864938196292}
2023-01-05 11:45:14,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:14,609 INFO:     Epoch: 34
2023-01-05 11:45:16,774 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4658339401086172, 'Total loss': 0.4658339401086172} | train loss {'Reaction outcome loss': 0.3828301128497623, 'Total loss': 0.3828301128497623}
2023-01-05 11:45:16,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:16,774 INFO:     Epoch: 35
2023-01-05 11:45:18,947 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4449894686539968, 'Total loss': 0.4449894686539968} | train loss {'Reaction outcome loss': 0.38177438360043814, 'Total loss': 0.38177438360043814}
2023-01-05 11:45:18,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:18,948 INFO:     Epoch: 36
2023-01-05 11:45:21,110 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44589512844880425, 'Total loss': 0.44589512844880425} | train loss {'Reaction outcome loss': 0.3731769128611802, 'Total loss': 0.3731769128611802}
2023-01-05 11:45:21,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:21,110 INFO:     Epoch: 37
2023-01-05 11:45:23,260 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4305482586224874, 'Total loss': 0.4305482586224874} | train loss {'Reaction outcome loss': 0.3743126645200089, 'Total loss': 0.3743126645200089}
2023-01-05 11:45:23,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:23,260 INFO:     Epoch: 38
2023-01-05 11:45:25,434 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45317702889442446, 'Total loss': 0.45317702889442446} | train loss {'Reaction outcome loss': 0.3702177873103197, 'Total loss': 0.3702177873103197}
2023-01-05 11:45:25,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:25,435 INFO:     Epoch: 39
2023-01-05 11:45:27,627 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47925545275211334, 'Total loss': 0.47925545275211334} | train loss {'Reaction outcome loss': 0.3642114957639887, 'Total loss': 0.3642114957639887}
2023-01-05 11:45:27,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:27,627 INFO:     Epoch: 40
2023-01-05 11:45:29,806 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.444277094801267, 'Total loss': 0.444277094801267} | train loss {'Reaction outcome loss': 0.35897349254211364, 'Total loss': 0.35897349254211364}
2023-01-05 11:45:29,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:29,807 INFO:     Epoch: 41
2023-01-05 11:45:31,999 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4681011339028676, 'Total loss': 0.4681011339028676} | train loss {'Reaction outcome loss': 0.3553245415379855, 'Total loss': 0.3553245415379855}
2023-01-05 11:45:31,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:31,999 INFO:     Epoch: 42
2023-01-05 11:45:34,157 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42410344978173575, 'Total loss': 0.42410344978173575} | train loss {'Reaction outcome loss': 0.35282223472633945, 'Total loss': 0.35282223472633945}
2023-01-05 11:45:34,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:34,157 INFO:     Epoch: 43
2023-01-05 11:45:36,330 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4679723302523295, 'Total loss': 0.4679723302523295} | train loss {'Reaction outcome loss': 0.34675193206820676, 'Total loss': 0.34675193206820676}
2023-01-05 11:45:36,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:36,331 INFO:     Epoch: 44
2023-01-05 11:45:38,502 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4213577369848887, 'Total loss': 0.4213577369848887} | train loss {'Reaction outcome loss': 0.34521877637892856, 'Total loss': 0.34521877637892856}
2023-01-05 11:45:38,502 INFO:     Found new best model at epoch 44
2023-01-05 11:45:38,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:38,503 INFO:     Epoch: 45
2023-01-05 11:45:40,716 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4446804702281952, 'Total loss': 0.4446804702281952} | train loss {'Reaction outcome loss': 0.343564355389521, 'Total loss': 0.343564355389521}
2023-01-05 11:45:40,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:40,717 INFO:     Epoch: 46
2023-01-05 11:45:42,894 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43074708779652915, 'Total loss': 0.43074708779652915} | train loss {'Reaction outcome loss': 0.34244836428427955, 'Total loss': 0.34244836428427955}
2023-01-05 11:45:42,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:42,895 INFO:     Epoch: 47
2023-01-05 11:45:45,037 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4598099837700526, 'Total loss': 0.4598099837700526} | train loss {'Reaction outcome loss': 0.33518934857759236, 'Total loss': 0.33518934857759236}
2023-01-05 11:45:45,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:45,037 INFO:     Epoch: 48
2023-01-05 11:45:47,184 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4432654236753782, 'Total loss': 0.4432654236753782} | train loss {'Reaction outcome loss': 0.34130581090435225, 'Total loss': 0.34130581090435225}
2023-01-05 11:45:47,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:47,185 INFO:     Epoch: 49
2023-01-05 11:45:49,359 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46223863661289216, 'Total loss': 0.46223863661289216} | train loss {'Reaction outcome loss': 0.3285200859719235, 'Total loss': 0.3285200859719235}
2023-01-05 11:45:49,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:49,360 INFO:     Epoch: 50
2023-01-05 11:45:51,546 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42547492881615956, 'Total loss': 0.42547492881615956} | train loss {'Reaction outcome loss': 0.3264499555210775, 'Total loss': 0.3264499555210775}
2023-01-05 11:45:51,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:51,547 INFO:     Epoch: 51
2023-01-05 11:45:53,713 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41669984261194865, 'Total loss': 0.41669984261194865} | train loss {'Reaction outcome loss': 0.3321105317895163, 'Total loss': 0.3321105317895163}
2023-01-05 11:45:53,713 INFO:     Found new best model at epoch 51
2023-01-05 11:45:53,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:53,715 INFO:     Epoch: 52
2023-01-05 11:45:55,866 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4036220878362656, 'Total loss': 0.4036220878362656} | train loss {'Reaction outcome loss': 0.3183714185138687, 'Total loss': 0.3183714185138687}
2023-01-05 11:45:55,866 INFO:     Found new best model at epoch 52
2023-01-05 11:45:55,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:55,868 INFO:     Epoch: 53
2023-01-05 11:45:58,121 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4374326288700104, 'Total loss': 0.4374326288700104} | train loss {'Reaction outcome loss': 0.31824657556328534, 'Total loss': 0.31824657556328534}
2023-01-05 11:45:58,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:45:58,122 INFO:     Epoch: 54
2023-01-05 11:46:00,340 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44519095321496327, 'Total loss': 0.44519095321496327} | train loss {'Reaction outcome loss': 0.31986098190507306, 'Total loss': 0.31986098190507306}
2023-01-05 11:46:00,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:00,340 INFO:     Epoch: 55
2023-01-05 11:46:02,321 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44281527598698933, 'Total loss': 0.44281527598698933} | train loss {'Reaction outcome loss': 0.31578066642480207, 'Total loss': 0.31578066642480207}
2023-01-05 11:46:02,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:02,322 INFO:     Epoch: 56
2023-01-05 11:46:04,465 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45832136273384094, 'Total loss': 0.45832136273384094} | train loss {'Reaction outcome loss': 0.3129760745630368, 'Total loss': 0.3129760745630368}
2023-01-05 11:46:04,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:04,466 INFO:     Epoch: 57
2023-01-05 11:46:06,608 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4201072990894318, 'Total loss': 0.4201072990894318} | train loss {'Reaction outcome loss': 0.31307942745702794, 'Total loss': 0.31307942745702794}
2023-01-05 11:46:06,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:06,608 INFO:     Epoch: 58
2023-01-05 11:46:08,759 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4212587962547938, 'Total loss': 0.4212587962547938} | train loss {'Reaction outcome loss': 0.3030388468358706, 'Total loss': 0.3030388468358706}
2023-01-05 11:46:08,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:08,759 INFO:     Epoch: 59
2023-01-05 11:46:10,926 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4241817340254784, 'Total loss': 0.4241817340254784} | train loss {'Reaction outcome loss': 0.3017264791505431, 'Total loss': 0.3017264791505431}
2023-01-05 11:46:10,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:10,926 INFO:     Epoch: 60
2023-01-05 11:46:13,098 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4227785031000773, 'Total loss': 0.4227785031000773} | train loss {'Reaction outcome loss': 0.3085477158481033, 'Total loss': 0.3085477158481033}
2023-01-05 11:46:13,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:13,099 INFO:     Epoch: 61
2023-01-05 11:46:15,269 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45386091272036233, 'Total loss': 0.45386091272036233} | train loss {'Reaction outcome loss': 0.30452787655570446, 'Total loss': 0.30452787655570446}
2023-01-05 11:46:15,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:15,269 INFO:     Epoch: 62
2023-01-05 11:46:17,454 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41311148007710774, 'Total loss': 0.41311148007710774} | train loss {'Reaction outcome loss': 0.30671257375056993, 'Total loss': 0.30671257375056993}
2023-01-05 11:46:17,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:17,454 INFO:     Epoch: 63
2023-01-05 11:46:19,629 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4143306771914164, 'Total loss': 0.4143306771914164} | train loss {'Reaction outcome loss': 0.30037175939293975, 'Total loss': 0.30037175939293975}
2023-01-05 11:46:19,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:19,630 INFO:     Epoch: 64
2023-01-05 11:46:21,812 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40969510475794474, 'Total loss': 0.40969510475794474} | train loss {'Reaction outcome loss': 0.2938748515254754, 'Total loss': 0.2938748515254754}
2023-01-05 11:46:21,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:21,812 INFO:     Epoch: 65
2023-01-05 11:46:23,989 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46254823803901673, 'Total loss': 0.46254823803901673} | train loss {'Reaction outcome loss': 0.29220691344798255, 'Total loss': 0.29220691344798255}
2023-01-05 11:46:23,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:23,989 INFO:     Epoch: 66
2023-01-05 11:46:26,183 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4145448714494705, 'Total loss': 0.4145448714494705} | train loss {'Reaction outcome loss': 0.29439740367099265, 'Total loss': 0.29439740367099265}
2023-01-05 11:46:26,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:26,184 INFO:     Epoch: 67
2023-01-05 11:46:28,378 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43824915687243143, 'Total loss': 0.43824915687243143} | train loss {'Reaction outcome loss': 0.2893782806875258, 'Total loss': 0.2893782806875258}
2023-01-05 11:46:28,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:28,379 INFO:     Epoch: 68
2023-01-05 11:46:30,531 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40110182265440625, 'Total loss': 0.40110182265440625} | train loss {'Reaction outcome loss': 0.2850262927637849, 'Total loss': 0.2850262927637849}
2023-01-05 11:46:30,531 INFO:     Found new best model at epoch 68
2023-01-05 11:46:30,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:30,532 INFO:     Epoch: 69
2023-01-05 11:46:32,671 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42305898368358613, 'Total loss': 0.42305898368358613} | train loss {'Reaction outcome loss': 0.286539366771383, 'Total loss': 0.286539366771383}
2023-01-05 11:46:32,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:32,672 INFO:     Epoch: 70
2023-01-05 11:46:34,849 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4063449631134669, 'Total loss': 0.4063449631134669} | train loss {'Reaction outcome loss': 0.29156335806373224, 'Total loss': 0.29156335806373224}
2023-01-05 11:46:34,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:34,850 INFO:     Epoch: 71
2023-01-05 11:46:37,017 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40064642230669656, 'Total loss': 0.40064642230669656} | train loss {'Reaction outcome loss': 0.28209446905187535, 'Total loss': 0.28209446905187535}
2023-01-05 11:46:37,017 INFO:     Found new best model at epoch 71
2023-01-05 11:46:37,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:37,019 INFO:     Epoch: 72
2023-01-05 11:46:39,176 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41446401278177897, 'Total loss': 0.41446401278177897} | train loss {'Reaction outcome loss': 0.28064670341109543, 'Total loss': 0.28064670341109543}
2023-01-05 11:46:39,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:39,176 INFO:     Epoch: 73
2023-01-05 11:46:41,365 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41805624862511953, 'Total loss': 0.41805624862511953} | train loss {'Reaction outcome loss': 0.2770799995679072, 'Total loss': 0.2770799995679072}
2023-01-05 11:46:41,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:41,366 INFO:     Epoch: 74
2023-01-05 11:46:43,531 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.434935650229454, 'Total loss': 0.434935650229454} | train loss {'Reaction outcome loss': 0.2811938486993313, 'Total loss': 0.2811938486993313}
2023-01-05 11:46:43,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:43,531 INFO:     Epoch: 75
2023-01-05 11:46:45,701 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4381663509955009, 'Total loss': 0.4381663509955009} | train loss {'Reaction outcome loss': 0.27943188855794365, 'Total loss': 0.27943188855794365}
2023-01-05 11:46:45,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:45,702 INFO:     Epoch: 76
2023-01-05 11:46:47,857 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41859003603458406, 'Total loss': 0.41859003603458406} | train loss {'Reaction outcome loss': 0.27841355416264774, 'Total loss': 0.27841355416264774}
2023-01-05 11:46:47,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:47,858 INFO:     Epoch: 77
2023-01-05 11:46:50,022 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4172262450059255, 'Total loss': 0.4172262450059255} | train loss {'Reaction outcome loss': 0.2760647053995072, 'Total loss': 0.2760647053995072}
2023-01-05 11:46:50,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:50,022 INFO:     Epoch: 78
2023-01-05 11:46:52,175 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3872826710343361, 'Total loss': 0.3872826710343361} | train loss {'Reaction outcome loss': 0.27036437677347275, 'Total loss': 0.27036437677347275}
2023-01-05 11:46:52,175 INFO:     Found new best model at epoch 78
2023-01-05 11:46:52,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:52,177 INFO:     Epoch: 79
2023-01-05 11:46:54,344 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43349372744560244, 'Total loss': 0.43349372744560244} | train loss {'Reaction outcome loss': 0.2724784885529792, 'Total loss': 0.2724784885529792}
2023-01-05 11:46:54,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:54,345 INFO:     Epoch: 80
2023-01-05 11:46:56,521 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4292888561884562, 'Total loss': 0.4292888561884562} | train loss {'Reaction outcome loss': 0.2710556097812816, 'Total loss': 0.2710556097812816}
2023-01-05 11:46:56,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:56,521 INFO:     Epoch: 81
2023-01-05 11:46:58,701 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4018701712290446, 'Total loss': 0.4018701712290446} | train loss {'Reaction outcome loss': 0.272351015238125, 'Total loss': 0.272351015238125}
2023-01-05 11:46:58,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:46:58,702 INFO:     Epoch: 82
2023-01-05 11:47:00,877 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41784924318393074, 'Total loss': 0.41784924318393074} | train loss {'Reaction outcome loss': 0.26592282930032657, 'Total loss': 0.26592282930032657}
2023-01-05 11:47:00,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:00,877 INFO:     Epoch: 83
2023-01-05 11:47:03,043 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41560135781764984, 'Total loss': 0.41560135781764984} | train loss {'Reaction outcome loss': 0.2631496665898428, 'Total loss': 0.2631496665898428}
2023-01-05 11:47:03,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:03,043 INFO:     Epoch: 84
2023-01-05 11:47:05,215 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45243152777353923, 'Total loss': 0.45243152777353923} | train loss {'Reaction outcome loss': 0.26393747905316334, 'Total loss': 0.26393747905316334}
2023-01-05 11:47:05,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:05,215 INFO:     Epoch: 85
2023-01-05 11:47:07,361 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45012203653653465, 'Total loss': 0.45012203653653465} | train loss {'Reaction outcome loss': 0.2624036819818648, 'Total loss': 0.2624036819818648}
2023-01-05 11:47:07,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:07,362 INFO:     Epoch: 86
2023-01-05 11:47:09,503 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4457201143105825, 'Total loss': 0.4457201143105825} | train loss {'Reaction outcome loss': 0.2680637771700801, 'Total loss': 0.2680637771700801}
2023-01-05 11:47:09,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:09,504 INFO:     Epoch: 87
2023-01-05 11:47:11,658 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4434424489736557, 'Total loss': 0.4434424489736557} | train loss {'Reaction outcome loss': 0.26111608472003833, 'Total loss': 0.26111608472003833}
2023-01-05 11:47:11,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:11,659 INFO:     Epoch: 88
2023-01-05 11:47:13,819 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3856734702984492, 'Total loss': 0.3856734702984492} | train loss {'Reaction outcome loss': 0.26237670285795356, 'Total loss': 0.26237670285795356}
2023-01-05 11:47:13,819 INFO:     Found new best model at epoch 88
2023-01-05 11:47:13,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:13,820 INFO:     Epoch: 89
2023-01-05 11:47:15,992 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42882943550745645, 'Total loss': 0.42882943550745645} | train loss {'Reaction outcome loss': 0.2540208012578397, 'Total loss': 0.2540208012578397}
2023-01-05 11:47:15,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:15,992 INFO:     Epoch: 90
2023-01-05 11:47:18,162 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4177231142918269, 'Total loss': 0.4177231142918269} | train loss {'Reaction outcome loss': 0.2670764875890761, 'Total loss': 0.2670764875890761}
2023-01-05 11:47:18,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:18,162 INFO:     Epoch: 91
2023-01-05 11:47:20,334 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41606152057647705, 'Total loss': 0.41606152057647705} | train loss {'Reaction outcome loss': 0.2540619731527696, 'Total loss': 0.2540619731527696}
2023-01-05 11:47:20,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:20,334 INFO:     Epoch: 92
2023-01-05 11:47:22,516 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4383477171262105, 'Total loss': 0.4383477171262105} | train loss {'Reaction outcome loss': 0.25378276037038827, 'Total loss': 0.25378276037038827}
2023-01-05 11:47:22,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:22,516 INFO:     Epoch: 93
2023-01-05 11:47:24,706 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42943088213602704, 'Total loss': 0.42943088213602704} | train loss {'Reaction outcome loss': 0.2527182633158102, 'Total loss': 0.2527182633158102}
2023-01-05 11:47:24,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:24,707 INFO:     Epoch: 94
2023-01-05 11:47:26,890 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4224197198947271, 'Total loss': 0.4224197198947271} | train loss {'Reaction outcome loss': 0.25156167275961555, 'Total loss': 0.25156167275961555}
2023-01-05 11:47:26,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:26,890 INFO:     Epoch: 95
2023-01-05 11:47:29,078 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4077521234750748, 'Total loss': 0.4077521234750748} | train loss {'Reaction outcome loss': 0.2615599109512159, 'Total loss': 0.2615599109512159}
2023-01-05 11:47:29,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:29,078 INFO:     Epoch: 96
2023-01-05 11:47:31,251 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4453522950410843, 'Total loss': 0.4453522950410843} | train loss {'Reaction outcome loss': 0.25290801890853404, 'Total loss': 0.25290801890853404}
2023-01-05 11:47:31,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:31,252 INFO:     Epoch: 97
2023-01-05 11:47:33,420 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42139622022708256, 'Total loss': 0.42139622022708256} | train loss {'Reaction outcome loss': 0.24707261639704342, 'Total loss': 0.24707261639704342}
2023-01-05 11:47:33,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:33,420 INFO:     Epoch: 98
2023-01-05 11:47:35,596 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4209397288660208, 'Total loss': 0.4209397288660208} | train loss {'Reaction outcome loss': 0.24672608075508787, 'Total loss': 0.24672608075508787}
2023-01-05 11:47:35,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:35,596 INFO:     Epoch: 99
2023-01-05 11:47:37,806 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.464748740196228, 'Total loss': 0.464748740196228} | train loss {'Reaction outcome loss': 0.24763887097877502, 'Total loss': 0.24763887097877502}
2023-01-05 11:47:37,806 INFO:     Best model found after epoch 89 of 100.
2023-01-05 11:47:37,806 INFO:   Done with stage: TRAINING
2023-01-05 11:47:37,806 INFO:   Starting stage: EVALUATION
2023-01-05 11:47:37,933 INFO:   Done with stage: EVALUATION
2023-01-05 11:47:37,933 INFO:   Leaving out SEQ value Fold_9
2023-01-05 11:47:37,946 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:47:37,946 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:47:38,596 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:47:38,596 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:47:38,666 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:47:38,666 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:47:38,666 INFO:     No hyperparam tuning for this model
2023-01-05 11:47:38,666 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:47:38,666 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:47:38,667 INFO:     None feature selector for col prot
2023-01-05 11:47:38,667 INFO:     None feature selector for col prot
2023-01-05 11:47:38,667 INFO:     None feature selector for col prot
2023-01-05 11:47:38,668 INFO:     None feature selector for col chem
2023-01-05 11:47:38,668 INFO:     None feature selector for col chem
2023-01-05 11:47:38,668 INFO:     None feature selector for col chem
2023-01-05 11:47:38,668 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:47:38,668 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:47:38,670 INFO:     Number of params in model 72901
2023-01-05 11:47:38,673 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:47:38,673 INFO:   Starting stage: TRAINING
2023-01-05 11:47:38,733 INFO:     Val loss before train {'Reaction outcome loss': 0.9885051826635997, 'Total loss': 0.9885051826635997}
2023-01-05 11:47:38,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:38,733 INFO:     Epoch: 0
2023-01-05 11:47:40,900 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8451458414395651, 'Total loss': 0.8451458414395651} | train loss {'Reaction outcome loss': 0.9588248694900179, 'Total loss': 0.9588248694900179}
2023-01-05 11:47:40,900 INFO:     Found new best model at epoch 0
2023-01-05 11:47:40,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:40,901 INFO:     Epoch: 1
2023-01-05 11:47:43,042 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6617830653985342, 'Total loss': 0.6617830653985342} | train loss {'Reaction outcome loss': 0.7878463061621589, 'Total loss': 0.7878463061621589}
2023-01-05 11:47:43,042 INFO:     Found new best model at epoch 1
2023-01-05 11:47:43,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:43,043 INFO:     Epoch: 2
2023-01-05 11:47:45,184 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5075207968552907, 'Total loss': 0.5075207968552907} | train loss {'Reaction outcome loss': 0.6087875159552497, 'Total loss': 0.6087875159552497}
2023-01-05 11:47:45,185 INFO:     Found new best model at epoch 2
2023-01-05 11:47:45,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:45,186 INFO:     Epoch: 3
2023-01-05 11:47:47,348 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48283474644025165, 'Total loss': 0.48283474644025165} | train loss {'Reaction outcome loss': 0.5333128585106265, 'Total loss': 0.5333128585106265}
2023-01-05 11:47:47,348 INFO:     Found new best model at epoch 3
2023-01-05 11:47:47,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:47,349 INFO:     Epoch: 4
2023-01-05 11:47:49,503 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46665139496326447, 'Total loss': 0.46665139496326447} | train loss {'Reaction outcome loss': 0.5146169963218, 'Total loss': 0.5146169963218}
2023-01-05 11:47:49,503 INFO:     Found new best model at epoch 4
2023-01-05 11:47:49,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:49,504 INFO:     Epoch: 5
2023-01-05 11:47:51,662 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4705048183600108, 'Total loss': 0.4705048183600108} | train loss {'Reaction outcome loss': 0.5008295385615669, 'Total loss': 0.5008295385615669}
2023-01-05 11:47:51,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:51,662 INFO:     Epoch: 6
2023-01-05 11:47:53,807 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5155965447425842, 'Total loss': 0.5155965447425842} | train loss {'Reaction outcome loss': 0.4896424454059044, 'Total loss': 0.4896424454059044}
2023-01-05 11:47:53,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:53,808 INFO:     Epoch: 7
2023-01-05 11:47:55,900 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46487047473589577, 'Total loss': 0.46487047473589577} | train loss {'Reaction outcome loss': 0.48037656043132726, 'Total loss': 0.48037656043132726}
2023-01-05 11:47:55,900 INFO:     Found new best model at epoch 7
2023-01-05 11:47:55,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:55,902 INFO:     Epoch: 8
2023-01-05 11:47:58,065 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4454935034116109, 'Total loss': 0.4454935034116109} | train loss {'Reaction outcome loss': 0.4753280621375481, 'Total loss': 0.4753280621375481}
2023-01-05 11:47:58,065 INFO:     Found new best model at epoch 8
2023-01-05 11:47:58,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:47:58,067 INFO:     Epoch: 9
2023-01-05 11:48:00,214 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45321869651476543, 'Total loss': 0.45321869651476543} | train loss {'Reaction outcome loss': 0.47139565749977624, 'Total loss': 0.47139565749977624}
2023-01-05 11:48:00,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:00,215 INFO:     Epoch: 10
2023-01-05 11:48:02,337 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43322441875934603, 'Total loss': 0.43322441875934603} | train loss {'Reaction outcome loss': 0.460594146192944, 'Total loss': 0.460594146192944}
2023-01-05 11:48:02,338 INFO:     Found new best model at epoch 10
2023-01-05 11:48:02,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:02,339 INFO:     Epoch: 11
2023-01-05 11:48:04,449 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44162101248900093, 'Total loss': 0.44162101248900093} | train loss {'Reaction outcome loss': 0.4572327765398217, 'Total loss': 0.4572327765398217}
2023-01-05 11:48:04,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:04,450 INFO:     Epoch: 12
2023-01-05 11:48:06,589 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4315584510564804, 'Total loss': 0.4315584510564804} | train loss {'Reaction outcome loss': 0.4526316019414115, 'Total loss': 0.4526316019414115}
2023-01-05 11:48:06,590 INFO:     Found new best model at epoch 12
2023-01-05 11:48:06,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:06,591 INFO:     Epoch: 13
2023-01-05 11:48:08,683 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4297832002242406, 'Total loss': 0.4297832002242406} | train loss {'Reaction outcome loss': 0.44916583129959387, 'Total loss': 0.44916583129959387}
2023-01-05 11:48:08,684 INFO:     Found new best model at epoch 13
2023-01-05 11:48:08,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:08,685 INFO:     Epoch: 14
2023-01-05 11:48:10,803 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45441643297672274, 'Total loss': 0.45441643297672274} | train loss {'Reaction outcome loss': 0.4447575837210582, 'Total loss': 0.4447575837210582}
2023-01-05 11:48:10,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:10,803 INFO:     Epoch: 15
2023-01-05 11:48:12,901 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45277581214904783, 'Total loss': 0.45277581214904783} | train loss {'Reaction outcome loss': 0.4390804459252497, 'Total loss': 0.4390804459252497}
2023-01-05 11:48:12,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:12,902 INFO:     Epoch: 16
2023-01-05 11:48:15,011 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40893578131993613, 'Total loss': 0.40893578131993613} | train loss {'Reaction outcome loss': 0.4387834867204193, 'Total loss': 0.4387834867204193}
2023-01-05 11:48:15,011 INFO:     Found new best model at epoch 16
2023-01-05 11:48:15,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:15,012 INFO:     Epoch: 17
2023-01-05 11:48:17,140 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4179731210072835, 'Total loss': 0.4179731210072835} | train loss {'Reaction outcome loss': 0.43160779861203075, 'Total loss': 0.43160779861203075}
2023-01-05 11:48:17,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:17,140 INFO:     Epoch: 18
2023-01-05 11:48:19,261 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43031808535257976, 'Total loss': 0.43031808535257976} | train loss {'Reaction outcome loss': 0.4355037576199448, 'Total loss': 0.4355037576199448}
2023-01-05 11:48:19,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:19,262 INFO:     Epoch: 19
2023-01-05 11:48:21,432 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4021505482494831, 'Total loss': 0.4021505482494831} | train loss {'Reaction outcome loss': 0.42330756489812893, 'Total loss': 0.42330756489812893}
2023-01-05 11:48:21,432 INFO:     Found new best model at epoch 19
2023-01-05 11:48:21,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:21,434 INFO:     Epoch: 20
2023-01-05 11:48:23,566 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4337822000185649, 'Total loss': 0.4337822000185649} | train loss {'Reaction outcome loss': 0.4235989729853442, 'Total loss': 0.4235989729853442}
2023-01-05 11:48:23,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:23,566 INFO:     Epoch: 21
2023-01-05 11:48:25,706 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4192235390345255, 'Total loss': 0.4192235390345255} | train loss {'Reaction outcome loss': 0.4221913498030962, 'Total loss': 0.4221913498030962}
2023-01-05 11:48:25,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:25,707 INFO:     Epoch: 22
2023-01-05 11:48:27,834 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43455736016233765, 'Total loss': 0.43455736016233765} | train loss {'Reaction outcome loss': 0.41813227863316116, 'Total loss': 0.41813227863316116}
2023-01-05 11:48:27,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:27,835 INFO:     Epoch: 23
2023-01-05 11:48:29,983 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3971517225106557, 'Total loss': 0.3971517225106557} | train loss {'Reaction outcome loss': 0.41130128070494554, 'Total loss': 0.41130128070494554}
2023-01-05 11:48:29,983 INFO:     Found new best model at epoch 23
2023-01-05 11:48:29,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:29,984 INFO:     Epoch: 24
2023-01-05 11:48:32,079 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4041193798184395, 'Total loss': 0.4041193798184395} | train loss {'Reaction outcome loss': 0.40282749031146947, 'Total loss': 0.40282749031146947}
2023-01-05 11:48:32,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:32,079 INFO:     Epoch: 25
2023-01-05 11:48:34,230 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4117686808109283, 'Total loss': 0.4117686808109283} | train loss {'Reaction outcome loss': 0.403460454957111, 'Total loss': 0.403460454957111}
2023-01-05 11:48:34,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:34,230 INFO:     Epoch: 26
2023-01-05 11:48:36,387 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40382226804892224, 'Total loss': 0.40382226804892224} | train loss {'Reaction outcome loss': 0.4042623686012778, 'Total loss': 0.4042623686012778}
2023-01-05 11:48:36,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:36,388 INFO:     Epoch: 27
2023-01-05 11:48:38,540 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40725948512554166, 'Total loss': 0.40725948512554166} | train loss {'Reaction outcome loss': 0.39893743077660127, 'Total loss': 0.39893743077660127}
2023-01-05 11:48:38,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:38,540 INFO:     Epoch: 28
2023-01-05 11:48:40,678 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43782664835453033, 'Total loss': 0.43782664835453033} | train loss {'Reaction outcome loss': 0.3976745241641128, 'Total loss': 0.3976745241641128}
2023-01-05 11:48:40,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:40,679 INFO:     Epoch: 29
2023-01-05 11:48:42,818 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39711434791485467, 'Total loss': 0.39711434791485467} | train loss {'Reaction outcome loss': 0.3973143997799306, 'Total loss': 0.3973143997799306}
2023-01-05 11:48:42,818 INFO:     Found new best model at epoch 29
2023-01-05 11:48:42,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:42,820 INFO:     Epoch: 30
2023-01-05 11:48:44,967 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41146555145581565, 'Total loss': 0.41146555145581565} | train loss {'Reaction outcome loss': 0.3901414823901914, 'Total loss': 0.3901414823901914}
2023-01-05 11:48:44,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:44,968 INFO:     Epoch: 31
2023-01-05 11:48:47,126 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4343984256188075, 'Total loss': 0.4343984256188075} | train loss {'Reaction outcome loss': 0.38438452421313657, 'Total loss': 0.38438452421313657}
2023-01-05 11:48:47,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:47,126 INFO:     Epoch: 32
2023-01-05 11:48:49,282 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45611284375190736, 'Total loss': 0.45611284375190736} | train loss {'Reaction outcome loss': 0.3858114093487715, 'Total loss': 0.3858114093487715}
2023-01-05 11:48:49,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:49,283 INFO:     Epoch: 33
2023-01-05 11:48:51,416 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4083108867208163, 'Total loss': 0.4083108867208163} | train loss {'Reaction outcome loss': 0.3831697766036883, 'Total loss': 0.3831697766036883}
2023-01-05 11:48:51,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:51,416 INFO:     Epoch: 34
2023-01-05 11:48:53,522 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4124406119187673, 'Total loss': 0.4124406119187673} | train loss {'Reaction outcome loss': 0.3813915590137026, 'Total loss': 0.3813915590137026}
2023-01-05 11:48:53,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:53,522 INFO:     Epoch: 35
2023-01-05 11:48:55,641 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47711570660273234, 'Total loss': 0.47711570660273234} | train loss {'Reaction outcome loss': 0.37703793669921637, 'Total loss': 0.37703793669921637}
2023-01-05 11:48:55,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:55,642 INFO:     Epoch: 36
2023-01-05 11:48:57,774 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4365154872337977, 'Total loss': 0.4365154872337977} | train loss {'Reaction outcome loss': 0.3704443975032246, 'Total loss': 0.3704443975032246}
2023-01-05 11:48:57,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:57,774 INFO:     Epoch: 37
2023-01-05 11:48:59,928 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42725992302099863, 'Total loss': 0.42725992302099863} | train loss {'Reaction outcome loss': 0.3749281768381161, 'Total loss': 0.3749281768381161}
2023-01-05 11:48:59,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:48:59,928 INFO:     Epoch: 38
2023-01-05 11:49:02,101 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4035707893470923, 'Total loss': 0.4035707893470923} | train loss {'Reaction outcome loss': 0.37654084108606745, 'Total loss': 0.37654084108606745}
2023-01-05 11:49:02,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:02,101 INFO:     Epoch: 39
2023-01-05 11:49:04,220 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4387433469295502, 'Total loss': 0.4387433469295502} | train loss {'Reaction outcome loss': 0.3698036823231373, 'Total loss': 0.3698036823231373}
2023-01-05 11:49:04,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:04,220 INFO:     Epoch: 40
2023-01-05 11:49:06,357 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41292973260084787, 'Total loss': 0.41292973260084787} | train loss {'Reaction outcome loss': 0.3620899049089338, 'Total loss': 0.3620899049089338}
2023-01-05 11:49:06,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:06,357 INFO:     Epoch: 41
2023-01-05 11:49:08,485 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40989658335844675, 'Total loss': 0.40989658335844675} | train loss {'Reaction outcome loss': 0.36294813851152896, 'Total loss': 0.36294813851152896}
2023-01-05 11:49:08,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:08,485 INFO:     Epoch: 42
2023-01-05 11:49:10,621 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41607712507247924, 'Total loss': 0.41607712507247924} | train loss {'Reaction outcome loss': 0.36014624622507685, 'Total loss': 0.36014624622507685}
2023-01-05 11:49:10,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:10,622 INFO:     Epoch: 43
2023-01-05 11:49:12,759 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44950339794158933, 'Total loss': 0.44950339794158933} | train loss {'Reaction outcome loss': 0.3552655061013507, 'Total loss': 0.3552655061013507}
2023-01-05 11:49:12,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:12,760 INFO:     Epoch: 44
2023-01-05 11:49:14,866 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4089673240979513, 'Total loss': 0.4089673240979513} | train loss {'Reaction outcome loss': 0.3555120799935212, 'Total loss': 0.3555120799935212}
2023-01-05 11:49:14,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:14,866 INFO:     Epoch: 45
2023-01-05 11:49:16,999 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4520099063714345, 'Total loss': 0.4520099063714345} | train loss {'Reaction outcome loss': 0.34986184493903694, 'Total loss': 0.34986184493903694}
2023-01-05 11:49:17,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:17,000 INFO:     Epoch: 46
2023-01-05 11:49:19,149 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42750401894251505, 'Total loss': 0.42750401894251505} | train loss {'Reaction outcome loss': 0.35406600879709216, 'Total loss': 0.35406600879709216}
2023-01-05 11:49:19,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:19,150 INFO:     Epoch: 47
2023-01-05 11:49:21,307 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4282270352045695, 'Total loss': 0.4282270352045695} | train loss {'Reaction outcome loss': 0.3486698590844435, 'Total loss': 0.3486698590844435}
2023-01-05 11:49:21,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:21,307 INFO:     Epoch: 48
2023-01-05 11:49:23,454 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4157677799463272, 'Total loss': 0.4157677799463272} | train loss {'Reaction outcome loss': 0.3433953761564989, 'Total loss': 0.3433953761564989}
2023-01-05 11:49:23,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:23,455 INFO:     Epoch: 49
2023-01-05 11:49:25,613 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4408831129471461, 'Total loss': 0.4408831129471461} | train loss {'Reaction outcome loss': 0.34397958017831304, 'Total loss': 0.34397958017831304}
2023-01-05 11:49:25,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:25,613 INFO:     Epoch: 50
2023-01-05 11:49:27,716 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42296918233235675, 'Total loss': 0.42296918233235675} | train loss {'Reaction outcome loss': 0.3386382080043537, 'Total loss': 0.3386382080043537}
2023-01-05 11:49:27,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:27,717 INFO:     Epoch: 51
2023-01-05 11:49:29,852 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38602849195400873, 'Total loss': 0.38602849195400873} | train loss {'Reaction outcome loss': 0.3395193415374434, 'Total loss': 0.3395193415374434}
2023-01-05 11:49:29,852 INFO:     Found new best model at epoch 51
2023-01-05 11:49:29,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:29,854 INFO:     Epoch: 52
2023-01-05 11:49:31,990 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4211040198802948, 'Total loss': 0.4211040198802948} | train loss {'Reaction outcome loss': 0.32971330452030595, 'Total loss': 0.32971330452030595}
2023-01-05 11:49:31,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:31,991 INFO:     Epoch: 53
2023-01-05 11:49:34,145 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43503239850203196, 'Total loss': 0.43503239850203196} | train loss {'Reaction outcome loss': 0.3312864748176432, 'Total loss': 0.3312864748176432}
2023-01-05 11:49:34,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:34,146 INFO:     Epoch: 54
2023-01-05 11:49:36,373 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4246074169874191, 'Total loss': 0.4246074169874191} | train loss {'Reaction outcome loss': 0.3276057304528943, 'Total loss': 0.3276057304528943}
2023-01-05 11:49:36,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:36,373 INFO:     Epoch: 55
2023-01-05 11:49:38,564 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4204773098230362, 'Total loss': 0.4204773098230362} | train loss {'Reaction outcome loss': 0.3224231754259689, 'Total loss': 0.3224231754259689}
2023-01-05 11:49:38,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:38,564 INFO:     Epoch: 56
2023-01-05 11:49:40,678 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42166800101598106, 'Total loss': 0.42166800101598106} | train loss {'Reaction outcome loss': 0.31816566713752537, 'Total loss': 0.31816566713752537}
2023-01-05 11:49:40,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:40,678 INFO:     Epoch: 57
2023-01-05 11:49:42,820 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41565475265185037, 'Total loss': 0.41565475265185037} | train loss {'Reaction outcome loss': 0.32241076194293744, 'Total loss': 0.32241076194293744}
2023-01-05 11:49:42,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:42,821 INFO:     Epoch: 58
2023-01-05 11:49:44,946 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44098658164342247, 'Total loss': 0.44098658164342247} | train loss {'Reaction outcome loss': 0.3176831646081414, 'Total loss': 0.3176831646081414}
2023-01-05 11:49:44,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:44,946 INFO:     Epoch: 59
2023-01-05 11:49:47,081 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42331908643245697, 'Total loss': 0.42331908643245697} | train loss {'Reaction outcome loss': 0.3160236058960648, 'Total loss': 0.3160236058960648}
2023-01-05 11:49:47,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:47,081 INFO:     Epoch: 60
2023-01-05 11:49:49,212 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42086632202068963, 'Total loss': 0.42086632202068963} | train loss {'Reaction outcome loss': 0.317477551227721, 'Total loss': 0.317477551227721}
2023-01-05 11:49:49,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:49,213 INFO:     Epoch: 61
2023-01-05 11:49:51,352 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43771474560101825, 'Total loss': 0.43771474560101825} | train loss {'Reaction outcome loss': 0.3104034854901315, 'Total loss': 0.3104034854901315}
2023-01-05 11:49:51,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:51,353 INFO:     Epoch: 62
2023-01-05 11:49:53,480 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4201186805963516, 'Total loss': 0.4201186805963516} | train loss {'Reaction outcome loss': 0.3114033514008361, 'Total loss': 0.3114033514008361}
2023-01-05 11:49:53,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:53,480 INFO:     Epoch: 63
2023-01-05 11:49:55,598 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4291197876135508, 'Total loss': 0.4291197876135508} | train loss {'Reaction outcome loss': 0.30691201063076945, 'Total loss': 0.30691201063076945}
2023-01-05 11:49:55,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:55,599 INFO:     Epoch: 64
2023-01-05 11:49:57,745 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38175711234410603, 'Total loss': 0.38175711234410603} | train loss {'Reaction outcome loss': 0.30189659300321425, 'Total loss': 0.30189659300321425}
2023-01-05 11:49:57,745 INFO:     Found new best model at epoch 64
2023-01-05 11:49:57,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:57,747 INFO:     Epoch: 65
2023-01-05 11:49:59,898 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3859065443277359, 'Total loss': 0.3859065443277359} | train loss {'Reaction outcome loss': 0.3147609863756564, 'Total loss': 0.3147609863756564}
2023-01-05 11:49:59,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:49:59,898 INFO:     Epoch: 66
2023-01-05 11:50:02,041 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4064700971978406, 'Total loss': 0.4064700971978406} | train loss {'Reaction outcome loss': 0.3066029929603538, 'Total loss': 0.3066029929603538}
2023-01-05 11:50:02,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:02,042 INFO:     Epoch: 67
2023-01-05 11:50:04,175 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44031273424625395, 'Total loss': 0.44031273424625395} | train loss {'Reaction outcome loss': 0.29242709226036157, 'Total loss': 0.29242709226036157}
2023-01-05 11:50:04,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:04,176 INFO:     Epoch: 68
2023-01-05 11:50:06,143 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3907874544461568, 'Total loss': 0.3907874544461568} | train loss {'Reaction outcome loss': 0.2990471545715619, 'Total loss': 0.2990471545715619}
2023-01-05 11:50:06,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:06,143 INFO:     Epoch: 69
2023-01-05 11:50:08,276 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45697988867759703, 'Total loss': 0.45697988867759703} | train loss {'Reaction outcome loss': 0.29377214845786565, 'Total loss': 0.29377214845786565}
2023-01-05 11:50:08,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:08,276 INFO:     Epoch: 70
2023-01-05 11:50:10,428 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.386827744046847, 'Total loss': 0.386827744046847} | train loss {'Reaction outcome loss': 0.29508769795652073, 'Total loss': 0.29508769795652073}
2023-01-05 11:50:10,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:10,428 INFO:     Epoch: 71
2023-01-05 11:50:12,558 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4115723490715027, 'Total loss': 0.4115723490715027} | train loss {'Reaction outcome loss': 0.2898135387277516, 'Total loss': 0.2898135387277516}
2023-01-05 11:50:12,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:12,559 INFO:     Epoch: 72
2023-01-05 11:50:14,671 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4098574072122574, 'Total loss': 0.4098574072122574} | train loss {'Reaction outcome loss': 0.29893043237554767, 'Total loss': 0.29893043237554767}
2023-01-05 11:50:14,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:14,671 INFO:     Epoch: 73
2023-01-05 11:50:16,803 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3920331617196401, 'Total loss': 0.3920331617196401} | train loss {'Reaction outcome loss': 0.2897189261024668, 'Total loss': 0.2897189261024668}
2023-01-05 11:50:16,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:16,804 INFO:     Epoch: 74
2023-01-05 11:50:18,918 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3783734718958537, 'Total loss': 0.3783734718958537} | train loss {'Reaction outcome loss': 0.28928138062792974, 'Total loss': 0.28928138062792974}
2023-01-05 11:50:18,919 INFO:     Found new best model at epoch 74
2023-01-05 11:50:18,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:18,921 INFO:     Epoch: 75
2023-01-05 11:50:21,089 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40089839498202007, 'Total loss': 0.40089839498202007} | train loss {'Reaction outcome loss': 0.28316234260879075, 'Total loss': 0.28316234260879075}
2023-01-05 11:50:21,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:21,090 INFO:     Epoch: 76
2023-01-05 11:50:23,236 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38958544433116915, 'Total loss': 0.38958544433116915} | train loss {'Reaction outcome loss': 0.2883877136411458, 'Total loss': 0.2883877136411458}
2023-01-05 11:50:23,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:23,237 INFO:     Epoch: 77
2023-01-05 11:50:25,370 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41676012029250464, 'Total loss': 0.41676012029250464} | train loss {'Reaction outcome loss': 0.2921554934179043, 'Total loss': 0.2921554934179043}
2023-01-05 11:50:25,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:25,371 INFO:     Epoch: 78
2023-01-05 11:50:27,494 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39359048108259836, 'Total loss': 0.39359048108259836} | train loss {'Reaction outcome loss': 0.2791005475310622, 'Total loss': 0.2791005475310622}
2023-01-05 11:50:27,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:27,494 INFO:     Epoch: 79
2023-01-05 11:50:29,626 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40748641391595203, 'Total loss': 0.40748641391595203} | train loss {'Reaction outcome loss': 0.2872543730603082, 'Total loss': 0.2872543730603082}
2023-01-05 11:50:29,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:29,626 INFO:     Epoch: 80
2023-01-05 11:50:31,781 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4280063579479853, 'Total loss': 0.4280063579479853} | train loss {'Reaction outcome loss': 0.2863570186207547, 'Total loss': 0.2863570186207547}
2023-01-05 11:50:31,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:31,782 INFO:     Epoch: 81
2023-01-05 11:50:33,958 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4472516755263011, 'Total loss': 0.4472516755263011} | train loss {'Reaction outcome loss': 0.2815446636238455, 'Total loss': 0.2815446636238455}
2023-01-05 11:50:33,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:33,958 INFO:     Epoch: 82
2023-01-05 11:50:36,093 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.404315568258365, 'Total loss': 0.404315568258365} | train loss {'Reaction outcome loss': 0.2804222014753053, 'Total loss': 0.2804222014753053}
2023-01-05 11:50:36,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:36,093 INFO:     Epoch: 83
2023-01-05 11:50:38,216 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38183949689070384, 'Total loss': 0.38183949689070384} | train loss {'Reaction outcome loss': 0.2788342395457473, 'Total loss': 0.2788342395457473}
2023-01-05 11:50:38,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:38,217 INFO:     Epoch: 84
2023-01-05 11:50:40,339 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43886479089657465, 'Total loss': 0.43886479089657465} | train loss {'Reaction outcome loss': 0.2730315042809196, 'Total loss': 0.2730315042809196}
2023-01-05 11:50:40,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:40,339 INFO:     Epoch: 85
2023-01-05 11:50:42,565 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4107433463136355, 'Total loss': 0.4107433463136355} | train loss {'Reaction outcome loss': 0.2725540142451977, 'Total loss': 0.2725540142451977}
2023-01-05 11:50:42,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:42,565 INFO:     Epoch: 86
2023-01-05 11:50:44,792 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4103062962492307, 'Total loss': 0.4103062962492307} | train loss {'Reaction outcome loss': 0.2733963814149373, 'Total loss': 0.2733963814149373}
2023-01-05 11:50:44,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:44,792 INFO:     Epoch: 87
2023-01-05 11:50:46,990 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44229267636934916, 'Total loss': 0.44229267636934916} | train loss {'Reaction outcome loss': 0.26606748181048534, 'Total loss': 0.26606748181048534}
2023-01-05 11:50:46,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:46,990 INFO:     Epoch: 88
2023-01-05 11:50:49,167 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3910025417804718, 'Total loss': 0.3910025417804718} | train loss {'Reaction outcome loss': 0.2687547888783534, 'Total loss': 0.2687547888783534}
2023-01-05 11:50:49,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:49,169 INFO:     Epoch: 89
2023-01-05 11:50:51,399 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3874931464592616, 'Total loss': 0.3874931464592616} | train loss {'Reaction outcome loss': 0.26843748025487374, 'Total loss': 0.26843748025487374}
2023-01-05 11:50:51,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:51,399 INFO:     Epoch: 90
2023-01-05 11:50:53,634 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3798506061236064, 'Total loss': 0.3798506061236064} | train loss {'Reaction outcome loss': 0.269750839357611, 'Total loss': 0.269750839357611}
2023-01-05 11:50:53,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:53,634 INFO:     Epoch: 91
2023-01-05 11:50:55,863 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3852473894755046, 'Total loss': 0.3852473894755046} | train loss {'Reaction outcome loss': 0.2597719499990888, 'Total loss': 0.2597719499990888}
2023-01-05 11:50:55,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:55,863 INFO:     Epoch: 92
2023-01-05 11:50:58,100 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4237855871518453, 'Total loss': 0.4237855871518453} | train loss {'Reaction outcome loss': 0.2696865736812788, 'Total loss': 0.2696865736812788}
2023-01-05 11:50:58,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:50:58,100 INFO:     Epoch: 93
2023-01-05 11:51:00,324 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4365129311879476, 'Total loss': 0.4365129311879476} | train loss {'Reaction outcome loss': 0.26694836487218626, 'Total loss': 0.26694836487218626}
2023-01-05 11:51:00,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:00,324 INFO:     Epoch: 94
2023-01-05 11:51:02,477 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38815583487351735, 'Total loss': 0.38815583487351735} | train loss {'Reaction outcome loss': 0.2645947510294997, 'Total loss': 0.2645947510294997}
2023-01-05 11:51:02,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:02,478 INFO:     Epoch: 95
2023-01-05 11:51:04,642 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40751843055089315, 'Total loss': 0.40751843055089315} | train loss {'Reaction outcome loss': 0.2597298811658891, 'Total loss': 0.2597298811658891}
2023-01-05 11:51:04,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:04,642 INFO:     Epoch: 96
2023-01-05 11:51:06,795 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4215826511383057, 'Total loss': 0.4215826511383057} | train loss {'Reaction outcome loss': 0.2590728553188761, 'Total loss': 0.2590728553188761}
2023-01-05 11:51:06,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:06,796 INFO:     Epoch: 97
2023-01-05 11:51:08,952 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.407086972395579, 'Total loss': 0.407086972395579} | train loss {'Reaction outcome loss': 0.2629392605791562, 'Total loss': 0.2629392605791562}
2023-01-05 11:51:08,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:08,953 INFO:     Epoch: 98
2023-01-05 11:51:11,087 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4203960041205088, 'Total loss': 0.4203960041205088} | train loss {'Reaction outcome loss': 0.2635020022246524, 'Total loss': 0.2635020022246524}
2023-01-05 11:51:11,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:11,087 INFO:     Epoch: 99
2023-01-05 11:51:13,208 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4426667292912801, 'Total loss': 0.4426667292912801} | train loss {'Reaction outcome loss': 0.2601647255602327, 'Total loss': 0.2601647255602327}
2023-01-05 11:51:13,209 INFO:     Best model found after epoch 75 of 100.
2023-01-05 11:51:13,209 INFO:   Done with stage: TRAINING
2023-01-05 11:51:13,209 INFO:   Starting stage: EVALUATION
2023-01-05 11:51:13,350 INFO:   Done with stage: EVALUATION
2023-01-05 11:51:13,359 INFO:   Leaving out SEQ value Fold_0
2023-01-05 11:51:13,372 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:51:13,372 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:51:14,025 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:51:14,025 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:51:14,095 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:51:14,095 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:51:14,095 INFO:     No hyperparam tuning for this model
2023-01-05 11:51:14,095 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:51:14,095 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:51:14,096 INFO:     None feature selector for col prot
2023-01-05 11:51:14,096 INFO:     None feature selector for col prot
2023-01-05 11:51:14,096 INFO:     None feature selector for col prot
2023-01-05 11:51:14,097 INFO:     None feature selector for col chem
2023-01-05 11:51:14,097 INFO:     None feature selector for col chem
2023-01-05 11:51:14,097 INFO:     None feature selector for col chem
2023-01-05 11:51:14,097 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:51:14,097 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:51:14,098 INFO:     Number of params in model 72901
2023-01-05 11:51:14,101 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:51:14,102 INFO:   Starting stage: TRAINING
2023-01-05 11:51:14,161 INFO:     Val loss before train {'Reaction outcome loss': 1.0868688742319743, 'Total loss': 1.0868688742319743}
2023-01-05 11:51:14,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:14,162 INFO:     Epoch: 0
2023-01-05 11:51:16,313 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8852543830871582, 'Total loss': 0.8852543830871582} | train loss {'Reaction outcome loss': 0.9100768491081948, 'Total loss': 0.9100768491081948}
2023-01-05 11:51:16,313 INFO:     Found new best model at epoch 0
2023-01-05 11:51:16,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:16,314 INFO:     Epoch: 1
2023-01-05 11:51:18,453 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6717854003111522, 'Total loss': 0.6717854003111522} | train loss {'Reaction outcome loss': 0.7246939455614473, 'Total loss': 0.7246939455614473}
2023-01-05 11:51:18,453 INFO:     Found new best model at epoch 1
2023-01-05 11:51:18,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:18,454 INFO:     Epoch: 2
2023-01-05 11:51:20,585 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5793516139189402, 'Total loss': 0.5793516139189402} | train loss {'Reaction outcome loss': 0.5750942707714373, 'Total loss': 0.5750942707714373}
2023-01-05 11:51:20,585 INFO:     Found new best model at epoch 2
2023-01-05 11:51:20,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:20,586 INFO:     Epoch: 3
2023-01-05 11:51:22,738 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5756545861562093, 'Total loss': 0.5756545861562093} | train loss {'Reaction outcome loss': 0.5229100689944559, 'Total loss': 0.5229100689944559}
2023-01-05 11:51:22,738 INFO:     Found new best model at epoch 3
2023-01-05 11:51:22,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:22,739 INFO:     Epoch: 4
2023-01-05 11:51:24,853 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5602528889973958, 'Total loss': 0.5602528889973958} | train loss {'Reaction outcome loss': 0.4995809582463146, 'Total loss': 0.4995809582463146}
2023-01-05 11:51:24,854 INFO:     Found new best model at epoch 4
2023-01-05 11:51:24,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:24,856 INFO:     Epoch: 5
2023-01-05 11:51:27,043 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5510791222254435, 'Total loss': 0.5510791222254435} | train loss {'Reaction outcome loss': 0.4951624743042201, 'Total loss': 0.4951624743042201}
2023-01-05 11:51:27,043 INFO:     Found new best model at epoch 5
2023-01-05 11:51:27,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:27,044 INFO:     Epoch: 6
2023-01-05 11:51:29,178 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5672400156656902, 'Total loss': 0.5672400156656902} | train loss {'Reaction outcome loss': 0.4815404495618639, 'Total loss': 0.4815404495618639}
2023-01-05 11:51:29,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:29,179 INFO:     Epoch: 7
2023-01-05 11:51:31,310 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5569656372070313, 'Total loss': 0.5569656372070313} | train loss {'Reaction outcome loss': 0.4731316629824412, 'Total loss': 0.4731316629824412}
2023-01-05 11:51:31,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:31,311 INFO:     Epoch: 8
2023-01-05 11:51:33,484 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.580206960439682, 'Total loss': 0.580206960439682} | train loss {'Reaction outcome loss': 0.4654326016341683, 'Total loss': 0.4654326016341683}
2023-01-05 11:51:33,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:33,485 INFO:     Epoch: 9
2023-01-05 11:51:35,610 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5557502269744873, 'Total loss': 0.5557502269744873} | train loss {'Reaction outcome loss': 0.4641137499443806, 'Total loss': 0.4641137499443806}
2023-01-05 11:51:35,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:35,610 INFO:     Epoch: 10
2023-01-05 11:51:37,834 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5583924094835917, 'Total loss': 0.5583924094835917} | train loss {'Reaction outcome loss': 0.45683732884426187, 'Total loss': 0.45683732884426187}
2023-01-05 11:51:37,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:37,834 INFO:     Epoch: 11
2023-01-05 11:51:40,047 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5226779679457346, 'Total loss': 0.5226779679457346} | train loss {'Reaction outcome loss': 0.4471272522189321, 'Total loss': 0.4471272522189321}
2023-01-05 11:51:40,047 INFO:     Found new best model at epoch 11
2023-01-05 11:51:40,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:40,048 INFO:     Epoch: 12
2023-01-05 11:51:42,288 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5247983515262604, 'Total loss': 0.5247983515262604} | train loss {'Reaction outcome loss': 0.447107760031728, 'Total loss': 0.447107760031728}
2023-01-05 11:51:42,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:42,289 INFO:     Epoch: 13
2023-01-05 11:51:44,520 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5406913538773854, 'Total loss': 0.5406913538773854} | train loss {'Reaction outcome loss': 0.44358143232164593, 'Total loss': 0.44358143232164593}
2023-01-05 11:51:44,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:44,521 INFO:     Epoch: 14
2023-01-05 11:51:46,705 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5275390366713206, 'Total loss': 0.5275390366713206} | train loss {'Reaction outcome loss': 0.44081182359126364, 'Total loss': 0.44081182359126364}
2023-01-05 11:51:46,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:46,705 INFO:     Epoch: 15
2023-01-05 11:51:48,829 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5638746599356333, 'Total loss': 0.5638746599356333} | train loss {'Reaction outcome loss': 0.4396257786637675, 'Total loss': 0.4396257786637675}
2023-01-05 11:51:48,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:48,829 INFO:     Epoch: 16
2023-01-05 11:51:51,006 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5822407980759938, 'Total loss': 0.5822407980759938} | train loss {'Reaction outcome loss': 0.4318816366530683, 'Total loss': 0.4318816366530683}
2023-01-05 11:51:51,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:51,006 INFO:     Epoch: 17
2023-01-05 11:51:53,176 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5152436077594758, 'Total loss': 0.5152436077594758} | train loss {'Reaction outcome loss': 0.42743730585831796, 'Total loss': 0.42743730585831796}
2023-01-05 11:51:53,176 INFO:     Found new best model at epoch 17
2023-01-05 11:51:53,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:53,177 INFO:     Epoch: 18
2023-01-05 11:51:55,315 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5235542674859365, 'Total loss': 0.5235542674859365} | train loss {'Reaction outcome loss': 0.4201412695820314, 'Total loss': 0.4201412695820314}
2023-01-05 11:51:55,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:55,316 INFO:     Epoch: 19
2023-01-05 11:51:57,479 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5224347074826559, 'Total loss': 0.5224347074826559} | train loss {'Reaction outcome loss': 0.42256591232479923, 'Total loss': 0.42256591232479923}
2023-01-05 11:51:57,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:57,480 INFO:     Epoch: 20
2023-01-05 11:51:59,609 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5262752950191498, 'Total loss': 0.5262752950191498} | train loss {'Reaction outcome loss': 0.41193213977300336, 'Total loss': 0.41193213977300336}
2023-01-05 11:51:59,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:51:59,609 INFO:     Epoch: 21
2023-01-05 11:52:01,807 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5290604720513026, 'Total loss': 0.5290604720513026} | train loss {'Reaction outcome loss': 0.4052738710748453, 'Total loss': 0.4052738710748453}
2023-01-05 11:52:01,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:01,809 INFO:     Epoch: 22
2023-01-05 11:52:04,009 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5516627371311188, 'Total loss': 0.5516627371311188} | train loss {'Reaction outcome loss': 0.40573860963221886, 'Total loss': 0.40573860963221886}
2023-01-05 11:52:04,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:04,009 INFO:     Epoch: 23
2023-01-05 11:52:06,274 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5751548667748769, 'Total loss': 0.5751548667748769} | train loss {'Reaction outcome loss': 0.4027463368473262, 'Total loss': 0.4027463368473262}
2023-01-05 11:52:06,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:06,274 INFO:     Epoch: 24
2023-01-05 11:52:08,528 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5690473973751068, 'Total loss': 0.5690473973751068} | train loss {'Reaction outcome loss': 0.3995012804648302, 'Total loss': 0.3995012804648302}
2023-01-05 11:52:08,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:08,528 INFO:     Epoch: 25
2023-01-05 11:52:10,775 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5227927287419637, 'Total loss': 0.5227927287419637} | train loss {'Reaction outcome loss': 0.3929301022830671, 'Total loss': 0.3929301022830671}
2023-01-05 11:52:10,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:10,775 INFO:     Epoch: 26
2023-01-05 11:52:13,010 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5199550827344258, 'Total loss': 0.5199550827344258} | train loss {'Reaction outcome loss': 0.3924785863309011, 'Total loss': 0.3924785863309011}
2023-01-05 11:52:13,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:13,010 INFO:     Epoch: 27
2023-01-05 11:52:15,193 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5136468748251597, 'Total loss': 0.5136468748251597} | train loss {'Reaction outcome loss': 0.3875101672036804, 'Total loss': 0.3875101672036804}
2023-01-05 11:52:15,193 INFO:     Found new best model at epoch 27
2023-01-05 11:52:15,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:15,194 INFO:     Epoch: 28
2023-01-05 11:52:17,354 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5277767181396484, 'Total loss': 0.5277767181396484} | train loss {'Reaction outcome loss': 0.3848931742900044, 'Total loss': 0.3848931742900044}
2023-01-05 11:52:17,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:17,354 INFO:     Epoch: 29
2023-01-05 11:52:19,508 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5228571434815724, 'Total loss': 0.5228571434815724} | train loss {'Reaction outcome loss': 0.38300113568939, 'Total loss': 0.38300113568939}
2023-01-05 11:52:19,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:19,508 INFO:     Epoch: 30
2023-01-05 11:52:21,665 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5484143078327179, 'Total loss': 0.5484143078327179} | train loss {'Reaction outcome loss': 0.3789003710840305, 'Total loss': 0.3789003710840305}
2023-01-05 11:52:21,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:21,666 INFO:     Epoch: 31
2023-01-05 11:52:23,814 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5389398733774821, 'Total loss': 0.5389398733774821} | train loss {'Reaction outcome loss': 0.37349877598946984, 'Total loss': 0.37349877598946984}
2023-01-05 11:52:23,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:23,814 INFO:     Epoch: 32
2023-01-05 11:52:25,965 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5160815378030141, 'Total loss': 0.5160815378030141} | train loss {'Reaction outcome loss': 0.37221403808815634, 'Total loss': 0.37221403808815634}
2023-01-05 11:52:25,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:25,965 INFO:     Epoch: 33
2023-01-05 11:52:28,127 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5420583675305048, 'Total loss': 0.5420583675305048} | train loss {'Reaction outcome loss': 0.3713164529797152, 'Total loss': 0.3713164529797152}
2023-01-05 11:52:28,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:28,128 INFO:     Epoch: 34
2023-01-05 11:52:30,290 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4842236856619517, 'Total loss': 0.4842236856619517} | train loss {'Reaction outcome loss': 0.37223885270909673, 'Total loss': 0.37223885270909673}
2023-01-05 11:52:30,290 INFO:     Found new best model at epoch 34
2023-01-05 11:52:30,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:30,292 INFO:     Epoch: 35
2023-01-05 11:52:32,453 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5596405585606893, 'Total loss': 0.5596405585606893} | train loss {'Reaction outcome loss': 0.36198940927529855, 'Total loss': 0.36198940927529855}
2023-01-05 11:52:32,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:32,454 INFO:     Epoch: 36
2023-01-05 11:52:34,598 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5045174419879913, 'Total loss': 0.5045174419879913} | train loss {'Reaction outcome loss': 0.35973741761306777, 'Total loss': 0.35973741761306777}
2023-01-05 11:52:34,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:34,598 INFO:     Epoch: 37
2023-01-05 11:52:36,752 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5195826808611552, 'Total loss': 0.5195826808611552} | train loss {'Reaction outcome loss': 0.35543183026576997, 'Total loss': 0.35543183026576997}
2023-01-05 11:52:36,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:36,752 INFO:     Epoch: 38
2023-01-05 11:52:38,910 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5010204414526621, 'Total loss': 0.5010204414526621} | train loss {'Reaction outcome loss': 0.352394995327196, 'Total loss': 0.352394995327196}
2023-01-05 11:52:38,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:38,911 INFO:     Epoch: 39
2023-01-05 11:52:41,102 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5256449073553086, 'Total loss': 0.5256449073553086} | train loss {'Reaction outcome loss': 0.34494676457269347, 'Total loss': 0.34494676457269347}
2023-01-05 11:52:41,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:41,102 INFO:     Epoch: 40
2023-01-05 11:52:43,270 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5223876416683197, 'Total loss': 0.5223876416683197} | train loss {'Reaction outcome loss': 0.35308768105332866, 'Total loss': 0.35308768105332866}
2023-01-05 11:52:43,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:43,270 INFO:     Epoch: 41
2023-01-05 11:52:45,444 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5328268905480703, 'Total loss': 0.5328268905480703} | train loss {'Reaction outcome loss': 0.3386927853970632, 'Total loss': 0.3386927853970632}
2023-01-05 11:52:45,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:45,445 INFO:     Epoch: 42
2023-01-05 11:52:47,593 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.517921061317126, 'Total loss': 0.517921061317126} | train loss {'Reaction outcome loss': 0.33713642140700867, 'Total loss': 0.33713642140700867}
2023-01-05 11:52:47,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:47,593 INFO:     Epoch: 43
2023-01-05 11:52:49,748 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5159985502560933, 'Total loss': 0.5159985502560933} | train loss {'Reaction outcome loss': 0.33360979469479435, 'Total loss': 0.33360979469479435}
2023-01-05 11:52:49,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:49,748 INFO:     Epoch: 44
2023-01-05 11:52:51,918 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5185731142759323, 'Total loss': 0.5185731142759323} | train loss {'Reaction outcome loss': 0.333316995089289, 'Total loss': 0.333316995089289}
2023-01-05 11:52:51,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:51,919 INFO:     Epoch: 45
2023-01-05 11:52:54,079 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5147877196470897, 'Total loss': 0.5147877196470897} | train loss {'Reaction outcome loss': 0.3354523066893546, 'Total loss': 0.3354523066893546}
2023-01-05 11:52:54,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:54,079 INFO:     Epoch: 46
2023-01-05 11:52:56,244 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5143965721130371, 'Total loss': 0.5143965721130371} | train loss {'Reaction outcome loss': 0.3258721907181244, 'Total loss': 0.3258721907181244}
2023-01-05 11:52:56,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:56,244 INFO:     Epoch: 47
2023-01-05 11:52:58,384 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5405688981215159, 'Total loss': 0.5405688981215159} | train loss {'Reaction outcome loss': 0.33195059013682127, 'Total loss': 0.33195059013682127}
2023-01-05 11:52:58,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:52:58,384 INFO:     Epoch: 48
2023-01-05 11:53:00,558 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5270251234372457, 'Total loss': 0.5270251234372457} | train loss {'Reaction outcome loss': 0.3212269446574641, 'Total loss': 0.3212269446574641}
2023-01-05 11:53:00,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:00,559 INFO:     Epoch: 49
2023-01-05 11:53:02,723 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5364433308442433, 'Total loss': 0.5364433308442433} | train loss {'Reaction outcome loss': 0.32672406144331406, 'Total loss': 0.32672406144331406}
2023-01-05 11:53:02,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:02,724 INFO:     Epoch: 50
2023-01-05 11:53:04,896 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5263604541619619, 'Total loss': 0.5263604541619619} | train loss {'Reaction outcome loss': 0.3154332086471093, 'Total loss': 0.3154332086471093}
2023-01-05 11:53:04,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:04,896 INFO:     Epoch: 51
2023-01-05 11:53:07,078 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5111608862876892, 'Total loss': 0.5111608862876892} | train loss {'Reaction outcome loss': 0.316710682721795, 'Total loss': 0.316710682721795}
2023-01-05 11:53:07,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:07,078 INFO:     Epoch: 52
2023-01-05 11:53:09,249 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.554588907957077, 'Total loss': 0.554588907957077} | train loss {'Reaction outcome loss': 0.31347583657144196, 'Total loss': 0.31347583657144196}
2023-01-05 11:53:09,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:09,250 INFO:     Epoch: 53
2023-01-05 11:53:11,415 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5259580572446187, 'Total loss': 0.5259580572446187} | train loss {'Reaction outcome loss': 0.3136578794623161, 'Total loss': 0.3136578794623161}
2023-01-05 11:53:11,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:11,415 INFO:     Epoch: 54
2023-01-05 11:53:13,576 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4942944218715032, 'Total loss': 0.4942944218715032} | train loss {'Reaction outcome loss': 0.3136941968007897, 'Total loss': 0.3136941968007897}
2023-01-05 11:53:13,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:13,577 INFO:     Epoch: 55
2023-01-05 11:53:15,749 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5286108990510304, 'Total loss': 0.5286108990510304} | train loss {'Reaction outcome loss': 0.3049753097423019, 'Total loss': 0.3049753097423019}
2023-01-05 11:53:15,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:15,750 INFO:     Epoch: 56
2023-01-05 11:53:17,911 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5092463930447896, 'Total loss': 0.5092463930447896} | train loss {'Reaction outcome loss': 0.30769705379476947, 'Total loss': 0.30769705379476947}
2023-01-05 11:53:17,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:17,911 INFO:     Epoch: 57
2023-01-05 11:53:20,055 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5515381038188935, 'Total loss': 0.5515381038188935} | train loss {'Reaction outcome loss': 0.29945735010678753, 'Total loss': 0.29945735010678753}
2023-01-05 11:53:20,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:20,056 INFO:     Epoch: 58
2023-01-05 11:53:22,207 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5287993967533111, 'Total loss': 0.5287993967533111} | train loss {'Reaction outcome loss': 0.30562367336484636, 'Total loss': 0.30562367336484636}
2023-01-05 11:53:22,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:22,208 INFO:     Epoch: 59
2023-01-05 11:53:24,368 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48633060057957966, 'Total loss': 0.48633060057957966} | train loss {'Reaction outcome loss': 0.3029374148914196, 'Total loss': 0.3029374148914196}
2023-01-05 11:53:24,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:24,368 INFO:     Epoch: 60
2023-01-05 11:53:26,529 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5321526646614074, 'Total loss': 0.5321526646614074} | train loss {'Reaction outcome loss': 0.2952131996624661, 'Total loss': 0.2952131996624661}
2023-01-05 11:53:26,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:26,529 INFO:     Epoch: 61
2023-01-05 11:53:28,697 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5245742718378703, 'Total loss': 0.5245742718378703} | train loss {'Reaction outcome loss': 0.29748424244568733, 'Total loss': 0.29748424244568733}
2023-01-05 11:53:28,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:28,697 INFO:     Epoch: 62
2023-01-05 11:53:30,866 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5333580940961837, 'Total loss': 0.5333580940961837} | train loss {'Reaction outcome loss': 0.29567804759925737, 'Total loss': 0.29567804759925737}
2023-01-05 11:53:30,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:30,866 INFO:     Epoch: 63
2023-01-05 11:53:32,998 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4872357686360677, 'Total loss': 0.4872357686360677} | train loss {'Reaction outcome loss': 0.2937858983819937, 'Total loss': 0.2937858983819937}
2023-01-05 11:53:32,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:32,999 INFO:     Epoch: 64
2023-01-05 11:53:35,151 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5170845001935959, 'Total loss': 0.5170845001935959} | train loss {'Reaction outcome loss': 0.2944193416594589, 'Total loss': 0.2944193416594589}
2023-01-05 11:53:35,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:35,151 INFO:     Epoch: 65
2023-01-05 11:53:37,303 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5528635402520498, 'Total loss': 0.5528635402520498} | train loss {'Reaction outcome loss': 0.29073567099760483, 'Total loss': 0.29073567099760483}
2023-01-05 11:53:37,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:37,304 INFO:     Epoch: 66
2023-01-05 11:53:39,464 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5437345703442892, 'Total loss': 0.5437345703442892} | train loss {'Reaction outcome loss': 0.28479276203217296, 'Total loss': 0.28479276203217296}
2023-01-05 11:53:39,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:39,465 INFO:     Epoch: 67
2023-01-05 11:53:41,617 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5330637127161026, 'Total loss': 0.5330637127161026} | train loss {'Reaction outcome loss': 0.28663526426484115, 'Total loss': 0.28663526426484115}
2023-01-05 11:53:41,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:41,618 INFO:     Epoch: 68
2023-01-05 11:53:43,766 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5117526799440384, 'Total loss': 0.5117526799440384} | train loss {'Reaction outcome loss': 0.28003163605819653, 'Total loss': 0.28003163605819653}
2023-01-05 11:53:43,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:43,767 INFO:     Epoch: 69
2023-01-05 11:53:45,914 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.521717153986295, 'Total loss': 0.521717153986295} | train loss {'Reaction outcome loss': 0.27656195523475646, 'Total loss': 0.27656195523475646}
2023-01-05 11:53:45,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:45,915 INFO:     Epoch: 70
2023-01-05 11:53:48,073 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5211964766184489, 'Total loss': 0.5211964766184489} | train loss {'Reaction outcome loss': 0.28568390368001306, 'Total loss': 0.28568390368001306}
2023-01-05 11:53:48,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:48,073 INFO:     Epoch: 71
2023-01-05 11:53:50,220 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5101748049259186, 'Total loss': 0.5101748049259186} | train loss {'Reaction outcome loss': 0.28195453016427313, 'Total loss': 0.28195453016427313}
2023-01-05 11:53:50,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:50,220 INFO:     Epoch: 72
2023-01-05 11:53:52,380 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5365028222401936, 'Total loss': 0.5365028222401936} | train loss {'Reaction outcome loss': 0.27924469064404495, 'Total loss': 0.27924469064404495}
2023-01-05 11:53:52,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:52,380 INFO:     Epoch: 73
2023-01-05 11:53:54,532 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5188139200210571, 'Total loss': 0.5188139200210571} | train loss {'Reaction outcome loss': 0.2793290788973988, 'Total loss': 0.2793290788973988}
2023-01-05 11:53:54,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:54,532 INFO:     Epoch: 74
2023-01-05 11:53:56,674 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5703220347563426, 'Total loss': 0.5703220347563426} | train loss {'Reaction outcome loss': 0.28693748918110434, 'Total loss': 0.28693748918110434}
2023-01-05 11:53:56,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:56,675 INFO:     Epoch: 75
2023-01-05 11:53:58,837 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5268671641747157, 'Total loss': 0.5268671641747157} | train loss {'Reaction outcome loss': 0.26853477525232483, 'Total loss': 0.26853477525232483}
2023-01-05 11:53:58,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:53:58,837 INFO:     Epoch: 76
2023-01-05 11:54:01,009 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4913223882516225, 'Total loss': 0.4913223882516225} | train loss {'Reaction outcome loss': 0.27155003338426786, 'Total loss': 0.27155003338426786}
2023-01-05 11:54:01,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:01,009 INFO:     Epoch: 77
2023-01-05 11:54:03,155 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49289065301418306, 'Total loss': 0.49289065301418306} | train loss {'Reaction outcome loss': 0.27730305059167154, 'Total loss': 0.27730305059167154}
2023-01-05 11:54:03,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:03,155 INFO:     Epoch: 78
2023-01-05 11:54:05,294 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5001046905914942, 'Total loss': 0.5001046905914942} | train loss {'Reaction outcome loss': 0.2708811939279311, 'Total loss': 0.2708811939279311}
2023-01-05 11:54:05,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:05,295 INFO:     Epoch: 79
2023-01-05 11:54:07,412 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.511426392197609, 'Total loss': 0.511426392197609} | train loss {'Reaction outcome loss': 0.2711618989366141, 'Total loss': 0.2711618989366141}
2023-01-05 11:54:07,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:07,412 INFO:     Epoch: 80
2023-01-05 11:54:09,496 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5100064814090729, 'Total loss': 0.5100064814090729} | train loss {'Reaction outcome loss': 0.27026716796477346, 'Total loss': 0.27026716796477346}
2023-01-05 11:54:09,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:09,496 INFO:     Epoch: 81
2023-01-05 11:54:11,448 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5148730844259262, 'Total loss': 0.5148730844259262} | train loss {'Reaction outcome loss': 0.26604089525657415, 'Total loss': 0.26604089525657415}
2023-01-05 11:54:11,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:11,449 INFO:     Epoch: 82
2023-01-05 11:54:13,609 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5071296403805415, 'Total loss': 0.5071296403805415} | train loss {'Reaction outcome loss': 0.2661129299374501, 'Total loss': 0.2661129299374501}
2023-01-05 11:54:13,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:13,610 INFO:     Epoch: 83
2023-01-05 11:54:15,764 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4967956284681956, 'Total loss': 0.4967956284681956} | train loss {'Reaction outcome loss': 0.25914863976276054, 'Total loss': 0.25914863976276054}
2023-01-05 11:54:15,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:15,765 INFO:     Epoch: 84
2023-01-05 11:54:17,895 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5306349257628123, 'Total loss': 0.5306349257628123} | train loss {'Reaction outcome loss': 0.26933532005624616, 'Total loss': 0.26933532005624616}
2023-01-05 11:54:17,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:17,895 INFO:     Epoch: 85
2023-01-05 11:54:20,016 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5388376692930857, 'Total loss': 0.5388376692930857} | train loss {'Reaction outcome loss': 0.2629511422158158, 'Total loss': 0.2629511422158158}
2023-01-05 11:54:20,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:20,017 INFO:     Epoch: 86
2023-01-05 11:54:22,155 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5389650702476502, 'Total loss': 0.5389650702476502} | train loss {'Reaction outcome loss': 0.2661427811372781, 'Total loss': 0.2661427811372781}
2023-01-05 11:54:22,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:22,155 INFO:     Epoch: 87
2023-01-05 11:54:24,340 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5063781837622324, 'Total loss': 0.5063781837622324} | train loss {'Reaction outcome loss': 0.2589901745808821, 'Total loss': 0.2589901745808821}
2023-01-05 11:54:24,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:24,340 INFO:     Epoch: 88
2023-01-05 11:54:26,513 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4796894749005636, 'Total loss': 0.4796894749005636} | train loss {'Reaction outcome loss': 0.2617040765981605, 'Total loss': 0.2617040765981605}
2023-01-05 11:54:26,513 INFO:     Found new best model at epoch 88
2023-01-05 11:54:26,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:26,514 INFO:     Epoch: 89
2023-01-05 11:54:28,682 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49359413211544356, 'Total loss': 0.49359413211544356} | train loss {'Reaction outcome loss': 0.26180149723408597, 'Total loss': 0.26180149723408597}
2023-01-05 11:54:28,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:28,682 INFO:     Epoch: 90
2023-01-05 11:54:30,830 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49976288080215453, 'Total loss': 0.49976288080215453} | train loss {'Reaction outcome loss': 0.2522104421059472, 'Total loss': 0.2522104421059472}
2023-01-05 11:54:30,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:30,830 INFO:     Epoch: 91
2023-01-05 11:54:32,978 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5278288662433624, 'Total loss': 0.5278288662433624} | train loss {'Reaction outcome loss': 0.25826599908462405, 'Total loss': 0.25826599908462405}
2023-01-05 11:54:32,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:32,979 INFO:     Epoch: 92
2023-01-05 11:54:35,111 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5327181875705719, 'Total loss': 0.5327181875705719} | train loss {'Reaction outcome loss': 0.2560212454031201, 'Total loss': 0.2560212454031201}
2023-01-05 11:54:35,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:35,111 INFO:     Epoch: 93
2023-01-05 11:54:37,247 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5020617797970772, 'Total loss': 0.5020617797970772} | train loss {'Reaction outcome loss': 0.2550637800599972, 'Total loss': 0.2550637800599972}
2023-01-05 11:54:37,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:37,247 INFO:     Epoch: 94
2023-01-05 11:54:39,387 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49371509353319804, 'Total loss': 0.49371509353319804} | train loss {'Reaction outcome loss': 0.24709634907054204, 'Total loss': 0.24709634907054204}
2023-01-05 11:54:39,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:39,387 INFO:     Epoch: 95
2023-01-05 11:54:41,521 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5328967610994975, 'Total loss': 0.5328967610994975} | train loss {'Reaction outcome loss': 0.24906838489492444, 'Total loss': 0.24906838489492444}
2023-01-05 11:54:41,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:41,521 INFO:     Epoch: 96
2023-01-05 11:54:43,680 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5626080532868704, 'Total loss': 0.5626080532868704} | train loss {'Reaction outcome loss': 0.25002401861885604, 'Total loss': 0.25002401861885604}
2023-01-05 11:54:43,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:43,680 INFO:     Epoch: 97
2023-01-05 11:54:45,810 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5330956329902014, 'Total loss': 0.5330956329902014} | train loss {'Reaction outcome loss': 0.2591260745441609, 'Total loss': 0.2591260745441609}
2023-01-05 11:54:45,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:45,810 INFO:     Epoch: 98
2023-01-05 11:54:47,963 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5454973022143046, 'Total loss': 0.5454973022143046} | train loss {'Reaction outcome loss': 0.24406251545152524, 'Total loss': 0.24406251545152524}
2023-01-05 11:54:47,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:47,963 INFO:     Epoch: 99
2023-01-05 11:54:50,100 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.558329705397288, 'Total loss': 0.558329705397288} | train loss {'Reaction outcome loss': 0.24909415514799801, 'Total loss': 0.24909415514799801}
2023-01-05 11:54:50,102 INFO:     Best model found after epoch 89 of 100.
2023-01-05 11:54:50,102 INFO:   Done with stage: TRAINING
2023-01-05 11:54:50,102 INFO:   Starting stage: EVALUATION
2023-01-05 11:54:50,241 INFO:   Done with stage: EVALUATION
2023-01-05 11:54:50,241 INFO:   Leaving out SEQ value Fold_1
2023-01-05 11:54:50,254 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 11:54:50,254 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:54:50,905 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:54:50,905 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:54:50,974 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:54:50,974 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:54:50,974 INFO:     No hyperparam tuning for this model
2023-01-05 11:54:50,974 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:54:50,974 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:54:50,975 INFO:     None feature selector for col prot
2023-01-05 11:54:50,975 INFO:     None feature selector for col prot
2023-01-05 11:54:50,975 INFO:     None feature selector for col prot
2023-01-05 11:54:50,976 INFO:     None feature selector for col chem
2023-01-05 11:54:50,976 INFO:     None feature selector for col chem
2023-01-05 11:54:50,976 INFO:     None feature selector for col chem
2023-01-05 11:54:50,976 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:54:50,976 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:54:50,977 INFO:     Number of params in model 72901
2023-01-05 11:54:50,981 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:54:50,981 INFO:   Starting stage: TRAINING
2023-01-05 11:54:51,041 INFO:     Val loss before train {'Reaction outcome loss': 0.9985106984774271, 'Total loss': 0.9985106984774271}
2023-01-05 11:54:51,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:51,041 INFO:     Epoch: 0
2023-01-05 11:54:53,178 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8252402186393738, 'Total loss': 0.8252402186393738} | train loss {'Reaction outcome loss': 0.9376077272969744, 'Total loss': 0.9376077272969744}
2023-01-05 11:54:53,178 INFO:     Found new best model at epoch 0
2023-01-05 11:54:53,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:53,179 INFO:     Epoch: 1
2023-01-05 11:54:55,323 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5568626920382181, 'Total loss': 0.5568626920382181} | train loss {'Reaction outcome loss': 0.7146127097700061, 'Total loss': 0.7146127097700061}
2023-01-05 11:54:55,323 INFO:     Found new best model at epoch 1
2023-01-05 11:54:55,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:55,325 INFO:     Epoch: 2
2023-01-05 11:54:57,479 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5076485216617584, 'Total loss': 0.5076485216617584} | train loss {'Reaction outcome loss': 0.5765066113376963, 'Total loss': 0.5765066113376963}
2023-01-05 11:54:57,480 INFO:     Found new best model at epoch 2
2023-01-05 11:54:57,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:57,481 INFO:     Epoch: 3
2023-01-05 11:54:59,627 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.509017288684845, 'Total loss': 0.509017288684845} | train loss {'Reaction outcome loss': 0.5344287075500503, 'Total loss': 0.5344287075500503}
2023-01-05 11:54:59,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:54:59,628 INFO:     Epoch: 4
2023-01-05 11:55:01,748 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48075781067212425, 'Total loss': 0.48075781067212425} | train loss {'Reaction outcome loss': 0.536776833884094, 'Total loss': 0.536776833884094}
2023-01-05 11:55:01,749 INFO:     Found new best model at epoch 4
2023-01-05 11:55:01,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:01,750 INFO:     Epoch: 5
2023-01-05 11:55:03,881 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4659820795059204, 'Total loss': 0.4659820795059204} | train loss {'Reaction outcome loss': 0.5124926934311035, 'Total loss': 0.5124926934311035}
2023-01-05 11:55:03,881 INFO:     Found new best model at epoch 5
2023-01-05 11:55:03,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:03,883 INFO:     Epoch: 6
2023-01-05 11:55:06,021 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4627200037240982, 'Total loss': 0.4627200037240982} | train loss {'Reaction outcome loss': 0.4965192755360318, 'Total loss': 0.4965192755360318}
2023-01-05 11:55:06,022 INFO:     Found new best model at epoch 6
2023-01-05 11:55:06,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:06,023 INFO:     Epoch: 7
2023-01-05 11:55:08,142 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4803148716688156, 'Total loss': 0.4803148716688156} | train loss {'Reaction outcome loss': 0.4871648804999996, 'Total loss': 0.4871648804999996}
2023-01-05 11:55:08,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:08,142 INFO:     Epoch: 8
2023-01-05 11:55:10,289 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4843634724617004, 'Total loss': 0.4843634724617004} | train loss {'Reaction outcome loss': 0.4759601427957524, 'Total loss': 0.4759601427957524}
2023-01-05 11:55:10,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:10,290 INFO:     Epoch: 9
2023-01-05 11:55:12,446 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45304840207099917, 'Total loss': 0.45304840207099917} | train loss {'Reaction outcome loss': 0.4706805154741944, 'Total loss': 0.4706805154741944}
2023-01-05 11:55:12,446 INFO:     Found new best model at epoch 9
2023-01-05 11:55:12,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:12,448 INFO:     Epoch: 10
2023-01-05 11:55:14,603 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46635574897130333, 'Total loss': 0.46635574897130333} | train loss {'Reaction outcome loss': 0.4684988482630866, 'Total loss': 0.4684988482630866}
2023-01-05 11:55:14,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:14,604 INFO:     Epoch: 11
2023-01-05 11:55:16,729 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4375026245911916, 'Total loss': 0.4375026245911916} | train loss {'Reaction outcome loss': 0.46177520727117854, 'Total loss': 0.46177520727117854}
2023-01-05 11:55:16,730 INFO:     Found new best model at epoch 11
2023-01-05 11:55:16,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:16,731 INFO:     Epoch: 12
2023-01-05 11:55:18,867 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4337957501411438, 'Total loss': 0.4337957501411438} | train loss {'Reaction outcome loss': 0.45875495051344234, 'Total loss': 0.45875495051344234}
2023-01-05 11:55:18,867 INFO:     Found new best model at epoch 12
2023-01-05 11:55:18,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:18,869 INFO:     Epoch: 13
2023-01-05 11:55:21,023 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45598337848981224, 'Total loss': 0.45598337848981224} | train loss {'Reaction outcome loss': 0.45789015394942567, 'Total loss': 0.45789015394942567}
2023-01-05 11:55:21,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:21,023 INFO:     Epoch: 14
2023-01-05 11:55:23,184 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4280162622531255, 'Total loss': 0.4280162622531255} | train loss {'Reaction outcome loss': 0.44989075326842454, 'Total loss': 0.44989075326842454}
2023-01-05 11:55:23,184 INFO:     Found new best model at epoch 14
2023-01-05 11:55:23,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:23,186 INFO:     Epoch: 15
2023-01-05 11:55:25,333 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44098204175631206, 'Total loss': 0.44098204175631206} | train loss {'Reaction outcome loss': 0.4400295725605194, 'Total loss': 0.4400295725605194}
2023-01-05 11:55:25,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:25,334 INFO:     Epoch: 16
2023-01-05 11:55:27,475 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45155015985171, 'Total loss': 0.45155015985171} | train loss {'Reaction outcome loss': 0.4485639203879712, 'Total loss': 0.4485639203879712}
2023-01-05 11:55:27,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:27,475 INFO:     Epoch: 17
2023-01-05 11:55:29,600 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4543656746546427, 'Total loss': 0.4543656746546427} | train loss {'Reaction outcome loss': 0.49512403431362, 'Total loss': 0.49512403431362}
2023-01-05 11:55:29,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:29,600 INFO:     Epoch: 18
2023-01-05 11:55:31,757 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4071233481168747, 'Total loss': 0.4071233481168747} | train loss {'Reaction outcome loss': 0.45604455728164833, 'Total loss': 0.45604455728164833}
2023-01-05 11:55:31,758 INFO:     Found new best model at epoch 18
2023-01-05 11:55:31,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:31,760 INFO:     Epoch: 19
2023-01-05 11:55:33,904 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43393736084302265, 'Total loss': 0.43393736084302265} | train loss {'Reaction outcome loss': 0.4259499194626899, 'Total loss': 0.4259499194626899}
2023-01-05 11:55:33,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:33,904 INFO:     Epoch: 20
2023-01-05 11:55:36,045 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41247590879599255, 'Total loss': 0.41247590879599255} | train loss {'Reaction outcome loss': 0.4176552360600065, 'Total loss': 0.4176552360600065}
2023-01-05 11:55:36,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:36,045 INFO:     Epoch: 21
2023-01-05 11:55:38,207 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42352045377095543, 'Total loss': 0.42352045377095543} | train loss {'Reaction outcome loss': 0.42596486313403514, 'Total loss': 0.42596486313403514}
2023-01-05 11:55:38,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:38,208 INFO:     Epoch: 22
2023-01-05 11:55:40,339 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40597344636917115, 'Total loss': 0.40597344636917115} | train loss {'Reaction outcome loss': 0.42618624182026565, 'Total loss': 0.42618624182026565}
2023-01-05 11:55:40,339 INFO:     Found new best model at epoch 22
2023-01-05 11:55:40,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:40,340 INFO:     Epoch: 23
2023-01-05 11:55:42,507 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.412203249335289, 'Total loss': 0.412203249335289} | train loss {'Reaction outcome loss': 0.40887853522123635, 'Total loss': 0.40887853522123635}
2023-01-05 11:55:42,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:42,508 INFO:     Epoch: 24
2023-01-05 11:55:44,736 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3952789584795634, 'Total loss': 0.3952789584795634} | train loss {'Reaction outcome loss': 0.40450808776886726, 'Total loss': 0.40450808776886726}
2023-01-05 11:55:44,737 INFO:     Found new best model at epoch 24
2023-01-05 11:55:44,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:44,738 INFO:     Epoch: 25
2023-01-05 11:55:46,889 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39956262906392415, 'Total loss': 0.39956262906392415} | train loss {'Reaction outcome loss': 0.4027909204444807, 'Total loss': 0.4027909204444807}
2023-01-05 11:55:46,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:46,890 INFO:     Epoch: 26
2023-01-05 11:55:49,050 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40838301479816436, 'Total loss': 0.40838301479816436} | train loss {'Reaction outcome loss': 0.4066071454435587, 'Total loss': 0.4066071454435587}
2023-01-05 11:55:49,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:49,051 INFO:     Epoch: 27
2023-01-05 11:55:51,201 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44360763430595396, 'Total loss': 0.44360763430595396} | train loss {'Reaction outcome loss': 0.41892741731071903, 'Total loss': 0.41892741731071903}
2023-01-05 11:55:51,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:51,201 INFO:     Epoch: 28
2023-01-05 11:55:53,340 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3828890552123388, 'Total loss': 0.3828890552123388} | train loss {'Reaction outcome loss': 0.3960758353198838, 'Total loss': 0.3960758353198838}
2023-01-05 11:55:53,340 INFO:     Found new best model at epoch 28
2023-01-05 11:55:53,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:53,341 INFO:     Epoch: 29
2023-01-05 11:55:55,478 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44499059369166694, 'Total loss': 0.44499059369166694} | train loss {'Reaction outcome loss': 0.3876322927628306, 'Total loss': 0.3876322927628306}
2023-01-05 11:55:55,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:55,478 INFO:     Epoch: 30
2023-01-05 11:55:57,651 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42851590712865195, 'Total loss': 0.42851590712865195} | train loss {'Reaction outcome loss': 0.4117831711495376, 'Total loss': 0.4117831711495376}
2023-01-05 11:55:57,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:57,651 INFO:     Epoch: 31
2023-01-05 11:55:59,806 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41068791747093203, 'Total loss': 0.41068791747093203} | train loss {'Reaction outcome loss': 0.38152729123670515, 'Total loss': 0.38152729123670515}
2023-01-05 11:55:59,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:55:59,806 INFO:     Epoch: 32
2023-01-05 11:56:01,947 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37339658141136167, 'Total loss': 0.37339658141136167} | train loss {'Reaction outcome loss': 0.3794461647790951, 'Total loss': 0.3794461647790951}
2023-01-05 11:56:01,948 INFO:     Found new best model at epoch 32
2023-01-05 11:56:01,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:01,949 INFO:     Epoch: 33
2023-01-05 11:56:04,107 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3785182237625122, 'Total loss': 0.3785182237625122} | train loss {'Reaction outcome loss': 0.36818095066490164, 'Total loss': 0.36818095066490164}
2023-01-05 11:56:04,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:04,107 INFO:     Epoch: 34
2023-01-05 11:56:06,250 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36862591207027434, 'Total loss': 0.36862591207027434} | train loss {'Reaction outcome loss': 0.3641043233278585, 'Total loss': 0.3641043233278585}
2023-01-05 11:56:06,251 INFO:     Found new best model at epoch 34
2023-01-05 11:56:06,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:06,252 INFO:     Epoch: 35
2023-01-05 11:56:08,411 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3836414158344269, 'Total loss': 0.3836414158344269} | train loss {'Reaction outcome loss': 0.3654489793647688, 'Total loss': 0.3654489793647688}
2023-01-05 11:56:08,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:08,411 INFO:     Epoch: 36
2023-01-05 11:56:10,546 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3941616187493006, 'Total loss': 0.3941616187493006} | train loss {'Reaction outcome loss': 0.35984229389662464, 'Total loss': 0.35984229389662464}
2023-01-05 11:56:10,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:10,546 INFO:     Epoch: 37
2023-01-05 11:56:12,711 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39377534588178, 'Total loss': 0.39377534588178} | train loss {'Reaction outcome loss': 0.3598159932180483, 'Total loss': 0.3598159932180483}
2023-01-05 11:56:12,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:12,711 INFO:     Epoch: 38
2023-01-05 11:56:14,846 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38455327053864796, 'Total loss': 0.38455327053864796} | train loss {'Reaction outcome loss': 0.3525563511673523, 'Total loss': 0.3525563511673523}
2023-01-05 11:56:14,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:14,846 INFO:     Epoch: 39
2023-01-05 11:56:16,996 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3878596186637878, 'Total loss': 0.3878596186637878} | train loss {'Reaction outcome loss': 0.37164018597399845, 'Total loss': 0.37164018597399845}
2023-01-05 11:56:16,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:16,996 INFO:     Epoch: 40
2023-01-05 11:56:19,147 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38703357974688213, 'Total loss': 0.38703357974688213} | train loss {'Reaction outcome loss': 0.41368069617003156, 'Total loss': 0.41368069617003156}
2023-01-05 11:56:19,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:19,147 INFO:     Epoch: 41
2023-01-05 11:56:21,294 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3745174691081047, 'Total loss': 0.3745174691081047} | train loss {'Reaction outcome loss': 0.3497983464039862, 'Total loss': 0.3497983464039862}
2023-01-05 11:56:21,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:21,295 INFO:     Epoch: 42
2023-01-05 11:56:23,430 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41048170203963913, 'Total loss': 0.41048170203963913} | train loss {'Reaction outcome loss': 0.3453934994573448, 'Total loss': 0.3453934994573448}
2023-01-05 11:56:23,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:23,430 INFO:     Epoch: 43
2023-01-05 11:56:25,566 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39570998748143515, 'Total loss': 0.39570998748143515} | train loss {'Reaction outcome loss': 0.34122065139395763, 'Total loss': 0.34122065139395763}
2023-01-05 11:56:25,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:25,567 INFO:     Epoch: 44
2023-01-05 11:56:27,726 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40279537041982016, 'Total loss': 0.40279537041982016} | train loss {'Reaction outcome loss': 0.34475798279603675, 'Total loss': 0.34475798279603675}
2023-01-05 11:56:27,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:27,726 INFO:     Epoch: 45
2023-01-05 11:56:29,896 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40087734659512836, 'Total loss': 0.40087734659512836} | train loss {'Reaction outcome loss': 0.3334858986732135, 'Total loss': 0.3334858986732135}
2023-01-05 11:56:29,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:29,896 INFO:     Epoch: 46
2023-01-05 11:56:32,057 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42013371785481773, 'Total loss': 0.42013371785481773} | train loss {'Reaction outcome loss': 0.33828725058423437, 'Total loss': 0.33828725058423437}
2023-01-05 11:56:32,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:32,058 INFO:     Epoch: 47
2023-01-05 11:56:34,207 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3830003529787064, 'Total loss': 0.3830003529787064} | train loss {'Reaction outcome loss': 0.33675273973832204, 'Total loss': 0.33675273973832204}
2023-01-05 11:56:34,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:34,207 INFO:     Epoch: 48
2023-01-05 11:56:36,372 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4148129165172577, 'Total loss': 0.4148129165172577} | train loss {'Reaction outcome loss': 0.3416579900228459, 'Total loss': 0.3416579900228459}
2023-01-05 11:56:36,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:36,372 INFO:     Epoch: 49
2023-01-05 11:56:38,522 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3680267776052157, 'Total loss': 0.3680267776052157} | train loss {'Reaction outcome loss': 0.44773897480057634, 'Total loss': 0.44773897480057634}
2023-01-05 11:56:38,523 INFO:     Found new best model at epoch 49
2023-01-05 11:56:38,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:38,524 INFO:     Epoch: 50
2023-01-05 11:56:40,677 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41510964234670006, 'Total loss': 0.41510964234670006} | train loss {'Reaction outcome loss': 0.3849094042797451, 'Total loss': 0.3849094042797451}
2023-01-05 11:56:40,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:40,677 INFO:     Epoch: 51
2023-01-05 11:56:42,840 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39464870244264605, 'Total loss': 0.39464870244264605} | train loss {'Reaction outcome loss': 0.3539753480463464, 'Total loss': 0.3539753480463464}
2023-01-05 11:56:42,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:42,840 INFO:     Epoch: 52
2023-01-05 11:56:45,021 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39600621263186137, 'Total loss': 0.39600621263186137} | train loss {'Reaction outcome loss': 0.4193051628863361, 'Total loss': 0.4193051628863361}
2023-01-05 11:56:45,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:45,021 INFO:     Epoch: 53
2023-01-05 11:56:47,180 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37563530007998147, 'Total loss': 0.37563530007998147} | train loss {'Reaction outcome loss': 0.35571482882875466, 'Total loss': 0.35571482882875466}
2023-01-05 11:56:47,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:47,180 INFO:     Epoch: 54
2023-01-05 11:56:49,332 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39258438150087993, 'Total loss': 0.39258438150087993} | train loss {'Reaction outcome loss': 0.3168292806578287, 'Total loss': 0.3168292806578287}
2023-01-05 11:56:49,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:49,333 INFO:     Epoch: 55
2023-01-05 11:56:51,493 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37224825024604796, 'Total loss': 0.37224825024604796} | train loss {'Reaction outcome loss': 0.31540512066103343, 'Total loss': 0.31540512066103343}
2023-01-05 11:56:51,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:51,494 INFO:     Epoch: 56
2023-01-05 11:56:53,685 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3678821975986163, 'Total loss': 0.3678821975986163} | train loss {'Reaction outcome loss': 0.317356477127127, 'Total loss': 0.317356477127127}
2023-01-05 11:56:53,685 INFO:     Found new best model at epoch 56
2023-01-05 11:56:53,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:53,687 INFO:     Epoch: 57
2023-01-05 11:56:55,833 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43345973591009773, 'Total loss': 0.43345973591009773} | train loss {'Reaction outcome loss': 0.344653222722548, 'Total loss': 0.344653222722548}
2023-01-05 11:56:55,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:55,833 INFO:     Epoch: 58
2023-01-05 11:56:57,997 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38160896450281145, 'Total loss': 0.38160896450281145} | train loss {'Reaction outcome loss': 0.3212248260240523, 'Total loss': 0.3212248260240523}
2023-01-05 11:56:57,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:56:57,998 INFO:     Epoch: 59
2023-01-05 11:57:00,165 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37524952391783395, 'Total loss': 0.37524952391783395} | train loss {'Reaction outcome loss': 0.308347332942846, 'Total loss': 0.308347332942846}
2023-01-05 11:57:00,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:00,165 INFO:     Epoch: 60
2023-01-05 11:57:02,313 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3368966281414032, 'Total loss': 0.3368966281414032} | train loss {'Reaction outcome loss': 0.3051074159912009, 'Total loss': 0.3051074159912009}
2023-01-05 11:57:02,313 INFO:     Found new best model at epoch 60
2023-01-05 11:57:02,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:02,314 INFO:     Epoch: 61
2023-01-05 11:57:04,446 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38755592008431755, 'Total loss': 0.38755592008431755} | train loss {'Reaction outcome loss': 0.303292724335114, 'Total loss': 0.303292724335114}
2023-01-05 11:57:04,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:04,447 INFO:     Epoch: 62
2023-01-05 11:57:06,607 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37914549907048545, 'Total loss': 0.37914549907048545} | train loss {'Reaction outcome loss': 0.2991347827854148, 'Total loss': 0.2991347827854148}
2023-01-05 11:57:06,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:06,607 INFO:     Epoch: 63
2023-01-05 11:57:08,755 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.34553691546122234, 'Total loss': 0.34553691546122234} | train loss {'Reaction outcome loss': 0.2980811160084778, 'Total loss': 0.2980811160084778}
2023-01-05 11:57:08,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:08,757 INFO:     Epoch: 64
2023-01-05 11:57:10,892 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3744122316439947, 'Total loss': 0.3744122316439947} | train loss {'Reaction outcome loss': 0.2897750447922643, 'Total loss': 0.2897750447922643}
2023-01-05 11:57:10,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:10,893 INFO:     Epoch: 65
2023-01-05 11:57:13,040 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37824421922365825, 'Total loss': 0.37824421922365825} | train loss {'Reaction outcome loss': 0.3194099583838513, 'Total loss': 0.3194099583838513}
2023-01-05 11:57:13,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:13,041 INFO:     Epoch: 66
2023-01-05 11:57:15,196 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37789867172638575, 'Total loss': 0.37789867172638575} | train loss {'Reaction outcome loss': 0.3594847214623334, 'Total loss': 0.3594847214623334}
2023-01-05 11:57:15,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:15,197 INFO:     Epoch: 67
2023-01-05 11:57:17,344 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4005338321129481, 'Total loss': 0.4005338321129481} | train loss {'Reaction outcome loss': 0.30809840672241146, 'Total loss': 0.30809840672241146}
2023-01-05 11:57:17,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:17,345 INFO:     Epoch: 68
2023-01-05 11:57:19,506 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3729796548684438, 'Total loss': 0.3729796548684438} | train loss {'Reaction outcome loss': 0.29452622322824557, 'Total loss': 0.29452622322824557}
2023-01-05 11:57:19,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:19,506 INFO:     Epoch: 69
2023-01-05 11:57:21,650 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38755468676487603, 'Total loss': 0.38755468676487603} | train loss {'Reaction outcome loss': 0.3062839518179712, 'Total loss': 0.3062839518179712}
2023-01-05 11:57:21,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:21,651 INFO:     Epoch: 70
2023-01-05 11:57:23,797 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34139134536186855, 'Total loss': 0.34139134536186855} | train loss {'Reaction outcome loss': 0.29453546543052234, 'Total loss': 0.29453546543052234}
2023-01-05 11:57:23,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:23,798 INFO:     Epoch: 71
2023-01-05 11:57:25,953 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3668398569027583, 'Total loss': 0.3668398569027583} | train loss {'Reaction outcome loss': 0.2869094618679652, 'Total loss': 0.2869094618679652}
2023-01-05 11:57:25,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:25,954 INFO:     Epoch: 72
2023-01-05 11:57:28,103 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3762111475070318, 'Total loss': 0.3762111475070318} | train loss {'Reaction outcome loss': 0.28303339957389084, 'Total loss': 0.28303339957389084}
2023-01-05 11:57:28,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:28,104 INFO:     Epoch: 73
2023-01-05 11:57:30,254 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33824684222539264, 'Total loss': 0.33824684222539264} | train loss {'Reaction outcome loss': 0.28422955504620273, 'Total loss': 0.28422955504620273}
2023-01-05 11:57:30,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:30,255 INFO:     Epoch: 74
2023-01-05 11:57:32,405 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.33999764968951546, 'Total loss': 0.33999764968951546} | train loss {'Reaction outcome loss': 0.27818111512486055, 'Total loss': 0.27818111512486055}
2023-01-05 11:57:32,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:32,405 INFO:     Epoch: 75
2023-01-05 11:57:34,559 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35410223255554835, 'Total loss': 0.35410223255554835} | train loss {'Reaction outcome loss': 0.2918621070466411, 'Total loss': 0.2918621070466411}
2023-01-05 11:57:34,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:34,559 INFO:     Epoch: 76
2023-01-05 11:57:36,701 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3680183341105779, 'Total loss': 0.3680183341105779} | train loss {'Reaction outcome loss': 0.29129551444877533, 'Total loss': 0.29129551444877533}
2023-01-05 11:57:36,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:36,702 INFO:     Epoch: 77
2023-01-05 11:57:38,857 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3646342771748702, 'Total loss': 0.3646342771748702} | train loss {'Reaction outcome loss': 0.3127478660296048, 'Total loss': 0.3127478660296048}
2023-01-05 11:57:38,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:38,858 INFO:     Epoch: 78
2023-01-05 11:57:41,013 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3772730936606725, 'Total loss': 0.3772730936606725} | train loss {'Reaction outcome loss': 0.28456308360910043, 'Total loss': 0.28456308360910043}
2023-01-05 11:57:41,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:41,013 INFO:     Epoch: 79
2023-01-05 11:57:43,166 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34811204969882964, 'Total loss': 0.34811204969882964} | train loss {'Reaction outcome loss': 0.2881643261184302, 'Total loss': 0.2881643261184302}
2023-01-05 11:57:43,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:43,166 INFO:     Epoch: 80
2023-01-05 11:57:45,317 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37783368428548175, 'Total loss': 0.37783368428548175} | train loss {'Reaction outcome loss': 0.2881523272144082, 'Total loss': 0.2881523272144082}
2023-01-05 11:57:45,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:45,318 INFO:     Epoch: 81
2023-01-05 11:57:47,463 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36340339680512745, 'Total loss': 0.36340339680512745} | train loss {'Reaction outcome loss': 0.3269440328999274, 'Total loss': 0.3269440328999274}
2023-01-05 11:57:47,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:47,463 INFO:     Epoch: 82
2023-01-05 11:57:49,617 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37556115438540777, 'Total loss': 0.37556115438540777} | train loss {'Reaction outcome loss': 0.36068286565159063, 'Total loss': 0.36068286565159063}
2023-01-05 11:57:49,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:49,618 INFO:     Epoch: 83
2023-01-05 11:57:51,756 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37432628075281776, 'Total loss': 0.37432628075281776} | train loss {'Reaction outcome loss': 0.29773678351425653, 'Total loss': 0.29773678351425653}
2023-01-05 11:57:51,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:51,756 INFO:     Epoch: 84
2023-01-05 11:57:53,911 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37602539658546447, 'Total loss': 0.37602539658546447} | train loss {'Reaction outcome loss': 0.2811083441641961, 'Total loss': 0.2811083441641961}
2023-01-05 11:57:53,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:53,911 INFO:     Epoch: 85
2023-01-05 11:57:56,078 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3483614290754, 'Total loss': 0.3483614290754} | train loss {'Reaction outcome loss': 0.2821310714352876, 'Total loss': 0.2821310714352876}
2023-01-05 11:57:56,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:56,078 INFO:     Epoch: 86
2023-01-05 11:57:58,203 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33469081223011016, 'Total loss': 0.33469081223011016} | train loss {'Reaction outcome loss': 0.27600343914557435, 'Total loss': 0.27600343914557435}
2023-01-05 11:57:58,204 INFO:     Found new best model at epoch 86
2023-01-05 11:57:58,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:57:58,206 INFO:     Epoch: 87
2023-01-05 11:58:00,392 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34641913572947186, 'Total loss': 0.34641913572947186} | train loss {'Reaction outcome loss': 0.2722137258587136, 'Total loss': 0.2722137258587136}
2023-01-05 11:58:00,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:00,392 INFO:     Epoch: 88
2023-01-05 11:58:02,534 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3502205510934194, 'Total loss': 0.3502205510934194} | train loss {'Reaction outcome loss': 0.27694157643270667, 'Total loss': 0.27694157643270667}
2023-01-05 11:58:02,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:02,534 INFO:     Epoch: 89
2023-01-05 11:58:04,708 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.349354953567187, 'Total loss': 0.349354953567187} | train loss {'Reaction outcome loss': 0.2786180846455534, 'Total loss': 0.2786180846455534}
2023-01-05 11:58:04,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:04,708 INFO:     Epoch: 90
2023-01-05 11:58:06,881 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3912232170502345, 'Total loss': 0.3912232170502345} | train loss {'Reaction outcome loss': 0.2734228895059314, 'Total loss': 0.2734228895059314}
2023-01-05 11:58:06,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:06,881 INFO:     Epoch: 91
2023-01-05 11:58:09,039 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.353934911886851, 'Total loss': 0.353934911886851} | train loss {'Reaction outcome loss': 0.352015213693633, 'Total loss': 0.352015213693633}
2023-01-05 11:58:09,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:09,040 INFO:     Epoch: 92
2023-01-05 11:58:11,199 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3285029963900646, 'Total loss': 0.3285029963900646} | train loss {'Reaction outcome loss': 0.28145025110321853, 'Total loss': 0.28145025110321853}
2023-01-05 11:58:11,199 INFO:     Found new best model at epoch 92
2023-01-05 11:58:11,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:11,200 INFO:     Epoch: 93
2023-01-05 11:58:13,361 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35648351113001503, 'Total loss': 0.35648351113001503} | train loss {'Reaction outcome loss': 0.2719269331550543, 'Total loss': 0.2719269331550543}
2023-01-05 11:58:13,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:13,361 INFO:     Epoch: 94
2023-01-05 11:58:15,178 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34446500887473425, 'Total loss': 0.34446500887473425} | train loss {'Reaction outcome loss': 0.26363092757410544, 'Total loss': 0.26363092757410544}
2023-01-05 11:58:15,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:15,179 INFO:     Epoch: 95
2023-01-05 11:58:16,926 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.365240071217219, 'Total loss': 0.365240071217219} | train loss {'Reaction outcome loss': 0.2642981755995171, 'Total loss': 0.2642981755995171}
2023-01-05 11:58:16,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:16,927 INFO:     Epoch: 96
2023-01-05 11:58:18,662 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.33342044601837795, 'Total loss': 0.33342044601837795} | train loss {'Reaction outcome loss': 0.26718076097144594, 'Total loss': 0.26718076097144594}
2023-01-05 11:58:18,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:18,662 INFO:     Epoch: 97
2023-01-05 11:58:20,140 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3801160827279091, 'Total loss': 0.3801160827279091} | train loss {'Reaction outcome loss': 0.2685084273967811, 'Total loss': 0.2685084273967811}
2023-01-05 11:58:20,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:20,141 INFO:     Epoch: 98
2023-01-05 11:58:21,402 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3659292181332906, 'Total loss': 0.3659292181332906} | train loss {'Reaction outcome loss': 0.2618343043394144, 'Total loss': 0.2618343043394144}
2023-01-05 11:58:21,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:21,403 INFO:     Epoch: 99
2023-01-05 11:58:22,926 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36047848463058474, 'Total loss': 0.36047848463058474} | train loss {'Reaction outcome loss': 0.2821970278788628, 'Total loss': 0.2821970278788628}
2023-01-05 11:58:22,926 INFO:     Best model found after epoch 93 of 100.
2023-01-05 11:58:22,926 INFO:   Done with stage: TRAINING
2023-01-05 11:58:22,926 INFO:   Starting stage: EVALUATION
2023-01-05 11:58:23,057 INFO:   Done with stage: EVALUATION
2023-01-05 11:58:23,057 INFO:   Leaving out SEQ value Fold_2
2023-01-05 11:58:23,070 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 11:58:23,071 INFO:   Starting stage: FEATURE SCALING
2023-01-05 11:58:23,729 INFO:   Done with stage: FEATURE SCALING
2023-01-05 11:58:23,729 INFO:   Starting stage: SCALING TARGETS
2023-01-05 11:58:23,798 INFO:   Done with stage: SCALING TARGETS
2023-01-05 11:58:23,798 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:58:23,798 INFO:     No hyperparam tuning for this model
2023-01-05 11:58:23,798 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 11:58:23,799 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 11:58:23,799 INFO:     None feature selector for col prot
2023-01-05 11:58:23,799 INFO:     None feature selector for col prot
2023-01-05 11:58:23,800 INFO:     None feature selector for col prot
2023-01-05 11:58:23,800 INFO:     None feature selector for col chem
2023-01-05 11:58:23,800 INFO:     None feature selector for col chem
2023-01-05 11:58:23,800 INFO:     None feature selector for col chem
2023-01-05 11:58:23,800 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 11:58:23,800 INFO:   Starting stage: BUILD MODEL
2023-01-05 11:58:23,802 INFO:     Number of params in model 72901
2023-01-05 11:58:23,805 INFO:   Done with stage: BUILD MODEL
2023-01-05 11:58:23,805 INFO:   Starting stage: TRAINING
2023-01-05 11:58:23,854 INFO:     Val loss before train {'Reaction outcome loss': 1.01739741563797, 'Total loss': 1.01739741563797}
2023-01-05 11:58:23,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:23,854 INFO:     Epoch: 0
2023-01-05 11:58:25,982 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7756503880023956, 'Total loss': 0.7756503880023956} | train loss {'Reaction outcome loss': 0.9254784580782383, 'Total loss': 0.9254784580782383}
2023-01-05 11:58:25,982 INFO:     Found new best model at epoch 0
2023-01-05 11:58:25,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:25,983 INFO:     Epoch: 1
2023-01-05 11:58:28,152 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6148692667484283, 'Total loss': 0.6148692667484283} | train loss {'Reaction outcome loss': 0.7553569341663027, 'Total loss': 0.7553569341663027}
2023-01-05 11:58:28,152 INFO:     Found new best model at epoch 1
2023-01-05 11:58:28,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:28,153 INFO:     Epoch: 2
2023-01-05 11:58:30,312 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5425121535857519, 'Total loss': 0.5425121535857519} | train loss {'Reaction outcome loss': 0.6077998054288599, 'Total loss': 0.6077998054288599}
2023-01-05 11:58:30,312 INFO:     Found new best model at epoch 2
2023-01-05 11:58:30,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:30,314 INFO:     Epoch: 3
2023-01-05 11:58:32,477 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4560694396495819, 'Total loss': 0.4560694396495819} | train loss {'Reaction outcome loss': 0.5504586770042886, 'Total loss': 0.5504586770042886}
2023-01-05 11:58:32,477 INFO:     Found new best model at epoch 3
2023-01-05 11:58:32,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:32,478 INFO:     Epoch: 4
2023-01-05 11:58:34,617 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44231850107510884, 'Total loss': 0.44231850107510884} | train loss {'Reaction outcome loss': 0.5200987478351071, 'Total loss': 0.5200987478351071}
2023-01-05 11:58:34,618 INFO:     Found new best model at epoch 4
2023-01-05 11:58:34,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:34,620 INFO:     Epoch: 5
2023-01-05 11:58:36,768 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4593971570332845, 'Total loss': 0.4593971570332845} | train loss {'Reaction outcome loss': 0.5061469510959012, 'Total loss': 0.5061469510959012}
2023-01-05 11:58:36,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:36,768 INFO:     Epoch: 6
2023-01-05 11:58:38,924 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4396361708641052, 'Total loss': 0.4396361708641052} | train loss {'Reaction outcome loss': 0.49878833127500366, 'Total loss': 0.49878833127500366}
2023-01-05 11:58:38,924 INFO:     Found new best model at epoch 6
2023-01-05 11:58:38,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:38,925 INFO:     Epoch: 7
2023-01-05 11:58:41,081 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4338312784830729, 'Total loss': 0.4338312784830729} | train loss {'Reaction outcome loss': 0.48457249547660786, 'Total loss': 0.48457249547660786}
2023-01-05 11:58:41,081 INFO:     Found new best model at epoch 7
2023-01-05 11:58:41,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:41,083 INFO:     Epoch: 8
2023-01-05 11:58:43,210 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4198768486579259, 'Total loss': 0.4198768486579259} | train loss {'Reaction outcome loss': 0.4874749195075383, 'Total loss': 0.4874749195075383}
2023-01-05 11:58:43,210 INFO:     Found new best model at epoch 8
2023-01-05 11:58:43,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:43,212 INFO:     Epoch: 9
2023-01-05 11:58:45,378 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4399754464626312, 'Total loss': 0.4399754464626312} | train loss {'Reaction outcome loss': 0.4776173022432919, 'Total loss': 0.4776173022432919}
2023-01-05 11:58:45,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:45,379 INFO:     Epoch: 10
2023-01-05 11:58:47,521 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41311876277128856, 'Total loss': 0.41311876277128856} | train loss {'Reaction outcome loss': 0.46688897276881836, 'Total loss': 0.46688897276881836}
2023-01-05 11:58:47,522 INFO:     Found new best model at epoch 10
2023-01-05 11:58:47,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:47,524 INFO:     Epoch: 11
2023-01-05 11:58:49,681 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4107413232326508, 'Total loss': 0.4107413232326508} | train loss {'Reaction outcome loss': 0.46296907700326323, 'Total loss': 0.46296907700326323}
2023-01-05 11:58:49,681 INFO:     Found new best model at epoch 11
2023-01-05 11:58:49,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:49,682 INFO:     Epoch: 12
2023-01-05 11:58:51,833 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45733367602030434, 'Total loss': 0.45733367602030434} | train loss {'Reaction outcome loss': 0.4610958672570486, 'Total loss': 0.4610958672570486}
2023-01-05 11:58:51,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:51,834 INFO:     Epoch: 13
2023-01-05 11:58:54,007 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3965574522813161, 'Total loss': 0.3965574522813161} | train loss {'Reaction outcome loss': 0.45731209373495874, 'Total loss': 0.45731209373495874}
2023-01-05 11:58:54,007 INFO:     Found new best model at epoch 13
2023-01-05 11:58:54,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:54,009 INFO:     Epoch: 14
2023-01-05 11:58:56,170 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40568519830703736, 'Total loss': 0.40568519830703736} | train loss {'Reaction outcome loss': 0.4467081930080469, 'Total loss': 0.4467081930080469}
2023-01-05 11:58:56,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:56,171 INFO:     Epoch: 15
2023-01-05 11:58:58,246 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42500802874565125, 'Total loss': 0.42500802874565125} | train loss {'Reaction outcome loss': 0.45068735248633546, 'Total loss': 0.45068735248633546}
2023-01-05 11:58:58,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:58:58,246 INFO:     Epoch: 16
2023-01-05 11:59:00,000 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40210554550091426, 'Total loss': 0.40210554550091426} | train loss {'Reaction outcome loss': 0.44608908113989515, 'Total loss': 0.44608908113989515}
2023-01-05 11:59:00,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:00,001 INFO:     Epoch: 17
2023-01-05 11:59:01,773 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4178151269753774, 'Total loss': 0.4178151269753774} | train loss {'Reaction outcome loss': 0.44033825832561857, 'Total loss': 0.44033825832561857}
2023-01-05 11:59:01,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:01,774 INFO:     Epoch: 18
2023-01-05 11:59:03,862 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37651664366324744, 'Total loss': 0.37651664366324744} | train loss {'Reaction outcome loss': 0.4408558488000918, 'Total loss': 0.4408558488000918}
2023-01-05 11:59:03,863 INFO:     Found new best model at epoch 18
2023-01-05 11:59:03,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:03,864 INFO:     Epoch: 19
2023-01-05 11:59:06,040 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37585520843664805, 'Total loss': 0.37585520843664805} | train loss {'Reaction outcome loss': 0.4294790492603814, 'Total loss': 0.4294790492603814}
2023-01-05 11:59:06,040 INFO:     Found new best model at epoch 19
2023-01-05 11:59:06,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:06,042 INFO:     Epoch: 20
2023-01-05 11:59:08,194 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3747466176748276, 'Total loss': 0.3747466176748276} | train loss {'Reaction outcome loss': 0.4279904411765781, 'Total loss': 0.4279904411765781}
2023-01-05 11:59:08,194 INFO:     Found new best model at epoch 20
2023-01-05 11:59:08,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:08,195 INFO:     Epoch: 21
2023-01-05 11:59:10,402 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3663951496283213, 'Total loss': 0.3663951496283213} | train loss {'Reaction outcome loss': 0.42807820792833384, 'Total loss': 0.42807820792833384}
2023-01-05 11:59:10,402 INFO:     Found new best model at epoch 21
2023-01-05 11:59:10,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:10,403 INFO:     Epoch: 22
2023-01-05 11:59:12,548 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40669714311758676, 'Total loss': 0.40669714311758676} | train loss {'Reaction outcome loss': 0.4237475122739799, 'Total loss': 0.4237475122739799}
2023-01-05 11:59:12,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:12,549 INFO:     Epoch: 23
2023-01-05 11:59:14,689 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.359429706633091, 'Total loss': 0.359429706633091} | train loss {'Reaction outcome loss': 0.41475431215915365, 'Total loss': 0.41475431215915365}
2023-01-05 11:59:14,689 INFO:     Found new best model at epoch 23
2023-01-05 11:59:14,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:14,691 INFO:     Epoch: 24
2023-01-05 11:59:16,911 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.371567091345787, 'Total loss': 0.371567091345787} | train loss {'Reaction outcome loss': 0.41662245377028073, 'Total loss': 0.41662245377028073}
2023-01-05 11:59:16,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:16,912 INFO:     Epoch: 25
2023-01-05 11:59:19,098 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3816013872623444, 'Total loss': 0.3816013872623444} | train loss {'Reaction outcome loss': 0.40789055856910067, 'Total loss': 0.40789055856910067}
2023-01-05 11:59:19,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:19,098 INFO:     Epoch: 26
2023-01-05 11:59:21,247 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38426737984021503, 'Total loss': 0.38426737984021503} | train loss {'Reaction outcome loss': 0.40531426029157464, 'Total loss': 0.40531426029157464}
2023-01-05 11:59:21,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:21,248 INFO:     Epoch: 27
2023-01-05 11:59:23,406 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3740457552174727, 'Total loss': 0.3740457552174727} | train loss {'Reaction outcome loss': 0.40366803416914315, 'Total loss': 0.40366803416914315}
2023-01-05 11:59:23,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:23,406 INFO:     Epoch: 28
2023-01-05 11:59:25,556 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3602856318155924, 'Total loss': 0.3602856318155924} | train loss {'Reaction outcome loss': 0.40163633477513805, 'Total loss': 0.40163633477513805}
2023-01-05 11:59:25,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:25,557 INFO:     Epoch: 29
2023-01-05 11:59:27,700 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3627143959204356, 'Total loss': 0.3627143959204356} | train loss {'Reaction outcome loss': 0.39250421812281994, 'Total loss': 0.39250421812281994}
2023-01-05 11:59:27,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:27,701 INFO:     Epoch: 30
2023-01-05 11:59:29,842 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3780866722265879, 'Total loss': 0.3780866722265879} | train loss {'Reaction outcome loss': 0.3920595676359469, 'Total loss': 0.3920595676359469}
2023-01-05 11:59:29,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:29,843 INFO:     Epoch: 31
2023-01-05 11:59:31,994 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38924195965131125, 'Total loss': 0.38924195965131125} | train loss {'Reaction outcome loss': 0.38986077072629094, 'Total loss': 0.38986077072629094}
2023-01-05 11:59:31,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:31,995 INFO:     Epoch: 32
2023-01-05 11:59:34,131 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36015579601128894, 'Total loss': 0.36015579601128894} | train loss {'Reaction outcome loss': 0.38344037508333684, 'Total loss': 0.38344037508333684}
2023-01-05 11:59:34,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:34,131 INFO:     Epoch: 33
2023-01-05 11:59:36,280 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37441327472527824, 'Total loss': 0.37441327472527824} | train loss {'Reaction outcome loss': 0.3794918424674194, 'Total loss': 0.3794918424674194}
2023-01-05 11:59:36,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:36,280 INFO:     Epoch: 34
2023-01-05 11:59:38,416 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4070805052916209, 'Total loss': 0.4070805052916209} | train loss {'Reaction outcome loss': 0.3767100509228933, 'Total loss': 0.3767100509228933}
2023-01-05 11:59:38,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:38,417 INFO:     Epoch: 35
2023-01-05 11:59:40,570 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36287592351436615, 'Total loss': 0.36287592351436615} | train loss {'Reaction outcome loss': 0.36713915579292894, 'Total loss': 0.36713915579292894}
2023-01-05 11:59:40,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:40,571 INFO:     Epoch: 36
2023-01-05 11:59:42,714 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3633843123912811, 'Total loss': 0.3633843123912811} | train loss {'Reaction outcome loss': 0.3646361418068409, 'Total loss': 0.3646361418068409}
2023-01-05 11:59:42,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:42,714 INFO:     Epoch: 37
2023-01-05 11:59:44,870 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3938585211833318, 'Total loss': 0.3938585211833318} | train loss {'Reaction outcome loss': 0.3606883824197915, 'Total loss': 0.3606883824197915}
2023-01-05 11:59:44,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:44,871 INFO:     Epoch: 38
2023-01-05 11:59:47,037 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3732914119958878, 'Total loss': 0.3732914119958878} | train loss {'Reaction outcome loss': 0.357056147752017, 'Total loss': 0.357056147752017}
2023-01-05 11:59:47,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:47,038 INFO:     Epoch: 39
2023-01-05 11:59:49,170 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37928125311930977, 'Total loss': 0.37928125311930977} | train loss {'Reaction outcome loss': 0.3603223131248986, 'Total loss': 0.3603223131248986}
2023-01-05 11:59:49,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:49,170 INFO:     Epoch: 40
2023-01-05 11:59:51,321 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3675311654806137, 'Total loss': 0.3675311654806137} | train loss {'Reaction outcome loss': 0.3529418315194602, 'Total loss': 0.3529418315194602}
2023-01-05 11:59:51,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:51,321 INFO:     Epoch: 41
2023-01-05 11:59:53,468 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36478488743305204, 'Total loss': 0.36478488743305204} | train loss {'Reaction outcome loss': 0.34745653862827014, 'Total loss': 0.34745653862827014}
2023-01-05 11:59:53,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:53,468 INFO:     Epoch: 42
2023-01-05 11:59:55,616 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3314407159884771, 'Total loss': 0.3314407159884771} | train loss {'Reaction outcome loss': 0.35202820071556273, 'Total loss': 0.35202820071556273}
2023-01-05 11:59:55,616 INFO:     Found new best model at epoch 42
2023-01-05 11:59:55,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:55,617 INFO:     Epoch: 43
2023-01-05 11:59:57,753 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3672867645819982, 'Total loss': 0.3672867645819982} | train loss {'Reaction outcome loss': 0.3464936329337367, 'Total loss': 0.3464936329337367}
2023-01-05 11:59:57,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:57,754 INFO:     Epoch: 44
2023-01-05 11:59:59,925 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3589712421099345, 'Total loss': 0.3589712421099345} | train loss {'Reaction outcome loss': 0.33410890159761386, 'Total loss': 0.33410890159761386}
2023-01-05 11:59:59,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 11:59:59,925 INFO:     Epoch: 45
2023-01-05 12:00:02,057 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3377181137601534, 'Total loss': 0.3377181137601534} | train loss {'Reaction outcome loss': 0.33560588671723857, 'Total loss': 0.33560588671723857}
2023-01-05 12:00:02,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:02,057 INFO:     Epoch: 46
2023-01-05 12:00:04,198 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3405161569515864, 'Total loss': 0.3405161569515864} | train loss {'Reaction outcome loss': 0.32906054003830376, 'Total loss': 0.32906054003830376}
2023-01-05 12:00:04,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:04,199 INFO:     Epoch: 47
2023-01-05 12:00:06,363 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3703471675515175, 'Total loss': 0.3703471675515175} | train loss {'Reaction outcome loss': 0.3283803313154809, 'Total loss': 0.3283803313154809}
2023-01-05 12:00:06,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:06,363 INFO:     Epoch: 48
2023-01-05 12:00:08,513 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35699225862820944, 'Total loss': 0.35699225862820944} | train loss {'Reaction outcome loss': 0.3255921360513155, 'Total loss': 0.3255921360513155}
2023-01-05 12:00:08,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:08,513 INFO:     Epoch: 49
2023-01-05 12:00:10,666 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37136120796203614, 'Total loss': 0.37136120796203614} | train loss {'Reaction outcome loss': 0.31848931949191395, 'Total loss': 0.31848931949191395}
2023-01-05 12:00:10,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:10,666 INFO:     Epoch: 50
2023-01-05 12:00:12,805 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3453820049762726, 'Total loss': 0.3453820049762726} | train loss {'Reaction outcome loss': 0.32239136665406887, 'Total loss': 0.32239136665406887}
2023-01-05 12:00:12,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:12,806 INFO:     Epoch: 51
2023-01-05 12:00:14,954 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.32236364781856536, 'Total loss': 0.32236364781856536} | train loss {'Reaction outcome loss': 0.3223096761770927, 'Total loss': 0.3223096761770927}
2023-01-05 12:00:14,954 INFO:     Found new best model at epoch 51
2023-01-05 12:00:14,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:14,956 INFO:     Epoch: 52
2023-01-05 12:00:17,098 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.33872542132933936, 'Total loss': 0.33872542132933936} | train loss {'Reaction outcome loss': 0.3107495635856677, 'Total loss': 0.3107495635856677}
2023-01-05 12:00:17,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:17,099 INFO:     Epoch: 53
2023-01-05 12:00:19,214 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3322643051544825, 'Total loss': 0.3322643051544825} | train loss {'Reaction outcome loss': 0.3155006921585024, 'Total loss': 0.3155006921585024}
2023-01-05 12:00:19,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:19,215 INFO:     Epoch: 54
2023-01-05 12:00:21,375 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3327975898981094, 'Total loss': 0.3327975898981094} | train loss {'Reaction outcome loss': 0.3113508346986814, 'Total loss': 0.3113508346986814}
2023-01-05 12:00:21,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:21,376 INFO:     Epoch: 55
2023-01-05 12:00:23,529 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.31055434737354515, 'Total loss': 0.31055434737354515} | train loss {'Reaction outcome loss': 0.3031774101112663, 'Total loss': 0.3031774101112663}
2023-01-05 12:00:23,530 INFO:     Found new best model at epoch 55
2023-01-05 12:00:23,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:23,531 INFO:     Epoch: 56
2023-01-05 12:00:25,671 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34805226754397156, 'Total loss': 0.34805226754397156} | train loss {'Reaction outcome loss': 0.30694245131020126, 'Total loss': 0.30694245131020126}
2023-01-05 12:00:25,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:25,671 INFO:     Epoch: 57
2023-01-05 12:00:27,834 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35482507397731144, 'Total loss': 0.35482507397731144} | train loss {'Reaction outcome loss': 0.3064961354146256, 'Total loss': 0.3064961354146256}
2023-01-05 12:00:27,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:27,836 INFO:     Epoch: 58
2023-01-05 12:00:29,989 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3423384626706441, 'Total loss': 0.3423384626706441} | train loss {'Reaction outcome loss': 0.30238379089392886, 'Total loss': 0.30238379089392886}
2023-01-05 12:00:29,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:29,989 INFO:     Epoch: 59
2023-01-05 12:00:32,128 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3472518861293793, 'Total loss': 0.3472518861293793} | train loss {'Reaction outcome loss': 0.29100600107960456, 'Total loss': 0.29100600107960456}
2023-01-05 12:00:32,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:32,128 INFO:     Epoch: 60
2023-01-05 12:00:34,273 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.33404668619235356, 'Total loss': 0.33404668619235356} | train loss {'Reaction outcome loss': 0.2848337719176155, 'Total loss': 0.2848337719176155}
2023-01-05 12:00:34,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:34,274 INFO:     Epoch: 61
2023-01-05 12:00:36,448 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.358597752948602, 'Total loss': 0.358597752948602} | train loss {'Reaction outcome loss': 0.29570100533973126, 'Total loss': 0.29570100533973126}
2023-01-05 12:00:36,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:36,448 INFO:     Epoch: 62
2023-01-05 12:00:38,631 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3448592022061348, 'Total loss': 0.3448592022061348} | train loss {'Reaction outcome loss': 0.28938932129501427, 'Total loss': 0.28938932129501427}
2023-01-05 12:00:38,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:38,631 INFO:     Epoch: 63
2023-01-05 12:00:40,784 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3409615139166514, 'Total loss': 0.3409615139166514} | train loss {'Reaction outcome loss': 0.2988431633443293, 'Total loss': 0.2988431633443293}
2023-01-05 12:00:40,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:40,785 INFO:     Epoch: 64
2023-01-05 12:00:42,943 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3286193201939265, 'Total loss': 0.3286193201939265} | train loss {'Reaction outcome loss': 0.2851674791534234, 'Total loss': 0.2851674791534234}
2023-01-05 12:00:42,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:42,944 INFO:     Epoch: 65
2023-01-05 12:00:45,119 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3539929658174515, 'Total loss': 0.3539929658174515} | train loss {'Reaction outcome loss': 0.28483733761865293, 'Total loss': 0.28483733761865293}
2023-01-05 12:00:45,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:45,119 INFO:     Epoch: 66
2023-01-05 12:00:47,278 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3520729750394821, 'Total loss': 0.3520729750394821} | train loss {'Reaction outcome loss': 0.278849759839312, 'Total loss': 0.278849759839312}
2023-01-05 12:00:47,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:47,279 INFO:     Epoch: 67
2023-01-05 12:00:49,430 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3322321546574434, 'Total loss': 0.3322321546574434} | train loss {'Reaction outcome loss': 0.27923297770593286, 'Total loss': 0.27923297770593286}
2023-01-05 12:00:49,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:49,430 INFO:     Epoch: 68
2023-01-05 12:00:51,575 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.32504452466964723, 'Total loss': 0.32504452466964723} | train loss {'Reaction outcome loss': 0.2852706613603735, 'Total loss': 0.2852706613603735}
2023-01-05 12:00:51,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:51,575 INFO:     Epoch: 69
2023-01-05 12:00:53,732 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3537136554718018, 'Total loss': 0.3537136554718018} | train loss {'Reaction outcome loss': 0.27072106144071495, 'Total loss': 0.27072106144071495}
2023-01-05 12:00:53,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:53,733 INFO:     Epoch: 70
2023-01-05 12:00:55,892 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.32991239180167514, 'Total loss': 0.32991239180167514} | train loss {'Reaction outcome loss': 0.2829453899749439, 'Total loss': 0.2829453899749439}
2023-01-05 12:00:55,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:55,892 INFO:     Epoch: 71
2023-01-05 12:00:58,048 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3102443420638641, 'Total loss': 0.3102443420638641} | train loss {'Reaction outcome loss': 0.2746095161980195, 'Total loss': 0.2746095161980195}
2023-01-05 12:00:58,048 INFO:     Found new best model at epoch 71
2023-01-05 12:00:58,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:00:58,049 INFO:     Epoch: 72
2023-01-05 12:01:00,201 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3207936272025108, 'Total loss': 0.3207936272025108} | train loss {'Reaction outcome loss': 0.26816801027986253, 'Total loss': 0.26816801027986253}
2023-01-05 12:01:00,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:00,202 INFO:     Epoch: 73
2023-01-05 12:01:02,387 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3196845233440399, 'Total loss': 0.3196845233440399} | train loss {'Reaction outcome loss': 0.2680439496460459, 'Total loss': 0.2680439496460459}
2023-01-05 12:01:02,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:02,387 INFO:     Epoch: 74
2023-01-05 12:01:04,572 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3386101767420769, 'Total loss': 0.3386101767420769} | train loss {'Reaction outcome loss': 0.26778467487625396, 'Total loss': 0.26778467487625396}
2023-01-05 12:01:04,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:04,574 INFO:     Epoch: 75
2023-01-05 12:01:06,724 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.34733923772970837, 'Total loss': 0.34733923772970837} | train loss {'Reaction outcome loss': 0.26503491634163107, 'Total loss': 0.26503491634163107}
2023-01-05 12:01:06,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:06,725 INFO:     Epoch: 76
2023-01-05 12:01:08,864 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3234974245230357, 'Total loss': 0.3234974245230357} | train loss {'Reaction outcome loss': 0.2673660723125412, 'Total loss': 0.2673660723125412}
2023-01-05 12:01:08,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:08,865 INFO:     Epoch: 77
2023-01-05 12:01:11,058 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3110475321610769, 'Total loss': 0.3110475321610769} | train loss {'Reaction outcome loss': 0.26839671933166953, 'Total loss': 0.26839671933166953}
2023-01-05 12:01:11,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:11,059 INFO:     Epoch: 78
2023-01-05 12:01:13,252 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.32676802575588226, 'Total loss': 0.32676802575588226} | train loss {'Reaction outcome loss': 0.26355779123064266, 'Total loss': 0.26355779123064266}
2023-01-05 12:01:13,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:13,252 INFO:     Epoch: 79
2023-01-05 12:01:15,462 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.32698429822921754, 'Total loss': 0.32698429822921754} | train loss {'Reaction outcome loss': 0.25966413160718055, 'Total loss': 0.25966413160718055}
2023-01-05 12:01:15,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:15,462 INFO:     Epoch: 80
2023-01-05 12:01:17,653 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.2854945033788681, 'Total loss': 0.2854945033788681} | train loss {'Reaction outcome loss': 0.25571216644216194, 'Total loss': 0.25571216644216194}
2023-01-05 12:01:17,653 INFO:     Found new best model at epoch 80
2023-01-05 12:01:17,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:17,654 INFO:     Epoch: 81
2023-01-05 12:01:19,878 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3326192061106364, 'Total loss': 0.3326192061106364} | train loss {'Reaction outcome loss': 0.2559983354796023, 'Total loss': 0.2559983354796023}
2023-01-05 12:01:19,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:19,878 INFO:     Epoch: 82
2023-01-05 12:01:22,081 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34556738833586376, 'Total loss': 0.34556738833586376} | train loss {'Reaction outcome loss': 0.25996151756848734, 'Total loss': 0.25996151756848734}
2023-01-05 12:01:22,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:22,081 INFO:     Epoch: 83
2023-01-05 12:01:24,271 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3400397052367528, 'Total loss': 0.3400397052367528} | train loss {'Reaction outcome loss': 0.24794193050640562, 'Total loss': 0.24794193050640562}
2023-01-05 12:01:24,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:24,272 INFO:     Epoch: 84
2023-01-05 12:01:26,449 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.33585672279198964, 'Total loss': 0.33585672279198964} | train loss {'Reaction outcome loss': 0.24911851998772064, 'Total loss': 0.24911851998772064}
2023-01-05 12:01:26,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:26,450 INFO:     Epoch: 85
2023-01-05 12:01:28,616 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3388680617014567, 'Total loss': 0.3388680617014567} | train loss {'Reaction outcome loss': 0.2503617811322647, 'Total loss': 0.2503617811322647}
2023-01-05 12:01:28,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:28,617 INFO:     Epoch: 86
2023-01-05 12:01:30,812 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.32014227112134297, 'Total loss': 0.32014227112134297} | train loss {'Reaction outcome loss': 0.2582478123397505, 'Total loss': 0.2582478123397505}
2023-01-05 12:01:30,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:30,812 INFO:     Epoch: 87
2023-01-05 12:01:33,006 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.30820618867874144, 'Total loss': 0.30820618867874144} | train loss {'Reaction outcome loss': 0.24811368899243155, 'Total loss': 0.24811368899243155}
2023-01-05 12:01:33,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:33,007 INFO:     Epoch: 88
2023-01-05 12:01:35,220 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3191913589835167, 'Total loss': 0.3191913589835167} | train loss {'Reaction outcome loss': 0.25631129785175744, 'Total loss': 0.25631129785175744}
2023-01-05 12:01:35,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:35,221 INFO:     Epoch: 89
2023-01-05 12:01:37,430 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.27777250011761984, 'Total loss': 0.27777250011761984} | train loss {'Reaction outcome loss': 0.24552619030332043, 'Total loss': 0.24552619030332043}
2023-01-05 12:01:37,430 INFO:     Found new best model at epoch 89
2023-01-05 12:01:37,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:37,431 INFO:     Epoch: 90
2023-01-05 12:01:39,640 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3399178708593051, 'Total loss': 0.3399178708593051} | train loss {'Reaction outcome loss': 0.25296472301230816, 'Total loss': 0.25296472301230816}
2023-01-05 12:01:39,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:39,640 INFO:     Epoch: 91
2023-01-05 12:01:41,830 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.31572302579879763, 'Total loss': 0.31572302579879763} | train loss {'Reaction outcome loss': 0.24725221186522803, 'Total loss': 0.24725221186522803}
2023-01-05 12:01:41,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:41,831 INFO:     Epoch: 92
2023-01-05 12:01:44,063 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.31659286419550575, 'Total loss': 0.31659286419550575} | train loss {'Reaction outcome loss': 0.24563067216752438, 'Total loss': 0.24563067216752438}
2023-01-05 12:01:44,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:44,063 INFO:     Epoch: 93
2023-01-05 12:01:46,246 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34179494182268777, 'Total loss': 0.34179494182268777} | train loss {'Reaction outcome loss': 0.2438801149191865, 'Total loss': 0.2438801149191865}
2023-01-05 12:01:46,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:46,246 INFO:     Epoch: 94
2023-01-05 12:01:48,390 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3272779459754626, 'Total loss': 0.3272779459754626} | train loss {'Reaction outcome loss': 0.23649996043570395, 'Total loss': 0.23649996043570395}
2023-01-05 12:01:48,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:48,390 INFO:     Epoch: 95
2023-01-05 12:01:50,548 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.319996087004741, 'Total loss': 0.319996087004741} | train loss {'Reaction outcome loss': 0.24510601472898122, 'Total loss': 0.24510601472898122}
2023-01-05 12:01:50,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:50,548 INFO:     Epoch: 96
2023-01-05 12:01:52,703 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.33726655406256517, 'Total loss': 0.33726655406256517} | train loss {'Reaction outcome loss': 0.23972193391680935, 'Total loss': 0.23972193391680935}
2023-01-05 12:01:52,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:52,703 INFO:     Epoch: 97
2023-01-05 12:01:54,864 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.35761981109778085, 'Total loss': 0.35761981109778085} | train loss {'Reaction outcome loss': 0.24259692497796168, 'Total loss': 0.24259692497796168}
2023-01-05 12:01:54,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:54,865 INFO:     Epoch: 98
2023-01-05 12:01:57,016 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.31491403679052987, 'Total loss': 0.31491403679052987} | train loss {'Reaction outcome loss': 0.24773309940648994, 'Total loss': 0.24773309940648994}
2023-01-05 12:01:57,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:01:57,016 INFO:     Epoch: 99
2023-01-05 12:01:59,162 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3210680201649666, 'Total loss': 0.3210680201649666} | train loss {'Reaction outcome loss': 0.23911006360511927, 'Total loss': 0.23911006360511927}
2023-01-05 12:01:59,163 INFO:     Best model found after epoch 90 of 100.
2023-01-05 12:01:59,163 INFO:   Done with stage: TRAINING
2023-01-05 12:01:59,163 INFO:   Starting stage: EVALUATION
2023-01-05 12:01:59,304 INFO:   Done with stage: EVALUATION
2023-01-05 12:01:59,304 INFO:   Leaving out SEQ value Fold_3
2023-01-05 12:01:59,317 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 12:01:59,317 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:01:59,970 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:01:59,970 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:02:00,039 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:02:00,039 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:02:00,040 INFO:     No hyperparam tuning for this model
2023-01-05 12:02:00,040 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:02:00,040 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:02:00,040 INFO:     None feature selector for col prot
2023-01-05 12:02:00,041 INFO:     None feature selector for col prot
2023-01-05 12:02:00,041 INFO:     None feature selector for col prot
2023-01-05 12:02:00,041 INFO:     None feature selector for col chem
2023-01-05 12:02:00,041 INFO:     None feature selector for col chem
2023-01-05 12:02:00,041 INFO:     None feature selector for col chem
2023-01-05 12:02:00,041 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:02:00,041 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:02:00,043 INFO:     Number of params in model 72901
2023-01-05 12:02:00,046 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:02:00,046 INFO:   Starting stage: TRAINING
2023-01-05 12:02:00,105 INFO:     Val loss before train {'Reaction outcome loss': 1.0030941009521483, 'Total loss': 1.0030941009521483}
2023-01-05 12:02:00,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:00,105 INFO:     Epoch: 0
2023-01-05 12:02:02,293 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8812662243843079, 'Total loss': 0.8812662243843079} | train loss {'Reaction outcome loss': 0.9273799176399524, 'Total loss': 0.9273799176399524}
2023-01-05 12:02:02,293 INFO:     Found new best model at epoch 0
2023-01-05 12:02:02,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:02,295 INFO:     Epoch: 1
2023-01-05 12:02:04,473 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6573678453763326, 'Total loss': 0.6573678453763326} | train loss {'Reaction outcome loss': 0.7481885967237172, 'Total loss': 0.7481885967237172}
2023-01-05 12:02:04,474 INFO:     Found new best model at epoch 1
2023-01-05 12:02:04,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:04,476 INFO:     Epoch: 2
2023-01-05 12:02:06,681 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.531957499186198, 'Total loss': 0.531957499186198} | train loss {'Reaction outcome loss': 0.5864234904011527, 'Total loss': 0.5864234904011527}
2023-01-05 12:02:06,682 INFO:     Found new best model at epoch 2
2023-01-05 12:02:06,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:06,683 INFO:     Epoch: 3
2023-01-05 12:02:08,867 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5395248095194499, 'Total loss': 0.5395248095194499} | train loss {'Reaction outcome loss': 0.5336833042757851, 'Total loss': 0.5336833042757851}
2023-01-05 12:02:08,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:08,867 INFO:     Epoch: 4
2023-01-05 12:02:11,029 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5148124595483144, 'Total loss': 0.5148124595483144} | train loss {'Reaction outcome loss': 0.507547880594547, 'Total loss': 0.507547880594547}
2023-01-05 12:02:11,030 INFO:     Found new best model at epoch 4
2023-01-05 12:02:11,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:11,031 INFO:     Epoch: 5
2023-01-05 12:02:13,211 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5387750128904979, 'Total loss': 0.5387750128904979} | train loss {'Reaction outcome loss': 0.49672337962594226, 'Total loss': 0.49672337962594226}
2023-01-05 12:02:13,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:13,211 INFO:     Epoch: 6
2023-01-05 12:02:15,388 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4966643472512563, 'Total loss': 0.4966643472512563} | train loss {'Reaction outcome loss': 0.4867335303580805, 'Total loss': 0.4867335303580805}
2023-01-05 12:02:15,388 INFO:     Found new best model at epoch 6
2023-01-05 12:02:15,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:15,390 INFO:     Epoch: 7
2023-01-05 12:02:17,592 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5029052456219991, 'Total loss': 0.5029052456219991} | train loss {'Reaction outcome loss': 0.47993271615042354, 'Total loss': 0.47993271615042354}
2023-01-05 12:02:17,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:17,592 INFO:     Epoch: 8
2023-01-05 12:02:19,773 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49598610401153564, 'Total loss': 0.49598610401153564} | train loss {'Reaction outcome loss': 0.47065131251628584, 'Total loss': 0.47065131251628584}
2023-01-05 12:02:19,773 INFO:     Found new best model at epoch 8
2023-01-05 12:02:19,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:19,774 INFO:     Epoch: 9
2023-01-05 12:02:21,898 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49512632191181183, 'Total loss': 0.49512632191181183} | train loss {'Reaction outcome loss': 0.47041471283405256, 'Total loss': 0.47041471283405256}
2023-01-05 12:02:21,898 INFO:     Found new best model at epoch 9
2023-01-05 12:02:21,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:21,899 INFO:     Epoch: 10
2023-01-05 12:02:24,055 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4816335548957189, 'Total loss': 0.4816335548957189} | train loss {'Reaction outcome loss': 0.46031642934450734, 'Total loss': 0.46031642934450734}
2023-01-05 12:02:24,056 INFO:     Found new best model at epoch 10
2023-01-05 12:02:24,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:24,057 INFO:     Epoch: 11
2023-01-05 12:02:26,084 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48164942239721614, 'Total loss': 0.48164942239721614} | train loss {'Reaction outcome loss': 0.456847645178601, 'Total loss': 0.456847645178601}
2023-01-05 12:02:26,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:26,084 INFO:     Epoch: 12
2023-01-05 12:02:28,176 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4944698095321655, 'Total loss': 0.4944698095321655} | train loss {'Reaction outcome loss': 0.4542410386241836, 'Total loss': 0.4542410386241836}
2023-01-05 12:02:28,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:28,176 INFO:     Epoch: 13
2023-01-05 12:02:30,316 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49890634218851726, 'Total loss': 0.49890634218851726} | train loss {'Reaction outcome loss': 0.4477746177178163, 'Total loss': 0.4477746177178163}
2023-01-05 12:02:30,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:30,316 INFO:     Epoch: 14
2023-01-05 12:02:32,477 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46426478823026024, 'Total loss': 0.46426478823026024} | train loss {'Reaction outcome loss': 0.4447786323862635, 'Total loss': 0.4447786323862635}
2023-01-05 12:02:32,477 INFO:     Found new best model at epoch 14
2023-01-05 12:02:32,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:32,478 INFO:     Epoch: 15
2023-01-05 12:02:34,619 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4814330200354258, 'Total loss': 0.4814330200354258} | train loss {'Reaction outcome loss': 0.4334763344172593, 'Total loss': 0.4334763344172593}
2023-01-05 12:02:34,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:34,619 INFO:     Epoch: 16
2023-01-05 12:02:36,782 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.468809707959493, 'Total loss': 0.468809707959493} | train loss {'Reaction outcome loss': 0.4337092264667972, 'Total loss': 0.4337092264667972}
2023-01-05 12:02:36,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:36,782 INFO:     Epoch: 17
2023-01-05 12:02:38,933 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4753214995066325, 'Total loss': 0.4753214995066325} | train loss {'Reaction outcome loss': 0.42922938284856493, 'Total loss': 0.42922938284856493}
2023-01-05 12:02:38,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:38,933 INFO:     Epoch: 18
2023-01-05 12:02:41,090 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47055407961209617, 'Total loss': 0.47055407961209617} | train loss {'Reaction outcome loss': 0.4286953074918998, 'Total loss': 0.4286953074918998}
2023-01-05 12:02:41,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:41,091 INFO:     Epoch: 19
2023-01-05 12:02:43,254 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4442350581288338, 'Total loss': 0.4442350581288338} | train loss {'Reaction outcome loss': 0.42009584931827293, 'Total loss': 0.42009584931827293}
2023-01-05 12:02:43,254 INFO:     Found new best model at epoch 19
2023-01-05 12:02:43,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:43,256 INFO:     Epoch: 20
2023-01-05 12:02:45,408 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45278199513753253, 'Total loss': 0.45278199513753253} | train loss {'Reaction outcome loss': 0.42241365012231763, 'Total loss': 0.42241365012231763}
2023-01-05 12:02:45,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:45,408 INFO:     Epoch: 21
2023-01-05 12:02:47,581 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48591853082180025, 'Total loss': 0.48591853082180025} | train loss {'Reaction outcome loss': 0.41073817233026244, 'Total loss': 0.41073817233026244}
2023-01-05 12:02:47,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:47,582 INFO:     Epoch: 22
2023-01-05 12:02:49,757 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4804665247599284, 'Total loss': 0.4804665247599284} | train loss {'Reaction outcome loss': 0.4106558455979868, 'Total loss': 0.4106558455979868}
2023-01-05 12:02:49,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:49,757 INFO:     Epoch: 23
2023-01-05 12:02:51,908 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47548426588376363, 'Total loss': 0.47548426588376363} | train loss {'Reaction outcome loss': 0.4039599578077103, 'Total loss': 0.4039599578077103}
2023-01-05 12:02:51,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:51,909 INFO:     Epoch: 24
2023-01-05 12:02:54,075 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45029058555761975, 'Total loss': 0.45029058555761975} | train loss {'Reaction outcome loss': 0.4022164909653502, 'Total loss': 0.4022164909653502}
2023-01-05 12:02:54,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:54,076 INFO:     Epoch: 25
2023-01-05 12:02:56,224 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42765347063541415, 'Total loss': 0.42765347063541415} | train loss {'Reaction outcome loss': 0.39487449513686884, 'Total loss': 0.39487449513686884}
2023-01-05 12:02:56,224 INFO:     Found new best model at epoch 25
2023-01-05 12:02:56,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:56,225 INFO:     Epoch: 26
2023-01-05 12:02:58,357 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4387934863567352, 'Total loss': 0.4387934863567352} | train loss {'Reaction outcome loss': 0.39655802046859656, 'Total loss': 0.39655802046859656}
2023-01-05 12:02:58,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:02:58,357 INFO:     Epoch: 27
2023-01-05 12:03:00,491 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45840529799461366, 'Total loss': 0.45840529799461366} | train loss {'Reaction outcome loss': 0.3887576181373317, 'Total loss': 0.3887576181373317}
2023-01-05 12:03:00,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:00,492 INFO:     Epoch: 28
2023-01-05 12:03:02,611 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4250590781370799, 'Total loss': 0.4250590781370799} | train loss {'Reaction outcome loss': 0.38641543114632915, 'Total loss': 0.38641543114632915}
2023-01-05 12:03:02,612 INFO:     Found new best model at epoch 28
2023-01-05 12:03:02,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:02,613 INFO:     Epoch: 29
2023-01-05 12:03:04,738 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46684581140677134, 'Total loss': 0.46684581140677134} | train loss {'Reaction outcome loss': 0.3836765636591029, 'Total loss': 0.3836765636591029}
2023-01-05 12:03:04,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:04,739 INFO:     Epoch: 30
2023-01-05 12:03:06,850 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48487839798132576, 'Total loss': 0.48487839798132576} | train loss {'Reaction outcome loss': 0.3775840481340667, 'Total loss': 0.3775840481340667}
2023-01-05 12:03:06,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:06,850 INFO:     Epoch: 31
2023-01-05 12:03:08,946 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46905068357785545, 'Total loss': 0.46905068357785545} | train loss {'Reaction outcome loss': 0.372302637950623, 'Total loss': 0.372302637950623}
2023-01-05 12:03:08,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:08,946 INFO:     Epoch: 32
2023-01-05 12:03:11,065 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44154549539089205, 'Total loss': 0.44154549539089205} | train loss {'Reaction outcome loss': 0.36777558397406185, 'Total loss': 0.36777558397406185}
2023-01-05 12:03:11,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:11,065 INFO:     Epoch: 33
2023-01-05 12:03:13,194 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43210382064183556, 'Total loss': 0.43210382064183556} | train loss {'Reaction outcome loss': 0.3634788789428197, 'Total loss': 0.3634788789428197}
2023-01-05 12:03:13,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:13,194 INFO:     Epoch: 34
2023-01-05 12:03:15,326 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46422191659609474, 'Total loss': 0.46422191659609474} | train loss {'Reaction outcome loss': 0.37537351709145766, 'Total loss': 0.37537351709145766}
2023-01-05 12:03:15,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:15,327 INFO:     Epoch: 35
2023-01-05 12:03:17,461 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4340904295444489, 'Total loss': 0.4340904295444489} | train loss {'Reaction outcome loss': 0.35903662800679714, 'Total loss': 0.35903662800679714}
2023-01-05 12:03:17,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:17,462 INFO:     Epoch: 36
2023-01-05 12:03:19,580 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44297095338503517, 'Total loss': 0.44297095338503517} | train loss {'Reaction outcome loss': 0.3564567304192445, 'Total loss': 0.3564567304192445}
2023-01-05 12:03:19,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:19,580 INFO:     Epoch: 37
2023-01-05 12:03:21,703 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4691483517487844, 'Total loss': 0.4691483517487844} | train loss {'Reaction outcome loss': 0.3543838525648082, 'Total loss': 0.3543838525648082}
2023-01-05 12:03:21,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:21,703 INFO:     Epoch: 38
2023-01-05 12:03:23,831 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42908099194367727, 'Total loss': 0.42908099194367727} | train loss {'Reaction outcome loss': 0.3493215093600663, 'Total loss': 0.3493215093600663}
2023-01-05 12:03:23,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:23,832 INFO:     Epoch: 39
2023-01-05 12:03:25,945 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.442588721960783, 'Total loss': 0.442588721960783} | train loss {'Reaction outcome loss': 0.3500049770451509, 'Total loss': 0.3500049770451509}
2023-01-05 12:03:25,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:25,945 INFO:     Epoch: 40
2023-01-05 12:03:28,089 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42793339093526206, 'Total loss': 0.42793339093526206} | train loss {'Reaction outcome loss': 0.34354133849397245, 'Total loss': 0.34354133849397245}
2023-01-05 12:03:28,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:28,090 INFO:     Epoch: 41
2023-01-05 12:03:30,237 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45597803095976513, 'Total loss': 0.45597803095976513} | train loss {'Reaction outcome loss': 0.34478048996610955, 'Total loss': 0.34478048996610955}
2023-01-05 12:03:30,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:30,237 INFO:     Epoch: 42
2023-01-05 12:03:32,376 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4523793915907542, 'Total loss': 0.4523793915907542} | train loss {'Reaction outcome loss': 0.33798022418122586, 'Total loss': 0.33798022418122586}
2023-01-05 12:03:32,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:32,376 INFO:     Epoch: 43
2023-01-05 12:03:34,525 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44058630367120105, 'Total loss': 0.44058630367120105} | train loss {'Reaction outcome loss': 0.3385132629929226, 'Total loss': 0.3385132629929226}
2023-01-05 12:03:34,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:34,525 INFO:     Epoch: 44
2023-01-05 12:03:36,648 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4103700896104177, 'Total loss': 0.4103700896104177} | train loss {'Reaction outcome loss': 0.33966971715509675, 'Total loss': 0.33966971715509675}
2023-01-05 12:03:36,648 INFO:     Found new best model at epoch 44
2023-01-05 12:03:36,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:36,650 INFO:     Epoch: 45
2023-01-05 12:03:38,797 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4141627957423528, 'Total loss': 0.4141627957423528} | train loss {'Reaction outcome loss': 0.3350692828605463, 'Total loss': 0.3350692828605463}
2023-01-05 12:03:38,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:38,797 INFO:     Epoch: 46
2023-01-05 12:03:40,948 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4097485254208247, 'Total loss': 0.4097485254208247} | train loss {'Reaction outcome loss': 0.3333064063073515, 'Total loss': 0.3333064063073515}
2023-01-05 12:03:40,948 INFO:     Found new best model at epoch 46
2023-01-05 12:03:40,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:40,949 INFO:     Epoch: 47
2023-01-05 12:03:43,116 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39970612625281016, 'Total loss': 0.39970612625281016} | train loss {'Reaction outcome loss': 0.32447325344105343, 'Total loss': 0.32447325344105343}
2023-01-05 12:03:43,116 INFO:     Found new best model at epoch 47
2023-01-05 12:03:43,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:43,117 INFO:     Epoch: 48
2023-01-05 12:03:45,249 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42547027468681337, 'Total loss': 0.42547027468681337} | train loss {'Reaction outcome loss': 0.31684677720738524, 'Total loss': 0.31684677720738524}
2023-01-05 12:03:45,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:45,249 INFO:     Epoch: 49
2023-01-05 12:03:47,468 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46624800165494285, 'Total loss': 0.46624800165494285} | train loss {'Reaction outcome loss': 0.3281535914392917, 'Total loss': 0.3281535914392917}
2023-01-05 12:03:47,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:47,469 INFO:     Epoch: 50
2023-01-05 12:03:49,688 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4409078096350034, 'Total loss': 0.4409078096350034} | train loss {'Reaction outcome loss': 0.3238725087335913, 'Total loss': 0.3238725087335913}
2023-01-05 12:03:49,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:49,688 INFO:     Epoch: 51
2023-01-05 12:03:51,918 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4343960553407669, 'Total loss': 0.4343960553407669} | train loss {'Reaction outcome loss': 0.32067196974496703, 'Total loss': 0.32067196974496703}
2023-01-05 12:03:51,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:51,919 INFO:     Epoch: 52
2023-01-05 12:03:54,078 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.439898752172788, 'Total loss': 0.439898752172788} | train loss {'Reaction outcome loss': 0.31396684771055705, 'Total loss': 0.31396684771055705}
2023-01-05 12:03:54,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:54,079 INFO:     Epoch: 53
2023-01-05 12:03:56,210 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45718357264995574, 'Total loss': 0.45718357264995574} | train loss {'Reaction outcome loss': 0.312774179046189, 'Total loss': 0.312774179046189}
2023-01-05 12:03:56,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:56,210 INFO:     Epoch: 54
2023-01-05 12:03:58,365 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4378995890418688, 'Total loss': 0.4378995890418688} | train loss {'Reaction outcome loss': 0.31798353118501305, 'Total loss': 0.31798353118501305}
2023-01-05 12:03:58,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:03:58,365 INFO:     Epoch: 55
2023-01-05 12:04:00,502 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4686974734067917, 'Total loss': 0.4686974734067917} | train loss {'Reaction outcome loss': 0.3121092455263758, 'Total loss': 0.3121092455263758}
2023-01-05 12:04:00,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:00,502 INFO:     Epoch: 56
2023-01-05 12:04:02,671 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37460682094097136, 'Total loss': 0.37460682094097136} | train loss {'Reaction outcome loss': 0.31506941501637953, 'Total loss': 0.31506941501637953}
2023-01-05 12:04:02,671 INFO:     Found new best model at epoch 56
2023-01-05 12:04:02,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:02,672 INFO:     Epoch: 57
2023-01-05 12:04:04,837 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40401034529010454, 'Total loss': 0.40401034529010454} | train loss {'Reaction outcome loss': 0.31017603244182174, 'Total loss': 0.31017603244182174}
2023-01-05 12:04:04,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:04,837 INFO:     Epoch: 58
2023-01-05 12:04:06,988 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4224804605046908, 'Total loss': 0.4224804605046908} | train loss {'Reaction outcome loss': 0.29926506001434044, 'Total loss': 0.29926506001434044}
2023-01-05 12:04:06,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:06,989 INFO:     Epoch: 59
2023-01-05 12:04:09,122 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3995210215449333, 'Total loss': 0.3995210215449333} | train loss {'Reaction outcome loss': 0.29820069530808224, 'Total loss': 0.29820069530808224}
2023-01-05 12:04:09,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:09,122 INFO:     Epoch: 60
2023-01-05 12:04:11,252 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42033939162890116, 'Total loss': 0.42033939162890116} | train loss {'Reaction outcome loss': 0.3061078116570637, 'Total loss': 0.3061078116570637}
2023-01-05 12:04:11,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:11,253 INFO:     Epoch: 61
2023-01-05 12:04:13,441 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4181277871131897, 'Total loss': 0.4181277871131897} | train loss {'Reaction outcome loss': 0.3060347709545504, 'Total loss': 0.3060347709545504}
2023-01-05 12:04:13,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:13,441 INFO:     Epoch: 62
2023-01-05 12:04:15,606 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40992120603720344, 'Total loss': 0.40992120603720344} | train loss {'Reaction outcome loss': 0.28622249434719155, 'Total loss': 0.28622249434719155}
2023-01-05 12:04:15,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:15,607 INFO:     Epoch: 63
2023-01-05 12:04:17,799 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4282799780368805, 'Total loss': 0.4282799780368805} | train loss {'Reaction outcome loss': 0.2910770700337031, 'Total loss': 0.2910770700337031}
2023-01-05 12:04:17,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:17,800 INFO:     Epoch: 64
2023-01-05 12:04:19,970 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4605994388461113, 'Total loss': 0.4605994388461113} | train loss {'Reaction outcome loss': 0.292006934252687, 'Total loss': 0.292006934252687}
2023-01-05 12:04:19,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:19,970 INFO:     Epoch: 65
2023-01-05 12:04:22,153 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.427890461931626, 'Total loss': 0.427890461931626} | train loss {'Reaction outcome loss': 0.29271252912506734, 'Total loss': 0.29271252912506734}
2023-01-05 12:04:22,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:22,153 INFO:     Epoch: 66
2023-01-05 12:04:24,320 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42551188711076976, 'Total loss': 0.42551188711076976} | train loss {'Reaction outcome loss': 0.28337241874004787, 'Total loss': 0.28337241874004787}
2023-01-05 12:04:24,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:24,321 INFO:     Epoch: 67
2023-01-05 12:04:26,497 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4378581037123998, 'Total loss': 0.4378581037123998} | train loss {'Reaction outcome loss': 0.28381511135088217, 'Total loss': 0.28381511135088217}
2023-01-05 12:04:26,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:26,497 INFO:     Epoch: 68
2023-01-05 12:04:28,654 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4058257192373276, 'Total loss': 0.4058257192373276} | train loss {'Reaction outcome loss': 0.2974738959400427, 'Total loss': 0.2974738959400427}
2023-01-05 12:04:28,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:28,654 INFO:     Epoch: 69
2023-01-05 12:04:30,779 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5211690942446391, 'Total loss': 0.5211690942446391} | train loss {'Reaction outcome loss': 0.28285167436541875, 'Total loss': 0.28285167436541875}
2023-01-05 12:04:30,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:30,780 INFO:     Epoch: 70
2023-01-05 12:04:32,916 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3820958033204079, 'Total loss': 0.3820958033204079} | train loss {'Reaction outcome loss': 0.28538813293253107, 'Total loss': 0.28538813293253107}
2023-01-05 12:04:32,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:32,916 INFO:     Epoch: 71
2023-01-05 12:04:35,049 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39786277363697686, 'Total loss': 0.39786277363697686} | train loss {'Reaction outcome loss': 0.2793514185445213, 'Total loss': 0.2793514185445213}
2023-01-05 12:04:35,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:35,049 INFO:     Epoch: 72
2023-01-05 12:04:37,198 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37876311341921487, 'Total loss': 0.37876311341921487} | train loss {'Reaction outcome loss': 0.27298543413916787, 'Total loss': 0.27298543413916787}
2023-01-05 12:04:37,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:37,198 INFO:     Epoch: 73
2023-01-05 12:04:39,338 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38510673145453134, 'Total loss': 0.38510673145453134} | train loss {'Reaction outcome loss': 0.28519716703302256, 'Total loss': 0.28519716703302256}
2023-01-05 12:04:39,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:39,338 INFO:     Epoch: 74
2023-01-05 12:04:41,484 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4135446866353353, 'Total loss': 0.4135446866353353} | train loss {'Reaction outcome loss': 0.2731340363580774, 'Total loss': 0.2731340363580774}
2023-01-05 12:04:41,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:41,484 INFO:     Epoch: 75
2023-01-05 12:04:43,634 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3999768496801456, 'Total loss': 0.3999768496801456} | train loss {'Reaction outcome loss': 0.273782723115914, 'Total loss': 0.273782723115914}
2023-01-05 12:04:43,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:43,635 INFO:     Epoch: 76
2023-01-05 12:04:45,805 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.385998139778773, 'Total loss': 0.385998139778773} | train loss {'Reaction outcome loss': 0.276830464915369, 'Total loss': 0.276830464915369}
2023-01-05 12:04:45,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:45,805 INFO:     Epoch: 77
2023-01-05 12:04:47,960 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4184764007727305, 'Total loss': 0.4184764007727305} | train loss {'Reaction outcome loss': 0.2732505591060871, 'Total loss': 0.2732505591060871}
2023-01-05 12:04:47,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:47,960 INFO:     Epoch: 78
2023-01-05 12:04:50,075 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4320218026638031, 'Total loss': 0.4320218026638031} | train loss {'Reaction outcome loss': 0.26902576741308737, 'Total loss': 0.26902576741308737}
2023-01-05 12:04:50,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:50,075 INFO:     Epoch: 79
2023-01-05 12:04:52,221 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4055750305453936, 'Total loss': 0.4055750305453936} | train loss {'Reaction outcome loss': 0.2697062427416826, 'Total loss': 0.2697062427416826}
2023-01-05 12:04:52,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:52,221 INFO:     Epoch: 80
2023-01-05 12:04:54,357 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39022930239637693, 'Total loss': 0.39022930239637693} | train loss {'Reaction outcome loss': 0.2724790758020057, 'Total loss': 0.2724790758020057}
2023-01-05 12:04:54,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:54,358 INFO:     Epoch: 81
2023-01-05 12:04:56,483 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4140017112096151, 'Total loss': 0.4140017112096151} | train loss {'Reaction outcome loss': 0.26095384600889554, 'Total loss': 0.26095384600889554}
2023-01-05 12:04:56,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:56,484 INFO:     Epoch: 82
2023-01-05 12:04:58,623 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40262789527575177, 'Total loss': 0.40262789527575177} | train loss {'Reaction outcome loss': 0.26645149177301936, 'Total loss': 0.26645149177301936}
2023-01-05 12:04:58,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:04:58,623 INFO:     Epoch: 83
2023-01-05 12:05:00,781 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42187153597672783, 'Total loss': 0.42187153597672783} | train loss {'Reaction outcome loss': 0.2650682916080122, 'Total loss': 0.2650682916080122}
2023-01-05 12:05:00,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:00,782 INFO:     Epoch: 84
2023-01-05 12:05:02,918 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4065183381239573, 'Total loss': 0.4065183381239573} | train loss {'Reaction outcome loss': 0.2699644805474596, 'Total loss': 0.2699644805474596}
2023-01-05 12:05:02,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:02,919 INFO:     Epoch: 85
2023-01-05 12:05:05,051 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41517238815625507, 'Total loss': 0.41517238815625507} | train loss {'Reaction outcome loss': 0.2664892731461292, 'Total loss': 0.2664892731461292}
2023-01-05 12:05:05,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:05,051 INFO:     Epoch: 86
2023-01-05 12:05:07,204 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43224034557739893, 'Total loss': 0.43224034557739893} | train loss {'Reaction outcome loss': 0.26320980998240545, 'Total loss': 0.26320980998240545}
2023-01-05 12:05:07,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:07,204 INFO:     Epoch: 87
2023-01-05 12:05:09,351 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4065763692061106, 'Total loss': 0.4065763692061106} | train loss {'Reaction outcome loss': 0.25837810704614217, 'Total loss': 0.25837810704614217}
2023-01-05 12:05:09,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:09,351 INFO:     Epoch: 88
2023-01-05 12:05:11,483 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42425773441791537, 'Total loss': 0.42425773441791537} | train loss {'Reaction outcome loss': 0.2506595136727387, 'Total loss': 0.2506595136727387}
2023-01-05 12:05:11,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:11,483 INFO:     Epoch: 89
2023-01-05 12:05:13,643 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41996616472800574, 'Total loss': 0.41996616472800574} | train loss {'Reaction outcome loss': 0.2589869975238602, 'Total loss': 0.2589869975238602}
2023-01-05 12:05:13,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:13,644 INFO:     Epoch: 90
2023-01-05 12:05:15,769 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4032858580350876, 'Total loss': 0.4032858580350876} | train loss {'Reaction outcome loss': 0.25519026824078717, 'Total loss': 0.25519026824078717}
2023-01-05 12:05:15,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:15,769 INFO:     Epoch: 91
2023-01-05 12:05:17,876 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.392779286702474, 'Total loss': 0.392779286702474} | train loss {'Reaction outcome loss': 0.2463118949250042, 'Total loss': 0.2463118949250042}
2023-01-05 12:05:17,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:17,876 INFO:     Epoch: 92
2023-01-05 12:05:20,029 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3990338365236918, 'Total loss': 0.3990338365236918} | train loss {'Reaction outcome loss': 0.26463542698844994, 'Total loss': 0.26463542698844994}
2023-01-05 12:05:20,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:20,029 INFO:     Epoch: 93
2023-01-05 12:05:22,161 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3843897710243861, 'Total loss': 0.3843897710243861} | train loss {'Reaction outcome loss': 0.25584977268899756, 'Total loss': 0.25584977268899756}
2023-01-05 12:05:22,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:22,162 INFO:     Epoch: 94
2023-01-05 12:05:24,304 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4107326625380665, 'Total loss': 0.4107326625380665} | train loss {'Reaction outcome loss': 0.2593681345465201, 'Total loss': 0.2593681345465201}
2023-01-05 12:05:24,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:24,305 INFO:     Epoch: 95
2023-01-05 12:05:26,451 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40925168991088867, 'Total loss': 0.40925168991088867} | train loss {'Reaction outcome loss': 0.25642325884010986, 'Total loss': 0.25642325884010986}
2023-01-05 12:05:26,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:26,451 INFO:     Epoch: 96
2023-01-05 12:05:28,608 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40520738661289213, 'Total loss': 0.40520738661289213} | train loss {'Reaction outcome loss': 0.24854458190309694, 'Total loss': 0.24854458190309694}
2023-01-05 12:05:28,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:28,608 INFO:     Epoch: 97
2023-01-05 12:05:30,744 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40996282001336415, 'Total loss': 0.40996282001336415} | train loss {'Reaction outcome loss': 0.2492212220009812, 'Total loss': 0.2492212220009812}
2023-01-05 12:05:30,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:30,745 INFO:     Epoch: 98
2023-01-05 12:05:32,890 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44639092683792114, 'Total loss': 0.44639092683792114} | train loss {'Reaction outcome loss': 0.24669679811722411, 'Total loss': 0.24669679811722411}
2023-01-05 12:05:32,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:32,890 INFO:     Epoch: 99
2023-01-05 12:05:35,047 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38882576922575635, 'Total loss': 0.38882576922575635} | train loss {'Reaction outcome loss': 0.2528736975194115, 'Total loss': 0.2528736975194115}
2023-01-05 12:05:35,047 INFO:     Best model found after epoch 57 of 100.
2023-01-05 12:05:35,047 INFO:   Done with stage: TRAINING
2023-01-05 12:05:35,048 INFO:   Starting stage: EVALUATION
2023-01-05 12:05:35,194 INFO:   Done with stage: EVALUATION
2023-01-05 12:05:35,194 INFO:   Leaving out SEQ value Fold_4
2023-01-05 12:05:35,206 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 12:05:35,207 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:05:35,856 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:05:35,856 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:05:35,926 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:05:35,926 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:05:35,926 INFO:     No hyperparam tuning for this model
2023-01-05 12:05:35,926 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:05:35,926 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:05:35,927 INFO:     None feature selector for col prot
2023-01-05 12:05:35,927 INFO:     None feature selector for col prot
2023-01-05 12:05:35,927 INFO:     None feature selector for col prot
2023-01-05 12:05:35,928 INFO:     None feature selector for col chem
2023-01-05 12:05:35,928 INFO:     None feature selector for col chem
2023-01-05 12:05:35,928 INFO:     None feature selector for col chem
2023-01-05 12:05:35,928 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:05:35,928 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:05:35,930 INFO:     Number of params in model 72901
2023-01-05 12:05:35,933 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:05:35,933 INFO:   Starting stage: TRAINING
2023-01-05 12:05:35,991 INFO:     Val loss before train {'Reaction outcome loss': 1.0974129637082417, 'Total loss': 1.0974129637082417}
2023-01-05 12:05:35,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:35,991 INFO:     Epoch: 0
2023-01-05 12:05:38,168 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8946521321932475, 'Total loss': 0.8946521321932475} | train loss {'Reaction outcome loss': 0.9404917589348295, 'Total loss': 0.9404917589348295}
2023-01-05 12:05:38,169 INFO:     Found new best model at epoch 0
2023-01-05 12:05:38,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:38,170 INFO:     Epoch: 1
2023-01-05 12:05:40,349 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6223628699779511, 'Total loss': 0.6223628699779511} | train loss {'Reaction outcome loss': 0.7357078655808489, 'Total loss': 0.7357078655808489}
2023-01-05 12:05:40,349 INFO:     Found new best model at epoch 1
2023-01-05 12:05:40,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:40,351 INFO:     Epoch: 2
2023-01-05 12:05:42,499 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5540240188439687, 'Total loss': 0.5540240188439687} | train loss {'Reaction outcome loss': 0.5828655299619245, 'Total loss': 0.5828655299619245}
2023-01-05 12:05:42,499 INFO:     Found new best model at epoch 2
2023-01-05 12:05:42,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:42,500 INFO:     Epoch: 3
2023-01-05 12:05:44,649 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5191769450902939, 'Total loss': 0.5191769450902939} | train loss {'Reaction outcome loss': 0.5332850928290113, 'Total loss': 0.5332850928290113}
2023-01-05 12:05:44,649 INFO:     Found new best model at epoch 3
2023-01-05 12:05:44,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:44,650 INFO:     Epoch: 4
2023-01-05 12:05:46,842 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5293837626775105, 'Total loss': 0.5293837626775105} | train loss {'Reaction outcome loss': 0.5127603435919256, 'Total loss': 0.5127603435919256}
2023-01-05 12:05:46,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:46,842 INFO:     Epoch: 5
2023-01-05 12:05:49,021 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5280586739381155, 'Total loss': 0.5280586739381155} | train loss {'Reaction outcome loss': 0.5001695354205921, 'Total loss': 0.5001695354205921}
2023-01-05 12:05:49,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:49,021 INFO:     Epoch: 6
2023-01-05 12:05:51,197 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4939659555753072, 'Total loss': 0.4939659555753072} | train loss {'Reaction outcome loss': 0.4938934183868485, 'Total loss': 0.4938934183868485}
2023-01-05 12:05:51,198 INFO:     Found new best model at epoch 6
2023-01-05 12:05:51,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:51,199 INFO:     Epoch: 7
2023-01-05 12:05:53,376 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49113062818845116, 'Total loss': 0.49113062818845116} | train loss {'Reaction outcome loss': 0.4816528659691845, 'Total loss': 0.4816528659691845}
2023-01-05 12:05:53,376 INFO:     Found new best model at epoch 7
2023-01-05 12:05:53,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:53,377 INFO:     Epoch: 8
2023-01-05 12:05:55,538 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48749607503414155, 'Total loss': 0.48749607503414155} | train loss {'Reaction outcome loss': 0.4920349602682003, 'Total loss': 0.4920349602682003}
2023-01-05 12:05:55,538 INFO:     Found new best model at epoch 8
2023-01-05 12:05:55,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:55,539 INFO:     Epoch: 9
2023-01-05 12:05:57,688 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.494316436847051, 'Total loss': 0.494316436847051} | train loss {'Reaction outcome loss': 0.48698544120555237, 'Total loss': 0.48698544120555237}
2023-01-05 12:05:57,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:57,688 INFO:     Epoch: 10
2023-01-05 12:05:59,864 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4977481404940287, 'Total loss': 0.4977481404940287} | train loss {'Reaction outcome loss': 0.47000092343997507, 'Total loss': 0.47000092343997507}
2023-01-05 12:05:59,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:05:59,865 INFO:     Epoch: 11
2023-01-05 12:06:02,036 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45614648262659707, 'Total loss': 0.45614648262659707} | train loss {'Reaction outcome loss': 0.4625155995937361, 'Total loss': 0.4625155995937361}
2023-01-05 12:06:02,036 INFO:     Found new best model at epoch 11
2023-01-05 12:06:02,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:02,038 INFO:     Epoch: 12
2023-01-05 12:06:04,206 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49286200404167174, 'Total loss': 0.49286200404167174} | train loss {'Reaction outcome loss': 0.46052868199953134, 'Total loss': 0.46052868199953134}
2023-01-05 12:06:04,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:04,207 INFO:     Epoch: 13
2023-01-05 12:06:06,361 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47090276579062146, 'Total loss': 0.47090276579062146} | train loss {'Reaction outcome loss': 0.45742977815140307, 'Total loss': 0.45742977815140307}
2023-01-05 12:06:06,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:06,362 INFO:     Epoch: 14
2023-01-05 12:06:08,514 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47865936954816185, 'Total loss': 0.47865936954816185} | train loss {'Reaction outcome loss': 0.4465076819440161, 'Total loss': 0.4465076819440161}
2023-01-05 12:06:08,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:08,514 INFO:     Epoch: 15
2023-01-05 12:06:10,678 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45824463268121085, 'Total loss': 0.45824463268121085} | train loss {'Reaction outcome loss': 0.44843656192466186, 'Total loss': 0.44843656192466186}
2023-01-05 12:06:10,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:10,678 INFO:     Epoch: 16
2023-01-05 12:06:12,842 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44977964560190836, 'Total loss': 0.44977964560190836} | train loss {'Reaction outcome loss': 0.44295559278343455, 'Total loss': 0.44295559278343455}
2023-01-05 12:06:12,843 INFO:     Found new best model at epoch 16
2023-01-05 12:06:12,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:12,844 INFO:     Epoch: 17
2023-01-05 12:06:15,023 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44883719434340796, 'Total loss': 0.44883719434340796} | train loss {'Reaction outcome loss': 0.4416534688755654, 'Total loss': 0.4416534688755654}
2023-01-05 12:06:15,023 INFO:     Found new best model at epoch 17
2023-01-05 12:06:15,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:15,024 INFO:     Epoch: 18
2023-01-05 12:06:17,185 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45602816541989644, 'Total loss': 0.45602816541989644} | train loss {'Reaction outcome loss': 0.4516434156351391, 'Total loss': 0.4516434156351391}
2023-01-05 12:06:17,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:17,185 INFO:     Epoch: 19
2023-01-05 12:06:19,343 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4539953033129374, 'Total loss': 0.4539953033129374} | train loss {'Reaction outcome loss': 0.4361057505821404, 'Total loss': 0.4361057505821404}
2023-01-05 12:06:19,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:19,344 INFO:     Epoch: 20
2023-01-05 12:06:21,505 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47086663643519083, 'Total loss': 0.47086663643519083} | train loss {'Reaction outcome loss': 0.4446871862139391, 'Total loss': 0.4446871862139391}
2023-01-05 12:06:21,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:21,505 INFO:     Epoch: 21
2023-01-05 12:06:23,680 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47285391092300416, 'Total loss': 0.47285391092300416} | train loss {'Reaction outcome loss': 0.4606701098686165, 'Total loss': 0.4606701098686165}
2023-01-05 12:06:23,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:23,680 INFO:     Epoch: 22
2023-01-05 12:06:25,846 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46830665369828545, 'Total loss': 0.46830665369828545} | train loss {'Reaction outcome loss': 0.4253774291472824, 'Total loss': 0.4253774291472824}
2023-01-05 12:06:25,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:25,846 INFO:     Epoch: 23
2023-01-05 12:06:28,006 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4478452583154043, 'Total loss': 0.4478452583154043} | train loss {'Reaction outcome loss': 0.44209908688629884, 'Total loss': 0.44209908688629884}
2023-01-05 12:06:28,006 INFO:     Found new best model at epoch 23
2023-01-05 12:06:28,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:28,007 INFO:     Epoch: 24
2023-01-05 12:06:30,175 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4610304524501165, 'Total loss': 0.4610304524501165} | train loss {'Reaction outcome loss': 0.41956805340621783, 'Total loss': 0.41956805340621783}
2023-01-05 12:06:30,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:30,176 INFO:     Epoch: 25
2023-01-05 12:06:32,327 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42833313544591267, 'Total loss': 0.42833313544591267} | train loss {'Reaction outcome loss': 0.45351547162062017, 'Total loss': 0.45351547162062017}
2023-01-05 12:06:32,328 INFO:     Found new best model at epoch 25
2023-01-05 12:06:32,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:32,329 INFO:     Epoch: 26
2023-01-05 12:06:34,310 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4554372012615204, 'Total loss': 0.4554372012615204} | train loss {'Reaction outcome loss': 0.40997162655643793, 'Total loss': 0.40997162655643793}
2023-01-05 12:06:34,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:34,311 INFO:     Epoch: 27
2023-01-05 12:06:36,474 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4243956317504247, 'Total loss': 0.4243956317504247} | train loss {'Reaction outcome loss': 0.41357666021887807, 'Total loss': 0.41357666021887807}
2023-01-05 12:06:36,475 INFO:     Found new best model at epoch 27
2023-01-05 12:06:36,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:36,477 INFO:     Epoch: 28
2023-01-05 12:06:38,635 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4587234139442444, 'Total loss': 0.4587234139442444} | train loss {'Reaction outcome loss': 0.4022629794705173, 'Total loss': 0.4022629794705173}
2023-01-05 12:06:38,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:38,635 INFO:     Epoch: 29
2023-01-05 12:06:40,794 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.446288804213206, 'Total loss': 0.446288804213206} | train loss {'Reaction outcome loss': 0.4012745001346575, 'Total loss': 0.4012745001346575}
2023-01-05 12:06:40,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:40,794 INFO:     Epoch: 30
2023-01-05 12:06:42,954 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45073188543319703, 'Total loss': 0.45073188543319703} | train loss {'Reaction outcome loss': 0.4061253219842911, 'Total loss': 0.4061253219842911}
2023-01-05 12:06:42,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:42,955 INFO:     Epoch: 31
2023-01-05 12:06:45,128 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42420638899008434, 'Total loss': 0.42420638899008434} | train loss {'Reaction outcome loss': 0.42240208085538633, 'Total loss': 0.42240208085538633}
2023-01-05 12:06:45,128 INFO:     Found new best model at epoch 31
2023-01-05 12:06:45,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:45,129 INFO:     Epoch: 32
2023-01-05 12:06:47,314 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46185511648654937, 'Total loss': 0.46185511648654937} | train loss {'Reaction outcome loss': 0.40618430051034776, 'Total loss': 0.40618430051034776}
2023-01-05 12:06:47,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:47,314 INFO:     Epoch: 33
2023-01-05 12:06:49,501 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41044208606084187, 'Total loss': 0.41044208606084187} | train loss {'Reaction outcome loss': 0.40758444684805634, 'Total loss': 0.40758444684805634}
2023-01-05 12:06:49,502 INFO:     Found new best model at epoch 33
2023-01-05 12:06:49,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:49,503 INFO:     Epoch: 34
2023-01-05 12:06:51,659 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44697076876958214, 'Total loss': 0.44697076876958214} | train loss {'Reaction outcome loss': 0.39083978533449554, 'Total loss': 0.39083978533449554}
2023-01-05 12:06:51,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:51,659 INFO:     Epoch: 35
2023-01-05 12:06:53,814 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4233256061871847, 'Total loss': 0.4233256061871847} | train loss {'Reaction outcome loss': 0.38761607458835223, 'Total loss': 0.38761607458835223}
2023-01-05 12:06:53,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:53,814 INFO:     Epoch: 36
2023-01-05 12:06:55,991 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37415552536646524, 'Total loss': 0.37415552536646524} | train loss {'Reaction outcome loss': 0.3855329697424009, 'Total loss': 0.3855329697424009}
2023-01-05 12:06:55,991 INFO:     Found new best model at epoch 36
2023-01-05 12:06:55,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:55,993 INFO:     Epoch: 37
2023-01-05 12:06:58,150 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42695151766141254, 'Total loss': 0.42695151766141254} | train loss {'Reaction outcome loss': 0.3704030357884999, 'Total loss': 0.3704030357884999}
2023-01-05 12:06:58,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:06:58,150 INFO:     Epoch: 38
2023-01-05 12:07:00,331 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41399692992369336, 'Total loss': 0.41399692992369336} | train loss {'Reaction outcome loss': 0.3783040717185097, 'Total loss': 0.3783040717185097}
2023-01-05 12:07:00,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:00,332 INFO:     Epoch: 39
2023-01-05 12:07:02,513 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3770978411038717, 'Total loss': 0.3770978411038717} | train loss {'Reaction outcome loss': 0.3701017033578693, 'Total loss': 0.3701017033578693}
2023-01-05 12:07:02,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:02,513 INFO:     Epoch: 40
2023-01-05 12:07:04,677 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42464817663033805, 'Total loss': 0.42464817663033805} | train loss {'Reaction outcome loss': 0.395262760663594, 'Total loss': 0.395262760663594}
2023-01-05 12:07:04,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:04,677 INFO:     Epoch: 41
2023-01-05 12:07:06,840 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39787149329980215, 'Total loss': 0.39787149329980215} | train loss {'Reaction outcome loss': 0.3670898295561041, 'Total loss': 0.3670898295561041}
2023-01-05 12:07:06,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:06,840 INFO:     Epoch: 42
2023-01-05 12:07:09,038 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39089251061280567, 'Total loss': 0.39089251061280567} | train loss {'Reaction outcome loss': 0.3662267043409752, 'Total loss': 0.3662267043409752}
2023-01-05 12:07:09,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:09,038 INFO:     Epoch: 43
2023-01-05 12:07:11,223 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4187034507592519, 'Total loss': 0.4187034507592519} | train loss {'Reaction outcome loss': 0.35753061795295926, 'Total loss': 0.35753061795295926}
2023-01-05 12:07:11,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:11,223 INFO:     Epoch: 44
2023-01-05 12:07:13,386 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.382779194911321, 'Total loss': 0.382779194911321} | train loss {'Reaction outcome loss': 0.3574427719523437, 'Total loss': 0.3574427719523437}
2023-01-05 12:07:13,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:13,387 INFO:     Epoch: 45
2023-01-05 12:07:15,545 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39971214334170024, 'Total loss': 0.39971214334170024} | train loss {'Reaction outcome loss': 0.3580402937310493, 'Total loss': 0.3580402937310493}
2023-01-05 12:07:15,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:15,545 INFO:     Epoch: 46
2023-01-05 12:07:17,706 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40259655912717185, 'Total loss': 0.40259655912717185} | train loss {'Reaction outcome loss': 0.35248222497656295, 'Total loss': 0.35248222497656295}
2023-01-05 12:07:17,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:17,707 INFO:     Epoch: 47
2023-01-05 12:07:19,889 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4020486722389857, 'Total loss': 0.4020486722389857} | train loss {'Reaction outcome loss': 0.35190706648796366, 'Total loss': 0.35190706648796366}
2023-01-05 12:07:19,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:19,890 INFO:     Epoch: 48
2023-01-05 12:07:22,055 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43714763820171354, 'Total loss': 0.43714763820171354} | train loss {'Reaction outcome loss': 0.38054074749326927, 'Total loss': 0.38054074749326927}
2023-01-05 12:07:22,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:22,055 INFO:     Epoch: 49
2023-01-05 12:07:24,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4123751034339269, 'Total loss': 0.4123751034339269} | train loss {'Reaction outcome loss': 0.34727435729101946, 'Total loss': 0.34727435729101946}
2023-01-05 12:07:24,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:24,233 INFO:     Epoch: 50
2023-01-05 12:07:26,399 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4280417064825694, 'Total loss': 0.4280417064825694} | train loss {'Reaction outcome loss': 0.3576962710560664, 'Total loss': 0.3576962710560664}
2023-01-05 12:07:26,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:26,399 INFO:     Epoch: 51
2023-01-05 12:07:28,567 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3650570926566919, 'Total loss': 0.3650570926566919} | train loss {'Reaction outcome loss': 0.3848961475642695, 'Total loss': 0.3848961475642695}
2023-01-05 12:07:28,567 INFO:     Found new best model at epoch 51
2023-01-05 12:07:28,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:28,568 INFO:     Epoch: 52
2023-01-05 12:07:30,748 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3633841772874196, 'Total loss': 0.3633841772874196} | train loss {'Reaction outcome loss': 0.3489660468573372, 'Total loss': 0.3489660468573372}
2023-01-05 12:07:30,748 INFO:     Found new best model at epoch 52
2023-01-05 12:07:30,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:30,749 INFO:     Epoch: 53
2023-01-05 12:07:32,908 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3767766416072845, 'Total loss': 0.3767766416072845} | train loss {'Reaction outcome loss': 0.32954624860102066, 'Total loss': 0.32954624860102066}
2023-01-05 12:07:32,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:32,909 INFO:     Epoch: 54
2023-01-05 12:07:35,101 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3819129372636477, 'Total loss': 0.3819129372636477} | train loss {'Reaction outcome loss': 0.3312515248270348, 'Total loss': 0.3312515248270348}
2023-01-05 12:07:35,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:35,101 INFO:     Epoch: 55
2023-01-05 12:07:37,291 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3647656654318174, 'Total loss': 0.3647656654318174} | train loss {'Reaction outcome loss': 0.3334624445187333, 'Total loss': 0.3334624445187333}
2023-01-05 12:07:37,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:37,291 INFO:     Epoch: 56
2023-01-05 12:07:39,450 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3796254098415375, 'Total loss': 0.3796254098415375} | train loss {'Reaction outcome loss': 0.3283084139119888, 'Total loss': 0.3283084139119888}
2023-01-05 12:07:39,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:39,450 INFO:     Epoch: 57
2023-01-05 12:07:41,613 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39363687535127007, 'Total loss': 0.39363687535127007} | train loss {'Reaction outcome loss': 0.32481688938302494, 'Total loss': 0.32481688938302494}
2023-01-05 12:07:41,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:41,613 INFO:     Epoch: 58
2023-01-05 12:07:43,786 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40295874178409574, 'Total loss': 0.40295874178409574} | train loss {'Reaction outcome loss': 0.3244747273215646, 'Total loss': 0.3244747273215646}
2023-01-05 12:07:43,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:43,787 INFO:     Epoch: 59
2023-01-05 12:07:45,968 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38275427718957267, 'Total loss': 0.38275427718957267} | train loss {'Reaction outcome loss': 0.32079578946114023, 'Total loss': 0.32079578946114023}
2023-01-05 12:07:45,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:45,968 INFO:     Epoch: 60
2023-01-05 12:07:48,128 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36920361618200936, 'Total loss': 0.36920361618200936} | train loss {'Reaction outcome loss': 0.3131475520051975, 'Total loss': 0.3131475520051975}
2023-01-05 12:07:48,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:48,128 INFO:     Epoch: 61
2023-01-05 12:07:50,290 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43392261266708376, 'Total loss': 0.43392261266708376} | train loss {'Reaction outcome loss': 0.3256989126161173, 'Total loss': 0.3256989126161173}
2023-01-05 12:07:50,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:50,291 INFO:     Epoch: 62
2023-01-05 12:07:52,457 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42207068304220835, 'Total loss': 0.42207068304220835} | train loss {'Reaction outcome loss': 0.3672186736339822, 'Total loss': 0.3672186736339822}
2023-01-05 12:07:52,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:52,457 INFO:     Epoch: 63
2023-01-05 12:07:54,625 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.414089893301328, 'Total loss': 0.414089893301328} | train loss {'Reaction outcome loss': 0.32850796038076, 'Total loss': 0.32850796038076}
2023-01-05 12:07:54,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:54,626 INFO:     Epoch: 64
2023-01-05 12:07:56,807 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37504761616388954, 'Total loss': 0.37504761616388954} | train loss {'Reaction outcome loss': 0.32574380270164943, 'Total loss': 0.32574380270164943}
2023-01-05 12:07:56,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:56,807 INFO:     Epoch: 65
2023-01-05 12:07:58,977 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35861321687698366, 'Total loss': 0.35861321687698366} | train loss {'Reaction outcome loss': 0.3188840208332176, 'Total loss': 0.3188840208332176}
2023-01-05 12:07:58,977 INFO:     Found new best model at epoch 65
2023-01-05 12:07:58,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:07:58,978 INFO:     Epoch: 66
2023-01-05 12:08:01,159 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4251609702905019, 'Total loss': 0.4251609702905019} | train loss {'Reaction outcome loss': 0.35134015200605645, 'Total loss': 0.35134015200605645}
2023-01-05 12:08:01,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:01,160 INFO:     Epoch: 67
2023-01-05 12:08:03,317 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43355564375718436, 'Total loss': 0.43355564375718436} | train loss {'Reaction outcome loss': 0.31922687017156376, 'Total loss': 0.31922687017156376}
2023-01-05 12:08:03,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:03,318 INFO:     Epoch: 68
2023-01-05 12:08:05,483 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4168117555479209, 'Total loss': 0.4168117555479209} | train loss {'Reaction outcome loss': 0.3135625960818235, 'Total loss': 0.3135625960818235}
2023-01-05 12:08:05,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:05,483 INFO:     Epoch: 69
2023-01-05 12:08:07,637 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4379163751999537, 'Total loss': 0.4379163751999537} | train loss {'Reaction outcome loss': 0.31866945720453194, 'Total loss': 0.31866945720453194}
2023-01-05 12:08:07,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:07,637 INFO:     Epoch: 70
2023-01-05 12:08:09,813 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38801048944393796, 'Total loss': 0.38801048944393796} | train loss {'Reaction outcome loss': 0.3173521475364923, 'Total loss': 0.3173521475364923}
2023-01-05 12:08:09,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:09,813 INFO:     Epoch: 71
2023-01-05 12:08:11,969 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4039091726144155, 'Total loss': 0.4039091726144155} | train loss {'Reaction outcome loss': 0.31024217409203236, 'Total loss': 0.31024217409203236}
2023-01-05 12:08:11,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:11,970 INFO:     Epoch: 72
2023-01-05 12:08:14,115 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3990131139755249, 'Total loss': 0.3990131139755249} | train loss {'Reaction outcome loss': 0.31033929488014267, 'Total loss': 0.31033929488014267}
2023-01-05 12:08:14,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:14,116 INFO:     Epoch: 73
2023-01-05 12:08:16,276 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40932518045107524, 'Total loss': 0.40932518045107524} | train loss {'Reaction outcome loss': 0.31353840720502363, 'Total loss': 0.31353840720502363}
2023-01-05 12:08:16,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:16,276 INFO:     Epoch: 74
2023-01-05 12:08:18,437 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37264234175284705, 'Total loss': 0.37264234175284705} | train loss {'Reaction outcome loss': 0.31971795315564744, 'Total loss': 0.31971795315564744}
2023-01-05 12:08:18,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:18,437 INFO:     Epoch: 75
2023-01-05 12:08:20,598 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4135496407747269, 'Total loss': 0.4135496407747269} | train loss {'Reaction outcome loss': 0.3119135042247565, 'Total loss': 0.3119135042247565}
2023-01-05 12:08:20,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:20,599 INFO:     Epoch: 76
2023-01-05 12:08:22,741 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4075634698073069, 'Total loss': 0.4075634698073069} | train loss {'Reaction outcome loss': 0.34626826920641074, 'Total loss': 0.34626826920641074}
2023-01-05 12:08:22,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:22,741 INFO:     Epoch: 77
2023-01-05 12:08:24,892 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4363237351179123, 'Total loss': 0.4363237351179123} | train loss {'Reaction outcome loss': 0.30813102125844405, 'Total loss': 0.30813102125844405}
2023-01-05 12:08:24,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:24,893 INFO:     Epoch: 78
2023-01-05 12:08:27,035 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4265068396925926, 'Total loss': 0.4265068396925926} | train loss {'Reaction outcome loss': 0.3089032230925733, 'Total loss': 0.3089032230925733}
2023-01-05 12:08:27,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:27,035 INFO:     Epoch: 79
2023-01-05 12:08:29,215 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4366012801726659, 'Total loss': 0.4366012801726659} | train loss {'Reaction outcome loss': 0.2997461891053177, 'Total loss': 0.2997461891053177}
2023-01-05 12:08:29,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:29,215 INFO:     Epoch: 80
2023-01-05 12:08:31,432 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40136382381121316, 'Total loss': 0.40136382381121316} | train loss {'Reaction outcome loss': 0.30782162986587785, 'Total loss': 0.30782162986587785}
2023-01-05 12:08:31,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:31,432 INFO:     Epoch: 81
2023-01-05 12:08:33,643 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4207805822292964, 'Total loss': 0.4207805822292964} | train loss {'Reaction outcome loss': 0.30200672660156264, 'Total loss': 0.30200672660156264}
2023-01-05 12:08:33,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:33,643 INFO:     Epoch: 82
2023-01-05 12:08:35,866 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.449477614959081, 'Total loss': 0.449477614959081} | train loss {'Reaction outcome loss': 0.2969543750910763, 'Total loss': 0.2969543750910763}
2023-01-05 12:08:35,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:35,867 INFO:     Epoch: 83
2023-01-05 12:08:38,043 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4231147885322571, 'Total loss': 0.4231147885322571} | train loss {'Reaction outcome loss': 0.3000338882717398, 'Total loss': 0.3000338882717398}
2023-01-05 12:08:38,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:38,044 INFO:     Epoch: 84
2023-01-05 12:08:40,222 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46635299225648247, 'Total loss': 0.46635299225648247} | train loss {'Reaction outcome loss': 0.29946805575889524, 'Total loss': 0.29946805575889524}
2023-01-05 12:08:40,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:40,222 INFO:     Epoch: 85
2023-01-05 12:08:42,385 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40324492355187735, 'Total loss': 0.40324492355187735} | train loss {'Reaction outcome loss': 0.2962589987816856, 'Total loss': 0.2962589987816856}
2023-01-05 12:08:42,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:42,385 INFO:     Epoch: 86
2023-01-05 12:08:44,557 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.371186175942421, 'Total loss': 0.371186175942421} | train loss {'Reaction outcome loss': 0.29351880623131443, 'Total loss': 0.29351880623131443}
2023-01-05 12:08:44,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:44,558 INFO:     Epoch: 87
2023-01-05 12:08:46,729 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3604311595360438, 'Total loss': 0.3604311595360438} | train loss {'Reaction outcome loss': 0.2873655087218588, 'Total loss': 0.2873655087218588}
2023-01-05 12:08:46,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:46,729 INFO:     Epoch: 88
2023-01-05 12:08:48,879 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3679906596740087, 'Total loss': 0.3679906596740087} | train loss {'Reaction outcome loss': 0.2892581993120088, 'Total loss': 0.2892581993120088}
2023-01-05 12:08:48,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:48,880 INFO:     Epoch: 89
2023-01-05 12:08:51,046 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35926107118527095, 'Total loss': 0.35926107118527095} | train loss {'Reaction outcome loss': 0.2841232093894665, 'Total loss': 0.2841232093894665}
2023-01-05 12:08:51,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:51,047 INFO:     Epoch: 90
2023-01-05 12:08:53,220 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3537189121047656, 'Total loss': 0.3537189121047656} | train loss {'Reaction outcome loss': 0.28319817183512275, 'Total loss': 0.28319817183512275}
2023-01-05 12:08:53,220 INFO:     Found new best model at epoch 90
2023-01-05 12:08:53,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:53,221 INFO:     Epoch: 91
2023-01-05 12:08:55,404 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36420742770036063, 'Total loss': 0.36420742770036063} | train loss {'Reaction outcome loss': 0.32447545327179966, 'Total loss': 0.32447545327179966}
2023-01-05 12:08:55,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:55,404 INFO:     Epoch: 92
2023-01-05 12:08:57,561 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3739041080077489, 'Total loss': 0.3739041080077489} | train loss {'Reaction outcome loss': 0.28235784267999936, 'Total loss': 0.28235784267999936}
2023-01-05 12:08:57,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:57,561 INFO:     Epoch: 93
2023-01-05 12:08:59,756 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3930174641311169, 'Total loss': 0.3930174641311169} | train loss {'Reaction outcome loss': 0.26936644006206695, 'Total loss': 0.26936644006206695}
2023-01-05 12:08:59,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:08:59,756 INFO:     Epoch: 94
2023-01-05 12:09:01,914 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3681355079015096, 'Total loss': 0.3681355079015096} | train loss {'Reaction outcome loss': 0.2811904158578187, 'Total loss': 0.2811904158578187}
2023-01-05 12:09:01,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:01,914 INFO:     Epoch: 95
2023-01-05 12:09:04,076 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36040897369384767, 'Total loss': 0.36040897369384767} | train loss {'Reaction outcome loss': 0.31443451886888646, 'Total loss': 0.31443451886888646}
2023-01-05 12:09:04,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:04,077 INFO:     Epoch: 96
2023-01-05 12:09:06,243 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45551377336184184, 'Total loss': 0.45551377336184184} | train loss {'Reaction outcome loss': 0.41929274312881887, 'Total loss': 0.41929274312881887}
2023-01-05 12:09:06,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:06,244 INFO:     Epoch: 97
2023-01-05 12:09:08,408 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38152117778857547, 'Total loss': 0.38152117778857547} | train loss {'Reaction outcome loss': 0.3098321334877308, 'Total loss': 0.3098321334877308}
2023-01-05 12:09:08,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:08,409 INFO:     Epoch: 98
2023-01-05 12:09:10,608 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4028347412745158, 'Total loss': 0.4028347412745158} | train loss {'Reaction outcome loss': 0.2932954504832868, 'Total loss': 0.2932954504832868}
2023-01-05 12:09:10,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:10,608 INFO:     Epoch: 99
2023-01-05 12:09:12,777 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38324486240744593, 'Total loss': 0.38324486240744593} | train loss {'Reaction outcome loss': 0.28359026606009086, 'Total loss': 0.28359026606009086}
2023-01-05 12:09:12,777 INFO:     Best model found after epoch 91 of 100.
2023-01-05 12:09:12,777 INFO:   Done with stage: TRAINING
2023-01-05 12:09:12,777 INFO:   Starting stage: EVALUATION
2023-01-05 12:09:12,909 INFO:   Done with stage: EVALUATION
2023-01-05 12:09:12,910 INFO:   Leaving out SEQ value Fold_5
2023-01-05 12:09:12,922 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 12:09:12,922 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:09:13,573 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:09:13,573 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:09:13,643 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:09:13,643 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:09:13,643 INFO:     No hyperparam tuning for this model
2023-01-05 12:09:13,643 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:09:13,643 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:09:13,644 INFO:     None feature selector for col prot
2023-01-05 12:09:13,644 INFO:     None feature selector for col prot
2023-01-05 12:09:13,644 INFO:     None feature selector for col prot
2023-01-05 12:09:13,644 INFO:     None feature selector for col chem
2023-01-05 12:09:13,645 INFO:     None feature selector for col chem
2023-01-05 12:09:13,645 INFO:     None feature selector for col chem
2023-01-05 12:09:13,645 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:09:13,645 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:09:13,646 INFO:     Number of params in model 72901
2023-01-05 12:09:13,650 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:09:13,650 INFO:   Starting stage: TRAINING
2023-01-05 12:09:13,710 INFO:     Val loss before train {'Reaction outcome loss': 1.043002156416575, 'Total loss': 1.043002156416575}
2023-01-05 12:09:13,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:13,710 INFO:     Epoch: 0
2023-01-05 12:09:15,876 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8328313906987508, 'Total loss': 0.8328313906987508} | train loss {'Reaction outcome loss': 0.94244469286523, 'Total loss': 0.94244469286523}
2023-01-05 12:09:15,876 INFO:     Found new best model at epoch 0
2023-01-05 12:09:15,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:15,878 INFO:     Epoch: 1
2023-01-05 12:09:18,062 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.603770316640536, 'Total loss': 0.603770316640536} | train loss {'Reaction outcome loss': 0.7536646319904189, 'Total loss': 0.7536646319904189}
2023-01-05 12:09:18,062 INFO:     Found new best model at epoch 1
2023-01-05 12:09:18,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:18,063 INFO:     Epoch: 2
2023-01-05 12:09:20,255 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4833950440088908, 'Total loss': 0.4833950440088908} | train loss {'Reaction outcome loss': 0.5929715530609415, 'Total loss': 0.5929715530609415}
2023-01-05 12:09:20,256 INFO:     Found new best model at epoch 2
2023-01-05 12:09:20,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:20,258 INFO:     Epoch: 3
2023-01-05 12:09:22,437 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4613690217336019, 'Total loss': 0.4613690217336019} | train loss {'Reaction outcome loss': 0.53128334689224, 'Total loss': 0.53128334689224}
2023-01-05 12:09:22,437 INFO:     Found new best model at epoch 3
2023-01-05 12:09:22,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:22,439 INFO:     Epoch: 4
2023-01-05 12:09:24,596 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4371506611506144, 'Total loss': 0.4371506611506144} | train loss {'Reaction outcome loss': 0.5105505287411042, 'Total loss': 0.5105505287411042}
2023-01-05 12:09:24,596 INFO:     Found new best model at epoch 4
2023-01-05 12:09:24,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:24,598 INFO:     Epoch: 5
2023-01-05 12:09:26,777 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4411946396032969, 'Total loss': 0.4411946396032969} | train loss {'Reaction outcome loss': 0.4998534162553277, 'Total loss': 0.4998534162553277}
2023-01-05 12:09:26,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:26,778 INFO:     Epoch: 6
2023-01-05 12:09:28,959 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4315829078356425, 'Total loss': 0.4315829078356425} | train loss {'Reaction outcome loss': 0.49025428392316983, 'Total loss': 0.49025428392316983}
2023-01-05 12:09:28,959 INFO:     Found new best model at epoch 6
2023-01-05 12:09:28,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:28,960 INFO:     Epoch: 7
2023-01-05 12:09:31,150 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42274969120820366, 'Total loss': 0.42274969120820366} | train loss {'Reaction outcome loss': 0.4825578090073406, 'Total loss': 0.4825578090073406}
2023-01-05 12:09:31,150 INFO:     Found new best model at epoch 7
2023-01-05 12:09:31,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:31,152 INFO:     Epoch: 8
2023-01-05 12:09:33,333 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45077646176020303, 'Total loss': 0.45077646176020303} | train loss {'Reaction outcome loss': 0.49170868492860725, 'Total loss': 0.49170868492860725}
2023-01-05 12:09:33,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:33,333 INFO:     Epoch: 9
2023-01-05 12:09:35,508 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4290998101234436, 'Total loss': 0.4290998101234436} | train loss {'Reaction outcome loss': 0.4701388053380061, 'Total loss': 0.4701388053380061}
2023-01-05 12:09:35,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:35,508 INFO:     Epoch: 10
2023-01-05 12:09:37,681 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45965301195780434, 'Total loss': 0.45965301195780434} | train loss {'Reaction outcome loss': 0.49007138134776684, 'Total loss': 0.49007138134776684}
2023-01-05 12:09:37,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:37,681 INFO:     Epoch: 11
2023-01-05 12:09:39,873 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4171577880779902, 'Total loss': 0.4171577880779902} | train loss {'Reaction outcome loss': 0.45301918336084834, 'Total loss': 0.45301918336084834}
2023-01-05 12:09:39,874 INFO:     Found new best model at epoch 11
2023-01-05 12:09:39,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:39,875 INFO:     Epoch: 12
2023-01-05 12:09:42,062 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44136594931284584, 'Total loss': 0.44136594931284584} | train loss {'Reaction outcome loss': 0.44914481080933544, 'Total loss': 0.44914481080933544}
2023-01-05 12:09:42,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:42,063 INFO:     Epoch: 13
2023-01-05 12:09:44,253 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4089858795205752, 'Total loss': 0.4089858795205752} | train loss {'Reaction outcome loss': 0.4466688556827991, 'Total loss': 0.4466688556827991}
2023-01-05 12:09:44,253 INFO:     Found new best model at epoch 13
2023-01-05 12:09:44,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:44,254 INFO:     Epoch: 14
2023-01-05 12:09:46,436 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4121823062499364, 'Total loss': 0.4121823062499364} | train loss {'Reaction outcome loss': 0.4359137887671671, 'Total loss': 0.4359137887671671}
2023-01-05 12:09:46,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:46,436 INFO:     Epoch: 15
2023-01-05 12:09:48,611 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4157423744599024, 'Total loss': 0.4157423744599024} | train loss {'Reaction outcome loss': 0.44303863428493956, 'Total loss': 0.44303863428493956}
2023-01-05 12:09:48,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:48,611 INFO:     Epoch: 16
2023-01-05 12:09:50,810 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4114147444566091, 'Total loss': 0.4114147444566091} | train loss {'Reaction outcome loss': 0.4360144838987701, 'Total loss': 0.4360144838987701}
2023-01-05 12:09:50,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:50,810 INFO:     Epoch: 17
2023-01-05 12:09:53,007 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3980829770366351, 'Total loss': 0.3980829770366351} | train loss {'Reaction outcome loss': 0.4263583384066199, 'Total loss': 0.4263583384066199}
2023-01-05 12:09:53,007 INFO:     Found new best model at epoch 17
2023-01-05 12:09:53,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:53,009 INFO:     Epoch: 18
2023-01-05 12:09:55,187 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41885493993759154, 'Total loss': 0.41885493993759154} | train loss {'Reaction outcome loss': 0.42969481658149994, 'Total loss': 0.42969481658149994}
2023-01-05 12:09:55,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:55,188 INFO:     Epoch: 19
2023-01-05 12:09:57,382 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41194659074147544, 'Total loss': 0.41194659074147544} | train loss {'Reaction outcome loss': 0.4313187245785704, 'Total loss': 0.4313187245785704}
2023-01-05 12:09:57,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:57,382 INFO:     Epoch: 20
2023-01-05 12:09:59,562 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3863475859165192, 'Total loss': 0.3863475859165192} | train loss {'Reaction outcome loss': 0.4199144921866178, 'Total loss': 0.4199144921866178}
2023-01-05 12:09:59,562 INFO:     Found new best model at epoch 20
2023-01-05 12:09:59,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:09:59,563 INFO:     Epoch: 21
2023-01-05 12:10:01,759 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3916185736656189, 'Total loss': 0.3916185736656189} | train loss {'Reaction outcome loss': 0.41878712459035433, 'Total loss': 0.41878712459035433}
2023-01-05 12:10:01,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:01,760 INFO:     Epoch: 22
2023-01-05 12:10:03,955 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40995662212371825, 'Total loss': 0.40995662212371825} | train loss {'Reaction outcome loss': 0.414321028048753, 'Total loss': 0.414321028048753}
2023-01-05 12:10:03,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:03,955 INFO:     Epoch: 23
2023-01-05 12:10:06,142 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39049976964791616, 'Total loss': 0.39049976964791616} | train loss {'Reaction outcome loss': 0.4131271966675674, 'Total loss': 0.4131271966675674}
2023-01-05 12:10:06,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:06,142 INFO:     Epoch: 24
2023-01-05 12:10:08,339 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4035067051649094, 'Total loss': 0.4035067051649094} | train loss {'Reaction outcome loss': 0.4147956096364752, 'Total loss': 0.4147956096364752}
2023-01-05 12:10:08,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:08,339 INFO:     Epoch: 25
2023-01-05 12:10:10,504 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4012183239062627, 'Total loss': 0.4012183239062627} | train loss {'Reaction outcome loss': 0.45530254364796524, 'Total loss': 0.45530254364796524}
2023-01-05 12:10:10,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:10,504 INFO:     Epoch: 26
2023-01-05 12:10:12,697 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3983085463444392, 'Total loss': 0.3983085463444392} | train loss {'Reaction outcome loss': 0.40507053628992423, 'Total loss': 0.40507053628992423}
2023-01-05 12:10:12,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:12,697 INFO:     Epoch: 27
2023-01-05 12:10:14,892 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4002725472052892, 'Total loss': 0.4002725472052892} | train loss {'Reaction outcome loss': 0.39868833265348297, 'Total loss': 0.39868833265348297}
2023-01-05 12:10:14,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:14,893 INFO:     Epoch: 28
2023-01-05 12:10:17,074 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4056336998939514, 'Total loss': 0.4056336998939514} | train loss {'Reaction outcome loss': 0.3964174541010373, 'Total loss': 0.3964174541010373}
2023-01-05 12:10:17,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:17,074 INFO:     Epoch: 29
2023-01-05 12:10:19,252 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38627275625864665, 'Total loss': 0.38627275625864665} | train loss {'Reaction outcome loss': 0.3961118426211043, 'Total loss': 0.3961118426211043}
2023-01-05 12:10:19,252 INFO:     Found new best model at epoch 29
2023-01-05 12:10:19,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:19,254 INFO:     Epoch: 30
2023-01-05 12:10:21,431 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.438324581583341, 'Total loss': 0.438324581583341} | train loss {'Reaction outcome loss': 0.38728468337406713, 'Total loss': 0.38728468337406713}
2023-01-05 12:10:21,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:21,431 INFO:     Epoch: 31
2023-01-05 12:10:23,585 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4030565023422241, 'Total loss': 0.4030565023422241} | train loss {'Reaction outcome loss': 0.39285723341194884, 'Total loss': 0.39285723341194884}
2023-01-05 12:10:23,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:23,585 INFO:     Epoch: 32
2023-01-05 12:10:25,769 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40118179718653363, 'Total loss': 0.40118179718653363} | train loss {'Reaction outcome loss': 0.38366638054603885, 'Total loss': 0.38366638054603885}
2023-01-05 12:10:25,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:25,769 INFO:     Epoch: 33
2023-01-05 12:10:27,952 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41151128013928734, 'Total loss': 0.41151128013928734} | train loss {'Reaction outcome loss': 0.38525766547452117, 'Total loss': 0.38525766547452117}
2023-01-05 12:10:27,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:27,953 INFO:     Epoch: 34
2023-01-05 12:10:30,129 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4336694896221161, 'Total loss': 0.4336694896221161} | train loss {'Reaction outcome loss': 0.37801385413457983, 'Total loss': 0.37801385413457983}
2023-01-05 12:10:30,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:30,129 INFO:     Epoch: 35
2023-01-05 12:10:32,322 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3856570104757945, 'Total loss': 0.3856570104757945} | train loss {'Reaction outcome loss': 0.37417060719040374, 'Total loss': 0.37417060719040374}
2023-01-05 12:10:32,323 INFO:     Found new best model at epoch 35
2023-01-05 12:10:32,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:32,324 INFO:     Epoch: 36
2023-01-05 12:10:34,482 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4167271206776301, 'Total loss': 0.4167271206776301} | train loss {'Reaction outcome loss': 0.373860163114749, 'Total loss': 0.373860163114749}
2023-01-05 12:10:34,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:34,482 INFO:     Epoch: 37
2023-01-05 12:10:36,675 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38270669082800546, 'Total loss': 0.38270669082800546} | train loss {'Reaction outcome loss': 0.3736394797089051, 'Total loss': 0.3736394797089051}
2023-01-05 12:10:36,675 INFO:     Found new best model at epoch 37
2023-01-05 12:10:36,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:36,677 INFO:     Epoch: 38
2023-01-05 12:10:38,869 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39560519059499105, 'Total loss': 0.39560519059499105} | train loss {'Reaction outcome loss': 0.37049000129859516, 'Total loss': 0.37049000129859516}
2023-01-05 12:10:38,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:38,870 INFO:     Epoch: 39
2023-01-05 12:10:40,859 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4128935356934865, 'Total loss': 0.4128935356934865} | train loss {'Reaction outcome loss': 0.3661605701714322, 'Total loss': 0.3661605701714322}
2023-01-05 12:10:40,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:40,859 INFO:     Epoch: 40
2023-01-05 12:10:43,052 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39558635652065277, 'Total loss': 0.39558635652065277} | train loss {'Reaction outcome loss': 0.36179825706252206, 'Total loss': 0.36179825706252206}
2023-01-05 12:10:43,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:43,053 INFO:     Epoch: 41
2023-01-05 12:10:45,233 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41244536836942036, 'Total loss': 0.41244536836942036} | train loss {'Reaction outcome loss': 0.35795737714236736, 'Total loss': 0.35795737714236736}
2023-01-05 12:10:45,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:45,234 INFO:     Epoch: 42
2023-01-05 12:10:47,421 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.396329132715861, 'Total loss': 0.396329132715861} | train loss {'Reaction outcome loss': 0.35521003575590643, 'Total loss': 0.35521003575590643}
2023-01-05 12:10:47,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:47,422 INFO:     Epoch: 43
2023-01-05 12:10:49,620 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4068203200896581, 'Total loss': 0.4068203200896581} | train loss {'Reaction outcome loss': 0.3506998060278736, 'Total loss': 0.3506998060278736}
2023-01-05 12:10:49,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:49,620 INFO:     Epoch: 44
2023-01-05 12:10:51,804 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38778619666894276, 'Total loss': 0.38778619666894276} | train loss {'Reaction outcome loss': 0.36168911043500557, 'Total loss': 0.36168911043500557}
2023-01-05 12:10:51,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:51,805 INFO:     Epoch: 45
2023-01-05 12:10:53,989 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4111752192179362, 'Total loss': 0.4111752192179362} | train loss {'Reaction outcome loss': 0.3623821947089248, 'Total loss': 0.3623821947089248}
2023-01-05 12:10:53,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:53,990 INFO:     Epoch: 46
2023-01-05 12:10:56,172 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4073333223660787, 'Total loss': 0.4073333223660787} | train loss {'Reaction outcome loss': 0.35271914516562136, 'Total loss': 0.35271914516562136}
2023-01-05 12:10:56,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:56,173 INFO:     Epoch: 47
2023-01-05 12:10:58,348 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3680860648552577, 'Total loss': 0.3680860648552577} | train loss {'Reaction outcome loss': 0.362513837918295, 'Total loss': 0.362513837918295}
2023-01-05 12:10:58,348 INFO:     Found new best model at epoch 47
2023-01-05 12:10:58,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:10:58,349 INFO:     Epoch: 48
2023-01-05 12:11:00,596 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4125624815622965, 'Total loss': 0.4125624815622965} | train loss {'Reaction outcome loss': 0.34360615826132573, 'Total loss': 0.34360615826132573}
2023-01-05 12:11:00,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:00,596 INFO:     Epoch: 49
2023-01-05 12:11:02,860 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3784216115872065, 'Total loss': 0.3784216115872065} | train loss {'Reaction outcome loss': 0.34229116874875204, 'Total loss': 0.34229116874875204}
2023-01-05 12:11:02,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:02,861 INFO:     Epoch: 50
2023-01-05 12:11:05,120 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3760698383053144, 'Total loss': 0.3760698383053144} | train loss {'Reaction outcome loss': 0.3364840014086888, 'Total loss': 0.3364840014086888}
2023-01-05 12:11:05,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:05,120 INFO:     Epoch: 51
2023-01-05 12:11:07,359 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3821400215228399, 'Total loss': 0.3821400215228399} | train loss {'Reaction outcome loss': 0.3314519636602937, 'Total loss': 0.3314519636602937}
2023-01-05 12:11:07,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:07,361 INFO:     Epoch: 52
2023-01-05 12:11:09,558 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3697373886903127, 'Total loss': 0.3697373886903127} | train loss {'Reaction outcome loss': 0.33049980271945073, 'Total loss': 0.33049980271945073}
2023-01-05 12:11:09,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:09,558 INFO:     Epoch: 53
2023-01-05 12:11:11,788 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.34121255030234654, 'Total loss': 0.34121255030234654} | train loss {'Reaction outcome loss': 0.33167366481654387, 'Total loss': 0.33167366481654387}
2023-01-05 12:11:11,788 INFO:     Found new best model at epoch 53
2023-01-05 12:11:11,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:11,790 INFO:     Epoch: 54
2023-01-05 12:11:14,044 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36800701717535655, 'Total loss': 0.36800701717535655} | train loss {'Reaction outcome loss': 0.32896080768304, 'Total loss': 0.32896080768304}
2023-01-05 12:11:14,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:14,045 INFO:     Epoch: 55
2023-01-05 12:11:16,235 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37625956485668816, 'Total loss': 0.37625956485668816} | train loss {'Reaction outcome loss': 0.3296428221561339, 'Total loss': 0.3296428221561339}
2023-01-05 12:11:16,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:16,235 INFO:     Epoch: 56
2023-01-05 12:11:18,416 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37901743352413175, 'Total loss': 0.37901743352413175} | train loss {'Reaction outcome loss': 0.3348930385638622, 'Total loss': 0.3348930385638622}
2023-01-05 12:11:18,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:18,416 INFO:     Epoch: 57
2023-01-05 12:11:20,571 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3955738842487335, 'Total loss': 0.3955738842487335} | train loss {'Reaction outcome loss': 0.34594495557552285, 'Total loss': 0.34594495557552285}
2023-01-05 12:11:20,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:20,571 INFO:     Epoch: 58
2023-01-05 12:11:22,735 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3672788679599762, 'Total loss': 0.3672788679599762} | train loss {'Reaction outcome loss': 0.3227151934516387, 'Total loss': 0.3227151934516387}
2023-01-05 12:11:22,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:22,735 INFO:     Epoch: 59
2023-01-05 12:11:24,893 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3753787318865458, 'Total loss': 0.3753787318865458} | train loss {'Reaction outcome loss': 0.32290700572016445, 'Total loss': 0.32290700572016445}
2023-01-05 12:11:24,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:24,893 INFO:     Epoch: 60
2023-01-05 12:11:27,062 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4232878774404526, 'Total loss': 0.4232878774404526} | train loss {'Reaction outcome loss': 0.3757635446373319, 'Total loss': 0.3757635446373319}
2023-01-05 12:11:27,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:27,063 INFO:     Epoch: 61
2023-01-05 12:11:29,235 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4198458919922511, 'Total loss': 0.4198458919922511} | train loss {'Reaction outcome loss': 0.40433007364660717, 'Total loss': 0.40433007364660717}
2023-01-05 12:11:29,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:29,235 INFO:     Epoch: 62
2023-01-05 12:11:31,408 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3839587281147639, 'Total loss': 0.3839587281147639} | train loss {'Reaction outcome loss': 0.3443218275113369, 'Total loss': 0.3443218275113369}
2023-01-05 12:11:31,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:31,408 INFO:     Epoch: 63
2023-01-05 12:11:33,550 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3782859519124031, 'Total loss': 0.3782859519124031} | train loss {'Reaction outcome loss': 0.3245715222361943, 'Total loss': 0.3245715222361943}
2023-01-05 12:11:33,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:33,551 INFO:     Epoch: 64
2023-01-05 12:11:35,721 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3872497111558914, 'Total loss': 0.3872497111558914} | train loss {'Reaction outcome loss': 0.3155062301084399, 'Total loss': 0.3155062301084399}
2023-01-05 12:11:35,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:35,721 INFO:     Epoch: 65
2023-01-05 12:11:37,888 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38358402053515117, 'Total loss': 0.38358402053515117} | train loss {'Reaction outcome loss': 0.31092035351658537, 'Total loss': 0.31092035351658537}
2023-01-05 12:11:37,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:37,888 INFO:     Epoch: 66
2023-01-05 12:11:40,083 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.352805091937383, 'Total loss': 0.352805091937383} | train loss {'Reaction outcome loss': 0.3022454497503651, 'Total loss': 0.3022454497503651}
2023-01-05 12:11:40,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:40,083 INFO:     Epoch: 67
2023-01-05 12:11:42,266 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.369082373380661, 'Total loss': 0.369082373380661} | train loss {'Reaction outcome loss': 0.3060420459892223, 'Total loss': 0.3060420459892223}
2023-01-05 12:11:42,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:42,266 INFO:     Epoch: 68
2023-01-05 12:11:44,456 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35455381373564404, 'Total loss': 0.35455381373564404} | train loss {'Reaction outcome loss': 0.300444198031218, 'Total loss': 0.300444198031218}
2023-01-05 12:11:44,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:44,458 INFO:     Epoch: 69
2023-01-05 12:11:46,668 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3827135850985845, 'Total loss': 0.3827135850985845} | train loss {'Reaction outcome loss': 0.29879224579612573, 'Total loss': 0.29879224579612573}
2023-01-05 12:11:46,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:46,669 INFO:     Epoch: 70
2023-01-05 12:11:48,898 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38144764105478923, 'Total loss': 0.38144764105478923} | train loss {'Reaction outcome loss': 0.2959473626595291, 'Total loss': 0.2959473626595291}
2023-01-05 12:11:48,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:48,898 INFO:     Epoch: 71
2023-01-05 12:11:51,115 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35936877826849617, 'Total loss': 0.35936877826849617} | train loss {'Reaction outcome loss': 0.299854282231114, 'Total loss': 0.299854282231114}
2023-01-05 12:11:51,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:51,116 INFO:     Epoch: 72
2023-01-05 12:11:53,309 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4101152002811432, 'Total loss': 0.4101152002811432} | train loss {'Reaction outcome loss': 0.2920113663117988, 'Total loss': 0.2920113663117988}
2023-01-05 12:11:53,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:53,309 INFO:     Epoch: 73
2023-01-05 12:11:55,481 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3710766762495041, 'Total loss': 0.3710766762495041} | train loss {'Reaction outcome loss': 0.2966416214228535, 'Total loss': 0.2966416214228535}
2023-01-05 12:11:55,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:55,481 INFO:     Epoch: 74
2023-01-05 12:11:57,652 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3757122327884038, 'Total loss': 0.3757122327884038} | train loss {'Reaction outcome loss': 0.29483545221307356, 'Total loss': 0.29483545221307356}
2023-01-05 12:11:57,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:57,652 INFO:     Epoch: 75
2023-01-05 12:11:59,815 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3648089587688446, 'Total loss': 0.3648089587688446} | train loss {'Reaction outcome loss': 0.287632594592941, 'Total loss': 0.287632594592941}
2023-01-05 12:11:59,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:11:59,815 INFO:     Epoch: 76
2023-01-05 12:12:01,996 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36654806236426035, 'Total loss': 0.36654806236426035} | train loss {'Reaction outcome loss': 0.2842241860605587, 'Total loss': 0.2842241860605587}
2023-01-05 12:12:01,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:01,996 INFO:     Epoch: 77
2023-01-05 12:12:04,174 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3892792691787084, 'Total loss': 0.3892792691787084} | train loss {'Reaction outcome loss': 0.2830178856181548, 'Total loss': 0.2830178856181548}
2023-01-05 12:12:04,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:04,175 INFO:     Epoch: 78
2023-01-05 12:12:06,334 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34977583090464276, 'Total loss': 0.34977583090464276} | train loss {'Reaction outcome loss': 0.2887037449425248, 'Total loss': 0.2887037449425248}
2023-01-05 12:12:06,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:06,334 INFO:     Epoch: 79
2023-01-05 12:12:08,504 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3646902245779832, 'Total loss': 0.3646902245779832} | train loss {'Reaction outcome loss': 0.27933392955869285, 'Total loss': 0.27933392955869285}
2023-01-05 12:12:08,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:08,505 INFO:     Epoch: 80
2023-01-05 12:12:10,675 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3581456204255422, 'Total loss': 0.3581456204255422} | train loss {'Reaction outcome loss': 0.28023345348175505, 'Total loss': 0.28023345348175505}
2023-01-05 12:12:10,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:10,676 INFO:     Epoch: 81
2023-01-05 12:12:12,840 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38304111659526824, 'Total loss': 0.38304111659526824} | train loss {'Reaction outcome loss': 0.27497568602700706, 'Total loss': 0.27497568602700706}
2023-01-05 12:12:12,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:12,841 INFO:     Epoch: 82
2023-01-05 12:12:15,002 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38981210223088664, 'Total loss': 0.38981210223088664} | train loss {'Reaction outcome loss': 0.27595302827008394, 'Total loss': 0.27595302827008394}
2023-01-05 12:12:15,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:15,003 INFO:     Epoch: 83
2023-01-05 12:12:17,140 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42156050900618236, 'Total loss': 0.42156050900618236} | train loss {'Reaction outcome loss': 0.35278449729557376, 'Total loss': 0.35278449729557376}
2023-01-05 12:12:17,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:17,141 INFO:     Epoch: 84
2023-01-05 12:12:19,302 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3741766942044099, 'Total loss': 0.3741766942044099} | train loss {'Reaction outcome loss': 0.2889420413623051, 'Total loss': 0.2889420413623051}
2023-01-05 12:12:19,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:19,302 INFO:     Epoch: 85
2023-01-05 12:12:21,452 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3796818311015765, 'Total loss': 0.3796818311015765} | train loss {'Reaction outcome loss': 0.2735539162362777, 'Total loss': 0.2735539162362777}
2023-01-05 12:12:21,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:21,453 INFO:     Epoch: 86
2023-01-05 12:12:23,629 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36519198417663573, 'Total loss': 0.36519198417663573} | train loss {'Reaction outcome loss': 0.27731157438762055, 'Total loss': 0.27731157438762055}
2023-01-05 12:12:23,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:23,629 INFO:     Epoch: 87
2023-01-05 12:12:25,785 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34342132483919463, 'Total loss': 0.34342132483919463} | train loss {'Reaction outcome loss': 0.26631155711315246, 'Total loss': 0.26631155711315246}
2023-01-05 12:12:25,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:25,786 INFO:     Epoch: 88
2023-01-05 12:12:27,942 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3684533040970564, 'Total loss': 0.3684533040970564} | train loss {'Reaction outcome loss': 0.26922592171805276, 'Total loss': 0.26922592171805276}
2023-01-05 12:12:27,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:27,942 INFO:     Epoch: 89
2023-01-05 12:12:30,093 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3978205864628156, 'Total loss': 0.3978205864628156} | train loss {'Reaction outcome loss': 0.2695574195017073, 'Total loss': 0.2695574195017073}
2023-01-05 12:12:30,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:30,093 INFO:     Epoch: 90
2023-01-05 12:12:32,268 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38392441272735595, 'Total loss': 0.38392441272735595} | train loss {'Reaction outcome loss': 0.26513224741780583, 'Total loss': 0.26513224741780583}
2023-01-05 12:12:32,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:32,268 INFO:     Epoch: 91
2023-01-05 12:12:34,436 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3662945061922073, 'Total loss': 0.3662945061922073} | train loss {'Reaction outcome loss': 0.26829532649202703, 'Total loss': 0.26829532649202703}
2023-01-05 12:12:34,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:34,437 INFO:     Epoch: 92
2023-01-05 12:12:36,595 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40033162931601207, 'Total loss': 0.40033162931601207} | train loss {'Reaction outcome loss': 0.264896666928046, 'Total loss': 0.264896666928046}
2023-01-05 12:12:36,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:36,595 INFO:     Epoch: 93
2023-01-05 12:12:38,748 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3848629787564278, 'Total loss': 0.3848629787564278} | train loss {'Reaction outcome loss': 0.2590392672834729, 'Total loss': 0.2590392672834729}
2023-01-05 12:12:38,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:38,748 INFO:     Epoch: 94
2023-01-05 12:12:40,899 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3891575415929159, 'Total loss': 0.3891575415929159} | train loss {'Reaction outcome loss': 0.2607783398429013, 'Total loss': 0.2607783398429013}
2023-01-05 12:12:40,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:40,899 INFO:     Epoch: 95
2023-01-05 12:12:43,064 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3649222532908122, 'Total loss': 0.3649222532908122} | train loss {'Reaction outcome loss': 0.2584749948287356, 'Total loss': 0.2584749948287356}
2023-01-05 12:12:43,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:43,064 INFO:     Epoch: 96
2023-01-05 12:12:45,234 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.393884931008021, 'Total loss': 0.393884931008021} | train loss {'Reaction outcome loss': 0.2787788065582298, 'Total loss': 0.2787788065582298}
2023-01-05 12:12:45,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:45,235 INFO:     Epoch: 97
2023-01-05 12:12:47,416 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36449348628520967, 'Total loss': 0.36449348628520967} | train loss {'Reaction outcome loss': 0.40309313931536145, 'Total loss': 0.40309313931536145}
2023-01-05 12:12:47,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:47,416 INFO:     Epoch: 98
2023-01-05 12:12:49,607 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33891699512799583, 'Total loss': 0.33891699512799583} | train loss {'Reaction outcome loss': 0.29008488176539, 'Total loss': 0.29008488176539}
2023-01-05 12:12:49,608 INFO:     Found new best model at epoch 98
2023-01-05 12:12:49,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:49,609 INFO:     Epoch: 99
2023-01-05 12:12:51,796 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3582935358087222, 'Total loss': 0.3582935358087222} | train loss {'Reaction outcome loss': 0.2791204623797018, 'Total loss': 0.2791204623797018}
2023-01-05 12:12:51,797 INFO:     Best model found after epoch 99 of 100.
2023-01-05 12:12:51,797 INFO:   Done with stage: TRAINING
2023-01-05 12:12:51,797 INFO:   Starting stage: EVALUATION
2023-01-05 12:12:51,930 INFO:   Done with stage: EVALUATION
2023-01-05 12:12:51,930 INFO:   Leaving out SEQ value Fold_6
2023-01-05 12:12:51,943 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 12:12:51,943 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:12:52,610 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:12:52,610 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:12:52,681 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:12:52,681 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:12:52,681 INFO:     No hyperparam tuning for this model
2023-01-05 12:12:52,681 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:12:52,681 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:12:52,682 INFO:     None feature selector for col prot
2023-01-05 12:12:52,682 INFO:     None feature selector for col prot
2023-01-05 12:12:52,682 INFO:     None feature selector for col prot
2023-01-05 12:12:52,683 INFO:     None feature selector for col chem
2023-01-05 12:12:52,683 INFO:     None feature selector for col chem
2023-01-05 12:12:52,683 INFO:     None feature selector for col chem
2023-01-05 12:12:52,683 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:12:52,683 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:12:52,684 INFO:     Number of params in model 72901
2023-01-05 12:12:52,688 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:12:52,688 INFO:   Starting stage: TRAINING
2023-01-05 12:12:52,747 INFO:     Val loss before train {'Reaction outcome loss': 1.016057288646698, 'Total loss': 1.016057288646698}
2023-01-05 12:12:52,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:52,747 INFO:     Epoch: 0
2023-01-05 12:12:54,913 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8953325748443604, 'Total loss': 0.8953325748443604} | train loss {'Reaction outcome loss': 0.9335865779118477, 'Total loss': 0.9335865779118477}
2023-01-05 12:12:54,914 INFO:     Found new best model at epoch 0
2023-01-05 12:12:54,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:54,915 INFO:     Epoch: 1
2023-01-05 12:12:57,092 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6338048716386159, 'Total loss': 0.6338048716386159} | train loss {'Reaction outcome loss': 0.759649233300993, 'Total loss': 0.759649233300993}
2023-01-05 12:12:57,092 INFO:     Found new best model at epoch 1
2023-01-05 12:12:57,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:57,093 INFO:     Epoch: 2
2023-01-05 12:12:59,254 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.592590347925822, 'Total loss': 0.592590347925822} | train loss {'Reaction outcome loss': 0.5881767933783324, 'Total loss': 0.5881767933783324}
2023-01-05 12:12:59,254 INFO:     Found new best model at epoch 2
2023-01-05 12:12:59,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:12:59,256 INFO:     Epoch: 3
2023-01-05 12:13:01,436 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5256147344907125, 'Total loss': 0.5256147344907125} | train loss {'Reaction outcome loss': 0.5367349237743495, 'Total loss': 0.5367349237743495}
2023-01-05 12:13:01,436 INFO:     Found new best model at epoch 3
2023-01-05 12:13:01,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:01,438 INFO:     Epoch: 4
2023-01-05 12:13:03,651 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5328061699867248, 'Total loss': 0.5328061699867248} | train loss {'Reaction outcome loss': 0.5277246925709904, 'Total loss': 0.5277246925709904}
2023-01-05 12:13:03,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:03,651 INFO:     Epoch: 5
2023-01-05 12:13:05,815 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.517912220954895, 'Total loss': 0.517912220954895} | train loss {'Reaction outcome loss': 0.5205005236354697, 'Total loss': 0.5205005236354697}
2023-01-05 12:13:05,816 INFO:     Found new best model at epoch 5
2023-01-05 12:13:05,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:05,817 INFO:     Epoch: 6
2023-01-05 12:13:07,984 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5066687742869059, 'Total loss': 0.5066687742869059} | train loss {'Reaction outcome loss': 0.4925273690048767, 'Total loss': 0.4925273690048767}
2023-01-05 12:13:07,984 INFO:     Found new best model at epoch 6
2023-01-05 12:13:07,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:07,985 INFO:     Epoch: 7
2023-01-05 12:13:10,154 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5521844337383907, 'Total loss': 0.5521844337383907} | train loss {'Reaction outcome loss': 0.48286140191814175, 'Total loss': 0.48286140191814175}
2023-01-05 12:13:10,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:10,155 INFO:     Epoch: 8
2023-01-05 12:13:12,338 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5194302678108216, 'Total loss': 0.5194302678108216} | train loss {'Reaction outcome loss': 0.4947380679372725, 'Total loss': 0.4947380679372725}
2023-01-05 12:13:12,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:12,338 INFO:     Epoch: 9
2023-01-05 12:13:14,498 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5311394890149435, 'Total loss': 0.5311394890149435} | train loss {'Reaction outcome loss': 0.4679031648767599, 'Total loss': 0.4679031648767599}
2023-01-05 12:13:14,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:14,499 INFO:     Epoch: 10
2023-01-05 12:13:16,656 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5214882512887319, 'Total loss': 0.5214882512887319} | train loss {'Reaction outcome loss': 0.4678892040712948, 'Total loss': 0.4678892040712948}
2023-01-05 12:13:16,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:16,656 INFO:     Epoch: 11
2023-01-05 12:13:18,828 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5133807241916657, 'Total loss': 0.5133807241916657} | train loss {'Reaction outcome loss': 0.4700790715498337, 'Total loss': 0.4700790715498337}
2023-01-05 12:13:18,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:18,828 INFO:     Epoch: 12
2023-01-05 12:13:21,014 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.514779676993688, 'Total loss': 0.514779676993688} | train loss {'Reaction outcome loss': 0.4636979976970959, 'Total loss': 0.4636979976970959}
2023-01-05 12:13:21,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:21,015 INFO:     Epoch: 13
2023-01-05 12:13:23,179 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5347949147224427, 'Total loss': 0.5347949147224427} | train loss {'Reaction outcome loss': 0.44990021981715655, 'Total loss': 0.44990021981715655}
2023-01-05 12:13:23,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:23,179 INFO:     Epoch: 14
2023-01-05 12:13:25,348 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.517601490020752, 'Total loss': 0.517601490020752} | train loss {'Reaction outcome loss': 0.44342311611399055, 'Total loss': 0.44342311611399055}
2023-01-05 12:13:25,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:25,348 INFO:     Epoch: 15
2023-01-05 12:13:27,511 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5136949201424916, 'Total loss': 0.5136949201424916} | train loss {'Reaction outcome loss': 0.4449449369440908, 'Total loss': 0.4449449369440908}
2023-01-05 12:13:27,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:27,512 INFO:     Epoch: 16
2023-01-05 12:13:29,676 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49262579878171286, 'Total loss': 0.49262579878171286} | train loss {'Reaction outcome loss': 0.44177018596615264, 'Total loss': 0.44177018596615264}
2023-01-05 12:13:29,677 INFO:     Found new best model at epoch 16
2023-01-05 12:13:29,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:29,678 INFO:     Epoch: 17
2023-01-05 12:13:31,820 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5133140166600545, 'Total loss': 0.5133140166600545} | train loss {'Reaction outcome loss': 0.4311731907579562, 'Total loss': 0.4311731907579562}
2023-01-05 12:13:31,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:31,820 INFO:     Epoch: 18
2023-01-05 12:13:33,983 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5146576623121898, 'Total loss': 0.5146576623121898} | train loss {'Reaction outcome loss': 0.4309604389431036, 'Total loss': 0.4309604389431036}
2023-01-05 12:13:33,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:33,983 INFO:     Epoch: 19
2023-01-05 12:13:36,148 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5462254603703817, 'Total loss': 0.5462254603703817} | train loss {'Reaction outcome loss': 0.4454300464603348, 'Total loss': 0.4454300464603348}
2023-01-05 12:13:36,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:36,148 INFO:     Epoch: 20
2023-01-05 12:13:38,313 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5061784585316976, 'Total loss': 0.5061784585316976} | train loss {'Reaction outcome loss': 0.4313355977524686, 'Total loss': 0.4313355977524686}
2023-01-05 12:13:38,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:38,313 INFO:     Epoch: 21
2023-01-05 12:13:40,455 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4988550086816152, 'Total loss': 0.4988550086816152} | train loss {'Reaction outcome loss': 0.42103930093298914, 'Total loss': 0.42103930093298914}
2023-01-05 12:13:40,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:40,456 INFO:     Epoch: 22
2023-01-05 12:13:42,606 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.518486738204956, 'Total loss': 0.518486738204956} | train loss {'Reaction outcome loss': 0.41406685016725375, 'Total loss': 0.41406685016725375}
2023-01-05 12:13:42,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:42,606 INFO:     Epoch: 23
2023-01-05 12:13:44,777 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5088629643122355, 'Total loss': 0.5088629643122355} | train loss {'Reaction outcome loss': 0.43097236224423174, 'Total loss': 0.43097236224423174}
2023-01-05 12:13:44,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:44,777 INFO:     Epoch: 24
2023-01-05 12:13:46,938 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4730761557817459, 'Total loss': 0.4730761557817459} | train loss {'Reaction outcome loss': 0.40533424533255724, 'Total loss': 0.40533424533255724}
2023-01-05 12:13:46,938 INFO:     Found new best model at epoch 24
2023-01-05 12:13:46,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:46,939 INFO:     Epoch: 25
2023-01-05 12:13:49,152 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48381531834602354, 'Total loss': 0.48381531834602354} | train loss {'Reaction outcome loss': 0.41757661403845187, 'Total loss': 0.41757661403845187}
2023-01-05 12:13:49,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:49,153 INFO:     Epoch: 26
2023-01-05 12:13:51,355 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5053937455018361, 'Total loss': 0.5053937455018361} | train loss {'Reaction outcome loss': 0.4012193469857068, 'Total loss': 0.4012193469857068}
2023-01-05 12:13:51,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:51,356 INFO:     Epoch: 27
2023-01-05 12:13:53,513 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4890604217847188, 'Total loss': 0.4890604217847188} | train loss {'Reaction outcome loss': 0.3950238454061142, 'Total loss': 0.3950238454061142}
2023-01-05 12:13:53,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:53,513 INFO:     Epoch: 28
2023-01-05 12:13:55,669 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4817438383897146, 'Total loss': 0.4817438383897146} | train loss {'Reaction outcome loss': 0.39073453749322495, 'Total loss': 0.39073453749322495}
2023-01-05 12:13:55,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:55,669 INFO:     Epoch: 29
2023-01-05 12:13:57,814 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5180784245332082, 'Total loss': 0.5180784245332082} | train loss {'Reaction outcome loss': 0.3853218141707855, 'Total loss': 0.3853218141707855}
2023-01-05 12:13:57,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:57,815 INFO:     Epoch: 30
2023-01-05 12:13:59,995 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5140067309141159, 'Total loss': 0.5140067309141159} | train loss {'Reaction outcome loss': 0.38313821610346377, 'Total loss': 0.38313821610346377}
2023-01-05 12:13:59,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:13:59,995 INFO:     Epoch: 31
2023-01-05 12:14:02,152 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49575368165969846, 'Total loss': 0.49575368165969846} | train loss {'Reaction outcome loss': 0.37702912294670293, 'Total loss': 0.37702912294670293}
2023-01-05 12:14:02,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:02,152 INFO:     Epoch: 32
2023-01-05 12:14:04,361 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4611870979269346, 'Total loss': 0.4611870979269346} | train loss {'Reaction outcome loss': 0.39222523467480275, 'Total loss': 0.39222523467480275}
2023-01-05 12:14:04,362 INFO:     Found new best model at epoch 32
2023-01-05 12:14:04,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:04,363 INFO:     Epoch: 33
2023-01-05 12:14:06,538 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49881114562352497, 'Total loss': 0.49881114562352497} | train loss {'Reaction outcome loss': 0.3645122441930521, 'Total loss': 0.3645122441930521}
2023-01-05 12:14:06,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:06,538 INFO:     Epoch: 34
2023-01-05 12:14:08,705 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.480267404516538, 'Total loss': 0.480267404516538} | train loss {'Reaction outcome loss': 0.38358522301026876, 'Total loss': 0.38358522301026876}
2023-01-05 12:14:08,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:08,706 INFO:     Epoch: 35
2023-01-05 12:14:10,860 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4765971899032593, 'Total loss': 0.4765971899032593} | train loss {'Reaction outcome loss': 0.37381624284645787, 'Total loss': 0.37381624284645787}
2023-01-05 12:14:10,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:10,860 INFO:     Epoch: 36
2023-01-05 12:14:13,029 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4705713133017222, 'Total loss': 0.4705713133017222} | train loss {'Reaction outcome loss': 0.36246186786034296, 'Total loss': 0.36246186786034296}
2023-01-05 12:14:13,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:13,029 INFO:     Epoch: 37
2023-01-05 12:14:15,209 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48879009783267974, 'Total loss': 0.48879009783267974} | train loss {'Reaction outcome loss': 0.36621702767476655, 'Total loss': 0.36621702767476655}
2023-01-05 12:14:15,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:15,209 INFO:     Epoch: 38
2023-01-05 12:14:17,367 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47926180164019266, 'Total loss': 0.47926180164019266} | train loss {'Reaction outcome loss': 0.3948965896708904, 'Total loss': 0.3948965896708904}
2023-01-05 12:14:17,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:17,368 INFO:     Epoch: 39
2023-01-05 12:14:19,584 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49292937815189364, 'Total loss': 0.49292937815189364} | train loss {'Reaction outcome loss': 0.34673702693881764, 'Total loss': 0.34673702693881764}
2023-01-05 12:14:19,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:19,584 INFO:     Epoch: 40
2023-01-05 12:14:21,821 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5034310340881347, 'Total loss': 0.5034310340881347} | train loss {'Reaction outcome loss': 0.34751911015094566, 'Total loss': 0.34751911015094566}
2023-01-05 12:14:21,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:21,821 INFO:     Epoch: 41
2023-01-05 12:14:24,027 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47491713662942253, 'Total loss': 0.47491713662942253} | train loss {'Reaction outcome loss': 0.3461401617775361, 'Total loss': 0.3461401617775361}
2023-01-05 12:14:24,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:24,027 INFO:     Epoch: 42
2023-01-05 12:14:26,187 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49897848765055336, 'Total loss': 0.49897848765055336} | train loss {'Reaction outcome loss': 0.35104044792714756, 'Total loss': 0.35104044792714756}
2023-01-05 12:14:26,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:26,187 INFO:     Epoch: 43
2023-01-05 12:14:28,348 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5923041641712189, 'Total loss': 0.5923041641712189} | train loss {'Reaction outcome loss': 0.4793718541175991, 'Total loss': 0.4793718541175991}
2023-01-05 12:14:28,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:28,349 INFO:     Epoch: 44
2023-01-05 12:14:30,513 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5429476281007131, 'Total loss': 0.5429476281007131} | train loss {'Reaction outcome loss': 0.46450185889135237, 'Total loss': 0.46450185889135237}
2023-01-05 12:14:30,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:30,513 INFO:     Epoch: 45
2023-01-05 12:14:32,687 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.515681125720342, 'Total loss': 0.515681125720342} | train loss {'Reaction outcome loss': 0.43827761002424837, 'Total loss': 0.43827761002424837}
2023-01-05 12:14:32,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:32,687 INFO:     Epoch: 46
2023-01-05 12:14:34,856 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5309069454669952, 'Total loss': 0.5309069454669952} | train loss {'Reaction outcome loss': 0.427953939808978, 'Total loss': 0.427953939808978}
2023-01-05 12:14:34,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:34,857 INFO:     Epoch: 47
2023-01-05 12:14:37,028 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5341086914141973, 'Total loss': 0.5341086914141973} | train loss {'Reaction outcome loss': 0.414933947927278, 'Total loss': 0.414933947927278}
2023-01-05 12:14:37,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:37,028 INFO:     Epoch: 48
2023-01-05 12:14:39,186 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5005723545948665, 'Total loss': 0.5005723545948665} | train loss {'Reaction outcome loss': 0.41051871324821876, 'Total loss': 0.41051871324821876}
2023-01-05 12:14:39,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:39,186 INFO:     Epoch: 49
2023-01-05 12:14:41,356 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5017092883586883, 'Total loss': 0.5017092883586883} | train loss {'Reaction outcome loss': 0.3916995220942477, 'Total loss': 0.3916995220942477}
2023-01-05 12:14:41,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:41,356 INFO:     Epoch: 50
2023-01-05 12:14:43,526 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5283242960770925, 'Total loss': 0.5283242960770925} | train loss {'Reaction outcome loss': 0.3884944450495085, 'Total loss': 0.3884944450495085}
2023-01-05 12:14:43,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:43,527 INFO:     Epoch: 51
2023-01-05 12:14:45,699 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5309505979220073, 'Total loss': 0.5309505979220073} | train loss {'Reaction outcome loss': 0.3723310797434786, 'Total loss': 0.3723310797434786}
2023-01-05 12:14:45,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:45,700 INFO:     Epoch: 52
2023-01-05 12:14:47,792 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4581468303998311, 'Total loss': 0.4581468303998311} | train loss {'Reaction outcome loss': 0.37870222395429376, 'Total loss': 0.37870222395429376}
2023-01-05 12:14:47,793 INFO:     Found new best model at epoch 52
2023-01-05 12:14:47,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:47,795 INFO:     Epoch: 53
2023-01-05 12:14:49,798 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.478513565659523, 'Total loss': 0.478513565659523} | train loss {'Reaction outcome loss': 0.3616626792092997, 'Total loss': 0.3616626792092997}
2023-01-05 12:14:49,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:49,798 INFO:     Epoch: 54
2023-01-05 12:14:51,937 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5141840994358062, 'Total loss': 0.5141840994358062} | train loss {'Reaction outcome loss': 0.35541893243519723, 'Total loss': 0.35541893243519723}
2023-01-05 12:14:51,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:51,937 INFO:     Epoch: 55
2023-01-05 12:14:54,109 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4836880604426066, 'Total loss': 0.4836880604426066} | train loss {'Reaction outcome loss': 0.34983881307171955, 'Total loss': 0.34983881307171955}
2023-01-05 12:14:54,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:54,109 INFO:     Epoch: 56
2023-01-05 12:14:56,274 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4914024412631989, 'Total loss': 0.4914024412631989} | train loss {'Reaction outcome loss': 0.34034173008040997, 'Total loss': 0.34034173008040997}
2023-01-05 12:14:56,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:56,274 INFO:     Epoch: 57
2023-01-05 12:14:58,448 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49657249748706817, 'Total loss': 0.49657249748706817} | train loss {'Reaction outcome loss': 0.3501931282867124, 'Total loss': 0.3501931282867124}
2023-01-05 12:14:58,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:14:58,449 INFO:     Epoch: 58
2023-01-05 12:15:00,621 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4727938155333201, 'Total loss': 0.4727938155333201} | train loss {'Reaction outcome loss': 0.3901441906025444, 'Total loss': 0.3901441906025444}
2023-01-05 12:15:00,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:00,621 INFO:     Epoch: 59
2023-01-05 12:15:02,813 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5153898616631826, 'Total loss': 0.5153898616631826} | train loss {'Reaction outcome loss': 0.3349838837950855, 'Total loss': 0.3349838837950855}
2023-01-05 12:15:02,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:02,814 INFO:     Epoch: 60
2023-01-05 12:15:04,963 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47007214824358623, 'Total loss': 0.47007214824358623} | train loss {'Reaction outcome loss': 0.3355987521465621, 'Total loss': 0.3355987521465621}
2023-01-05 12:15:04,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:04,963 INFO:     Epoch: 61
2023-01-05 12:15:07,097 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4823051909605662, 'Total loss': 0.4823051909605662} | train loss {'Reaction outcome loss': 0.3311410957962769, 'Total loss': 0.3311410957962769}
2023-01-05 12:15:07,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:07,097 INFO:     Epoch: 62
2023-01-05 12:15:09,243 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48594776292641956, 'Total loss': 0.48594776292641956} | train loss {'Reaction outcome loss': 0.32739743023125484, 'Total loss': 0.32739743023125484}
2023-01-05 12:15:09,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:09,243 INFO:     Epoch: 63
2023-01-05 12:15:11,393 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.476600710550944, 'Total loss': 0.476600710550944} | train loss {'Reaction outcome loss': 0.3277920663286697, 'Total loss': 0.3277920663286697}
2023-01-05 12:15:11,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:11,393 INFO:     Epoch: 64
2023-01-05 12:15:13,568 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45547366241614023, 'Total loss': 0.45547366241614023} | train loss {'Reaction outcome loss': 0.32083008050297696, 'Total loss': 0.32083008050297696}
2023-01-05 12:15:13,568 INFO:     Found new best model at epoch 64
2023-01-05 12:15:13,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:13,570 INFO:     Epoch: 65
2023-01-05 12:15:15,732 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5101740757624308, 'Total loss': 0.5101740757624308} | train loss {'Reaction outcome loss': 0.3419151019230755, 'Total loss': 0.3419151019230755}
2023-01-05 12:15:15,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:15,732 INFO:     Epoch: 66
2023-01-05 12:15:17,889 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4901865462462107, 'Total loss': 0.4901865462462107} | train loss {'Reaction outcome loss': 0.3263492297205696, 'Total loss': 0.3263492297205696}
2023-01-05 12:15:17,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:17,890 INFO:     Epoch: 67
2023-01-05 12:15:20,058 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.515080322821935, 'Total loss': 0.515080322821935} | train loss {'Reaction outcome loss': 0.3305930324519674, 'Total loss': 0.3305930324519674}
2023-01-05 12:15:20,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:20,058 INFO:     Epoch: 68
2023-01-05 12:15:22,294 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49064649144808453, 'Total loss': 0.49064649144808453} | train loss {'Reaction outcome loss': 0.33001894027372636, 'Total loss': 0.33001894027372636}
2023-01-05 12:15:22,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:22,294 INFO:     Epoch: 69
2023-01-05 12:15:24,461 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42729693055152895, 'Total loss': 0.42729693055152895} | train loss {'Reaction outcome loss': 0.3864918512935865, 'Total loss': 0.3864918512935865}
2023-01-05 12:15:24,461 INFO:     Found new best model at epoch 69
2023-01-05 12:15:24,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:24,463 INFO:     Epoch: 70
2023-01-05 12:15:26,638 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47661851247151693, 'Total loss': 0.47661851247151693} | train loss {'Reaction outcome loss': 0.3193579738102583, 'Total loss': 0.3193579738102583}
2023-01-05 12:15:26,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:26,639 INFO:     Epoch: 71
2023-01-05 12:15:28,787 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5067224164803823, 'Total loss': 0.5067224164803823} | train loss {'Reaction outcome loss': 0.31836868881963304, 'Total loss': 0.31836868881963304}
2023-01-05 12:15:28,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:28,787 INFO:     Epoch: 72
2023-01-05 12:15:30,951 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4731193661689758, 'Total loss': 0.4731193661689758} | train loss {'Reaction outcome loss': 0.3080451001845084, 'Total loss': 0.3080451001845084}
2023-01-05 12:15:30,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:30,952 INFO:     Epoch: 73
2023-01-05 12:15:33,103 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48779755234718325, 'Total loss': 0.48779755234718325} | train loss {'Reaction outcome loss': 0.30777481993309397, 'Total loss': 0.30777481993309397}
2023-01-05 12:15:33,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:33,105 INFO:     Epoch: 74
2023-01-05 12:15:35,259 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4924613098303477, 'Total loss': 0.4924613098303477} | train loss {'Reaction outcome loss': 0.3167764687250119, 'Total loss': 0.3167764687250119}
2023-01-05 12:15:35,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:35,259 INFO:     Epoch: 75
2023-01-05 12:15:37,437 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4814365575710932, 'Total loss': 0.4814365575710932} | train loss {'Reaction outcome loss': 0.30031332874289324, 'Total loss': 0.30031332874289324}
2023-01-05 12:15:37,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:37,437 INFO:     Epoch: 76
2023-01-05 12:15:39,594 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4696743369102478, 'Total loss': 0.4696743369102478} | train loss {'Reaction outcome loss': 0.3108676265304287, 'Total loss': 0.3108676265304287}
2023-01-05 12:15:39,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:39,594 INFO:     Epoch: 77
2023-01-05 12:15:41,758 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4396406109134356, 'Total loss': 0.4396406109134356} | train loss {'Reaction outcome loss': 0.30043595660886174, 'Total loss': 0.30043595660886174}
2023-01-05 12:15:41,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:41,758 INFO:     Epoch: 78
2023-01-05 12:15:43,915 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4712097684542338, 'Total loss': 0.4712097684542338} | train loss {'Reaction outcome loss': 0.30042653903365135, 'Total loss': 0.30042653903365135}
2023-01-05 12:15:43,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:43,916 INFO:     Epoch: 79
2023-01-05 12:15:46,080 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46672703127066295, 'Total loss': 0.46672703127066295} | train loss {'Reaction outcome loss': 0.3100278311547405, 'Total loss': 0.3100278311547405}
2023-01-05 12:15:46,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:46,081 INFO:     Epoch: 80
2023-01-05 12:15:48,243 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.491184800863266, 'Total loss': 0.491184800863266} | train loss {'Reaction outcome loss': 0.302658665024311, 'Total loss': 0.302658665024311}
2023-01-05 12:15:48,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:48,243 INFO:     Epoch: 81
2023-01-05 12:15:50,415 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5269763390223186, 'Total loss': 0.5269763390223186} | train loss {'Reaction outcome loss': 0.2923032395352704, 'Total loss': 0.2923032395352704}
2023-01-05 12:15:50,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:50,415 INFO:     Epoch: 82
2023-01-05 12:15:52,570 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48223238984743755, 'Total loss': 0.48223238984743755} | train loss {'Reaction outcome loss': 0.2962226563242926, 'Total loss': 0.2962226563242926}
2023-01-05 12:15:52,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:52,571 INFO:     Epoch: 83
2023-01-05 12:15:54,732 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44008171061674756, 'Total loss': 0.44008171061674756} | train loss {'Reaction outcome loss': 0.3000714778128262, 'Total loss': 0.3000714778128262}
2023-01-05 12:15:54,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:54,732 INFO:     Epoch: 84
2023-01-05 12:15:56,886 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44108466704686483, 'Total loss': 0.44108466704686483} | train loss {'Reaction outcome loss': 0.2913723535535425, 'Total loss': 0.2913723535535425}
2023-01-05 12:15:56,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:56,886 INFO:     Epoch: 85
2023-01-05 12:15:59,025 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48868833084901175, 'Total loss': 0.48868833084901175} | train loss {'Reaction outcome loss': 0.2936070142107159, 'Total loss': 0.2936070142107159}
2023-01-05 12:15:59,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:15:59,026 INFO:     Epoch: 86
2023-01-05 12:16:01,181 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48050014798839885, 'Total loss': 0.48050014798839885} | train loss {'Reaction outcome loss': 0.2911019396995181, 'Total loss': 0.2911019396995181}
2023-01-05 12:16:01,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:01,181 INFO:     Epoch: 87
2023-01-05 12:16:03,321 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4722578684488932, 'Total loss': 0.4722578684488932} | train loss {'Reaction outcome loss': 0.2870860460376286, 'Total loss': 0.2870860460376286}
2023-01-05 12:16:03,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:03,321 INFO:     Epoch: 88
2023-01-05 12:16:05,483 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45329786141713463, 'Total loss': 0.45329786141713463} | train loss {'Reaction outcome loss': 0.2910069378794751, 'Total loss': 0.2910069378794751}
2023-01-05 12:16:05,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:05,483 INFO:     Epoch: 89
2023-01-05 12:16:07,644 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4633198767900467, 'Total loss': 0.4633198767900467} | train loss {'Reaction outcome loss': 0.332430590626588, 'Total loss': 0.332430590626588}
2023-01-05 12:16:07,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:07,644 INFO:     Epoch: 90
2023-01-05 12:16:09,802 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46249267061551413, 'Total loss': 0.46249267061551413} | train loss {'Reaction outcome loss': 0.30744002591160574, 'Total loss': 0.30744002591160574}
2023-01-05 12:16:09,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:09,804 INFO:     Epoch: 91
2023-01-05 12:16:11,960 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4607620179653168, 'Total loss': 0.4607620179653168} | train loss {'Reaction outcome loss': 0.3001719188498522, 'Total loss': 0.3001719188498522}
2023-01-05 12:16:11,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:11,961 INFO:     Epoch: 92
2023-01-05 12:16:14,114 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.529043318827947, 'Total loss': 0.529043318827947} | train loss {'Reaction outcome loss': 0.2940570427432987, 'Total loss': 0.2940570427432987}
2023-01-05 12:16:14,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:14,114 INFO:     Epoch: 93
2023-01-05 12:16:16,262 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47441568970680237, 'Total loss': 0.47441568970680237} | train loss {'Reaction outcome loss': 0.28813472584537836, 'Total loss': 0.28813472584537836}
2023-01-05 12:16:16,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:16,263 INFO:     Epoch: 94
2023-01-05 12:16:18,425 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46386576890945436, 'Total loss': 0.46386576890945436} | train loss {'Reaction outcome loss': 0.28935185465556773, 'Total loss': 0.28935185465556773}
2023-01-05 12:16:18,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:18,425 INFO:     Epoch: 95
2023-01-05 12:16:20,589 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4831674853960673, 'Total loss': 0.4831674853960673} | train loss {'Reaction outcome loss': 0.31211101616044407, 'Total loss': 0.31211101616044407}
2023-01-05 12:16:20,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:20,589 INFO:     Epoch: 96
2023-01-05 12:16:22,746 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46927656630674996, 'Total loss': 0.46927656630674996} | train loss {'Reaction outcome loss': 0.293808461644548, 'Total loss': 0.293808461644548}
2023-01-05 12:16:22,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:22,746 INFO:     Epoch: 97
2023-01-05 12:16:24,899 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47602842847506205, 'Total loss': 0.47602842847506205} | train loss {'Reaction outcome loss': 0.283641243745765, 'Total loss': 0.283641243745765}
2023-01-05 12:16:24,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:24,900 INFO:     Epoch: 98
2023-01-05 12:16:27,054 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47744893133640287, 'Total loss': 0.47744893133640287} | train loss {'Reaction outcome loss': 0.28724731959791033, 'Total loss': 0.28724731959791033}
2023-01-05 12:16:27,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:27,054 INFO:     Epoch: 99
2023-01-05 12:16:29,218 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44525495568911233, 'Total loss': 0.44525495568911233} | train loss {'Reaction outcome loss': 0.2833144945502484, 'Total loss': 0.2833144945502484}
2023-01-05 12:16:29,219 INFO:     Best model found after epoch 70 of 100.
2023-01-05 12:16:29,219 INFO:   Done with stage: TRAINING
2023-01-05 12:16:29,219 INFO:   Starting stage: EVALUATION
2023-01-05 12:16:29,352 INFO:   Done with stage: EVALUATION
2023-01-05 12:16:29,352 INFO:   Leaving out SEQ value Fold_7
2023-01-05 12:16:29,364 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 12:16:29,365 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:16:30,016 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:16:30,016 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:16:30,086 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:16:30,087 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:16:30,087 INFO:     No hyperparam tuning for this model
2023-01-05 12:16:30,087 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:16:30,087 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:16:30,088 INFO:     None feature selector for col prot
2023-01-05 12:16:30,088 INFO:     None feature selector for col prot
2023-01-05 12:16:30,088 INFO:     None feature selector for col prot
2023-01-05 12:16:30,088 INFO:     None feature selector for col chem
2023-01-05 12:16:30,088 INFO:     None feature selector for col chem
2023-01-05 12:16:30,088 INFO:     None feature selector for col chem
2023-01-05 12:16:30,089 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:16:30,089 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:16:30,090 INFO:     Number of params in model 72901
2023-01-05 12:16:30,093 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:16:30,093 INFO:   Starting stage: TRAINING
2023-01-05 12:16:30,152 INFO:     Val loss before train {'Reaction outcome loss': 1.0545644362767537, 'Total loss': 1.0545644362767537}
2023-01-05 12:16:30,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:30,152 INFO:     Epoch: 0
2023-01-05 12:16:32,345 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8430028120676677, 'Total loss': 0.8430028120676677} | train loss {'Reaction outcome loss': 0.9022192153474484, 'Total loss': 0.9022192153474484}
2023-01-05 12:16:32,345 INFO:     Found new best model at epoch 0
2023-01-05 12:16:32,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:32,346 INFO:     Epoch: 1
2023-01-05 12:16:34,491 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.592236053943634, 'Total loss': 0.592236053943634} | train loss {'Reaction outcome loss': 0.6971597047489042, 'Total loss': 0.6971597047489042}
2023-01-05 12:16:34,491 INFO:     Found new best model at epoch 1
2023-01-05 12:16:34,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:34,492 INFO:     Epoch: 2
2023-01-05 12:16:36,662 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5845996002356212, 'Total loss': 0.5845996002356212} | train loss {'Reaction outcome loss': 0.573507907427175, 'Total loss': 0.573507907427175}
2023-01-05 12:16:36,662 INFO:     Found new best model at epoch 2
2023-01-05 12:16:36,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:36,664 INFO:     Epoch: 3
2023-01-05 12:16:38,845 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5422023713588715, 'Total loss': 0.5422023713588715} | train loss {'Reaction outcome loss': 0.5254012991267422, 'Total loss': 0.5254012991267422}
2023-01-05 12:16:38,845 INFO:     Found new best model at epoch 3
2023-01-05 12:16:38,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:38,847 INFO:     Epoch: 4
2023-01-05 12:16:41,033 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5272658665974935, 'Total loss': 0.5272658665974935} | train loss {'Reaction outcome loss': 0.5100400536606888, 'Total loss': 0.5100400536606888}
2023-01-05 12:16:41,033 INFO:     Found new best model at epoch 4
2023-01-05 12:16:41,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:41,034 INFO:     Epoch: 5
2023-01-05 12:16:43,204 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5209873040517171, 'Total loss': 0.5209873040517171} | train loss {'Reaction outcome loss': 0.49264464718340106, 'Total loss': 0.49264464718340106}
2023-01-05 12:16:43,205 INFO:     Found new best model at epoch 5
2023-01-05 12:16:43,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:43,206 INFO:     Epoch: 6
2023-01-05 12:16:45,343 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5275306383768718, 'Total loss': 0.5275306383768718} | train loss {'Reaction outcome loss': 0.4869378433438415, 'Total loss': 0.4869378433438415}
2023-01-05 12:16:45,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:45,344 INFO:     Epoch: 7
2023-01-05 12:16:47,509 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5031939387321472, 'Total loss': 0.5031939387321472} | train loss {'Reaction outcome loss': 0.47327263491893934, 'Total loss': 0.47327263491893934}
2023-01-05 12:16:47,509 INFO:     Found new best model at epoch 7
2023-01-05 12:16:47,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:47,510 INFO:     Epoch: 8
2023-01-05 12:16:49,672 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5013013531764349, 'Total loss': 0.5013013531764349} | train loss {'Reaction outcome loss': 0.47286969988139527, 'Total loss': 0.47286969988139527}
2023-01-05 12:16:49,673 INFO:     Found new best model at epoch 8
2023-01-05 12:16:49,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:49,674 INFO:     Epoch: 9
2023-01-05 12:16:51,825 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.509633074204127, 'Total loss': 0.509633074204127} | train loss {'Reaction outcome loss': 0.4635374376597387, 'Total loss': 0.4635374376597387}
2023-01-05 12:16:51,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:51,826 INFO:     Epoch: 10
2023-01-05 12:16:53,993 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4965050439039866, 'Total loss': 0.4965050439039866} | train loss {'Reaction outcome loss': 0.4516110251849309, 'Total loss': 0.4516110251849309}
2023-01-05 12:16:53,993 INFO:     Found new best model at epoch 10
2023-01-05 12:16:53,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:53,994 INFO:     Epoch: 11
2023-01-05 12:16:56,154 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48829783002535504, 'Total loss': 0.48829783002535504} | train loss {'Reaction outcome loss': 0.4507763470768498, 'Total loss': 0.4507763470768498}
2023-01-05 12:16:56,154 INFO:     Found new best model at epoch 11
2023-01-05 12:16:56,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:56,155 INFO:     Epoch: 12
2023-01-05 12:16:58,330 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48330283562342324, 'Total loss': 0.48330283562342324} | train loss {'Reaction outcome loss': 0.4460871686573924, 'Total loss': 0.4460871686573924}
2023-01-05 12:16:58,330 INFO:     Found new best model at epoch 12
2023-01-05 12:16:58,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:16:58,331 INFO:     Epoch: 13
2023-01-05 12:17:00,497 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4957250624895096, 'Total loss': 0.4957250624895096} | train loss {'Reaction outcome loss': 0.4383153496343737, 'Total loss': 0.4383153496343737}
2023-01-05 12:17:00,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:00,498 INFO:     Epoch: 14
2023-01-05 12:17:02,645 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.475786022345225, 'Total loss': 0.475786022345225} | train loss {'Reaction outcome loss': 0.43829783305041625, 'Total loss': 0.43829783305041625}
2023-01-05 12:17:02,645 INFO:     Found new best model at epoch 14
2023-01-05 12:17:02,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:02,646 INFO:     Epoch: 15
2023-01-05 12:17:04,810 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5021894534428915, 'Total loss': 0.5021894534428915} | train loss {'Reaction outcome loss': 0.42775232110858397, 'Total loss': 0.42775232110858397}
2023-01-05 12:17:04,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:04,811 INFO:     Epoch: 16
2023-01-05 12:17:06,977 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46588855783144634, 'Total loss': 0.46588855783144634} | train loss {'Reaction outcome loss': 0.4255891838766608, 'Total loss': 0.4255891838766608}
2023-01-05 12:17:06,977 INFO:     Found new best model at epoch 16
2023-01-05 12:17:06,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:06,979 INFO:     Epoch: 17
2023-01-05 12:17:09,126 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4901631514231364, 'Total loss': 0.4901631514231364} | train loss {'Reaction outcome loss': 0.42545196473168123, 'Total loss': 0.42545196473168123}
2023-01-05 12:17:09,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:09,127 INFO:     Epoch: 18
2023-01-05 12:17:11,285 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4662011921405792, 'Total loss': 0.4662011921405792} | train loss {'Reaction outcome loss': 0.41265293033222, 'Total loss': 0.41265293033222}
2023-01-05 12:17:11,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:11,285 INFO:     Epoch: 19
2023-01-05 12:17:13,438 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4637012685338656, 'Total loss': 0.4637012685338656} | train loss {'Reaction outcome loss': 0.4120335818843291, 'Total loss': 0.4120335818843291}
2023-01-05 12:17:13,438 INFO:     Found new best model at epoch 19
2023-01-05 12:17:13,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:13,440 INFO:     Epoch: 20
2023-01-05 12:17:15,618 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47161792119344076, 'Total loss': 0.47161792119344076} | train loss {'Reaction outcome loss': 0.41047375971982625, 'Total loss': 0.41047375971982625}
2023-01-05 12:17:15,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:15,618 INFO:     Epoch: 21
2023-01-05 12:17:17,759 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4810026824474335, 'Total loss': 0.4810026824474335} | train loss {'Reaction outcome loss': 0.40508194725005636, 'Total loss': 0.40508194725005636}
2023-01-05 12:17:17,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:17,760 INFO:     Epoch: 22
2023-01-05 12:17:19,906 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45860472122828166, 'Total loss': 0.45860472122828166} | train loss {'Reaction outcome loss': 0.3998426236615715, 'Total loss': 0.3998426236615715}
2023-01-05 12:17:19,907 INFO:     Found new best model at epoch 22
2023-01-05 12:17:19,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:19,908 INFO:     Epoch: 23
2023-01-05 12:17:22,089 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.480487318833669, 'Total loss': 0.480487318833669} | train loss {'Reaction outcome loss': 0.39413133462628736, 'Total loss': 0.39413133462628736}
2023-01-05 12:17:22,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:22,090 INFO:     Epoch: 24
2023-01-05 12:17:24,267 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4912535160779953, 'Total loss': 0.4912535160779953} | train loss {'Reaction outcome loss': 0.3933164387107541, 'Total loss': 0.3933164387107541}
2023-01-05 12:17:24,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:24,267 INFO:     Epoch: 25
2023-01-05 12:17:26,441 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44708959658940634, 'Total loss': 0.44708959658940634} | train loss {'Reaction outcome loss': 0.38805528145135526, 'Total loss': 0.38805528145135526}
2023-01-05 12:17:26,441 INFO:     Found new best model at epoch 25
2023-01-05 12:17:26,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:26,443 INFO:     Epoch: 26
2023-01-05 12:17:28,603 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4844070335229238, 'Total loss': 0.4844070335229238} | train loss {'Reaction outcome loss': 0.3821296061688382, 'Total loss': 0.3821296061688382}
2023-01-05 12:17:28,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:28,604 INFO:     Epoch: 27
2023-01-05 12:17:30,769 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4255990336338679, 'Total loss': 0.4255990336338679} | train loss {'Reaction outcome loss': 0.37690218817778876, 'Total loss': 0.37690218817778876}
2023-01-05 12:17:30,769 INFO:     Found new best model at epoch 27
2023-01-05 12:17:30,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:30,770 INFO:     Epoch: 28
2023-01-05 12:17:32,950 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45134547650814055, 'Total loss': 0.45134547650814055} | train loss {'Reaction outcome loss': 0.3786373718066766, 'Total loss': 0.3786373718066766}
2023-01-05 12:17:32,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:32,950 INFO:     Epoch: 29
2023-01-05 12:17:35,126 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4548077901204427, 'Total loss': 0.4548077901204427} | train loss {'Reaction outcome loss': 0.37735228111382424, 'Total loss': 0.37735228111382424}
2023-01-05 12:17:35,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:35,126 INFO:     Epoch: 30
2023-01-05 12:17:37,284 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48576428095499674, 'Total loss': 0.48576428095499674} | train loss {'Reaction outcome loss': 0.3685167688163609, 'Total loss': 0.3685167688163609}
2023-01-05 12:17:37,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:37,284 INFO:     Epoch: 31
2023-01-05 12:17:39,458 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46885363658269247, 'Total loss': 0.46885363658269247} | train loss {'Reaction outcome loss': 0.36749056433512417, 'Total loss': 0.36749056433512417}
2023-01-05 12:17:39,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:39,459 INFO:     Epoch: 32
2023-01-05 12:17:41,617 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4881038725376129, 'Total loss': 0.4881038725376129} | train loss {'Reaction outcome loss': 0.3606292475014925, 'Total loss': 0.3606292475014925}
2023-01-05 12:17:41,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:41,618 INFO:     Epoch: 33
2023-01-05 12:17:43,450 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47266549269358316, 'Total loss': 0.47266549269358316} | train loss {'Reaction outcome loss': 0.3616319534903399, 'Total loss': 0.3616319534903399}
2023-01-05 12:17:43,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:43,451 INFO:     Epoch: 34
2023-01-05 12:17:45,211 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4279387483994166, 'Total loss': 0.4279387483994166} | train loss {'Reaction outcome loss': 0.35323777942773665, 'Total loss': 0.35323777942773665}
2023-01-05 12:17:45,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:45,211 INFO:     Epoch: 35
2023-01-05 12:17:46,955 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4793726166089376, 'Total loss': 0.4793726166089376} | train loss {'Reaction outcome loss': 0.35715218127742143, 'Total loss': 0.35715218127742143}
2023-01-05 12:17:46,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:46,955 INFO:     Epoch: 36
2023-01-05 12:17:49,114 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43811940848827363, 'Total loss': 0.43811940848827363} | train loss {'Reaction outcome loss': 0.3463475849439091, 'Total loss': 0.3463475849439091}
2023-01-05 12:17:49,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:49,114 INFO:     Epoch: 37
2023-01-05 12:17:51,278 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45305111904939016, 'Total loss': 0.45305111904939016} | train loss {'Reaction outcome loss': 0.35074367062171874, 'Total loss': 0.35074367062171874}
2023-01-05 12:17:51,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:51,278 INFO:     Epoch: 38
2023-01-05 12:17:53,451 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4425167371829351, 'Total loss': 0.4425167371829351} | train loss {'Reaction outcome loss': 0.3442942780923327, 'Total loss': 0.3442942780923327}
2023-01-05 12:17:53,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:53,453 INFO:     Epoch: 39
2023-01-05 12:17:55,626 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.451682381828626, 'Total loss': 0.451682381828626} | train loss {'Reaction outcome loss': 0.34850933831790293, 'Total loss': 0.34850933831790293}
2023-01-05 12:17:55,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:55,627 INFO:     Epoch: 40
2023-01-05 12:17:57,878 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45138134211301806, 'Total loss': 0.45138134211301806} | train loss {'Reaction outcome loss': 0.33432707123270106, 'Total loss': 0.33432707123270106}
2023-01-05 12:17:57,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:17:57,879 INFO:     Epoch: 41
2023-01-05 12:18:00,091 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4607729156812032, 'Total loss': 0.4607729156812032} | train loss {'Reaction outcome loss': 0.3367005199436031, 'Total loss': 0.3367005199436031}
2023-01-05 12:18:00,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:00,092 INFO:     Epoch: 42
2023-01-05 12:18:02,257 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4694069763024648, 'Total loss': 0.4694069763024648} | train loss {'Reaction outcome loss': 0.32871741925228376, 'Total loss': 0.32871741925228376}
2023-01-05 12:18:02,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:02,258 INFO:     Epoch: 43
2023-01-05 12:18:04,456 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45556053320566814, 'Total loss': 0.45556053320566814} | train loss {'Reaction outcome loss': 0.33100287484455626, 'Total loss': 0.33100287484455626}
2023-01-05 12:18:04,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:04,456 INFO:     Epoch: 44
2023-01-05 12:18:06,630 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4531753828128179, 'Total loss': 0.4531753828128179} | train loss {'Reaction outcome loss': 0.3281458996048042, 'Total loss': 0.3281458996048042}
2023-01-05 12:18:06,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:06,630 INFO:     Epoch: 45
2023-01-05 12:18:08,817 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4358293851216634, 'Total loss': 0.4358293851216634} | train loss {'Reaction outcome loss': 0.31957216243451253, 'Total loss': 0.31957216243451253}
2023-01-05 12:18:08,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:08,818 INFO:     Epoch: 46
2023-01-05 12:18:10,978 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4299408495426178, 'Total loss': 0.4299408495426178} | train loss {'Reaction outcome loss': 0.3182940098325914, 'Total loss': 0.3182940098325914}
2023-01-05 12:18:10,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:10,978 INFO:     Epoch: 47
2023-01-05 12:18:13,167 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43959450324376426, 'Total loss': 0.43959450324376426} | train loss {'Reaction outcome loss': 0.3149398989598889, 'Total loss': 0.3149398989598889}
2023-01-05 12:18:13,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:13,168 INFO:     Epoch: 48
2023-01-05 12:18:15,352 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4713844805955887, 'Total loss': 0.4713844805955887} | train loss {'Reaction outcome loss': 0.3158170792546513, 'Total loss': 0.3158170792546513}
2023-01-05 12:18:15,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:15,352 INFO:     Epoch: 49
2023-01-05 12:18:17,532 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4595720112323761, 'Total loss': 0.4595720112323761} | train loss {'Reaction outcome loss': 0.31196940506031795, 'Total loss': 0.31196940506031795}
2023-01-05 12:18:17,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:17,532 INFO:     Epoch: 50
2023-01-05 12:18:19,729 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47437576750914257, 'Total loss': 0.47437576750914257} | train loss {'Reaction outcome loss': 0.3048595917690209, 'Total loss': 0.3048595917690209}
2023-01-05 12:18:19,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:19,729 INFO:     Epoch: 51
2023-01-05 12:18:21,889 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46448418299357097, 'Total loss': 0.46448418299357097} | train loss {'Reaction outcome loss': 0.3091017941369369, 'Total loss': 0.3091017941369369}
2023-01-05 12:18:21,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:21,889 INFO:     Epoch: 52
2023-01-05 12:18:24,060 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43357752164204916, 'Total loss': 0.43357752164204916} | train loss {'Reaction outcome loss': 0.30279209536066554, 'Total loss': 0.30279209536066554}
2023-01-05 12:18:24,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:24,060 INFO:     Epoch: 53
2023-01-05 12:18:26,249 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4395820001761119, 'Total loss': 0.4395820001761119} | train loss {'Reaction outcome loss': 0.31009072261368215, 'Total loss': 0.31009072261368215}
2023-01-05 12:18:26,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:26,249 INFO:     Epoch: 54
2023-01-05 12:18:28,430 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4360214730103811, 'Total loss': 0.4360214730103811} | train loss {'Reaction outcome loss': 0.30034412912997527, 'Total loss': 0.30034412912997527}
2023-01-05 12:18:28,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:28,431 INFO:     Epoch: 55
2023-01-05 12:18:30,628 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42566345433394115, 'Total loss': 0.42566345433394115} | train loss {'Reaction outcome loss': 0.30357388168949945, 'Total loss': 0.30357388168949945}
2023-01-05 12:18:30,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:30,628 INFO:     Epoch: 56
2023-01-05 12:18:32,812 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45803577502568565, 'Total loss': 0.45803577502568565} | train loss {'Reaction outcome loss': 0.29427755250181964, 'Total loss': 0.29427755250181964}
2023-01-05 12:18:32,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:32,812 INFO:     Epoch: 57
2023-01-05 12:18:34,676 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4908315991361936, 'Total loss': 0.4908315991361936} | train loss {'Reaction outcome loss': 0.29095164980967986, 'Total loss': 0.29095164980967986}
2023-01-05 12:18:34,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:34,677 INFO:     Epoch: 58
2023-01-05 12:18:36,406 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4854125599066416, 'Total loss': 0.4854125599066416} | train loss {'Reaction outcome loss': 0.28962110227733745, 'Total loss': 0.28962110227733745}
2023-01-05 12:18:36,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:36,406 INFO:     Epoch: 59
2023-01-05 12:18:38,254 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45974821150302886, 'Total loss': 0.45974821150302886} | train loss {'Reaction outcome loss': 0.2884879625177125, 'Total loss': 0.2884879625177125}
2023-01-05 12:18:38,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:38,255 INFO:     Epoch: 60
2023-01-05 12:18:40,463 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48991311391194664, 'Total loss': 0.48991311391194664} | train loss {'Reaction outcome loss': 0.2868822630535179, 'Total loss': 0.2868822630535179}
2023-01-05 12:18:40,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:40,463 INFO:     Epoch: 61
2023-01-05 12:18:42,643 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4619679937760035, 'Total loss': 0.4619679937760035} | train loss {'Reaction outcome loss': 0.2859334977552133, 'Total loss': 0.2859334977552133}
2023-01-05 12:18:42,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:42,644 INFO:     Epoch: 62
2023-01-05 12:18:44,823 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48405174612998964, 'Total loss': 0.48405174612998964} | train loss {'Reaction outcome loss': 0.2898124770701792, 'Total loss': 0.2898124770701792}
2023-01-05 12:18:44,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:44,824 INFO:     Epoch: 63
2023-01-05 12:18:47,005 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46957626740137737, 'Total loss': 0.46957626740137737} | train loss {'Reaction outcome loss': 0.279339748196008, 'Total loss': 0.279339748196008}
2023-01-05 12:18:47,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:47,006 INFO:     Epoch: 64
2023-01-05 12:18:49,194 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45620033144950867, 'Total loss': 0.45620033144950867} | train loss {'Reaction outcome loss': 0.28512540661363395, 'Total loss': 0.28512540661363395}
2023-01-05 12:18:49,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:49,194 INFO:     Epoch: 65
2023-01-05 12:18:51,373 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43860900700092315, 'Total loss': 0.43860900700092315} | train loss {'Reaction outcome loss': 0.2741220532933297, 'Total loss': 0.2741220532933297}
2023-01-05 12:18:51,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:51,374 INFO:     Epoch: 66
2023-01-05 12:18:53,425 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4333425233761469, 'Total loss': 0.4333425233761469} | train loss {'Reaction outcome loss': 0.279109168636347, 'Total loss': 0.279109168636347}
2023-01-05 12:18:53,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:53,425 INFO:     Epoch: 67
2023-01-05 12:18:55,537 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4292121489842733, 'Total loss': 0.4292121489842733} | train loss {'Reaction outcome loss': 0.27937622475925333, 'Total loss': 0.27937622475925333}
2023-01-05 12:18:55,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:55,537 INFO:     Epoch: 68
2023-01-05 12:18:57,738 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47904070615768435, 'Total loss': 0.47904070615768435} | train loss {'Reaction outcome loss': 0.2741521865748111, 'Total loss': 0.2741521865748111}
2023-01-05 12:18:57,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:57,739 INFO:     Epoch: 69
2023-01-05 12:18:59,913 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44113560368617377, 'Total loss': 0.44113560368617377} | train loss {'Reaction outcome loss': 0.27087365378649225, 'Total loss': 0.27087365378649225}
2023-01-05 12:18:59,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:18:59,913 INFO:     Epoch: 70
2023-01-05 12:19:02,089 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4428891122341156, 'Total loss': 0.4428891122341156} | train loss {'Reaction outcome loss': 0.26775956326013006, 'Total loss': 0.26775956326013006}
2023-01-05 12:19:02,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:02,089 INFO:     Epoch: 71
2023-01-05 12:19:04,277 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46537348031997683, 'Total loss': 0.46537348031997683} | train loss {'Reaction outcome loss': 0.27358359272595134, 'Total loss': 0.27358359272595134}
2023-01-05 12:19:04,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:04,279 INFO:     Epoch: 72
2023-01-05 12:19:06,472 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46500436663627626, 'Total loss': 0.46500436663627626} | train loss {'Reaction outcome loss': 0.2642452092202454, 'Total loss': 0.2642452092202454}
2023-01-05 12:19:06,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:06,472 INFO:     Epoch: 73
2023-01-05 12:19:08,651 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4411609391371409, 'Total loss': 0.4411609391371409} | train loss {'Reaction outcome loss': 0.2672220559703314, 'Total loss': 0.2672220559703314}
2023-01-05 12:19:08,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:08,652 INFO:     Epoch: 74
2023-01-05 12:19:10,821 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44986564020315806, 'Total loss': 0.44986564020315806} | train loss {'Reaction outcome loss': 0.26131542612015124, 'Total loss': 0.26131542612015124}
2023-01-05 12:19:10,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:10,822 INFO:     Epoch: 75
2023-01-05 12:19:13,013 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43480875094731647, 'Total loss': 0.43480875094731647} | train loss {'Reaction outcome loss': 0.25763817710485915, 'Total loss': 0.25763817710485915}
2023-01-05 12:19:13,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:13,014 INFO:     Epoch: 76
2023-01-05 12:19:15,209 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44923604528109234, 'Total loss': 0.44923604528109234} | train loss {'Reaction outcome loss': 0.26038849990586294, 'Total loss': 0.26038849990586294}
2023-01-05 12:19:15,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:15,209 INFO:     Epoch: 77
2023-01-05 12:19:17,406 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44095799028873445, 'Total loss': 0.44095799028873445} | train loss {'Reaction outcome loss': 0.25625057377270843, 'Total loss': 0.25625057377270843}
2023-01-05 12:19:17,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:17,406 INFO:     Epoch: 78
2023-01-05 12:19:19,570 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4453763782978058, 'Total loss': 0.4453763782978058} | train loss {'Reaction outcome loss': 0.2507736771989493, 'Total loss': 0.2507736771989493}
2023-01-05 12:19:19,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:19,570 INFO:     Epoch: 79
2023-01-05 12:19:21,752 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43070937593777975, 'Total loss': 0.43070937593777975} | train loss {'Reaction outcome loss': 0.2561958998118927, 'Total loss': 0.2561958998118927}
2023-01-05 12:19:21,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:21,752 INFO:     Epoch: 80
2023-01-05 12:19:23,936 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4956097662448883, 'Total loss': 0.4956097662448883} | train loss {'Reaction outcome loss': 0.2527540039224046, 'Total loss': 0.2527540039224046}
2023-01-05 12:19:23,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:23,937 INFO:     Epoch: 81
2023-01-05 12:19:26,117 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44499245782693225, 'Total loss': 0.44499245782693225} | train loss {'Reaction outcome loss': 0.24964756595259968, 'Total loss': 0.24964756595259968}
2023-01-05 12:19:26,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:26,117 INFO:     Epoch: 82
2023-01-05 12:19:28,306 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4276180684566498, 'Total loss': 0.4276180684566498} | train loss {'Reaction outcome loss': 0.25632911908443656, 'Total loss': 0.25632911908443656}
2023-01-05 12:19:28,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:28,306 INFO:     Epoch: 83
2023-01-05 12:19:30,487 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4738638013601303, 'Total loss': 0.4738638013601303} | train loss {'Reaction outcome loss': 0.24743327589887143, 'Total loss': 0.24743327589887143}
2023-01-05 12:19:30,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:30,487 INFO:     Epoch: 84
2023-01-05 12:19:32,677 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5186802923679352, 'Total loss': 0.5186802923679352} | train loss {'Reaction outcome loss': 0.2556213274033276, 'Total loss': 0.2556213274033276}
2023-01-05 12:19:32,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:32,677 INFO:     Epoch: 85
2023-01-05 12:19:34,846 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46163409948349, 'Total loss': 0.46163409948349} | train loss {'Reaction outcome loss': 0.24783943134228892, 'Total loss': 0.24783943134228892}
2023-01-05 12:19:34,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:34,846 INFO:     Epoch: 86
2023-01-05 12:19:37,027 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46203917761643726, 'Total loss': 0.46203917761643726} | train loss {'Reaction outcome loss': 0.24236954625574905, 'Total loss': 0.24236954625574905}
2023-01-05 12:19:37,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:37,027 INFO:     Epoch: 87
2023-01-05 12:19:39,230 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48841726779937744, 'Total loss': 0.48841726779937744} | train loss {'Reaction outcome loss': 0.2422025275487278, 'Total loss': 0.2422025275487278}
2023-01-05 12:19:39,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:39,231 INFO:     Epoch: 88
2023-01-05 12:19:41,433 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45571145017941794, 'Total loss': 0.45571145017941794} | train loss {'Reaction outcome loss': 0.24878934870342917, 'Total loss': 0.24878934870342917}
2023-01-05 12:19:41,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:41,434 INFO:     Epoch: 89
2023-01-05 12:19:43,599 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4627959102392197, 'Total loss': 0.4627959102392197} | train loss {'Reaction outcome loss': 0.24437246543594002, 'Total loss': 0.24437246543594002}
2023-01-05 12:19:43,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:43,599 INFO:     Epoch: 90
2023-01-05 12:19:45,799 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4517488131920497, 'Total loss': 0.4517488131920497} | train loss {'Reaction outcome loss': 0.23703079080269654, 'Total loss': 0.23703079080269654}
2023-01-05 12:19:45,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:45,800 INFO:     Epoch: 91
2023-01-05 12:19:47,974 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4627734492222468, 'Total loss': 0.4627734492222468} | train loss {'Reaction outcome loss': 0.24100876029325305, 'Total loss': 0.24100876029325305}
2023-01-05 12:19:47,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:47,974 INFO:     Epoch: 92
2023-01-05 12:19:50,172 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4758923371632894, 'Total loss': 0.4758923371632894} | train loss {'Reaction outcome loss': 0.23711986684438768, 'Total loss': 0.23711986684438768}
2023-01-05 12:19:50,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:50,172 INFO:     Epoch: 93
2023-01-05 12:19:52,361 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46570977171262107, 'Total loss': 0.46570977171262107} | train loss {'Reaction outcome loss': 0.2453371276978121, 'Total loss': 0.2453371276978121}
2023-01-05 12:19:52,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:52,361 INFO:     Epoch: 94
2023-01-05 12:19:54,536 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45126451800266904, 'Total loss': 0.45126451800266904} | train loss {'Reaction outcome loss': 0.2363421454259097, 'Total loss': 0.2363421454259097}
2023-01-05 12:19:54,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:54,536 INFO:     Epoch: 95
2023-01-05 12:19:56,721 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42146068811416626, 'Total loss': 0.42146068811416626} | train loss {'Reaction outcome loss': 0.23485252005636476, 'Total loss': 0.23485252005636476}
2023-01-05 12:19:56,721 INFO:     Found new best model at epoch 95
2023-01-05 12:19:56,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:56,722 INFO:     Epoch: 96
2023-01-05 12:19:58,900 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45914220015207924, 'Total loss': 0.45914220015207924} | train loss {'Reaction outcome loss': 0.2303072219001741, 'Total loss': 0.2303072219001741}
2023-01-05 12:19:58,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:19:58,901 INFO:     Epoch: 97
2023-01-05 12:20:01,070 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44404950439929963, 'Total loss': 0.44404950439929963} | train loss {'Reaction outcome loss': 0.23043493106826762, 'Total loss': 0.23043493106826762}
2023-01-05 12:20:01,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:01,070 INFO:     Epoch: 98
2023-01-05 12:20:03,245 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.495930552482605, 'Total loss': 0.495930552482605} | train loss {'Reaction outcome loss': 0.23569909214220322, 'Total loss': 0.23569909214220322}
2023-01-05 12:20:03,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:03,246 INFO:     Epoch: 99
2023-01-05 12:20:05,410 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4443489561478297, 'Total loss': 0.4443489561478297} | train loss {'Reaction outcome loss': 0.236469231619893, 'Total loss': 0.236469231619893}
2023-01-05 12:20:05,410 INFO:     Best model found after epoch 96 of 100.
2023-01-05 12:20:05,411 INFO:   Done with stage: TRAINING
2023-01-05 12:20:05,411 INFO:   Starting stage: EVALUATION
2023-01-05 12:20:05,539 INFO:   Done with stage: EVALUATION
2023-01-05 12:20:05,540 INFO:   Leaving out SEQ value Fold_8
2023-01-05 12:20:05,552 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 12:20:05,552 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:20:06,199 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:20:06,200 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:20:06,269 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:20:06,269 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:20:06,269 INFO:     No hyperparam tuning for this model
2023-01-05 12:20:06,269 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:20:06,269 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:20:06,270 INFO:     None feature selector for col prot
2023-01-05 12:20:06,270 INFO:     None feature selector for col prot
2023-01-05 12:20:06,270 INFO:     None feature selector for col prot
2023-01-05 12:20:06,271 INFO:     None feature selector for col chem
2023-01-05 12:20:06,271 INFO:     None feature selector for col chem
2023-01-05 12:20:06,271 INFO:     None feature selector for col chem
2023-01-05 12:20:06,271 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:20:06,271 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:20:06,273 INFO:     Number of params in model 72901
2023-01-05 12:20:06,276 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:20:06,276 INFO:   Starting stage: TRAINING
2023-01-05 12:20:06,337 INFO:     Val loss before train {'Reaction outcome loss': 1.0381343762079875, 'Total loss': 1.0381343762079875}
2023-01-05 12:20:06,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:06,337 INFO:     Epoch: 0
2023-01-05 12:20:08,497 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8353582163651784, 'Total loss': 0.8353582163651784} | train loss {'Reaction outcome loss': 0.9443227180412838, 'Total loss': 0.9443227180412838}
2023-01-05 12:20:08,497 INFO:     Found new best model at epoch 0
2023-01-05 12:20:08,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:08,498 INFO:     Epoch: 1
2023-01-05 12:20:10,652 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6573223769664764, 'Total loss': 0.6573223769664764} | train loss {'Reaction outcome loss': 0.7591508373672708, 'Total loss': 0.7591508373672708}
2023-01-05 12:20:10,653 INFO:     Found new best model at epoch 1
2023-01-05 12:20:10,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:10,654 INFO:     Epoch: 2
2023-01-05 12:20:12,805 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5587620089451472, 'Total loss': 0.5587620089451472} | train loss {'Reaction outcome loss': 0.5973633046879436, 'Total loss': 0.5973633046879436}
2023-01-05 12:20:12,805 INFO:     Found new best model at epoch 2
2023-01-05 12:20:12,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:12,807 INFO:     Epoch: 3
2023-01-05 12:20:14,977 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48828022281328837, 'Total loss': 0.48828022281328837} | train loss {'Reaction outcome loss': 0.536462318711665, 'Total loss': 0.536462318711665}
2023-01-05 12:20:14,978 INFO:     Found new best model at epoch 3
2023-01-05 12:20:14,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:14,980 INFO:     Epoch: 4
2023-01-05 12:20:17,138 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49930712978045144, 'Total loss': 0.49930712978045144} | train loss {'Reaction outcome loss': 0.5167312132460731, 'Total loss': 0.5167312132460731}
2023-01-05 12:20:17,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:17,138 INFO:     Epoch: 5
2023-01-05 12:20:19,312 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4772627303997676, 'Total loss': 0.4772627303997676} | train loss {'Reaction outcome loss': 0.5039486545564491, 'Total loss': 0.5039486545564491}
2023-01-05 12:20:19,312 INFO:     Found new best model at epoch 5
2023-01-05 12:20:19,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:19,313 INFO:     Epoch: 6
2023-01-05 12:20:21,495 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46511996189753213, 'Total loss': 0.46511996189753213} | train loss {'Reaction outcome loss': 0.48933937949138684, 'Total loss': 0.48933937949138684}
2023-01-05 12:20:21,496 INFO:     Found new best model at epoch 6
2023-01-05 12:20:21,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:21,497 INFO:     Epoch: 7
2023-01-05 12:20:23,667 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4808304419120153, 'Total loss': 0.4808304419120153} | train loss {'Reaction outcome loss': 0.48360155288116397, 'Total loss': 0.48360155288116397}
2023-01-05 12:20:23,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:23,668 INFO:     Epoch: 8
2023-01-05 12:20:25,828 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5052579402923584, 'Total loss': 0.5052579402923584} | train loss {'Reaction outcome loss': 0.4730496727503263, 'Total loss': 0.4730496727503263}
2023-01-05 12:20:25,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:25,828 INFO:     Epoch: 9
2023-01-05 12:20:27,985 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48285266558329265, 'Total loss': 0.48285266558329265} | train loss {'Reaction outcome loss': 0.4711253001139714, 'Total loss': 0.4711253001139714}
2023-01-05 12:20:27,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:27,986 INFO:     Epoch: 10
2023-01-05 12:20:30,158 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48737828234831493, 'Total loss': 0.48737828234831493} | train loss {'Reaction outcome loss': 0.4639830645242017, 'Total loss': 0.4639830645242017}
2023-01-05 12:20:30,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:30,158 INFO:     Epoch: 11
2023-01-05 12:20:32,321 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4638079543908437, 'Total loss': 0.4638079543908437} | train loss {'Reaction outcome loss': 0.4547156485773268, 'Total loss': 0.4547156485773268}
2023-01-05 12:20:32,321 INFO:     Found new best model at epoch 11
2023-01-05 12:20:32,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:32,323 INFO:     Epoch: 12
2023-01-05 12:20:34,467 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4734594762325287, 'Total loss': 0.4734594762325287} | train loss {'Reaction outcome loss': 0.45572798379829954, 'Total loss': 0.45572798379829954}
2023-01-05 12:20:34,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:34,468 INFO:     Epoch: 13
2023-01-05 12:20:36,621 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4566200097401937, 'Total loss': 0.4566200097401937} | train loss {'Reaction outcome loss': 0.45070490634048377, 'Total loss': 0.45070490634048377}
2023-01-05 12:20:36,621 INFO:     Found new best model at epoch 13
2023-01-05 12:20:36,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:36,623 INFO:     Epoch: 14
2023-01-05 12:20:38,785 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43878576904535294, 'Total loss': 0.43878576904535294} | train loss {'Reaction outcome loss': 0.4405975788285881, 'Total loss': 0.4405975788285881}
2023-01-05 12:20:38,785 INFO:     Found new best model at epoch 14
2023-01-05 12:20:38,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:38,787 INFO:     Epoch: 15
2023-01-05 12:20:40,926 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48062317272027333, 'Total loss': 0.48062317272027333} | train loss {'Reaction outcome loss': 0.4364809734480722, 'Total loss': 0.4364809734480722}
2023-01-05 12:20:40,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:40,926 INFO:     Epoch: 16
2023-01-05 12:20:43,079 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4359328657388687, 'Total loss': 0.4359328657388687} | train loss {'Reaction outcome loss': 0.4333559131120151, 'Total loss': 0.4333559131120151}
2023-01-05 12:20:43,079 INFO:     Found new best model at epoch 16
2023-01-05 12:20:43,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:43,081 INFO:     Epoch: 17
2023-01-05 12:20:45,219 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4486037383476893, 'Total loss': 0.4486037383476893} | train loss {'Reaction outcome loss': 0.42714886304550553, 'Total loss': 0.42714886304550553}
2023-01-05 12:20:45,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:45,219 INFO:     Epoch: 18
2023-01-05 12:20:47,357 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46349013249079385, 'Total loss': 0.46349013249079385} | train loss {'Reaction outcome loss': 0.4275053379299876, 'Total loss': 0.4275053379299876}
2023-01-05 12:20:47,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:47,357 INFO:     Epoch: 19
2023-01-05 12:20:49,504 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44677787522474927, 'Total loss': 0.44677787522474927} | train loss {'Reaction outcome loss': 0.4258399912507543, 'Total loss': 0.4258399912507543}
2023-01-05 12:20:49,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:49,505 INFO:     Epoch: 20
2023-01-05 12:20:51,641 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44420682489871977, 'Total loss': 0.44420682489871977} | train loss {'Reaction outcome loss': 0.41590539210445276, 'Total loss': 0.41590539210445276}
2023-01-05 12:20:51,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:51,642 INFO:     Epoch: 21
2023-01-05 12:20:53,788 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.418666868408521, 'Total loss': 0.418666868408521} | train loss {'Reaction outcome loss': 0.41281922172495733, 'Total loss': 0.41281922172495733}
2023-01-05 12:20:53,788 INFO:     Found new best model at epoch 21
2023-01-05 12:20:53,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:53,789 INFO:     Epoch: 22
2023-01-05 12:20:55,936 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4478281776110331, 'Total loss': 0.4478281776110331} | train loss {'Reaction outcome loss': 0.4101974442328289, 'Total loss': 0.4101974442328289}
2023-01-05 12:20:55,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:55,936 INFO:     Epoch: 23
2023-01-05 12:20:58,063 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4316185861825943, 'Total loss': 0.4316185861825943} | train loss {'Reaction outcome loss': 0.40709617488331845, 'Total loss': 0.40709617488331845}
2023-01-05 12:20:58,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:20:58,064 INFO:     Epoch: 24
2023-01-05 12:21:00,226 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4380555192629496, 'Total loss': 0.4380555192629496} | train loss {'Reaction outcome loss': 0.3956551316838998, 'Total loss': 0.3956551316838998}
2023-01-05 12:21:00,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:00,227 INFO:     Epoch: 25
2023-01-05 12:21:02,365 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40304890523354214, 'Total loss': 0.40304890523354214} | train loss {'Reaction outcome loss': 0.3979350541592081, 'Total loss': 0.3979350541592081}
2023-01-05 12:21:02,365 INFO:     Found new best model at epoch 25
2023-01-05 12:21:02,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:02,367 INFO:     Epoch: 26
2023-01-05 12:21:04,497 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4206434945265452, 'Total loss': 0.4206434945265452} | train loss {'Reaction outcome loss': 0.393244254283416, 'Total loss': 0.393244254283416}
2023-01-05 12:21:04,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:04,497 INFO:     Epoch: 27
2023-01-05 12:21:06,643 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3897449920574824, 'Total loss': 0.3897449920574824} | train loss {'Reaction outcome loss': 0.3859753123460672, 'Total loss': 0.3859753123460672}
2023-01-05 12:21:06,643 INFO:     Found new best model at epoch 27
2023-01-05 12:21:06,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:06,644 INFO:     Epoch: 28
2023-01-05 12:21:08,784 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4450104882319768, 'Total loss': 0.4450104882319768} | train loss {'Reaction outcome loss': 0.38304913693513626, 'Total loss': 0.38304913693513626}
2023-01-05 12:21:08,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:08,785 INFO:     Epoch: 29
2023-01-05 12:21:10,908 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4537567436695099, 'Total loss': 0.4537567436695099} | train loss {'Reaction outcome loss': 0.3827658329745789, 'Total loss': 0.3827658329745789}
2023-01-05 12:21:10,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:10,909 INFO:     Epoch: 30
2023-01-05 12:21:13,043 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42413230141003927, 'Total loss': 0.42413230141003927} | train loss {'Reaction outcome loss': 0.37752002923861966, 'Total loss': 0.37752002923861966}
2023-01-05 12:21:13,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:13,043 INFO:     Epoch: 31
2023-01-05 12:21:15,183 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43882578015327456, 'Total loss': 0.43882578015327456} | train loss {'Reaction outcome loss': 0.37089092692448977, 'Total loss': 0.37089092692448977}
2023-01-05 12:21:15,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:15,183 INFO:     Epoch: 32
2023-01-05 12:21:17,328 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43130161662896477, 'Total loss': 0.43130161662896477} | train loss {'Reaction outcome loss': 0.3743639114029678, 'Total loss': 0.3743639114029678}
2023-01-05 12:21:17,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:17,329 INFO:     Epoch: 33
2023-01-05 12:21:19,465 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41159625053405763, 'Total loss': 0.41159625053405763} | train loss {'Reaction outcome loss': 0.3721565394474691, 'Total loss': 0.3721565394474691}
2023-01-05 12:21:19,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:19,465 INFO:     Epoch: 34
2023-01-05 12:21:21,604 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3941482365131378, 'Total loss': 0.3941482365131378} | train loss {'Reaction outcome loss': 0.3729772449030981, 'Total loss': 0.3729772449030981}
2023-01-05 12:21:21,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:21,604 INFO:     Epoch: 35
2023-01-05 12:21:23,746 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41456080973148346, 'Total loss': 0.41456080973148346} | train loss {'Reaction outcome loss': 0.36358116628540743, 'Total loss': 0.36358116628540743}
2023-01-05 12:21:23,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:23,747 INFO:     Epoch: 36
2023-01-05 12:21:25,893 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42063217163085936, 'Total loss': 0.42063217163085936} | train loss {'Reaction outcome loss': 0.3613022146644173, 'Total loss': 0.3613022146644173}
2023-01-05 12:21:25,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:25,893 INFO:     Epoch: 37
2023-01-05 12:21:28,044 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41912737488746643, 'Total loss': 0.41912737488746643} | train loss {'Reaction outcome loss': 0.3543687952962114, 'Total loss': 0.3543687952962114}
2023-01-05 12:21:28,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:28,045 INFO:     Epoch: 38
2023-01-05 12:21:30,184 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4058129101991653, 'Total loss': 0.4058129101991653} | train loss {'Reaction outcome loss': 0.3583495950142106, 'Total loss': 0.3583495950142106}
2023-01-05 12:21:30,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:30,185 INFO:     Epoch: 39
2023-01-05 12:21:32,325 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3986315786838531, 'Total loss': 0.3986315786838531} | train loss {'Reaction outcome loss': 0.35715260831536827, 'Total loss': 0.35715260831536827}
2023-01-05 12:21:32,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:32,325 INFO:     Epoch: 40
2023-01-05 12:21:34,443 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3872335508465767, 'Total loss': 0.3872335508465767} | train loss {'Reaction outcome loss': 0.3450405506533144, 'Total loss': 0.3450405506533144}
2023-01-05 12:21:34,444 INFO:     Found new best model at epoch 40
2023-01-05 12:21:34,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:34,446 INFO:     Epoch: 41
2023-01-05 12:21:36,586 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38176136116186776, 'Total loss': 0.38176136116186776} | train loss {'Reaction outcome loss': 0.3395794844493652, 'Total loss': 0.3395794844493652}
2023-01-05 12:21:36,586 INFO:     Found new best model at epoch 41
2023-01-05 12:21:36,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:36,587 INFO:     Epoch: 42
2023-01-05 12:21:38,722 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3903549214204152, 'Total loss': 0.3903549214204152} | train loss {'Reaction outcome loss': 0.3503365356461469, 'Total loss': 0.3503365356461469}
2023-01-05 12:21:38,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:38,722 INFO:     Epoch: 43
2023-01-05 12:21:40,856 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4167132655779521, 'Total loss': 0.4167132655779521} | train loss {'Reaction outcome loss': 0.34093241119286516, 'Total loss': 0.34093241119286516}
2023-01-05 12:21:40,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:40,857 INFO:     Epoch: 44
2023-01-05 12:21:43,007 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3910111794869105, 'Total loss': 0.3910111794869105} | train loss {'Reaction outcome loss': 0.33526348343098555, 'Total loss': 0.33526348343098555}
2023-01-05 12:21:43,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:43,007 INFO:     Epoch: 45
2023-01-05 12:21:45,142 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3982870896657308, 'Total loss': 0.3982870896657308} | train loss {'Reaction outcome loss': 0.33396671616878265, 'Total loss': 0.33396671616878265}
2023-01-05 12:21:45,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:45,142 INFO:     Epoch: 46
2023-01-05 12:21:47,295 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36794409652551013, 'Total loss': 0.36794409652551013} | train loss {'Reaction outcome loss': 0.3296851872197001, 'Total loss': 0.3296851872197001}
2023-01-05 12:21:47,295 INFO:     Found new best model at epoch 46
2023-01-05 12:21:47,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:47,297 INFO:     Epoch: 47
2023-01-05 12:21:49,425 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4395394707719485, 'Total loss': 0.4395394707719485} | train loss {'Reaction outcome loss': 0.3244125956034922, 'Total loss': 0.3244125956034922}
2023-01-05 12:21:49,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:49,425 INFO:     Epoch: 48
2023-01-05 12:21:51,552 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3791375537713369, 'Total loss': 0.3791375537713369} | train loss {'Reaction outcome loss': 0.32994012310828047, 'Total loss': 0.32994012310828047}
2023-01-05 12:21:51,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:51,552 INFO:     Epoch: 49
2023-01-05 12:21:53,704 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3914460718631744, 'Total loss': 0.3914460718631744} | train loss {'Reaction outcome loss': 0.3230866015012011, 'Total loss': 0.3230866015012011}
2023-01-05 12:21:53,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:53,705 INFO:     Epoch: 50
2023-01-05 12:21:55,828 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3882157901922862, 'Total loss': 0.3882157901922862} | train loss {'Reaction outcome loss': 0.32619113461438554, 'Total loss': 0.32619113461438554}
2023-01-05 12:21:55,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:55,828 INFO:     Epoch: 51
2023-01-05 12:21:57,959 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4040945063034693, 'Total loss': 0.4040945063034693} | train loss {'Reaction outcome loss': 0.3218188174068928, 'Total loss': 0.3218188174068928}
2023-01-05 12:21:57,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:21:57,961 INFO:     Epoch: 52
2023-01-05 12:22:00,101 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38344424615303674, 'Total loss': 0.38344424615303674} | train loss {'Reaction outcome loss': 0.3201379584141703, 'Total loss': 0.3201379584141703}
2023-01-05 12:22:00,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:00,102 INFO:     Epoch: 53
2023-01-05 12:22:02,239 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3698177084326744, 'Total loss': 0.3698177084326744} | train loss {'Reaction outcome loss': 0.31270962887385606, 'Total loss': 0.31270962887385606}
2023-01-05 12:22:02,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:02,240 INFO:     Epoch: 54
2023-01-05 12:22:04,369 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3589293956756592, 'Total loss': 0.3589293956756592} | train loss {'Reaction outcome loss': 0.3098290818351092, 'Total loss': 0.3098290818351092}
2023-01-05 12:22:04,370 INFO:     Found new best model at epoch 54
2023-01-05 12:22:04,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:04,371 INFO:     Epoch: 55
2023-01-05 12:22:06,520 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40440637269445384, 'Total loss': 0.40440637269445384} | train loss {'Reaction outcome loss': 0.3142489031666801, 'Total loss': 0.3142489031666801}
2023-01-05 12:22:06,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:06,520 INFO:     Epoch: 56
2023-01-05 12:22:08,658 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3722135583559672, 'Total loss': 0.3722135583559672} | train loss {'Reaction outcome loss': 0.31078254565214497, 'Total loss': 0.31078254565214497}
2023-01-05 12:22:08,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:08,658 INFO:     Epoch: 57
2023-01-05 12:22:10,780 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3849856456120809, 'Total loss': 0.3849856456120809} | train loss {'Reaction outcome loss': 0.3054022841401153, 'Total loss': 0.3054022841401153}
2023-01-05 12:22:10,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:10,780 INFO:     Epoch: 58
2023-01-05 12:22:12,927 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37868995567162833, 'Total loss': 0.37868995567162833} | train loss {'Reaction outcome loss': 0.3038475390646484, 'Total loss': 0.3038475390646484}
2023-01-05 12:22:12,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:12,927 INFO:     Epoch: 59
2023-01-05 12:22:15,075 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36791257858276366, 'Total loss': 0.36791257858276366} | train loss {'Reaction outcome loss': 0.3045870874882181, 'Total loss': 0.3045870874882181}
2023-01-05 12:22:15,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:15,075 INFO:     Epoch: 60
2023-01-05 12:22:17,242 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36486027787129083, 'Total loss': 0.36486027787129083} | train loss {'Reaction outcome loss': 0.30321358881153904, 'Total loss': 0.30321358881153904}
2023-01-05 12:22:17,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:17,243 INFO:     Epoch: 61
2023-01-05 12:22:19,389 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36802234351634977, 'Total loss': 0.36802234351634977} | train loss {'Reaction outcome loss': 0.2949029180211025, 'Total loss': 0.2949029180211025}
2023-01-05 12:22:19,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:19,390 INFO:     Epoch: 62
2023-01-05 12:22:21,516 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36862341364224754, 'Total loss': 0.36862341364224754} | train loss {'Reaction outcome loss': 0.2957015403788605, 'Total loss': 0.2957015403788605}
2023-01-05 12:22:21,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:21,516 INFO:     Epoch: 63
2023-01-05 12:22:23,642 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3996904085079829, 'Total loss': 0.3996904085079829} | train loss {'Reaction outcome loss': 0.28979979138889594, 'Total loss': 0.28979979138889594}
2023-01-05 12:22:23,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:23,642 INFO:     Epoch: 64
2023-01-05 12:22:25,803 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3675461123387019, 'Total loss': 0.3675461123387019} | train loss {'Reaction outcome loss': 0.29662969686609486, 'Total loss': 0.29662969686609486}
2023-01-05 12:22:25,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:25,803 INFO:     Epoch: 65
2023-01-05 12:22:27,945 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39514254927635195, 'Total loss': 0.39514254927635195} | train loss {'Reaction outcome loss': 0.29311152505296056, 'Total loss': 0.29311152505296056}
2023-01-05 12:22:27,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:27,945 INFO:     Epoch: 66
2023-01-05 12:22:30,081 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36866700847943623, 'Total loss': 0.36866700847943623} | train loss {'Reaction outcome loss': 0.2907873496631563, 'Total loss': 0.2907873496631563}
2023-01-05 12:22:30,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:30,083 INFO:     Epoch: 67
2023-01-05 12:22:32,202 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3577120006084442, 'Total loss': 0.3577120006084442} | train loss {'Reaction outcome loss': 0.29143533195222254, 'Total loss': 0.29143533195222254}
2023-01-05 12:22:32,202 INFO:     Found new best model at epoch 67
2023-01-05 12:22:32,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:32,204 INFO:     Epoch: 68
2023-01-05 12:22:34,334 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35495557089646657, 'Total loss': 0.35495557089646657} | train loss {'Reaction outcome loss': 0.29060227819633133, 'Total loss': 0.29060227819633133}
2023-01-05 12:22:34,334 INFO:     Found new best model at epoch 68
2023-01-05 12:22:34,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:34,335 INFO:     Epoch: 69
2023-01-05 12:22:36,462 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36538247565428417, 'Total loss': 0.36538247565428417} | train loss {'Reaction outcome loss': 0.2913314355980782, 'Total loss': 0.2913314355980782}
2023-01-05 12:22:36,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:36,463 INFO:     Epoch: 70
2023-01-05 12:22:38,606 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37752445638179777, 'Total loss': 0.37752445638179777} | train loss {'Reaction outcome loss': 0.2809611005783627, 'Total loss': 0.2809611005783627}
2023-01-05 12:22:38,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:38,606 INFO:     Epoch: 71
2023-01-05 12:22:40,741 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3321706344683965, 'Total loss': 0.3321706344683965} | train loss {'Reaction outcome loss': 0.2813244613754007, 'Total loss': 0.2813244613754007}
2023-01-05 12:22:40,742 INFO:     Found new best model at epoch 71
2023-01-05 12:22:40,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:40,743 INFO:     Epoch: 72
2023-01-05 12:22:42,889 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3486499081055323, 'Total loss': 0.3486499081055323} | train loss {'Reaction outcome loss': 0.28178657334802787, 'Total loss': 0.28178657334802787}
2023-01-05 12:22:42,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:42,889 INFO:     Epoch: 73
2023-01-05 12:22:45,011 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3442005922396978, 'Total loss': 0.3442005922396978} | train loss {'Reaction outcome loss': 0.288081548084597, 'Total loss': 0.288081548084597}
2023-01-05 12:22:45,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:45,011 INFO:     Epoch: 74
2023-01-05 12:22:47,146 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3680288990338643, 'Total loss': 0.3680288990338643} | train loss {'Reaction outcome loss': 0.28140643320895814, 'Total loss': 0.28140643320895814}
2023-01-05 12:22:47,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:47,146 INFO:     Epoch: 75
2023-01-05 12:22:49,284 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.34582655926545464, 'Total loss': 0.34582655926545464} | train loss {'Reaction outcome loss': 0.282966717559121, 'Total loss': 0.282966717559121}
2023-01-05 12:22:49,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:49,285 INFO:     Epoch: 76
2023-01-05 12:22:51,422 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3825883110364278, 'Total loss': 0.3825883110364278} | train loss {'Reaction outcome loss': 0.2751153977212561, 'Total loss': 0.2751153977212561}
2023-01-05 12:22:51,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:51,423 INFO:     Epoch: 77
2023-01-05 12:22:53,552 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3870870937903722, 'Total loss': 0.3870870937903722} | train loss {'Reaction outcome loss': 0.27864393951446365, 'Total loss': 0.27864393951446365}
2023-01-05 12:22:53,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:53,552 INFO:     Epoch: 78
2023-01-05 12:22:55,689 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37009263336658477, 'Total loss': 0.37009263336658477} | train loss {'Reaction outcome loss': 0.2739031738277538, 'Total loss': 0.2739031738277538}
2023-01-05 12:22:55,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:55,689 INFO:     Epoch: 79
2023-01-05 12:22:57,830 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3823054889837901, 'Total loss': 0.3823054889837901} | train loss {'Reaction outcome loss': 0.2789490191409221, 'Total loss': 0.2789490191409221}
2023-01-05 12:22:57,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:57,831 INFO:     Epoch: 80
2023-01-05 12:22:59,956 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3251506000757217, 'Total loss': 0.3251506000757217} | train loss {'Reaction outcome loss': 0.2748490490032967, 'Total loss': 0.2748490490032967}
2023-01-05 12:22:59,957 INFO:     Found new best model at epoch 80
2023-01-05 12:22:59,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:22:59,958 INFO:     Epoch: 81
2023-01-05 12:23:01,940 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4037610967954, 'Total loss': 0.4037610967954} | train loss {'Reaction outcome loss': 0.26725147391631926, 'Total loss': 0.26725147391631926}
2023-01-05 12:23:01,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:01,940 INFO:     Epoch: 82
2023-01-05 12:23:04,084 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3916687309741974, 'Total loss': 0.3916687309741974} | train loss {'Reaction outcome loss': 0.2701262767962265, 'Total loss': 0.2701262767962265}
2023-01-05 12:23:04,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:04,084 INFO:     Epoch: 83
2023-01-05 12:23:06,209 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34859431187311807, 'Total loss': 0.34859431187311807} | train loss {'Reaction outcome loss': 0.2673289174514212, 'Total loss': 0.2673289174514212}
2023-01-05 12:23:06,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:06,210 INFO:     Epoch: 84
2023-01-05 12:23:08,357 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.33360411537190277, 'Total loss': 0.33360411537190277} | train loss {'Reaction outcome loss': 0.2609168940220342, 'Total loss': 0.2609168940220342}
2023-01-05 12:23:08,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:08,357 INFO:     Epoch: 85
2023-01-05 12:23:10,498 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35665908753871917, 'Total loss': 0.35665908753871917} | train loss {'Reaction outcome loss': 0.26482629511955674, 'Total loss': 0.26482629511955674}
2023-01-05 12:23:10,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:10,498 INFO:     Epoch: 86
2023-01-05 12:23:12,632 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33949508170286813, 'Total loss': 0.33949508170286813} | train loss {'Reaction outcome loss': 0.26524788964260027, 'Total loss': 0.26524788964260027}
2023-01-05 12:23:12,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:12,633 INFO:     Epoch: 87
2023-01-05 12:23:14,774 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3445928245782852, 'Total loss': 0.3445928245782852} | train loss {'Reaction outcome loss': 0.26571178063750267, 'Total loss': 0.26571178063750267}
2023-01-05 12:23:14,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:14,774 INFO:     Epoch: 88
2023-01-05 12:23:16,920 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3911593645811081, 'Total loss': 0.3911593645811081} | train loss {'Reaction outcome loss': 0.2543216190358876, 'Total loss': 0.2543216190358876}
2023-01-05 12:23:16,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:16,921 INFO:     Epoch: 89
2023-01-05 12:23:19,054 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3747733811537425, 'Total loss': 0.3747733811537425} | train loss {'Reaction outcome loss': 0.2570022536448507, 'Total loss': 0.2570022536448507}
2023-01-05 12:23:19,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:19,054 INFO:     Epoch: 90
2023-01-05 12:23:21,193 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3689363618691762, 'Total loss': 0.3689363618691762} | train loss {'Reaction outcome loss': 0.25476953749555153, 'Total loss': 0.25476953749555153}
2023-01-05 12:23:21,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:21,193 INFO:     Epoch: 91
2023-01-05 12:23:23,344 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36599328418572746, 'Total loss': 0.36599328418572746} | train loss {'Reaction outcome loss': 0.2622281139641454, 'Total loss': 0.2622281139641454}
2023-01-05 12:23:23,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:23,344 INFO:     Epoch: 92
2023-01-05 12:23:25,493 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.313924166560173, 'Total loss': 0.313924166560173} | train loss {'Reaction outcome loss': 0.2574465931921979, 'Total loss': 0.2574465931921979}
2023-01-05 12:23:25,493 INFO:     Found new best model at epoch 92
2023-01-05 12:23:25,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:25,495 INFO:     Epoch: 93
2023-01-05 12:23:27,670 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36751173039277396, 'Total loss': 0.36751173039277396} | train loss {'Reaction outcome loss': 0.25276903530767003, 'Total loss': 0.25276903530767003}
2023-01-05 12:23:27,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:27,671 INFO:     Epoch: 94
2023-01-05 12:23:29,822 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33071715633074444, 'Total loss': 0.33071715633074444} | train loss {'Reaction outcome loss': 0.2538572263634412, 'Total loss': 0.2538572263634412}
2023-01-05 12:23:29,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:29,823 INFO:     Epoch: 95
2023-01-05 12:23:31,944 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3787885904312134, 'Total loss': 0.3787885904312134} | train loss {'Reaction outcome loss': 0.24965411562458936, 'Total loss': 0.24965411562458936}
2023-01-05 12:23:31,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:31,944 INFO:     Epoch: 96
2023-01-05 12:23:34,080 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.33188024113575615, 'Total loss': 0.33188024113575615} | train loss {'Reaction outcome loss': 0.2575240217203841, 'Total loss': 0.2575240217203841}
2023-01-05 12:23:34,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:34,080 INFO:     Epoch: 97
2023-01-05 12:23:36,226 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4110835259159406, 'Total loss': 0.4110835259159406} | train loss {'Reaction outcome loss': 0.2530855056863865, 'Total loss': 0.2530855056863865}
2023-01-05 12:23:36,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:36,226 INFO:     Epoch: 98
2023-01-05 12:23:38,367 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3869513377547264, 'Total loss': 0.3869513377547264} | train loss {'Reaction outcome loss': 0.25392559670157483, 'Total loss': 0.25392559670157483}
2023-01-05 12:23:38,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:38,367 INFO:     Epoch: 99
2023-01-05 12:23:40,506 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34394293030103046, 'Total loss': 0.34394293030103046} | train loss {'Reaction outcome loss': 0.25024864762584803, 'Total loss': 0.25024864762584803}
2023-01-05 12:23:40,506 INFO:     Best model found after epoch 93 of 100.
2023-01-05 12:23:40,506 INFO:   Done with stage: TRAINING
2023-01-05 12:23:40,506 INFO:   Starting stage: EVALUATION
2023-01-05 12:23:40,653 INFO:   Done with stage: EVALUATION
2023-01-05 12:23:40,654 INFO:   Leaving out SEQ value Fold_9
2023-01-05 12:23:40,666 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 12:23:40,666 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:23:41,323 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:23:41,325 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:23:41,395 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:23:41,395 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:23:41,395 INFO:     No hyperparam tuning for this model
2023-01-05 12:23:41,395 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:23:41,395 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:23:41,396 INFO:     None feature selector for col prot
2023-01-05 12:23:41,396 INFO:     None feature selector for col prot
2023-01-05 12:23:41,396 INFO:     None feature selector for col prot
2023-01-05 12:23:41,397 INFO:     None feature selector for col chem
2023-01-05 12:23:41,397 INFO:     None feature selector for col chem
2023-01-05 12:23:41,397 INFO:     None feature selector for col chem
2023-01-05 12:23:41,397 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:23:41,397 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:23:41,398 INFO:     Number of params in model 72901
2023-01-05 12:23:41,402 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:23:41,402 INFO:   Starting stage: TRAINING
2023-01-05 12:23:41,462 INFO:     Val loss before train {'Reaction outcome loss': 0.9639424204826355, 'Total loss': 0.9639424204826355}
2023-01-05 12:23:41,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:41,462 INFO:     Epoch: 0
2023-01-05 12:23:43,622 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.767118388414383, 'Total loss': 0.767118388414383} | train loss {'Reaction outcome loss': 0.9397712235846675, 'Total loss': 0.9397712235846675}
2023-01-05 12:23:43,622 INFO:     Found new best model at epoch 0
2023-01-05 12:23:43,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:43,624 INFO:     Epoch: 1
2023-01-05 12:23:45,781 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5520035485426585, 'Total loss': 0.5520035485426585} | train loss {'Reaction outcome loss': 0.7338723945380978, 'Total loss': 0.7338723945380978}
2023-01-05 12:23:45,781 INFO:     Found new best model at epoch 1
2023-01-05 12:23:45,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:45,783 INFO:     Epoch: 2
2023-01-05 12:23:47,944 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4983727276325226, 'Total loss': 0.4983727276325226} | train loss {'Reaction outcome loss': 0.5847195112533088, 'Total loss': 0.5847195112533088}
2023-01-05 12:23:47,945 INFO:     Found new best model at epoch 2
2023-01-05 12:23:47,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:47,947 INFO:     Epoch: 3
2023-01-05 12:23:50,101 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.468157031138738, 'Total loss': 0.468157031138738} | train loss {'Reaction outcome loss': 0.5438521891724762, 'Total loss': 0.5438521891724762}
2023-01-05 12:23:50,101 INFO:     Found new best model at epoch 3
2023-01-05 12:23:50,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:50,102 INFO:     Epoch: 4
2023-01-05 12:23:52,277 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48248675366242727, 'Total loss': 0.48248675366242727} | train loss {'Reaction outcome loss': 0.520170421215171, 'Total loss': 0.520170421215171}
2023-01-05 12:23:52,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:52,277 INFO:     Epoch: 5
2023-01-05 12:23:54,427 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4774670918782552, 'Total loss': 0.4774670918782552} | train loss {'Reaction outcome loss': 0.5073186738503969, 'Total loss': 0.5073186738503969}
2023-01-05 12:23:54,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:54,427 INFO:     Epoch: 6
2023-01-05 12:23:56,583 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47005389134089154, 'Total loss': 0.47005389134089154} | train loss {'Reaction outcome loss': 0.5019845810285114, 'Total loss': 0.5019845810285114}
2023-01-05 12:23:56,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:56,584 INFO:     Epoch: 7
2023-01-05 12:23:58,763 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4588918834924698, 'Total loss': 0.4588918834924698} | train loss {'Reaction outcome loss': 0.4898578450890655, 'Total loss': 0.4898578450890655}
2023-01-05 12:23:58,763 INFO:     Found new best model at epoch 7
2023-01-05 12:23:58,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:23:58,764 INFO:     Epoch: 8
2023-01-05 12:24:00,953 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43968857526779176, 'Total loss': 0.43968857526779176} | train loss {'Reaction outcome loss': 0.47881605365861624, 'Total loss': 0.47881605365861624}
2023-01-05 12:24:00,953 INFO:     Found new best model at epoch 8
2023-01-05 12:24:00,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:00,955 INFO:     Epoch: 9
2023-01-05 12:24:03,134 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46093945304552714, 'Total loss': 0.46093945304552714} | train loss {'Reaction outcome loss': 0.47584986982577976, 'Total loss': 0.47584986982577976}
2023-01-05 12:24:03,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:03,134 INFO:     Epoch: 10
2023-01-05 12:24:05,292 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4490958333015442, 'Total loss': 0.4490958333015442} | train loss {'Reaction outcome loss': 0.46891481450856376, 'Total loss': 0.46891481450856376}
2023-01-05 12:24:05,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:05,292 INFO:     Epoch: 11
2023-01-05 12:24:07,441 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43138149976730344, 'Total loss': 0.43138149976730344} | train loss {'Reaction outcome loss': 0.46837428524175706, 'Total loss': 0.46837428524175706}
2023-01-05 12:24:07,441 INFO:     Found new best model at epoch 11
2023-01-05 12:24:07,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:07,443 INFO:     Epoch: 12
2023-01-05 12:24:09,612 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43782310287157694, 'Total loss': 0.43782310287157694} | train loss {'Reaction outcome loss': 0.457201059221791, 'Total loss': 0.457201059221791}
2023-01-05 12:24:09,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:09,612 INFO:     Epoch: 13
2023-01-05 12:24:11,773 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4453907390435537, 'Total loss': 0.4453907390435537} | train loss {'Reaction outcome loss': 0.4596732465099772, 'Total loss': 0.4596732465099772}
2023-01-05 12:24:11,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:11,773 INFO:     Epoch: 14
2023-01-05 12:24:13,951 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4383102774620056, 'Total loss': 0.4383102774620056} | train loss {'Reaction outcome loss': 0.4526217415767456, 'Total loss': 0.4526217415767456}
2023-01-05 12:24:13,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:13,952 INFO:     Epoch: 15
2023-01-05 12:24:16,111 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4425826450188955, 'Total loss': 0.4425826450188955} | train loss {'Reaction outcome loss': 0.4453139631649217, 'Total loss': 0.4453139631649217}
2023-01-05 12:24:16,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:16,111 INFO:     Epoch: 16
2023-01-05 12:24:18,265 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4456500748793284, 'Total loss': 0.4456500748793284} | train loss {'Reaction outcome loss': 0.43926867826535815, 'Total loss': 0.43926867826535815}
2023-01-05 12:24:18,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:18,265 INFO:     Epoch: 17
2023-01-05 12:24:20,470 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43142896294593813, 'Total loss': 0.43142896294593813} | train loss {'Reaction outcome loss': 0.4354696739935703, 'Total loss': 0.4354696739935703}
2023-01-05 12:24:20,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:20,470 INFO:     Epoch: 18
2023-01-05 12:24:22,745 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42211147050062814, 'Total loss': 0.42211147050062814} | train loss {'Reaction outcome loss': 0.43437025842630045, 'Total loss': 0.43437025842630045}
2023-01-05 12:24:22,746 INFO:     Found new best model at epoch 18
2023-01-05 12:24:22,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:22,747 INFO:     Epoch: 19
2023-01-05 12:24:24,970 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4316879630088806, 'Total loss': 0.4316879630088806} | train loss {'Reaction outcome loss': 0.4278046235926315, 'Total loss': 0.4278046235926315}
2023-01-05 12:24:24,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:24,970 INFO:     Epoch: 20
2023-01-05 12:24:27,210 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.424683869878451, 'Total loss': 0.424683869878451} | train loss {'Reaction outcome loss': 0.4231218203418091, 'Total loss': 0.4231218203418091}
2023-01-05 12:24:27,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:27,210 INFO:     Epoch: 21
2023-01-05 12:24:29,425 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4180421402057012, 'Total loss': 0.4180421402057012} | train loss {'Reaction outcome loss': 0.425252243661278, 'Total loss': 0.425252243661278}
2023-01-05 12:24:29,425 INFO:     Found new best model at epoch 21
2023-01-05 12:24:29,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:29,426 INFO:     Epoch: 22
2023-01-05 12:24:31,634 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42127675414085386, 'Total loss': 0.42127675414085386} | train loss {'Reaction outcome loss': 0.4233182562441172, 'Total loss': 0.4233182562441172}
2023-01-05 12:24:31,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:31,634 INFO:     Epoch: 23
2023-01-05 12:24:33,827 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4229903449614843, 'Total loss': 0.4229903449614843} | train loss {'Reaction outcome loss': 0.41734546713450327, 'Total loss': 0.41734546713450327}
2023-01-05 12:24:33,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:33,828 INFO:     Epoch: 24
2023-01-05 12:24:36,021 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42859548528989155, 'Total loss': 0.42859548528989155} | train loss {'Reaction outcome loss': 0.41281665681394, 'Total loss': 0.41281665681394}
2023-01-05 12:24:36,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:36,021 INFO:     Epoch: 25
2023-01-05 12:24:38,236 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41957565347353615, 'Total loss': 0.41957565347353615} | train loss {'Reaction outcome loss': 0.41103438957718735, 'Total loss': 0.41103438957718735}
2023-01-05 12:24:38,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:38,236 INFO:     Epoch: 26
2023-01-05 12:24:40,481 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41022408107916514, 'Total loss': 0.41022408107916514} | train loss {'Reaction outcome loss': 0.4085123459892583, 'Total loss': 0.4085123459892583}
2023-01-05 12:24:40,482 INFO:     Found new best model at epoch 26
2023-01-05 12:24:40,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:40,483 INFO:     Epoch: 27
2023-01-05 12:24:42,668 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41239751478036246, 'Total loss': 0.41239751478036246} | train loss {'Reaction outcome loss': 0.40097737413182155, 'Total loss': 0.40097737413182155}
2023-01-05 12:24:42,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:42,668 INFO:     Epoch: 28
2023-01-05 12:24:44,864 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40836583574612934, 'Total loss': 0.40836583574612934} | train loss {'Reaction outcome loss': 0.40012682318041903, 'Total loss': 0.40012682318041903}
2023-01-05 12:24:44,865 INFO:     Found new best model at epoch 28
2023-01-05 12:24:44,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:44,867 INFO:     Epoch: 29
2023-01-05 12:24:47,044 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41079028348128, 'Total loss': 0.41079028348128} | train loss {'Reaction outcome loss': 0.39788714357877036, 'Total loss': 0.39788714357877036}
2023-01-05 12:24:47,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:47,044 INFO:     Epoch: 30
2023-01-05 12:24:49,221 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3971991608540217, 'Total loss': 0.3971991608540217} | train loss {'Reaction outcome loss': 0.39462280684967765, 'Total loss': 0.39462280684967765}
2023-01-05 12:24:49,221 INFO:     Found new best model at epoch 30
2023-01-05 12:24:49,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:49,222 INFO:     Epoch: 31
2023-01-05 12:24:51,402 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4121227701505025, 'Total loss': 0.4121227701505025} | train loss {'Reaction outcome loss': 0.3918414540346779, 'Total loss': 0.3918414540346779}
2023-01-05 12:24:51,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:51,403 INFO:     Epoch: 32
2023-01-05 12:24:53,572 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39103561639785767, 'Total loss': 0.39103561639785767} | train loss {'Reaction outcome loss': 0.38665783687726685, 'Total loss': 0.38665783687726685}
2023-01-05 12:24:53,573 INFO:     Found new best model at epoch 32
2023-01-05 12:24:53,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:53,574 INFO:     Epoch: 33
2023-01-05 12:24:55,752 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.412632276614507, 'Total loss': 0.412632276614507} | train loss {'Reaction outcome loss': 0.38047448768942793, 'Total loss': 0.38047448768942793}
2023-01-05 12:24:55,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:55,752 INFO:     Epoch: 34
2023-01-05 12:24:57,934 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3750996748606364, 'Total loss': 0.3750996748606364} | train loss {'Reaction outcome loss': 0.3784183547008339, 'Total loss': 0.3784183547008339}
2023-01-05 12:24:57,934 INFO:     Found new best model at epoch 34
2023-01-05 12:24:57,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:24:57,936 INFO:     Epoch: 35
2023-01-05 12:25:00,108 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.388434570034345, 'Total loss': 0.388434570034345} | train loss {'Reaction outcome loss': 0.37857539349299474, 'Total loss': 0.37857539349299474}
2023-01-05 12:25:00,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:00,108 INFO:     Epoch: 36
2023-01-05 12:25:02,305 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41793377498785655, 'Total loss': 0.41793377498785655} | train loss {'Reaction outcome loss': 0.3740769907132813, 'Total loss': 0.3740769907132813}
2023-01-05 12:25:02,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:02,305 INFO:     Epoch: 37
2023-01-05 12:25:04,489 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39612339238325756, 'Total loss': 0.39612339238325756} | train loss {'Reaction outcome loss': 0.3695790245591088, 'Total loss': 0.3695790245591088}
2023-01-05 12:25:04,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:04,490 INFO:     Epoch: 38
2023-01-05 12:25:06,652 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40989453593889874, 'Total loss': 0.40989453593889874} | train loss {'Reaction outcome loss': 0.36470993097185656, 'Total loss': 0.36470993097185656}
2023-01-05 12:25:06,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:06,652 INFO:     Epoch: 39
2023-01-05 12:25:08,843 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37940906782945, 'Total loss': 0.37940906782945} | train loss {'Reaction outcome loss': 0.3656159948813141, 'Total loss': 0.3656159948813141}
2023-01-05 12:25:08,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:08,843 INFO:     Epoch: 40
2023-01-05 12:25:11,030 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4161079426606496, 'Total loss': 0.4161079426606496} | train loss {'Reaction outcome loss': 0.3674977206446849, 'Total loss': 0.3674977206446849}
2023-01-05 12:25:11,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:11,030 INFO:     Epoch: 41
2023-01-05 12:25:13,219 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4024856865406036, 'Total loss': 0.4024856865406036} | train loss {'Reaction outcome loss': 0.35616748537935505, 'Total loss': 0.35616748537935505}
2023-01-05 12:25:13,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:13,219 INFO:     Epoch: 42
2023-01-05 12:25:15,415 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4171804895003637, 'Total loss': 0.4171804895003637} | train loss {'Reaction outcome loss': 0.35244019365859375, 'Total loss': 0.35244019365859375}
2023-01-05 12:25:15,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:15,415 INFO:     Epoch: 43
2023-01-05 12:25:17,607 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.390405281384786, 'Total loss': 0.390405281384786} | train loss {'Reaction outcome loss': 0.35707589987974736, 'Total loss': 0.35707589987974736}
2023-01-05 12:25:17,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:17,608 INFO:     Epoch: 44
2023-01-05 12:25:19,787 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3897566616535187, 'Total loss': 0.3897566616535187} | train loss {'Reaction outcome loss': 0.3507360412271875, 'Total loss': 0.3507360412271875}
2023-01-05 12:25:19,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:19,788 INFO:     Epoch: 45
2023-01-05 12:25:21,969 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41699030101299284, 'Total loss': 0.41699030101299284} | train loss {'Reaction outcome loss': 0.3391963743103755, 'Total loss': 0.3391963743103755}
2023-01-05 12:25:21,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:21,969 INFO:     Epoch: 46
2023-01-05 12:25:24,142 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39185689588387806, 'Total loss': 0.39185689588387806} | train loss {'Reaction outcome loss': 0.34658241933648765, 'Total loss': 0.34658241933648765}
2023-01-05 12:25:24,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:24,143 INFO:     Epoch: 47
2023-01-05 12:25:26,322 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36327804426352184, 'Total loss': 0.36327804426352184} | train loss {'Reaction outcome loss': 0.33966561581683935, 'Total loss': 0.33966561581683935}
2023-01-05 12:25:26,323 INFO:     Found new best model at epoch 47
2023-01-05 12:25:26,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:26,324 INFO:     Epoch: 48
2023-01-05 12:25:28,475 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36396052266160644, 'Total loss': 0.36396052266160644} | train loss {'Reaction outcome loss': 0.33256099636696734, 'Total loss': 0.33256099636696734}
2023-01-05 12:25:28,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:28,475 INFO:     Epoch: 49
2023-01-05 12:25:30,651 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3926325152317683, 'Total loss': 0.3926325152317683} | train loss {'Reaction outcome loss': 0.336129298655565, 'Total loss': 0.336129298655565}
2023-01-05 12:25:30,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:30,652 INFO:     Epoch: 50
2023-01-05 12:25:32,819 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.401311985651652, 'Total loss': 0.401311985651652} | train loss {'Reaction outcome loss': 0.3329543494468131, 'Total loss': 0.3329543494468131}
2023-01-05 12:25:32,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:32,820 INFO:     Epoch: 51
2023-01-05 12:25:35,002 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3901831477880478, 'Total loss': 0.3901831477880478} | train loss {'Reaction outcome loss': 0.3334435504804019, 'Total loss': 0.3334435504804019}
2023-01-05 12:25:35,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:35,002 INFO:     Epoch: 52
2023-01-05 12:25:37,186 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37586937149365746, 'Total loss': 0.37586937149365746} | train loss {'Reaction outcome loss': 0.33309076834026224, 'Total loss': 0.33309076834026224}
2023-01-05 12:25:37,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:37,186 INFO:     Epoch: 53
2023-01-05 12:25:39,365 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40086424549420674, 'Total loss': 0.40086424549420674} | train loss {'Reaction outcome loss': 0.3275875449180603, 'Total loss': 0.3275875449180603}
2023-01-05 12:25:39,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:39,366 INFO:     Epoch: 54
2023-01-05 12:25:41,565 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3685858507951101, 'Total loss': 0.3685858507951101} | train loss {'Reaction outcome loss': 0.3283102097332693, 'Total loss': 0.3283102097332693}
2023-01-05 12:25:41,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:41,565 INFO:     Epoch: 55
2023-01-05 12:25:43,793 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39249573250611625, 'Total loss': 0.39249573250611625} | train loss {'Reaction outcome loss': 0.3182735316697441, 'Total loss': 0.3182735316697441}
2023-01-05 12:25:43,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:43,793 INFO:     Epoch: 56
2023-01-05 12:25:45,951 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37803874388337133, 'Total loss': 0.37803874388337133} | train loss {'Reaction outcome loss': 0.3155508246877994, 'Total loss': 0.3155508246877994}
2023-01-05 12:25:45,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:45,951 INFO:     Epoch: 57
2023-01-05 12:25:48,128 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36893720030784605, 'Total loss': 0.36893720030784605} | train loss {'Reaction outcome loss': 0.31129598464238517, 'Total loss': 0.31129598464238517}
2023-01-05 12:25:48,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:48,129 INFO:     Epoch: 58
2023-01-05 12:25:50,314 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3792666494846344, 'Total loss': 0.3792666494846344} | train loss {'Reaction outcome loss': 0.308232943920775, 'Total loss': 0.308232943920775}
2023-01-05 12:25:50,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:50,314 INFO:     Epoch: 59
2023-01-05 12:25:52,462 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37586292723814646, 'Total loss': 0.37586292723814646} | train loss {'Reaction outcome loss': 0.308867546625516, 'Total loss': 0.308867546625516}
2023-01-05 12:25:52,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:52,462 INFO:     Epoch: 60
2023-01-05 12:25:54,651 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37688984870910647, 'Total loss': 0.37688984870910647} | train loss {'Reaction outcome loss': 0.3115341245105981, 'Total loss': 0.3115341245105981}
2023-01-05 12:25:54,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:54,653 INFO:     Epoch: 61
2023-01-05 12:25:56,821 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38457098255554834, 'Total loss': 0.38457098255554834} | train loss {'Reaction outcome loss': 0.31631806262832685, 'Total loss': 0.31631806262832685}
2023-01-05 12:25:56,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:56,821 INFO:     Epoch: 62
2023-01-05 12:25:58,994 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38872485955556235, 'Total loss': 0.38872485955556235} | train loss {'Reaction outcome loss': 0.30938415450551665, 'Total loss': 0.30938415450551665}
2023-01-05 12:25:58,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:25:58,995 INFO:     Epoch: 63
2023-01-05 12:26:01,162 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38307419915994007, 'Total loss': 0.38307419915994007} | train loss {'Reaction outcome loss': 0.30629971391430616, 'Total loss': 0.30629971391430616}
2023-01-05 12:26:01,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:01,163 INFO:     Epoch: 64
2023-01-05 12:26:03,321 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36809614350398384, 'Total loss': 0.36809614350398384} | train loss {'Reaction outcome loss': 0.3027484888002438, 'Total loss': 0.3027484888002438}
2023-01-05 12:26:03,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:03,321 INFO:     Epoch: 65
2023-01-05 12:26:05,537 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36591340800126393, 'Total loss': 0.36591340800126393} | train loss {'Reaction outcome loss': 0.3004218331850823, 'Total loss': 0.3004218331850823}
2023-01-05 12:26:05,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:05,537 INFO:     Epoch: 66
2023-01-05 12:26:07,753 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37263614932696026, 'Total loss': 0.37263614932696026} | train loss {'Reaction outcome loss': 0.29462305346120565, 'Total loss': 0.29462305346120565}
2023-01-05 12:26:07,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:07,753 INFO:     Epoch: 67
2023-01-05 12:26:09,975 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.402687731385231, 'Total loss': 0.402687731385231} | train loss {'Reaction outcome loss': 0.29396205700745653, 'Total loss': 0.29396205700745653}
2023-01-05 12:26:09,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:09,975 INFO:     Epoch: 68
2023-01-05 12:26:12,203 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3622897297143936, 'Total loss': 0.3622897297143936} | train loss {'Reaction outcome loss': 0.2965947637731203, 'Total loss': 0.2965947637731203}
2023-01-05 12:26:12,203 INFO:     Found new best model at epoch 68
2023-01-05 12:26:12,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:12,204 INFO:     Epoch: 69
2023-01-05 12:26:14,386 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38280822734038034, 'Total loss': 0.38280822734038034} | train loss {'Reaction outcome loss': 0.29138751913009997, 'Total loss': 0.29138751913009997}
2023-01-05 12:26:14,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:14,387 INFO:     Epoch: 70
2023-01-05 12:26:16,578 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3698378294706345, 'Total loss': 0.3698378294706345} | train loss {'Reaction outcome loss': 0.2924788975180379, 'Total loss': 0.2924788975180379}
2023-01-05 12:26:16,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:16,579 INFO:     Epoch: 71
2023-01-05 12:26:18,749 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37482312619686126, 'Total loss': 0.37482312619686126} | train loss {'Reaction outcome loss': 0.2872633220701872, 'Total loss': 0.2872633220701872}
2023-01-05 12:26:18,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:18,749 INFO:     Epoch: 72
2023-01-05 12:26:20,916 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.382712717851003, 'Total loss': 0.382712717851003} | train loss {'Reaction outcome loss': 0.287258433480663, 'Total loss': 0.287258433480663}
2023-01-05 12:26:20,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:20,916 INFO:     Epoch: 73
2023-01-05 12:26:23,100 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3890376696983973, 'Total loss': 0.3890376696983973} | train loss {'Reaction outcome loss': 0.29107829349431535, 'Total loss': 0.29107829349431535}
2023-01-05 12:26:23,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:23,100 INFO:     Epoch: 74
2023-01-05 12:26:25,277 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38056318561236063, 'Total loss': 0.38056318561236063} | train loss {'Reaction outcome loss': 0.28770105798967477, 'Total loss': 0.28770105798967477}
2023-01-05 12:26:25,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:25,277 INFO:     Epoch: 75
2023-01-05 12:26:27,432 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.394016432762146, 'Total loss': 0.394016432762146} | train loss {'Reaction outcome loss': 0.2882262431892032, 'Total loss': 0.2882262431892032}
2023-01-05 12:26:27,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:27,433 INFO:     Epoch: 76
2023-01-05 12:26:29,602 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37968764702479046, 'Total loss': 0.37968764702479046} | train loss {'Reaction outcome loss': 0.27902264427057455, 'Total loss': 0.27902264427057455}
2023-01-05 12:26:29,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:29,602 INFO:     Epoch: 77
2023-01-05 12:26:31,784 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3940483140448729, 'Total loss': 0.3940483140448729} | train loss {'Reaction outcome loss': 0.27635240082087714, 'Total loss': 0.27635240082087714}
2023-01-05 12:26:31,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:31,785 INFO:     Epoch: 78
2023-01-05 12:26:33,952 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3991210917631785, 'Total loss': 0.3991210917631785} | train loss {'Reaction outcome loss': 0.274132703284696, 'Total loss': 0.274132703284696}
2023-01-05 12:26:33,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:33,953 INFO:     Epoch: 79
2023-01-05 12:26:36,126 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3949417422215144, 'Total loss': 0.3949417422215144} | train loss {'Reaction outcome loss': 0.2756209425117135, 'Total loss': 0.2756209425117135}
2023-01-05 12:26:36,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:36,126 INFO:     Epoch: 80
2023-01-05 12:26:38,312 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38046875993410745, 'Total loss': 0.38046875993410745} | train loss {'Reaction outcome loss': 0.26936483083945106, 'Total loss': 0.26936483083945106}
2023-01-05 12:26:38,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:38,313 INFO:     Epoch: 81
2023-01-05 12:26:40,486 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43317698041598, 'Total loss': 0.43317698041598} | train loss {'Reaction outcome loss': 0.2717284207578601, 'Total loss': 0.2717284207578601}
2023-01-05 12:26:40,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:40,486 INFO:     Epoch: 82
2023-01-05 12:26:42,661 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35525281776984535, 'Total loss': 0.35525281776984535} | train loss {'Reaction outcome loss': 0.2693469144255999, 'Total loss': 0.2693469144255999}
2023-01-05 12:26:42,661 INFO:     Found new best model at epoch 82
2023-01-05 12:26:42,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:42,662 INFO:     Epoch: 83
2023-01-05 12:26:44,858 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3746133734782537, 'Total loss': 0.3746133734782537} | train loss {'Reaction outcome loss': 0.26582164762521476, 'Total loss': 0.26582164762521476}
2023-01-05 12:26:44,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:44,858 INFO:     Epoch: 84
2023-01-05 12:26:47,040 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35720792214075725, 'Total loss': 0.35720792214075725} | train loss {'Reaction outcome loss': 0.26901269747139317, 'Total loss': 0.26901269747139317}
2023-01-05 12:26:47,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:47,040 INFO:     Epoch: 85
2023-01-05 12:26:49,213 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3754035532474518, 'Total loss': 0.3754035532474518} | train loss {'Reaction outcome loss': 0.27564103319057487, 'Total loss': 0.27564103319057487}
2023-01-05 12:26:49,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:49,213 INFO:     Epoch: 86
2023-01-05 12:26:51,376 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3710061863064766, 'Total loss': 0.3710061863064766} | train loss {'Reaction outcome loss': 0.26952335627124197, 'Total loss': 0.26952335627124197}
2023-01-05 12:26:51,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:51,377 INFO:     Epoch: 87
2023-01-05 12:26:53,548 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3695174197355906, 'Total loss': 0.3695174197355906} | train loss {'Reaction outcome loss': 0.264886933220853, 'Total loss': 0.264886933220853}
2023-01-05 12:26:53,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:53,548 INFO:     Epoch: 88
2023-01-05 12:26:55,739 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39825212260087334, 'Total loss': 0.39825212260087334} | train loss {'Reaction outcome loss': 0.25677172054237407, 'Total loss': 0.25677172054237407}
2023-01-05 12:26:55,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:55,740 INFO:     Epoch: 89
2023-01-05 12:26:57,931 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37374748786290485, 'Total loss': 0.37374748786290485} | train loss {'Reaction outcome loss': 0.26572725608514536, 'Total loss': 0.26572725608514536}
2023-01-05 12:26:57,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:26:57,932 INFO:     Epoch: 90
2023-01-05 12:27:00,123 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.35167789657910664, 'Total loss': 0.35167789657910664} | train loss {'Reaction outcome loss': 0.25508714437027485, 'Total loss': 0.25508714437027485}
2023-01-05 12:27:00,123 INFO:     Found new best model at epoch 90
2023-01-05 12:27:00,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:00,124 INFO:     Epoch: 91
2023-01-05 12:27:02,276 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34503891120354335, 'Total loss': 0.34503891120354335} | train loss {'Reaction outcome loss': 0.26028016579441643, 'Total loss': 0.26028016579441643}
2023-01-05 12:27:02,277 INFO:     Found new best model at epoch 91
2023-01-05 12:27:02,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:02,278 INFO:     Epoch: 92
2023-01-05 12:27:04,460 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3485574801762899, 'Total loss': 0.3485574801762899} | train loss {'Reaction outcome loss': 0.2654220099537381, 'Total loss': 0.2654220099537381}
2023-01-05 12:27:04,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:04,461 INFO:     Epoch: 93
2023-01-05 12:27:06,633 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4059696028629939, 'Total loss': 0.4059696028629939} | train loss {'Reaction outcome loss': 0.26867152164128716, 'Total loss': 0.26867152164128716}
2023-01-05 12:27:06,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:06,633 INFO:     Epoch: 94
2023-01-05 12:27:08,602 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36522285441557567, 'Total loss': 0.36522285441557567} | train loss {'Reaction outcome loss': 0.2588467753361171, 'Total loss': 0.2588467753361171}
2023-01-05 12:27:08,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:08,603 INFO:     Epoch: 95
2023-01-05 12:27:10,798 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39402690827846526, 'Total loss': 0.39402690827846526} | train loss {'Reaction outcome loss': 0.26120745099489223, 'Total loss': 0.26120745099489223}
2023-01-05 12:27:10,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:10,798 INFO:     Epoch: 96
2023-01-05 12:27:12,974 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4052976836760839, 'Total loss': 0.4052976836760839} | train loss {'Reaction outcome loss': 0.25648102587230154, 'Total loss': 0.25648102587230154}
2023-01-05 12:27:12,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:12,974 INFO:     Epoch: 97
2023-01-05 12:27:15,138 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3861686835686366, 'Total loss': 0.3861686835686366} | train loss {'Reaction outcome loss': 0.2524384065776633, 'Total loss': 0.2524384065776633}
2023-01-05 12:27:15,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:15,139 INFO:     Epoch: 98
2023-01-05 12:27:17,314 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3897994061311086, 'Total loss': 0.3897994061311086} | train loss {'Reaction outcome loss': 0.2574354554341588, 'Total loss': 0.2574354554341588}
2023-01-05 12:27:17,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:17,314 INFO:     Epoch: 99
2023-01-05 12:27:19,486 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37399486601352694, 'Total loss': 0.37399486601352694} | train loss {'Reaction outcome loss': 0.2520196038947209, 'Total loss': 0.2520196038947209}
2023-01-05 12:27:19,486 INFO:     Best model found after epoch 92 of 100.
2023-01-05 12:27:19,487 INFO:   Done with stage: TRAINING
2023-01-05 12:27:19,487 INFO:   Starting stage: EVALUATION
2023-01-05 12:27:19,613 INFO:   Done with stage: EVALUATION
2023-01-05 12:27:19,622 INFO:   Leaving out SEQ value Fold_0
2023-01-05 12:27:19,634 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 12:27:19,635 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:27:20,287 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:27:20,288 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:27:20,357 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:27:20,357 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:27:20,357 INFO:     No hyperparam tuning for this model
2023-01-05 12:27:20,357 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:27:20,357 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:27:20,358 INFO:     None feature selector for col prot
2023-01-05 12:27:20,358 INFO:     None feature selector for col prot
2023-01-05 12:27:20,358 INFO:     None feature selector for col prot
2023-01-05 12:27:20,359 INFO:     None feature selector for col chem
2023-01-05 12:27:20,359 INFO:     None feature selector for col chem
2023-01-05 12:27:20,359 INFO:     None feature selector for col chem
2023-01-05 12:27:20,359 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:27:20,359 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:27:20,361 INFO:     Number of params in model 72901
2023-01-05 12:27:20,364 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:27:20,364 INFO:   Starting stage: TRAINING
2023-01-05 12:27:20,425 INFO:     Val loss before train {'Reaction outcome loss': 0.9538790543874105, 'Total loss': 0.9538790543874105}
2023-01-05 12:27:20,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:20,425 INFO:     Epoch: 0
2023-01-05 12:27:22,598 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7728070616722107, 'Total loss': 0.7728070616722107} | train loss {'Reaction outcome loss': 0.9281571317410123, 'Total loss': 0.9281571317410123}
2023-01-05 12:27:22,599 INFO:     Found new best model at epoch 0
2023-01-05 12:27:22,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:22,601 INFO:     Epoch: 1
2023-01-05 12:27:24,762 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.604448390007019, 'Total loss': 0.604448390007019} | train loss {'Reaction outcome loss': 0.7586452625151994, 'Total loss': 0.7586452625151994}
2023-01-05 12:27:24,762 INFO:     Found new best model at epoch 1
2023-01-05 12:27:24,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:24,763 INFO:     Epoch: 2
2023-01-05 12:27:26,934 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5184197107950846, 'Total loss': 0.5184197107950846} | train loss {'Reaction outcome loss': 0.607622461520014, 'Total loss': 0.607622461520014}
2023-01-05 12:27:26,934 INFO:     Found new best model at epoch 2
2023-01-05 12:27:26,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:26,936 INFO:     Epoch: 3
2023-01-05 12:27:29,096 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4846200923124949, 'Total loss': 0.4846200923124949} | train loss {'Reaction outcome loss': 0.5346979806503362, 'Total loss': 0.5346979806503362}
2023-01-05 12:27:29,096 INFO:     Found new best model at epoch 3
2023-01-05 12:27:29,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:29,098 INFO:     Epoch: 4
2023-01-05 12:27:31,276 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47635418077309927, 'Total loss': 0.47635418077309927} | train loss {'Reaction outcome loss': 0.5084220874040808, 'Total loss': 0.5084220874040808}
2023-01-05 12:27:31,276 INFO:     Found new best model at epoch 4
2023-01-05 12:27:31,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:31,277 INFO:     Epoch: 5
2023-01-05 12:27:33,478 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.454913721481959, 'Total loss': 0.454913721481959} | train loss {'Reaction outcome loss': 0.5035753161443964, 'Total loss': 0.5035753161443964}
2023-01-05 12:27:33,478 INFO:     Found new best model at epoch 5
2023-01-05 12:27:33,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:33,480 INFO:     Epoch: 6
2023-01-05 12:27:35,658 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4755518943071365, 'Total loss': 0.4755518943071365} | train loss {'Reaction outcome loss': 0.49677796445894934, 'Total loss': 0.49677796445894934}
2023-01-05 12:27:35,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:35,658 INFO:     Epoch: 7
2023-01-05 12:27:37,825 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4619426111380259, 'Total loss': 0.4619426111380259} | train loss {'Reaction outcome loss': 0.5111456255199037, 'Total loss': 0.5111456255199037}
2023-01-05 12:27:37,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:37,827 INFO:     Epoch: 8
2023-01-05 12:27:40,003 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4594558795293172, 'Total loss': 0.4594558795293172} | train loss {'Reaction outcome loss': 0.4793929761829044, 'Total loss': 0.4793929761829044}
2023-01-05 12:27:40,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:40,003 INFO:     Epoch: 9
2023-01-05 12:27:42,191 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4270810147126516, 'Total loss': 0.4270810147126516} | train loss {'Reaction outcome loss': 0.4717718207857747, 'Total loss': 0.4717718207857747}
2023-01-05 12:27:42,191 INFO:     Found new best model at epoch 9
2023-01-05 12:27:42,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:42,192 INFO:     Epoch: 10
2023-01-05 12:27:44,371 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.433931635816892, 'Total loss': 0.433931635816892} | train loss {'Reaction outcome loss': 0.47402706075513706, 'Total loss': 0.47402706075513706}
2023-01-05 12:27:44,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:44,372 INFO:     Epoch: 11
2023-01-05 12:27:46,552 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44586315254370373, 'Total loss': 0.44586315254370373} | train loss {'Reaction outcome loss': 0.4645156015193198, 'Total loss': 0.4645156015193198}
2023-01-05 12:27:46,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:46,552 INFO:     Epoch: 12
2023-01-05 12:27:48,731 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4118944197893143, 'Total loss': 0.4118944197893143} | train loss {'Reaction outcome loss': 0.45880732183223183, 'Total loss': 0.45880732183223183}
2023-01-05 12:27:48,731 INFO:     Found new best model at epoch 12
2023-01-05 12:27:48,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:48,732 INFO:     Epoch: 13
2023-01-05 12:27:50,936 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4714651177326838, 'Total loss': 0.4714651177326838} | train loss {'Reaction outcome loss': 0.45326345122041367, 'Total loss': 0.45326345122041367}
2023-01-05 12:27:50,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:50,937 INFO:     Epoch: 14
2023-01-05 12:27:53,183 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41986626386642456, 'Total loss': 0.41986626386642456} | train loss {'Reaction outcome loss': 0.4529956875357775, 'Total loss': 0.4529956875357775}
2023-01-05 12:27:53,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:53,184 INFO:     Epoch: 15
2023-01-05 12:27:55,425 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43303571244080863, 'Total loss': 0.43303571244080863} | train loss {'Reaction outcome loss': 0.44864056650819123, 'Total loss': 0.44864056650819123}
2023-01-05 12:27:55,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:55,425 INFO:     Epoch: 16
2023-01-05 12:27:57,647 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4323783616224925, 'Total loss': 0.4323783616224925} | train loss {'Reaction outcome loss': 0.4439500845712272, 'Total loss': 0.4439500845712272}
2023-01-05 12:27:57,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:57,648 INFO:     Epoch: 17
2023-01-05 12:27:59,857 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4086147079865138, 'Total loss': 0.4086147079865138} | train loss {'Reaction outcome loss': 0.4381326248302408, 'Total loss': 0.4381326248302408}
2023-01-05 12:27:59,857 INFO:     Found new best model at epoch 17
2023-01-05 12:27:59,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:27:59,859 INFO:     Epoch: 18
2023-01-05 12:28:02,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41491074760754904, 'Total loss': 0.41491074760754904} | train loss {'Reaction outcome loss': 0.4371629467645687, 'Total loss': 0.4371629467645687}
2023-01-05 12:28:02,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:02,066 INFO:     Epoch: 19
2023-01-05 12:28:04,251 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3968309789896011, 'Total loss': 0.3968309789896011} | train loss {'Reaction outcome loss': 0.44238225176282553, 'Total loss': 0.44238225176282553}
2023-01-05 12:28:04,251 INFO:     Found new best model at epoch 19
2023-01-05 12:28:04,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:04,252 INFO:     Epoch: 20
2023-01-05 12:28:06,431 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40648497343063356, 'Total loss': 0.40648497343063356} | train loss {'Reaction outcome loss': 0.45330067803624313, 'Total loss': 0.45330067803624313}
2023-01-05 12:28:06,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:06,431 INFO:     Epoch: 21
2023-01-05 12:28:08,625 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41117183764775594, 'Total loss': 0.41117183764775594} | train loss {'Reaction outcome loss': 0.4246854884954898, 'Total loss': 0.4246854884954898}
2023-01-05 12:28:08,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:08,626 INFO:     Epoch: 22
2023-01-05 12:28:10,806 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39510628978411355, 'Total loss': 0.39510628978411355} | train loss {'Reaction outcome loss': 0.4231335047187041, 'Total loss': 0.4231335047187041}
2023-01-05 12:28:10,806 INFO:     Found new best model at epoch 22
2023-01-05 12:28:10,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:10,808 INFO:     Epoch: 23
2023-01-05 12:28:12,978 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4073582887649536, 'Total loss': 0.4073582887649536} | train loss {'Reaction outcome loss': 0.4139702362489239, 'Total loss': 0.4139702362489239}
2023-01-05 12:28:12,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:12,980 INFO:     Epoch: 24
2023-01-05 12:28:15,180 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4136341243982315, 'Total loss': 0.4136341243982315} | train loss {'Reaction outcome loss': 0.4138847333581551, 'Total loss': 0.4138847333581551}
2023-01-05 12:28:15,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:15,180 INFO:     Epoch: 25
2023-01-05 12:28:17,358 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38043179114659625, 'Total loss': 0.38043179114659625} | train loss {'Reaction outcome loss': 0.4296167773073134, 'Total loss': 0.4296167773073134}
2023-01-05 12:28:17,358 INFO:     Found new best model at epoch 25
2023-01-05 12:28:17,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:17,360 INFO:     Epoch: 26
2023-01-05 12:28:19,557 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4031564712524414, 'Total loss': 0.4031564712524414} | train loss {'Reaction outcome loss': 0.40543089565709667, 'Total loss': 0.40543089565709667}
2023-01-05 12:28:19,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:19,558 INFO:     Epoch: 27
2023-01-05 12:28:21,730 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41060335040092466, 'Total loss': 0.41060335040092466} | train loss {'Reaction outcome loss': 0.40529530179565365, 'Total loss': 0.40529530179565365}
2023-01-05 12:28:21,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:21,730 INFO:     Epoch: 28
2023-01-05 12:28:23,919 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3953627328077952, 'Total loss': 0.3953627328077952} | train loss {'Reaction outcome loss': 0.40186998328916135, 'Total loss': 0.40186998328916135}
2023-01-05 12:28:23,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:23,920 INFO:     Epoch: 29
2023-01-05 12:28:26,096 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41296967963377634, 'Total loss': 0.41296967963377634} | train loss {'Reaction outcome loss': 0.39133452372692956, 'Total loss': 0.39133452372692956}
2023-01-05 12:28:26,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:26,096 INFO:     Epoch: 30
2023-01-05 12:28:28,280 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39734777410825095, 'Total loss': 0.39734777410825095} | train loss {'Reaction outcome loss': 0.39268003362846776, 'Total loss': 0.39268003362846776}
2023-01-05 12:28:28,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:28,280 INFO:     Epoch: 31
2023-01-05 12:28:30,467 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40437847673892974, 'Total loss': 0.40437847673892974} | train loss {'Reaction outcome loss': 0.3883328667463924, 'Total loss': 0.3883328667463924}
2023-01-05 12:28:30,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:30,468 INFO:     Epoch: 32
2023-01-05 12:28:32,660 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3778860340515772, 'Total loss': 0.3778860340515772} | train loss {'Reaction outcome loss': 0.3839414226451376, 'Total loss': 0.3839414226451376}
2023-01-05 12:28:32,661 INFO:     Found new best model at epoch 32
2023-01-05 12:28:32,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:32,662 INFO:     Epoch: 33
2023-01-05 12:28:34,846 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3716781560331583, 'Total loss': 0.3716781560331583} | train loss {'Reaction outcome loss': 0.38272225165354135, 'Total loss': 0.38272225165354135}
2023-01-05 12:28:34,846 INFO:     Found new best model at epoch 33
2023-01-05 12:28:34,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:34,848 INFO:     Epoch: 34
2023-01-05 12:28:37,020 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37849030991395316, 'Total loss': 0.37849030991395316} | train loss {'Reaction outcome loss': 0.3798185727623143, 'Total loss': 0.3798185727623143}
2023-01-05 12:28:37,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:37,020 INFO:     Epoch: 35
2023-01-05 12:28:39,213 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40777729948361713, 'Total loss': 0.40777729948361713} | train loss {'Reaction outcome loss': 0.37415495397020265, 'Total loss': 0.37415495397020265}
2023-01-05 12:28:39,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:39,213 INFO:     Epoch: 36
2023-01-05 12:28:41,395 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.381403552989165, 'Total loss': 0.381403552989165} | train loss {'Reaction outcome loss': 0.3723212659731845, 'Total loss': 0.3723212659731845}
2023-01-05 12:28:41,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:41,395 INFO:     Epoch: 37
2023-01-05 12:28:43,573 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37369407042860986, 'Total loss': 0.37369407042860986} | train loss {'Reaction outcome loss': 0.36821214534996916, 'Total loss': 0.36821214534996916}
2023-01-05 12:28:43,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:43,573 INFO:     Epoch: 38
2023-01-05 12:28:45,747 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41139456977446875, 'Total loss': 0.41139456977446875} | train loss {'Reaction outcome loss': 0.36855602245507896, 'Total loss': 0.36855602245507896}
2023-01-05 12:28:45,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:45,748 INFO:     Epoch: 39
2023-01-05 12:28:47,922 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.388510861992836, 'Total loss': 0.388510861992836} | train loss {'Reaction outcome loss': 0.3660669955855195, 'Total loss': 0.3660669955855195}
2023-01-05 12:28:47,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:47,922 INFO:     Epoch: 40
2023-01-05 12:28:50,103 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3854938710729281, 'Total loss': 0.3854938710729281} | train loss {'Reaction outcome loss': 0.35745268666321045, 'Total loss': 0.35745268666321045}
2023-01-05 12:28:50,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:50,104 INFO:     Epoch: 41
2023-01-05 12:28:52,284 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39795488913853966, 'Total loss': 0.39795488913853966} | train loss {'Reaction outcome loss': 0.3537650353098886, 'Total loss': 0.3537650353098886}
2023-01-05 12:28:52,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:52,285 INFO:     Epoch: 42
2023-01-05 12:28:54,478 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3893365462621053, 'Total loss': 0.3893365462621053} | train loss {'Reaction outcome loss': 0.35393396361557633, 'Total loss': 0.35393396361557633}
2023-01-05 12:28:54,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:54,478 INFO:     Epoch: 43
2023-01-05 12:28:56,663 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3937206377585729, 'Total loss': 0.3937206377585729} | train loss {'Reaction outcome loss': 0.3491325575917511, 'Total loss': 0.3491325575917511}
2023-01-05 12:28:56,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:56,664 INFO:     Epoch: 44
2023-01-05 12:28:58,831 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39963224828243255, 'Total loss': 0.39963224828243255} | train loss {'Reaction outcome loss': 0.3442670129833446, 'Total loss': 0.3442670129833446}
2023-01-05 12:28:58,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:28:58,832 INFO:     Epoch: 45
2023-01-05 12:29:01,009 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39476621747016905, 'Total loss': 0.39476621747016905} | train loss {'Reaction outcome loss': 0.34803873789159284, 'Total loss': 0.34803873789159284}
2023-01-05 12:29:01,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:01,009 INFO:     Epoch: 46
2023-01-05 12:29:03,178 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4067328562339147, 'Total loss': 0.4067328562339147} | train loss {'Reaction outcome loss': 0.3549716532613367, 'Total loss': 0.3549716532613367}
2023-01-05 12:29:03,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:03,178 INFO:     Epoch: 47
2023-01-05 12:29:05,353 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38567774295806884, 'Total loss': 0.38567774295806884} | train loss {'Reaction outcome loss': 0.33602575052772526, 'Total loss': 0.33602575052772526}
2023-01-05 12:29:05,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:05,353 INFO:     Epoch: 48
2023-01-05 12:29:07,526 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3636682579914729, 'Total loss': 0.3636682579914729} | train loss {'Reaction outcome loss': 0.3367804596065611, 'Total loss': 0.3367804596065611}
2023-01-05 12:29:07,527 INFO:     Found new best model at epoch 48
2023-01-05 12:29:07,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:07,528 INFO:     Epoch: 49
2023-01-05 12:29:09,699 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3867130617300669, 'Total loss': 0.3867130617300669} | train loss {'Reaction outcome loss': 0.340920597895224, 'Total loss': 0.340920597895224}
2023-01-05 12:29:09,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:09,700 INFO:     Epoch: 50
2023-01-05 12:29:11,854 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3786243220170339, 'Total loss': 0.3786243220170339} | train loss {'Reaction outcome loss': 0.33976369993963645, 'Total loss': 0.33976369993963645}
2023-01-05 12:29:11,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:11,854 INFO:     Epoch: 51
2023-01-05 12:29:14,033 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39981741408507027, 'Total loss': 0.39981741408507027} | train loss {'Reaction outcome loss': 0.3321717489929195, 'Total loss': 0.3321717489929195}
2023-01-05 12:29:14,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:14,034 INFO:     Epoch: 52
2023-01-05 12:29:16,208 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35159048760930695, 'Total loss': 0.35159048760930695} | train loss {'Reaction outcome loss': 0.33117816478783346, 'Total loss': 0.33117816478783346}
2023-01-05 12:29:16,208 INFO:     Found new best model at epoch 52
2023-01-05 12:29:16,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:16,210 INFO:     Epoch: 53
2023-01-05 12:29:18,380 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3969130486249924, 'Total loss': 0.3969130486249924} | train loss {'Reaction outcome loss': 0.3310583883329578, 'Total loss': 0.3310583883329578}
2023-01-05 12:29:18,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:18,381 INFO:     Epoch: 54
2023-01-05 12:29:20,557 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3856477975845337, 'Total loss': 0.3856477975845337} | train loss {'Reaction outcome loss': 0.33057771323913493, 'Total loss': 0.33057771323913493}
2023-01-05 12:29:20,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:20,558 INFO:     Epoch: 55
2023-01-05 12:29:22,751 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.365521439909935, 'Total loss': 0.365521439909935} | train loss {'Reaction outcome loss': 0.32915600173283316, 'Total loss': 0.32915600173283316}
2023-01-05 12:29:22,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:22,751 INFO:     Epoch: 56
2023-01-05 12:29:24,952 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41201807459195455, 'Total loss': 0.41201807459195455} | train loss {'Reaction outcome loss': 0.3368520382386835, 'Total loss': 0.3368520382386835}
2023-01-05 12:29:24,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:24,952 INFO:     Epoch: 57
2023-01-05 12:29:27,171 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39554079473018644, 'Total loss': 0.39554079473018644} | train loss {'Reaction outcome loss': 0.32698879625546606, 'Total loss': 0.32698879625546606}
2023-01-05 12:29:27,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:27,172 INFO:     Epoch: 58
2023-01-05 12:29:29,373 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41440532306830086, 'Total loss': 0.41440532306830086} | train loss {'Reaction outcome loss': 0.3190386460662104, 'Total loss': 0.3190386460662104}
2023-01-05 12:29:29,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:29,374 INFO:     Epoch: 59
2023-01-05 12:29:31,541 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38432126541932427, 'Total loss': 0.38432126541932427} | train loss {'Reaction outcome loss': 0.3418689206486095, 'Total loss': 0.3418689206486095}
2023-01-05 12:29:31,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:31,541 INFO:     Epoch: 60
2023-01-05 12:29:33,764 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3620541791121165, 'Total loss': 0.3620541791121165} | train loss {'Reaction outcome loss': 0.3132005636377827, 'Total loss': 0.3132005636377827}
2023-01-05 12:29:33,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:33,764 INFO:     Epoch: 61
2023-01-05 12:29:35,967 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4522235929965973, 'Total loss': 0.4522235929965973} | train loss {'Reaction outcome loss': 0.3281499548423765, 'Total loss': 0.3281499548423765}
2023-01-05 12:29:35,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:35,968 INFO:     Epoch: 62
2023-01-05 12:29:38,181 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4110613584518433, 'Total loss': 0.4110613584518433} | train loss {'Reaction outcome loss': 0.3163421346387991, 'Total loss': 0.3163421346387991}
2023-01-05 12:29:38,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:38,182 INFO:     Epoch: 63
2023-01-05 12:29:40,383 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38651199887196225, 'Total loss': 0.38651199887196225} | train loss {'Reaction outcome loss': 0.30446641298771865, 'Total loss': 0.30446641298771865}
2023-01-05 12:29:40,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:40,384 INFO:     Epoch: 64
2023-01-05 12:29:42,595 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4045741279919942, 'Total loss': 0.4045741279919942} | train loss {'Reaction outcome loss': 0.31450403261713794, 'Total loss': 0.31450403261713794}
2023-01-05 12:29:42,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:42,595 INFO:     Epoch: 65
2023-01-05 12:29:44,768 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39804183741410576, 'Total loss': 0.39804183741410576} | train loss {'Reaction outcome loss': 0.30814131529278593, 'Total loss': 0.30814131529278593}
2023-01-05 12:29:44,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:44,768 INFO:     Epoch: 66
2023-01-05 12:29:46,948 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39623462955156963, 'Total loss': 0.39623462955156963} | train loss {'Reaction outcome loss': 0.3042347482844269, 'Total loss': 0.3042347482844269}
2023-01-05 12:29:46,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:46,948 INFO:     Epoch: 67
2023-01-05 12:29:49,166 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3656333774328232, 'Total loss': 0.3656333774328232} | train loss {'Reaction outcome loss': 0.3010339980390997, 'Total loss': 0.3010339980390997}
2023-01-05 12:29:49,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:49,166 INFO:     Epoch: 68
2023-01-05 12:29:51,361 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39554812709490456, 'Total loss': 0.39554812709490456} | train loss {'Reaction outcome loss': 0.3078153069279548, 'Total loss': 0.3078153069279548}
2023-01-05 12:29:51,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:51,362 INFO:     Epoch: 69
2023-01-05 12:29:53,561 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4267418771982193, 'Total loss': 0.4267418771982193} | train loss {'Reaction outcome loss': 0.30340684778723476, 'Total loss': 0.30340684778723476}
2023-01-05 12:29:53,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:53,562 INFO:     Epoch: 70
2023-01-05 12:29:55,761 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38199764440457024, 'Total loss': 0.38199764440457024} | train loss {'Reaction outcome loss': 0.301376059185419, 'Total loss': 0.301376059185419}
2023-01-05 12:29:55,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:55,762 INFO:     Epoch: 71
2023-01-05 12:29:57,929 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4162890886267026, 'Total loss': 0.4162890886267026} | train loss {'Reaction outcome loss': 0.2910113306951235, 'Total loss': 0.2910113306951235}
2023-01-05 12:29:57,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:29:57,930 INFO:     Epoch: 72
2023-01-05 12:30:00,121 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3633731712897619, 'Total loss': 0.3633731712897619} | train loss {'Reaction outcome loss': 0.29002535037115973, 'Total loss': 0.29002535037115973}
2023-01-05 12:30:00,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:00,122 INFO:     Epoch: 73
2023-01-05 12:30:02,293 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4041329622268677, 'Total loss': 0.4041329622268677} | train loss {'Reaction outcome loss': 0.28231032234021847, 'Total loss': 0.28231032234021847}
2023-01-05 12:30:02,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:02,293 INFO:     Epoch: 74
2023-01-05 12:30:04,466 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46086656749248506, 'Total loss': 0.46086656749248506} | train loss {'Reaction outcome loss': 0.2884571317277943, 'Total loss': 0.2884571317277943}
2023-01-05 12:30:04,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:04,467 INFO:     Epoch: 75
2023-01-05 12:30:06,656 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3949605663617452, 'Total loss': 0.3949605663617452} | train loss {'Reaction outcome loss': 0.27934810403646715, 'Total loss': 0.27934810403646715}
2023-01-05 12:30:06,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:06,656 INFO:     Epoch: 76
2023-01-05 12:30:08,828 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3654184033473333, 'Total loss': 0.3654184033473333} | train loss {'Reaction outcome loss': 0.2835480381234421, 'Total loss': 0.2835480381234421}
2023-01-05 12:30:08,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:08,829 INFO:     Epoch: 77
2023-01-05 12:30:10,973 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4304673840602239, 'Total loss': 0.4304673840602239} | train loss {'Reaction outcome loss': 0.2793188128566396, 'Total loss': 0.2793188128566396}
2023-01-05 12:30:10,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:10,974 INFO:     Epoch: 78
2023-01-05 12:30:13,137 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4029483507076899, 'Total loss': 0.4029483507076899} | train loss {'Reaction outcome loss': 0.3552276726164248, 'Total loss': 0.3552276726164248}
2023-01-05 12:30:13,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:13,137 INFO:     Epoch: 79
2023-01-05 12:30:15,326 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3966492215792338, 'Total loss': 0.3966492215792338} | train loss {'Reaction outcome loss': 0.28660801211852865, 'Total loss': 0.28660801211852865}
2023-01-05 12:30:15,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:15,326 INFO:     Epoch: 80
2023-01-05 12:30:17,490 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43692830701669055, 'Total loss': 0.43692830701669055} | train loss {'Reaction outcome loss': 0.28078140303546534, 'Total loss': 0.28078140303546534}
2023-01-05 12:30:17,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:17,490 INFO:     Epoch: 81
2023-01-05 12:30:19,637 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.346747737377882, 'Total loss': 0.346747737377882} | train loss {'Reaction outcome loss': 0.28196395154510107, 'Total loss': 0.28196395154510107}
2023-01-05 12:30:19,638 INFO:     Found new best model at epoch 81
2023-01-05 12:30:19,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:19,639 INFO:     Epoch: 82
2023-01-05 12:30:21,800 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39637233714262643, 'Total loss': 0.39637233714262643} | train loss {'Reaction outcome loss': 0.2668424603205336, 'Total loss': 0.2668424603205336}
2023-01-05 12:30:21,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:21,801 INFO:     Epoch: 83
2023-01-05 12:30:23,958 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3885642801721891, 'Total loss': 0.3885642801721891} | train loss {'Reaction outcome loss': 0.2821682866095849, 'Total loss': 0.2821682866095849}
2023-01-05 12:30:23,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:23,958 INFO:     Epoch: 84
2023-01-05 12:30:26,111 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39486233492692313, 'Total loss': 0.39486233492692313} | train loss {'Reaction outcome loss': 0.27135161116640794, 'Total loss': 0.27135161116640794}
2023-01-05 12:30:26,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:26,112 INFO:     Epoch: 85
2023-01-05 12:30:28,287 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42842911879221596, 'Total loss': 0.42842911879221596} | train loss {'Reaction outcome loss': 0.27341962726655183, 'Total loss': 0.27341962726655183}
2023-01-05 12:30:28,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:28,288 INFO:     Epoch: 86
2023-01-05 12:30:30,462 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3874529500802358, 'Total loss': 0.3874529500802358} | train loss {'Reaction outcome loss': 0.2617110307708018, 'Total loss': 0.2617110307708018}
2023-01-05 12:30:30,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:30,462 INFO:     Epoch: 87
2023-01-05 12:30:32,620 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3855935086806615, 'Total loss': 0.3855935086806615} | train loss {'Reaction outcome loss': 0.260744325778248, 'Total loss': 0.260744325778248}
2023-01-05 12:30:32,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:32,621 INFO:     Epoch: 88
2023-01-05 12:30:34,794 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40337021052837374, 'Total loss': 0.40337021052837374} | train loss {'Reaction outcome loss': 0.26480379691043787, 'Total loss': 0.26480379691043787}
2023-01-05 12:30:34,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:34,794 INFO:     Epoch: 89
2023-01-05 12:30:36,953 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37029840250809987, 'Total loss': 0.37029840250809987} | train loss {'Reaction outcome loss': 0.274089768016036, 'Total loss': 0.274089768016036}
2023-01-05 12:30:36,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:36,954 INFO:     Epoch: 90
2023-01-05 12:30:39,109 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4695869505405426, 'Total loss': 0.4695869505405426} | train loss {'Reaction outcome loss': 0.3264776597312395, 'Total loss': 0.3264776597312395}
2023-01-05 12:30:39,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:39,109 INFO:     Epoch: 91
2023-01-05 12:30:41,275 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.401474928855896, 'Total loss': 0.401474928855896} | train loss {'Reaction outcome loss': 0.2724934137844737, 'Total loss': 0.2724934137844737}
2023-01-05 12:30:41,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:41,276 INFO:     Epoch: 92
2023-01-05 12:30:43,428 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4024592339992523, 'Total loss': 0.4024592339992523} | train loss {'Reaction outcome loss': 0.26207011398451024, 'Total loss': 0.26207011398451024}
2023-01-05 12:30:43,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:43,428 INFO:     Epoch: 93
2023-01-05 12:30:45,589 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4209777757525444, 'Total loss': 0.4209777757525444} | train loss {'Reaction outcome loss': 0.26212848381449777, 'Total loss': 0.26212848381449777}
2023-01-05 12:30:45,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:45,590 INFO:     Epoch: 94
2023-01-05 12:30:47,752 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4057182734211286, 'Total loss': 0.4057182734211286} | train loss {'Reaction outcome loss': 0.2836330738863435, 'Total loss': 0.2836330738863435}
2023-01-05 12:30:47,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:47,752 INFO:     Epoch: 95
2023-01-05 12:30:49,918 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38209940294424694, 'Total loss': 0.38209940294424694} | train loss {'Reaction outcome loss': 0.2572249026547254, 'Total loss': 0.2572249026547254}
2023-01-05 12:30:49,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:49,918 INFO:     Epoch: 96
2023-01-05 12:30:52,069 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37667385389407476, 'Total loss': 0.37667385389407476} | train loss {'Reaction outcome loss': 0.26063003119729133, 'Total loss': 0.26063003119729133}
2023-01-05 12:30:52,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:52,069 INFO:     Epoch: 97
2023-01-05 12:30:54,244 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4057271125415961, 'Total loss': 0.4057271125415961} | train loss {'Reaction outcome loss': 0.2585448931171334, 'Total loss': 0.2585448931171334}
2023-01-05 12:30:54,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:54,245 INFO:     Epoch: 98
2023-01-05 12:30:56,400 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40225066939989723, 'Total loss': 0.40225066939989723} | train loss {'Reaction outcome loss': 0.25249241363338154, 'Total loss': 0.25249241363338154}
2023-01-05 12:30:56,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:56,400 INFO:     Epoch: 99
2023-01-05 12:30:58,558 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3781943917274475, 'Total loss': 0.3781943917274475} | train loss {'Reaction outcome loss': 0.24826175838150422, 'Total loss': 0.24826175838150422}
2023-01-05 12:30:58,559 INFO:     Best model found after epoch 82 of 100.
2023-01-05 12:30:58,559 INFO:   Done with stage: TRAINING
2023-01-05 12:30:58,559 INFO:   Starting stage: EVALUATION
2023-01-05 12:30:58,693 INFO:   Done with stage: EVALUATION
2023-01-05 12:30:58,693 INFO:   Leaving out SEQ value Fold_1
2023-01-05 12:30:58,706 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 12:30:58,707 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:30:59,361 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:30:59,361 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:30:59,430 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:30:59,430 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:30:59,430 INFO:     No hyperparam tuning for this model
2023-01-05 12:30:59,430 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:30:59,430 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:30:59,431 INFO:     None feature selector for col prot
2023-01-05 12:30:59,431 INFO:     None feature selector for col prot
2023-01-05 12:30:59,431 INFO:     None feature selector for col prot
2023-01-05 12:30:59,432 INFO:     None feature selector for col chem
2023-01-05 12:30:59,432 INFO:     None feature selector for col chem
2023-01-05 12:30:59,432 INFO:     None feature selector for col chem
2023-01-05 12:30:59,432 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:30:59,432 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:30:59,434 INFO:     Number of params in model 72901
2023-01-05 12:30:59,437 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:30:59,437 INFO:   Starting stage: TRAINING
2023-01-05 12:30:59,496 INFO:     Val loss before train {'Reaction outcome loss': 1.1543112675348917, 'Total loss': 1.1543112675348917}
2023-01-05 12:30:59,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:30:59,496 INFO:     Epoch: 0
2023-01-05 12:31:01,631 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9052068630854289, 'Total loss': 0.9052068630854289} | train loss {'Reaction outcome loss': 0.9121086545755942, 'Total loss': 0.9121086545755942}
2023-01-05 12:31:01,631 INFO:     Found new best model at epoch 0
2023-01-05 12:31:01,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:01,632 INFO:     Epoch: 1
2023-01-05 12:31:03,767 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.641186519463857, 'Total loss': 0.641186519463857} | train loss {'Reaction outcome loss': 0.7375786794947522, 'Total loss': 0.7375786794947522}
2023-01-05 12:31:03,767 INFO:     Found new best model at epoch 1
2023-01-05 12:31:03,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:03,768 INFO:     Epoch: 2
2023-01-05 12:31:05,920 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5671664158503215, 'Total loss': 0.5671664158503215} | train loss {'Reaction outcome loss': 0.5918354340365012, 'Total loss': 0.5918354340365012}
2023-01-05 12:31:05,921 INFO:     Found new best model at epoch 2
2023-01-05 12:31:05,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:05,923 INFO:     Epoch: 3
2023-01-05 12:31:08,044 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5290458391110102, 'Total loss': 0.5290458391110102} | train loss {'Reaction outcome loss': 0.5451704909495761, 'Total loss': 0.5451704909495761}
2023-01-05 12:31:08,044 INFO:     Found new best model at epoch 3
2023-01-05 12:31:08,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:08,046 INFO:     Epoch: 4
2023-01-05 12:31:10,188 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.578567498922348, 'Total loss': 0.578567498922348} | train loss {'Reaction outcome loss': 0.5241881330184831, 'Total loss': 0.5241881330184831}
2023-01-05 12:31:10,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:10,188 INFO:     Epoch: 5
2023-01-05 12:31:12,335 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5637463053067525, 'Total loss': 0.5637463053067525} | train loss {'Reaction outcome loss': 0.5100260390676695, 'Total loss': 0.5100260390676695}
2023-01-05 12:31:12,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:12,335 INFO:     Epoch: 6
2023-01-05 12:31:14,475 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5426691095034282, 'Total loss': 0.5426691095034282} | train loss {'Reaction outcome loss': 0.5003063423607182, 'Total loss': 0.5003063423607182}
2023-01-05 12:31:14,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:14,475 INFO:     Epoch: 7
2023-01-05 12:31:16,383 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.516778971751531, 'Total loss': 0.516778971751531} | train loss {'Reaction outcome loss': 0.4979509259282003, 'Total loss': 0.4979509259282003}
2023-01-05 12:31:16,383 INFO:     Found new best model at epoch 7
2023-01-05 12:31:16,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:16,385 INFO:     Epoch: 8
2023-01-05 12:31:18,500 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5208434601624806, 'Total loss': 0.5208434601624806} | train loss {'Reaction outcome loss': 0.4888623176190686, 'Total loss': 0.4888623176190686}
2023-01-05 12:31:18,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:18,501 INFO:     Epoch: 9
2023-01-05 12:31:20,631 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5399066627025604, 'Total loss': 0.5399066627025604} | train loss {'Reaction outcome loss': 0.4861115146826994, 'Total loss': 0.4861115146826994}
2023-01-05 12:31:20,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:20,631 INFO:     Epoch: 10
2023-01-05 12:31:22,737 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5149812042713166, 'Total loss': 0.5149812042713166} | train loss {'Reaction outcome loss': 0.47892816353768003, 'Total loss': 0.47892816353768003}
2023-01-05 12:31:22,737 INFO:     Found new best model at epoch 10
2023-01-05 12:31:22,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:22,739 INFO:     Epoch: 11
2023-01-05 12:31:24,854 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49641024072964984, 'Total loss': 0.49641024072964984} | train loss {'Reaction outcome loss': 0.4748975089665269, 'Total loss': 0.4748975089665269}
2023-01-05 12:31:24,854 INFO:     Found new best model at epoch 11
2023-01-05 12:31:24,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:24,855 INFO:     Epoch: 12
2023-01-05 12:31:26,986 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5068806389967601, 'Total loss': 0.5068806389967601} | train loss {'Reaction outcome loss': 0.46813325328250655, 'Total loss': 0.46813325328250655}
2023-01-05 12:31:26,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:26,987 INFO:     Epoch: 13
2023-01-05 12:31:29,134 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4724544882774353, 'Total loss': 0.4724544882774353} | train loss {'Reaction outcome loss': 0.4641359979046227, 'Total loss': 0.4641359979046227}
2023-01-05 12:31:29,134 INFO:     Found new best model at epoch 13
2023-01-05 12:31:29,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:29,135 INFO:     Epoch: 14
2023-01-05 12:31:31,265 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4852527856826782, 'Total loss': 0.4852527856826782} | train loss {'Reaction outcome loss': 0.45540757213351474, 'Total loss': 0.45540757213351474}
2023-01-05 12:31:31,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:31,265 INFO:     Epoch: 15
2023-01-05 12:31:33,411 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5354938824971517, 'Total loss': 0.5354938824971517} | train loss {'Reaction outcome loss': 0.45509734782785505, 'Total loss': 0.45509734782785505}
2023-01-05 12:31:33,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:33,412 INFO:     Epoch: 16
2023-01-05 12:31:35,555 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5242153644561768, 'Total loss': 0.5242153644561768} | train loss {'Reaction outcome loss': 0.45151860951497547, 'Total loss': 0.45151860951497547}
2023-01-05 12:31:35,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:35,556 INFO:     Epoch: 17
2023-01-05 12:31:37,705 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5064872115850448, 'Total loss': 0.5064872115850448} | train loss {'Reaction outcome loss': 0.44739725470982794, 'Total loss': 0.44739725470982794}
2023-01-05 12:31:37,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:37,705 INFO:     Epoch: 18
2023-01-05 12:31:39,844 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4738150229056676, 'Total loss': 0.4738150229056676} | train loss {'Reaction outcome loss': 0.44532244297851054, 'Total loss': 0.44532244297851054}
2023-01-05 12:31:39,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:39,845 INFO:     Epoch: 19
2023-01-05 12:31:41,992 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5026618540287018, 'Total loss': 0.5026618540287018} | train loss {'Reaction outcome loss': 0.43882221959503814, 'Total loss': 0.43882221959503814}
2023-01-05 12:31:41,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:41,992 INFO:     Epoch: 20
2023-01-05 12:31:44,132 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48942660093307494, 'Total loss': 0.48942660093307494} | train loss {'Reaction outcome loss': 0.44463200938657643, 'Total loss': 0.44463200938657643}
2023-01-05 12:31:44,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:44,133 INFO:     Epoch: 21
2023-01-05 12:31:46,268 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5158547719319662, 'Total loss': 0.5158547719319662} | train loss {'Reaction outcome loss': 0.4347517456295745, 'Total loss': 0.4347517456295745}
2023-01-05 12:31:46,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:46,268 INFO:     Epoch: 22
2023-01-05 12:31:48,415 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45937641014655434, 'Total loss': 0.45937641014655434} | train loss {'Reaction outcome loss': 0.43184373115371516, 'Total loss': 0.43184373115371516}
2023-01-05 12:31:48,415 INFO:     Found new best model at epoch 22
2023-01-05 12:31:48,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:48,416 INFO:     Epoch: 23
2023-01-05 12:31:50,588 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5043821394443512, 'Total loss': 0.5043821394443512} | train loss {'Reaction outcome loss': 0.4273586853843773, 'Total loss': 0.4273586853843773}
2023-01-05 12:31:50,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:50,588 INFO:     Epoch: 24
2023-01-05 12:31:52,779 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5402621736129125, 'Total loss': 0.5402621736129125} | train loss {'Reaction outcome loss': 0.42047662417167225, 'Total loss': 0.42047662417167225}
2023-01-05 12:31:52,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:52,780 INFO:     Epoch: 25
2023-01-05 12:31:54,903 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4915459948281447, 'Total loss': 0.4915459948281447} | train loss {'Reaction outcome loss': 0.4200862841852477, 'Total loss': 0.4200862841852477}
2023-01-05 12:31:54,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:54,904 INFO:     Epoch: 26
2023-01-05 12:31:57,043 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46763442854086557, 'Total loss': 0.46763442854086557} | train loss {'Reaction outcome loss': 0.4178723333286623, 'Total loss': 0.4178723333286623}
2023-01-05 12:31:57,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:57,043 INFO:     Epoch: 27
2023-01-05 12:31:59,199 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45319159626960753, 'Total loss': 0.45319159626960753} | train loss {'Reaction outcome loss': 0.41777210998799086, 'Total loss': 0.41777210998799086}
2023-01-05 12:31:59,200 INFO:     Found new best model at epoch 27
2023-01-05 12:31:59,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:31:59,201 INFO:     Epoch: 28
2023-01-05 12:32:01,327 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.451277486483256, 'Total loss': 0.451277486483256} | train loss {'Reaction outcome loss': 0.408157011239731, 'Total loss': 0.408157011239731}
2023-01-05 12:32:01,327 INFO:     Found new best model at epoch 28
2023-01-05 12:32:01,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:01,329 INFO:     Epoch: 29
2023-01-05 12:32:03,466 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4485034863154093, 'Total loss': 0.4485034863154093} | train loss {'Reaction outcome loss': 0.40561279937679917, 'Total loss': 0.40561279937679917}
2023-01-05 12:32:03,466 INFO:     Found new best model at epoch 29
2023-01-05 12:32:03,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:03,467 INFO:     Epoch: 30
2023-01-05 12:32:05,619 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.502364440759023, 'Total loss': 0.502364440759023} | train loss {'Reaction outcome loss': 0.40820165459630237, 'Total loss': 0.40820165459630237}
2023-01-05 12:32:05,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:05,619 INFO:     Epoch: 31
2023-01-05 12:32:07,746 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4519185761610667, 'Total loss': 0.4519185761610667} | train loss {'Reaction outcome loss': 0.3978664830766921, 'Total loss': 0.3978664830766921}
2023-01-05 12:32:07,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:07,747 INFO:     Epoch: 32
2023-01-05 12:32:09,881 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43727986911932626, 'Total loss': 0.43727986911932626} | train loss {'Reaction outcome loss': 0.3999991437275911, 'Total loss': 0.3999991437275911}
2023-01-05 12:32:09,882 INFO:     Found new best model at epoch 32
2023-01-05 12:32:09,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:09,883 INFO:     Epoch: 33
2023-01-05 12:32:12,033 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4493703116973241, 'Total loss': 0.4493703116973241} | train loss {'Reaction outcome loss': 0.3978453874038154, 'Total loss': 0.3978453874038154}
2023-01-05 12:32:12,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:12,033 INFO:     Epoch: 34
2023-01-05 12:32:14,159 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4454843590656916, 'Total loss': 0.4454843590656916} | train loss {'Reaction outcome loss': 0.38510604219243094, 'Total loss': 0.38510604219243094}
2023-01-05 12:32:14,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:14,159 INFO:     Epoch: 35
2023-01-05 12:32:16,302 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4982904503742854, 'Total loss': 0.4982904503742854} | train loss {'Reaction outcome loss': 0.3856402431576894, 'Total loss': 0.3856402431576894}
2023-01-05 12:32:16,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:16,303 INFO:     Epoch: 36
2023-01-05 12:32:18,437 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46571975747744243, 'Total loss': 0.46571975747744243} | train loss {'Reaction outcome loss': 0.38645878659623134, 'Total loss': 0.38645878659623134}
2023-01-05 12:32:18,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:18,437 INFO:     Epoch: 37
2023-01-05 12:32:20,583 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4939367135365804, 'Total loss': 0.4939367135365804} | train loss {'Reaction outcome loss': 0.37542137888524807, 'Total loss': 0.37542137888524807}
2023-01-05 12:32:20,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:20,583 INFO:     Epoch: 38
2023-01-05 12:32:22,719 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42802178859710693, 'Total loss': 0.42802178859710693} | train loss {'Reaction outcome loss': 0.37915794906031164, 'Total loss': 0.37915794906031164}
2023-01-05 12:32:22,719 INFO:     Found new best model at epoch 38
2023-01-05 12:32:22,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:22,720 INFO:     Epoch: 39
2023-01-05 12:32:24,854 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4462401469548543, 'Total loss': 0.4462401469548543} | train loss {'Reaction outcome loss': 0.37342898473418507, 'Total loss': 0.37342898473418507}
2023-01-05 12:32:24,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:24,854 INFO:     Epoch: 40
2023-01-05 12:32:27,000 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45582735935846963, 'Total loss': 0.45582735935846963} | train loss {'Reaction outcome loss': 0.37480458944376105, 'Total loss': 0.37480458944376105}
2023-01-05 12:32:27,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:27,000 INFO:     Epoch: 41
2023-01-05 12:32:29,131 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4503738214572271, 'Total loss': 0.4503738214572271} | train loss {'Reaction outcome loss': 0.365578371962718, 'Total loss': 0.365578371962718}
2023-01-05 12:32:29,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:29,132 INFO:     Epoch: 42
2023-01-05 12:32:31,264 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.446825443704923, 'Total loss': 0.446825443704923} | train loss {'Reaction outcome loss': 0.3641789675418741, 'Total loss': 0.3641789675418741}
2023-01-05 12:32:31,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:31,265 INFO:     Epoch: 43
2023-01-05 12:32:33,412 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4849928061167399, 'Total loss': 0.4849928061167399} | train loss {'Reaction outcome loss': 0.3588939410569043, 'Total loss': 0.3588939410569043}
2023-01-05 12:32:33,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:33,413 INFO:     Epoch: 44
2023-01-05 12:32:35,549 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48359365463256837, 'Total loss': 0.48359365463256837} | train loss {'Reaction outcome loss': 0.3526915161702026, 'Total loss': 0.3526915161702026}
2023-01-05 12:32:35,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:35,549 INFO:     Epoch: 45
2023-01-05 12:32:37,667 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5049387812614441, 'Total loss': 0.5049387812614441} | train loss {'Reaction outcome loss': 0.35287433776083466, 'Total loss': 0.35287433776083466}
2023-01-05 12:32:37,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:37,667 INFO:     Epoch: 46
2023-01-05 12:32:39,802 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4445132791996002, 'Total loss': 0.4445132791996002} | train loss {'Reaction outcome loss': 0.3478988338935419, 'Total loss': 0.3478988338935419}
2023-01-05 12:32:39,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:39,804 INFO:     Epoch: 47
2023-01-05 12:32:41,918 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4943466544151306, 'Total loss': 0.4943466544151306} | train loss {'Reaction outcome loss': 0.35321567779427526, 'Total loss': 0.35321567779427526}
2023-01-05 12:32:41,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:41,919 INFO:     Epoch: 48
2023-01-05 12:32:44,045 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4688442935546239, 'Total loss': 0.4688442935546239} | train loss {'Reaction outcome loss': 0.34880241938622675, 'Total loss': 0.34880241938622675}
2023-01-05 12:32:44,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:44,046 INFO:     Epoch: 49
2023-01-05 12:32:46,170 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4621935456991196, 'Total loss': 0.4621935456991196} | train loss {'Reaction outcome loss': 0.34265762523531473, 'Total loss': 0.34265762523531473}
2023-01-05 12:32:46,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:46,171 INFO:     Epoch: 50
2023-01-05 12:32:48,287 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4375964979330699, 'Total loss': 0.4375964979330699} | train loss {'Reaction outcome loss': 0.34356860773864706, 'Total loss': 0.34356860773864706}
2023-01-05 12:32:48,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:48,287 INFO:     Epoch: 51
2023-01-05 12:32:50,407 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45095495581626893, 'Total loss': 0.45095495581626893} | train loss {'Reaction outcome loss': 0.3431237838145112, 'Total loss': 0.3431237838145112}
2023-01-05 12:32:50,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:50,407 INFO:     Epoch: 52
2023-01-05 12:32:52,527 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4380062520503998, 'Total loss': 0.4380062520503998} | train loss {'Reaction outcome loss': 0.3401785290549162, 'Total loss': 0.3401785290549162}
2023-01-05 12:32:52,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:52,527 INFO:     Epoch: 53
2023-01-05 12:32:54,656 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41038207908471425, 'Total loss': 0.41038207908471425} | train loss {'Reaction outcome loss': 0.33794517859101736, 'Total loss': 0.33794517859101736}
2023-01-05 12:32:54,656 INFO:     Found new best model at epoch 53
2023-01-05 12:32:54,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:54,657 INFO:     Epoch: 54
2023-01-05 12:32:56,800 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.437742073337237, 'Total loss': 0.437742073337237} | train loss {'Reaction outcome loss': 0.33237447287213756, 'Total loss': 0.33237447287213756}
2023-01-05 12:32:56,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:56,801 INFO:     Epoch: 55
2023-01-05 12:32:58,958 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44023126661777495, 'Total loss': 0.44023126661777495} | train loss {'Reaction outcome loss': 0.3304724501672706, 'Total loss': 0.3304724501672706}
2023-01-05 12:32:58,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:32:58,959 INFO:     Epoch: 56
2023-01-05 12:33:01,082 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4941105266412099, 'Total loss': 0.4941105266412099} | train loss {'Reaction outcome loss': 0.32718659872773387, 'Total loss': 0.32718659872773387}
2023-01-05 12:33:01,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:01,083 INFO:     Epoch: 57
2023-01-05 12:33:03,200 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48316178818543754, 'Total loss': 0.48316178818543754} | train loss {'Reaction outcome loss': 0.3263308796550515, 'Total loss': 0.3263308796550515}
2023-01-05 12:33:03,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:03,201 INFO:     Epoch: 58
2023-01-05 12:33:05,334 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4311258329078555, 'Total loss': 0.4311258329078555} | train loss {'Reaction outcome loss': 0.3201533991472308, 'Total loss': 0.3201533991472308}
2023-01-05 12:33:05,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:05,334 INFO:     Epoch: 59
2023-01-05 12:33:07,483 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4454664756854375, 'Total loss': 0.4454664756854375} | train loss {'Reaction outcome loss': 0.31967405753546974, 'Total loss': 0.31967405753546974}
2023-01-05 12:33:07,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:07,483 INFO:     Epoch: 60
2023-01-05 12:33:09,626 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41831416040658953, 'Total loss': 0.41831416040658953} | train loss {'Reaction outcome loss': 0.3230456372111266, 'Total loss': 0.3230456372111266}
2023-01-05 12:33:09,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:09,627 INFO:     Epoch: 61
2023-01-05 12:33:11,757 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44791835149129233, 'Total loss': 0.44791835149129233} | train loss {'Reaction outcome loss': 0.3197985193743697, 'Total loss': 0.3197985193743697}
2023-01-05 12:33:11,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:11,757 INFO:     Epoch: 62
2023-01-05 12:33:13,904 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49044126669565835, 'Total loss': 0.49044126669565835} | train loss {'Reaction outcome loss': 0.3165263695250578, 'Total loss': 0.3165263695250578}
2023-01-05 12:33:13,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:13,904 INFO:     Epoch: 63
2023-01-05 12:33:16,036 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46135250528653465, 'Total loss': 0.46135250528653465} | train loss {'Reaction outcome loss': 0.3158935705454147, 'Total loss': 0.3158935705454147}
2023-01-05 12:33:16,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:16,037 INFO:     Epoch: 64
2023-01-05 12:33:18,171 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4261891762415568, 'Total loss': 0.4261891762415568} | train loss {'Reaction outcome loss': 0.30904719214267834, 'Total loss': 0.30904719214267834}
2023-01-05 12:33:18,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:18,171 INFO:     Epoch: 65
2023-01-05 12:33:20,314 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.492122878630956, 'Total loss': 0.492122878630956} | train loss {'Reaction outcome loss': 0.30711220599353534, 'Total loss': 0.30711220599353534}
2023-01-05 12:33:20,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:20,315 INFO:     Epoch: 66
2023-01-05 12:33:22,443 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44043197979529697, 'Total loss': 0.44043197979529697} | train loss {'Reaction outcome loss': 0.305621092348631, 'Total loss': 0.305621092348631}
2023-01-05 12:33:22,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:22,444 INFO:     Epoch: 67
2023-01-05 12:33:24,577 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49926149944464365, 'Total loss': 0.49926149944464365} | train loss {'Reaction outcome loss': 0.30768038680247717, 'Total loss': 0.30768038680247717}
2023-01-05 12:33:24,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:24,577 INFO:     Epoch: 68
2023-01-05 12:33:26,707 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42497290670871735, 'Total loss': 0.42497290670871735} | train loss {'Reaction outcome loss': 0.30769288417542995, 'Total loss': 0.30769288417542995}
2023-01-05 12:33:26,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:26,707 INFO:     Epoch: 69
2023-01-05 12:33:28,821 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4723645123342673, 'Total loss': 0.4723645123342673} | train loss {'Reaction outcome loss': 0.309259396225104, 'Total loss': 0.309259396225104}
2023-01-05 12:33:28,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:28,822 INFO:     Epoch: 70
2023-01-05 12:33:30,952 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45225557188193005, 'Total loss': 0.45225557188193005} | train loss {'Reaction outcome loss': 0.30538871735884254, 'Total loss': 0.30538871735884254}
2023-01-05 12:33:30,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:30,952 INFO:     Epoch: 71
2023-01-05 12:33:33,077 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46091747283935547, 'Total loss': 0.46091747283935547} | train loss {'Reaction outcome loss': 0.2986235525390319, 'Total loss': 0.2986235525390319}
2023-01-05 12:33:33,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:33,078 INFO:     Epoch: 72
2023-01-05 12:33:35,196 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43784563144048055, 'Total loss': 0.43784563144048055} | train loss {'Reaction outcome loss': 0.2965455091252538, 'Total loss': 0.2965455091252538}
2023-01-05 12:33:35,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:35,197 INFO:     Epoch: 73
2023-01-05 12:33:37,311 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4567873924970627, 'Total loss': 0.4567873924970627} | train loss {'Reaction outcome loss': 0.29628086638571594, 'Total loss': 0.29628086638571594}
2023-01-05 12:33:37,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:37,311 INFO:     Epoch: 74
2023-01-05 12:33:39,444 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4526984214782715, 'Total loss': 0.4526984214782715} | train loss {'Reaction outcome loss': 0.2909964052650981, 'Total loss': 0.2909964052650981}
2023-01-05 12:33:39,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:39,444 INFO:     Epoch: 75
2023-01-05 12:33:41,540 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4539509922266006, 'Total loss': 0.4539509922266006} | train loss {'Reaction outcome loss': 0.2922345656090557, 'Total loss': 0.2922345656090557}
2023-01-05 12:33:41,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:41,540 INFO:     Epoch: 76
2023-01-05 12:33:43,665 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4873467485109965, 'Total loss': 0.4873467485109965} | train loss {'Reaction outcome loss': 0.29091518006641487, 'Total loss': 0.29091518006641487}
2023-01-05 12:33:43,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:43,665 INFO:     Epoch: 77
2023-01-05 12:33:45,772 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42781484325726826, 'Total loss': 0.42781484325726826} | train loss {'Reaction outcome loss': 0.29200513568806474, 'Total loss': 0.29200513568806474}
2023-01-05 12:33:45,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:45,773 INFO:     Epoch: 78
2023-01-05 12:33:47,909 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4501057167847951, 'Total loss': 0.4501057167847951} | train loss {'Reaction outcome loss': 0.2902369355968444, 'Total loss': 0.2902369355968444}
2023-01-05 12:33:47,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:47,910 INFO:     Epoch: 79
2023-01-05 12:33:50,047 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46560487647851306, 'Total loss': 0.46560487647851306} | train loss {'Reaction outcome loss': 0.2848396497431496, 'Total loss': 0.2848396497431496}
2023-01-05 12:33:50,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:50,048 INFO:     Epoch: 80
2023-01-05 12:33:52,168 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4884328246116638, 'Total loss': 0.4884328246116638} | train loss {'Reaction outcome loss': 0.28889054041424583, 'Total loss': 0.28889054041424583}
2023-01-05 12:33:52,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:52,169 INFO:     Epoch: 81
2023-01-05 12:33:54,317 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4461681465307871, 'Total loss': 0.4461681465307871} | train loss {'Reaction outcome loss': 0.28711249386527443, 'Total loss': 0.28711249386527443}
2023-01-05 12:33:54,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:54,318 INFO:     Epoch: 82
2023-01-05 12:33:56,445 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4547413547833761, 'Total loss': 0.4547413547833761} | train loss {'Reaction outcome loss': 0.2798661057840744, 'Total loss': 0.2798661057840744}
2023-01-05 12:33:56,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:56,446 INFO:     Epoch: 83
2023-01-05 12:33:58,556 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4485026031732559, 'Total loss': 0.4485026031732559} | train loss {'Reaction outcome loss': 0.28374363976870953, 'Total loss': 0.28374363976870953}
2023-01-05 12:33:58,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:33:58,556 INFO:     Epoch: 84
2023-01-05 12:34:00,683 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41891143321990965, 'Total loss': 0.41891143321990965} | train loss {'Reaction outcome loss': 0.27961171001910723, 'Total loss': 0.27961171001910723}
2023-01-05 12:34:00,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:00,684 INFO:     Epoch: 85
2023-01-05 12:34:02,834 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5210003773371379, 'Total loss': 0.5210003773371379} | train loss {'Reaction outcome loss': 0.27456834917798695, 'Total loss': 0.27456834917798695}
2023-01-05 12:34:02,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:02,834 INFO:     Epoch: 86
2023-01-05 12:34:04,952 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.424729826549689, 'Total loss': 0.424729826549689} | train loss {'Reaction outcome loss': 0.2793062336990314, 'Total loss': 0.2793062336990314}
2023-01-05 12:34:04,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:04,953 INFO:     Epoch: 87
2023-01-05 12:34:07,081 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4253437027335167, 'Total loss': 0.4253437027335167} | train loss {'Reaction outcome loss': 0.2805769220681868, 'Total loss': 0.2805769220681868}
2023-01-05 12:34:07,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:07,081 INFO:     Epoch: 88
2023-01-05 12:34:09,205 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45754412511984505, 'Total loss': 0.45754412511984505} | train loss {'Reaction outcome loss': 0.2729345618771231, 'Total loss': 0.2729345618771231}
2023-01-05 12:34:09,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:09,205 INFO:     Epoch: 89
2023-01-05 12:34:11,335 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4694934924443563, 'Total loss': 0.4694934924443563} | train loss {'Reaction outcome loss': 0.2664884320181894, 'Total loss': 0.2664884320181894}
2023-01-05 12:34:11,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:11,335 INFO:     Epoch: 90
2023-01-05 12:34:13,481 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4715572734673818, 'Total loss': 0.4715572734673818} | train loss {'Reaction outcome loss': 0.2714415504373747, 'Total loss': 0.2714415504373747}
2023-01-05 12:34:13,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:13,481 INFO:     Epoch: 91
2023-01-05 12:34:15,595 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5069217324256897, 'Total loss': 0.5069217324256897} | train loss {'Reaction outcome loss': 0.27000511976859337, 'Total loss': 0.27000511976859337}
2023-01-05 12:34:15,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:15,596 INFO:     Epoch: 92
2023-01-05 12:34:17,736 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4416066787826518, 'Total loss': 0.4416066787826518} | train loss {'Reaction outcome loss': 0.2665681605986783, 'Total loss': 0.2665681605986783}
2023-01-05 12:34:17,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:17,736 INFO:     Epoch: 93
2023-01-05 12:34:19,873 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5618901312351227, 'Total loss': 0.5618901312351227} | train loss {'Reaction outcome loss': 0.26689845099495346, 'Total loss': 0.26689845099495346}
2023-01-05 12:34:19,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:19,873 INFO:     Epoch: 94
2023-01-05 12:34:22,002 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43739186227321625, 'Total loss': 0.43739186227321625} | train loss {'Reaction outcome loss': 0.2655617915286349, 'Total loss': 0.2655617915286349}
2023-01-05 12:34:22,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:22,003 INFO:     Epoch: 95
2023-01-05 12:34:24,124 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47450894912083946, 'Total loss': 0.47450894912083946} | train loss {'Reaction outcome loss': 0.26129888097078596, 'Total loss': 0.26129888097078596}
2023-01-05 12:34:24,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:24,124 INFO:     Epoch: 96
2023-01-05 12:34:26,253 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4259261498848597, 'Total loss': 0.4259261498848597} | train loss {'Reaction outcome loss': 0.26395745160284956, 'Total loss': 0.26395745160284956}
2023-01-05 12:34:26,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:26,254 INFO:     Epoch: 97
2023-01-05 12:34:28,395 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45042083859443666, 'Total loss': 0.45042083859443666} | train loss {'Reaction outcome loss': 0.2650585686066274, 'Total loss': 0.2650585686066274}
2023-01-05 12:34:28,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:28,396 INFO:     Epoch: 98
2023-01-05 12:34:30,513 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4360023925701777, 'Total loss': 0.4360023925701777} | train loss {'Reaction outcome loss': 0.2600681481683606, 'Total loss': 0.2600681481683606}
2023-01-05 12:34:30,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:30,514 INFO:     Epoch: 99
2023-01-05 12:34:32,618 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46140280564626057, 'Total loss': 0.46140280564626057} | train loss {'Reaction outcome loss': 0.25627379935935857, 'Total loss': 0.25627379935935857}
2023-01-05 12:34:32,618 INFO:     Best model found after epoch 54 of 100.
2023-01-05 12:34:32,618 INFO:   Done with stage: TRAINING
2023-01-05 12:34:32,618 INFO:   Starting stage: EVALUATION
2023-01-05 12:34:32,771 INFO:   Done with stage: EVALUATION
2023-01-05 12:34:32,771 INFO:   Leaving out SEQ value Fold_2
2023-01-05 12:34:32,784 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 12:34:32,784 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:34:33,429 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:34:33,430 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:34:33,499 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:34:33,499 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:34:33,499 INFO:     No hyperparam tuning for this model
2023-01-05 12:34:33,499 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:34:33,499 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:34:33,500 INFO:     None feature selector for col prot
2023-01-05 12:34:33,500 INFO:     None feature selector for col prot
2023-01-05 12:34:33,500 INFO:     None feature selector for col prot
2023-01-05 12:34:33,500 INFO:     None feature selector for col chem
2023-01-05 12:34:33,500 INFO:     None feature selector for col chem
2023-01-05 12:34:33,501 INFO:     None feature selector for col chem
2023-01-05 12:34:33,501 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:34:33,501 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:34:33,502 INFO:     Number of params in model 72901
2023-01-05 12:34:33,505 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:34:33,505 INFO:   Starting stage: TRAINING
2023-01-05 12:34:33,566 INFO:     Val loss before train {'Reaction outcome loss': 0.9585106174151102, 'Total loss': 0.9585106174151102}
2023-01-05 12:34:33,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:33,566 INFO:     Epoch: 0
2023-01-05 12:34:35,723 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8007988055547078, 'Total loss': 0.8007988055547078} | train loss {'Reaction outcome loss': 0.9397154804998941, 'Total loss': 0.9397154804998941}
2023-01-05 12:34:35,723 INFO:     Found new best model at epoch 0
2023-01-05 12:34:35,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:35,725 INFO:     Epoch: 1
2023-01-05 12:34:37,868 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5870941082636515, 'Total loss': 0.5870941082636515} | train loss {'Reaction outcome loss': 0.722655819062769, 'Total loss': 0.722655819062769}
2023-01-05 12:34:37,869 INFO:     Found new best model at epoch 1
2023-01-05 12:34:37,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:37,870 INFO:     Epoch: 2
2023-01-05 12:34:40,018 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5009521822134654, 'Total loss': 0.5009521822134654} | train loss {'Reaction outcome loss': 0.5796249043332399, 'Total loss': 0.5796249043332399}
2023-01-05 12:34:40,018 INFO:     Found new best model at epoch 2
2023-01-05 12:34:40,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:40,019 INFO:     Epoch: 3
2023-01-05 12:34:42,176 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5111818671226501, 'Total loss': 0.5111818671226501} | train loss {'Reaction outcome loss': 0.5353395024681613, 'Total loss': 0.5353395024681613}
2023-01-05 12:34:42,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:42,177 INFO:     Epoch: 4
2023-01-05 12:34:44,310 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4829748143752416, 'Total loss': 0.4829748143752416} | train loss {'Reaction outcome loss': 0.5159308245255999, 'Total loss': 0.5159308245255999}
2023-01-05 12:34:44,310 INFO:     Found new best model at epoch 4
2023-01-05 12:34:44,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:44,311 INFO:     Epoch: 5
2023-01-05 12:34:46,465 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4747305154800415, 'Total loss': 0.4747305154800415} | train loss {'Reaction outcome loss': 0.5061245004843621, 'Total loss': 0.5061245004843621}
2023-01-05 12:34:46,465 INFO:     Found new best model at epoch 5
2023-01-05 12:34:46,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:46,466 INFO:     Epoch: 6
2023-01-05 12:34:48,641 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4859102467695872, 'Total loss': 0.4859102467695872} | train loss {'Reaction outcome loss': 0.4948541135901082, 'Total loss': 0.4948541135901082}
2023-01-05 12:34:48,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:48,641 INFO:     Epoch: 7
2023-01-05 12:34:50,783 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.434915816783905, 'Total loss': 0.434915816783905} | train loss {'Reaction outcome loss': 0.4905840768104922, 'Total loss': 0.4905840768104922}
2023-01-05 12:34:50,783 INFO:     Found new best model at epoch 7
2023-01-05 12:34:50,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:50,785 INFO:     Epoch: 8
2023-01-05 12:34:52,944 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48645211656888326, 'Total loss': 0.48645211656888326} | train loss {'Reaction outcome loss': 0.4829150315945166, 'Total loss': 0.4829150315945166}
2023-01-05 12:34:52,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:52,944 INFO:     Epoch: 9
2023-01-05 12:34:55,044 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49055398305257164, 'Total loss': 0.49055398305257164} | train loss {'Reaction outcome loss': 0.477949845747356, 'Total loss': 0.477949845747356}
2023-01-05 12:34:55,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:55,044 INFO:     Epoch: 10
2023-01-05 12:34:57,190 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5018594890832901, 'Total loss': 0.5018594890832901} | train loss {'Reaction outcome loss': 0.4697853667783911, 'Total loss': 0.4697853667783911}
2023-01-05 12:34:57,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:57,191 INFO:     Epoch: 11
2023-01-05 12:34:59,319 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4466251949469248, 'Total loss': 0.4466251949469248} | train loss {'Reaction outcome loss': 0.469476713588203, 'Total loss': 0.469476713588203}
2023-01-05 12:34:59,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:34:59,320 INFO:     Epoch: 12
2023-01-05 12:35:01,448 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4305438240369161, 'Total loss': 0.4305438240369161} | train loss {'Reaction outcome loss': 0.4631312106375712, 'Total loss': 0.4631312106375712}
2023-01-05 12:35:01,448 INFO:     Found new best model at epoch 12
2023-01-05 12:35:01,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:01,450 INFO:     Epoch: 13
2023-01-05 12:35:03,595 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47059571544329326, 'Total loss': 0.47059571544329326} | train loss {'Reaction outcome loss': 0.4568792885019831, 'Total loss': 0.4568792885019831}
2023-01-05 12:35:03,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:03,596 INFO:     Epoch: 14
2023-01-05 12:35:05,759 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47233857909838356, 'Total loss': 0.47233857909838356} | train loss {'Reaction outcome loss': 0.45066845291939966, 'Total loss': 0.45066845291939966}
2023-01-05 12:35:05,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:05,760 INFO:     Epoch: 15
2023-01-05 12:35:07,999 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43847473661104835, 'Total loss': 0.43847473661104835} | train loss {'Reaction outcome loss': 0.45163441688692485, 'Total loss': 0.45163441688692485}
2023-01-05 12:35:08,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:08,000 INFO:     Epoch: 16
2023-01-05 12:35:10,258 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41667122741540275, 'Total loss': 0.41667122741540275} | train loss {'Reaction outcome loss': 0.44585662278054405, 'Total loss': 0.44585662278054405}
2023-01-05 12:35:10,258 INFO:     Found new best model at epoch 16
2023-01-05 12:35:10,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:10,259 INFO:     Epoch: 17
2023-01-05 12:35:12,512 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.435675906141599, 'Total loss': 0.435675906141599} | train loss {'Reaction outcome loss': 0.4364047448021652, 'Total loss': 0.4364047448021652}
2023-01-05 12:35:12,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:12,512 INFO:     Epoch: 18
2023-01-05 12:35:14,752 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4435891499121984, 'Total loss': 0.4435891499121984} | train loss {'Reaction outcome loss': 0.4346946296791961, 'Total loss': 0.4346946296791961}
2023-01-05 12:35:14,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:14,752 INFO:     Epoch: 19
2023-01-05 12:35:17,021 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4648520588874817, 'Total loss': 0.4648520588874817} | train loss {'Reaction outcome loss': 0.42973382825398965, 'Total loss': 0.42973382825398965}
2023-01-05 12:35:17,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:17,022 INFO:     Epoch: 20
2023-01-05 12:35:19,274 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4417829692363739, 'Total loss': 0.4417829692363739} | train loss {'Reaction outcome loss': 0.4255785934463905, 'Total loss': 0.4255785934463905}
2023-01-05 12:35:19,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:19,274 INFO:     Epoch: 21
2023-01-05 12:35:21,539 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42984695235888165, 'Total loss': 0.42984695235888165} | train loss {'Reaction outcome loss': 0.42411260676645013, 'Total loss': 0.42411260676645013}
2023-01-05 12:35:21,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:21,540 INFO:     Epoch: 22
2023-01-05 12:35:23,615 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4563702940940857, 'Total loss': 0.4563702940940857} | train loss {'Reaction outcome loss': 0.4175192767033612, 'Total loss': 0.4175192767033612}
2023-01-05 12:35:23,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:23,615 INFO:     Epoch: 23
2023-01-05 12:35:25,885 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4207961360613505, 'Total loss': 0.4207961360613505} | train loss {'Reaction outcome loss': 0.4137746842346922, 'Total loss': 0.4137746842346922}
2023-01-05 12:35:25,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:25,885 INFO:     Epoch: 24
2023-01-05 12:35:28,064 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4320375164349874, 'Total loss': 0.4320375164349874} | train loss {'Reaction outcome loss': 0.40822874395734204, 'Total loss': 0.40822874395734204}
2023-01-05 12:35:28,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:28,065 INFO:     Epoch: 25
2023-01-05 12:35:30,256 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42178827375173567, 'Total loss': 0.42178827375173567} | train loss {'Reaction outcome loss': 0.4070369399213878, 'Total loss': 0.4070369399213878}
2023-01-05 12:35:30,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:30,256 INFO:     Epoch: 26
2023-01-05 12:35:32,453 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42785314420859016, 'Total loss': 0.42785314420859016} | train loss {'Reaction outcome loss': 0.4033186019663393, 'Total loss': 0.4033186019663393}
2023-01-05 12:35:32,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:32,453 INFO:     Epoch: 27
2023-01-05 12:35:34,595 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4349581430355708, 'Total loss': 0.4349581430355708} | train loss {'Reaction outcome loss': 0.40666838338340283, 'Total loss': 0.40666838338340283}
2023-01-05 12:35:34,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:34,597 INFO:     Epoch: 28
2023-01-05 12:35:36,754 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4301309029261271, 'Total loss': 0.4301309029261271} | train loss {'Reaction outcome loss': 0.3960566801855164, 'Total loss': 0.3960566801855164}
2023-01-05 12:35:36,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:36,754 INFO:     Epoch: 29
2023-01-05 12:35:38,902 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40305553476015726, 'Total loss': 0.40305553476015726} | train loss {'Reaction outcome loss': 0.3934965877909295, 'Total loss': 0.3934965877909295}
2023-01-05 12:35:38,902 INFO:     Found new best model at epoch 29
2023-01-05 12:35:38,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:38,903 INFO:     Epoch: 30
2023-01-05 12:35:41,053 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41113408307234445, 'Total loss': 0.41113408307234445} | train loss {'Reaction outcome loss': 0.3932257798520753, 'Total loss': 0.3932257798520753}
2023-01-05 12:35:41,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:41,054 INFO:     Epoch: 31
2023-01-05 12:35:43,229 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41298451920350393, 'Total loss': 0.41298451920350393} | train loss {'Reaction outcome loss': 0.3863714871669773, 'Total loss': 0.3863714871669773}
2023-01-05 12:35:43,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:43,230 INFO:     Epoch: 32
2023-01-05 12:35:45,441 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41462542116642, 'Total loss': 0.41462542116642} | train loss {'Reaction outcome loss': 0.38335078807860395, 'Total loss': 0.38335078807860395}
2023-01-05 12:35:45,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:45,442 INFO:     Epoch: 33
2023-01-05 12:35:47,631 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4133596102396647, 'Total loss': 0.4133596102396647} | train loss {'Reaction outcome loss': 0.37359610232558566, 'Total loss': 0.37359610232558566}
2023-01-05 12:35:47,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:47,631 INFO:     Epoch: 34
2023-01-05 12:35:49,842 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4182736615339915, 'Total loss': 0.4182736615339915} | train loss {'Reaction outcome loss': 0.3803512752056122, 'Total loss': 0.3803512752056122}
2023-01-05 12:35:49,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:49,842 INFO:     Epoch: 35
2023-01-05 12:35:52,000 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4202220926682154, 'Total loss': 0.4202220926682154} | train loss {'Reaction outcome loss': 0.3776613673752677, 'Total loss': 0.3776613673752677}
2023-01-05 12:35:52,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:52,001 INFO:     Epoch: 36
2023-01-05 12:35:54,137 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3985238134860992, 'Total loss': 0.3985238134860992} | train loss {'Reaction outcome loss': 0.37694550147891914, 'Total loss': 0.37694550147891914}
2023-01-05 12:35:54,137 INFO:     Found new best model at epoch 36
2023-01-05 12:35:54,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:54,139 INFO:     Epoch: 37
2023-01-05 12:35:56,292 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3929010291894277, 'Total loss': 0.3929010291894277} | train loss {'Reaction outcome loss': 0.361585562871973, 'Total loss': 0.361585562871973}
2023-01-05 12:35:56,292 INFO:     Found new best model at epoch 37
2023-01-05 12:35:56,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:56,293 INFO:     Epoch: 38
2023-01-05 12:35:58,450 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41128246585528055, 'Total loss': 0.41128246585528055} | train loss {'Reaction outcome loss': 0.35956898119545333, 'Total loss': 0.35956898119545333}
2023-01-05 12:35:58,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:35:58,450 INFO:     Epoch: 39
2023-01-05 12:36:00,616 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3857361127932866, 'Total loss': 0.3857361127932866} | train loss {'Reaction outcome loss': 0.3568864305415293, 'Total loss': 0.3568864305415293}
2023-01-05 12:36:00,616 INFO:     Found new best model at epoch 39
2023-01-05 12:36:00,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:00,617 INFO:     Epoch: 40
2023-01-05 12:36:02,774 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39755344291528066, 'Total loss': 0.39755344291528066} | train loss {'Reaction outcome loss': 0.351494819877574, 'Total loss': 0.351494819877574}
2023-01-05 12:36:02,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:02,774 INFO:     Epoch: 41
2023-01-05 12:36:04,934 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4463444878657659, 'Total loss': 0.4463444878657659} | train loss {'Reaction outcome loss': 0.35417893382102034, 'Total loss': 0.35417893382102034}
2023-01-05 12:36:04,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:04,935 INFO:     Epoch: 42
2023-01-05 12:36:07,090 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4153708597024282, 'Total loss': 0.4153708597024282} | train loss {'Reaction outcome loss': 0.3521095842231799, 'Total loss': 0.3521095842231799}
2023-01-05 12:36:07,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:07,091 INFO:     Epoch: 43
2023-01-05 12:36:09,259 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40713223616282146, 'Total loss': 0.40713223616282146} | train loss {'Reaction outcome loss': 0.3427055590398555, 'Total loss': 0.3427055590398555}
2023-01-05 12:36:09,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:09,259 INFO:     Epoch: 44
2023-01-05 12:36:11,422 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3883374070127805, 'Total loss': 0.3883374070127805} | train loss {'Reaction outcome loss': 0.3394734160090885, 'Total loss': 0.3394734160090885}
2023-01-05 12:36:11,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:11,423 INFO:     Epoch: 45
2023-01-05 12:36:13,589 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40756071309248604, 'Total loss': 0.40756071309248604} | train loss {'Reaction outcome loss': 0.3382651262447564, 'Total loss': 0.3382651262447564}
2023-01-05 12:36:13,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:13,589 INFO:     Epoch: 46
2023-01-05 12:36:15,745 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44308960139751435, 'Total loss': 0.44308960139751435} | train loss {'Reaction outcome loss': 0.33379321303354564, 'Total loss': 0.33379321303354564}
2023-01-05 12:36:15,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:15,745 INFO:     Epoch: 47
2023-01-05 12:36:17,895 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3907682776451111, 'Total loss': 0.3907682776451111} | train loss {'Reaction outcome loss': 0.3376642088167859, 'Total loss': 0.3376642088167859}
2023-01-05 12:36:17,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:17,895 INFO:     Epoch: 48
2023-01-05 12:36:20,060 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4019888629515966, 'Total loss': 0.4019888629515966} | train loss {'Reaction outcome loss': 0.3269680375573191, 'Total loss': 0.3269680375573191}
2023-01-05 12:36:20,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:20,061 INFO:     Epoch: 49
2023-01-05 12:36:22,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4016692489385605, 'Total loss': 0.4016692489385605} | train loss {'Reaction outcome loss': 0.3240146725608485, 'Total loss': 0.3240146725608485}
2023-01-05 12:36:22,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:22,233 INFO:     Epoch: 50
2023-01-05 12:36:24,403 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38407115638256073, 'Total loss': 0.38407115638256073} | train loss {'Reaction outcome loss': 0.3237075455976229, 'Total loss': 0.3237075455976229}
2023-01-05 12:36:24,404 INFO:     Found new best model at epoch 50
2023-01-05 12:36:24,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:24,405 INFO:     Epoch: 51
2023-01-05 12:36:26,560 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38850795129934945, 'Total loss': 0.38850795129934945} | train loss {'Reaction outcome loss': 0.3173561710184508, 'Total loss': 0.3173561710184508}
2023-01-05 12:36:26,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:26,561 INFO:     Epoch: 52
2023-01-05 12:36:28,705 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42526527047157286, 'Total loss': 0.42526527047157286} | train loss {'Reaction outcome loss': 0.31647413536688707, 'Total loss': 0.31647413536688707}
2023-01-05 12:36:28,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:28,705 INFO:     Epoch: 53
2023-01-05 12:36:30,876 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3847141683101654, 'Total loss': 0.3847141683101654} | train loss {'Reaction outcome loss': 0.3153620838411968, 'Total loss': 0.3153620838411968}
2023-01-05 12:36:30,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:30,877 INFO:     Epoch: 54
2023-01-05 12:36:33,048 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4388612945874532, 'Total loss': 0.4388612945874532} | train loss {'Reaction outcome loss': 0.3070392619519338, 'Total loss': 0.3070392619519338}
2023-01-05 12:36:33,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:33,049 INFO:     Epoch: 55
2023-01-05 12:36:35,208 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4036137153704961, 'Total loss': 0.4036137153704961} | train loss {'Reaction outcome loss': 0.31111720113260466, 'Total loss': 0.31111720113260466}
2023-01-05 12:36:35,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:35,208 INFO:     Epoch: 56
2023-01-05 12:36:37,366 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3773158997297287, 'Total loss': 0.3773158997297287} | train loss {'Reaction outcome loss': 0.30864054860587975, 'Total loss': 0.30864054860587975}
2023-01-05 12:36:37,367 INFO:     Found new best model at epoch 56
2023-01-05 12:36:37,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:37,368 INFO:     Epoch: 57
2023-01-05 12:36:39,529 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3929793824752172, 'Total loss': 0.3929793824752172} | train loss {'Reaction outcome loss': 0.30935737340418745, 'Total loss': 0.30935737340418745}
2023-01-05 12:36:39,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:39,530 INFO:     Epoch: 58
2023-01-05 12:36:41,707 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38271559675534567, 'Total loss': 0.38271559675534567} | train loss {'Reaction outcome loss': 0.29991303174926415, 'Total loss': 0.29991303174926415}
2023-01-05 12:36:41,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:41,707 INFO:     Epoch: 59
2023-01-05 12:36:43,876 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4388572484254837, 'Total loss': 0.4388572484254837} | train loss {'Reaction outcome loss': 0.29836210541862207, 'Total loss': 0.29836210541862207}
2023-01-05 12:36:43,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:43,876 INFO:     Epoch: 60
2023-01-05 12:36:46,030 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4069463421901067, 'Total loss': 0.4069463421901067} | train loss {'Reaction outcome loss': 0.301419952190923, 'Total loss': 0.301419952190923}
2023-01-05 12:36:46,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:46,031 INFO:     Epoch: 61
2023-01-05 12:36:48,187 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4350514054298401, 'Total loss': 0.4350514054298401} | train loss {'Reaction outcome loss': 0.2989564138960882, 'Total loss': 0.2989564138960882}
2023-01-05 12:36:48,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:48,187 INFO:     Epoch: 62
2023-01-05 12:36:50,360 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38897754351298014, 'Total loss': 0.38897754351298014} | train loss {'Reaction outcome loss': 0.30056258826686516, 'Total loss': 0.30056258826686516}
2023-01-05 12:36:50,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:50,360 INFO:     Epoch: 63
2023-01-05 12:36:52,507 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3831481320162614, 'Total loss': 0.3831481320162614} | train loss {'Reaction outcome loss': 0.2914533789548343, 'Total loss': 0.2914533789548343}
2023-01-05 12:36:52,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:52,507 INFO:     Epoch: 64
2023-01-05 12:36:54,670 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39120122889677683, 'Total loss': 0.39120122889677683} | train loss {'Reaction outcome loss': 0.29232704684301447, 'Total loss': 0.29232704684301447}
2023-01-05 12:36:54,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:54,670 INFO:     Epoch: 65
2023-01-05 12:36:56,844 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40349163909753166, 'Total loss': 0.40349163909753166} | train loss {'Reaction outcome loss': 0.2871474241090082, 'Total loss': 0.2871474241090082}
2023-01-05 12:36:56,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:56,845 INFO:     Epoch: 66
2023-01-05 12:36:59,017 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3740903039773305, 'Total loss': 0.3740903039773305} | train loss {'Reaction outcome loss': 0.2941274435742058, 'Total loss': 0.2941274435742058}
2023-01-05 12:36:59,018 INFO:     Found new best model at epoch 66
2023-01-05 12:36:59,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:36:59,019 INFO:     Epoch: 67
2023-01-05 12:37:01,172 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.393107271194458, 'Total loss': 0.393107271194458} | train loss {'Reaction outcome loss': 0.28512555373030424, 'Total loss': 0.28512555373030424}
2023-01-05 12:37:01,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:01,172 INFO:     Epoch: 68
2023-01-05 12:37:03,176 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3920051584641139, 'Total loss': 0.3920051584641139} | train loss {'Reaction outcome loss': 0.28402778572899146, 'Total loss': 0.28402778572899146}
2023-01-05 12:37:03,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:03,176 INFO:     Epoch: 69
2023-01-05 12:37:04,943 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3574500307440758, 'Total loss': 0.3574500307440758} | train loss {'Reaction outcome loss': 0.2870593088522662, 'Total loss': 0.2870593088522662}
2023-01-05 12:37:04,943 INFO:     Found new best model at epoch 69
2023-01-05 12:37:04,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:04,944 INFO:     Epoch: 70
2023-01-05 12:37:06,720 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42149026195208233, 'Total loss': 0.42149026195208233} | train loss {'Reaction outcome loss': 0.28482018155555655, 'Total loss': 0.28482018155555655}
2023-01-05 12:37:06,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:06,720 INFO:     Epoch: 71
2023-01-05 12:37:08,877 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3750450100128849, 'Total loss': 0.3750450100128849} | train loss {'Reaction outcome loss': 0.2755345511284188, 'Total loss': 0.2755345511284188}
2023-01-05 12:37:08,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:08,878 INFO:     Epoch: 72
2023-01-05 12:37:11,034 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3805279642343521, 'Total loss': 0.3805279642343521} | train loss {'Reaction outcome loss': 0.27116299347177036, 'Total loss': 0.27116299347177036}
2023-01-05 12:37:11,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:11,034 INFO:     Epoch: 73
2023-01-05 12:37:13,204 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.388276078303655, 'Total loss': 0.388276078303655} | train loss {'Reaction outcome loss': 0.2750716423139955, 'Total loss': 0.2750716423139955}
2023-01-05 12:37:13,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:13,204 INFO:     Epoch: 74
2023-01-05 12:37:15,363 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38360233306884767, 'Total loss': 0.38360233306884767} | train loss {'Reaction outcome loss': 0.2730621667510837, 'Total loss': 0.2730621667510837}
2023-01-05 12:37:15,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:15,364 INFO:     Epoch: 75
2023-01-05 12:37:17,534 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3928348413358132, 'Total loss': 0.3928348413358132} | train loss {'Reaction outcome loss': 0.2802227658430373, 'Total loss': 0.2802227658430373}
2023-01-05 12:37:17,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:17,535 INFO:     Epoch: 76
2023-01-05 12:37:19,701 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38581433494885764, 'Total loss': 0.38581433494885764} | train loss {'Reaction outcome loss': 0.2755397148974185, 'Total loss': 0.2755397148974185}
2023-01-05 12:37:19,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:19,701 INFO:     Epoch: 77
2023-01-05 12:37:21,869 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3826599688579639, 'Total loss': 0.3826599688579639} | train loss {'Reaction outcome loss': 0.2624206460033455, 'Total loss': 0.2624206460033455}
2023-01-05 12:37:21,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:21,870 INFO:     Epoch: 78
2023-01-05 12:37:24,020 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4074391941229502, 'Total loss': 0.4074391941229502} | train loss {'Reaction outcome loss': 0.26763353680335256, 'Total loss': 0.26763353680335256}
2023-01-05 12:37:24,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:24,020 INFO:     Epoch: 79
2023-01-05 12:37:26,183 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4128348236282667, 'Total loss': 0.4128348236282667} | train loss {'Reaction outcome loss': 0.26634917249155304, 'Total loss': 0.26634917249155304}
2023-01-05 12:37:26,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:26,183 INFO:     Epoch: 80
2023-01-05 12:37:28,357 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40798069536685944, 'Total loss': 0.40798069536685944} | train loss {'Reaction outcome loss': 0.2640627561694514, 'Total loss': 0.2640627561694514}
2023-01-05 12:37:28,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:28,358 INFO:     Epoch: 81
2023-01-05 12:37:30,512 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3821467623114586, 'Total loss': 0.3821467623114586} | train loss {'Reaction outcome loss': 0.26213463476050075, 'Total loss': 0.26213463476050075}
2023-01-05 12:37:30,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:30,512 INFO:     Epoch: 82
2023-01-05 12:37:32,678 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4092492749293645, 'Total loss': 0.4092492749293645} | train loss {'Reaction outcome loss': 0.2670228710214533, 'Total loss': 0.2670228710214533}
2023-01-05 12:37:32,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:32,679 INFO:     Epoch: 83
2023-01-05 12:37:34,843 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4099180355668068, 'Total loss': 0.4099180355668068} | train loss {'Reaction outcome loss': 0.2603485133281372, 'Total loss': 0.2603485133281372}
2023-01-05 12:37:34,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:34,844 INFO:     Epoch: 84
2023-01-05 12:37:36,994 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4153732081254323, 'Total loss': 0.4153732081254323} | train loss {'Reaction outcome loss': 0.26180133907409914, 'Total loss': 0.26180133907409914}
2023-01-05 12:37:36,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:36,994 INFO:     Epoch: 85
2023-01-05 12:37:39,159 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4108296195665995, 'Total loss': 0.4108296195665995} | train loss {'Reaction outcome loss': 0.25435223008920677, 'Total loss': 0.25435223008920677}
2023-01-05 12:37:39,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:39,159 INFO:     Epoch: 86
2023-01-05 12:37:41,315 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38611311664183934, 'Total loss': 0.38611311664183934} | train loss {'Reaction outcome loss': 0.2528347556520063, 'Total loss': 0.2528347556520063}
2023-01-05 12:37:41,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:41,315 INFO:     Epoch: 87
2023-01-05 12:37:43,460 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43042841653029124, 'Total loss': 0.43042841653029124} | train loss {'Reaction outcome loss': 0.259024362261645, 'Total loss': 0.259024362261645}
2023-01-05 12:37:43,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:43,460 INFO:     Epoch: 88
2023-01-05 12:37:45,639 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3710758417844772, 'Total loss': 0.3710758417844772} | train loss {'Reaction outcome loss': 0.2627382764021737, 'Total loss': 0.2627382764021737}
2023-01-05 12:37:45,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:45,639 INFO:     Epoch: 89
2023-01-05 12:37:47,795 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38414490868647894, 'Total loss': 0.38414490868647894} | train loss {'Reaction outcome loss': 0.24970377389559129, 'Total loss': 0.24970377389559129}
2023-01-05 12:37:47,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:47,795 INFO:     Epoch: 90
2023-01-05 12:37:50,005 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42561771273612975, 'Total loss': 0.42561771273612975} | train loss {'Reaction outcome loss': 0.256462072097037, 'Total loss': 0.256462072097037}
2023-01-05 12:37:50,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:50,006 INFO:     Epoch: 91
2023-01-05 12:37:52,162 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3622008408109347, 'Total loss': 0.3622008408109347} | train loss {'Reaction outcome loss': 0.25080966220380074, 'Total loss': 0.25080966220380074}
2023-01-05 12:37:52,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:52,163 INFO:     Epoch: 92
2023-01-05 12:37:54,333 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3880627224842707, 'Total loss': 0.3880627224842707} | train loss {'Reaction outcome loss': 0.24770053934278716, 'Total loss': 0.24770053934278716}
2023-01-05 12:37:54,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:54,333 INFO:     Epoch: 93
2023-01-05 12:37:56,484 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38880848189195, 'Total loss': 0.38880848189195} | train loss {'Reaction outcome loss': 0.24574794778328415, 'Total loss': 0.24574794778328415}
2023-01-05 12:37:56,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:56,484 INFO:     Epoch: 94
2023-01-05 12:37:58,630 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36779350141684214, 'Total loss': 0.36779350141684214} | train loss {'Reaction outcome loss': 0.2593080039836303, 'Total loss': 0.2593080039836303}
2023-01-05 12:37:58,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:37:58,631 INFO:     Epoch: 95
2023-01-05 12:38:00,791 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43295208315054573, 'Total loss': 0.43295208315054573} | train loss {'Reaction outcome loss': 0.24990331467213858, 'Total loss': 0.24990331467213858}
2023-01-05 12:38:00,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:00,791 INFO:     Epoch: 96
2023-01-05 12:38:02,964 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4062951644261678, 'Total loss': 0.4062951644261678} | train loss {'Reaction outcome loss': 0.24971329992514674, 'Total loss': 0.24971329992514674}
2023-01-05 12:38:02,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:02,964 INFO:     Epoch: 97
2023-01-05 12:38:05,098 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.382229945063591, 'Total loss': 0.382229945063591} | train loss {'Reaction outcome loss': 0.25085956873848053, 'Total loss': 0.25085956873848053}
2023-01-05 12:38:05,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:05,098 INFO:     Epoch: 98
2023-01-05 12:38:07,272 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3765334119399389, 'Total loss': 0.3765334119399389} | train loss {'Reaction outcome loss': 0.2508008691964902, 'Total loss': 0.2508008691964902}
2023-01-05 12:38:07,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:07,272 INFO:     Epoch: 99
2023-01-05 12:38:09,436 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40729970832665763, 'Total loss': 0.40729970832665763} | train loss {'Reaction outcome loss': 0.24856981040950674, 'Total loss': 0.24856981040950674}
2023-01-05 12:38:09,436 INFO:     Best model found after epoch 70 of 100.
2023-01-05 12:38:09,436 INFO:   Done with stage: TRAINING
2023-01-05 12:38:09,436 INFO:   Starting stage: EVALUATION
2023-01-05 12:38:09,575 INFO:   Done with stage: EVALUATION
2023-01-05 12:38:09,575 INFO:   Leaving out SEQ value Fold_3
2023-01-05 12:38:09,588 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 12:38:09,588 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:38:10,245 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:38:10,245 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:38:10,315 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:38:10,316 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:38:10,316 INFO:     No hyperparam tuning for this model
2023-01-05 12:38:10,316 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:38:10,316 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:38:10,316 INFO:     None feature selector for col prot
2023-01-05 12:38:10,317 INFO:     None feature selector for col prot
2023-01-05 12:38:10,317 INFO:     None feature selector for col prot
2023-01-05 12:38:10,317 INFO:     None feature selector for col chem
2023-01-05 12:38:10,317 INFO:     None feature selector for col chem
2023-01-05 12:38:10,317 INFO:     None feature selector for col chem
2023-01-05 12:38:10,317 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:38:10,318 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:38:10,319 INFO:     Number of params in model 72901
2023-01-05 12:38:10,322 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:38:10,322 INFO:   Starting stage: TRAINING
2023-01-05 12:38:10,370 INFO:     Val loss before train {'Reaction outcome loss': 0.949650772412618, 'Total loss': 0.949650772412618}
2023-01-05 12:38:10,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:10,370 INFO:     Epoch: 0
2023-01-05 12:38:12,144 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7637880007425945, 'Total loss': 0.7637880007425945} | train loss {'Reaction outcome loss': 0.9193487937433006, 'Total loss': 0.9193487937433006}
2023-01-05 12:38:12,145 INFO:     Found new best model at epoch 0
2023-01-05 12:38:12,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:12,146 INFO:     Epoch: 1
2023-01-05 12:38:13,916 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5868079503377278, 'Total loss': 0.5868079503377278} | train loss {'Reaction outcome loss': 0.7262319788663056, 'Total loss': 0.7262319788663056}
2023-01-05 12:38:13,916 INFO:     Found new best model at epoch 1
2023-01-05 12:38:13,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:13,918 INFO:     Epoch: 2
2023-01-05 12:38:15,988 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.521984875202179, 'Total loss': 0.521984875202179} | train loss {'Reaction outcome loss': 0.5791995671108692, 'Total loss': 0.5791995671108692}
2023-01-05 12:38:15,988 INFO:     Found new best model at epoch 2
2023-01-05 12:38:15,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:15,989 INFO:     Epoch: 3
2023-01-05 12:38:18,144 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5048421839872996, 'Total loss': 0.5048421839872996} | train loss {'Reaction outcome loss': 0.5346149909887871, 'Total loss': 0.5346149909887871}
2023-01-05 12:38:18,144 INFO:     Found new best model at epoch 3
2023-01-05 12:38:18,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:18,145 INFO:     Epoch: 4
2023-01-05 12:38:20,303 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4808355381091436, 'Total loss': 0.4808355381091436} | train loss {'Reaction outcome loss': 0.5147321883888141, 'Total loss': 0.5147321883888141}
2023-01-05 12:38:20,303 INFO:     Found new best model at epoch 4
2023-01-05 12:38:20,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:20,305 INFO:     Epoch: 5
2023-01-05 12:38:22,464 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46137479742368065, 'Total loss': 0.46137479742368065} | train loss {'Reaction outcome loss': 0.5014108973045419, 'Total loss': 0.5014108973045419}
2023-01-05 12:38:22,464 INFO:     Found new best model at epoch 5
2023-01-05 12:38:22,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:22,465 INFO:     Epoch: 6
2023-01-05 12:38:24,626 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49552951057751976, 'Total loss': 0.49552951057751976} | train loss {'Reaction outcome loss': 0.49577411666621257, 'Total loss': 0.49577411666621257}
2023-01-05 12:38:24,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:24,626 INFO:     Epoch: 7
2023-01-05 12:38:26,751 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4708340624968211, 'Total loss': 0.4708340624968211} | train loss {'Reaction outcome loss': 0.48669302294941713, 'Total loss': 0.48669302294941713}
2023-01-05 12:38:26,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:26,751 INFO:     Epoch: 8
2023-01-05 12:38:28,915 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.468447466691335, 'Total loss': 0.468447466691335} | train loss {'Reaction outcome loss': 0.47459946186655627, 'Total loss': 0.47459946186655627}
2023-01-05 12:38:28,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:28,916 INFO:     Epoch: 9
2023-01-05 12:38:31,081 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4543175419171651, 'Total loss': 0.4543175419171651} | train loss {'Reaction outcome loss': 0.47677098627943193, 'Total loss': 0.47677098627943193}
2023-01-05 12:38:31,081 INFO:     Found new best model at epoch 9
2023-01-05 12:38:31,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:31,082 INFO:     Epoch: 10
2023-01-05 12:38:33,282 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46454784969488777, 'Total loss': 0.46454784969488777} | train loss {'Reaction outcome loss': 0.4631504919515909, 'Total loss': 0.4631504919515909}
2023-01-05 12:38:33,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:33,282 INFO:     Epoch: 11
2023-01-05 12:38:35,446 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47125688393910725, 'Total loss': 0.47125688393910725} | train loss {'Reaction outcome loss': 0.46522150623754865, 'Total loss': 0.46522150623754865}
2023-01-05 12:38:35,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:35,447 INFO:     Epoch: 12
2023-01-05 12:38:37,614 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47485891779263817, 'Total loss': 0.47485891779263817} | train loss {'Reaction outcome loss': 0.45162845359448966, 'Total loss': 0.45162845359448966}
2023-01-05 12:38:37,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:37,614 INFO:     Epoch: 13
2023-01-05 12:38:39,742 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45767921904722847, 'Total loss': 0.45767921904722847} | train loss {'Reaction outcome loss': 0.45193665420269447, 'Total loss': 0.45193665420269447}
2023-01-05 12:38:39,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:39,742 INFO:     Epoch: 14
2023-01-05 12:38:41,900 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.492175018787384, 'Total loss': 0.492175018787384} | train loss {'Reaction outcome loss': 0.45283042935885653, 'Total loss': 0.45283042935885653}
2023-01-05 12:38:41,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:41,900 INFO:     Epoch: 15
2023-01-05 12:38:44,064 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4375800957282384, 'Total loss': 0.4375800957282384} | train loss {'Reaction outcome loss': 0.44433889494542655, 'Total loss': 0.44433889494542655}
2023-01-05 12:38:44,064 INFO:     Found new best model at epoch 15
2023-01-05 12:38:44,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:44,065 INFO:     Epoch: 16
2023-01-05 12:38:46,205 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4546939849853516, 'Total loss': 0.4546939849853516} | train loss {'Reaction outcome loss': 0.4405040879645487, 'Total loss': 0.4405040879645487}
2023-01-05 12:38:46,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:46,205 INFO:     Epoch: 17
2023-01-05 12:38:48,353 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4468727608521779, 'Total loss': 0.4468727608521779} | train loss {'Reaction outcome loss': 0.42966753616929054, 'Total loss': 0.42966753616929054}
2023-01-05 12:38:48,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:48,354 INFO:     Epoch: 18
2023-01-05 12:38:50,471 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4622506469488144, 'Total loss': 0.4622506469488144} | train loss {'Reaction outcome loss': 0.4312247640731996, 'Total loss': 0.4312247640731996}
2023-01-05 12:38:50,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:50,471 INFO:     Epoch: 19
2023-01-05 12:38:52,612 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45207567811012267, 'Total loss': 0.45207567811012267} | train loss {'Reaction outcome loss': 0.4287805154810857, 'Total loss': 0.4287805154810857}
2023-01-05 12:38:52,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:52,613 INFO:     Epoch: 20
2023-01-05 12:38:54,757 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4621634344259898, 'Total loss': 0.4621634344259898} | train loss {'Reaction outcome loss': 0.42059717039122196, 'Total loss': 0.42059717039122196}
2023-01-05 12:38:54,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:54,758 INFO:     Epoch: 21
2023-01-05 12:38:56,909 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45272178649902345, 'Total loss': 0.45272178649902345} | train loss {'Reaction outcome loss': 0.4174137594599793, 'Total loss': 0.4174137594599793}
2023-01-05 12:38:56,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:56,910 INFO:     Epoch: 22
2023-01-05 12:38:59,054 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46102462311585746, 'Total loss': 0.46102462311585746} | train loss {'Reaction outcome loss': 0.415130225084994, 'Total loss': 0.415130225084994}
2023-01-05 12:38:59,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:38:59,056 INFO:     Epoch: 23
2023-01-05 12:39:01,188 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4651391843954722, 'Total loss': 0.4651391843954722} | train loss {'Reaction outcome loss': 0.4123014328307914, 'Total loss': 0.4123014328307914}
2023-01-05 12:39:01,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:01,189 INFO:     Epoch: 24
2023-01-05 12:39:03,311 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4528911550839742, 'Total loss': 0.4528911550839742} | train loss {'Reaction outcome loss': 0.40528348572280287, 'Total loss': 0.40528348572280287}
2023-01-05 12:39:03,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:03,311 INFO:     Epoch: 25
2023-01-05 12:39:05,458 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4600163469711939, 'Total loss': 0.4600163469711939} | train loss {'Reaction outcome loss': 0.4043259633174778, 'Total loss': 0.4043259633174778}
2023-01-05 12:39:05,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:05,459 INFO:     Epoch: 26
2023-01-05 12:39:07,602 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4629560063282649, 'Total loss': 0.4629560063282649} | train loss {'Reaction outcome loss': 0.3987014547643, 'Total loss': 0.3987014547643}
2023-01-05 12:39:07,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:07,602 INFO:     Epoch: 27
2023-01-05 12:39:09,740 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.444511353969574, 'Total loss': 0.444511353969574} | train loss {'Reaction outcome loss': 0.3945025862024648, 'Total loss': 0.3945025862024648}
2023-01-05 12:39:09,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:09,740 INFO:     Epoch: 28
2023-01-05 12:39:11,885 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4584126114845276, 'Total loss': 0.4584126114845276} | train loss {'Reaction outcome loss': 0.38850418192735553, 'Total loss': 0.38850418192735553}
2023-01-05 12:39:11,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:11,886 INFO:     Epoch: 29
2023-01-05 12:39:14,014 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44041579167048134, 'Total loss': 0.44041579167048134} | train loss {'Reaction outcome loss': 0.3895707070609949, 'Total loss': 0.3895707070609949}
2023-01-05 12:39:14,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:14,014 INFO:     Epoch: 30
2023-01-05 12:39:16,173 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45475309491157534, 'Total loss': 0.45475309491157534} | train loss {'Reaction outcome loss': 0.38657068444864595, 'Total loss': 0.38657068444864595}
2023-01-05 12:39:16,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:16,173 INFO:     Epoch: 31
2023-01-05 12:39:18,400 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45904190142949425, 'Total loss': 0.45904190142949425} | train loss {'Reaction outcome loss': 0.38187358085147655, 'Total loss': 0.38187358085147655}
2023-01-05 12:39:18,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:18,401 INFO:     Epoch: 32
2023-01-05 12:39:20,580 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40713393886884053, 'Total loss': 0.40713393886884053} | train loss {'Reaction outcome loss': 0.37780702105947656, 'Total loss': 0.37780702105947656}
2023-01-05 12:39:20,580 INFO:     Found new best model at epoch 32
2023-01-05 12:39:20,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:20,581 INFO:     Epoch: 33
2023-01-05 12:39:22,743 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4243168373902639, 'Total loss': 0.4243168373902639} | train loss {'Reaction outcome loss': 0.3749058109293454, 'Total loss': 0.3749058109293454}
2023-01-05 12:39:22,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:22,744 INFO:     Epoch: 34
2023-01-05 12:39:24,884 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4659529616435369, 'Total loss': 0.4659529616435369} | train loss {'Reaction outcome loss': 0.37501561747741524, 'Total loss': 0.37501561747741524}
2023-01-05 12:39:24,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:24,885 INFO:     Epoch: 35
2023-01-05 12:39:27,058 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43882880012194314, 'Total loss': 0.43882880012194314} | train loss {'Reaction outcome loss': 0.3680865665095566, 'Total loss': 0.3680865665095566}
2023-01-05 12:39:27,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:27,058 INFO:     Epoch: 36
2023-01-05 12:39:29,020 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44171585837999977, 'Total loss': 0.44171585837999977} | train loss {'Reaction outcome loss': 0.36290118130889254, 'Total loss': 0.36290118130889254}
2023-01-05 12:39:29,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:29,022 INFO:     Epoch: 37
2023-01-05 12:39:31,165 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4593475341796875, 'Total loss': 0.4593475341796875} | train loss {'Reaction outcome loss': 0.3597286936901782, 'Total loss': 0.3597286936901782}
2023-01-05 12:39:31,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:31,165 INFO:     Epoch: 38
2023-01-05 12:39:33,317 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46450740098953247, 'Total loss': 0.46450740098953247} | train loss {'Reaction outcome loss': 0.35682935838716745, 'Total loss': 0.35682935838716745}
2023-01-05 12:39:33,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:33,317 INFO:     Epoch: 39
2023-01-05 12:39:35,476 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44794328808784484, 'Total loss': 0.44794328808784484} | train loss {'Reaction outcome loss': 0.3533544983361324, 'Total loss': 0.3533544983361324}
2023-01-05 12:39:35,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:35,477 INFO:     Epoch: 40
2023-01-05 12:39:37,606 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42110901375611626, 'Total loss': 0.42110901375611626} | train loss {'Reaction outcome loss': 0.3475061404335238, 'Total loss': 0.3475061404335238}
2023-01-05 12:39:37,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:37,606 INFO:     Epoch: 41
2023-01-05 12:39:39,753 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4256958281000455, 'Total loss': 0.4256958281000455} | train loss {'Reaction outcome loss': 0.34836850995129914, 'Total loss': 0.34836850995129914}
2023-01-05 12:39:39,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:39,754 INFO:     Epoch: 42
2023-01-05 12:39:41,889 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4299765467643738, 'Total loss': 0.4299765467643738} | train loss {'Reaction outcome loss': 0.3474761793716219, 'Total loss': 0.3474761793716219}
2023-01-05 12:39:41,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:41,889 INFO:     Epoch: 43
2023-01-05 12:39:44,033 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43898896674315135, 'Total loss': 0.43898896674315135} | train loss {'Reaction outcome loss': 0.3460222934746612, 'Total loss': 0.3460222934746612}
2023-01-05 12:39:44,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:44,034 INFO:     Epoch: 44
2023-01-05 12:39:46,181 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43518170664707817, 'Total loss': 0.43518170664707817} | train loss {'Reaction outcome loss': 0.33580794239783807, 'Total loss': 0.33580794239783807}
2023-01-05 12:39:46,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:46,181 INFO:     Epoch: 45
2023-01-05 12:39:48,321 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.425578906138738, 'Total loss': 0.425578906138738} | train loss {'Reaction outcome loss': 0.3354751030459021, 'Total loss': 0.3354751030459021}
2023-01-05 12:39:48,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:48,322 INFO:     Epoch: 46
2023-01-05 12:39:50,475 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44622954229513806, 'Total loss': 0.44622954229513806} | train loss {'Reaction outcome loss': 0.327470544045859, 'Total loss': 0.327470544045859}
2023-01-05 12:39:50,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:50,475 INFO:     Epoch: 47
2023-01-05 12:39:52,631 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43574247558911644, 'Total loss': 0.43574247558911644} | train loss {'Reaction outcome loss': 0.3318620813860945, 'Total loss': 0.3318620813860945}
2023-01-05 12:39:52,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:52,631 INFO:     Epoch: 48
2023-01-05 12:39:54,791 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45099273522694905, 'Total loss': 0.45099273522694905} | train loss {'Reaction outcome loss': 0.33045005903028657, 'Total loss': 0.33045005903028657}
2023-01-05 12:39:54,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:54,791 INFO:     Epoch: 49
2023-01-05 12:39:56,945 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3826786130666733, 'Total loss': 0.3826786130666733} | train loss {'Reaction outcome loss': 0.32046519668541684, 'Total loss': 0.32046519668541684}
2023-01-05 12:39:56,945 INFO:     Found new best model at epoch 49
2023-01-05 12:39:56,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:56,947 INFO:     Epoch: 50
2023-01-05 12:39:59,096 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4166769504547119, 'Total loss': 0.4166769504547119} | train loss {'Reaction outcome loss': 0.32759846281940047, 'Total loss': 0.32759846281940047}
2023-01-05 12:39:59,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:39:59,096 INFO:     Epoch: 51
2023-01-05 12:40:01,217 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4146865616242091, 'Total loss': 0.4146865616242091} | train loss {'Reaction outcome loss': 0.31667307681356466, 'Total loss': 0.31667307681356466}
2023-01-05 12:40:01,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:01,217 INFO:     Epoch: 52
2023-01-05 12:40:03,359 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.393103156487147, 'Total loss': 0.393103156487147} | train loss {'Reaction outcome loss': 0.326700767950855, 'Total loss': 0.326700767950855}
2023-01-05 12:40:03,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:03,359 INFO:     Epoch: 53
2023-01-05 12:40:05,495 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39643334845701855, 'Total loss': 0.39643334845701855} | train loss {'Reaction outcome loss': 0.30633661341275614, 'Total loss': 0.30633661341275614}
2023-01-05 12:40:05,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:05,496 INFO:     Epoch: 54
2023-01-05 12:40:07,632 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.423133181532224, 'Total loss': 0.423133181532224} | train loss {'Reaction outcome loss': 0.3147248340920158, 'Total loss': 0.3147248340920158}
2023-01-05 12:40:07,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:07,632 INFO:     Epoch: 55
2023-01-05 12:40:09,781 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38549976895252863, 'Total loss': 0.38549976895252863} | train loss {'Reaction outcome loss': 0.30706600518557275, 'Total loss': 0.30706600518557275}
2023-01-05 12:40:09,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:09,781 INFO:     Epoch: 56
2023-01-05 12:40:11,908 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4246470133463542, 'Total loss': 0.4246470133463542} | train loss {'Reaction outcome loss': 0.3069344671973347, 'Total loss': 0.3069344671973347}
2023-01-05 12:40:11,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:11,909 INFO:     Epoch: 57
2023-01-05 12:40:14,056 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41556714177131654, 'Total loss': 0.41556714177131654} | train loss {'Reaction outcome loss': 0.3026747847941235, 'Total loss': 0.3026747847941235}
2023-01-05 12:40:14,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:14,056 INFO:     Epoch: 58
2023-01-05 12:40:16,197 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4500137408574422, 'Total loss': 0.4500137408574422} | train loss {'Reaction outcome loss': 0.30555156810059597, 'Total loss': 0.30555156810059597}
2023-01-05 12:40:16,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:16,197 INFO:     Epoch: 59
2023-01-05 12:40:18,348 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39325936933358513, 'Total loss': 0.39325936933358513} | train loss {'Reaction outcome loss': 0.29697731237885727, 'Total loss': 0.29697731237885727}
2023-01-05 12:40:18,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:18,349 INFO:     Epoch: 60
2023-01-05 12:40:20,495 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4289243976275126, 'Total loss': 0.4289243976275126} | train loss {'Reaction outcome loss': 0.29922189108048475, 'Total loss': 0.29922189108048475}
2023-01-05 12:40:20,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:20,496 INFO:     Epoch: 61
2023-01-05 12:40:22,659 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4070064157247543, 'Total loss': 0.4070064157247543} | train loss {'Reaction outcome loss': 0.29757967488636283, 'Total loss': 0.29757967488636283}
2023-01-05 12:40:22,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:22,660 INFO:     Epoch: 62
2023-01-05 12:40:24,781 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39807433585325874, 'Total loss': 0.39807433585325874} | train loss {'Reaction outcome loss': 0.28986288389585313, 'Total loss': 0.28986288389585313}
2023-01-05 12:40:24,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:24,782 INFO:     Epoch: 63
2023-01-05 12:40:26,929 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4212075680494308, 'Total loss': 0.4212075680494308} | train loss {'Reaction outcome loss': 0.2869816403292174, 'Total loss': 0.2869816403292174}
2023-01-05 12:40:26,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:26,929 INFO:     Epoch: 64
2023-01-05 12:40:29,065 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4178836584091187, 'Total loss': 0.4178836584091187} | train loss {'Reaction outcome loss': 0.28638593263815354, 'Total loss': 0.28638593263815354}
2023-01-05 12:40:29,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:29,065 INFO:     Epoch: 65
2023-01-05 12:40:31,227 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42095045348008475, 'Total loss': 0.42095045348008475} | train loss {'Reaction outcome loss': 0.2893775350203479, 'Total loss': 0.2893775350203479}
2023-01-05 12:40:31,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:31,227 INFO:     Epoch: 66
2023-01-05 12:40:33,379 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39013464947541554, 'Total loss': 0.39013464947541554} | train loss {'Reaction outcome loss': 0.2845996161854833, 'Total loss': 0.2845996161854833}
2023-01-05 12:40:33,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:33,379 INFO:     Epoch: 67
2023-01-05 12:40:35,540 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4270341217517853, 'Total loss': 0.4270341217517853} | train loss {'Reaction outcome loss': 0.2830758582474324, 'Total loss': 0.2830758582474324}
2023-01-05 12:40:35,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:35,540 INFO:     Epoch: 68
2023-01-05 12:40:37,746 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3957684506972631, 'Total loss': 0.3957684506972631} | train loss {'Reaction outcome loss': 0.27860061378374584, 'Total loss': 0.27860061378374584}
2023-01-05 12:40:37,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:37,746 INFO:     Epoch: 69
2023-01-05 12:40:40,029 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4505524575710297, 'Total loss': 0.4505524575710297} | train loss {'Reaction outcome loss': 0.28183581603922114, 'Total loss': 0.28183581603922114}
2023-01-05 12:40:40,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:40,029 INFO:     Epoch: 70
2023-01-05 12:40:42,225 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3945617030064265, 'Total loss': 0.3945617030064265} | train loss {'Reaction outcome loss': 0.2715364069997394, 'Total loss': 0.2715364069997394}
2023-01-05 12:40:42,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:42,226 INFO:     Epoch: 71
2023-01-05 12:40:44,391 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43422247370084127, 'Total loss': 0.43422247370084127} | train loss {'Reaction outcome loss': 0.28142556048807327, 'Total loss': 0.28142556048807327}
2023-01-05 12:40:44,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:44,392 INFO:     Epoch: 72
2023-01-05 12:40:46,549 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4097053329149882, 'Total loss': 0.4097053329149882} | train loss {'Reaction outcome loss': 0.2743267361890443, 'Total loss': 0.2743267361890443}
2023-01-05 12:40:46,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:46,549 INFO:     Epoch: 73
2023-01-05 12:40:48,702 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39856507778167727, 'Total loss': 0.39856507778167727} | train loss {'Reaction outcome loss': 0.2760089240070895, 'Total loss': 0.2760089240070895}
2023-01-05 12:40:48,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:48,703 INFO:     Epoch: 74
2023-01-05 12:40:50,868 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4194271405537923, 'Total loss': 0.4194271405537923} | train loss {'Reaction outcome loss': 0.27232991652495236, 'Total loss': 0.27232991652495236}
2023-01-05 12:40:50,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:50,868 INFO:     Epoch: 75
2023-01-05 12:40:53,042 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42606625854969027, 'Total loss': 0.42606625854969027} | train loss {'Reaction outcome loss': 0.27508677659134795, 'Total loss': 0.27508677659134795}
2023-01-05 12:40:53,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:53,042 INFO:     Epoch: 76
2023-01-05 12:40:55,202 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3985887298981349, 'Total loss': 0.3985887298981349} | train loss {'Reaction outcome loss': 0.26442681828065073, 'Total loss': 0.26442681828065073}
2023-01-05 12:40:55,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:55,203 INFO:     Epoch: 77
2023-01-05 12:40:57,352 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35824331889549893, 'Total loss': 0.35824331889549893} | train loss {'Reaction outcome loss': 0.2686734855256594, 'Total loss': 0.2686734855256594}
2023-01-05 12:40:57,352 INFO:     Found new best model at epoch 77
2023-01-05 12:40:57,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:57,353 INFO:     Epoch: 78
2023-01-05 12:40:59,493 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39050152003765104, 'Total loss': 0.39050152003765104} | train loss {'Reaction outcome loss': 0.26968469711387677, 'Total loss': 0.26968469711387677}
2023-01-05 12:40:59,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:40:59,493 INFO:     Epoch: 79
2023-01-05 12:41:01,647 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3485094631711642, 'Total loss': 0.3485094631711642} | train loss {'Reaction outcome loss': 0.26391531104888144, 'Total loss': 0.26391531104888144}
2023-01-05 12:41:01,648 INFO:     Found new best model at epoch 79
2023-01-05 12:41:01,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:01,650 INFO:     Epoch: 80
2023-01-05 12:41:03,816 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39525097211201987, 'Total loss': 0.39525097211201987} | train loss {'Reaction outcome loss': 0.2650765137488607, 'Total loss': 0.2650765137488607}
2023-01-05 12:41:03,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:03,816 INFO:     Epoch: 81
2023-01-05 12:41:05,982 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40695192317167916, 'Total loss': 0.40695192317167916} | train loss {'Reaction outcome loss': 0.26021429344359104, 'Total loss': 0.26021429344359104}
2023-01-05 12:41:05,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:05,983 INFO:     Epoch: 82
2023-01-05 12:41:08,127 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36982903877894086, 'Total loss': 0.36982903877894086} | train loss {'Reaction outcome loss': 0.25910124717021943, 'Total loss': 0.25910124717021943}
2023-01-05 12:41:08,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:08,127 INFO:     Epoch: 83
2023-01-05 12:41:10,265 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42669347375631334, 'Total loss': 0.42669347375631334} | train loss {'Reaction outcome loss': 0.2545452382769028, 'Total loss': 0.2545452382769028}
2023-01-05 12:41:10,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:10,265 INFO:     Epoch: 84
2023-01-05 12:41:12,390 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39571012407541273, 'Total loss': 0.39571012407541273} | train loss {'Reaction outcome loss': 0.2582534090581819, 'Total loss': 0.2582534090581819}
2023-01-05 12:41:12,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:12,391 INFO:     Epoch: 85
2023-01-05 12:41:14,539 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3875759287426869, 'Total loss': 0.3875759287426869} | train loss {'Reaction outcome loss': 0.2623839959447836, 'Total loss': 0.2623839959447836}
2023-01-05 12:41:14,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:14,539 INFO:     Epoch: 86
2023-01-05 12:41:16,678 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4229655663172404, 'Total loss': 0.4229655663172404} | train loss {'Reaction outcome loss': 0.2522317033641747, 'Total loss': 0.2522317033641747}
2023-01-05 12:41:16,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:16,679 INFO:     Epoch: 87
2023-01-05 12:41:18,816 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4139764070510864, 'Total loss': 0.4139764070510864} | train loss {'Reaction outcome loss': 0.2568708809813226, 'Total loss': 0.2568708809813226}
2023-01-05 12:41:18,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:18,817 INFO:     Epoch: 88
2023-01-05 12:41:20,960 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4139877617359161, 'Total loss': 0.4139877617359161} | train loss {'Reaction outcome loss': 0.2524490171676352, 'Total loss': 0.2524490171676352}
2023-01-05 12:41:20,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:20,961 INFO:     Epoch: 89
2023-01-05 12:41:23,175 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40778612792491914, 'Total loss': 0.40778612792491914} | train loss {'Reaction outcome loss': 0.24958217899947271, 'Total loss': 0.24958217899947271}
2023-01-05 12:41:23,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:23,176 INFO:     Epoch: 90
2023-01-05 12:41:25,333 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41081084857384365, 'Total loss': 0.41081084857384365} | train loss {'Reaction outcome loss': 0.2552845063789265, 'Total loss': 0.2552845063789265}
2023-01-05 12:41:25,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:25,333 INFO:     Epoch: 91
2023-01-05 12:41:27,486 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37275014221668246, 'Total loss': 0.37275014221668246} | train loss {'Reaction outcome loss': 0.24810816547459494, 'Total loss': 0.24810816547459494}
2023-01-05 12:41:27,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:27,486 INFO:     Epoch: 92
2023-01-05 12:41:29,628 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3631094584862391, 'Total loss': 0.3631094584862391} | train loss {'Reaction outcome loss': 0.24774051431811203, 'Total loss': 0.24774051431811203}
2023-01-05 12:41:29,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:29,628 INFO:     Epoch: 93
2023-01-05 12:41:31,766 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42862560153007506, 'Total loss': 0.42862560153007506} | train loss {'Reaction outcome loss': 0.2527700819782097, 'Total loss': 0.2527700819782097}
2023-01-05 12:41:31,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:31,767 INFO:     Epoch: 94
2023-01-05 12:41:33,906 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39039774735768634, 'Total loss': 0.39039774735768634} | train loss {'Reaction outcome loss': 0.2409826525126713, 'Total loss': 0.2409826525126713}
2023-01-05 12:41:33,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:33,907 INFO:     Epoch: 95
2023-01-05 12:41:36,049 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4027371068795522, 'Total loss': 0.4027371068795522} | train loss {'Reaction outcome loss': 0.2508225444174052, 'Total loss': 0.2508225444174052}
2023-01-05 12:41:36,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:36,050 INFO:     Epoch: 96
2023-01-05 12:41:38,207 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3943206757307053, 'Total loss': 0.3943206757307053} | train loss {'Reaction outcome loss': 0.24219635590897315, 'Total loss': 0.24219635590897315}
2023-01-05 12:41:38,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:38,207 INFO:     Epoch: 97
2023-01-05 12:41:40,371 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39879787266254424, 'Total loss': 0.39879787266254424} | train loss {'Reaction outcome loss': 0.24526428926165086, 'Total loss': 0.24526428926165086}
2023-01-05 12:41:40,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:40,371 INFO:     Epoch: 98
2023-01-05 12:41:42,526 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41660726169745127, 'Total loss': 0.41660726169745127} | train loss {'Reaction outcome loss': 0.24172909831777759, 'Total loss': 0.24172909831777759}
2023-01-05 12:41:42,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:42,527 INFO:     Epoch: 99
2023-01-05 12:41:44,671 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42368758618831637, 'Total loss': 0.42368758618831637} | train loss {'Reaction outcome loss': 0.23637337168257166, 'Total loss': 0.23637337168257166}
2023-01-05 12:41:44,671 INFO:     Best model found after epoch 80 of 100.
2023-01-05 12:41:44,671 INFO:   Done with stage: TRAINING
2023-01-05 12:41:44,671 INFO:   Starting stage: EVALUATION
2023-01-05 12:41:44,812 INFO:   Done with stage: EVALUATION
2023-01-05 12:41:44,812 INFO:   Leaving out SEQ value Fold_4
2023-01-05 12:41:44,825 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 12:41:44,825 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:41:45,485 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:41:45,485 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:41:45,555 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:41:45,555 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:41:45,555 INFO:     No hyperparam tuning for this model
2023-01-05 12:41:45,555 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:41:45,555 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:41:45,556 INFO:     None feature selector for col prot
2023-01-05 12:41:45,556 INFO:     None feature selector for col prot
2023-01-05 12:41:45,556 INFO:     None feature selector for col prot
2023-01-05 12:41:45,557 INFO:     None feature selector for col chem
2023-01-05 12:41:45,557 INFO:     None feature selector for col chem
2023-01-05 12:41:45,557 INFO:     None feature selector for col chem
2023-01-05 12:41:45,557 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:41:45,557 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:41:45,559 INFO:     Number of params in model 72901
2023-01-05 12:41:45,562 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:41:45,562 INFO:   Starting stage: TRAINING
2023-01-05 12:41:45,620 INFO:     Val loss before train {'Reaction outcome loss': 0.8900210916996002, 'Total loss': 0.8900210916996002}
2023-01-05 12:41:45,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:45,620 INFO:     Epoch: 0
2023-01-05 12:41:47,783 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6826968828837077, 'Total loss': 0.6826968828837077} | train loss {'Reaction outcome loss': 0.9342900664694067, 'Total loss': 0.9342900664694067}
2023-01-05 12:41:47,784 INFO:     Found new best model at epoch 0
2023-01-05 12:41:47,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:47,785 INFO:     Epoch: 1
2023-01-05 12:41:49,947 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5008071819941203, 'Total loss': 0.5008071819941203} | train loss {'Reaction outcome loss': 0.6838343309232648, 'Total loss': 0.6838343309232648}
2023-01-05 12:41:49,947 INFO:     Found new best model at epoch 1
2023-01-05 12:41:49,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:49,949 INFO:     Epoch: 2
2023-01-05 12:41:52,145 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5055889864762624, 'Total loss': 0.5055889864762624} | train loss {'Reaction outcome loss': 0.5544182181466317, 'Total loss': 0.5544182181466317}
2023-01-05 12:41:52,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:52,145 INFO:     Epoch: 3
2023-01-05 12:41:54,322 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49270107547442116, 'Total loss': 0.49270107547442116} | train loss {'Reaction outcome loss': 0.5150924842210783, 'Total loss': 0.5150924842210783}
2023-01-05 12:41:54,322 INFO:     Found new best model at epoch 3
2023-01-05 12:41:54,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:54,324 INFO:     Epoch: 4
2023-01-05 12:41:56,465 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.471417111158371, 'Total loss': 0.471417111158371} | train loss {'Reaction outcome loss': 0.5005798351904968, 'Total loss': 0.5005798351904968}
2023-01-05 12:41:56,465 INFO:     Found new best model at epoch 4
2023-01-05 12:41:56,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:56,466 INFO:     Epoch: 5
2023-01-05 12:41:58,646 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4538797785838445, 'Total loss': 0.4538797785838445} | train loss {'Reaction outcome loss': 0.4930144560833772, 'Total loss': 0.4930144560833772}
2023-01-05 12:41:58,646 INFO:     Found new best model at epoch 5
2023-01-05 12:41:58,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:41:58,647 INFO:     Epoch: 6
2023-01-05 12:42:00,821 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44583026468753817, 'Total loss': 0.44583026468753817} | train loss {'Reaction outcome loss': 0.47882591600975266, 'Total loss': 0.47882591600975266}
2023-01-05 12:42:00,821 INFO:     Found new best model at epoch 6
2023-01-05 12:42:00,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:00,822 INFO:     Epoch: 7
2023-01-05 12:42:02,981 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4482546240091324, 'Total loss': 0.4482546240091324} | train loss {'Reaction outcome loss': 0.4656917909194, 'Total loss': 0.4656917909194}
2023-01-05 12:42:02,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:02,982 INFO:     Epoch: 8
2023-01-05 12:42:05,158 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44776950081189476, 'Total loss': 0.44776950081189476} | train loss {'Reaction outcome loss': 0.4645363038972668, 'Total loss': 0.4645363038972668}
2023-01-05 12:42:05,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:05,158 INFO:     Epoch: 9
2023-01-05 12:42:07,312 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.426783827940623, 'Total loss': 0.426783827940623} | train loss {'Reaction outcome loss': 0.4675974826854856, 'Total loss': 0.4675974826854856}
2023-01-05 12:42:07,313 INFO:     Found new best model at epoch 9
2023-01-05 12:42:07,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:07,314 INFO:     Epoch: 10
2023-01-05 12:42:09,474 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4224629163742065, 'Total loss': 0.4224629163742065} | train loss {'Reaction outcome loss': 0.44399425691935995, 'Total loss': 0.44399425691935995}
2023-01-05 12:42:09,474 INFO:     Found new best model at epoch 10
2023-01-05 12:42:09,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:09,475 INFO:     Epoch: 11
2023-01-05 12:42:11,637 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43070958455403646, 'Total loss': 0.43070958455403646} | train loss {'Reaction outcome loss': 0.4402824656787308, 'Total loss': 0.4402824656787308}
2023-01-05 12:42:11,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:11,637 INFO:     Epoch: 12
2023-01-05 12:42:13,803 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4473731944958369, 'Total loss': 0.4473731944958369} | train loss {'Reaction outcome loss': 0.44682648378437845, 'Total loss': 0.44682648378437845}
2023-01-05 12:42:13,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:13,803 INFO:     Epoch: 13
2023-01-05 12:42:15,951 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4120273103316625, 'Total loss': 0.4120273103316625} | train loss {'Reaction outcome loss': 0.4466393096380921, 'Total loss': 0.4466393096380921}
2023-01-05 12:42:15,952 INFO:     Found new best model at epoch 13
2023-01-05 12:42:15,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:15,953 INFO:     Epoch: 14
2023-01-05 12:42:18,123 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.453194397687912, 'Total loss': 0.453194397687912} | train loss {'Reaction outcome loss': 0.4344393932193086, 'Total loss': 0.4344393932193086}
2023-01-05 12:42:18,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:18,124 INFO:     Epoch: 15
2023-01-05 12:42:20,276 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44463435212771096, 'Total loss': 0.44463435212771096} | train loss {'Reaction outcome loss': 0.4298995685952621, 'Total loss': 0.4298995685952621}
2023-01-05 12:42:20,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:20,276 INFO:     Epoch: 16
2023-01-05 12:42:22,437 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.419946026802063, 'Total loss': 0.419946026802063} | train loss {'Reaction outcome loss': 0.4101490942707312, 'Total loss': 0.4101490942707312}
2023-01-05 12:42:22,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:22,437 INFO:     Epoch: 17
2023-01-05 12:42:24,614 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43787915060917537, 'Total loss': 0.43787915060917537} | train loss {'Reaction outcome loss': 0.4216691844430634, 'Total loss': 0.4216691844430634}
2023-01-05 12:42:24,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:24,615 INFO:     Epoch: 18
2023-01-05 12:42:26,789 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4007519483566284, 'Total loss': 0.4007519483566284} | train loss {'Reaction outcome loss': 0.40495880493435304, 'Total loss': 0.40495880493435304}
2023-01-05 12:42:26,790 INFO:     Found new best model at epoch 18
2023-01-05 12:42:26,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:26,791 INFO:     Epoch: 19
2023-01-05 12:42:28,951 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4167446319013834, 'Total loss': 0.4167446319013834} | train loss {'Reaction outcome loss': 0.41264682981199113, 'Total loss': 0.41264682981199113}
2023-01-05 12:42:28,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:28,951 INFO:     Epoch: 20
2023-01-05 12:42:31,113 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4314631501833598, 'Total loss': 0.4314631501833598} | train loss {'Reaction outcome loss': 0.4234130700807209, 'Total loss': 0.4234130700807209}
2023-01-05 12:42:31,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:31,114 INFO:     Epoch: 21
2023-01-05 12:42:33,270 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4130337635676066, 'Total loss': 0.4130337635676066} | train loss {'Reaction outcome loss': 0.42910679999361, 'Total loss': 0.42910679999361}
2023-01-05 12:42:33,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:33,270 INFO:     Epoch: 22
2023-01-05 12:42:35,450 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3993535747130712, 'Total loss': 0.3993535747130712} | train loss {'Reaction outcome loss': 0.40748042727401573, 'Total loss': 0.40748042727401573}
2023-01-05 12:42:35,450 INFO:     Found new best model at epoch 22
2023-01-05 12:42:35,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:35,452 INFO:     Epoch: 23
2023-01-05 12:42:37,622 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40230815211931864, 'Total loss': 0.40230815211931864} | train loss {'Reaction outcome loss': 0.3963270441804459, 'Total loss': 0.3963270441804459}
2023-01-05 12:42:37,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:37,623 INFO:     Epoch: 24
2023-01-05 12:42:39,810 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42553009192148844, 'Total loss': 0.42553009192148844} | train loss {'Reaction outcome loss': 0.3896495072066487, 'Total loss': 0.3896495072066487}
2023-01-05 12:42:39,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:39,810 INFO:     Epoch: 25
2023-01-05 12:42:41,963 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4028729130824407, 'Total loss': 0.4028729130824407} | train loss {'Reaction outcome loss': 0.3866893667626478, 'Total loss': 0.3866893667626478}
2023-01-05 12:42:41,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:41,963 INFO:     Epoch: 26
2023-01-05 12:42:44,138 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42222159802913667, 'Total loss': 0.42222159802913667} | train loss {'Reaction outcome loss': 0.381677029941204, 'Total loss': 0.381677029941204}
2023-01-05 12:42:44,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:44,139 INFO:     Epoch: 27
2023-01-05 12:42:46,302 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40641454656918846, 'Total loss': 0.40641454656918846} | train loss {'Reaction outcome loss': 0.38192293035588565, 'Total loss': 0.38192293035588565}
2023-01-05 12:42:46,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:46,302 INFO:     Epoch: 28
2023-01-05 12:42:48,480 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40062479972839354, 'Total loss': 0.40062479972839354} | train loss {'Reaction outcome loss': 0.3790786326726777, 'Total loss': 0.3790786326726777}
2023-01-05 12:42:48,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:48,481 INFO:     Epoch: 29
2023-01-05 12:42:50,656 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42444474101066587, 'Total loss': 0.42444474101066587} | train loss {'Reaction outcome loss': 0.3725976352415919, 'Total loss': 0.3725976352415919}
2023-01-05 12:42:50,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:50,656 INFO:     Epoch: 30
2023-01-05 12:42:52,836 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39367294708887735, 'Total loss': 0.39367294708887735} | train loss {'Reaction outcome loss': 0.37851857605889655, 'Total loss': 0.37851857605889655}
2023-01-05 12:42:52,836 INFO:     Found new best model at epoch 30
2023-01-05 12:42:52,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:52,837 INFO:     Epoch: 31
2023-01-05 12:42:54,985 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4342553973197937, 'Total loss': 0.4342553973197937} | train loss {'Reaction outcome loss': 0.3894629727629776, 'Total loss': 0.3894629727629776}
2023-01-05 12:42:54,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:54,986 INFO:     Epoch: 32
2023-01-05 12:42:57,151 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38499463299910225, 'Total loss': 0.38499463299910225} | train loss {'Reaction outcome loss': 0.3635309353399941, 'Total loss': 0.3635309353399941}
2023-01-05 12:42:57,152 INFO:     Found new best model at epoch 32
2023-01-05 12:42:57,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:57,153 INFO:     Epoch: 33
2023-01-05 12:42:59,317 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39661952555179597, 'Total loss': 0.39661952555179597} | train loss {'Reaction outcome loss': 0.3626718773452592, 'Total loss': 0.3626718773452592}
2023-01-05 12:42:59,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:42:59,317 INFO:     Epoch: 34
2023-01-05 12:43:01,482 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39560858011245725, 'Total loss': 0.39560858011245725} | train loss {'Reaction outcome loss': 0.3541169774759075, 'Total loss': 0.3541169774759075}
2023-01-05 12:43:01,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:01,483 INFO:     Epoch: 35
2023-01-05 12:43:03,646 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4122803628444672, 'Total loss': 0.4122803628444672} | train loss {'Reaction outcome loss': 0.3551924543048633, 'Total loss': 0.3551924543048633}
2023-01-05 12:43:03,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:03,646 INFO:     Epoch: 36
2023-01-05 12:43:05,797 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39173258940378824, 'Total loss': 0.39173258940378824} | train loss {'Reaction outcome loss': 0.34866639002617716, 'Total loss': 0.34866639002617716}
2023-01-05 12:43:05,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:05,797 INFO:     Epoch: 37
2023-01-05 12:43:07,953 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4178715894619624, 'Total loss': 0.4178715894619624} | train loss {'Reaction outcome loss': 0.34782716348443343, 'Total loss': 0.34782716348443343}
2023-01-05 12:43:07,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:07,954 INFO:     Epoch: 38
2023-01-05 12:43:10,125 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.381736621260643, 'Total loss': 0.381736621260643} | train loss {'Reaction outcome loss': 0.3647342420493563, 'Total loss': 0.3647342420493563}
2023-01-05 12:43:10,125 INFO:     Found new best model at epoch 38
2023-01-05 12:43:10,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:10,126 INFO:     Epoch: 39
2023-01-05 12:43:12,299 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3987462391455968, 'Total loss': 0.3987462391455968} | train loss {'Reaction outcome loss': 0.3434450828909325, 'Total loss': 0.3434450828909325}
2023-01-05 12:43:12,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:12,300 INFO:     Epoch: 40
2023-01-05 12:43:14,472 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3765857299168905, 'Total loss': 0.3765857299168905} | train loss {'Reaction outcome loss': 0.34280684230948544, 'Total loss': 0.34280684230948544}
2023-01-05 12:43:14,473 INFO:     Found new best model at epoch 40
2023-01-05 12:43:14,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:14,474 INFO:     Epoch: 41
2023-01-05 12:43:16,637 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41293503642082213, 'Total loss': 0.41293503642082213} | train loss {'Reaction outcome loss': 0.3536468188318869, 'Total loss': 0.3536468188318869}
2023-01-05 12:43:16,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:16,637 INFO:     Epoch: 42
2023-01-05 12:43:18,807 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39550126641988753, 'Total loss': 0.39550126641988753} | train loss {'Reaction outcome loss': 0.34650669030953146, 'Total loss': 0.34650669030953146}
2023-01-05 12:43:18,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:18,807 INFO:     Epoch: 43
2023-01-05 12:43:20,966 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3945681442817052, 'Total loss': 0.3945681442817052} | train loss {'Reaction outcome loss': 0.36847192300511, 'Total loss': 0.36847192300511}
2023-01-05 12:43:20,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:20,966 INFO:     Epoch: 44
2023-01-05 12:43:23,138 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.395312429467837, 'Total loss': 0.395312429467837} | train loss {'Reaction outcome loss': 0.32714914101982856, 'Total loss': 0.32714914101982856}
2023-01-05 12:43:23,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:23,138 INFO:     Epoch: 45
2023-01-05 12:43:25,290 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36758048335711163, 'Total loss': 0.36758048335711163} | train loss {'Reaction outcome loss': 0.3243293807558391, 'Total loss': 0.3243293807558391}
2023-01-05 12:43:25,292 INFO:     Found new best model at epoch 45
2023-01-05 12:43:25,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:25,293 INFO:     Epoch: 46
2023-01-05 12:43:27,454 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3975562562545141, 'Total loss': 0.3975562562545141} | train loss {'Reaction outcome loss': 0.34296558057700377, 'Total loss': 0.34296558057700377}
2023-01-05 12:43:27,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:27,454 INFO:     Epoch: 47
2023-01-05 12:43:29,623 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4569063941637675, 'Total loss': 0.4569063941637675} | train loss {'Reaction outcome loss': 0.3347820623953273, 'Total loss': 0.3347820623953273}
2023-01-05 12:43:29,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:29,624 INFO:     Epoch: 48
2023-01-05 12:43:31,787 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.394078462322553, 'Total loss': 0.394078462322553} | train loss {'Reaction outcome loss': 0.3571931171109495, 'Total loss': 0.3571931171109495}
2023-01-05 12:43:31,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:31,788 INFO:     Epoch: 49
2023-01-05 12:43:33,957 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3900582740704219, 'Total loss': 0.3900582740704219} | train loss {'Reaction outcome loss': 0.3236929735749204, 'Total loss': 0.3236929735749204}
2023-01-05 12:43:33,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:33,957 INFO:     Epoch: 50
2023-01-05 12:43:35,973 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3863389735420545, 'Total loss': 0.3863389735420545} | train loss {'Reaction outcome loss': 0.3131163801856177, 'Total loss': 0.3131163801856177}
2023-01-05 12:43:35,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:35,974 INFO:     Epoch: 51
2023-01-05 12:43:38,152 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37644178767999015, 'Total loss': 0.37644178767999015} | train loss {'Reaction outcome loss': 0.3097150169796278, 'Total loss': 0.3097150169796278}
2023-01-05 12:43:38,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:38,152 INFO:     Epoch: 52
2023-01-05 12:43:40,345 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3590429375569026, 'Total loss': 0.3590429375569026} | train loss {'Reaction outcome loss': 0.313603960498965, 'Total loss': 0.313603960498965}
2023-01-05 12:43:40,345 INFO:     Found new best model at epoch 52
2023-01-05 12:43:40,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:40,346 INFO:     Epoch: 53
2023-01-05 12:43:42,522 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35336173127094905, 'Total loss': 0.35336173127094905} | train loss {'Reaction outcome loss': 0.31231990026013146, 'Total loss': 0.31231990026013146}
2023-01-05 12:43:42,522 INFO:     Found new best model at epoch 53
2023-01-05 12:43:42,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:42,523 INFO:     Epoch: 54
2023-01-05 12:43:44,713 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39251476228237153, 'Total loss': 0.39251476228237153} | train loss {'Reaction outcome loss': 0.32872657620928425, 'Total loss': 0.32872657620928425}
2023-01-05 12:43:44,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:44,714 INFO:     Epoch: 55
2023-01-05 12:43:46,881 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37204051613807676, 'Total loss': 0.37204051613807676} | train loss {'Reaction outcome loss': 0.3095735409415942, 'Total loss': 0.3095735409415942}
2023-01-05 12:43:46,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:46,881 INFO:     Epoch: 56
2023-01-05 12:43:49,048 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3996714373429616, 'Total loss': 0.3996714373429616} | train loss {'Reaction outcome loss': 0.311656147776428, 'Total loss': 0.311656147776428}
2023-01-05 12:43:49,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:49,048 INFO:     Epoch: 57
2023-01-05 12:43:51,206 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.391346820195516, 'Total loss': 0.391346820195516} | train loss {'Reaction outcome loss': 0.2980900235150171, 'Total loss': 0.2980900235150171}
2023-01-05 12:43:51,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:51,207 INFO:     Epoch: 58
2023-01-05 12:43:53,370 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38524288932482403, 'Total loss': 0.38524288932482403} | train loss {'Reaction outcome loss': 0.2975548120161545, 'Total loss': 0.2975548120161545}
2023-01-05 12:43:53,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:53,370 INFO:     Epoch: 59
2023-01-05 12:43:55,528 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3841626301407814, 'Total loss': 0.3841626301407814} | train loss {'Reaction outcome loss': 0.2949435031404246, 'Total loss': 0.2949435031404246}
2023-01-05 12:43:55,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:55,528 INFO:     Epoch: 60
2023-01-05 12:43:57,698 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3665523543953896, 'Total loss': 0.3665523543953896} | train loss {'Reaction outcome loss': 0.288182011010181, 'Total loss': 0.288182011010181}
2023-01-05 12:43:57,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:57,699 INFO:     Epoch: 61
2023-01-05 12:43:59,880 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4020755479733149, 'Total loss': 0.4020755479733149} | train loss {'Reaction outcome loss': 0.2891595757632192, 'Total loss': 0.2891595757632192}
2023-01-05 12:43:59,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:43:59,882 INFO:     Epoch: 62
2023-01-05 12:44:02,065 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3990595748027166, 'Total loss': 0.3990595748027166} | train loss {'Reaction outcome loss': 0.2912747255961775, 'Total loss': 0.2912747255961775}
2023-01-05 12:44:02,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:02,065 INFO:     Epoch: 63
2023-01-05 12:44:04,211 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40178311467170713, 'Total loss': 0.40178311467170713} | train loss {'Reaction outcome loss': 0.28400355377021513, 'Total loss': 0.28400355377021513}
2023-01-05 12:44:04,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:04,211 INFO:     Epoch: 64
2023-01-05 12:44:06,364 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37478201389312743, 'Total loss': 0.37478201389312743} | train loss {'Reaction outcome loss': 0.2866310094412963, 'Total loss': 0.2866310094412963}
2023-01-05 12:44:06,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:06,364 INFO:     Epoch: 65
2023-01-05 12:44:08,527 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3726495822270711, 'Total loss': 0.3726495822270711} | train loss {'Reaction outcome loss': 0.28190262420716666, 'Total loss': 0.28190262420716666}
2023-01-05 12:44:08,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:08,527 INFO:     Epoch: 66
2023-01-05 12:44:10,697 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3808972373604774, 'Total loss': 0.3808972373604774} | train loss {'Reaction outcome loss': 0.2797318382958031, 'Total loss': 0.2797318382958031}
2023-01-05 12:44:10,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:10,697 INFO:     Epoch: 67
2023-01-05 12:44:12,940 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3933324247598648, 'Total loss': 0.3933324247598648} | train loss {'Reaction outcome loss': 0.28082350715724885, 'Total loss': 0.28082350715724885}
2023-01-05 12:44:12,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:12,941 INFO:     Epoch: 68
2023-01-05 12:44:15,198 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45164156953493756, 'Total loss': 0.45164156953493756} | train loss {'Reaction outcome loss': 0.2926603285798236, 'Total loss': 0.2926603285798236}
2023-01-05 12:44:15,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:15,198 INFO:     Epoch: 69
2023-01-05 12:44:17,470 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3995521366596222, 'Total loss': 0.3995521366596222} | train loss {'Reaction outcome loss': 0.2733575250055857, 'Total loss': 0.2733575250055857}
2023-01-05 12:44:17,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:17,470 INFO:     Epoch: 70
2023-01-05 12:44:19,706 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41346367498238884, 'Total loss': 0.41346367498238884} | train loss {'Reaction outcome loss': 0.283361675636168, 'Total loss': 0.283361675636168}
2023-01-05 12:44:19,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:19,707 INFO:     Epoch: 71
2023-01-05 12:44:21,948 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3880223512649536, 'Total loss': 0.3880223512649536} | train loss {'Reaction outcome loss': 0.3099067383578665, 'Total loss': 0.3099067383578665}
2023-01-05 12:44:21,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:21,948 INFO:     Epoch: 72
2023-01-05 12:44:24,122 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3814689467350642, 'Total loss': 0.3814689467350642} | train loss {'Reaction outcome loss': 0.27386874905315, 'Total loss': 0.27386874905315}
2023-01-05 12:44:24,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:24,122 INFO:     Epoch: 73
2023-01-05 12:44:26,305 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4002711961666743, 'Total loss': 0.4002711961666743} | train loss {'Reaction outcome loss': 0.2677647105729852, 'Total loss': 0.2677647105729852}
2023-01-05 12:44:26,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:26,306 INFO:     Epoch: 74
2023-01-05 12:44:28,497 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4240174333254496, 'Total loss': 0.4240174333254496} | train loss {'Reaction outcome loss': 0.26346884213684907, 'Total loss': 0.26346884213684907}
2023-01-05 12:44:28,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:28,498 INFO:     Epoch: 75
2023-01-05 12:44:30,654 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.389537180463473, 'Total loss': 0.389537180463473} | train loss {'Reaction outcome loss': 0.2635405467219138, 'Total loss': 0.2635405467219138}
2023-01-05 12:44:30,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:30,655 INFO:     Epoch: 76
2023-01-05 12:44:32,825 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41918162206808723, 'Total loss': 0.41918162206808723} | train loss {'Reaction outcome loss': 0.26123845628443226, 'Total loss': 0.26123845628443226}
2023-01-05 12:44:32,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:32,826 INFO:     Epoch: 77
2023-01-05 12:44:34,992 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39179445505142213, 'Total loss': 0.39179445505142213} | train loss {'Reaction outcome loss': 0.2675410326738147, 'Total loss': 0.2675410326738147}
2023-01-05 12:44:34,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:34,993 INFO:     Epoch: 78
2023-01-05 12:44:37,181 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3941642463207245, 'Total loss': 0.3941642463207245} | train loss {'Reaction outcome loss': 0.2635707467380216, 'Total loss': 0.2635707467380216}
2023-01-05 12:44:37,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:37,183 INFO:     Epoch: 79
2023-01-05 12:44:39,363 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3855726321538289, 'Total loss': 0.3855726321538289} | train loss {'Reaction outcome loss': 0.2777910074489056, 'Total loss': 0.2777910074489056}
2023-01-05 12:44:39,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:39,363 INFO:     Epoch: 80
2023-01-05 12:44:41,546 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3942068248987198, 'Total loss': 0.3942068248987198} | train loss {'Reaction outcome loss': 0.33701674477534665, 'Total loss': 0.33701674477534665}
2023-01-05 12:44:41,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:41,546 INFO:     Epoch: 81
2023-01-05 12:44:43,729 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3986724515755971, 'Total loss': 0.3986724515755971} | train loss {'Reaction outcome loss': 0.28376084107541194, 'Total loss': 0.28376084107541194}
2023-01-05 12:44:43,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:43,730 INFO:     Epoch: 82
2023-01-05 12:44:45,923 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38747796714305877, 'Total loss': 0.38747796714305877} | train loss {'Reaction outcome loss': 0.2755718852487811, 'Total loss': 0.2755718852487811}
2023-01-05 12:44:45,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:45,924 INFO:     Epoch: 83
2023-01-05 12:44:48,121 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37472654779752096, 'Total loss': 0.37472654779752096} | train loss {'Reaction outcome loss': 0.2643690632345776, 'Total loss': 0.2643690632345776}
2023-01-05 12:44:48,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:48,121 INFO:     Epoch: 84
2023-01-05 12:44:50,301 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4154835070172946, 'Total loss': 0.4154835070172946} | train loss {'Reaction outcome loss': 0.26297994235790323, 'Total loss': 0.26297994235790323}
2023-01-05 12:44:50,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:50,301 INFO:     Epoch: 85
2023-01-05 12:44:52,466 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38705403804779054, 'Total loss': 0.38705403804779054} | train loss {'Reaction outcome loss': 0.2559735891873192, 'Total loss': 0.2559735891873192}
2023-01-05 12:44:52,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:52,467 INFO:     Epoch: 86
2023-01-05 12:44:54,641 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40898710787296294, 'Total loss': 0.40898710787296294} | train loss {'Reaction outcome loss': 0.25922371119930465, 'Total loss': 0.25922371119930465}
2023-01-05 12:44:54,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:54,642 INFO:     Epoch: 87
2023-01-05 12:44:56,857 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38861680825551354, 'Total loss': 0.38861680825551354} | train loss {'Reaction outcome loss': 0.2562822251735876, 'Total loss': 0.2562822251735876}
2023-01-05 12:44:56,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:56,858 INFO:     Epoch: 88
2023-01-05 12:44:59,078 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3830866744120916, 'Total loss': 0.3830866744120916} | train loss {'Reaction outcome loss': 0.25476910155671445, 'Total loss': 0.25476910155671445}
2023-01-05 12:44:59,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:44:59,078 INFO:     Epoch: 89
2023-01-05 12:45:01,285 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39315295616785684, 'Total loss': 0.39315295616785684} | train loss {'Reaction outcome loss': 0.2542323930647926, 'Total loss': 0.2542323930647926}
2023-01-05 12:45:01,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:01,286 INFO:     Epoch: 90
2023-01-05 12:45:03,504 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3667334318161011, 'Total loss': 0.3667334318161011} | train loss {'Reaction outcome loss': 0.24756846159963997, 'Total loss': 0.24756846159963997}
2023-01-05 12:45:03,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:03,504 INFO:     Epoch: 91
2023-01-05 12:45:05,707 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3768027645846208, 'Total loss': 0.3768027645846208} | train loss {'Reaction outcome loss': 0.26135606130423106, 'Total loss': 0.26135606130423106}
2023-01-05 12:45:05,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:05,707 INFO:     Epoch: 92
2023-01-05 12:45:07,895 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3542246099561453, 'Total loss': 0.3542246099561453} | train loss {'Reaction outcome loss': 0.24532840746215315, 'Total loss': 0.24532840746215315}
2023-01-05 12:45:07,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:07,896 INFO:     Epoch: 93
2023-01-05 12:45:10,070 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43781585693359376, 'Total loss': 0.43781585693359376} | train loss {'Reaction outcome loss': 0.24814114526616057, 'Total loss': 0.24814114526616057}
2023-01-05 12:45:10,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:10,070 INFO:     Epoch: 94
2023-01-05 12:45:12,241 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42269843419392905, 'Total loss': 0.42269843419392905} | train loss {'Reaction outcome loss': 0.25876053889025596, 'Total loss': 0.25876053889025596}
2023-01-05 12:45:12,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:12,242 INFO:     Epoch: 95
2023-01-05 12:45:14,431 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38756550252437594, 'Total loss': 0.38756550252437594} | train loss {'Reaction outcome loss': 0.2533537508730871, 'Total loss': 0.2533537508730871}
2023-01-05 12:45:14,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:14,432 INFO:     Epoch: 96
2023-01-05 12:45:16,606 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3907947391271591, 'Total loss': 0.3907947391271591} | train loss {'Reaction outcome loss': 0.29987840140334365, 'Total loss': 0.29987840140334365}
2023-01-05 12:45:16,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:16,606 INFO:     Epoch: 97
2023-01-05 12:45:18,789 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41199210584163665, 'Total loss': 0.41199210584163665} | train loss {'Reaction outcome loss': 0.25425374433984543, 'Total loss': 0.25425374433984543}
2023-01-05 12:45:18,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:18,790 INFO:     Epoch: 98
2023-01-05 12:45:20,971 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3941849200675885, 'Total loss': 0.3941849200675885} | train loss {'Reaction outcome loss': 0.252352554951727, 'Total loss': 0.252352554951727}
2023-01-05 12:45:20,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:20,971 INFO:     Epoch: 99
2023-01-05 12:45:23,165 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39913014868895214, 'Total loss': 0.39913014868895214} | train loss {'Reaction outcome loss': 0.27971609408421605, 'Total loss': 0.27971609408421605}
2023-01-05 12:45:23,165 INFO:     Best model found after epoch 54 of 100.
2023-01-05 12:45:23,165 INFO:   Done with stage: TRAINING
2023-01-05 12:45:23,165 INFO:   Starting stage: EVALUATION
2023-01-05 12:45:23,298 INFO:   Done with stage: EVALUATION
2023-01-05 12:45:23,298 INFO:   Leaving out SEQ value Fold_5
2023-01-05 12:45:23,310 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 12:45:23,311 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:45:23,970 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:45:23,970 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:45:24,041 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:45:24,041 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:45:24,041 INFO:     No hyperparam tuning for this model
2023-01-05 12:45:24,041 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:45:24,042 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:45:24,042 INFO:     None feature selector for col prot
2023-01-05 12:45:24,042 INFO:     None feature selector for col prot
2023-01-05 12:45:24,043 INFO:     None feature selector for col prot
2023-01-05 12:45:24,043 INFO:     None feature selector for col chem
2023-01-05 12:45:24,043 INFO:     None feature selector for col chem
2023-01-05 12:45:24,043 INFO:     None feature selector for col chem
2023-01-05 12:45:24,043 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:45:24,043 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:45:24,045 INFO:     Number of params in model 72901
2023-01-05 12:45:24,048 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:45:24,048 INFO:   Starting stage: TRAINING
2023-01-05 12:45:24,109 INFO:     Val loss before train {'Reaction outcome loss': 0.953892449537913, 'Total loss': 0.953892449537913}
2023-01-05 12:45:24,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:24,110 INFO:     Epoch: 0
2023-01-05 12:45:26,299 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8180600901444753, 'Total loss': 0.8180600901444753} | train loss {'Reaction outcome loss': 0.931777790565353, 'Total loss': 0.931777790565353}
2023-01-05 12:45:26,299 INFO:     Found new best model at epoch 0
2023-01-05 12:45:26,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:26,301 INFO:     Epoch: 1
2023-01-05 12:45:28,495 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6462958335876465, 'Total loss': 0.6462958335876465} | train loss {'Reaction outcome loss': 0.7664071113839477, 'Total loss': 0.7664071113839477}
2023-01-05 12:45:28,496 INFO:     Found new best model at epoch 1
2023-01-05 12:45:28,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:28,498 INFO:     Epoch: 2
2023-01-05 12:45:30,673 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5788350820541381, 'Total loss': 0.5788350820541381} | train loss {'Reaction outcome loss': 0.5900536982698992, 'Total loss': 0.5900536982698992}
2023-01-05 12:45:30,674 INFO:     Found new best model at epoch 2
2023-01-05 12:45:30,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:30,675 INFO:     Epoch: 3
2023-01-05 12:45:32,860 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5338287889957428, 'Total loss': 0.5338287889957428} | train loss {'Reaction outcome loss': 0.5409550885215993, 'Total loss': 0.5409550885215993}
2023-01-05 12:45:32,860 INFO:     Found new best model at epoch 3
2023-01-05 12:45:32,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:32,861 INFO:     Epoch: 4
2023-01-05 12:45:35,044 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5278349200884501, 'Total loss': 0.5278349200884501} | train loss {'Reaction outcome loss': 0.5168547556342201, 'Total loss': 0.5168547556342201}
2023-01-05 12:45:35,044 INFO:     Found new best model at epoch 4
2023-01-05 12:45:35,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:35,045 INFO:     Epoch: 5
2023-01-05 12:45:37,220 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5352723260720571, 'Total loss': 0.5352723260720571} | train loss {'Reaction outcome loss': 0.5037349903088615, 'Total loss': 0.5037349903088615}
2023-01-05 12:45:37,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:37,222 INFO:     Epoch: 6
2023-01-05 12:45:39,400 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5436911225318909, 'Total loss': 0.5436911225318909} | train loss {'Reaction outcome loss': 0.4942847399935395, 'Total loss': 0.4942847399935395}
2023-01-05 12:45:39,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:39,401 INFO:     Epoch: 7
2023-01-05 12:45:41,571 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5221618175506592, 'Total loss': 0.5221618175506592} | train loss {'Reaction outcome loss': 0.48281925852117985, 'Total loss': 0.48281925852117985}
2023-01-05 12:45:41,571 INFO:     Found new best model at epoch 7
2023-01-05 12:45:41,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:41,572 INFO:     Epoch: 8
2023-01-05 12:45:43,761 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5420021076997121, 'Total loss': 0.5420021076997121} | train loss {'Reaction outcome loss': 0.4792363456440316, 'Total loss': 0.4792363456440316}
2023-01-05 12:45:43,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:43,762 INFO:     Epoch: 9
2023-01-05 12:45:45,961 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5321331103642781, 'Total loss': 0.5321331103642781} | train loss {'Reaction outcome loss': 0.4704374801165791, 'Total loss': 0.4704374801165791}
2023-01-05 12:45:45,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:45,961 INFO:     Epoch: 10
2023-01-05 12:45:48,143 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5271897693475087, 'Total loss': 0.5271897693475087} | train loss {'Reaction outcome loss': 0.4639377390649775, 'Total loss': 0.4639377390649775}
2023-01-05 12:45:48,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:48,143 INFO:     Epoch: 11
2023-01-05 12:45:50,390 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5193767289320628, 'Total loss': 0.5193767289320628} | train loss {'Reaction outcome loss': 0.4640145483645291, 'Total loss': 0.4640145483645291}
2023-01-05 12:45:50,390 INFO:     Found new best model at epoch 11
2023-01-05 12:45:50,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:50,391 INFO:     Epoch: 12
2023-01-05 12:45:52,605 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5440805395444234, 'Total loss': 0.5440805395444234} | train loss {'Reaction outcome loss': 0.4536449521349656, 'Total loss': 0.4536449521349656}
2023-01-05 12:45:52,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:52,605 INFO:     Epoch: 13
2023-01-05 12:45:54,856 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5314037601153055, 'Total loss': 0.5314037601153055} | train loss {'Reaction outcome loss': 0.45202849256648053, 'Total loss': 0.45202849256648053}
2023-01-05 12:45:54,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:54,857 INFO:     Epoch: 14
2023-01-05 12:45:57,094 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5340032716592152, 'Total loss': 0.5340032716592152} | train loss {'Reaction outcome loss': 0.44914988821056345, 'Total loss': 0.44914988821056345}
2023-01-05 12:45:57,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:57,095 INFO:     Epoch: 15
2023-01-05 12:45:59,270 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5154600004355113, 'Total loss': 0.5154600004355113} | train loss {'Reaction outcome loss': 0.4453450711948347, 'Total loss': 0.4453450711948347}
2023-01-05 12:45:59,270 INFO:     Found new best model at epoch 15
2023-01-05 12:45:59,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:45:59,271 INFO:     Epoch: 16
2023-01-05 12:46:01,472 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5333461960156759, 'Total loss': 0.5333461960156759} | train loss {'Reaction outcome loss': 0.4390856109909202, 'Total loss': 0.4390856109909202}
2023-01-05 12:46:01,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:01,472 INFO:     Epoch: 17
2023-01-05 12:46:03,674 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5296378632386526, 'Total loss': 0.5296378632386526} | train loss {'Reaction outcome loss': 0.43666721436628797, 'Total loss': 0.43666721436628797}
2023-01-05 12:46:03,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:03,674 INFO:     Epoch: 18
2023-01-05 12:46:05,861 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5004013657569886, 'Total loss': 0.5004013657569886} | train loss {'Reaction outcome loss': 0.43041816305382585, 'Total loss': 0.43041816305382585}
2023-01-05 12:46:05,862 INFO:     Found new best model at epoch 18
2023-01-05 12:46:05,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:05,863 INFO:     Epoch: 19
2023-01-05 12:46:08,070 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5265723168849945, 'Total loss': 0.5265723168849945} | train loss {'Reaction outcome loss': 0.4312447716720698, 'Total loss': 0.4312447716720698}
2023-01-05 12:46:08,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:08,070 INFO:     Epoch: 20
2023-01-05 12:46:10,275 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5248998274405797, 'Total loss': 0.5248998274405797} | train loss {'Reaction outcome loss': 0.4243217576765842, 'Total loss': 0.4243217576765842}
2023-01-05 12:46:10,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:10,275 INFO:     Epoch: 21
2023-01-05 12:46:12,459 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5008251130580902, 'Total loss': 0.5008251130580902} | train loss {'Reaction outcome loss': 0.4157696389979834, 'Total loss': 0.4157696389979834}
2023-01-05 12:46:12,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:12,459 INFO:     Epoch: 22
2023-01-05 12:46:14,652 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5142343799273174, 'Total loss': 0.5142343799273174} | train loss {'Reaction outcome loss': 0.411981083748573, 'Total loss': 0.411981083748573}
2023-01-05 12:46:14,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:14,654 INFO:     Epoch: 23
2023-01-05 12:46:16,802 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5125817517439525, 'Total loss': 0.5125817517439525} | train loss {'Reaction outcome loss': 0.40952744375282246, 'Total loss': 0.40952744375282246}
2023-01-05 12:46:16,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:16,802 INFO:     Epoch: 24
2023-01-05 12:46:18,986 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.512531441450119, 'Total loss': 0.512531441450119} | train loss {'Reaction outcome loss': 0.4096564823754858, 'Total loss': 0.4096564823754858}
2023-01-05 12:46:18,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:18,986 INFO:     Epoch: 25
2023-01-05 12:46:21,162 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48364036679267886, 'Total loss': 0.48364036679267886} | train loss {'Reaction outcome loss': 0.40310550365422176, 'Total loss': 0.40310550365422176}
2023-01-05 12:46:21,163 INFO:     Found new best model at epoch 25
2023-01-05 12:46:21,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:21,165 INFO:     Epoch: 26
2023-01-05 12:46:23,362 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4918913046518962, 'Total loss': 0.4918913046518962} | train loss {'Reaction outcome loss': 0.39811937734215697, 'Total loss': 0.39811937734215697}
2023-01-05 12:46:23,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:23,362 INFO:     Epoch: 27
2023-01-05 12:46:25,560 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5085822602113088, 'Total loss': 0.5085822602113088} | train loss {'Reaction outcome loss': 0.397217186873893, 'Total loss': 0.397217186873893}
2023-01-05 12:46:25,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:25,560 INFO:     Epoch: 28
2023-01-05 12:46:27,742 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5083040843407313, 'Total loss': 0.5083040843407313} | train loss {'Reaction outcome loss': 0.39409944191844026, 'Total loss': 0.39409944191844026}
2023-01-05 12:46:27,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:27,742 INFO:     Epoch: 29
2023-01-05 12:46:29,946 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5082295467456182, 'Total loss': 0.5082295467456182} | train loss {'Reaction outcome loss': 0.3821530605965573, 'Total loss': 0.3821530605965573}
2023-01-05 12:46:29,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:29,946 INFO:     Epoch: 30
2023-01-05 12:46:32,136 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4939647436141968, 'Total loss': 0.4939647436141968} | train loss {'Reaction outcome loss': 0.3835902315856963, 'Total loss': 0.3835902315856963}
2023-01-05 12:46:32,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:32,136 INFO:     Epoch: 31
2023-01-05 12:46:34,328 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5401779154936472, 'Total loss': 0.5401779154936472} | train loss {'Reaction outcome loss': 0.37822553526193226, 'Total loss': 0.37822553526193226}
2023-01-05 12:46:34,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:34,329 INFO:     Epoch: 32
2023-01-05 12:46:36,560 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5062209904193878, 'Total loss': 0.5062209904193878} | train loss {'Reaction outcome loss': 0.3731356667697645, 'Total loss': 0.3731356667697645}
2023-01-05 12:46:36,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:36,561 INFO:     Epoch: 33
2023-01-05 12:46:38,739 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5236572802066803, 'Total loss': 0.5236572802066803} | train loss {'Reaction outcome loss': 0.3747744983337846, 'Total loss': 0.3747744983337846}
2023-01-05 12:46:38,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:38,739 INFO:     Epoch: 34
2023-01-05 12:46:40,916 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5038736879825592, 'Total loss': 0.5038736879825592} | train loss {'Reaction outcome loss': 0.36777545414891916, 'Total loss': 0.36777545414891916}
2023-01-05 12:46:40,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:40,916 INFO:     Epoch: 35
2023-01-05 12:46:43,102 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5131730804840724, 'Total loss': 0.5131730804840724} | train loss {'Reaction outcome loss': 0.3610458428625165, 'Total loss': 0.3610458428625165}
2023-01-05 12:46:43,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:43,102 INFO:     Epoch: 36
2023-01-05 12:46:45,274 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4995482583840688, 'Total loss': 0.4995482583840688} | train loss {'Reaction outcome loss': 0.3638298540285348, 'Total loss': 0.3638298540285348}
2023-01-05 12:46:45,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:45,275 INFO:     Epoch: 37
2023-01-05 12:46:47,488 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5216261833906174, 'Total loss': 0.5216261833906174} | train loss {'Reaction outcome loss': 0.3574457650311587, 'Total loss': 0.3574457650311587}
2023-01-05 12:46:47,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:47,488 INFO:     Epoch: 38
2023-01-05 12:46:49,653 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5037051022052765, 'Total loss': 0.5037051022052765} | train loss {'Reaction outcome loss': 0.3562914249403167, 'Total loss': 0.3562914249403167}
2023-01-05 12:46:49,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:49,653 INFO:     Epoch: 39
2023-01-05 12:46:51,812 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4936494827270508, 'Total loss': 0.4936494827270508} | train loss {'Reaction outcome loss': 0.3556792715745928, 'Total loss': 0.3556792715745928}
2023-01-05 12:46:51,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:51,813 INFO:     Epoch: 40
2023-01-05 12:46:53,974 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4897428770860036, 'Total loss': 0.4897428770860036} | train loss {'Reaction outcome loss': 0.3414100270839374, 'Total loss': 0.3414100270839374}
2023-01-05 12:46:53,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:53,974 INFO:     Epoch: 41
2023-01-05 12:46:56,143 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5271024445692698, 'Total loss': 0.5271024445692698} | train loss {'Reaction outcome loss': 0.34790239649881954, 'Total loss': 0.34790239649881954}
2023-01-05 12:46:56,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:56,143 INFO:     Epoch: 42
2023-01-05 12:46:58,306 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4905572553475698, 'Total loss': 0.4905572553475698} | train loss {'Reaction outcome loss': 0.3393365650400788, 'Total loss': 0.3393365650400788}
2023-01-05 12:46:58,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:46:58,306 INFO:     Epoch: 43
2023-01-05 12:47:00,479 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48170774479707085, 'Total loss': 0.48170774479707085} | train loss {'Reaction outcome loss': 0.33487546808399016, 'Total loss': 0.33487546808399016}
2023-01-05 12:47:00,479 INFO:     Found new best model at epoch 43
2023-01-05 12:47:00,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:00,481 INFO:     Epoch: 44
2023-01-05 12:47:02,638 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4861728330453237, 'Total loss': 0.4861728330453237} | train loss {'Reaction outcome loss': 0.3390271844281832, 'Total loss': 0.3390271844281832}
2023-01-05 12:47:02,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:02,638 INFO:     Epoch: 45
2023-01-05 12:47:04,794 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4650466759999593, 'Total loss': 0.4650466759999593} | train loss {'Reaction outcome loss': 0.330234241399524, 'Total loss': 0.330234241399524}
2023-01-05 12:47:04,795 INFO:     Found new best model at epoch 45
2023-01-05 12:47:04,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:04,797 INFO:     Epoch: 46
2023-01-05 12:47:06,971 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4862242917219798, 'Total loss': 0.4862242917219798} | train loss {'Reaction outcome loss': 0.3324243185725668, 'Total loss': 0.3324243185725668}
2023-01-05 12:47:06,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:06,972 INFO:     Epoch: 47
2023-01-05 12:47:09,137 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4809370249509811, 'Total loss': 0.4809370249509811} | train loss {'Reaction outcome loss': 0.32497617619831637, 'Total loss': 0.32497617619831637}
2023-01-05 12:47:09,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:09,137 INFO:     Epoch: 48
2023-01-05 12:47:11,299 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46784920891126, 'Total loss': 0.46784920891126} | train loss {'Reaction outcome loss': 0.32785513744242356, 'Total loss': 0.32785513744242356}
2023-01-05 12:47:11,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:11,300 INFO:     Epoch: 49
2023-01-05 12:47:13,473 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49532973269621533, 'Total loss': 0.49532973269621533} | train loss {'Reaction outcome loss': 0.31393138608401, 'Total loss': 0.31393138608401}
2023-01-05 12:47:13,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:13,473 INFO:     Epoch: 50
2023-01-05 12:47:15,617 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46996988157431285, 'Total loss': 0.46996988157431285} | train loss {'Reaction outcome loss': 0.31830695561983957, 'Total loss': 0.31830695561983957}
2023-01-05 12:47:15,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:15,618 INFO:     Epoch: 51
2023-01-05 12:47:17,789 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47005292971928914, 'Total loss': 0.47005292971928914} | train loss {'Reaction outcome loss': 0.32165328937747417, 'Total loss': 0.32165328937747417}
2023-01-05 12:47:17,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:17,790 INFO:     Epoch: 52
2023-01-05 12:47:19,945 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4938336928685506, 'Total loss': 0.4938336928685506} | train loss {'Reaction outcome loss': 0.31175801136433434, 'Total loss': 0.31175801136433434}
2023-01-05 12:47:19,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:19,945 INFO:     Epoch: 53
2023-01-05 12:47:22,128 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49151010711987814, 'Total loss': 0.49151010711987814} | train loss {'Reaction outcome loss': 0.31095230335954727, 'Total loss': 0.31095230335954727}
2023-01-05 12:47:22,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:22,129 INFO:     Epoch: 54
2023-01-05 12:47:24,300 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4792506764332453, 'Total loss': 0.4792506764332453} | train loss {'Reaction outcome loss': 0.30929504169507577, 'Total loss': 0.30929504169507577}
2023-01-05 12:47:24,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:24,300 INFO:     Epoch: 55
2023-01-05 12:47:26,470 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48667959968249, 'Total loss': 0.48667959968249} | train loss {'Reaction outcome loss': 0.30670962240614186, 'Total loss': 0.30670962240614186}
2023-01-05 12:47:26,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:26,470 INFO:     Epoch: 56
2023-01-05 12:47:28,672 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4924863398075104, 'Total loss': 0.4924863398075104} | train loss {'Reaction outcome loss': 0.30366096033677725, 'Total loss': 0.30366096033677725}
2023-01-05 12:47:28,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:28,673 INFO:     Epoch: 57
2023-01-05 12:47:30,858 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5101061175266902, 'Total loss': 0.5101061175266902} | train loss {'Reaction outcome loss': 0.2926973362826483, 'Total loss': 0.2926973362826483}
2023-01-05 12:47:30,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:30,859 INFO:     Epoch: 58
2023-01-05 12:47:33,065 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4868790715932846, 'Total loss': 0.4868790715932846} | train loss {'Reaction outcome loss': 0.2980490115467822, 'Total loss': 0.2980490115467822}
2023-01-05 12:47:33,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:33,065 INFO:     Epoch: 59
2023-01-05 12:47:35,280 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49176963965098064, 'Total loss': 0.49176963965098064} | train loss {'Reaction outcome loss': 0.2999595308925163, 'Total loss': 0.2999595308925163}
2023-01-05 12:47:35,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:35,281 INFO:     Epoch: 60
2023-01-05 12:47:37,456 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46565239429473876, 'Total loss': 0.46565239429473876} | train loss {'Reaction outcome loss': 0.2958880290254574, 'Total loss': 0.2958880290254574}
2023-01-05 12:47:37,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:37,456 INFO:     Epoch: 61
2023-01-05 12:47:39,642 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.514173279205958, 'Total loss': 0.514173279205958} | train loss {'Reaction outcome loss': 0.2853753228372615, 'Total loss': 0.2853753228372615}
2023-01-05 12:47:39,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:39,642 INFO:     Epoch: 62
2023-01-05 12:47:41,823 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.467795201142629, 'Total loss': 0.467795201142629} | train loss {'Reaction outcome loss': 0.2893992339929949, 'Total loss': 0.2893992339929949}
2023-01-05 12:47:41,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:41,824 INFO:     Epoch: 63
2023-01-05 12:47:43,781 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48303205172220864, 'Total loss': 0.48303205172220864} | train loss {'Reaction outcome loss': 0.2835450366892539, 'Total loss': 0.2835450366892539}
2023-01-05 12:47:43,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:43,781 INFO:     Epoch: 64
2023-01-05 12:47:45,946 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46247191429138185, 'Total loss': 0.46247191429138185} | train loss {'Reaction outcome loss': 0.285146206859432, 'Total loss': 0.285146206859432}
2023-01-05 12:47:45,946 INFO:     Found new best model at epoch 64
2023-01-05 12:47:45,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:45,948 INFO:     Epoch: 65
2023-01-05 12:47:48,108 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4626151263713837, 'Total loss': 0.4626151263713837} | train loss {'Reaction outcome loss': 0.29067857100860306, 'Total loss': 0.29067857100860306}
2023-01-05 12:47:48,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:48,109 INFO:     Epoch: 66
2023-01-05 12:47:50,273 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4941292683283488, 'Total loss': 0.4941292683283488} | train loss {'Reaction outcome loss': 0.28508425902050755, 'Total loss': 0.28508425902050755}
2023-01-05 12:47:50,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:50,275 INFO:     Epoch: 67
2023-01-05 12:47:52,436 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49043527444203694, 'Total loss': 0.49043527444203694} | train loss {'Reaction outcome loss': 0.2851513624863719, 'Total loss': 0.2851513624863719}
2023-01-05 12:47:52,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:52,437 INFO:     Epoch: 68
2023-01-05 12:47:54,614 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49910191098848977, 'Total loss': 0.49910191098848977} | train loss {'Reaction outcome loss': 0.2874840047170109, 'Total loss': 0.2874840047170109}
2023-01-05 12:47:54,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:54,614 INFO:     Epoch: 69
2023-01-05 12:47:56,824 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47041297356287637, 'Total loss': 0.47041297356287637} | train loss {'Reaction outcome loss': 0.28662089616167846, 'Total loss': 0.28662089616167846}
2023-01-05 12:47:56,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:56,826 INFO:     Epoch: 70
2023-01-05 12:47:59,011 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44806899031003317, 'Total loss': 0.44806899031003317} | train loss {'Reaction outcome loss': 0.2748430887983594, 'Total loss': 0.2748430887983594}
2023-01-05 12:47:59,012 INFO:     Found new best model at epoch 70
2023-01-05 12:47:59,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:47:59,013 INFO:     Epoch: 71
2023-01-05 12:48:01,195 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5238903681437175, 'Total loss': 0.5238903681437175} | train loss {'Reaction outcome loss': 0.2747484958639859, 'Total loss': 0.2747484958639859}
2023-01-05 12:48:01,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:01,195 INFO:     Epoch: 72
2023-01-05 12:48:03,384 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.481638133029143, 'Total loss': 0.481638133029143} | train loss {'Reaction outcome loss': 0.27457931245061895, 'Total loss': 0.27457931245061895}
2023-01-05 12:48:03,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:03,384 INFO:     Epoch: 73
2023-01-05 12:48:05,549 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4841858267784119, 'Total loss': 0.4841858267784119} | train loss {'Reaction outcome loss': 0.27774669036322985, 'Total loss': 0.27774669036322985}
2023-01-05 12:48:05,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:05,550 INFO:     Epoch: 74
2023-01-05 12:48:07,719 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4716730535030365, 'Total loss': 0.4716730535030365} | train loss {'Reaction outcome loss': 0.2824603771716894, 'Total loss': 0.2824603771716894}
2023-01-05 12:48:07,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:07,719 INFO:     Epoch: 75
2023-01-05 12:48:09,921 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4908165939152241, 'Total loss': 0.4908165939152241} | train loss {'Reaction outcome loss': 0.2750677214767313, 'Total loss': 0.2750677214767313}
2023-01-05 12:48:09,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:09,922 INFO:     Epoch: 76
2023-01-05 12:48:12,086 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5140780548254649, 'Total loss': 0.5140780548254649} | train loss {'Reaction outcome loss': 0.2729546118406613, 'Total loss': 0.2729546118406613}
2023-01-05 12:48:12,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:12,086 INFO:     Epoch: 77
2023-01-05 12:48:14,250 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5163623402516048, 'Total loss': 0.5163623402516048} | train loss {'Reaction outcome loss': 0.27271210018289865, 'Total loss': 0.27271210018289865}
2023-01-05 12:48:14,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:14,250 INFO:     Epoch: 78
2023-01-05 12:48:16,426 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49079189300537107, 'Total loss': 0.49079189300537107} | train loss {'Reaction outcome loss': 0.26611306352224806, 'Total loss': 0.26611306352224806}
2023-01-05 12:48:16,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:16,426 INFO:     Epoch: 79
2023-01-05 12:48:18,582 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47300683657328285, 'Total loss': 0.47300683657328285} | train loss {'Reaction outcome loss': 0.265087521463525, 'Total loss': 0.265087521463525}
2023-01-05 12:48:18,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:18,582 INFO:     Epoch: 80
2023-01-05 12:48:20,770 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.501262096563975, 'Total loss': 0.501262096563975} | train loss {'Reaction outcome loss': 0.2670455975626135, 'Total loss': 0.2670455975626135}
2023-01-05 12:48:20,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:20,770 INFO:     Epoch: 81
2023-01-05 12:48:22,949 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45634098798036576, 'Total loss': 0.45634098798036576} | train loss {'Reaction outcome loss': 0.26901738691254645, 'Total loss': 0.26901738691254645}
2023-01-05 12:48:22,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:22,950 INFO:     Epoch: 82
2023-01-05 12:48:25,122 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45227751731872556, 'Total loss': 0.45227751731872556} | train loss {'Reaction outcome loss': 0.2691114273809892, 'Total loss': 0.2691114273809892}
2023-01-05 12:48:25,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:25,122 INFO:     Epoch: 83
2023-01-05 12:48:27,303 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5020556921760241, 'Total loss': 0.5020556921760241} | train loss {'Reaction outcome loss': 0.2677591578086791, 'Total loss': 0.2677591578086791}
2023-01-05 12:48:27,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:27,304 INFO:     Epoch: 84
2023-01-05 12:48:29,475 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5155338227748871, 'Total loss': 0.5155338227748871} | train loss {'Reaction outcome loss': 0.2641450471180871, 'Total loss': 0.2641450471180871}
2023-01-05 12:48:29,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:29,475 INFO:     Epoch: 85
2023-01-05 12:48:31,647 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48114084055026374, 'Total loss': 0.48114084055026374} | train loss {'Reaction outcome loss': 0.2667216810831524, 'Total loss': 0.2667216810831524}
2023-01-05 12:48:31,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:31,648 INFO:     Epoch: 86
2023-01-05 12:48:33,809 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48815335432688395, 'Total loss': 0.48815335432688395} | train loss {'Reaction outcome loss': 0.2550720176743579, 'Total loss': 0.2550720176743579}
2023-01-05 12:48:33,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:33,810 INFO:     Epoch: 87
2023-01-05 12:48:35,987 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45893940031528474, 'Total loss': 0.45893940031528474} | train loss {'Reaction outcome loss': 0.26129801600620095, 'Total loss': 0.26129801600620095}
2023-01-05 12:48:35,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:35,987 INFO:     Epoch: 88
2023-01-05 12:48:38,149 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5160186598698299, 'Total loss': 0.5160186598698299} | train loss {'Reaction outcome loss': 0.26068350540252155, 'Total loss': 0.26068350540252155}
2023-01-05 12:48:38,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:38,149 INFO:     Epoch: 89
2023-01-05 12:48:40,325 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.464463080962499, 'Total loss': 0.464463080962499} | train loss {'Reaction outcome loss': 0.26293629285835723, 'Total loss': 0.26293629285835723}
2023-01-05 12:48:40,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:40,325 INFO:     Epoch: 90
2023-01-05 12:48:42,500 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49733404914538065, 'Total loss': 0.49733404914538065} | train loss {'Reaction outcome loss': 0.2494767772215368, 'Total loss': 0.2494767772215368}
2023-01-05 12:48:42,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:42,500 INFO:     Epoch: 91
2023-01-05 12:48:44,675 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47249442636966704, 'Total loss': 0.47249442636966704} | train loss {'Reaction outcome loss': 0.25722954843179846, 'Total loss': 0.25722954843179846}
2023-01-05 12:48:44,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:44,675 INFO:     Epoch: 92
2023-01-05 12:48:46,861 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46775393684705097, 'Total loss': 0.46775393684705097} | train loss {'Reaction outcome loss': 0.2583439355373167, 'Total loss': 0.2583439355373167}
2023-01-05 12:48:46,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:46,862 INFO:     Epoch: 93
2023-01-05 12:48:49,047 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4872691869735718, 'Total loss': 0.4872691869735718} | train loss {'Reaction outcome loss': 0.2580096449178479, 'Total loss': 0.2580096449178479}
2023-01-05 12:48:49,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:49,047 INFO:     Epoch: 94
2023-01-05 12:48:51,205 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47438569118579227, 'Total loss': 0.47438569118579227} | train loss {'Reaction outcome loss': 0.255933051088334, 'Total loss': 0.255933051088334}
2023-01-05 12:48:51,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:51,205 INFO:     Epoch: 95
2023-01-05 12:48:53,382 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4966976404190063, 'Total loss': 0.4966976404190063} | train loss {'Reaction outcome loss': 0.24622683486622163, 'Total loss': 0.24622683486622163}
2023-01-05 12:48:53,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:53,382 INFO:     Epoch: 96
2023-01-05 12:48:55,586 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4591383477052053, 'Total loss': 0.4591383477052053} | train loss {'Reaction outcome loss': 0.24558326316869647, 'Total loss': 0.24558326316869647}
2023-01-05 12:48:55,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:55,586 INFO:     Epoch: 97
2023-01-05 12:48:57,801 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5286096215248108, 'Total loss': 0.5286096215248108} | train loss {'Reaction outcome loss': 0.25192623025324157, 'Total loss': 0.25192623025324157}
2023-01-05 12:48:57,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:57,801 INFO:     Epoch: 98
2023-01-05 12:48:59,993 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.475941198070844, 'Total loss': 0.475941198070844} | train loss {'Reaction outcome loss': 0.24566898373920565, 'Total loss': 0.24566898373920565}
2023-01-05 12:48:59,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:48:59,994 INFO:     Epoch: 99
2023-01-05 12:49:02,194 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4800260295470556, 'Total loss': 0.4800260295470556} | train loss {'Reaction outcome loss': 0.24631849958120916, 'Total loss': 0.24631849958120916}
2023-01-05 12:49:02,196 INFO:     Best model found after epoch 71 of 100.
2023-01-05 12:49:02,196 INFO:   Done with stage: TRAINING
2023-01-05 12:49:02,196 INFO:   Starting stage: EVALUATION
2023-01-05 12:49:02,323 INFO:   Done with stage: EVALUATION
2023-01-05 12:49:02,323 INFO:   Leaving out SEQ value Fold_6
2023-01-05 12:49:02,336 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 12:49:02,336 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:49:02,993 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:49:02,993 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:49:03,064 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:49:03,064 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:49:03,064 INFO:     No hyperparam tuning for this model
2023-01-05 12:49:03,064 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:49:03,064 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:49:03,065 INFO:     None feature selector for col prot
2023-01-05 12:49:03,065 INFO:     None feature selector for col prot
2023-01-05 12:49:03,065 INFO:     None feature selector for col prot
2023-01-05 12:49:03,066 INFO:     None feature selector for col chem
2023-01-05 12:49:03,066 INFO:     None feature selector for col chem
2023-01-05 12:49:03,066 INFO:     None feature selector for col chem
2023-01-05 12:49:03,066 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:49:03,066 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:49:03,067 INFO:     Number of params in model 72901
2023-01-05 12:49:03,071 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:49:03,071 INFO:   Starting stage: TRAINING
2023-01-05 12:49:03,130 INFO:     Val loss before train {'Reaction outcome loss': 0.9187795082728069, 'Total loss': 0.9187795082728069}
2023-01-05 12:49:03,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:03,130 INFO:     Epoch: 0
2023-01-05 12:49:05,296 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7329135258992513, 'Total loss': 0.7329135258992513} | train loss {'Reaction outcome loss': 0.9066750129637735, 'Total loss': 0.9066750129637735}
2023-01-05 12:49:05,296 INFO:     Found new best model at epoch 0
2023-01-05 12:49:05,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:05,297 INFO:     Epoch: 1
2023-01-05 12:49:07,465 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5482132057348887, 'Total loss': 0.5482132057348887} | train loss {'Reaction outcome loss': 0.7019589074789833, 'Total loss': 0.7019589074789833}
2023-01-05 12:49:07,465 INFO:     Found new best model at epoch 1
2023-01-05 12:49:07,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:07,467 INFO:     Epoch: 2
2023-01-05 12:49:09,650 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5271701316038767, 'Total loss': 0.5271701316038767} | train loss {'Reaction outcome loss': 0.5656358185980724, 'Total loss': 0.5656358185980724}
2023-01-05 12:49:09,651 INFO:     Found new best model at epoch 2
2023-01-05 12:49:09,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:09,652 INFO:     Epoch: 3
2023-01-05 12:49:11,823 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5023717204729716, 'Total loss': 0.5023717204729716} | train loss {'Reaction outcome loss': 0.5272254550607626, 'Total loss': 0.5272254550607626}
2023-01-05 12:49:11,823 INFO:     Found new best model at epoch 3
2023-01-05 12:49:11,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:11,825 INFO:     Epoch: 4
2023-01-05 12:49:14,025 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4814489205678304, 'Total loss': 0.4814489205678304} | train loss {'Reaction outcome loss': 0.5046261338120334, 'Total loss': 0.5046261338120334}
2023-01-05 12:49:14,025 INFO:     Found new best model at epoch 4
2023-01-05 12:49:14,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:14,026 INFO:     Epoch: 5
2023-01-05 12:49:16,206 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4859653294086456, 'Total loss': 0.4859653294086456} | train loss {'Reaction outcome loss': 0.4979775566809444, 'Total loss': 0.4979775566809444}
2023-01-05 12:49:16,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:16,206 INFO:     Epoch: 6
2023-01-05 12:49:18,375 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4691897571086884, 'Total loss': 0.4691897571086884} | train loss {'Reaction outcome loss': 0.4848158922759204, 'Total loss': 0.4848158922759204}
2023-01-05 12:49:18,376 INFO:     Found new best model at epoch 6
2023-01-05 12:49:18,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:18,377 INFO:     Epoch: 7
2023-01-05 12:49:20,512 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46880880892276766, 'Total loss': 0.46880880892276766} | train loss {'Reaction outcome loss': 0.47429375006188557, 'Total loss': 0.47429375006188557}
2023-01-05 12:49:20,512 INFO:     Found new best model at epoch 7
2023-01-05 12:49:20,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:20,513 INFO:     Epoch: 8
2023-01-05 12:49:22,654 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4608141094446182, 'Total loss': 0.4608141094446182} | train loss {'Reaction outcome loss': 0.47447866744728295, 'Total loss': 0.47447866744728295}
2023-01-05 12:49:22,655 INFO:     Found new best model at epoch 8
2023-01-05 12:49:22,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:22,656 INFO:     Epoch: 9
2023-01-05 12:49:24,839 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4685764153798421, 'Total loss': 0.4685764153798421} | train loss {'Reaction outcome loss': 0.46338115164519217, 'Total loss': 0.46338115164519217}
2023-01-05 12:49:24,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:24,839 INFO:     Epoch: 10
2023-01-05 12:49:27,009 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45310859282811483, 'Total loss': 0.45310859282811483} | train loss {'Reaction outcome loss': 0.4606066187204867, 'Total loss': 0.4606066187204867}
2023-01-05 12:49:27,010 INFO:     Found new best model at epoch 10
2023-01-05 12:49:27,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:27,011 INFO:     Epoch: 11
2023-01-05 12:49:29,151 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46923528909683226, 'Total loss': 0.46923528909683226} | train loss {'Reaction outcome loss': 0.45393066562792883, 'Total loss': 0.45393066562792883}
2023-01-05 12:49:29,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:29,152 INFO:     Epoch: 12
2023-01-05 12:49:31,303 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4358989963928858, 'Total loss': 0.4358989963928858} | train loss {'Reaction outcome loss': 0.44514477790908263, 'Total loss': 0.44514477790908263}
2023-01-05 12:49:31,304 INFO:     Found new best model at epoch 12
2023-01-05 12:49:31,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:31,305 INFO:     Epoch: 13
2023-01-05 12:49:33,472 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4585725426673889, 'Total loss': 0.4585725426673889} | train loss {'Reaction outcome loss': 0.4411038629414803, 'Total loss': 0.4411038629414803}
2023-01-05 12:49:33,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:33,472 INFO:     Epoch: 14
2023-01-05 12:49:35,640 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4471878538529078, 'Total loss': 0.4471878538529078} | train loss {'Reaction outcome loss': 0.4395369707946313, 'Total loss': 0.4395369707946313}
2023-01-05 12:49:35,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:35,641 INFO:     Epoch: 15
2023-01-05 12:49:37,799 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4401760617891947, 'Total loss': 0.4401760617891947} | train loss {'Reaction outcome loss': 0.4330178194743201, 'Total loss': 0.4330178194743201}
2023-01-05 12:49:37,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:37,801 INFO:     Epoch: 16
2023-01-05 12:49:39,942 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.437711031238238, 'Total loss': 0.437711031238238} | train loss {'Reaction outcome loss': 0.42781810930489633, 'Total loss': 0.42781810930489633}
2023-01-05 12:49:39,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:39,942 INFO:     Epoch: 17
2023-01-05 12:49:42,099 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4502844015757243, 'Total loss': 0.4502844015757243} | train loss {'Reaction outcome loss': 0.4220210150529762, 'Total loss': 0.4220210150529762}
2023-01-05 12:49:42,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:42,099 INFO:     Epoch: 18
2023-01-05 12:49:44,266 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4559111475944519, 'Total loss': 0.4559111475944519} | train loss {'Reaction outcome loss': 0.4189804956747306, 'Total loss': 0.4189804956747306}
2023-01-05 12:49:44,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:44,267 INFO:     Epoch: 19
2023-01-05 12:49:46,413 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43176246583461764, 'Total loss': 0.43176246583461764} | train loss {'Reaction outcome loss': 0.4108253028579998, 'Total loss': 0.4108253028579998}
2023-01-05 12:49:46,413 INFO:     Found new best model at epoch 19
2023-01-05 12:49:46,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:46,414 INFO:     Epoch: 20
2023-01-05 12:49:48,558 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4636334170897802, 'Total loss': 0.4636334170897802} | train loss {'Reaction outcome loss': 0.41590933001428737, 'Total loss': 0.41590933001428737}
2023-01-05 12:49:48,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:48,559 INFO:     Epoch: 21
2023-01-05 12:49:50,716 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4891667614380519, 'Total loss': 0.4891667614380519} | train loss {'Reaction outcome loss': 0.4080867967181688, 'Total loss': 0.4080867967181688}
2023-01-05 12:49:50,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:50,716 INFO:     Epoch: 22
2023-01-05 12:49:52,885 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42406649788220724, 'Total loss': 0.42406649788220724} | train loss {'Reaction outcome loss': 0.40555569637122996, 'Total loss': 0.40555569637122996}
2023-01-05 12:49:52,885 INFO:     Found new best model at epoch 22
2023-01-05 12:49:52,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:52,886 INFO:     Epoch: 23
2023-01-05 12:49:55,053 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4466097300251325, 'Total loss': 0.4466097300251325} | train loss {'Reaction outcome loss': 0.4018774424487933, 'Total loss': 0.4018774424487933}
2023-01-05 12:49:55,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:55,053 INFO:     Epoch: 24
2023-01-05 12:49:57,209 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42806782325108844, 'Total loss': 0.42806782325108844} | train loss {'Reaction outcome loss': 0.39280641074914363, 'Total loss': 0.39280641074914363}
2023-01-05 12:49:57,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:57,210 INFO:     Epoch: 25
2023-01-05 12:49:59,366 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4283037881056468, 'Total loss': 0.4283037881056468} | train loss {'Reaction outcome loss': 0.39032993960574214, 'Total loss': 0.39032993960574214}
2023-01-05 12:49:59,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:49:59,366 INFO:     Epoch: 26
2023-01-05 12:50:01,536 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4459113597869873, 'Total loss': 0.4459113597869873} | train loss {'Reaction outcome loss': 0.3841194183118507, 'Total loss': 0.3841194183118507}
2023-01-05 12:50:01,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:01,537 INFO:     Epoch: 27
2023-01-05 12:50:03,697 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45418163339296974, 'Total loss': 0.45418163339296974} | train loss {'Reaction outcome loss': 0.39357780735092474, 'Total loss': 0.39357780735092474}
2023-01-05 12:50:03,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:03,697 INFO:     Epoch: 28
2023-01-05 12:50:05,869 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42780578682820003, 'Total loss': 0.42780578682820003} | train loss {'Reaction outcome loss': 0.3835889463605433, 'Total loss': 0.3835889463605433}
2023-01-05 12:50:05,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:05,869 INFO:     Epoch: 29
2023-01-05 12:50:08,040 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4723146935304006, 'Total loss': 0.4723146935304006} | train loss {'Reaction outcome loss': 0.3746800703746317, 'Total loss': 0.3746800703746317}
2023-01-05 12:50:08,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:08,041 INFO:     Epoch: 30
2023-01-05 12:50:10,214 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42856210966904956, 'Total loss': 0.42856210966904956} | train loss {'Reaction outcome loss': 0.37341221688241305, 'Total loss': 0.37341221688241305}
2023-01-05 12:50:10,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:10,214 INFO:     Epoch: 31
2023-01-05 12:50:12,375 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4394122213125229, 'Total loss': 0.4394122213125229} | train loss {'Reaction outcome loss': 0.37407674220817616, 'Total loss': 0.37407674220817616}
2023-01-05 12:50:12,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:12,375 INFO:     Epoch: 32
2023-01-05 12:50:14,601 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.426296067237854, 'Total loss': 0.426296067237854} | train loss {'Reaction outcome loss': 0.36916878044820434, 'Total loss': 0.36916878044820434}
2023-01-05 12:50:14,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:14,603 INFO:     Epoch: 33
2023-01-05 12:50:16,860 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41786730488141377, 'Total loss': 0.41786730488141377} | train loss {'Reaction outcome loss': 0.3592414835515005, 'Total loss': 0.3592414835515005}
2023-01-05 12:50:16,860 INFO:     Found new best model at epoch 33
2023-01-05 12:50:16,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:16,862 INFO:     Epoch: 34
2023-01-05 12:50:19,125 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41832839051882426, 'Total loss': 0.41832839051882426} | train loss {'Reaction outcome loss': 0.3603574336919974, 'Total loss': 0.3603574336919974}
2023-01-05 12:50:19,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:19,126 INFO:     Epoch: 35
2023-01-05 12:50:21,373 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4261468589305878, 'Total loss': 0.4261468589305878} | train loss {'Reaction outcome loss': 0.3521508108891735, 'Total loss': 0.3521508108891735}
2023-01-05 12:50:21,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:21,374 INFO:     Epoch: 36
2023-01-05 12:50:23,565 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4353928069273631, 'Total loss': 0.4353928069273631} | train loss {'Reaction outcome loss': 0.35135340258909475, 'Total loss': 0.35135340258909475}
2023-01-05 12:50:23,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:23,565 INFO:     Epoch: 37
2023-01-05 12:50:25,744 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4290765513976415, 'Total loss': 0.4290765513976415} | train loss {'Reaction outcome loss': 0.35372672340284617, 'Total loss': 0.35372672340284617}
2023-01-05 12:50:25,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:25,744 INFO:     Epoch: 38
2023-01-05 12:50:27,917 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41305133601029714, 'Total loss': 0.41305133601029714} | train loss {'Reaction outcome loss': 0.34249686426903364, 'Total loss': 0.34249686426903364}
2023-01-05 12:50:27,917 INFO:     Found new best model at epoch 38
2023-01-05 12:50:27,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:27,919 INFO:     Epoch: 39
2023-01-05 12:50:30,087 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40108391642570496, 'Total loss': 0.40108391642570496} | train loss {'Reaction outcome loss': 0.3403790735972487, 'Total loss': 0.3403790735972487}
2023-01-05 12:50:30,088 INFO:     Found new best model at epoch 39
2023-01-05 12:50:30,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:30,089 INFO:     Epoch: 40
2023-01-05 12:50:32,260 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.446274338165919, 'Total loss': 0.446274338165919} | train loss {'Reaction outcome loss': 0.33898013086471745, 'Total loss': 0.33898013086471745}
2023-01-05 12:50:32,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:32,260 INFO:     Epoch: 41
2023-01-05 12:50:34,411 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4134607175985972, 'Total loss': 0.4134607175985972} | train loss {'Reaction outcome loss': 0.33424501852653515, 'Total loss': 0.33424501852653515}
2023-01-05 12:50:34,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:34,412 INFO:     Epoch: 42
2023-01-05 12:50:36,575 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43241391479969027, 'Total loss': 0.43241391479969027} | train loss {'Reaction outcome loss': 0.3318253661294061, 'Total loss': 0.3318253661294061}
2023-01-05 12:50:36,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:36,576 INFO:     Epoch: 43
2023-01-05 12:50:38,741 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41436216831207273, 'Total loss': 0.41436216831207273} | train loss {'Reaction outcome loss': 0.3301845054925564, 'Total loss': 0.3301845054925564}
2023-01-05 12:50:38,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:38,741 INFO:     Epoch: 44
2023-01-05 12:50:40,930 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43407161434491476, 'Total loss': 0.43407161434491476} | train loss {'Reaction outcome loss': 0.3309877550612718, 'Total loss': 0.3309877550612718}
2023-01-05 12:50:40,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:40,930 INFO:     Epoch: 45
2023-01-05 12:50:43,106 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43013222018877667, 'Total loss': 0.43013222018877667} | train loss {'Reaction outcome loss': 0.32435577217529826, 'Total loss': 0.32435577217529826}
2023-01-05 12:50:43,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:43,106 INFO:     Epoch: 46
2023-01-05 12:50:45,274 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3831373068193595, 'Total loss': 0.3831373068193595} | train loss {'Reaction outcome loss': 0.32376027169102795, 'Total loss': 0.32376027169102795}
2023-01-05 12:50:45,275 INFO:     Found new best model at epoch 46
2023-01-05 12:50:45,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:45,276 INFO:     Epoch: 47
2023-01-05 12:50:47,438 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40371653536955515, 'Total loss': 0.40371653536955515} | train loss {'Reaction outcome loss': 0.3135098913677763, 'Total loss': 0.3135098913677763}
2023-01-05 12:50:47,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:47,438 INFO:     Epoch: 48
2023-01-05 12:50:49,600 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42785982688268026, 'Total loss': 0.42785982688268026} | train loss {'Reaction outcome loss': 0.30920096516394013, 'Total loss': 0.30920096516394013}
2023-01-05 12:50:49,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:49,602 INFO:     Epoch: 49
2023-01-05 12:50:51,770 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39153237342834474, 'Total loss': 0.39153237342834474} | train loss {'Reaction outcome loss': 0.3236619067590159, 'Total loss': 0.3236619067590159}
2023-01-05 12:50:51,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:51,770 INFO:     Epoch: 50
2023-01-05 12:50:53,931 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4132380356391271, 'Total loss': 0.4132380356391271} | train loss {'Reaction outcome loss': 0.306607401973504, 'Total loss': 0.306607401973504}
2023-01-05 12:50:53,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:53,931 INFO:     Epoch: 51
2023-01-05 12:50:56,093 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4223228846987089, 'Total loss': 0.4223228846987089} | train loss {'Reaction outcome loss': 0.3068592676133025, 'Total loss': 0.3068592676133025}
2023-01-05 12:50:56,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:56,094 INFO:     Epoch: 52
2023-01-05 12:50:58,272 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3808694799741109, 'Total loss': 0.3808694799741109} | train loss {'Reaction outcome loss': 0.30260737432630913, 'Total loss': 0.30260737432630913}
2023-01-05 12:50:58,272 INFO:     Found new best model at epoch 52
2023-01-05 12:50:58,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:50:58,274 INFO:     Epoch: 53
2023-01-05 12:51:00,437 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3874823967615763, 'Total loss': 0.3874823967615763} | train loss {'Reaction outcome loss': 0.3016808590572664, 'Total loss': 0.3016808590572664}
2023-01-05 12:51:00,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:00,438 INFO:     Epoch: 54
2023-01-05 12:51:02,614 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4008177101612091, 'Total loss': 0.4008177101612091} | train loss {'Reaction outcome loss': 0.3020901788859914, 'Total loss': 0.3020901788859914}
2023-01-05 12:51:02,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:02,614 INFO:     Epoch: 55
2023-01-05 12:51:04,787 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.397614778081576, 'Total loss': 0.397614778081576} | train loss {'Reaction outcome loss': 0.2992166805380303, 'Total loss': 0.2992166805380303}
2023-01-05 12:51:04,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:04,787 INFO:     Epoch: 56
2023-01-05 12:51:06,967 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3721823384364446, 'Total loss': 0.3721823384364446} | train loss {'Reaction outcome loss': 0.29685812038688886, 'Total loss': 0.29685812038688886}
2023-01-05 12:51:06,967 INFO:     Found new best model at epoch 56
2023-01-05 12:51:06,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:06,969 INFO:     Epoch: 57
2023-01-05 12:51:09,121 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40134947498639423, 'Total loss': 0.40134947498639423} | train loss {'Reaction outcome loss': 0.2920291296303918, 'Total loss': 0.2920291296303918}
2023-01-05 12:51:09,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:09,122 INFO:     Epoch: 58
2023-01-05 12:51:11,296 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4092193454504013, 'Total loss': 0.4092193454504013} | train loss {'Reaction outcome loss': 0.29275580814330154, 'Total loss': 0.29275580814330154}
2023-01-05 12:51:11,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:11,296 INFO:     Epoch: 59
2023-01-05 12:51:13,485 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3863661840558052, 'Total loss': 0.3863661840558052} | train loss {'Reaction outcome loss': 0.2893761896027339, 'Total loss': 0.2893761896027339}
2023-01-05 12:51:13,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:13,486 INFO:     Epoch: 60
2023-01-05 12:51:15,663 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39792392204205196, 'Total loss': 0.39792392204205196} | train loss {'Reaction outcome loss': 0.2927516779798463, 'Total loss': 0.2927516779798463}
2023-01-05 12:51:15,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:15,663 INFO:     Epoch: 61
2023-01-05 12:51:17,836 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43047953496376673, 'Total loss': 0.43047953496376673} | train loss {'Reaction outcome loss': 0.29085179359151137, 'Total loss': 0.29085179359151137}
2023-01-05 12:51:17,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:17,837 INFO:     Epoch: 62
2023-01-05 12:51:20,011 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38839469850063324, 'Total loss': 0.38839469850063324} | train loss {'Reaction outcome loss': 0.2803618414495611, 'Total loss': 0.2803618414495611}
2023-01-05 12:51:20,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:20,012 INFO:     Epoch: 63
2023-01-05 12:51:22,170 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40150809387365977, 'Total loss': 0.40150809387365977} | train loss {'Reaction outcome loss': 0.28522670201768946, 'Total loss': 0.28522670201768946}
2023-01-05 12:51:22,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:22,170 INFO:     Epoch: 64
2023-01-05 12:51:24,352 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.429607655107975, 'Total loss': 0.429607655107975} | train loss {'Reaction outcome loss': 0.27799825188081834, 'Total loss': 0.27799825188081834}
2023-01-05 12:51:24,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:24,352 INFO:     Epoch: 65
2023-01-05 12:51:26,539 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39362697800000507, 'Total loss': 0.39362697800000507} | train loss {'Reaction outcome loss': 0.27809332815479715, 'Total loss': 0.27809332815479715}
2023-01-05 12:51:26,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:26,541 INFO:     Epoch: 66
2023-01-05 12:51:28,701 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4120547026395798, 'Total loss': 0.4120547026395798} | train loss {'Reaction outcome loss': 0.28071338981927946, 'Total loss': 0.28071338981927946}
2023-01-05 12:51:28,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:28,702 INFO:     Epoch: 67
2023-01-05 12:51:30,876 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4091491222381592, 'Total loss': 0.4091491222381592} | train loss {'Reaction outcome loss': 0.2724333255541669, 'Total loss': 0.2724333255541669}
2023-01-05 12:51:30,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:30,877 INFO:     Epoch: 68
2023-01-05 12:51:33,045 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41363617380460105, 'Total loss': 0.41363617380460105} | train loss {'Reaction outcome loss': 0.2735168289137661, 'Total loss': 0.2735168289137661}
2023-01-05 12:51:33,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:33,046 INFO:     Epoch: 69
2023-01-05 12:51:35,216 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41246065497398376, 'Total loss': 0.41246065497398376} | train loss {'Reaction outcome loss': 0.271635432576337, 'Total loss': 0.271635432576337}
2023-01-05 12:51:35,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:35,216 INFO:     Epoch: 70
2023-01-05 12:51:37,391 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.407111793756485, 'Total loss': 0.407111793756485} | train loss {'Reaction outcome loss': 0.27149004485148814, 'Total loss': 0.27149004485148814}
2023-01-05 12:51:37,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:37,391 INFO:     Epoch: 71
2023-01-05 12:51:39,558 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3849047283331553, 'Total loss': 0.3849047283331553} | train loss {'Reaction outcome loss': 0.26562756370578217, 'Total loss': 0.26562756370578217}
2023-01-05 12:51:39,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:39,558 INFO:     Epoch: 72
2023-01-05 12:51:41,734 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4025805334250132, 'Total loss': 0.4025805334250132} | train loss {'Reaction outcome loss': 0.26806959226754384, 'Total loss': 0.26806959226754384}
2023-01-05 12:51:41,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:41,734 INFO:     Epoch: 73
2023-01-05 12:51:43,894 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3886392722527186, 'Total loss': 0.3886392722527186} | train loss {'Reaction outcome loss': 0.2624195665591783, 'Total loss': 0.2624195665591783}
2023-01-05 12:51:43,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:43,894 INFO:     Epoch: 74
2023-01-05 12:51:46,044 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39531111319859824, 'Total loss': 0.39531111319859824} | train loss {'Reaction outcome loss': 0.25951386202086396, 'Total loss': 0.25951386202086396}
2023-01-05 12:51:46,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:46,045 INFO:     Epoch: 75
2023-01-05 12:51:48,214 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4033458838860194, 'Total loss': 0.4033458838860194} | train loss {'Reaction outcome loss': 0.26046269753483875, 'Total loss': 0.26046269753483875}
2023-01-05 12:51:48,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:48,214 INFO:     Epoch: 76
2023-01-05 12:51:50,181 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4236245065927505, 'Total loss': 0.4236245065927505} | train loss {'Reaction outcome loss': 0.25864669161475523, 'Total loss': 0.25864669161475523}
2023-01-05 12:51:50,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:50,181 INFO:     Epoch: 77
2023-01-05 12:51:52,358 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3744805872440338, 'Total loss': 0.3744805872440338} | train loss {'Reaction outcome loss': 0.2577109524664143, 'Total loss': 0.2577109524664143}
2023-01-05 12:51:52,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:52,358 INFO:     Epoch: 78
2023-01-05 12:51:54,527 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37619496633609134, 'Total loss': 0.37619496633609134} | train loss {'Reaction outcome loss': 0.25335444265216694, 'Total loss': 0.25335444265216694}
2023-01-05 12:51:54,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:54,527 INFO:     Epoch: 79
2023-01-05 12:51:56,683 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36811122571428617, 'Total loss': 0.36811122571428617} | train loss {'Reaction outcome loss': 0.25266225473276116, 'Total loss': 0.25266225473276116}
2023-01-05 12:51:56,683 INFO:     Found new best model at epoch 79
2023-01-05 12:51:56,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:56,684 INFO:     Epoch: 80
2023-01-05 12:51:58,832 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38594414591789244, 'Total loss': 0.38594414591789244} | train loss {'Reaction outcome loss': 0.2535840154016922, 'Total loss': 0.2535840154016922}
2023-01-05 12:51:58,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:51:58,832 INFO:     Epoch: 81
2023-01-05 12:52:01,010 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.407460606098175, 'Total loss': 0.407460606098175} | train loss {'Reaction outcome loss': 0.2546866156416357, 'Total loss': 0.2546866156416357}
2023-01-05 12:52:01,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:01,010 INFO:     Epoch: 82
2023-01-05 12:52:03,165 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3993222897251447, 'Total loss': 0.3993222897251447} | train loss {'Reaction outcome loss': 0.25123117618693125, 'Total loss': 0.25123117618693125}
2023-01-05 12:52:03,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:03,166 INFO:     Epoch: 83
2023-01-05 12:52:05,324 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3940742512543996, 'Total loss': 0.3940742512543996} | train loss {'Reaction outcome loss': 0.244622050243218, 'Total loss': 0.244622050243218}
2023-01-05 12:52:05,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:05,324 INFO:     Epoch: 84
2023-01-05 12:52:07,485 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40773434738318126, 'Total loss': 0.40773434738318126} | train loss {'Reaction outcome loss': 0.24311058822387177, 'Total loss': 0.24311058822387177}
2023-01-05 12:52:07,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:07,485 INFO:     Epoch: 85
2023-01-05 12:52:09,637 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4258102476596832, 'Total loss': 0.4258102476596832} | train loss {'Reaction outcome loss': 0.25351770678098023, 'Total loss': 0.25351770678098023}
2023-01-05 12:52:09,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:09,638 INFO:     Epoch: 86
2023-01-05 12:52:11,803 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4012204666932424, 'Total loss': 0.4012204666932424} | train loss {'Reaction outcome loss': 0.244103383420822, 'Total loss': 0.244103383420822}
2023-01-05 12:52:11,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:11,803 INFO:     Epoch: 87
2023-01-05 12:52:13,966 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41310144066810606, 'Total loss': 0.41310144066810606} | train loss {'Reaction outcome loss': 0.24188238651313507, 'Total loss': 0.24188238651313507}
2023-01-05 12:52:13,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:13,966 INFO:     Epoch: 88
2023-01-05 12:52:16,134 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39828250954548516, 'Total loss': 0.39828250954548516} | train loss {'Reaction outcome loss': 0.24985610025292698, 'Total loss': 0.24985610025292698}
2023-01-05 12:52:16,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:16,134 INFO:     Epoch: 89
2023-01-05 12:52:18,301 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36840884685516356, 'Total loss': 0.36840884685516356} | train loss {'Reaction outcome loss': 0.24075820799984227, 'Total loss': 0.24075820799984227}
2023-01-05 12:52:18,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:18,302 INFO:     Epoch: 90
2023-01-05 12:52:20,433 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37808858752250674, 'Total loss': 0.37808858752250674} | train loss {'Reaction outcome loss': 0.23845741987927727, 'Total loss': 0.23845741987927727}
2023-01-05 12:52:20,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:20,434 INFO:     Epoch: 91
2023-01-05 12:52:22,594 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3800903787215551, 'Total loss': 0.3800903787215551} | train loss {'Reaction outcome loss': 0.23978301122892204, 'Total loss': 0.23978301122892204}
2023-01-05 12:52:22,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:22,594 INFO:     Epoch: 92
2023-01-05 12:52:24,737 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4113289311528206, 'Total loss': 0.4113289311528206} | train loss {'Reaction outcome loss': 0.23201960365587193, 'Total loss': 0.23201960365587193}
2023-01-05 12:52:24,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:24,737 INFO:     Epoch: 93
2023-01-05 12:52:26,889 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4015816609064738, 'Total loss': 0.4015816609064738} | train loss {'Reaction outcome loss': 0.22918882986718944, 'Total loss': 0.22918882986718944}
2023-01-05 12:52:26,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:26,889 INFO:     Epoch: 94
2023-01-05 12:52:29,049 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33839487545192243, 'Total loss': 0.33839487545192243} | train loss {'Reaction outcome loss': 0.2406173720485144, 'Total loss': 0.2406173720485144}
2023-01-05 12:52:29,049 INFO:     Found new best model at epoch 94
2023-01-05 12:52:29,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:29,050 INFO:     Epoch: 95
2023-01-05 12:52:31,217 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35605670263369876, 'Total loss': 0.35605670263369876} | train loss {'Reaction outcome loss': 0.24358910668829611, 'Total loss': 0.24358910668829611}
2023-01-05 12:52:31,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:31,217 INFO:     Epoch: 96
2023-01-05 12:52:33,386 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4115852942069372, 'Total loss': 0.4115852942069372} | train loss {'Reaction outcome loss': 0.22671321015603277, 'Total loss': 0.22671321015603277}
2023-01-05 12:52:33,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:33,387 INFO:     Epoch: 97
2023-01-05 12:52:35,554 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.394913449883461, 'Total loss': 0.394913449883461} | train loss {'Reaction outcome loss': 0.23880529800423217, 'Total loss': 0.23880529800423217}
2023-01-05 12:52:35,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:35,554 INFO:     Epoch: 98
2023-01-05 12:52:37,718 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3976128617922465, 'Total loss': 0.3976128617922465} | train loss {'Reaction outcome loss': 0.22893459956911444, 'Total loss': 0.22893459956911444}
2023-01-05 12:52:37,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:37,718 INFO:     Epoch: 99
2023-01-05 12:52:39,898 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3901398221651713, 'Total loss': 0.3901398221651713} | train loss {'Reaction outcome loss': 0.23148067915368328, 'Total loss': 0.23148067915368328}
2023-01-05 12:52:39,899 INFO:     Best model found after epoch 95 of 100.
2023-01-05 12:52:39,899 INFO:   Done with stage: TRAINING
2023-01-05 12:52:39,899 INFO:   Starting stage: EVALUATION
2023-01-05 12:52:40,026 INFO:   Done with stage: EVALUATION
2023-01-05 12:52:40,026 INFO:   Leaving out SEQ value Fold_7
2023-01-05 12:52:40,039 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 12:52:40,039 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:52:40,706 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:52:40,706 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:52:40,776 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:52:40,776 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:52:40,776 INFO:     No hyperparam tuning for this model
2023-01-05 12:52:40,776 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:52:40,776 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:52:40,777 INFO:     None feature selector for col prot
2023-01-05 12:52:40,777 INFO:     None feature selector for col prot
2023-01-05 12:52:40,777 INFO:     None feature selector for col prot
2023-01-05 12:52:40,778 INFO:     None feature selector for col chem
2023-01-05 12:52:40,778 INFO:     None feature selector for col chem
2023-01-05 12:52:40,778 INFO:     None feature selector for col chem
2023-01-05 12:52:40,778 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:52:40,778 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:52:40,780 INFO:     Number of params in model 72901
2023-01-05 12:52:40,783 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:52:40,783 INFO:   Starting stage: TRAINING
2023-01-05 12:52:40,844 INFO:     Val loss before train {'Reaction outcome loss': 1.1265733043352764, 'Total loss': 1.1265733043352764}
2023-01-05 12:52:40,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:40,844 INFO:     Epoch: 0
2023-01-05 12:52:42,999 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9931338429450989, 'Total loss': 0.9931338429450989} | train loss {'Reaction outcome loss': 0.9438210878035297, 'Total loss': 0.9438210878035297}
2023-01-05 12:52:42,999 INFO:     Found new best model at epoch 0
2023-01-05 12:52:43,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:43,000 INFO:     Epoch: 1
2023-01-05 12:52:45,161 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7464623312155406, 'Total loss': 0.7464623312155406} | train loss {'Reaction outcome loss': 0.7755271464124814, 'Total loss': 0.7755271464124814}
2023-01-05 12:52:45,161 INFO:     Found new best model at epoch 1
2023-01-05 12:52:45,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:45,162 INFO:     Epoch: 2
2023-01-05 12:52:47,345 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5845665872097016, 'Total loss': 0.5845665872097016} | train loss {'Reaction outcome loss': 0.6193237603638672, 'Total loss': 0.6193237603638672}
2023-01-05 12:52:47,345 INFO:     Found new best model at epoch 2
2023-01-05 12:52:47,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:47,347 INFO:     Epoch: 3
2023-01-05 12:52:49,514 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5588172376155853, 'Total loss': 0.5588172376155853} | train loss {'Reaction outcome loss': 0.5490588348196901, 'Total loss': 0.5490588348196901}
2023-01-05 12:52:49,514 INFO:     Found new best model at epoch 3
2023-01-05 12:52:49,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:49,516 INFO:     Epoch: 4
2023-01-05 12:52:51,687 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5867216726144154, 'Total loss': 0.5867216726144154} | train loss {'Reaction outcome loss': 0.5185907551532855, 'Total loss': 0.5185907551532855}
2023-01-05 12:52:51,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:51,687 INFO:     Epoch: 5
2023-01-05 12:52:53,843 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5689926743507385, 'Total loss': 0.5689926743507385} | train loss {'Reaction outcome loss': 0.5059302687258278, 'Total loss': 0.5059302687258278}
2023-01-05 12:52:53,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:53,844 INFO:     Epoch: 6
2023-01-05 12:52:56,008 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6013851235310237, 'Total loss': 0.6013851235310237} | train loss {'Reaction outcome loss': 0.4910149495454802, 'Total loss': 0.4910149495454802}
2023-01-05 12:52:56,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:56,008 INFO:     Epoch: 7
2023-01-05 12:52:58,180 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5749651153882345, 'Total loss': 0.5749651153882345} | train loss {'Reaction outcome loss': 0.4860382909123934, 'Total loss': 0.4860382909123934}
2023-01-05 12:52:58,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:52:58,181 INFO:     Epoch: 8
2023-01-05 12:53:00,357 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5660960535208385, 'Total loss': 0.5660960535208385} | train loss {'Reaction outcome loss': 0.47828426637494453, 'Total loss': 0.47828426637494453}
2023-01-05 12:53:00,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:00,358 INFO:     Epoch: 9
2023-01-05 12:53:02,523 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5408386210600535, 'Total loss': 0.5408386210600535} | train loss {'Reaction outcome loss': 0.49791887483519054, 'Total loss': 0.49791887483519054}
2023-01-05 12:53:02,523 INFO:     Found new best model at epoch 9
2023-01-05 12:53:02,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:02,525 INFO:     Epoch: 10
2023-01-05 12:53:04,694 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.540800021092097, 'Total loss': 0.540800021092097} | train loss {'Reaction outcome loss': 0.48650540017052146, 'Total loss': 0.48650540017052146}
2023-01-05 12:53:04,695 INFO:     Found new best model at epoch 10
2023-01-05 12:53:04,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:04,697 INFO:     Epoch: 11
2023-01-05 12:53:06,856 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5492292602856954, 'Total loss': 0.5492292602856954} | train loss {'Reaction outcome loss': 0.4596888788940344, 'Total loss': 0.4596888788940344}
2023-01-05 12:53:06,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:06,857 INFO:     Epoch: 12
2023-01-05 12:53:09,033 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5189396719137828, 'Total loss': 0.5189396719137828} | train loss {'Reaction outcome loss': 0.4595525998308364, 'Total loss': 0.4595525998308364}
2023-01-05 12:53:09,033 INFO:     Found new best model at epoch 12
2023-01-05 12:53:09,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:09,035 INFO:     Epoch: 13
2023-01-05 12:53:11,194 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5338808447122574, 'Total loss': 0.5338808447122574} | train loss {'Reaction outcome loss': 0.4541767906098951, 'Total loss': 0.4541767906098951}
2023-01-05 12:53:11,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:11,195 INFO:     Epoch: 14
2023-01-05 12:53:13,364 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5420363446076711, 'Total loss': 0.5420363446076711} | train loss {'Reaction outcome loss': 0.4476513016591038, 'Total loss': 0.4476513016591038}
2023-01-05 12:53:13,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:13,364 INFO:     Epoch: 15
2023-01-05 12:53:15,526 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5189398050308227, 'Total loss': 0.5189398050308227} | train loss {'Reaction outcome loss': 0.4461993141794928, 'Total loss': 0.4461993141794928}
2023-01-05 12:53:15,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:15,526 INFO:     Epoch: 16
2023-01-05 12:53:17,668 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5086071987946829, 'Total loss': 0.5086071987946829} | train loss {'Reaction outcome loss': 0.4426443919040047, 'Total loss': 0.4426443919040047}
2023-01-05 12:53:17,669 INFO:     Found new best model at epoch 16
2023-01-05 12:53:17,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:17,670 INFO:     Epoch: 17
2023-01-05 12:53:19,828 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5184525142113368, 'Total loss': 0.5184525142113368} | train loss {'Reaction outcome loss': 0.43875644771733147, 'Total loss': 0.43875644771733147}
2023-01-05 12:53:19,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:19,829 INFO:     Epoch: 18
2023-01-05 12:53:21,989 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5073734561602274, 'Total loss': 0.5073734561602274} | train loss {'Reaction outcome loss': 0.4329192935161911, 'Total loss': 0.4329192935161911}
2023-01-05 12:53:21,989 INFO:     Found new best model at epoch 18
2023-01-05 12:53:21,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:21,990 INFO:     Epoch: 19
2023-01-05 12:53:24,149 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5221575041611989, 'Total loss': 0.5221575041611989} | train loss {'Reaction outcome loss': 0.4313984129415906, 'Total loss': 0.4313984129415906}
2023-01-05 12:53:24,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:24,150 INFO:     Epoch: 20
2023-01-05 12:53:26,310 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5075441221396129, 'Total loss': 0.5075441221396129} | train loss {'Reaction outcome loss': 0.4295594453410097, 'Total loss': 0.4295594453410097}
2023-01-05 12:53:26,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:26,310 INFO:     Epoch: 21
2023-01-05 12:53:28,483 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4809040705362956, 'Total loss': 0.4809040705362956} | train loss {'Reaction outcome loss': 0.44532977120167966, 'Total loss': 0.44532977120167966}
2023-01-05 12:53:28,483 INFO:     Found new best model at epoch 21
2023-01-05 12:53:28,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:28,484 INFO:     Epoch: 22
2023-01-05 12:53:30,645 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5037693907817204, 'Total loss': 0.5037693907817204} | train loss {'Reaction outcome loss': 0.41818322527957946, 'Total loss': 0.41818322527957946}
2023-01-05 12:53:30,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:30,645 INFO:     Epoch: 23
2023-01-05 12:53:32,800 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48533188303311664, 'Total loss': 0.48533188303311664} | train loss {'Reaction outcome loss': 0.4151213279321277, 'Total loss': 0.4151213279321277}
2023-01-05 12:53:32,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:32,800 INFO:     Epoch: 24
2023-01-05 12:53:34,970 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5039001047611237, 'Total loss': 0.5039001047611237} | train loss {'Reaction outcome loss': 0.4118751176578951, 'Total loss': 0.4118751176578951}
2023-01-05 12:53:34,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:34,970 INFO:     Epoch: 25
2023-01-05 12:53:37,139 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.487398099899292, 'Total loss': 0.487398099899292} | train loss {'Reaction outcome loss': 0.4079507659796787, 'Total loss': 0.4079507659796787}
2023-01-05 12:53:37,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:37,139 INFO:     Epoch: 26
2023-01-05 12:53:39,297 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49315478205680846, 'Total loss': 0.49315478205680846} | train loss {'Reaction outcome loss': 0.41245830925248994, 'Total loss': 0.41245830925248994}
2023-01-05 12:53:39,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:39,299 INFO:     Epoch: 27
2023-01-05 12:53:41,449 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4832391063372294, 'Total loss': 0.4832391063372294} | train loss {'Reaction outcome loss': 0.39792482634547394, 'Total loss': 0.39792482634547394}
2023-01-05 12:53:41,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:41,449 INFO:     Epoch: 28
2023-01-05 12:53:43,612 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4947366158167521, 'Total loss': 0.4947366158167521} | train loss {'Reaction outcome loss': 0.396199330192336, 'Total loss': 0.396199330192336}
2023-01-05 12:53:43,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:43,612 INFO:     Epoch: 29
2023-01-05 12:53:45,782 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5001997818549474, 'Total loss': 0.5001997818549474} | train loss {'Reaction outcome loss': 0.3996453828083864, 'Total loss': 0.3996453828083864}
2023-01-05 12:53:45,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:45,783 INFO:     Epoch: 30
2023-01-05 12:53:47,950 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48779694736003876, 'Total loss': 0.48779694736003876} | train loss {'Reaction outcome loss': 0.41888553996380756, 'Total loss': 0.41888553996380756}
2023-01-05 12:53:47,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:47,951 INFO:     Epoch: 31
2023-01-05 12:53:50,119 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48374958833058673, 'Total loss': 0.48374958833058673} | train loss {'Reaction outcome loss': 0.39216629938438424, 'Total loss': 0.39216629938438424}
2023-01-05 12:53:50,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:50,119 INFO:     Epoch: 32
2023-01-05 12:53:52,289 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4680979778369268, 'Total loss': 0.4680979778369268} | train loss {'Reaction outcome loss': 0.39041667201630503, 'Total loss': 0.39041667201630503}
2023-01-05 12:53:52,290 INFO:     Found new best model at epoch 32
2023-01-05 12:53:52,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:52,291 INFO:     Epoch: 33
2023-01-05 12:53:54,443 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46390552322069806, 'Total loss': 0.46390552322069806} | train loss {'Reaction outcome loss': 0.3772319710975432, 'Total loss': 0.3772319710975432}
2023-01-05 12:53:54,443 INFO:     Found new best model at epoch 33
2023-01-05 12:53:54,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:54,445 INFO:     Epoch: 34
2023-01-05 12:53:56,622 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4834028114875158, 'Total loss': 0.4834028114875158} | train loss {'Reaction outcome loss': 0.3767536083924706, 'Total loss': 0.3767536083924706}
2023-01-05 12:53:56,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:56,622 INFO:     Epoch: 35
2023-01-05 12:53:58,797 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44542691704506676, 'Total loss': 0.44542691704506676} | train loss {'Reaction outcome loss': 0.395292691414015, 'Total loss': 0.395292691414015}
2023-01-05 12:53:58,798 INFO:     Found new best model at epoch 35
2023-01-05 12:53:58,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:53:58,799 INFO:     Epoch: 36
2023-01-05 12:54:00,990 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48873353699843086, 'Total loss': 0.48873353699843086} | train loss {'Reaction outcome loss': 0.3785645766749009, 'Total loss': 0.3785645766749009}
2023-01-05 12:54:00,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:00,990 INFO:     Epoch: 37
2023-01-05 12:54:03,163 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48014416396617887, 'Total loss': 0.48014416396617887} | train loss {'Reaction outcome loss': 0.4008846542649511, 'Total loss': 0.4008846542649511}
2023-01-05 12:54:03,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:03,163 INFO:     Epoch: 38
2023-01-05 12:54:05,324 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46822245717048644, 'Total loss': 0.46822245717048644} | train loss {'Reaction outcome loss': 0.36809056539483287, 'Total loss': 0.36809056539483287}
2023-01-05 12:54:05,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:05,325 INFO:     Epoch: 39
2023-01-05 12:54:07,501 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4909899294376373, 'Total loss': 0.4909899294376373} | train loss {'Reaction outcome loss': 0.36239115225380636, 'Total loss': 0.36239115225380636}
2023-01-05 12:54:07,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:07,501 INFO:     Epoch: 40
2023-01-05 12:54:09,659 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44569259881973267, 'Total loss': 0.44569259881973267} | train loss {'Reaction outcome loss': 0.3561853757896313, 'Total loss': 0.3561853757896313}
2023-01-05 12:54:09,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:09,659 INFO:     Epoch: 41
2023-01-05 12:54:11,824 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46962178746859234, 'Total loss': 0.46962178746859234} | train loss {'Reaction outcome loss': 0.3592755858098035, 'Total loss': 0.3592755858098035}
2023-01-05 12:54:11,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:11,825 INFO:     Epoch: 42
2023-01-05 12:54:14,004 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4787588119506836, 'Total loss': 0.4787588119506836} | train loss {'Reaction outcome loss': 0.3580546088186025, 'Total loss': 0.3580546088186025}
2023-01-05 12:54:14,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:14,004 INFO:     Epoch: 43
2023-01-05 12:54:16,154 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4908937493960063, 'Total loss': 0.4908937493960063} | train loss {'Reaction outcome loss': 0.3473350106117626, 'Total loss': 0.3473350106117626}
2023-01-05 12:54:16,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:16,155 INFO:     Epoch: 44
2023-01-05 12:54:18,322 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5034398059050242, 'Total loss': 0.5034398059050242} | train loss {'Reaction outcome loss': 0.355739210245952, 'Total loss': 0.355739210245952}
2023-01-05 12:54:18,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:18,322 INFO:     Epoch: 45
2023-01-05 12:54:20,485 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5210424602031708, 'Total loss': 0.5210424602031708} | train loss {'Reaction outcome loss': 0.3406839633765533, 'Total loss': 0.3406839633765533}
2023-01-05 12:54:20,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:20,486 INFO:     Epoch: 46
2023-01-05 12:54:22,658 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49362564583619434, 'Total loss': 0.49362564583619434} | train loss {'Reaction outcome loss': 0.3467751577388319, 'Total loss': 0.3467751577388319}
2023-01-05 12:54:22,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:22,659 INFO:     Epoch: 47
2023-01-05 12:54:24,824 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4915237188339233, 'Total loss': 0.4915237188339233} | train loss {'Reaction outcome loss': 0.3437727685693813, 'Total loss': 0.3437727685693813}
2023-01-05 12:54:24,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:24,824 INFO:     Epoch: 48
2023-01-05 12:54:26,984 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4825884943207105, 'Total loss': 0.4825884943207105} | train loss {'Reaction outcome loss': 0.3542488199633173, 'Total loss': 0.3542488199633173}
2023-01-05 12:54:26,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:26,984 INFO:     Epoch: 49
2023-01-05 12:54:29,135 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44634215434392294, 'Total loss': 0.44634215434392294} | train loss {'Reaction outcome loss': 0.335232875512346, 'Total loss': 0.335232875512346}
2023-01-05 12:54:29,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:29,136 INFO:     Epoch: 50
2023-01-05 12:54:31,305 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4412448078393936, 'Total loss': 0.4412448078393936} | train loss {'Reaction outcome loss': 0.33206916203135217, 'Total loss': 0.33206916203135217}
2023-01-05 12:54:31,306 INFO:     Found new best model at epoch 50
2023-01-05 12:54:31,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:31,307 INFO:     Epoch: 51
2023-01-05 12:54:33,466 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4614826718966166, 'Total loss': 0.4614826718966166} | train loss {'Reaction outcome loss': 0.33057152539275697, 'Total loss': 0.33057152539275697}
2023-01-05 12:54:33,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:33,466 INFO:     Epoch: 52
2023-01-05 12:54:35,623 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43177559077739713, 'Total loss': 0.43177559077739713} | train loss {'Reaction outcome loss': 0.3451315754209645, 'Total loss': 0.3451315754209645}
2023-01-05 12:54:35,624 INFO:     Found new best model at epoch 52
2023-01-05 12:54:35,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:35,625 INFO:     Epoch: 53
2023-01-05 12:54:37,810 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46032657821973166, 'Total loss': 0.46032657821973166} | train loss {'Reaction outcome loss': 0.3539795557684872, 'Total loss': 0.3539795557684872}
2023-01-05 12:54:37,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:37,810 INFO:     Epoch: 54
2023-01-05 12:54:39,955 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4819601704676946, 'Total loss': 0.4819601704676946} | train loss {'Reaction outcome loss': 0.32481225111236645, 'Total loss': 0.32481225111236645}
2023-01-05 12:54:39,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:39,955 INFO:     Epoch: 55
2023-01-05 12:54:42,132 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4520522077878316, 'Total loss': 0.4520522077878316} | train loss {'Reaction outcome loss': 0.32204265109654784, 'Total loss': 0.32204265109654784}
2023-01-05 12:54:42,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:42,133 INFO:     Epoch: 56
2023-01-05 12:54:44,305 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4635324483116468, 'Total loss': 0.4635324483116468} | train loss {'Reaction outcome loss': 0.32237835915377905, 'Total loss': 0.32237835915377905}
2023-01-05 12:54:44,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:44,306 INFO:     Epoch: 57
2023-01-05 12:54:46,486 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5152965267499288, 'Total loss': 0.5152965267499288} | train loss {'Reaction outcome loss': 0.31449882340759516, 'Total loss': 0.31449882340759516}
2023-01-05 12:54:46,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:46,487 INFO:     Epoch: 58
2023-01-05 12:54:48,652 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5032646978894869, 'Total loss': 0.5032646978894869} | train loss {'Reaction outcome loss': 0.31093470994718425, 'Total loss': 0.31093470994718425}
2023-01-05 12:54:48,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:48,652 INFO:     Epoch: 59
2023-01-05 12:54:50,812 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4563415835301081, 'Total loss': 0.4563415835301081} | train loss {'Reaction outcome loss': 0.3064109429936819, 'Total loss': 0.3064109429936819}
2023-01-05 12:54:50,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:50,812 INFO:     Epoch: 60
2023-01-05 12:54:52,985 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48958593209584556, 'Total loss': 0.48958593209584556} | train loss {'Reaction outcome loss': 0.31203441082101746, 'Total loss': 0.31203441082101746}
2023-01-05 12:54:52,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:52,986 INFO:     Epoch: 61
2023-01-05 12:54:55,153 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45101362466812134, 'Total loss': 0.45101362466812134} | train loss {'Reaction outcome loss': 0.29894855473716947, 'Total loss': 0.29894855473716947}
2023-01-05 12:54:55,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:55,154 INFO:     Epoch: 62
2023-01-05 12:54:57,324 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46849560787280403, 'Total loss': 0.46849560787280403} | train loss {'Reaction outcome loss': 0.29982252013903327, 'Total loss': 0.29982252013903327}
2023-01-05 12:54:57,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:57,325 INFO:     Epoch: 63
2023-01-05 12:54:59,491 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4394043326377869, 'Total loss': 0.4394043326377869} | train loss {'Reaction outcome loss': 0.3018022917777948, 'Total loss': 0.3018022917777948}
2023-01-05 12:54:59,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:54:59,492 INFO:     Epoch: 64
2023-01-05 12:55:01,668 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4560613453388214, 'Total loss': 0.4560613453388214} | train loss {'Reaction outcome loss': 0.2916699096533483, 'Total loss': 0.2916699096533483}
2023-01-05 12:55:01,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:01,668 INFO:     Epoch: 65
2023-01-05 12:55:03,825 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.451859978834788, 'Total loss': 0.451859978834788} | train loss {'Reaction outcome loss': 0.2995363084744473, 'Total loss': 0.2995363084744473}
2023-01-05 12:55:03,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:03,825 INFO:     Epoch: 66
2023-01-05 12:55:05,983 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45692461133003237, 'Total loss': 0.45692461133003237} | train loss {'Reaction outcome loss': 0.2923321965820345, 'Total loss': 0.2923321965820345}
2023-01-05 12:55:05,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:05,984 INFO:     Epoch: 67
2023-01-05 12:55:08,151 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41765315930048624, 'Total loss': 0.41765315930048624} | train loss {'Reaction outcome loss': 0.29189879670266766, 'Total loss': 0.29189879670266766}
2023-01-05 12:55:08,151 INFO:     Found new best model at epoch 67
2023-01-05 12:55:08,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:08,153 INFO:     Epoch: 68
2023-01-05 12:55:10,322 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44786350925763446, 'Total loss': 0.44786350925763446} | train loss {'Reaction outcome loss': 0.296729254671305, 'Total loss': 0.296729254671305}
2023-01-05 12:55:10,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:10,322 INFO:     Epoch: 69
2023-01-05 12:55:12,494 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41759069164594015, 'Total loss': 0.41759069164594015} | train loss {'Reaction outcome loss': 0.3217766849936553, 'Total loss': 0.3217766849936553}
2023-01-05 12:55:12,494 INFO:     Found new best model at epoch 69
2023-01-05 12:55:12,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:12,496 INFO:     Epoch: 70
2023-01-05 12:55:14,676 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39952050844828285, 'Total loss': 0.39952050844828285} | train loss {'Reaction outcome loss': 0.2970130887604656, 'Total loss': 0.2970130887604656}
2023-01-05 12:55:14,676 INFO:     Found new best model at epoch 70
2023-01-05 12:55:14,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:14,678 INFO:     Epoch: 71
2023-01-05 12:55:16,848 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4357796063025792, 'Total loss': 0.4357796063025792} | train loss {'Reaction outcome loss': 0.4220837630817424, 'Total loss': 0.4220837630817424}
2023-01-05 12:55:16,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:16,849 INFO:     Epoch: 72
2023-01-05 12:55:19,032 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4114886996646722, 'Total loss': 0.4114886996646722} | train loss {'Reaction outcome loss': 0.3504548530377772, 'Total loss': 0.3504548530377772}
2023-01-05 12:55:19,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:19,032 INFO:     Epoch: 73
2023-01-05 12:55:21,205 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4466443876425425, 'Total loss': 0.4466443876425425} | train loss {'Reaction outcome loss': 0.30233837189692736, 'Total loss': 0.30233837189692736}
2023-01-05 12:55:21,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:21,206 INFO:     Epoch: 74
2023-01-05 12:55:23,384 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4455017685890198, 'Total loss': 0.4455017685890198} | train loss {'Reaction outcome loss': 0.2922875788786189, 'Total loss': 0.2922875788786189}
2023-01-05 12:55:23,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:23,385 INFO:     Epoch: 75
2023-01-05 12:55:25,542 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4597328841686249, 'Total loss': 0.4597328841686249} | train loss {'Reaction outcome loss': 0.2846357832068347, 'Total loss': 0.2846357832068347}
2023-01-05 12:55:25,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:25,542 INFO:     Epoch: 76
2023-01-05 12:55:27,688 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4385647674401601, 'Total loss': 0.4385647674401601} | train loss {'Reaction outcome loss': 0.2815086699174835, 'Total loss': 0.2815086699174835}
2023-01-05 12:55:27,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:27,688 INFO:     Epoch: 77
2023-01-05 12:55:29,859 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4839714745680491, 'Total loss': 0.4839714745680491} | train loss {'Reaction outcome loss': 0.28258157637606346, 'Total loss': 0.28258157637606346}
2023-01-05 12:55:29,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:29,859 INFO:     Epoch: 78
2023-01-05 12:55:32,019 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4579493224620819, 'Total loss': 0.4579493224620819} | train loss {'Reaction outcome loss': 0.28293951764293446, 'Total loss': 0.28293951764293446}
2023-01-05 12:55:32,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:32,019 INFO:     Epoch: 79
2023-01-05 12:55:34,192 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5150375664234161, 'Total loss': 0.5150375664234161} | train loss {'Reaction outcome loss': 0.2777759026612857, 'Total loss': 0.2777759026612857}
2023-01-05 12:55:34,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:34,193 INFO:     Epoch: 80
2023-01-05 12:55:36,352 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4116229603687922, 'Total loss': 0.4116229603687922} | train loss {'Reaction outcome loss': 0.28523592028405814, 'Total loss': 0.28523592028405814}
2023-01-05 12:55:36,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:36,353 INFO:     Epoch: 81
2023-01-05 12:55:38,487 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43850242098172504, 'Total loss': 0.43850242098172504} | train loss {'Reaction outcome loss': 0.2772821133510898, 'Total loss': 0.2772821133510898}
2023-01-05 12:55:38,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:38,487 INFO:     Epoch: 82
2023-01-05 12:55:40,620 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46270580490430196, 'Total loss': 0.46270580490430196} | train loss {'Reaction outcome loss': 0.27769374816368025, 'Total loss': 0.27769374816368025}
2023-01-05 12:55:40,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:40,621 INFO:     Epoch: 83
2023-01-05 12:55:42,789 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4383596738179525, 'Total loss': 0.4383596738179525} | train loss {'Reaction outcome loss': 0.274712003055791, 'Total loss': 0.274712003055791}
2023-01-05 12:55:42,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:42,789 INFO:     Epoch: 84
2023-01-05 12:55:44,951 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4275916109482447, 'Total loss': 0.4275916109482447} | train loss {'Reaction outcome loss': 0.2753858891234774, 'Total loss': 0.2753858891234774}
2023-01-05 12:55:44,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:44,951 INFO:     Epoch: 85
2023-01-05 12:55:47,109 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4301887273788452, 'Total loss': 0.4301887273788452} | train loss {'Reaction outcome loss': 0.2702687469182833, 'Total loss': 0.2702687469182833}
2023-01-05 12:55:47,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:47,109 INFO:     Epoch: 86
2023-01-05 12:55:49,264 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4489607791105906, 'Total loss': 0.4489607791105906} | train loss {'Reaction outcome loss': 0.2672551813486042, 'Total loss': 0.2672551813486042}
2023-01-05 12:55:49,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:49,264 INFO:     Epoch: 87
2023-01-05 12:55:51,408 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39327962001164757, 'Total loss': 0.39327962001164757} | train loss {'Reaction outcome loss': 0.26303327514830493, 'Total loss': 0.26303327514830493}
2023-01-05 12:55:51,408 INFO:     Found new best model at epoch 87
2023-01-05 12:55:51,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:51,410 INFO:     Epoch: 88
2023-01-05 12:55:53,546 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38683076947927475, 'Total loss': 0.38683076947927475} | train loss {'Reaction outcome loss': 0.27336772812017496, 'Total loss': 0.27336772812017496}
2023-01-05 12:55:53,547 INFO:     Found new best model at epoch 88
2023-01-05 12:55:53,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:53,549 INFO:     Epoch: 89
2023-01-05 12:55:55,531 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4364890774091085, 'Total loss': 0.4364890774091085} | train loss {'Reaction outcome loss': 0.26701923054165294, 'Total loss': 0.26701923054165294}
2023-01-05 12:55:55,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:55,531 INFO:     Epoch: 90
2023-01-05 12:55:57,686 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4070388297239939, 'Total loss': 0.4070388297239939} | train loss {'Reaction outcome loss': 0.2678474600602319, 'Total loss': 0.2678474600602319}
2023-01-05 12:55:57,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:57,686 INFO:     Epoch: 91
2023-01-05 12:55:59,848 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43044151465098063, 'Total loss': 0.43044151465098063} | train loss {'Reaction outcome loss': 0.26977060229072103, 'Total loss': 0.26977060229072103}
2023-01-05 12:55:59,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:55:59,849 INFO:     Epoch: 92
2023-01-05 12:56:01,990 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4175164719422658, 'Total loss': 0.4175164719422658} | train loss {'Reaction outcome loss': 0.3810442944908889, 'Total loss': 0.3810442944908889}
2023-01-05 12:56:01,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:01,990 INFO:     Epoch: 93
2023-01-05 12:56:04,153 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42293450186649956, 'Total loss': 0.42293450186649956} | train loss {'Reaction outcome loss': 0.28926115819553344, 'Total loss': 0.28926115819553344}
2023-01-05 12:56:04,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:04,153 INFO:     Epoch: 94
2023-01-05 12:56:06,316 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40249713410933813, 'Total loss': 0.40249713410933813} | train loss {'Reaction outcome loss': 0.27672716388073954, 'Total loss': 0.27672716388073954}
2023-01-05 12:56:06,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:06,316 INFO:     Epoch: 95
2023-01-05 12:56:08,474 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4104434723655383, 'Total loss': 0.4104434723655383} | train loss {'Reaction outcome loss': 0.2726307770648998, 'Total loss': 0.2726307770648998}
2023-01-05 12:56:08,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:08,475 INFO:     Epoch: 96
2023-01-05 12:56:10,631 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42851184904575346, 'Total loss': 0.42851184904575346} | train loss {'Reaction outcome loss': 0.26907229661995097, 'Total loss': 0.26907229661995097}
2023-01-05 12:56:10,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:10,631 INFO:     Epoch: 97
2023-01-05 12:56:12,778 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41375046769777934, 'Total loss': 0.41375046769777934} | train loss {'Reaction outcome loss': 0.2609165984115638, 'Total loss': 0.2609165984115638}
2023-01-05 12:56:12,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:12,779 INFO:     Epoch: 98
2023-01-05 12:56:14,922 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41248274544874824, 'Total loss': 0.41248274544874824} | train loss {'Reaction outcome loss': 0.26798398486352054, 'Total loss': 0.26798398486352054}
2023-01-05 12:56:14,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:14,922 INFO:     Epoch: 99
2023-01-05 12:56:17,091 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45417352914810183, 'Total loss': 0.45417352914810183} | train loss {'Reaction outcome loss': 0.2622073161908412, 'Total loss': 0.2622073161908412}
2023-01-05 12:56:17,091 INFO:     Best model found after epoch 89 of 100.
2023-01-05 12:56:17,091 INFO:   Done with stage: TRAINING
2023-01-05 12:56:17,091 INFO:   Starting stage: EVALUATION
2023-01-05 12:56:17,224 INFO:   Done with stage: EVALUATION
2023-01-05 12:56:17,225 INFO:   Leaving out SEQ value Fold_8
2023-01-05 12:56:17,237 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 12:56:17,238 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:56:17,886 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:56:17,886 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:56:17,956 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:56:17,956 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:56:17,956 INFO:     No hyperparam tuning for this model
2023-01-05 12:56:17,956 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:56:17,956 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:56:17,957 INFO:     None feature selector for col prot
2023-01-05 12:56:17,957 INFO:     None feature selector for col prot
2023-01-05 12:56:17,957 INFO:     None feature selector for col prot
2023-01-05 12:56:17,957 INFO:     None feature selector for col chem
2023-01-05 12:56:17,957 INFO:     None feature selector for col chem
2023-01-05 12:56:17,958 INFO:     None feature selector for col chem
2023-01-05 12:56:17,958 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:56:17,958 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:56:17,959 INFO:     Number of params in model 72901
2023-01-05 12:56:17,962 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:56:17,962 INFO:   Starting stage: TRAINING
2023-01-05 12:56:18,023 INFO:     Val loss before train {'Reaction outcome loss': 0.8733989159266154, 'Total loss': 0.8733989159266154}
2023-01-05 12:56:18,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:18,023 INFO:     Epoch: 0
2023-01-05 12:56:20,162 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7116710782051087, 'Total loss': 0.7116710782051087} | train loss {'Reaction outcome loss': 0.9389144597697432, 'Total loss': 0.9389144597697432}
2023-01-05 12:56:20,162 INFO:     Found new best model at epoch 0
2023-01-05 12:56:20,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:20,163 INFO:     Epoch: 1
2023-01-05 12:56:22,275 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6163968205451965, 'Total loss': 0.6163968205451965} | train loss {'Reaction outcome loss': 0.7658631660207345, 'Total loss': 0.7658631660207345}
2023-01-05 12:56:22,275 INFO:     Found new best model at epoch 1
2023-01-05 12:56:22,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:22,277 INFO:     Epoch: 2
2023-01-05 12:56:24,051 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4984274908900261, 'Total loss': 0.4984274908900261} | train loss {'Reaction outcome loss': 0.6080849293592202, 'Total loss': 0.6080849293592202}
2023-01-05 12:56:24,051 INFO:     Found new best model at epoch 2
2023-01-05 12:56:24,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:24,053 INFO:     Epoch: 3
2023-01-05 12:56:25,799 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4804161290327708, 'Total loss': 0.4804161290327708} | train loss {'Reaction outcome loss': 0.5504492613738471, 'Total loss': 0.5504492613738471}
2023-01-05 12:56:25,799 INFO:     Found new best model at epoch 3
2023-01-05 12:56:25,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:25,800 INFO:     Epoch: 4
2023-01-05 12:56:27,807 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47657384872436526, 'Total loss': 0.47657384872436526} | train loss {'Reaction outcome loss': 0.5112722082077151, 'Total loss': 0.5112722082077151}
2023-01-05 12:56:27,808 INFO:     Found new best model at epoch 4
2023-01-05 12:56:27,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:27,809 INFO:     Epoch: 5
2023-01-05 12:56:29,940 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4506673594315847, 'Total loss': 0.4506673594315847} | train loss {'Reaction outcome loss': 0.5074392899218267, 'Total loss': 0.5074392899218267}
2023-01-05 12:56:29,940 INFO:     Found new best model at epoch 5
2023-01-05 12:56:29,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:29,941 INFO:     Epoch: 6
2023-01-05 12:56:32,078 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4846030533313751, 'Total loss': 0.4846030533313751} | train loss {'Reaction outcome loss': 0.4912652802945924, 'Total loss': 0.4912652802945924}
2023-01-05 12:56:32,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:32,078 INFO:     Epoch: 7
2023-01-05 12:56:34,211 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5223666151364644, 'Total loss': 0.5223666151364644} | train loss {'Reaction outcome loss': 0.48191607901214684, 'Total loss': 0.48191607901214684}
2023-01-05 12:56:34,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:34,212 INFO:     Epoch: 8
2023-01-05 12:56:36,329 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4821555217107137, 'Total loss': 0.4821555217107137} | train loss {'Reaction outcome loss': 0.47497545786365103, 'Total loss': 0.47497545786365103}
2023-01-05 12:56:36,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:36,329 INFO:     Epoch: 9
2023-01-05 12:56:38,427 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4902504046758016, 'Total loss': 0.4902504046758016} | train loss {'Reaction outcome loss': 0.4692283477770151, 'Total loss': 0.4692283477770151}
2023-01-05 12:56:38,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:38,428 INFO:     Epoch: 10
2023-01-05 12:56:40,578 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46338544487953187, 'Total loss': 0.46338544487953187} | train loss {'Reaction outcome loss': 0.46574920818318416, 'Total loss': 0.46574920818318416}
2023-01-05 12:56:40,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:40,578 INFO:     Epoch: 11
2023-01-05 12:56:42,732 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47280923823515575, 'Total loss': 0.47280923823515575} | train loss {'Reaction outcome loss': 0.458854985171861, 'Total loss': 0.458854985171861}
2023-01-05 12:56:42,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:42,732 INFO:     Epoch: 12
2023-01-05 12:56:44,848 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46171490053335823, 'Total loss': 0.46171490053335823} | train loss {'Reaction outcome loss': 0.4551001864410665, 'Total loss': 0.4551001864410665}
2023-01-05 12:56:44,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:44,849 INFO:     Epoch: 13
2023-01-05 12:56:47,008 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48078113396962485, 'Total loss': 0.48078113396962485} | train loss {'Reaction outcome loss': 0.44886252634825496, 'Total loss': 0.44886252634825496}
2023-01-05 12:56:47,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:47,008 INFO:     Epoch: 14
2023-01-05 12:56:49,141 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4623356024424235, 'Total loss': 0.4623356024424235} | train loss {'Reaction outcome loss': 0.4452435056114719, 'Total loss': 0.4452435056114719}
2023-01-05 12:56:49,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:49,141 INFO:     Epoch: 15
2023-01-05 12:56:51,304 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48185279170672096, 'Total loss': 0.48185279170672096} | train loss {'Reaction outcome loss': 0.43842223623808285, 'Total loss': 0.43842223623808285}
2023-01-05 12:56:51,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:51,304 INFO:     Epoch: 16
2023-01-05 12:56:53,407 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4338071723779043, 'Total loss': 0.4338071723779043} | train loss {'Reaction outcome loss': 0.43345817822935806, 'Total loss': 0.43345817822935806}
2023-01-05 12:56:53,407 INFO:     Found new best model at epoch 16
2023-01-05 12:56:53,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:53,408 INFO:     Epoch: 17
2023-01-05 12:56:55,563 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4782441079616547, 'Total loss': 0.4782441079616547} | train loss {'Reaction outcome loss': 0.4292413638836711, 'Total loss': 0.4292413638836711}
2023-01-05 12:56:55,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:55,564 INFO:     Epoch: 18
2023-01-05 12:56:57,706 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44787291089693704, 'Total loss': 0.44787291089693704} | train loss {'Reaction outcome loss': 0.42365220798193104, 'Total loss': 0.42365220798193104}
2023-01-05 12:56:57,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:57,706 INFO:     Epoch: 19
2023-01-05 12:56:59,870 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4787714272737503, 'Total loss': 0.4787714272737503} | train loss {'Reaction outcome loss': 0.4201466492275252, 'Total loss': 0.4201466492275252}
2023-01-05 12:56:59,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:56:59,871 INFO:     Epoch: 20
2023-01-05 12:57:01,998 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4417344033718109, 'Total loss': 0.4417344033718109} | train loss {'Reaction outcome loss': 0.4192462782681423, 'Total loss': 0.4192462782681423}
2023-01-05 12:57:01,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:01,998 INFO:     Epoch: 21
2023-01-05 12:57:04,143 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48869913518428804, 'Total loss': 0.48869913518428804} | train loss {'Reaction outcome loss': 0.41391778511613825, 'Total loss': 0.41391778511613825}
2023-01-05 12:57:04,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:04,145 INFO:     Epoch: 22
2023-01-05 12:57:06,285 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47383596897125246, 'Total loss': 0.47383596897125246} | train loss {'Reaction outcome loss': 0.4163796890826121, 'Total loss': 0.4163796890826121}
2023-01-05 12:57:06,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:06,285 INFO:     Epoch: 23
2023-01-05 12:57:08,418 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45048204163710276, 'Total loss': 0.45048204163710276} | train loss {'Reaction outcome loss': 0.4088007657360421, 'Total loss': 0.4088007657360421}
2023-01-05 12:57:08,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:08,418 INFO:     Epoch: 24
2023-01-05 12:57:10,566 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4415125240882238, 'Total loss': 0.4415125240882238} | train loss {'Reaction outcome loss': 0.40320652348064157, 'Total loss': 0.40320652348064157}
2023-01-05 12:57:10,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:10,567 INFO:     Epoch: 25
2023-01-05 12:57:12,777 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48813509941101074, 'Total loss': 0.48813509941101074} | train loss {'Reaction outcome loss': 0.3982162900595334, 'Total loss': 0.3982162900595334}
2023-01-05 12:57:12,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:12,777 INFO:     Epoch: 26
2023-01-05 12:57:14,963 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4412498126427333, 'Total loss': 0.4412498126427333} | train loss {'Reaction outcome loss': 0.39988278214187517, 'Total loss': 0.39988278214187517}
2023-01-05 12:57:14,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:14,963 INFO:     Epoch: 27
2023-01-05 12:57:17,114 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44036027093728386, 'Total loss': 0.44036027093728386} | train loss {'Reaction outcome loss': 0.3894777469010684, 'Total loss': 0.3894777469010684}
2023-01-05 12:57:17,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:17,114 INFO:     Epoch: 28
2023-01-05 12:57:19,277 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48720525900522865, 'Total loss': 0.48720525900522865} | train loss {'Reaction outcome loss': 0.3883251141294511, 'Total loss': 0.3883251141294511}
2023-01-05 12:57:19,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:19,277 INFO:     Epoch: 29
2023-01-05 12:57:21,439 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4439313977956772, 'Total loss': 0.4439313977956772} | train loss {'Reaction outcome loss': 0.3845784573333107, 'Total loss': 0.3845784573333107}
2023-01-05 12:57:21,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:21,440 INFO:     Epoch: 30
2023-01-05 12:57:23,585 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4241055582960447, 'Total loss': 0.4241055582960447} | train loss {'Reaction outcome loss': 0.3819875868893888, 'Total loss': 0.3819875868893888}
2023-01-05 12:57:23,586 INFO:     Found new best model at epoch 30
2023-01-05 12:57:23,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:23,588 INFO:     Epoch: 31
2023-01-05 12:57:25,727 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4113827054699262, 'Total loss': 0.4113827054699262} | train loss {'Reaction outcome loss': 0.3761313143220261, 'Total loss': 0.3761313143220261}
2023-01-05 12:57:25,727 INFO:     Found new best model at epoch 31
2023-01-05 12:57:25,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:25,728 INFO:     Epoch: 32
2023-01-05 12:57:27,880 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42875096450249356, 'Total loss': 0.42875096450249356} | train loss {'Reaction outcome loss': 0.3772575842474934, 'Total loss': 0.3772575842474934}
2023-01-05 12:57:27,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:27,881 INFO:     Epoch: 33
2023-01-05 12:57:30,053 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4343947097659111, 'Total loss': 0.4343947097659111} | train loss {'Reaction outcome loss': 0.3817194544703421, 'Total loss': 0.3817194544703421}
2023-01-05 12:57:30,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:30,053 INFO:     Epoch: 34
2023-01-05 12:57:32,196 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4969659119844437, 'Total loss': 0.4969659119844437} | train loss {'Reaction outcome loss': 0.37532884238736475, 'Total loss': 0.37532884238736475}
2023-01-05 12:57:32,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:32,197 INFO:     Epoch: 35
2023-01-05 12:57:34,345 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4387001362939676, 'Total loss': 0.4387001362939676} | train loss {'Reaction outcome loss': 0.36647166431385236, 'Total loss': 0.36647166431385236}
2023-01-05 12:57:34,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:34,346 INFO:     Epoch: 36
2023-01-05 12:57:36,461 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4526299317677816, 'Total loss': 0.4526299317677816} | train loss {'Reaction outcome loss': 0.3652807919811593, 'Total loss': 0.3652807919811593}
2023-01-05 12:57:36,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:36,462 INFO:     Epoch: 37
2023-01-05 12:57:38,615 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4211908941467603, 'Total loss': 0.4211908941467603} | train loss {'Reaction outcome loss': 0.36563892113248797, 'Total loss': 0.36563892113248797}
2023-01-05 12:57:38,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:38,615 INFO:     Epoch: 38
2023-01-05 12:57:40,765 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4572524607181549, 'Total loss': 0.4572524607181549} | train loss {'Reaction outcome loss': 0.35062511580703903, 'Total loss': 0.35062511580703903}
2023-01-05 12:57:40,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:40,766 INFO:     Epoch: 39
2023-01-05 12:57:42,912 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4520454198122025, 'Total loss': 0.4520454198122025} | train loss {'Reaction outcome loss': 0.35220883002192, 'Total loss': 0.35220883002192}
2023-01-05 12:57:42,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:42,912 INFO:     Epoch: 40
2023-01-05 12:57:45,067 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40353613495826723, 'Total loss': 0.40353613495826723} | train loss {'Reaction outcome loss': 0.35210390201341496, 'Total loss': 0.35210390201341496}
2023-01-05 12:57:45,067 INFO:     Found new best model at epoch 40
2023-01-05 12:57:45,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:45,068 INFO:     Epoch: 41
2023-01-05 12:57:47,148 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44490345418453214, 'Total loss': 0.44490345418453214} | train loss {'Reaction outcome loss': 0.34868987861776, 'Total loss': 0.34868987861776}
2023-01-05 12:57:47,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:47,148 INFO:     Epoch: 42
2023-01-05 12:57:48,909 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41604466636975607, 'Total loss': 0.41604466636975607} | train loss {'Reaction outcome loss': 0.35314085127880973, 'Total loss': 0.35314085127880973}
2023-01-05 12:57:48,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:48,910 INFO:     Epoch: 43
2023-01-05 12:57:50,694 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43166692554950714, 'Total loss': 0.43166692554950714} | train loss {'Reaction outcome loss': 0.34303350482870193, 'Total loss': 0.34303350482870193}
2023-01-05 12:57:50,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:50,695 INFO:     Epoch: 44
2023-01-05 12:57:52,759 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4454209297895432, 'Total loss': 0.4454209297895432} | train loss {'Reaction outcome loss': 0.34568751513631674, 'Total loss': 0.34568751513631674}
2023-01-05 12:57:52,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:52,759 INFO:     Epoch: 45
2023-01-05 12:57:54,918 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43978266716003417, 'Total loss': 0.43978266716003417} | train loss {'Reaction outcome loss': 0.33916464783795125, 'Total loss': 0.33916464783795125}
2023-01-05 12:57:54,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:54,918 INFO:     Epoch: 46
2023-01-05 12:57:57,058 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41596947113672894, 'Total loss': 0.41596947113672894} | train loss {'Reaction outcome loss': 0.3396196474531924, 'Total loss': 0.3396196474531924}
2023-01-05 12:57:57,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:57,058 INFO:     Epoch: 47
2023-01-05 12:57:59,200 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41747942169507346, 'Total loss': 0.41747942169507346} | train loss {'Reaction outcome loss': 0.3355739888102904, 'Total loss': 0.3355739888102904}
2023-01-05 12:57:59,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:57:59,201 INFO:     Epoch: 48
2023-01-05 12:58:01,353 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4274828498562177, 'Total loss': 0.4274828498562177} | train loss {'Reaction outcome loss': 0.33827834055643446, 'Total loss': 0.33827834055643446}
2023-01-05 12:58:01,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:01,354 INFO:     Epoch: 49
2023-01-05 12:58:03,506 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45804977615674336, 'Total loss': 0.45804977615674336} | train loss {'Reaction outcome loss': 0.3259814210970254, 'Total loss': 0.3259814210970254}
2023-01-05 12:58:03,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:03,506 INFO:     Epoch: 50
2023-01-05 12:58:05,679 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4463241418202718, 'Total loss': 0.4463241418202718} | train loss {'Reaction outcome loss': 0.3259141050061605, 'Total loss': 0.3259141050061605}
2023-01-05 12:58:05,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:05,679 INFO:     Epoch: 51
2023-01-05 12:58:07,835 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4184907888372739, 'Total loss': 0.4184907888372739} | train loss {'Reaction outcome loss': 0.3260047231821248, 'Total loss': 0.3260047231821248}
2023-01-05 12:58:07,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:07,835 INFO:     Epoch: 52
2023-01-05 12:58:09,982 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4587712566057841, 'Total loss': 0.4587712566057841} | train loss {'Reaction outcome loss': 0.32722440802485403, 'Total loss': 0.32722440802485403}
2023-01-05 12:58:09,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:09,983 INFO:     Epoch: 53
2023-01-05 12:58:12,143 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4500673403342565, 'Total loss': 0.4500673403342565} | train loss {'Reaction outcome loss': 0.3189939539811581, 'Total loss': 0.3189939539811581}
2023-01-05 12:58:12,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:12,144 INFO:     Epoch: 54
2023-01-05 12:58:14,282 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4384062558412552, 'Total loss': 0.4384062558412552} | train loss {'Reaction outcome loss': 0.31482165449564037, 'Total loss': 0.31482165449564037}
2023-01-05 12:58:14,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:14,283 INFO:     Epoch: 55
2023-01-05 12:58:16,434 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3978290249903997, 'Total loss': 0.3978290249903997} | train loss {'Reaction outcome loss': 0.31192198335906884, 'Total loss': 0.31192198335906884}
2023-01-05 12:58:16,434 INFO:     Found new best model at epoch 55
2023-01-05 12:58:16,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:16,436 INFO:     Epoch: 56
2023-01-05 12:58:18,588 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44638316333293915, 'Total loss': 0.44638316333293915} | train loss {'Reaction outcome loss': 0.31283240110008387, 'Total loss': 0.31283240110008387}
2023-01-05 12:58:18,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:18,588 INFO:     Epoch: 57
2023-01-05 12:58:20,733 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4212902208169301, 'Total loss': 0.4212902208169301} | train loss {'Reaction outcome loss': 0.313362987875177, 'Total loss': 0.313362987875177}
2023-01-05 12:58:20,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:20,733 INFO:     Epoch: 58
2023-01-05 12:58:22,899 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42937301099300385, 'Total loss': 0.42937301099300385} | train loss {'Reaction outcome loss': 0.3103692486855018, 'Total loss': 0.3103692486855018}
2023-01-05 12:58:22,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:22,899 INFO:     Epoch: 59
2023-01-05 12:58:25,109 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43008487969636916, 'Total loss': 0.43008487969636916} | train loss {'Reaction outcome loss': 0.30033586452966626, 'Total loss': 0.30033586452966626}
2023-01-05 12:58:25,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:25,109 INFO:     Epoch: 60
2023-01-05 12:58:27,270 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41842519541581474, 'Total loss': 0.41842519541581474} | train loss {'Reaction outcome loss': 0.29978452391759325, 'Total loss': 0.29978452391759325}
2023-01-05 12:58:27,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:27,271 INFO:     Epoch: 61
2023-01-05 12:58:29,416 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.458122322956721, 'Total loss': 0.458122322956721} | train loss {'Reaction outcome loss': 0.2992155425332106, 'Total loss': 0.2992155425332106}
2023-01-05 12:58:29,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:29,417 INFO:     Epoch: 62
2023-01-05 12:58:31,568 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48145250976085663, 'Total loss': 0.48145250976085663} | train loss {'Reaction outcome loss': 0.2993890272222296, 'Total loss': 0.2993890272222296}
2023-01-05 12:58:31,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:31,568 INFO:     Epoch: 63
2023-01-05 12:58:33,692 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46389656762282055, 'Total loss': 0.46389656762282055} | train loss {'Reaction outcome loss': 0.29630262219775333, 'Total loss': 0.29630262219775333}
2023-01-05 12:58:33,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:33,692 INFO:     Epoch: 64
2023-01-05 12:58:35,827 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40685929656028746, 'Total loss': 0.40685929656028746} | train loss {'Reaction outcome loss': 0.2917108911150781, 'Total loss': 0.2917108911150781}
2023-01-05 12:58:35,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:35,827 INFO:     Epoch: 65
2023-01-05 12:58:38,016 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42579447229703266, 'Total loss': 0.42579447229703266} | train loss {'Reaction outcome loss': 0.2920991104422477, 'Total loss': 0.2920991104422477}
2023-01-05 12:58:38,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:38,017 INFO:     Epoch: 66
2023-01-05 12:58:40,141 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4294372151295344, 'Total loss': 0.4294372151295344} | train loss {'Reaction outcome loss': 0.28625800731136414, 'Total loss': 0.28625800731136414}
2023-01-05 12:58:40,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:40,142 INFO:     Epoch: 67
2023-01-05 12:58:42,339 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4244832744201024, 'Total loss': 0.4244832744201024} | train loss {'Reaction outcome loss': 0.2909927359054776, 'Total loss': 0.2909927359054776}
2023-01-05 12:58:42,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:42,339 INFO:     Epoch: 68
2023-01-05 12:58:44,521 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48346127072970074, 'Total loss': 0.48346127072970074} | train loss {'Reaction outcome loss': 0.2924450717213815, 'Total loss': 0.2924450717213815}
2023-01-05 12:58:44,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:44,521 INFO:     Epoch: 69
2023-01-05 12:58:46,712 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41907493670781454, 'Total loss': 0.41907493670781454} | train loss {'Reaction outcome loss': 0.2871548558456184, 'Total loss': 0.2871548558456184}
2023-01-05 12:58:46,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:46,713 INFO:     Epoch: 70
2023-01-05 12:58:48,887 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3791140784819921, 'Total loss': 0.3791140784819921} | train loss {'Reaction outcome loss': 0.2802338056184732, 'Total loss': 0.2802338056184732}
2023-01-05 12:58:48,887 INFO:     Found new best model at epoch 70
2023-01-05 12:58:48,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:48,888 INFO:     Epoch: 71
2023-01-05 12:58:51,013 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4376909772555033, 'Total loss': 0.4376909772555033} | train loss {'Reaction outcome loss': 0.2869804123770038, 'Total loss': 0.2869804123770038}
2023-01-05 12:58:51,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:51,013 INFO:     Epoch: 72
2023-01-05 12:58:53,168 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4006318587809801, 'Total loss': 0.4006318587809801} | train loss {'Reaction outcome loss': 0.28375210572224463, 'Total loss': 0.28375210572224463}
2023-01-05 12:58:53,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:53,169 INFO:     Epoch: 73
2023-01-05 12:58:55,315 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37721512615680697, 'Total loss': 0.37721512615680697} | train loss {'Reaction outcome loss': 0.2791227361962308, 'Total loss': 0.2791227361962308}
2023-01-05 12:58:55,315 INFO:     Found new best model at epoch 73
2023-01-05 12:58:55,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:55,317 INFO:     Epoch: 74
2023-01-05 12:58:57,445 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40168389479319255, 'Total loss': 0.40168389479319255} | train loss {'Reaction outcome loss': 0.27759111459183433, 'Total loss': 0.27759111459183433}
2023-01-05 12:58:57,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:57,446 INFO:     Epoch: 75
2023-01-05 12:58:59,582 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4262049277623495, 'Total loss': 0.4262049277623495} | train loss {'Reaction outcome loss': 0.2689202573476699, 'Total loss': 0.2689202573476699}
2023-01-05 12:58:59,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:58:59,582 INFO:     Epoch: 76
2023-01-05 12:59:01,719 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4112582003076871, 'Total loss': 0.4112582003076871} | train loss {'Reaction outcome loss': 0.2706665860040344, 'Total loss': 0.2706665860040344}
2023-01-05 12:59:01,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:01,719 INFO:     Epoch: 77
2023-01-05 12:59:03,843 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39314932425816856, 'Total loss': 0.39314932425816856} | train loss {'Reaction outcome loss': 0.2762020942449135, 'Total loss': 0.2762020942449135}
2023-01-05 12:59:03,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:03,843 INFO:     Epoch: 78
2023-01-05 12:59:05,997 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4627947360277176, 'Total loss': 0.4627947360277176} | train loss {'Reaction outcome loss': 0.266255354128071, 'Total loss': 0.266255354128071}
2023-01-05 12:59:05,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:05,998 INFO:     Epoch: 79
2023-01-05 12:59:08,141 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38240512907505037, 'Total loss': 0.38240512907505037} | train loss {'Reaction outcome loss': 0.27408636166938466, 'Total loss': 0.27408636166938466}
2023-01-05 12:59:08,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:08,141 INFO:     Epoch: 80
2023-01-05 12:59:10,274 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42796894411245984, 'Total loss': 0.42796894411245984} | train loss {'Reaction outcome loss': 0.2671015670754179, 'Total loss': 0.2671015670754179}
2023-01-05 12:59:10,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:10,274 INFO:     Epoch: 81
2023-01-05 12:59:12,427 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3995018914341927, 'Total loss': 0.3995018914341927} | train loss {'Reaction outcome loss': 0.2604786919321131, 'Total loss': 0.2604786919321131}
2023-01-05 12:59:12,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:12,427 INFO:     Epoch: 82
2023-01-05 12:59:14,562 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4044252435366313, 'Total loss': 0.4044252435366313} | train loss {'Reaction outcome loss': 0.25915654331282545, 'Total loss': 0.25915654331282545}
2023-01-05 12:59:14,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:14,562 INFO:     Epoch: 83
2023-01-05 12:59:16,725 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43093618551890056, 'Total loss': 0.43093618551890056} | train loss {'Reaction outcome loss': 0.2693457319027316, 'Total loss': 0.2693457319027316}
2023-01-05 12:59:16,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:16,726 INFO:     Epoch: 84
2023-01-05 12:59:18,859 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39671415587266284, 'Total loss': 0.39671415587266284} | train loss {'Reaction outcome loss': 0.2553874205417224, 'Total loss': 0.2553874205417224}
2023-01-05 12:59:18,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:18,860 INFO:     Epoch: 85
2023-01-05 12:59:20,995 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3815982381502787, 'Total loss': 0.3815982381502787} | train loss {'Reaction outcome loss': 0.26319606985597715, 'Total loss': 0.26319606985597715}
2023-01-05 12:59:20,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:20,996 INFO:     Epoch: 86
2023-01-05 12:59:23,157 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44440954526265464, 'Total loss': 0.44440954526265464} | train loss {'Reaction outcome loss': 0.25777934692854426, 'Total loss': 0.25777934692854426}
2023-01-05 12:59:23,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:23,159 INFO:     Epoch: 87
2023-01-05 12:59:25,306 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4398501972357432, 'Total loss': 0.4398501972357432} | train loss {'Reaction outcome loss': 0.2518128564948366, 'Total loss': 0.2518128564948366}
2023-01-05 12:59:25,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:25,307 INFO:     Epoch: 88
2023-01-05 12:59:27,460 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40774778872728346, 'Total loss': 0.40774778872728346} | train loss {'Reaction outcome loss': 0.26616355945376585, 'Total loss': 0.26616355945376585}
2023-01-05 12:59:27,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:27,461 INFO:     Epoch: 89
2023-01-05 12:59:29,619 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41827661395072935, 'Total loss': 0.41827661395072935} | train loss {'Reaction outcome loss': 0.2575604878230034, 'Total loss': 0.2575604878230034}
2023-01-05 12:59:29,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:29,620 INFO:     Epoch: 90
2023-01-05 12:59:31,772 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3969862659772237, 'Total loss': 0.3969862659772237} | train loss {'Reaction outcome loss': 0.25874443806327174, 'Total loss': 0.25874443806327174}
2023-01-05 12:59:31,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:31,772 INFO:     Epoch: 91
2023-01-05 12:59:33,921 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40744486848513284, 'Total loss': 0.40744486848513284} | train loss {'Reaction outcome loss': 0.25916527965561537, 'Total loss': 0.25916527965561537}
2023-01-05 12:59:33,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:33,922 INFO:     Epoch: 92
2023-01-05 12:59:36,087 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40281661798556645, 'Total loss': 0.40281661798556645} | train loss {'Reaction outcome loss': 0.25518075297212733, 'Total loss': 0.25518075297212733}
2023-01-05 12:59:36,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:36,087 INFO:     Epoch: 93
2023-01-05 12:59:38,222 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.431618112574021, 'Total loss': 0.431618112574021} | train loss {'Reaction outcome loss': 0.2552410282235402, 'Total loss': 0.2552410282235402}
2023-01-05 12:59:38,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:38,222 INFO:     Epoch: 94
2023-01-05 12:59:40,390 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44747171700000765, 'Total loss': 0.44747171700000765} | train loss {'Reaction outcome loss': 0.24948638003237927, 'Total loss': 0.24948638003237927}
2023-01-05 12:59:40,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:40,390 INFO:     Epoch: 95
2023-01-05 12:59:42,543 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42272747655709586, 'Total loss': 0.42272747655709586} | train loss {'Reaction outcome loss': 0.2547860288054404, 'Total loss': 0.2547860288054404}
2023-01-05 12:59:42,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:42,544 INFO:     Epoch: 96
2023-01-05 12:59:44,707 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4088940213123957, 'Total loss': 0.4088940213123957} | train loss {'Reaction outcome loss': 0.2429569989483613, 'Total loss': 0.2429569989483613}
2023-01-05 12:59:44,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:44,707 INFO:     Epoch: 97
2023-01-05 12:59:46,879 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.458645768960317, 'Total loss': 0.458645768960317} | train loss {'Reaction outcome loss': 0.24798404509677505, 'Total loss': 0.24798404509677505}
2023-01-05 12:59:46,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:46,879 INFO:     Epoch: 98
2023-01-05 12:59:49,027 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4619596203168233, 'Total loss': 0.4619596203168233} | train loss {'Reaction outcome loss': 0.2513449679325967, 'Total loss': 0.2513449679325967}
2023-01-05 12:59:49,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:49,027 INFO:     Epoch: 99
2023-01-05 12:59:51,179 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40106587012608846, 'Total loss': 0.40106587012608846} | train loss {'Reaction outcome loss': 0.24654311463780645, 'Total loss': 0.24654311463780645}
2023-01-05 12:59:51,180 INFO:     Best model found after epoch 74 of 100.
2023-01-05 12:59:51,180 INFO:   Done with stage: TRAINING
2023-01-05 12:59:51,180 INFO:   Starting stage: EVALUATION
2023-01-05 12:59:51,319 INFO:   Done with stage: EVALUATION
2023-01-05 12:59:51,319 INFO:   Leaving out SEQ value Fold_9
2023-01-05 12:59:51,332 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 12:59:51,332 INFO:   Starting stage: FEATURE SCALING
2023-01-05 12:59:51,991 INFO:   Done with stage: FEATURE SCALING
2023-01-05 12:59:51,991 INFO:   Starting stage: SCALING TARGETS
2023-01-05 12:59:52,061 INFO:   Done with stage: SCALING TARGETS
2023-01-05 12:59:52,061 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:59:52,061 INFO:     No hyperparam tuning for this model
2023-01-05 12:59:52,061 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 12:59:52,061 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 12:59:52,062 INFO:     None feature selector for col prot
2023-01-05 12:59:52,062 INFO:     None feature selector for col prot
2023-01-05 12:59:52,062 INFO:     None feature selector for col prot
2023-01-05 12:59:52,063 INFO:     None feature selector for col chem
2023-01-05 12:59:52,063 INFO:     None feature selector for col chem
2023-01-05 12:59:52,063 INFO:     None feature selector for col chem
2023-01-05 12:59:52,063 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 12:59:52,063 INFO:   Starting stage: BUILD MODEL
2023-01-05 12:59:52,065 INFO:     Number of params in model 72901
2023-01-05 12:59:52,068 INFO:   Done with stage: BUILD MODEL
2023-01-05 12:59:52,068 INFO:   Starting stage: TRAINING
2023-01-05 12:59:52,128 INFO:     Val loss before train {'Reaction outcome loss': 1.051679269472758, 'Total loss': 1.051679269472758}
2023-01-05 12:59:52,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:52,128 INFO:     Epoch: 0
2023-01-05 12:59:54,298 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7996467222770055, 'Total loss': 0.7996467222770055} | train loss {'Reaction outcome loss': 0.9035459617557733, 'Total loss': 0.9035459617557733}
2023-01-05 12:59:54,299 INFO:     Found new best model at epoch 0
2023-01-05 12:59:54,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:54,301 INFO:     Epoch: 1
2023-01-05 12:59:56,465 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5905811846256256, 'Total loss': 0.5905811846256256} | train loss {'Reaction outcome loss': 0.6789732280632724, 'Total loss': 0.6789732280632724}
2023-01-05 12:59:56,465 INFO:     Found new best model at epoch 1
2023-01-05 12:59:56,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:56,467 INFO:     Epoch: 2
2023-01-05 12:59:58,629 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5699416895707449, 'Total loss': 0.5699416895707449} | train loss {'Reaction outcome loss': 0.5655111430779748, 'Total loss': 0.5655111430779748}
2023-01-05 12:59:58,630 INFO:     Found new best model at epoch 2
2023-01-05 12:59:58,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 12:59:58,631 INFO:     Epoch: 3
2023-01-05 13:00:00,634 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5441842277844747, 'Total loss': 0.5441842277844747} | train loss {'Reaction outcome loss': 0.5311546205320274, 'Total loss': 0.5311546205320274}
2023-01-05 13:00:00,635 INFO:     Found new best model at epoch 3
2023-01-05 13:00:00,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:00,636 INFO:     Epoch: 4
2023-01-05 13:00:02,844 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5505660971005758, 'Total loss': 0.5505660971005758} | train loss {'Reaction outcome loss': 0.5041038449940126, 'Total loss': 0.5041038449940126}
2023-01-05 13:00:02,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:02,844 INFO:     Epoch: 5
2023-01-05 13:00:04,994 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5177448928356171, 'Total loss': 0.5177448928356171} | train loss {'Reaction outcome loss': 0.489753367505398, 'Total loss': 0.489753367505398}
2023-01-05 13:00:04,995 INFO:     Found new best model at epoch 5
2023-01-05 13:00:04,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:04,996 INFO:     Epoch: 6
2023-01-05 13:00:07,159 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5169920961062113, 'Total loss': 0.5169920961062113} | train loss {'Reaction outcome loss': 0.48957118251448684, 'Total loss': 0.48957118251448684}
2023-01-05 13:00:07,159 INFO:     Found new best model at epoch 6
2023-01-05 13:00:07,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:07,161 INFO:     Epoch: 7
2023-01-05 13:00:09,313 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5365223745505016, 'Total loss': 0.5365223745505016} | train loss {'Reaction outcome loss': 0.4825212942517322, 'Total loss': 0.4825212942517322}
2023-01-05 13:00:09,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:09,313 INFO:     Epoch: 8
2023-01-05 13:00:11,473 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49691860675811766, 'Total loss': 0.49691860675811766} | train loss {'Reaction outcome loss': 0.47828411849796015, 'Total loss': 0.47828411849796015}
2023-01-05 13:00:11,473 INFO:     Found new best model at epoch 8
2023-01-05 13:00:11,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:11,474 INFO:     Epoch: 9
2023-01-05 13:00:13,620 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5103854487339655, 'Total loss': 0.5103854487339655} | train loss {'Reaction outcome loss': 0.47093786315425584, 'Total loss': 0.47093786315425584}
2023-01-05 13:00:13,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:13,621 INFO:     Epoch: 10
2023-01-05 13:00:15,797 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5159821589787801, 'Total loss': 0.5159821589787801} | train loss {'Reaction outcome loss': 0.4811755111306042, 'Total loss': 0.4811755111306042}
2023-01-05 13:00:15,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:15,797 INFO:     Epoch: 11
2023-01-05 13:00:17,940 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.51422571738561, 'Total loss': 0.51422571738561} | train loss {'Reaction outcome loss': 0.5240692037150966, 'Total loss': 0.5240692037150966}
2023-01-05 13:00:17,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:17,941 INFO:     Epoch: 12
2023-01-05 13:00:20,111 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4902331610520681, 'Total loss': 0.4902331610520681} | train loss {'Reaction outcome loss': 0.45672972524957056, 'Total loss': 0.45672972524957056}
2023-01-05 13:00:20,111 INFO:     Found new best model at epoch 12
2023-01-05 13:00:20,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:20,113 INFO:     Epoch: 13
2023-01-05 13:00:22,284 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5040741920471191, 'Total loss': 0.5040741920471191} | train loss {'Reaction outcome loss': 0.44645362669720984, 'Total loss': 0.44645362669720984}
2023-01-05 13:00:22,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:22,285 INFO:     Epoch: 14
2023-01-05 13:00:24,434 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48646085063616434, 'Total loss': 0.48646085063616434} | train loss {'Reaction outcome loss': 0.44486083978773566, 'Total loss': 0.44486083978773566}
2023-01-05 13:00:24,434 INFO:     Found new best model at epoch 14
2023-01-05 13:00:24,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:24,435 INFO:     Epoch: 15
2023-01-05 13:00:26,596 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48719120820363365, 'Total loss': 0.48719120820363365} | train loss {'Reaction outcome loss': 0.4369856850606848, 'Total loss': 0.4369856850606848}
2023-01-05 13:00:26,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:26,596 INFO:     Epoch: 16
2023-01-05 13:00:28,741 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4943093319733938, 'Total loss': 0.4943093319733938} | train loss {'Reaction outcome loss': 0.43150426925200486, 'Total loss': 0.43150426925200486}
2023-01-05 13:00:28,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:28,742 INFO:     Epoch: 17
2023-01-05 13:00:30,919 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5154163261254628, 'Total loss': 0.5154163261254628} | train loss {'Reaction outcome loss': 0.43359034978177236, 'Total loss': 0.43359034978177236}
2023-01-05 13:00:30,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:30,919 INFO:     Epoch: 18
2023-01-05 13:00:33,061 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48331809441248574, 'Total loss': 0.48331809441248574} | train loss {'Reaction outcome loss': 0.4271623404777568, 'Total loss': 0.4271623404777568}
2023-01-05 13:00:33,061 INFO:     Found new best model at epoch 18
2023-01-05 13:00:33,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:33,063 INFO:     Epoch: 19
2023-01-05 13:00:35,210 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5018123298883438, 'Total loss': 0.5018123298883438} | train loss {'Reaction outcome loss': 0.4287662153088815, 'Total loss': 0.4287662153088815}
2023-01-05 13:00:35,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:35,211 INFO:     Epoch: 20
2023-01-05 13:00:37,373 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49445467392603554, 'Total loss': 0.49445467392603554} | train loss {'Reaction outcome loss': 0.4151789130424942, 'Total loss': 0.4151789130424942}
2023-01-05 13:00:37,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:37,373 INFO:     Epoch: 21
2023-01-05 13:00:39,553 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47968610227108, 'Total loss': 0.47968610227108} | train loss {'Reaction outcome loss': 0.409242672610518, 'Total loss': 0.409242672610518}
2023-01-05 13:00:39,553 INFO:     Found new best model at epoch 21
2023-01-05 13:00:39,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:39,554 INFO:     Epoch: 22
2023-01-05 13:00:41,713 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4900411943594615, 'Total loss': 0.4900411943594615} | train loss {'Reaction outcome loss': 0.4029493932230516, 'Total loss': 0.4029493932230516}
2023-01-05 13:00:41,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:41,713 INFO:     Epoch: 23
2023-01-05 13:00:43,888 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5593269765377045, 'Total loss': 0.5593269765377045} | train loss {'Reaction outcome loss': 0.41397283339630003, 'Total loss': 0.41397283339630003}
2023-01-05 13:00:43,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:43,888 INFO:     Epoch: 24
2023-01-05 13:00:46,062 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.477640692392985, 'Total loss': 0.477640692392985} | train loss {'Reaction outcome loss': 0.4495796943758277, 'Total loss': 0.4495796943758277}
2023-01-05 13:00:46,062 INFO:     Found new best model at epoch 24
2023-01-05 13:00:46,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:46,063 INFO:     Epoch: 25
2023-01-05 13:00:48,217 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46911110083262125, 'Total loss': 0.46911110083262125} | train loss {'Reaction outcome loss': 0.4033582246983829, 'Total loss': 0.4033582246983829}
2023-01-05 13:00:48,218 INFO:     Found new best model at epoch 25
2023-01-05 13:00:48,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:48,219 INFO:     Epoch: 26
2023-01-05 13:00:50,365 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4710486570994059, 'Total loss': 0.4710486570994059} | train loss {'Reaction outcome loss': 0.39824317661586445, 'Total loss': 0.39824317661586445}
2023-01-05 13:00:50,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:50,365 INFO:     Epoch: 27
2023-01-05 13:00:52,530 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49901665449142457, 'Total loss': 0.49901665449142457} | train loss {'Reaction outcome loss': 0.39286307499244594, 'Total loss': 0.39286307499244594}
2023-01-05 13:00:52,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:52,530 INFO:     Epoch: 28
2023-01-05 13:00:54,707 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47059214214483897, 'Total loss': 0.47059214214483897} | train loss {'Reaction outcome loss': 0.42281593159650976, 'Total loss': 0.42281593159650976}
2023-01-05 13:00:54,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:54,708 INFO:     Epoch: 29
2023-01-05 13:00:56,869 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4642323742310206, 'Total loss': 0.4642323742310206} | train loss {'Reaction outcome loss': 0.4064951707150085, 'Total loss': 0.4064951707150085}
2023-01-05 13:00:56,869 INFO:     Found new best model at epoch 29
2023-01-05 13:00:56,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:56,871 INFO:     Epoch: 30
2023-01-05 13:00:59,037 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4573912024497986, 'Total loss': 0.4573912024497986} | train loss {'Reaction outcome loss': 0.383763694255849, 'Total loss': 0.383763694255849}
2023-01-05 13:00:59,037 INFO:     Found new best model at epoch 30
2023-01-05 13:00:59,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:00:59,038 INFO:     Epoch: 31
2023-01-05 13:01:01,217 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4897245039542516, 'Total loss': 0.4897245039542516} | train loss {'Reaction outcome loss': 0.3839494024902798, 'Total loss': 0.3839494024902798}
2023-01-05 13:01:01,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:01,217 INFO:     Epoch: 32
2023-01-05 13:01:03,383 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47959517215689024, 'Total loss': 0.47959517215689024} | train loss {'Reaction outcome loss': 0.37869129351157177, 'Total loss': 0.37869129351157177}
2023-01-05 13:01:03,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:03,383 INFO:     Epoch: 33
2023-01-05 13:01:05,535 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4515433887640635, 'Total loss': 0.4515433887640635} | train loss {'Reaction outcome loss': 0.3708736491592034, 'Total loss': 0.3708736491592034}
2023-01-05 13:01:05,536 INFO:     Found new best model at epoch 33
2023-01-05 13:01:05,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:05,537 INFO:     Epoch: 34
2023-01-05 13:01:07,725 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46072733650604886, 'Total loss': 0.46072733650604886} | train loss {'Reaction outcome loss': 0.3748153888563916, 'Total loss': 0.3748153888563916}
2023-01-05 13:01:07,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:07,726 INFO:     Epoch: 35
2023-01-05 13:01:09,919 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43991161783536276, 'Total loss': 0.43991161783536276} | train loss {'Reaction outcome loss': 0.3661519911020414, 'Total loss': 0.3661519911020414}
2023-01-05 13:01:09,919 INFO:     Found new best model at epoch 35
2023-01-05 13:01:09,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:09,920 INFO:     Epoch: 36
2023-01-05 13:01:12,084 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4316448181867599, 'Total loss': 0.4316448181867599} | train loss {'Reaction outcome loss': 0.36297147794697515, 'Total loss': 0.36297147794697515}
2023-01-05 13:01:12,085 INFO:     Found new best model at epoch 36
2023-01-05 13:01:12,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:12,086 INFO:     Epoch: 37
2023-01-05 13:01:14,258 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4651170055071513, 'Total loss': 0.4651170055071513} | train loss {'Reaction outcome loss': 0.356038271928665, 'Total loss': 0.356038271928665}
2023-01-05 13:01:14,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:14,258 INFO:     Epoch: 38
2023-01-05 13:01:16,439 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4444818327824275, 'Total loss': 0.4444818327824275} | train loss {'Reaction outcome loss': 0.3599792711733692, 'Total loss': 0.3599792711733692}
2023-01-05 13:01:16,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:16,439 INFO:     Epoch: 39
2023-01-05 13:01:18,626 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43509669105211896, 'Total loss': 0.43509669105211896} | train loss {'Reaction outcome loss': 0.36664191922307876, 'Total loss': 0.36664191922307876}
2023-01-05 13:01:18,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:18,626 INFO:     Epoch: 40
2023-01-05 13:01:20,808 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47168662945429485, 'Total loss': 0.47168662945429485} | train loss {'Reaction outcome loss': 0.36097509195299254, 'Total loss': 0.36097509195299254}
2023-01-05 13:01:20,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:20,809 INFO:     Epoch: 41
2023-01-05 13:01:22,985 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48417765100797017, 'Total loss': 0.48417765100797017} | train loss {'Reaction outcome loss': 0.35050918771615386, 'Total loss': 0.35050918771615386}
2023-01-05 13:01:22,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:22,986 INFO:     Epoch: 42
2023-01-05 13:01:25,161 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4794683873653412, 'Total loss': 0.4794683873653412} | train loss {'Reaction outcome loss': 0.3453742424701003, 'Total loss': 0.3453742424701003}
2023-01-05 13:01:25,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:25,162 INFO:     Epoch: 43
2023-01-05 13:01:27,340 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4516798337300619, 'Total loss': 0.4516798337300619} | train loss {'Reaction outcome loss': 0.340967133844548, 'Total loss': 0.340967133844548}
2023-01-05 13:01:27,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:27,340 INFO:     Epoch: 44
2023-01-05 13:01:29,515 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4603957235813141, 'Total loss': 0.4603957235813141} | train loss {'Reaction outcome loss': 0.3497291906565753, 'Total loss': 0.3497291906565753}
2023-01-05 13:01:29,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:29,516 INFO:     Epoch: 45
2023-01-05 13:01:31,709 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45001577933629355, 'Total loss': 0.45001577933629355} | train loss {'Reaction outcome loss': 0.33547682582360244, 'Total loss': 0.33547682582360244}
2023-01-05 13:01:31,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:31,709 INFO:     Epoch: 46
2023-01-05 13:01:33,897 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4570304493109385, 'Total loss': 0.4570304493109385} | train loss {'Reaction outcome loss': 0.3343900983167839, 'Total loss': 0.3343900983167839}
2023-01-05 13:01:33,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:33,897 INFO:     Epoch: 47
2023-01-05 13:01:36,104 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44636561373869577, 'Total loss': 0.44636561373869577} | train loss {'Reaction outcome loss': 0.3316744884781445, 'Total loss': 0.3316744884781445}
2023-01-05 13:01:36,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:36,106 INFO:     Epoch: 48
2023-01-05 13:01:38,280 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4491182694832484, 'Total loss': 0.4491182694832484} | train loss {'Reaction outcome loss': 0.3266285149324888, 'Total loss': 0.3266285149324888}
2023-01-05 13:01:38,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:38,280 INFO:     Epoch: 49
2023-01-05 13:01:40,474 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42628615299860634, 'Total loss': 0.42628615299860634} | train loss {'Reaction outcome loss': 0.32927786369565065, 'Total loss': 0.32927786369565065}
2023-01-05 13:01:40,475 INFO:     Found new best model at epoch 49
2023-01-05 13:01:40,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:40,476 INFO:     Epoch: 50
2023-01-05 13:01:42,666 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4231660395860672, 'Total loss': 0.4231660395860672} | train loss {'Reaction outcome loss': 0.31858643983234314, 'Total loss': 0.31858643983234314}
2023-01-05 13:01:42,667 INFO:     Found new best model at epoch 50
2023-01-05 13:01:42,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:42,668 INFO:     Epoch: 51
2023-01-05 13:01:44,862 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49446231325467427, 'Total loss': 0.49446231325467427} | train loss {'Reaction outcome loss': 0.32452773366937926, 'Total loss': 0.32452773366937926}
2023-01-05 13:01:44,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:44,862 INFO:     Epoch: 52
2023-01-05 13:01:47,026 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4662446578343709, 'Total loss': 0.4662446578343709} | train loss {'Reaction outcome loss': 0.31802236455479177, 'Total loss': 0.31802236455479177}
2023-01-05 13:01:47,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:47,027 INFO:     Epoch: 53
2023-01-05 13:01:49,203 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43633255958557127, 'Total loss': 0.43633255958557127} | train loss {'Reaction outcome loss': 0.3127483235726106, 'Total loss': 0.3127483235726106}
2023-01-05 13:01:49,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:49,203 INFO:     Epoch: 54
2023-01-05 13:01:51,483 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46746153632799786, 'Total loss': 0.46746153632799786} | train loss {'Reaction outcome loss': 0.31240251924390433, 'Total loss': 0.31240251924390433}
2023-01-05 13:01:51,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:51,483 INFO:     Epoch: 55
2023-01-05 13:01:53,844 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4579386502504349, 'Total loss': 0.4579386502504349} | train loss {'Reaction outcome loss': 0.3092837530269247, 'Total loss': 0.3092837530269247}
2023-01-05 13:01:53,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:53,844 INFO:     Epoch: 56
2023-01-05 13:01:56,050 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42605948249499004, 'Total loss': 0.42605948249499004} | train loss {'Reaction outcome loss': 0.3096745741027205, 'Total loss': 0.3096745741027205}
2023-01-05 13:01:56,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:56,051 INFO:     Epoch: 57
2023-01-05 13:01:58,215 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44736174046993255, 'Total loss': 0.44736174046993255} | train loss {'Reaction outcome loss': 0.3102208112250082, 'Total loss': 0.3102208112250082}
2023-01-05 13:01:58,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:01:58,215 INFO:     Epoch: 58
2023-01-05 13:02:00,383 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46857257684071857, 'Total loss': 0.46857257684071857} | train loss {'Reaction outcome loss': 0.301897433825998, 'Total loss': 0.301897433825998}
2023-01-05 13:02:00,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:00,384 INFO:     Epoch: 59
2023-01-05 13:02:02,547 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4373414079348246, 'Total loss': 0.4373414079348246} | train loss {'Reaction outcome loss': 0.29949659429342096, 'Total loss': 0.29949659429342096}
2023-01-05 13:02:02,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:02,547 INFO:     Epoch: 60
2023-01-05 13:02:04,740 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43495467205842336, 'Total loss': 0.43495467205842336} | train loss {'Reaction outcome loss': 0.3014247610684623, 'Total loss': 0.3014247610684623}
2023-01-05 13:02:04,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:04,740 INFO:     Epoch: 61
2023-01-05 13:02:06,922 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4383930971225103, 'Total loss': 0.4383930971225103} | train loss {'Reaction outcome loss': 0.29177600679500704, 'Total loss': 0.29177600679500704}
2023-01-05 13:02:06,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:06,924 INFO:     Epoch: 62
2023-01-05 13:02:09,096 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41849275430043537, 'Total loss': 0.41849275430043537} | train loss {'Reaction outcome loss': 0.2962694048111334, 'Total loss': 0.2962694048111334}
2023-01-05 13:02:09,096 INFO:     Found new best model at epoch 62
2023-01-05 13:02:09,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:09,098 INFO:     Epoch: 63
2023-01-05 13:02:11,265 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4434662143389384, 'Total loss': 0.4434662143389384} | train loss {'Reaction outcome loss': 0.2886313404010582, 'Total loss': 0.2886313404010582}
2023-01-05 13:02:11,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:11,265 INFO:     Epoch: 64
2023-01-05 13:02:13,431 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43406405051549274, 'Total loss': 0.43406405051549274} | train loss {'Reaction outcome loss': 0.29156746303298225, 'Total loss': 0.29156746303298225}
2023-01-05 13:02:13,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:13,432 INFO:     Epoch: 65
2023-01-05 13:02:15,603 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43325834373633065, 'Total loss': 0.43325834373633065} | train loss {'Reaction outcome loss': 0.3152917032332524, 'Total loss': 0.3152917032332524}
2023-01-05 13:02:15,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:15,604 INFO:     Epoch: 66
2023-01-05 13:02:17,779 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43428006718556084, 'Total loss': 0.43428006718556084} | train loss {'Reaction outcome loss': 0.28645982294498634, 'Total loss': 0.28645982294498634}
2023-01-05 13:02:17,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:17,779 INFO:     Epoch: 67
2023-01-05 13:02:19,948 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46705528199672697, 'Total loss': 0.46705528199672697} | train loss {'Reaction outcome loss': 0.28747609152460296, 'Total loss': 0.28747609152460296}
2023-01-05 13:02:19,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:19,948 INFO:     Epoch: 68
2023-01-05 13:02:22,109 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.455437046289444, 'Total loss': 0.455437046289444} | train loss {'Reaction outcome loss': 0.28034945182135096, 'Total loss': 0.28034945182135096}
2023-01-05 13:02:22,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:22,110 INFO:     Epoch: 69
2023-01-05 13:02:24,286 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46793920199076333, 'Total loss': 0.46793920199076333} | train loss {'Reaction outcome loss': 0.2847751378480546, 'Total loss': 0.2847751378480546}
2023-01-05 13:02:24,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:24,286 INFO:     Epoch: 70
2023-01-05 13:02:26,445 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44360046287377675, 'Total loss': 0.44360046287377675} | train loss {'Reaction outcome loss': 0.27493725592891377, 'Total loss': 0.27493725592891377}
2023-01-05 13:02:26,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:26,446 INFO:     Epoch: 71
2023-01-05 13:02:28,613 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4796244889497757, 'Total loss': 0.4796244889497757} | train loss {'Reaction outcome loss': 0.28102519736368803, 'Total loss': 0.28102519736368803}
2023-01-05 13:02:28,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:28,613 INFO:     Epoch: 72
2023-01-05 13:02:30,788 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45225754876931507, 'Total loss': 0.45225754876931507} | train loss {'Reaction outcome loss': 0.2789398580401515, 'Total loss': 0.2789398580401515}
2023-01-05 13:02:30,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:30,789 INFO:     Epoch: 73
2023-01-05 13:02:32,948 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41972289979457855, 'Total loss': 0.41972289979457855} | train loss {'Reaction outcome loss': 0.2687236747225288, 'Total loss': 0.2687236747225288}
2023-01-05 13:02:32,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:32,948 INFO:     Epoch: 74
2023-01-05 13:02:35,109 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45886992613474525, 'Total loss': 0.45886992613474525} | train loss {'Reaction outcome loss': 0.3024606188232808, 'Total loss': 0.3024606188232808}
2023-01-05 13:02:35,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:35,109 INFO:     Epoch: 75
2023-01-05 13:02:37,282 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4598641653855642, 'Total loss': 0.4598641653855642} | train loss {'Reaction outcome loss': 0.2743173164916157, 'Total loss': 0.2743173164916157}
2023-01-05 13:02:37,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:37,283 INFO:     Epoch: 76
2023-01-05 13:02:39,485 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45571771264076233, 'Total loss': 0.45571771264076233} | train loss {'Reaction outcome loss': 0.2687919890033754, 'Total loss': 0.2687919890033754}
2023-01-05 13:02:39,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:39,485 INFO:     Epoch: 77
2023-01-05 13:02:41,674 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4498811488350232, 'Total loss': 0.4498811488350232} | train loss {'Reaction outcome loss': 0.27243759833483794, 'Total loss': 0.27243759833483794}
2023-01-05 13:02:41,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:41,674 INFO:     Epoch: 78
2023-01-05 13:02:43,869 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4816243906815847, 'Total loss': 0.4816243906815847} | train loss {'Reaction outcome loss': 0.26803504291787694, 'Total loss': 0.26803504291787694}
2023-01-05 13:02:43,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:43,870 INFO:     Epoch: 79
2023-01-05 13:02:46,036 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4380606730779012, 'Total loss': 0.4380606730779012} | train loss {'Reaction outcome loss': 0.27070126423369284, 'Total loss': 0.27070126423369284}
2023-01-05 13:02:46,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:46,036 INFO:     Epoch: 80
2023-01-05 13:02:48,185 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4242094397544861, 'Total loss': 0.4242094397544861} | train loss {'Reaction outcome loss': 0.27176778582667094, 'Total loss': 0.27176778582667094}
2023-01-05 13:02:48,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:48,185 INFO:     Epoch: 81
2023-01-05 13:02:50,353 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4265436773498853, 'Total loss': 0.4265436773498853} | train loss {'Reaction outcome loss': 0.258995143938911, 'Total loss': 0.258995143938911}
2023-01-05 13:02:50,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:50,354 INFO:     Epoch: 82
2023-01-05 13:02:52,526 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4195298314094543, 'Total loss': 0.4195298314094543} | train loss {'Reaction outcome loss': 0.2634035811896193, 'Total loss': 0.2634035811896193}
2023-01-05 13:02:52,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:52,527 INFO:     Epoch: 83
2023-01-05 13:02:54,692 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4308843553066254, 'Total loss': 0.4308843553066254} | train loss {'Reaction outcome loss': 0.26571277795406734, 'Total loss': 0.26571277795406734}
2023-01-05 13:02:54,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:54,693 INFO:     Epoch: 84
2023-01-05 13:02:56,857 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41642436683177947, 'Total loss': 0.41642436683177947} | train loss {'Reaction outcome loss': 0.2846953920493631, 'Total loss': 0.2846953920493631}
2023-01-05 13:02:56,858 INFO:     Found new best model at epoch 84
2023-01-05 13:02:56,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:56,859 INFO:     Epoch: 85
2023-01-05 13:02:59,034 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4441029856602351, 'Total loss': 0.4441029856602351} | train loss {'Reaction outcome loss': 0.2565673912902349, 'Total loss': 0.2565673912902349}
2023-01-05 13:02:59,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:02:59,034 INFO:     Epoch: 86
2023-01-05 13:03:01,205 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.442280051112175, 'Total loss': 0.442280051112175} | train loss {'Reaction outcome loss': 0.25879619703155715, 'Total loss': 0.25879619703155715}
2023-01-05 13:03:01,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:01,205 INFO:     Epoch: 87
2023-01-05 13:03:03,377 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45974678695201876, 'Total loss': 0.45974678695201876} | train loss {'Reaction outcome loss': 0.3511413777638497, 'Total loss': 0.3511413777638497}
2023-01-05 13:03:03,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:03,377 INFO:     Epoch: 88
2023-01-05 13:03:05,553 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45488566160202026, 'Total loss': 0.45488566160202026} | train loss {'Reaction outcome loss': 0.28078613635617605, 'Total loss': 0.28078613635617605}
2023-01-05 13:03:05,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:05,553 INFO:     Epoch: 89
2023-01-05 13:03:07,750 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.453185964624087, 'Total loss': 0.453185964624087} | train loss {'Reaction outcome loss': 0.296261596398941, 'Total loss': 0.296261596398941}
2023-01-05 13:03:07,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:07,750 INFO:     Epoch: 90
2023-01-05 13:03:09,915 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4839966714382172, 'Total loss': 0.4839966714382172} | train loss {'Reaction outcome loss': 0.26623171488956915, 'Total loss': 0.26623171488956915}
2023-01-05 13:03:09,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:09,916 INFO:     Epoch: 91
2023-01-05 13:03:12,111 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48420229653517405, 'Total loss': 0.48420229653517405} | train loss {'Reaction outcome loss': 0.2627835875048903, 'Total loss': 0.2627835875048903}
2023-01-05 13:03:12,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:12,113 INFO:     Epoch: 92
2023-01-05 13:03:14,297 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41560484568277994, 'Total loss': 0.41560484568277994} | train loss {'Reaction outcome loss': 0.26168553519275284, 'Total loss': 0.26168553519275284}
2023-01-05 13:03:14,298 INFO:     Found new best model at epoch 92
2023-01-05 13:03:14,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:14,299 INFO:     Epoch: 93
2023-01-05 13:03:16,454 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.420322822034359, 'Total loss': 0.420322822034359} | train loss {'Reaction outcome loss': 0.2640663062360137, 'Total loss': 0.2640663062360137}
2023-01-05 13:03:16,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:16,454 INFO:     Epoch: 94
2023-01-05 13:03:18,633 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5208530187606811, 'Total loss': 0.5208530187606811} | train loss {'Reaction outcome loss': 0.25486618646054, 'Total loss': 0.25486618646054}
2023-01-05 13:03:18,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:18,634 INFO:     Epoch: 95
2023-01-05 13:03:20,822 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46993278960386914, 'Total loss': 0.46993278960386914} | train loss {'Reaction outcome loss': 0.25743849704651994, 'Total loss': 0.25743849704651994}
2023-01-05 13:03:20,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:20,823 INFO:     Epoch: 96
2023-01-05 13:03:23,005 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43663872182369234, 'Total loss': 0.43663872182369234} | train loss {'Reaction outcome loss': 0.25263030236211154, 'Total loss': 0.25263030236211154}
2023-01-05 13:03:23,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:23,005 INFO:     Epoch: 97
2023-01-05 13:03:25,177 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45936567385991417, 'Total loss': 0.45936567385991417} | train loss {'Reaction outcome loss': 0.2550107615538434, 'Total loss': 0.2550107615538434}
2023-01-05 13:03:25,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:25,178 INFO:     Epoch: 98
2023-01-05 13:03:27,359 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4326640198628108, 'Total loss': 0.4326640198628108} | train loss {'Reaction outcome loss': 0.2511888071422236, 'Total loss': 0.2511888071422236}
2023-01-05 13:03:27,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:27,359 INFO:     Epoch: 99
2023-01-05 13:03:29,517 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46599256098270414, 'Total loss': 0.46599256098270414} | train loss {'Reaction outcome loss': 0.26159874860035337, 'Total loss': 0.26159874860035337}
2023-01-05 13:03:29,517 INFO:     Best model found after epoch 93 of 100.
2023-01-05 13:03:29,517 INFO:   Done with stage: TRAINING
2023-01-05 13:03:29,517 INFO:   Starting stage: EVALUATION
2023-01-05 13:03:29,651 INFO:   Done with stage: EVALUATION
2023-01-05 13:03:29,651 INFO: Done with stage: RUNNING SPLITS
2023-01-05 13:03:29,651 INFO: Starting stage: COMPUTE METRICS
2023-01-05 13:03:30,833 INFO: Done with stage: COMPUTE METRICS
2023-01-05 13:03:30,834 INFO: Starting stage: EXPORT RESULTS
2023-01-05 13:03:30,851 INFO:   Final results averaged over 50 folds: 
2023-01-05 13:03:30,855 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.182513           NaN  0.345338       NaN
2023-01-05 13:03:32,504 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-05 13:03:32,510 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-05 13:03:32,511 DEBUG:   interactive is False
2023-01-05 13:03:32,512 DEBUG:   platform is linux
2023-01-05 13:03:32,512 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-05 13:03:32,692 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-05 13:03:32,694 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-05 13:03:33,133 DEBUG:   Loaded backend agg version unknown.
2023-01-05 13:03:33,135 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 13:03:33,135 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,136 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 13:03:33,137 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 13:03:33,138 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,138 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 13:03:33,175 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 13:03:33,178 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,178 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 13:03:33,187 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 13:03:33,187 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,187 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,187 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,187 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,187 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,187 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,188 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 13:03:33,189 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,190 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,190 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 13:03:33,190 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 13:03:33,190 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 13:03:33,190 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 13:03:33,500 INFO: Done with stage: EXPORT RESULTS
2023-01-05 13:03:33,500 INFO: Starting stage: SAVE MODEL
2023-01-05 13:03:33,558 INFO: Done with stage: SAVE MODEL
2023-01-05 13:03:33,593 INFO: Wall time for program:  10757.56 seconds
