2022-12-31 11:45:16,226 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/49a4ce39930b950120bbf9460d9f51e9/2022_12_31-024244",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 3,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-31 11:45:16,236 INFO: Starting stage: BUILD FEATURIZERS
2022-12-31 11:45:16,238 INFO:   Creating esm representation model
2022-12-31 11:45:16,238 INFO:   Done esm representation model
2022-12-31 11:45:16,238 INFO: Done with stage: BUILD FEATURIZERS
2022-12-31 11:45:16,238 INFO: Starting stage: BUILDING DATASET
2022-12-31 11:45:16,292 INFO: Done with stage: BUILDING DATASET
2022-12-31 11:45:16,292 INFO: Starting stage: FEATURIZING DATA
2022-12-31 11:45:16,292 INFO:   Featurizing proteins
2022-12-31 11:45:16,294 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-31 11:45:16,299 INFO:   Loaded feature cache of size 489
2022-12-31 11:45:16,300 INFO:   Starting to pool ESM Embeddings
2022-12-31 11:45:16,399 INFO:   Featurizing molecules
2022-12-31 11:45:16,400 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-31 11:45:16,403 INFO:   Loaded feature cache of size 498
2022-12-31 11:45:17,734 INFO: Done with stage: FEATURIZING DATA
2022-12-31 11:45:17,734 INFO: Starting stage: RUNNING SPLITS
2022-12-31 11:45:17,743 INFO:   Leaving out SEQ value Fold_0
2022-12-31 11:45:17,756 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 11:45:17,756 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:45:18,411 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:45:18,412 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:45:18,478 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:45:18,479 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:45:18,479 INFO:     No hyperparam tuning for this model
2022-12-31 11:45:18,479 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:45:18,479 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:45:18,480 INFO:     None feature selector for col prot
2022-12-31 11:45:18,480 INFO:     None feature selector for col prot
2022-12-31 11:45:18,480 INFO:     None feature selector for col prot
2022-12-31 11:45:18,480 INFO:     None feature selector for col chem
2022-12-31 11:45:18,480 INFO:     None feature selector for col chem
2022-12-31 11:45:18,481 INFO:     None feature selector for col chem
2022-12-31 11:45:18,481 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:45:18,481 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:45:18,482 INFO:     Number of params in model 223921
2022-12-31 11:45:18,483 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:45:18,483 INFO:   Starting stage: TRAINING
2022-12-31 11:45:20,092 INFO:     Val loss before train {'Reaction outcome loss': 1.117107093334198, 'Total loss': 1.117107093334198}
2022-12-31 11:45:20,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:20,093 INFO:     Epoch: 0
2022-12-31 11:45:21,680 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6874524970849355, 'Total loss': 0.6874524970849355} | train loss {'Reaction outcome loss': 0.8006584265511552, 'Total loss': 0.8006584265511552}
2022-12-31 11:45:21,680 INFO:     Found new best model at epoch 0
2022-12-31 11:45:21,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:21,681 INFO:     Epoch: 1
2022-12-31 11:45:23,284 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5340693871180217, 'Total loss': 0.5340693871180217} | train loss {'Reaction outcome loss': 0.5844811952703601, 'Total loss': 0.5844811952703601}
2022-12-31 11:45:23,284 INFO:     Found new best model at epoch 1
2022-12-31 11:45:23,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:23,285 INFO:     Epoch: 2
2022-12-31 11:45:24,887 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5269107391436895, 'Total loss': 0.5269107391436895} | train loss {'Reaction outcome loss': 0.5388718652965385, 'Total loss': 0.5388718652965385}
2022-12-31 11:45:24,887 INFO:     Found new best model at epoch 2
2022-12-31 11:45:24,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:24,888 INFO:     Epoch: 3
2022-12-31 11:45:26,506 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5135997573534647, 'Total loss': 0.5135997573534647} | train loss {'Reaction outcome loss': 0.5068249249414647, 'Total loss': 0.5068249249414647}
2022-12-31 11:45:26,506 INFO:     Found new best model at epoch 3
2022-12-31 11:45:26,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:26,507 INFO:     Epoch: 4
2022-12-31 11:45:28,112 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5305386841297149, 'Total loss': 0.5305386841297149} | train loss {'Reaction outcome loss': 0.488884775356932, 'Total loss': 0.488884775356932}
2022-12-31 11:45:28,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:28,112 INFO:     Epoch: 5
2022-12-31 11:45:29,700 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48996174534161885, 'Total loss': 0.48996174534161885} | train loss {'Reaction outcome loss': 0.4808509777753781, 'Total loss': 0.4808509777753781}
2022-12-31 11:45:29,700 INFO:     Found new best model at epoch 5
2022-12-31 11:45:29,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:29,701 INFO:     Epoch: 6
2022-12-31 11:45:31,347 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5730870465437571, 'Total loss': 0.5730870465437571} | train loss {'Reaction outcome loss': 0.47109549386160715, 'Total loss': 0.47109549386160715}
2022-12-31 11:45:31,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:31,347 INFO:     Epoch: 7
2022-12-31 11:45:32,995 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48347499072551725, 'Total loss': 0.48347499072551725} | train loss {'Reaction outcome loss': 0.4608175265483367, 'Total loss': 0.4608175265483367}
2022-12-31 11:45:32,995 INFO:     Found new best model at epoch 7
2022-12-31 11:45:32,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:32,996 INFO:     Epoch: 8
2022-12-31 11:45:34,598 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48660784562428794, 'Total loss': 0.48660784562428794} | train loss {'Reaction outcome loss': 0.4538455984858803, 'Total loss': 0.4538455984858803}
2022-12-31 11:45:34,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:34,598 INFO:     Epoch: 9
2022-12-31 11:45:36,250 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5124463975429535, 'Total loss': 0.5124463975429535} | train loss {'Reaction outcome loss': 0.4457315389107872, 'Total loss': 0.4457315389107872}
2022-12-31 11:45:36,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:36,250 INFO:     Epoch: 10
2022-12-31 11:45:37,900 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5042067666848501, 'Total loss': 0.5042067666848501} | train loss {'Reaction outcome loss': 0.43781986030248493, 'Total loss': 0.43781986030248493}
2022-12-31 11:45:37,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:37,900 INFO:     Epoch: 11
2022-12-31 11:45:39,514 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5110376417636872, 'Total loss': 0.5110376417636872} | train loss {'Reaction outcome loss': 0.4308315042556424, 'Total loss': 0.4308315042556424}
2022-12-31 11:45:39,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:39,514 INFO:     Epoch: 12
2022-12-31 11:45:41,128 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5202577710151672, 'Total loss': 0.5202577710151672} | train loss {'Reaction outcome loss': 0.4302674112739144, 'Total loss': 0.4302674112739144}
2022-12-31 11:45:41,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:41,128 INFO:     Epoch: 13
2022-12-31 11:45:42,725 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48767179052035015, 'Total loss': 0.48767179052035015} | train loss {'Reaction outcome loss': 0.41947357946044794, 'Total loss': 0.41947357946044794}
2022-12-31 11:45:42,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:42,726 INFO:     Epoch: 14
2022-12-31 11:45:44,309 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4847182104984919, 'Total loss': 0.4847182104984919} | train loss {'Reaction outcome loss': 0.41397622568812564, 'Total loss': 0.41397622568812564}
2022-12-31 11:45:44,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:44,309 INFO:     Epoch: 15
2022-12-31 11:45:45,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5003076513608297, 'Total loss': 0.5003076513608297} | train loss {'Reaction outcome loss': 0.4134976620693783, 'Total loss': 0.4134976620693783}
2022-12-31 11:45:45,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:45,908 INFO:     Epoch: 16
2022-12-31 11:45:47,537 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48288678626219433, 'Total loss': 0.48288678626219433} | train loss {'Reaction outcome loss': 0.3972483206260608, 'Total loss': 0.3972483206260608}
2022-12-31 11:45:47,537 INFO:     Found new best model at epoch 16
2022-12-31 11:45:47,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:47,538 INFO:     Epoch: 17
2022-12-31 11:45:49,130 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5078531086444855, 'Total loss': 0.5078531086444855} | train loss {'Reaction outcome loss': 0.39469389890358125, 'Total loss': 0.39469389890358125}
2022-12-31 11:45:49,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:49,130 INFO:     Epoch: 18
2022-12-31 11:45:50,731 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5059867878754933, 'Total loss': 0.5059867878754933} | train loss {'Reaction outcome loss': 0.39146286980573075, 'Total loss': 0.39146286980573075}
2022-12-31 11:45:50,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:50,731 INFO:     Epoch: 19
2022-12-31 11:45:52,328 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4981790800889333, 'Total loss': 0.4981790800889333} | train loss {'Reaction outcome loss': 0.38765842770482156, 'Total loss': 0.38765842770482156}
2022-12-31 11:45:52,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:52,329 INFO:     Epoch: 20
2022-12-31 11:45:53,951 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4737981855869293, 'Total loss': 0.4737981855869293} | train loss {'Reaction outcome loss': 0.3863218891205805, 'Total loss': 0.3863218891205805}
2022-12-31 11:45:53,953 INFO:     Found new best model at epoch 20
2022-12-31 11:45:53,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:53,954 INFO:     Epoch: 21
2022-12-31 11:45:55,546 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46607306599617004, 'Total loss': 0.46607306599617004} | train loss {'Reaction outcome loss': 0.3705167567609867, 'Total loss': 0.3705167567609867}
2022-12-31 11:45:55,546 INFO:     Found new best model at epoch 21
2022-12-31 11:45:55,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:55,547 INFO:     Epoch: 22
2022-12-31 11:45:57,125 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4800545195738474, 'Total loss': 0.4800545195738474} | train loss {'Reaction outcome loss': 0.36548178853132784, 'Total loss': 0.36548178853132784}
2022-12-31 11:45:57,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:57,125 INFO:     Epoch: 23
2022-12-31 11:45:58,737 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4958549618721008, 'Total loss': 0.4958549618721008} | train loss {'Reaction outcome loss': 0.366796337613911, 'Total loss': 0.366796337613911}
2022-12-31 11:45:58,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:58,738 INFO:     Epoch: 24
2022-12-31 11:46:00,336 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4949183354775111, 'Total loss': 0.4949183354775111} | train loss {'Reaction outcome loss': 0.3510957998957062, 'Total loss': 0.3510957998957062}
2022-12-31 11:46:00,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:00,337 INFO:     Epoch: 25
2022-12-31 11:46:01,912 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5027657389640808, 'Total loss': 0.5027657389640808} | train loss {'Reaction outcome loss': 0.3504541911757909, 'Total loss': 0.3504541911757909}
2022-12-31 11:46:01,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:01,912 INFO:     Epoch: 26
2022-12-31 11:46:03,510 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5142683247725169, 'Total loss': 0.5142683247725169} | train loss {'Reaction outcome loss': 0.34736986212678006, 'Total loss': 0.34736986212678006}
2022-12-31 11:46:03,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:03,510 INFO:     Epoch: 27
2022-12-31 11:46:05,108 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4616859217484792, 'Total loss': 0.4616859217484792} | train loss {'Reaction outcome loss': 0.3414687544052854, 'Total loss': 0.3414687544052854}
2022-12-31 11:46:05,108 INFO:     Found new best model at epoch 27
2022-12-31 11:46:05,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:05,109 INFO:     Epoch: 28
2022-12-31 11:46:06,694 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.507531542579333, 'Total loss': 0.507531542579333} | train loss {'Reaction outcome loss': 0.3361417176850113, 'Total loss': 0.3361417176850113}
2022-12-31 11:46:06,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:06,694 INFO:     Epoch: 29
2022-12-31 11:46:08,347 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5011594116687774, 'Total loss': 0.5011594116687774} | train loss {'Reaction outcome loss': 0.33596648719339145, 'Total loss': 0.33596648719339145}
2022-12-31 11:46:08,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:08,347 INFO:     Epoch: 30
2022-12-31 11:46:09,944 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48661732077598574, 'Total loss': 0.48661732077598574} | train loss {'Reaction outcome loss': 0.3292322092768037, 'Total loss': 0.3292322092768037}
2022-12-31 11:46:09,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:09,944 INFO:     Epoch: 31
2022-12-31 11:46:11,536 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5077552398045858, 'Total loss': 0.5077552398045858} | train loss {'Reaction outcome loss': 0.3206021627104217, 'Total loss': 0.3206021627104217}
2022-12-31 11:46:11,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:11,536 INFO:     Epoch: 32
2022-12-31 11:46:13,132 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4790169219175974, 'Total loss': 0.4790169219175974} | train loss {'Reaction outcome loss': 0.31454340425821453, 'Total loss': 0.31454340425821453}
2022-12-31 11:46:13,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:13,133 INFO:     Epoch: 33
2022-12-31 11:46:14,728 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5106394896904628, 'Total loss': 0.5106394896904628} | train loss {'Reaction outcome loss': 0.3090375814136568, 'Total loss': 0.3090375814136568}
2022-12-31 11:46:14,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:14,728 INFO:     Epoch: 34
2022-12-31 11:46:16,316 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4689942521353563, 'Total loss': 0.4689942521353563} | train loss {'Reaction outcome loss': 0.3226395064876193, 'Total loss': 0.3226395064876193}
2022-12-31 11:46:16,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:16,316 INFO:     Epoch: 35
2022-12-31 11:46:17,913 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5036159078280131, 'Total loss': 0.5036159078280131} | train loss {'Reaction outcome loss': 0.30202568633543264, 'Total loss': 0.30202568633543264}
2022-12-31 11:46:17,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:17,913 INFO:     Epoch: 36
2022-12-31 11:46:19,509 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47943059404691063, 'Total loss': 0.47943059404691063} | train loss {'Reaction outcome loss': 0.2956846839724443, 'Total loss': 0.2956846839724443}
2022-12-31 11:46:19,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:19,509 INFO:     Epoch: 37
2022-12-31 11:46:21,085 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48310797214508056, 'Total loss': 0.48310797214508056} | train loss {'Reaction outcome loss': 0.29827303365691676, 'Total loss': 0.29827303365691676}
2022-12-31 11:46:21,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:21,085 INFO:     Epoch: 38
2022-12-31 11:46:22,682 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47253628373146056, 'Total loss': 0.47253628373146056} | train loss {'Reaction outcome loss': 0.29036777308244843, 'Total loss': 0.29036777308244843}
2022-12-31 11:46:22,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:22,682 INFO:     Epoch: 39
2022-12-31 11:46:24,256 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4669011041522026, 'Total loss': 0.4669011041522026} | train loss {'Reaction outcome loss': 0.29105712709464, 'Total loss': 0.29105712709464}
2022-12-31 11:46:24,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:24,257 INFO:     Epoch: 40
2022-12-31 11:46:25,854 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4698057343562444, 'Total loss': 0.4698057343562444} | train loss {'Reaction outcome loss': 0.2927349655728637, 'Total loss': 0.2927349655728637}
2022-12-31 11:46:25,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:25,854 INFO:     Epoch: 41
2022-12-31 11:46:27,449 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4867839256922404, 'Total loss': 0.4867839256922404} | train loss {'Reaction outcome loss': 0.28166394510848836, 'Total loss': 0.28166394510848836}
2022-12-31 11:46:27,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:27,449 INFO:     Epoch: 42
2022-12-31 11:46:29,024 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46563939849535624, 'Total loss': 0.46563939849535624} | train loss {'Reaction outcome loss': 0.27716093949782544, 'Total loss': 0.27716093949782544}
2022-12-31 11:46:29,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:29,024 INFO:     Epoch: 43
2022-12-31 11:46:30,669 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.471100049217542, 'Total loss': 0.471100049217542} | train loss {'Reaction outcome loss': 0.27100618538402377, 'Total loss': 0.27100618538402377}
2022-12-31 11:46:30,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:30,669 INFO:     Epoch: 44
2022-12-31 11:46:32,314 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4761970301469167, 'Total loss': 0.4761970301469167} | train loss {'Reaction outcome loss': 0.2708931681375964, 'Total loss': 0.2708931681375964}
2022-12-31 11:46:32,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:32,315 INFO:     Epoch: 45
2022-12-31 11:46:33,915 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47321581840515137, 'Total loss': 0.47321581840515137} | train loss {'Reaction outcome loss': 0.2697306516419946, 'Total loss': 0.2697306516419946}
2022-12-31 11:46:33,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:33,915 INFO:     Epoch: 46
2022-12-31 11:46:35,512 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49352802634239196, 'Total loss': 0.49352802634239196} | train loss {'Reaction outcome loss': 0.26984271529939147, 'Total loss': 0.26984271529939147}
2022-12-31 11:46:35,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:35,512 INFO:     Epoch: 47
2022-12-31 11:46:37,104 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.457134943207105, 'Total loss': 0.457134943207105} | train loss {'Reaction outcome loss': 0.26895526718798574, 'Total loss': 0.26895526718798574}
2022-12-31 11:46:37,104 INFO:     Found new best model at epoch 47
2022-12-31 11:46:37,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:37,105 INFO:     Epoch: 48
2022-12-31 11:46:38,688 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4903254459301631, 'Total loss': 0.4903254459301631} | train loss {'Reaction outcome loss': 0.26019317157320926, 'Total loss': 0.26019317157320926}
2022-12-31 11:46:38,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:38,688 INFO:     Epoch: 49
2022-12-31 11:46:40,282 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5361087302366893, 'Total loss': 0.5361087302366893} | train loss {'Reaction outcome loss': 0.2639885005223882, 'Total loss': 0.2639885005223882}
2022-12-31 11:46:40,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:40,282 INFO:     Epoch: 50
2022-12-31 11:46:41,877 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4912969350814819, 'Total loss': 0.4912969350814819} | train loss {'Reaction outcome loss': 0.2607889681535981, 'Total loss': 0.2607889681535981}
2022-12-31 11:46:41,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:41,878 INFO:     Epoch: 51
2022-12-31 11:46:43,475 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.504410273830096, 'Total loss': 0.504410273830096} | train loss {'Reaction outcome loss': 0.2626121432789953, 'Total loss': 0.2626121432789953}
2022-12-31 11:46:43,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:43,476 INFO:     Epoch: 52
2022-12-31 11:46:45,089 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5535041093826294, 'Total loss': 0.5535041093826294} | train loss {'Reaction outcome loss': 0.25297078330601963, 'Total loss': 0.25297078330601963}
2022-12-31 11:46:45,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:45,089 INFO:     Epoch: 53
2022-12-31 11:46:46,684 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5083771079778672, 'Total loss': 0.5083771079778672} | train loss {'Reaction outcome loss': 0.267747528591763, 'Total loss': 0.267747528591763}
2022-12-31 11:46:46,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:46,684 INFO:     Epoch: 54
2022-12-31 11:46:48,260 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44739080766836803, 'Total loss': 0.44739080766836803} | train loss {'Reaction outcome loss': 0.2575134354005585, 'Total loss': 0.2575134354005585}
2022-12-31 11:46:48,260 INFO:     Found new best model at epoch 54
2022-12-31 11:46:48,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:48,261 INFO:     Epoch: 55
2022-12-31 11:46:49,849 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4335428404311339, 'Total loss': 0.4335428404311339} | train loss {'Reaction outcome loss': 0.2546648518233509, 'Total loss': 0.2546648518233509}
2022-12-31 11:46:49,849 INFO:     Found new best model at epoch 55
2022-12-31 11:46:49,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:49,850 INFO:     Epoch: 56
2022-12-31 11:46:51,426 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4448289394378662, 'Total loss': 0.4448289394378662} | train loss {'Reaction outcome loss': 0.24543197057295196, 'Total loss': 0.24543197057295196}
2022-12-31 11:46:51,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:51,426 INFO:     Epoch: 57
2022-12-31 11:46:53,024 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4724834024906158, 'Total loss': 0.4724834024906158} | train loss {'Reaction outcome loss': 0.24966665616620592, 'Total loss': 0.24966665616620592}
2022-12-31 11:46:53,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:53,025 INFO:     Epoch: 58
2022-12-31 11:46:54,622 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45306335190931957, 'Total loss': 0.45306335190931957} | train loss {'Reaction outcome loss': 0.24400416975875042, 'Total loss': 0.24400416975875042}
2022-12-31 11:46:54,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:54,622 INFO:     Epoch: 59
2022-12-31 11:46:56,197 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.529276180267334, 'Total loss': 0.529276180267334} | train loss {'Reaction outcome loss': 0.2402952341806321, 'Total loss': 0.2402952341806321}
2022-12-31 11:46:56,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:56,198 INFO:     Epoch: 60
2022-12-31 11:46:57,817 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5143140057722727, 'Total loss': 0.5143140057722727} | train loss {'Reaction outcome loss': 0.24259566308950986, 'Total loss': 0.24259566308950986}
2022-12-31 11:46:57,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:57,817 INFO:     Epoch: 61
2022-12-31 11:46:59,415 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47157991528511045, 'Total loss': 0.47157991528511045} | train loss {'Reaction outcome loss': 0.2415085763980945, 'Total loss': 0.2415085763980945}
2022-12-31 11:46:59,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:46:59,415 INFO:     Epoch: 62
2022-12-31 11:47:01,034 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4911833027998606, 'Total loss': 0.4911833027998606} | train loss {'Reaction outcome loss': 0.2368548170666828, 'Total loss': 0.2368548170666828}
2022-12-31 11:47:01,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:01,035 INFO:     Epoch: 63
2022-12-31 11:47:02,652 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5158876121044159, 'Total loss': 0.5158876121044159} | train loss {'Reaction outcome loss': 0.2343781775020527, 'Total loss': 0.2343781775020527}
2022-12-31 11:47:02,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:02,652 INFO:     Epoch: 64
2022-12-31 11:47:04,250 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5092315296332042, 'Total loss': 0.5092315296332042} | train loss {'Reaction outcome loss': 0.2372141371279846, 'Total loss': 0.2372141371279846}
2022-12-31 11:47:04,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:04,250 INFO:     Epoch: 65
2022-12-31 11:47:05,826 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4198114444812139, 'Total loss': 0.4198114444812139} | train loss {'Reaction outcome loss': 0.23235780925868632, 'Total loss': 0.23235780925868632}
2022-12-31 11:47:05,826 INFO:     Found new best model at epoch 65
2022-12-31 11:47:05,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:05,827 INFO:     Epoch: 66
2022-12-31 11:47:07,424 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4650994559129079, 'Total loss': 0.4650994559129079} | train loss {'Reaction outcome loss': 0.22978902920643926, 'Total loss': 0.22978902920643926}
2022-12-31 11:47:07,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:07,425 INFO:     Epoch: 67
2022-12-31 11:47:09,021 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45232698917388914, 'Total loss': 0.45232698917388914} | train loss {'Reaction outcome loss': 0.2302502357254262, 'Total loss': 0.2302502357254262}
2022-12-31 11:47:09,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:09,021 INFO:     Epoch: 68
2022-12-31 11:47:10,632 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48946728706359866, 'Total loss': 0.48946728706359866} | train loss {'Reaction outcome loss': 0.22235980774907074, 'Total loss': 0.22235980774907074}
2022-12-31 11:47:10,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:10,632 INFO:     Epoch: 69
2022-12-31 11:47:12,283 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4738575289646784, 'Total loss': 0.4738575289646784} | train loss {'Reaction outcome loss': 0.22505347267639286, 'Total loss': 0.22505347267639286}
2022-12-31 11:47:12,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:12,283 INFO:     Epoch: 70
2022-12-31 11:47:13,878 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4694268087546031, 'Total loss': 0.4694268087546031} | train loss {'Reaction outcome loss': 0.22759792560731973, 'Total loss': 0.22759792560731973}
2022-12-31 11:47:13,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:13,878 INFO:     Epoch: 71
2022-12-31 11:47:15,453 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4549056805670261, 'Total loss': 0.4549056805670261} | train loss {'Reaction outcome loss': 0.2234306040018688, 'Total loss': 0.2234306040018688}
2022-12-31 11:47:15,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:15,453 INFO:     Epoch: 72
2022-12-31 11:47:17,051 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48373757004737855, 'Total loss': 0.48373757004737855} | train loss {'Reaction outcome loss': 0.21949314079059787, 'Total loss': 0.21949314079059787}
2022-12-31 11:47:17,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:17,051 INFO:     Epoch: 73
2022-12-31 11:47:18,639 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5003798147042592, 'Total loss': 0.5003798147042592} | train loss {'Reaction outcome loss': 0.22066753720625853, 'Total loss': 0.22066753720625853}
2022-12-31 11:47:18,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:18,639 INFO:     Epoch: 74
2022-12-31 11:47:20,282 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4503186772267024, 'Total loss': 0.4503186772267024} | train loss {'Reaction outcome loss': 0.22351453634108598, 'Total loss': 0.22351453634108598}
2022-12-31 11:47:20,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:20,283 INFO:     Epoch: 75
2022-12-31 11:47:21,879 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48221948742866516, 'Total loss': 0.48221948742866516} | train loss {'Reaction outcome loss': 0.2140586981174601, 'Total loss': 0.2140586981174601}
2022-12-31 11:47:21,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:21,879 INFO:     Epoch: 76
2022-12-31 11:47:23,454 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4333694100379944, 'Total loss': 0.4333694100379944} | train loss {'Reaction outcome loss': 0.22240867778222204, 'Total loss': 0.22240867778222204}
2022-12-31 11:47:23,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:23,454 INFO:     Epoch: 77
2022-12-31 11:47:25,050 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46300959785779316, 'Total loss': 0.46300959785779316} | train loss {'Reaction outcome loss': 0.21741655104599156, 'Total loss': 0.21741655104599156}
2022-12-31 11:47:25,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:25,050 INFO:     Epoch: 78
2022-12-31 11:47:26,649 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48706533511479694, 'Total loss': 0.48706533511479694} | train loss {'Reaction outcome loss': 0.23113327377199472, 'Total loss': 0.23113327377199472}
2022-12-31 11:47:26,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:26,649 INFO:     Epoch: 79
2022-12-31 11:47:28,235 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4714260826508204, 'Total loss': 0.4714260826508204} | train loss {'Reaction outcome loss': 0.2171674026688049, 'Total loss': 0.2171674026688049}
2022-12-31 11:47:28,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:28,235 INFO:     Epoch: 80
2022-12-31 11:47:29,833 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4955401023228963, 'Total loss': 0.4955401023228963} | train loss {'Reaction outcome loss': 0.21640556948361817, 'Total loss': 0.21640556948361817}
2022-12-31 11:47:29,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:29,833 INFO:     Epoch: 81
2022-12-31 11:47:31,429 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49534193277359007, 'Total loss': 0.49534193277359007} | train loss {'Reaction outcome loss': 0.21373476700741292, 'Total loss': 0.21373476700741292}
2022-12-31 11:47:31,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:31,430 INFO:     Epoch: 82
2022-12-31 11:47:33,007 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47043289293845497, 'Total loss': 0.47043289293845497} | train loss {'Reaction outcome loss': 0.22072759900419486, 'Total loss': 0.22072759900419486}
2022-12-31 11:47:33,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:33,007 INFO:     Epoch: 83
2022-12-31 11:47:34,605 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4856015811363856, 'Total loss': 0.4856015811363856} | train loss {'Reaction outcome loss': 0.20911378311095657, 'Total loss': 0.20911378311095657}
2022-12-31 11:47:34,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:34,606 INFO:     Epoch: 84
2022-12-31 11:47:36,203 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46846246520678203, 'Total loss': 0.46846246520678203} | train loss {'Reaction outcome loss': 0.21344568063215022, 'Total loss': 0.21344568063215022}
2022-12-31 11:47:36,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:36,204 INFO:     Epoch: 85
2022-12-31 11:47:37,816 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47518622875213623, 'Total loss': 0.47518622875213623} | train loss {'Reaction outcome loss': 0.21155982144900184, 'Total loss': 0.21155982144900184}
2022-12-31 11:47:37,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:37,816 INFO:     Epoch: 86
2022-12-31 11:47:39,449 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.469527933994929, 'Total loss': 0.469527933994929} | train loss {'Reaction outcome loss': 0.2118158752624041, 'Total loss': 0.2118158752624041}
2022-12-31 11:47:39,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:39,449 INFO:     Epoch: 87
2022-12-31 11:47:41,059 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5267897625764211, 'Total loss': 0.5267897625764211} | train loss {'Reaction outcome loss': 0.20857280480501417, 'Total loss': 0.20857280480501417}
2022-12-31 11:47:41,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:41,059 INFO:     Epoch: 88
2022-12-31 11:47:42,635 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47307016849517824, 'Total loss': 0.47307016849517824} | train loss {'Reaction outcome loss': 0.20720387633630644, 'Total loss': 0.20720387633630644}
2022-12-31 11:47:42,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:42,636 INFO:     Epoch: 89
2022-12-31 11:47:44,234 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44385217626889545, 'Total loss': 0.44385217626889545} | train loss {'Reaction outcome loss': 0.20469326699824641, 'Total loss': 0.20469326699824641}
2022-12-31 11:47:44,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:44,234 INFO:     Epoch: 90
2022-12-31 11:47:45,818 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5399382059772809, 'Total loss': 0.5399382059772809} | train loss {'Reaction outcome loss': 0.20639290022680828, 'Total loss': 0.20639290022680828}
2022-12-31 11:47:45,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:45,818 INFO:     Epoch: 91
2022-12-31 11:47:47,441 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48331020871798197, 'Total loss': 0.48331020871798197} | train loss {'Reaction outcome loss': 0.21275653647627313, 'Total loss': 0.21275653647627313}
2022-12-31 11:47:47,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:47,442 INFO:     Epoch: 92
2022-12-31 11:47:49,038 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5150606254736583, 'Total loss': 0.5150606254736583} | train loss {'Reaction outcome loss': 0.20169302666962366, 'Total loss': 0.20169302666962366}
2022-12-31 11:47:49,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:49,039 INFO:     Epoch: 93
2022-12-31 11:47:50,615 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4853066593408585, 'Total loss': 0.4853066593408585} | train loss {'Reaction outcome loss': 0.2081353832786773, 'Total loss': 0.2081353832786773}
2022-12-31 11:47:50,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:50,615 INFO:     Epoch: 94
2022-12-31 11:47:52,213 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5526585320631663, 'Total loss': 0.5526585320631663} | train loss {'Reaction outcome loss': 0.21165528544821802, 'Total loss': 0.21165528544821802}
2022-12-31 11:47:52,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:52,213 INFO:     Epoch: 95
2022-12-31 11:47:53,810 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49407778183619183, 'Total loss': 0.49407778183619183} | train loss {'Reaction outcome loss': 0.20591225704321495, 'Total loss': 0.20591225704321495}
2022-12-31 11:47:53,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:53,810 INFO:     Epoch: 96
2022-12-31 11:47:55,400 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4782266914844513, 'Total loss': 0.4782266914844513} | train loss {'Reaction outcome loss': 0.2007691026989357, 'Total loss': 0.2007691026989357}
2022-12-31 11:47:55,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:55,401 INFO:     Epoch: 97
2022-12-31 11:47:56,997 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5025764624277751, 'Total loss': 0.5025764624277751} | train loss {'Reaction outcome loss': 0.1995396690414161, 'Total loss': 0.1995396690414161}
2022-12-31 11:47:56,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:56,998 INFO:     Epoch: 98
2022-12-31 11:47:58,597 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4581203401088715, 'Total loss': 0.4581203401088715} | train loss {'Reaction outcome loss': 0.19124242114824253, 'Total loss': 0.19124242114824253}
2022-12-31 11:47:58,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:47:58,597 INFO:     Epoch: 99
2022-12-31 11:48:00,190 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44042684584856034, 'Total loss': 0.44042684584856034} | train loss {'Reaction outcome loss': 0.20417233920850597, 'Total loss': 0.20417233920850597}
2022-12-31 11:48:00,190 INFO:     Best model found after epoch 66 of 100.
2022-12-31 11:48:00,190 INFO:   Done with stage: TRAINING
2022-12-31 11:48:00,190 INFO:   Starting stage: EVALUATION
2022-12-31 11:48:00,330 INFO:   Done with stage: EVALUATION
2022-12-31 11:48:00,330 INFO:   Leaving out SEQ value Fold_1
2022-12-31 11:48:00,343 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:48:00,343 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:48:01,003 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:48:01,003 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:48:01,072 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:48:01,072 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:48:01,072 INFO:     No hyperparam tuning for this model
2022-12-31 11:48:01,072 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:48:01,072 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:48:01,073 INFO:     None feature selector for col prot
2022-12-31 11:48:01,073 INFO:     None feature selector for col prot
2022-12-31 11:48:01,073 INFO:     None feature selector for col prot
2022-12-31 11:48:01,073 INFO:     None feature selector for col chem
2022-12-31 11:48:01,073 INFO:     None feature selector for col chem
2022-12-31 11:48:01,074 INFO:     None feature selector for col chem
2022-12-31 11:48:01,074 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:48:01,074 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:48:01,075 INFO:     Number of params in model 223921
2022-12-31 11:48:01,078 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:48:01,079 INFO:   Starting stage: TRAINING
2022-12-31 11:48:01,122 INFO:     Val loss before train {'Reaction outcome loss': 1.1283984978993733, 'Total loss': 1.1283984978993733}
2022-12-31 11:48:01,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:01,122 INFO:     Epoch: 0
2022-12-31 11:48:02,739 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.773970365524292, 'Total loss': 0.773970365524292} | train loss {'Reaction outcome loss': 0.8015566157021871, 'Total loss': 0.8015566157021871}
2022-12-31 11:48:02,739 INFO:     Found new best model at epoch 0
2022-12-31 11:48:02,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:02,740 INFO:     Epoch: 1
2022-12-31 11:48:04,335 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5863897621631622, 'Total loss': 0.5863897621631622} | train loss {'Reaction outcome loss': 0.5963805180204951, 'Total loss': 0.5963805180204951}
2022-12-31 11:48:04,335 INFO:     Found new best model at epoch 1
2022-12-31 11:48:04,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:04,336 INFO:     Epoch: 2
2022-12-31 11:48:05,946 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5865298767884572, 'Total loss': 0.5865298767884572} | train loss {'Reaction outcome loss': 0.5328857325746313, 'Total loss': 0.5328857325746313}
2022-12-31 11:48:05,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:05,946 INFO:     Epoch: 3
2022-12-31 11:48:07,557 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.574260754386584, 'Total loss': 0.574260754386584} | train loss {'Reaction outcome loss': 0.5036244252089249, 'Total loss': 0.5036244252089249}
2022-12-31 11:48:07,558 INFO:     Found new best model at epoch 3
2022-12-31 11:48:07,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:07,559 INFO:     Epoch: 4
2022-12-31 11:48:09,178 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5590234875679017, 'Total loss': 0.5590234875679017} | train loss {'Reaction outcome loss': 0.4834868999660366, 'Total loss': 0.4834868999660366}
2022-12-31 11:48:09,178 INFO:     Found new best model at epoch 4
2022-12-31 11:48:09,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:09,179 INFO:     Epoch: 5
2022-12-31 11:48:10,799 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5407399415969849, 'Total loss': 0.5407399415969849} | train loss {'Reaction outcome loss': 0.4780322220446407, 'Total loss': 0.4780322220446407}
2022-12-31 11:48:10,799 INFO:     Found new best model at epoch 5
2022-12-31 11:48:10,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:10,800 INFO:     Epoch: 6
2022-12-31 11:48:12,429 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.538946141799291, 'Total loss': 0.538946141799291} | train loss {'Reaction outcome loss': 0.4626096893309454, 'Total loss': 0.4626096893309454}
2022-12-31 11:48:12,429 INFO:     Found new best model at epoch 6
2022-12-31 11:48:12,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:12,430 INFO:     Epoch: 7
2022-12-31 11:48:14,044 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.511977861324946, 'Total loss': 0.511977861324946} | train loss {'Reaction outcome loss': 0.45862084247873747, 'Total loss': 0.45862084247873747}
2022-12-31 11:48:14,045 INFO:     Found new best model at epoch 7
2022-12-31 11:48:14,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:14,046 INFO:     Epoch: 8
2022-12-31 11:48:15,659 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5135924637317657, 'Total loss': 0.5135924637317657} | train loss {'Reaction outcome loss': 0.45380528492556105, 'Total loss': 0.45380528492556105}
2022-12-31 11:48:15,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:15,659 INFO:     Epoch: 9
2022-12-31 11:48:17,255 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5103518605232239, 'Total loss': 0.5103518605232239} | train loss {'Reaction outcome loss': 0.4451291102619059, 'Total loss': 0.4451291102619059}
2022-12-31 11:48:17,256 INFO:     Found new best model at epoch 9
2022-12-31 11:48:17,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:17,256 INFO:     Epoch: 10
2022-12-31 11:48:18,874 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4966406146685282, 'Total loss': 0.4966406146685282} | train loss {'Reaction outcome loss': 0.4407043525771844, 'Total loss': 0.4407043525771844}
2022-12-31 11:48:18,874 INFO:     Found new best model at epoch 10
2022-12-31 11:48:18,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:18,875 INFO:     Epoch: 11
2022-12-31 11:48:20,488 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49819386601448057, 'Total loss': 0.49819386601448057} | train loss {'Reaction outcome loss': 0.4423106775443623, 'Total loss': 0.4423106775443623}
2022-12-31 11:48:20,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:20,488 INFO:     Epoch: 12
2022-12-31 11:48:22,106 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5168439785639445, 'Total loss': 0.5168439785639445} | train loss {'Reaction outcome loss': 0.4551621406116401, 'Total loss': 0.4551621406116401}
2022-12-31 11:48:22,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:22,106 INFO:     Epoch: 13
2022-12-31 11:48:23,778 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5057689150174459, 'Total loss': 0.5057689150174459} | train loss {'Reaction outcome loss': 0.42496515327619144, 'Total loss': 0.42496515327619144}
2022-12-31 11:48:23,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:23,778 INFO:     Epoch: 14
2022-12-31 11:48:25,438 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46605019370714823, 'Total loss': 0.46605019370714823} | train loss {'Reaction outcome loss': 0.418524785871631, 'Total loss': 0.418524785871631}
2022-12-31 11:48:25,438 INFO:     Found new best model at epoch 14
2022-12-31 11:48:25,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:25,439 INFO:     Epoch: 15
2022-12-31 11:48:27,051 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4963667800029119, 'Total loss': 0.4963667800029119} | train loss {'Reaction outcome loss': 0.40891049220395426, 'Total loss': 0.40891049220395426}
2022-12-31 11:48:27,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:27,052 INFO:     Epoch: 16
2022-12-31 11:48:28,663 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5158895800511042, 'Total loss': 0.5158895800511042} | train loss {'Reaction outcome loss': 0.4044956109439385, 'Total loss': 0.4044956109439385}
2022-12-31 11:48:28,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:28,663 INFO:     Epoch: 17
2022-12-31 11:48:30,269 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4749190777540207, 'Total loss': 0.4749190777540207} | train loss {'Reaction outcome loss': 0.4029583283632562, 'Total loss': 0.4029583283632562}
2022-12-31 11:48:30,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:30,269 INFO:     Epoch: 18
2022-12-31 11:48:31,875 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47074509461720787, 'Total loss': 0.47074509461720787} | train loss {'Reaction outcome loss': 0.4062810157332063, 'Total loss': 0.4062810157332063}
2022-12-31 11:48:31,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:31,875 INFO:     Epoch: 19
2022-12-31 11:48:33,490 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4911371946334839, 'Total loss': 0.4911371946334839} | train loss {'Reaction outcome loss': 0.39337274329601857, 'Total loss': 0.39337274329601857}
2022-12-31 11:48:33,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:33,490 INFO:     Epoch: 20
2022-12-31 11:48:35,108 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.477739421526591, 'Total loss': 0.477739421526591} | train loss {'Reaction outcome loss': 0.4002796633277034, 'Total loss': 0.4002796633277034}
2022-12-31 11:48:35,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:35,108 INFO:     Epoch: 21
2022-12-31 11:48:36,744 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.514844556649526, 'Total loss': 0.514844556649526} | train loss {'Reaction outcome loss': 0.3862529526198067, 'Total loss': 0.3862529526198067}
2022-12-31 11:48:36,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:36,744 INFO:     Epoch: 22
2022-12-31 11:48:38,373 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4460171103477478, 'Total loss': 0.4460171103477478} | train loss {'Reaction outcome loss': 0.37520853507305507, 'Total loss': 0.37520853507305507}
2022-12-31 11:48:38,374 INFO:     Found new best model at epoch 22
2022-12-31 11:48:38,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:38,375 INFO:     Epoch: 23
2022-12-31 11:48:39,985 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4704348305861155, 'Total loss': 0.4704348305861155} | train loss {'Reaction outcome loss': 0.3775160597785767, 'Total loss': 0.3775160597785767}
2022-12-31 11:48:39,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:39,986 INFO:     Epoch: 24
2022-12-31 11:48:41,612 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4743348777294159, 'Total loss': 0.4743348777294159} | train loss {'Reaction outcome loss': 0.36271377205232874, 'Total loss': 0.36271377205232874}
2022-12-31 11:48:41,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:41,612 INFO:     Epoch: 25
2022-12-31 11:48:43,232 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4441838413476944, 'Total loss': 0.4441838413476944} | train loss {'Reaction outcome loss': 0.35824016156349925, 'Total loss': 0.35824016156349925}
2022-12-31 11:48:43,233 INFO:     Found new best model at epoch 25
2022-12-31 11:48:43,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:43,234 INFO:     Epoch: 26
2022-12-31 11:48:44,826 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4630696554978689, 'Total loss': 0.4630696554978689} | train loss {'Reaction outcome loss': 0.3603374740189832, 'Total loss': 0.3603374740189832}
2022-12-31 11:48:44,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:44,826 INFO:     Epoch: 27
2022-12-31 11:48:46,481 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45918874541918436, 'Total loss': 0.45918874541918436} | train loss {'Reaction outcome loss': 0.37976039055248967, 'Total loss': 0.37976039055248967}
2022-12-31 11:48:46,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:46,481 INFO:     Epoch: 28
2022-12-31 11:48:48,096 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4903415302435557, 'Total loss': 0.4903415302435557} | train loss {'Reaction outcome loss': 0.36251319997835957, 'Total loss': 0.36251319997835957}
2022-12-31 11:48:48,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:48,096 INFO:     Epoch: 29
2022-12-31 11:48:49,699 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46836814483006795, 'Total loss': 0.46836814483006795} | train loss {'Reaction outcome loss': 0.34627892999434035, 'Total loss': 0.34627892999434035}
2022-12-31 11:48:49,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:49,700 INFO:     Epoch: 30
2022-12-31 11:48:51,314 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4325540999571482, 'Total loss': 0.4325540999571482} | train loss {'Reaction outcome loss': 0.3456131211090563, 'Total loss': 0.3456131211090563}
2022-12-31 11:48:51,314 INFO:     Found new best model at epoch 30
2022-12-31 11:48:51,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:51,315 INFO:     Epoch: 31
2022-12-31 11:48:52,929 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.444057689110438, 'Total loss': 0.444057689110438} | train loss {'Reaction outcome loss': 0.3414889204474436, 'Total loss': 0.3414889204474436}
2022-12-31 11:48:52,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:52,929 INFO:     Epoch: 32
2022-12-31 11:48:54,526 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49618752002716066, 'Total loss': 0.49618752002716066} | train loss {'Reaction outcome loss': 0.3241722964798944, 'Total loss': 0.3241722964798944}
2022-12-31 11:48:54,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:54,526 INFO:     Epoch: 33
2022-12-31 11:48:56,143 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4551644076903661, 'Total loss': 0.4551644076903661} | train loss {'Reaction outcome loss': 0.3229145025279781, 'Total loss': 0.3229145025279781}
2022-12-31 11:48:56,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:56,143 INFO:     Epoch: 34
2022-12-31 11:48:57,745 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4513988455136617, 'Total loss': 0.4513988455136617} | train loss {'Reaction outcome loss': 0.32336443190739583, 'Total loss': 0.32336443190739583}
2022-12-31 11:48:57,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:57,745 INFO:     Epoch: 35
2022-12-31 11:48:59,386 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48524982333183286, 'Total loss': 0.48524982333183286} | train loss {'Reaction outcome loss': 0.32341027930849214, 'Total loss': 0.32341027930849214}
2022-12-31 11:48:59,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:48:59,386 INFO:     Epoch: 36
2022-12-31 11:49:01,007 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4391545424858729, 'Total loss': 0.4391545424858729} | train loss {'Reaction outcome loss': 0.315848620136039, 'Total loss': 0.315848620136039}
2022-12-31 11:49:01,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:01,007 INFO:     Epoch: 37
2022-12-31 11:49:02,612 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4562973529100418, 'Total loss': 0.4562973529100418} | train loss {'Reaction outcome loss': 0.31087441137904115, 'Total loss': 0.31087441137904115}
2022-12-31 11:49:02,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:02,613 INFO:     Epoch: 38
2022-12-31 11:49:04,214 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.405783674120903, 'Total loss': 0.405783674120903} | train loss {'Reaction outcome loss': 0.31035494734195695, 'Total loss': 0.31035494734195695}
2022-12-31 11:49:04,214 INFO:     Found new best model at epoch 38
2022-12-31 11:49:04,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:04,215 INFO:     Epoch: 39
2022-12-31 11:49:05,829 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42549809714158376, 'Total loss': 0.42549809714158376} | train loss {'Reaction outcome loss': 0.3194388590510125, 'Total loss': 0.3194388590510125}
2022-12-31 11:49:05,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:05,829 INFO:     Epoch: 40
2022-12-31 11:49:07,433 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4535553197065989, 'Total loss': 0.4535553197065989} | train loss {'Reaction outcome loss': 0.30544944080537645, 'Total loss': 0.30544944080537645}
2022-12-31 11:49:07,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:07,434 INFO:     Epoch: 41
2022-12-31 11:49:09,048 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4472319185733795, 'Total loss': 0.4472319185733795} | train loss {'Reaction outcome loss': 0.29541435486812523, 'Total loss': 0.29541435486812523}
2022-12-31 11:49:09,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:09,049 INFO:     Epoch: 42
2022-12-31 11:49:10,665 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.56175883213679, 'Total loss': 0.56175883213679} | train loss {'Reaction outcome loss': 0.29922977521799615, 'Total loss': 0.29922977521799615}
2022-12-31 11:49:10,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:10,666 INFO:     Epoch: 43
2022-12-31 11:49:12,275 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4556022634108861, 'Total loss': 0.4556022634108861} | train loss {'Reaction outcome loss': 0.3730478211697461, 'Total loss': 0.3730478211697461}
2022-12-31 11:49:12,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:12,275 INFO:     Epoch: 44
2022-12-31 11:49:13,942 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4207355797290802, 'Total loss': 0.4207355797290802} | train loss {'Reaction outcome loss': 0.32107892064917565, 'Total loss': 0.32107892064917565}
2022-12-31 11:49:13,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:13,944 INFO:     Epoch: 45
2022-12-31 11:49:15,525 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.426596474647522, 'Total loss': 0.426596474647522} | train loss {'Reaction outcome loss': 0.3096231776369783, 'Total loss': 0.3096231776369783}
2022-12-31 11:49:15,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:15,525 INFO:     Epoch: 46
2022-12-31 11:49:17,163 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4423910578091939, 'Total loss': 0.4423910578091939} | train loss {'Reaction outcome loss': 0.299251870252192, 'Total loss': 0.299251870252192}
2022-12-31 11:49:17,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:17,164 INFO:     Epoch: 47
2022-12-31 11:49:18,811 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4136783609787623, 'Total loss': 0.4136783609787623} | train loss {'Reaction outcome loss': 0.3115635890027751, 'Total loss': 0.3115635890027751}
2022-12-31 11:49:18,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:18,811 INFO:     Epoch: 48
2022-12-31 11:49:20,482 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4178800344467163, 'Total loss': 0.4178800344467163} | train loss {'Reaction outcome loss': 0.3138788081975519, 'Total loss': 0.3138788081975519}
2022-12-31 11:49:20,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:20,483 INFO:     Epoch: 49
2022-12-31 11:49:22,116 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42989559670289357, 'Total loss': 0.42989559670289357} | train loss {'Reaction outcome loss': 0.2901361032918035, 'Total loss': 0.2901361032918035}
2022-12-31 11:49:22,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:22,116 INFO:     Epoch: 50
2022-12-31 11:49:23,783 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4182450900475184, 'Total loss': 0.4182450900475184} | train loss {'Reaction outcome loss': 0.2832739203672711, 'Total loss': 0.2832739203672711}
2022-12-31 11:49:23,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:23,783 INFO:     Epoch: 51
2022-12-31 11:49:25,415 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.401101412375768, 'Total loss': 0.401101412375768} | train loss {'Reaction outcome loss': 0.278059219717874, 'Total loss': 0.278059219717874}
2022-12-31 11:49:25,415 INFO:     Found new best model at epoch 51
2022-12-31 11:49:25,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:25,416 INFO:     Epoch: 52
2022-12-31 11:49:27,049 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4066744605700175, 'Total loss': 0.4066744605700175} | train loss {'Reaction outcome loss': 0.27832978392910696, 'Total loss': 0.27832978392910696}
2022-12-31 11:49:27,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:27,049 INFO:     Epoch: 53
2022-12-31 11:49:28,659 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.475075368086497, 'Total loss': 0.475075368086497} | train loss {'Reaction outcome loss': 0.2731837907137916, 'Total loss': 0.2731837907137916}
2022-12-31 11:49:28,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:28,659 INFO:     Epoch: 54
2022-12-31 11:49:30,249 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4555812458197276, 'Total loss': 0.4555812458197276} | train loss {'Reaction outcome loss': 0.2770567227393706, 'Total loss': 0.2770567227393706}
2022-12-31 11:49:30,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:30,249 INFO:     Epoch: 55
2022-12-31 11:49:31,871 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4531511763731639, 'Total loss': 0.4531511763731639} | train loss {'Reaction outcome loss': 0.2682647240654805, 'Total loss': 0.2682647240654805}
2022-12-31 11:49:31,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:31,871 INFO:     Epoch: 56
2022-12-31 11:49:33,486 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3948331440488497, 'Total loss': 0.3948331440488497} | train loss {'Reaction outcome loss': 0.26967261944209103, 'Total loss': 0.26967261944209103}
2022-12-31 11:49:33,486 INFO:     Found new best model at epoch 56
2022-12-31 11:49:33,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:33,487 INFO:     Epoch: 57
2022-12-31 11:49:35,088 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41298755407333376, 'Total loss': 0.41298755407333376} | train loss {'Reaction outcome loss': 0.2726597038225905, 'Total loss': 0.2726597038225905}
2022-12-31 11:49:35,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:35,089 INFO:     Epoch: 58
2022-12-31 11:49:36,702 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42466820081075035, 'Total loss': 0.42466820081075035} | train loss {'Reaction outcome loss': 0.2721818611835656, 'Total loss': 0.2721818611835656}
2022-12-31 11:49:36,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:36,702 INFO:     Epoch: 59
2022-12-31 11:49:38,314 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45028104186058043, 'Total loss': 0.45028104186058043} | train loss {'Reaction outcome loss': 0.3237596896921615, 'Total loss': 0.3237596896921615}
2022-12-31 11:49:38,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:38,315 INFO:     Epoch: 60
2022-12-31 11:49:39,907 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4487257411082586, 'Total loss': 0.4487257411082586} | train loss {'Reaction outcome loss': 0.2830120822300028, 'Total loss': 0.2830120822300028}
2022-12-31 11:49:39,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:39,908 INFO:     Epoch: 61
2022-12-31 11:49:41,522 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45486879348754883, 'Total loss': 0.45486879348754883} | train loss {'Reaction outcome loss': 0.2733514392208578, 'Total loss': 0.2733514392208578}
2022-12-31 11:49:41,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:41,523 INFO:     Epoch: 62
2022-12-31 11:49:43,121 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4363007714351018, 'Total loss': 0.4363007714351018} | train loss {'Reaction outcome loss': 0.2688951718374628, 'Total loss': 0.2688951718374628}
2022-12-31 11:49:43,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:43,121 INFO:     Epoch: 63
2022-12-31 11:49:44,734 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4098225067059199, 'Total loss': 0.4098225067059199} | train loss {'Reaction outcome loss': 0.25970756761312985, 'Total loss': 0.25970756761312985}
2022-12-31 11:49:44,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:44,735 INFO:     Epoch: 64
2022-12-31 11:49:46,347 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4153137028217316, 'Total loss': 0.4153137028217316} | train loss {'Reaction outcome loss': 0.2597458554106276, 'Total loss': 0.2597458554106276}
2022-12-31 11:49:46,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:46,347 INFO:     Epoch: 65
2022-12-31 11:49:47,958 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43334636092185974, 'Total loss': 0.43334636092185974} | train loss {'Reaction outcome loss': 0.2572396575014336, 'Total loss': 0.2572396575014336}
2022-12-31 11:49:47,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:47,958 INFO:     Epoch: 66
2022-12-31 11:49:49,555 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4161736706892649, 'Total loss': 0.4161736706892649} | train loss {'Reaction outcome loss': 0.25787227539737045, 'Total loss': 0.25787227539737045}
2022-12-31 11:49:49,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:49,555 INFO:     Epoch: 67
2022-12-31 11:49:51,193 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3861697554588318, 'Total loss': 0.3861697554588318} | train loss {'Reaction outcome loss': 0.2582301840091637, 'Total loss': 0.2582301840091637}
2022-12-31 11:49:51,194 INFO:     Found new best model at epoch 67
2022-12-31 11:49:51,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:51,195 INFO:     Epoch: 68
2022-12-31 11:49:52,822 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4312531506021818, 'Total loss': 0.4312531506021818} | train loss {'Reaction outcome loss': 0.25467004443682684, 'Total loss': 0.25467004443682684}
2022-12-31 11:49:52,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:52,822 INFO:     Epoch: 69
2022-12-31 11:49:54,434 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41242414017518364, 'Total loss': 0.41242414017518364} | train loss {'Reaction outcome loss': 0.2504479598529819, 'Total loss': 0.2504479598529819}
2022-12-31 11:49:54,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:54,435 INFO:     Epoch: 70
2022-12-31 11:49:56,048 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38356641431649524, 'Total loss': 0.38356641431649524} | train loss {'Reaction outcome loss': 0.2419631575011527, 'Total loss': 0.2419631575011527}
2022-12-31 11:49:56,048 INFO:     Found new best model at epoch 70
2022-12-31 11:49:56,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:56,049 INFO:     Epoch: 71
2022-12-31 11:49:57,660 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4229614779353142, 'Total loss': 0.4229614779353142} | train loss {'Reaction outcome loss': 0.25459681163487985, 'Total loss': 0.25459681163487985}
2022-12-31 11:49:57,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:57,660 INFO:     Epoch: 72
2022-12-31 11:49:59,274 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45053812563419343, 'Total loss': 0.45053812563419343} | train loss {'Reaction outcome loss': 0.2485210810968504, 'Total loss': 0.2485210810968504}
2022-12-31 11:49:59,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:49:59,274 INFO:     Epoch: 73
2022-12-31 11:50:00,881 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4541030059258143, 'Total loss': 0.4541030059258143} | train loss {'Reaction outcome loss': 0.23988390670400922, 'Total loss': 0.23988390670400922}
2022-12-31 11:50:00,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:00,881 INFO:     Epoch: 74
2022-12-31 11:50:02,479 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41761722366015114, 'Total loss': 0.41761722366015114} | train loss {'Reaction outcome loss': 0.2468800030351765, 'Total loss': 0.2468800030351765}
2022-12-31 11:50:02,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:02,479 INFO:     Epoch: 75
2022-12-31 11:50:04,094 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4292347878217697, 'Total loss': 0.4292347878217697} | train loss {'Reaction outcome loss': 0.2711438545687259, 'Total loss': 0.2711438545687259}
2022-12-31 11:50:04,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:04,095 INFO:     Epoch: 76
2022-12-31 11:50:05,710 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38539851605892184, 'Total loss': 0.38539851605892184} | train loss {'Reaction outcome loss': 0.25439300494390016, 'Total loss': 0.25439300494390016}
2022-12-31 11:50:05,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:05,710 INFO:     Epoch: 77
2022-12-31 11:50:07,312 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5014069557189942, 'Total loss': 0.5014069557189942} | train loss {'Reaction outcome loss': 0.2356898564764339, 'Total loss': 0.2356898564764339}
2022-12-31 11:50:07,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:07,313 INFO:     Epoch: 78
2022-12-31 11:50:08,927 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4899773160616557, 'Total loss': 0.4899773160616557} | train loss {'Reaction outcome loss': 0.25288495827682206, 'Total loss': 0.25288495827682206}
2022-12-31 11:50:08,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:08,928 INFO:     Epoch: 79
2022-12-31 11:50:10,521 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39308152596155804, 'Total loss': 0.39308152596155804} | train loss {'Reaction outcome loss': 0.2928110667895796, 'Total loss': 0.2928110667895796}
2022-12-31 11:50:10,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:10,522 INFO:     Epoch: 80
2022-12-31 11:50:12,138 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4687241926789284, 'Total loss': 0.4687241926789284} | train loss {'Reaction outcome loss': 0.2572772507640142, 'Total loss': 0.2572772507640142}
2022-12-31 11:50:12,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:12,138 INFO:     Epoch: 81
2022-12-31 11:50:13,753 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4008200039466222, 'Total loss': 0.4008200039466222} | train loss {'Reaction outcome loss': 0.23356893710003362, 'Total loss': 0.23356893710003362}
2022-12-31 11:50:13,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:13,754 INFO:     Epoch: 82
2022-12-31 11:50:15,348 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45786142150561016, 'Total loss': 0.45786142150561016} | train loss {'Reaction outcome loss': 0.24299477166293756, 'Total loss': 0.24299477166293756}
2022-12-31 11:50:15,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:15,348 INFO:     Epoch: 83
2022-12-31 11:50:17,008 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4167917271455129, 'Total loss': 0.4167917271455129} | train loss {'Reaction outcome loss': 0.33085859647911525, 'Total loss': 0.33085859647911525}
2022-12-31 11:50:17,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:17,008 INFO:     Epoch: 84
2022-12-31 11:50:18,632 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4348253031571706, 'Total loss': 0.4348253031571706} | train loss {'Reaction outcome loss': 0.2520737186178862, 'Total loss': 0.2520737186178862}
2022-12-31 11:50:18,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:18,632 INFO:     Epoch: 85
2022-12-31 11:50:20,261 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4188950667778651, 'Total loss': 0.4188950667778651} | train loss {'Reaction outcome loss': 0.2380381891456689, 'Total loss': 0.2380381891456689}
2022-12-31 11:50:20,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:20,262 INFO:     Epoch: 86
2022-12-31 11:50:21,882 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3988355487585068, 'Total loss': 0.3988355487585068} | train loss {'Reaction outcome loss': 0.22526753513065212, 'Total loss': 0.22526753513065212}
2022-12-31 11:50:21,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:21,882 INFO:     Epoch: 87
2022-12-31 11:50:23,498 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3927533869942029, 'Total loss': 0.3927533869942029} | train loss {'Reaction outcome loss': 0.2254498861561381, 'Total loss': 0.2254498861561381}
2022-12-31 11:50:23,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:23,498 INFO:     Epoch: 88
2022-12-31 11:50:25,105 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39542629023392994, 'Total loss': 0.39542629023392994} | train loss {'Reaction outcome loss': 0.22594351881559924, 'Total loss': 0.22594351881559924}
2022-12-31 11:50:25,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:25,106 INFO:     Epoch: 89
2022-12-31 11:50:26,742 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4258113334576289, 'Total loss': 0.4258113334576289} | train loss {'Reaction outcome loss': 0.2286054190057969, 'Total loss': 0.2286054190057969}
2022-12-31 11:50:26,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:26,742 INFO:     Epoch: 90
2022-12-31 11:50:28,346 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4035453379154205, 'Total loss': 0.4035453379154205} | train loss {'Reaction outcome loss': 0.22881473326866608, 'Total loss': 0.22881473326866608}
2022-12-31 11:50:28,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:28,346 INFO:     Epoch: 91
2022-12-31 11:50:29,963 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45319333573182424, 'Total loss': 0.45319333573182424} | train loss {'Reaction outcome loss': 0.22947088303044438, 'Total loss': 0.22947088303044438}
2022-12-31 11:50:29,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:29,963 INFO:     Epoch: 92
2022-12-31 11:50:31,586 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3861956199010213, 'Total loss': 0.3861956199010213} | train loss {'Reaction outcome loss': 0.22906604377836312, 'Total loss': 0.22906604377836312}
2022-12-31 11:50:31,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:31,587 INFO:     Epoch: 93
2022-12-31 11:50:33,201 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41528538266817727, 'Total loss': 0.41528538266817727} | train loss {'Reaction outcome loss': 0.2280486774009963, 'Total loss': 0.2280486774009963}
2022-12-31 11:50:33,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:33,201 INFO:     Epoch: 94
2022-12-31 11:50:34,799 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4006494919459025, 'Total loss': 0.4006494919459025} | train loss {'Reaction outcome loss': 0.22529554172573282, 'Total loss': 0.22529554172573282}
2022-12-31 11:50:34,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:34,799 INFO:     Epoch: 95
2022-12-31 11:50:36,415 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4321509778499603, 'Total loss': 0.4321509778499603} | train loss {'Reaction outcome loss': 0.2219327660589614, 'Total loss': 0.2219327660589614}
2022-12-31 11:50:36,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:36,415 INFO:     Epoch: 96
2022-12-31 11:50:38,012 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41388524174690244, 'Total loss': 0.41388524174690244} | train loss {'Reaction outcome loss': 0.2257202716841214, 'Total loss': 0.2257202716841214}
2022-12-31 11:50:38,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:38,013 INFO:     Epoch: 97
2022-12-31 11:50:39,664 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4561662922302882, 'Total loss': 0.4561662922302882} | train loss {'Reaction outcome loss': 0.22376256432060315, 'Total loss': 0.22376256432060315}
2022-12-31 11:50:39,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:39,665 INFO:     Epoch: 98
2022-12-31 11:50:41,279 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4431096911430359, 'Total loss': 0.4431096911430359} | train loss {'Reaction outcome loss': 0.22023053873208878, 'Total loss': 0.22023053873208878}
2022-12-31 11:50:41,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:41,280 INFO:     Epoch: 99
2022-12-31 11:50:42,888 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42625222106774646, 'Total loss': 0.42625222106774646} | train loss {'Reaction outcome loss': 0.22766361983519964, 'Total loss': 0.22766361983519964}
2022-12-31 11:50:42,888 INFO:     Best model found after epoch 71 of 100.
2022-12-31 11:50:42,888 INFO:   Done with stage: TRAINING
2022-12-31 11:50:42,888 INFO:   Starting stage: EVALUATION
2022-12-31 11:50:43,016 INFO:   Done with stage: EVALUATION
2022-12-31 11:50:43,016 INFO:   Leaving out SEQ value Fold_2
2022-12-31 11:50:43,029 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 11:50:43,029 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:50:43,685 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:50:43,685 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:50:43,754 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:50:43,754 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:50:43,754 INFO:     No hyperparam tuning for this model
2022-12-31 11:50:43,754 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:50:43,754 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:50:43,755 INFO:     None feature selector for col prot
2022-12-31 11:50:43,755 INFO:     None feature selector for col prot
2022-12-31 11:50:43,755 INFO:     None feature selector for col prot
2022-12-31 11:50:43,756 INFO:     None feature selector for col chem
2022-12-31 11:50:43,756 INFO:     None feature selector for col chem
2022-12-31 11:50:43,756 INFO:     None feature selector for col chem
2022-12-31 11:50:43,756 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:50:43,756 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:50:43,758 INFO:     Number of params in model 223921
2022-12-31 11:50:43,761 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:50:43,761 INFO:   Starting stage: TRAINING
2022-12-31 11:50:43,805 INFO:     Val loss before train {'Reaction outcome loss': 0.8625451266765595, 'Total loss': 0.8625451266765595}
2022-12-31 11:50:43,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:43,805 INFO:     Epoch: 0
2022-12-31 11:50:45,461 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6055381953716278, 'Total loss': 0.6055381953716278} | train loss {'Reaction outcome loss': 0.8155859235646951, 'Total loss': 0.8155859235646951}
2022-12-31 11:50:45,461 INFO:     Found new best model at epoch 0
2022-12-31 11:50:45,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:45,462 INFO:     Epoch: 1
2022-12-31 11:50:47,064 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4964299460252126, 'Total loss': 0.4964299460252126} | train loss {'Reaction outcome loss': 0.5956644277720555, 'Total loss': 0.5956644277720555}
2022-12-31 11:50:47,064 INFO:     Found new best model at epoch 1
2022-12-31 11:50:47,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:47,065 INFO:     Epoch: 2
2022-12-31 11:50:48,670 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4864380578200022, 'Total loss': 0.4864380578200022} | train loss {'Reaction outcome loss': 0.5294590844181333, 'Total loss': 0.5294590844181333}
2022-12-31 11:50:48,670 INFO:     Found new best model at epoch 2
2022-12-31 11:50:48,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:48,671 INFO:     Epoch: 3
2022-12-31 11:50:50,275 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4738703727722168, 'Total loss': 0.4738703727722168} | train loss {'Reaction outcome loss': 0.5015799018425228, 'Total loss': 0.5015799018425228}
2022-12-31 11:50:50,275 INFO:     Found new best model at epoch 3
2022-12-31 11:50:50,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:50,276 INFO:     Epoch: 4
2022-12-31 11:50:51,862 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46634524265925087, 'Total loss': 0.46634524265925087} | train loss {'Reaction outcome loss': 0.4864932555351814, 'Total loss': 0.4864932555351814}
2022-12-31 11:50:51,863 INFO:     Found new best model at epoch 4
2022-12-31 11:50:51,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:51,864 INFO:     Epoch: 5
2022-12-31 11:50:53,468 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47791610956192015, 'Total loss': 0.47791610956192015} | train loss {'Reaction outcome loss': 0.4748347696379153, 'Total loss': 0.4748347696379153}
2022-12-31 11:50:53,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:53,468 INFO:     Epoch: 6
2022-12-31 11:50:55,081 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45511414408683776, 'Total loss': 0.45511414408683776} | train loss {'Reaction outcome loss': 0.4675721931849083, 'Total loss': 0.4675721931849083}
2022-12-31 11:50:55,081 INFO:     Found new best model at epoch 6
2022-12-31 11:50:55,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:55,082 INFO:     Epoch: 7
2022-12-31 11:50:56,665 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44254021247227987, 'Total loss': 0.44254021247227987} | train loss {'Reaction outcome loss': 0.45372589122857493, 'Total loss': 0.45372589122857493}
2022-12-31 11:50:56,665 INFO:     Found new best model at epoch 7
2022-12-31 11:50:56,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:56,666 INFO:     Epoch: 8
2022-12-31 11:50:58,299 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42749288529157636, 'Total loss': 0.42749288529157636} | train loss {'Reaction outcome loss': 0.44872488899931423, 'Total loss': 0.44872488899931423}
2022-12-31 11:50:58,300 INFO:     Found new best model at epoch 8
2022-12-31 11:50:58,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:58,301 INFO:     Epoch: 9
2022-12-31 11:50:59,931 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4707602063814799, 'Total loss': 0.4707602063814799} | train loss {'Reaction outcome loss': 0.44064261908405017, 'Total loss': 0.44064261908405017}
2022-12-31 11:50:59,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:50:59,932 INFO:     Epoch: 10
2022-12-31 11:51:01,235 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4254520207643509, 'Total loss': 0.4254520207643509} | train loss {'Reaction outcome loss': 0.43445044212097667, 'Total loss': 0.43445044212097667}
2022-12-31 11:51:01,235 INFO:     Found new best model at epoch 10
2022-12-31 11:51:01,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:01,236 INFO:     Epoch: 11
2022-12-31 11:51:02,309 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4275573601325353, 'Total loss': 0.4275573601325353} | train loss {'Reaction outcome loss': 0.42666441392507, 'Total loss': 0.42666441392507}
2022-12-31 11:51:02,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:02,310 INFO:     Epoch: 12
2022-12-31 11:51:03,402 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4242708732684453, 'Total loss': 0.4242708732684453} | train loss {'Reaction outcome loss': 0.42083389480618666, 'Total loss': 0.42083389480618666}
2022-12-31 11:51:03,402 INFO:     Found new best model at epoch 12
2022-12-31 11:51:03,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:03,403 INFO:     Epoch: 13
2022-12-31 11:51:04,493 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4180091967185338, 'Total loss': 0.4180091967185338} | train loss {'Reaction outcome loss': 0.41618011663429927, 'Total loss': 0.41618011663429927}
2022-12-31 11:51:04,493 INFO:     Found new best model at epoch 13
2022-12-31 11:51:04,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:04,494 INFO:     Epoch: 14
2022-12-31 11:51:05,767 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4259469230969747, 'Total loss': 0.4259469230969747} | train loss {'Reaction outcome loss': 0.41031164904362966, 'Total loss': 0.41031164904362966}
2022-12-31 11:51:05,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:05,767 INFO:     Epoch: 15
2022-12-31 11:51:07,371 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41983231802781423, 'Total loss': 0.41983231802781423} | train loss {'Reaction outcome loss': 0.41671803147688397, 'Total loss': 0.41671803147688397}
2022-12-31 11:51:07,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:07,372 INFO:     Epoch: 16
2022-12-31 11:51:08,974 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41990411629279456, 'Total loss': 0.41990411629279456} | train loss {'Reaction outcome loss': 0.39774147067626897, 'Total loss': 0.39774147067626897}
2022-12-31 11:51:08,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:08,974 INFO:     Epoch: 17
2022-12-31 11:51:10,577 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4387674450874329, 'Total loss': 0.4387674450874329} | train loss {'Reaction outcome loss': 0.39051375597932914, 'Total loss': 0.39051375597932914}
2022-12-31 11:51:10,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:10,578 INFO:     Epoch: 18
2022-12-31 11:51:12,163 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4524714787801107, 'Total loss': 0.4524714787801107} | train loss {'Reaction outcome loss': 0.3929516377240202, 'Total loss': 0.3929516377240202}
2022-12-31 11:51:12,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:12,163 INFO:     Epoch: 19
2022-12-31 11:51:13,769 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.420903213818868, 'Total loss': 0.420903213818868} | train loss {'Reaction outcome loss': 0.385030596904511, 'Total loss': 0.385030596904511}
2022-12-31 11:51:13,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:13,769 INFO:     Epoch: 20
2022-12-31 11:51:15,375 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4257316470146179, 'Total loss': 0.4257316470146179} | train loss {'Reaction outcome loss': 0.37220621370051027, 'Total loss': 0.37220621370051027}
2022-12-31 11:51:15,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:15,376 INFO:     Epoch: 21
2022-12-31 11:51:17,028 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43876572052637736, 'Total loss': 0.43876572052637736} | train loss {'Reaction outcome loss': 0.37207236483584355, 'Total loss': 0.37207236483584355}
2022-12-31 11:51:17,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:17,028 INFO:     Epoch: 22
2022-12-31 11:51:18,636 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40903599858283995, 'Total loss': 0.40903599858283995} | train loss {'Reaction outcome loss': 0.36849524382583415, 'Total loss': 0.36849524382583415}
2022-12-31 11:51:18,636 INFO:     Found new best model at epoch 22
2022-12-31 11:51:18,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:18,637 INFO:     Epoch: 23
2022-12-31 11:51:20,226 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43110957443714143, 'Total loss': 0.43110957443714143} | train loss {'Reaction outcome loss': 0.36053795748165923, 'Total loss': 0.36053795748165923}
2022-12-31 11:51:20,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:20,226 INFO:     Epoch: 24
2022-12-31 11:51:21,872 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4289839992920558, 'Total loss': 0.4289839992920558} | train loss {'Reaction outcome loss': 0.35756607715339556, 'Total loss': 0.35756607715339556}
2022-12-31 11:51:21,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:21,872 INFO:     Epoch: 25
2022-12-31 11:51:23,509 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4196260233720144, 'Total loss': 0.4196260233720144} | train loss {'Reaction outcome loss': 0.3461766686208927, 'Total loss': 0.3461766686208927}
2022-12-31 11:51:23,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:23,509 INFO:     Epoch: 26
2022-12-31 11:51:25,145 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3943867295980453, 'Total loss': 0.3943867295980453} | train loss {'Reaction outcome loss': 0.3480355212886403, 'Total loss': 0.3480355212886403}
2022-12-31 11:51:25,145 INFO:     Found new best model at epoch 26
2022-12-31 11:51:25,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:25,146 INFO:     Epoch: 27
2022-12-31 11:51:26,785 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42342957109212875, 'Total loss': 0.42342957109212875} | train loss {'Reaction outcome loss': 0.3432601289347793, 'Total loss': 0.3432601289347793}
2022-12-31 11:51:26,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:26,786 INFO:     Epoch: 28
2022-12-31 11:51:28,441 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.419680713613828, 'Total loss': 0.419680713613828} | train loss {'Reaction outcome loss': 0.3345204548787897, 'Total loss': 0.3345204548787897}
2022-12-31 11:51:28,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:28,441 INFO:     Epoch: 29
2022-12-31 11:51:30,053 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42489132583141326, 'Total loss': 0.42489132583141326} | train loss {'Reaction outcome loss': 0.3310459179762941, 'Total loss': 0.3310459179762941}
2022-12-31 11:51:30,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:30,053 INFO:     Epoch: 30
2022-12-31 11:51:31,701 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38669001758098603, 'Total loss': 0.38669001758098603} | train loss {'Reaction outcome loss': 0.3266199666490085, 'Total loss': 0.3266199666490085}
2022-12-31 11:51:31,702 INFO:     Found new best model at epoch 30
2022-12-31 11:51:31,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:31,702 INFO:     Epoch: 31
2022-12-31 11:51:33,321 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4088441848754883, 'Total loss': 0.4088441848754883} | train loss {'Reaction outcome loss': 0.32100798059118923, 'Total loss': 0.32100798059118923}
2022-12-31 11:51:33,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:33,322 INFO:     Epoch: 32
2022-12-31 11:51:34,976 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4238538295030594, 'Total loss': 0.4238538295030594} | train loss {'Reaction outcome loss': 0.32065749521890696, 'Total loss': 0.32065749521890696}
2022-12-31 11:51:34,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:34,976 INFO:     Epoch: 33
2022-12-31 11:51:36,632 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4425800154606501, 'Total loss': 0.4425800154606501} | train loss {'Reaction outcome loss': 0.3120841135671974, 'Total loss': 0.3120841135671974}
2022-12-31 11:51:36,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:36,632 INFO:     Epoch: 34
2022-12-31 11:51:38,280 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43987657725811, 'Total loss': 0.43987657725811} | train loss {'Reaction outcome loss': 0.3082060068301911, 'Total loss': 0.3082060068301911}
2022-12-31 11:51:38,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:38,280 INFO:     Epoch: 35
2022-12-31 11:51:39,899 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4362887899080912, 'Total loss': 0.4362887899080912} | train loss {'Reaction outcome loss': 0.3014566285304562, 'Total loss': 0.3014566285304562}
2022-12-31 11:51:39,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:39,899 INFO:     Epoch: 36
2022-12-31 11:51:41,549 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4081329360604286, 'Total loss': 0.4081329360604286} | train loss {'Reaction outcome loss': 0.3061988183779873, 'Total loss': 0.3061988183779873}
2022-12-31 11:51:41,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:41,549 INFO:     Epoch: 37
2022-12-31 11:51:43,150 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38615449766318005, 'Total loss': 0.38615449766318005} | train loss {'Reaction outcome loss': 0.3043235215854688, 'Total loss': 0.3043235215854688}
2022-12-31 11:51:43,150 INFO:     Found new best model at epoch 37
2022-12-31 11:51:43,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:43,151 INFO:     Epoch: 38
2022-12-31 11:51:44,754 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3874544312556585, 'Total loss': 0.3874544312556585} | train loss {'Reaction outcome loss': 0.29312680914562983, 'Total loss': 0.29312680914562983}
2022-12-31 11:51:44,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:44,754 INFO:     Epoch: 39
2022-12-31 11:51:46,360 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3736855367819468, 'Total loss': 0.3736855367819468} | train loss {'Reaction outcome loss': 0.2961278084094507, 'Total loss': 0.2961278084094507}
2022-12-31 11:51:46,360 INFO:     Found new best model at epoch 39
2022-12-31 11:51:46,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:46,362 INFO:     Epoch: 40
2022-12-31 11:51:47,945 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4237397760152817, 'Total loss': 0.4237397760152817} | train loss {'Reaction outcome loss': 0.2875805753521132, 'Total loss': 0.2875805753521132}
2022-12-31 11:51:47,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:47,945 INFO:     Epoch: 41
2022-12-31 11:51:49,559 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4008686681588491, 'Total loss': 0.4008686681588491} | train loss {'Reaction outcome loss': 0.28898406911124713, 'Total loss': 0.28898406911124713}
2022-12-31 11:51:49,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:49,559 INFO:     Epoch: 42
2022-12-31 11:51:51,202 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3898679087559382, 'Total loss': 0.3898679087559382} | train loss {'Reaction outcome loss': 0.2841119239392289, 'Total loss': 0.2841119239392289}
2022-12-31 11:51:51,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:51,203 INFO:     Epoch: 43
2022-12-31 11:51:52,810 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38571873009204866, 'Total loss': 0.38571873009204866} | train loss {'Reaction outcome loss': 0.2839894156875837, 'Total loss': 0.2839894156875837}
2022-12-31 11:51:52,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:52,810 INFO:     Epoch: 44
2022-12-31 11:51:54,417 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38699669589598973, 'Total loss': 0.38699669589598973} | train loss {'Reaction outcome loss': 0.2787966029514579, 'Total loss': 0.2787966029514579}
2022-12-31 11:51:54,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:54,417 INFO:     Epoch: 45
2022-12-31 11:51:56,024 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37635741432507835, 'Total loss': 0.37635741432507835} | train loss {'Reaction outcome loss': 0.2794123016379393, 'Total loss': 0.2794123016379393}
2022-12-31 11:51:56,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:56,024 INFO:     Epoch: 46
2022-12-31 11:51:57,614 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3912233650684357, 'Total loss': 0.3912233650684357} | train loss {'Reaction outcome loss': 0.27321115108954647, 'Total loss': 0.27321115108954647}
2022-12-31 11:51:57,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:57,616 INFO:     Epoch: 47
2022-12-31 11:51:59,235 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35292409049967927, 'Total loss': 0.35292409049967927} | train loss {'Reaction outcome loss': 0.27350610712828644, 'Total loss': 0.27350610712828644}
2022-12-31 11:51:59,235 INFO:     Found new best model at epoch 47
2022-12-31 11:51:59,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:51:59,236 INFO:     Epoch: 48
2022-12-31 11:52:00,851 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46106942370533943, 'Total loss': 0.46106942370533943} | train loss {'Reaction outcome loss': 0.2778391065483872, 'Total loss': 0.2778391065483872}
2022-12-31 11:52:00,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:00,851 INFO:     Epoch: 49
2022-12-31 11:52:02,482 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39342427303393684, 'Total loss': 0.39342427303393684} | train loss {'Reaction outcome loss': 0.2681578285856186, 'Total loss': 0.2681578285856186}
2022-12-31 11:52:02,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:02,483 INFO:     Epoch: 50
2022-12-31 11:52:04,114 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37776683966318764, 'Total loss': 0.37776683966318764} | train loss {'Reaction outcome loss': 0.26358839922523414, 'Total loss': 0.26358839922523414}
2022-12-31 11:52:04,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:04,115 INFO:     Epoch: 51
2022-12-31 11:52:05,729 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4060953011115392, 'Total loss': 0.4060953011115392} | train loss {'Reaction outcome loss': 0.25726669918011574, 'Total loss': 0.25726669918011574}
2022-12-31 11:52:05,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:05,729 INFO:     Epoch: 52
2022-12-31 11:52:07,313 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3780225103100141, 'Total loss': 0.3780225103100141} | train loss {'Reaction outcome loss': 0.26386733974472887, 'Total loss': 0.26386733974472887}
2022-12-31 11:52:07,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:07,313 INFO:     Epoch: 53
2022-12-31 11:52:08,912 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3859277422229449, 'Total loss': 0.3859277422229449} | train loss {'Reaction outcome loss': 0.2558117347164419, 'Total loss': 0.2558117347164419}
2022-12-31 11:52:08,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:08,912 INFO:     Epoch: 54
2022-12-31 11:52:10,490 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3685080945491791, 'Total loss': 0.3685080945491791} | train loss {'Reaction outcome loss': 0.2588699768657667, 'Total loss': 0.2588699768657667}
2022-12-31 11:52:10,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:10,491 INFO:     Epoch: 55
2022-12-31 11:52:12,089 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38861477971076963, 'Total loss': 0.38861477971076963} | train loss {'Reaction outcome loss': 0.2609924487429705, 'Total loss': 0.2609924487429705}
2022-12-31 11:52:12,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:12,089 INFO:     Epoch: 56
2022-12-31 11:52:13,688 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39319773465394975, 'Total loss': 0.39319773465394975} | train loss {'Reaction outcome loss': 0.24929224625637714, 'Total loss': 0.24929224625637714}
2022-12-31 11:52:13,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:13,688 INFO:     Epoch: 57
2022-12-31 11:52:15,309 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45658456087112426, 'Total loss': 0.45658456087112426} | train loss {'Reaction outcome loss': 0.2510163410682313, 'Total loss': 0.2510163410682313}
2022-12-31 11:52:15,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:15,309 INFO:     Epoch: 58
2022-12-31 11:52:16,940 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3761699179808299, 'Total loss': 0.3761699179808299} | train loss {'Reaction outcome loss': 0.24698125002701787, 'Total loss': 0.24698125002701787}
2022-12-31 11:52:16,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:16,941 INFO:     Epoch: 59
2022-12-31 11:52:18,538 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3763129363457362, 'Total loss': 0.3763129363457362} | train loss {'Reaction outcome loss': 0.251407926072822, 'Total loss': 0.251407926072822}
2022-12-31 11:52:18,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:18,538 INFO:     Epoch: 60
2022-12-31 11:52:20,173 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37299234544237453, 'Total loss': 0.37299234544237453} | train loss {'Reaction outcome loss': 0.24752752752090892, 'Total loss': 0.24752752752090892}
2022-12-31 11:52:20,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:20,173 INFO:     Epoch: 61
2022-12-31 11:52:21,782 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3498512377341588, 'Total loss': 0.3498512377341588} | train loss {'Reaction outcome loss': 0.2482281857625629, 'Total loss': 0.2482281857625629}
2022-12-31 11:52:21,782 INFO:     Found new best model at epoch 61
2022-12-31 11:52:21,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:21,783 INFO:     Epoch: 62
2022-12-31 11:52:23,379 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3755736311276754, 'Total loss': 0.3755736311276754} | train loss {'Reaction outcome loss': 0.23908678977920192, 'Total loss': 0.23908678977920192}
2022-12-31 11:52:23,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:23,379 INFO:     Epoch: 63
2022-12-31 11:52:24,970 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4050406485795975, 'Total loss': 0.4050406485795975} | train loss {'Reaction outcome loss': 0.24387286884207143, 'Total loss': 0.24387286884207143}
2022-12-31 11:52:24,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:24,970 INFO:     Epoch: 64
2022-12-31 11:52:26,575 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3918347621957461, 'Total loss': 0.3918347621957461} | train loss {'Reaction outcome loss': 0.2501900597291924, 'Total loss': 0.2501900597291924}
2022-12-31 11:52:26,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:26,575 INFO:     Epoch: 65
2022-12-31 11:52:28,176 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37688193122545877, 'Total loss': 0.37688193122545877} | train loss {'Reaction outcome loss': 0.2365169963547892, 'Total loss': 0.2365169963547892}
2022-12-31 11:52:28,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:28,177 INFO:     Epoch: 66
2022-12-31 11:52:29,804 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3801138669252396, 'Total loss': 0.3801138669252396} | train loss {'Reaction outcome loss': 0.2395187814713177, 'Total loss': 0.2395187814713177}
2022-12-31 11:52:29,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:29,805 INFO:     Epoch: 67
2022-12-31 11:52:31,435 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3763304198781649, 'Total loss': 0.3763304198781649} | train loss {'Reaction outcome loss': 0.23817218430204332, 'Total loss': 0.23817218430204332}
2022-12-31 11:52:31,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:31,435 INFO:     Epoch: 68
2022-12-31 11:52:33,066 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3668130228916804, 'Total loss': 0.3668130228916804} | train loss {'Reaction outcome loss': 0.23742245115937977, 'Total loss': 0.23742245115937977}
2022-12-31 11:52:33,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:33,066 INFO:     Epoch: 69
2022-12-31 11:52:34,660 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4284134993950526, 'Total loss': 0.4284134993950526} | train loss {'Reaction outcome loss': 0.2286627878482542, 'Total loss': 0.2286627878482542}
2022-12-31 11:52:34,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:34,661 INFO:     Epoch: 70
2022-12-31 11:52:36,280 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3919713487227758, 'Total loss': 0.3919713487227758} | train loss {'Reaction outcome loss': 0.2304161449581602, 'Total loss': 0.2304161449581602}
2022-12-31 11:52:36,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:36,281 INFO:     Epoch: 71
2022-12-31 11:52:37,903 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4315097729365031, 'Total loss': 0.4315097729365031} | train loss {'Reaction outcome loss': 0.22736518747125664, 'Total loss': 0.22736518747125664}
2022-12-31 11:52:37,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:37,903 INFO:     Epoch: 72
2022-12-31 11:52:39,548 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3754365034401417, 'Total loss': 0.3754365034401417} | train loss {'Reaction outcome loss': 0.22414264478550774, 'Total loss': 0.22414264478550774}
2022-12-31 11:52:39,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:39,548 INFO:     Epoch: 73
2022-12-31 11:52:41,178 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4176136245330175, 'Total loss': 0.4176136245330175} | train loss {'Reaction outcome loss': 0.22686933505817922, 'Total loss': 0.22686933505817922}
2022-12-31 11:52:41,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:41,178 INFO:     Epoch: 74
2022-12-31 11:52:42,804 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3864402780930201, 'Total loss': 0.3864402780930201} | train loss {'Reaction outcome loss': 0.22839630749688422, 'Total loss': 0.22839630749688422}
2022-12-31 11:52:42,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:42,804 INFO:     Epoch: 75
2022-12-31 11:52:44,455 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3922419846057892, 'Total loss': 0.3922419846057892} | train loss {'Reaction outcome loss': 0.2211413748535144, 'Total loss': 0.2211413748535144}
2022-12-31 11:52:44,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:44,455 INFO:     Epoch: 76
2022-12-31 11:52:46,062 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41037374834219614, 'Total loss': 0.41037374834219614} | train loss {'Reaction outcome loss': 0.2231981231334762, 'Total loss': 0.2231981231334762}
2022-12-31 11:52:46,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:46,062 INFO:     Epoch: 77
2022-12-31 11:52:47,663 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3854297856489817, 'Total loss': 0.3854297856489817} | train loss {'Reaction outcome loss': 0.22278745877590492, 'Total loss': 0.22278745877590492}
2022-12-31 11:52:47,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:47,664 INFO:     Epoch: 78
2022-12-31 11:52:49,265 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4322840084632238, 'Total loss': 0.4322840084632238} | train loss {'Reaction outcome loss': 0.22181216141983975, 'Total loss': 0.22181216141983975}
2022-12-31 11:52:49,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:49,265 INFO:     Epoch: 79
2022-12-31 11:52:50,864 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3847684383392334, 'Total loss': 0.3847684383392334} | train loss {'Reaction outcome loss': 0.2161379373448826, 'Total loss': 0.2161379373448826}
2022-12-31 11:52:50,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:50,865 INFO:     Epoch: 80
2022-12-31 11:52:52,454 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39543799658616385, 'Total loss': 0.39543799658616385} | train loss {'Reaction outcome loss': 0.21627927978054015, 'Total loss': 0.21627927978054015}
2022-12-31 11:52:52,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:52,454 INFO:     Epoch: 81
2022-12-31 11:52:54,054 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4384786695241928, 'Total loss': 0.4384786695241928} | train loss {'Reaction outcome loss': 0.21457453804212984, 'Total loss': 0.21457453804212984}
2022-12-31 11:52:54,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:54,054 INFO:     Epoch: 82
2022-12-31 11:52:55,637 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38602420190970105, 'Total loss': 0.38602420190970105} | train loss {'Reaction outcome loss': 0.21250951933898848, 'Total loss': 0.21250951933898848}
2022-12-31 11:52:55,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:55,638 INFO:     Epoch: 83
2022-12-31 11:52:57,239 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44443106452624004, 'Total loss': 0.44443106452624004} | train loss {'Reaction outcome loss': 0.20631373932680291, 'Total loss': 0.20631373932680291}
2022-12-31 11:52:57,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:57,239 INFO:     Epoch: 84
2022-12-31 11:52:58,851 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4248288705945015, 'Total loss': 0.4248288705945015} | train loss {'Reaction outcome loss': 0.21210413569937983, 'Total loss': 0.21210413569937983}
2022-12-31 11:52:58,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:52:58,852 INFO:     Epoch: 85
2022-12-31 11:53:00,468 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39147911270459496, 'Total loss': 0.39147911270459496} | train loss {'Reaction outcome loss': 0.20837191866207733, 'Total loss': 0.20837191866207733}
2022-12-31 11:53:00,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:00,468 INFO:     Epoch: 86
2022-12-31 11:53:02,061 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39168179432551065, 'Total loss': 0.39168179432551065} | train loss {'Reaction outcome loss': 0.2110224795004312, 'Total loss': 0.2110224795004312}
2022-12-31 11:53:02,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:02,062 INFO:     Epoch: 87
2022-12-31 11:53:03,661 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3771911561489105, 'Total loss': 0.3771911561489105} | train loss {'Reaction outcome loss': 0.21699508365216483, 'Total loss': 0.21699508365216483}
2022-12-31 11:53:03,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:03,661 INFO:     Epoch: 88
2022-12-31 11:53:05,243 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40760307808717094, 'Total loss': 0.40760307808717094} | train loss {'Reaction outcome loss': 0.19998132181183917, 'Total loss': 0.19998132181183917}
2022-12-31 11:53:05,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:05,244 INFO:     Epoch: 89
2022-12-31 11:53:06,854 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40382700562477114, 'Total loss': 0.40382700562477114} | train loss {'Reaction outcome loss': 0.20623491170822922, 'Total loss': 0.20623491170822922}
2022-12-31 11:53:06,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:06,854 INFO:     Epoch: 90
2022-12-31 11:53:08,457 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.359080770611763, 'Total loss': 0.359080770611763} | train loss {'Reaction outcome loss': 0.20918778627159168, 'Total loss': 0.20918778627159168}
2022-12-31 11:53:08,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:08,457 INFO:     Epoch: 91
2022-12-31 11:53:10,043 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4125100294748942, 'Total loss': 0.4125100294748942} | train loss {'Reaction outcome loss': 0.20715099751242322, 'Total loss': 0.20715099751242322}
2022-12-31 11:53:10,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:10,043 INFO:     Epoch: 92
2022-12-31 11:53:11,646 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39911371767520903, 'Total loss': 0.39911371767520903} | train loss {'Reaction outcome loss': 0.20980498431943848, 'Total loss': 0.20980498431943848}
2022-12-31 11:53:11,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:11,646 INFO:     Epoch: 93
2022-12-31 11:53:13,227 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36191662748654685, 'Total loss': 0.36191662748654685} | train loss {'Reaction outcome loss': 0.20607703286189125, 'Total loss': 0.20607703286189125}
2022-12-31 11:53:13,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:13,227 INFO:     Epoch: 94
2022-12-31 11:53:14,847 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37991781656940776, 'Total loss': 0.37991781656940776} | train loss {'Reaction outcome loss': 0.20307405434385703, 'Total loss': 0.20307405434385703}
2022-12-31 11:53:14,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:14,847 INFO:     Epoch: 95
2022-12-31 11:53:16,475 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4089781289299329, 'Total loss': 0.4089781289299329} | train loss {'Reaction outcome loss': 0.20668812444855045, 'Total loss': 0.20668812444855045}
2022-12-31 11:53:16,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:16,476 INFO:     Epoch: 96
2022-12-31 11:53:18,079 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37750325798988343, 'Total loss': 0.37750325798988343} | train loss {'Reaction outcome loss': 0.19811658596919074, 'Total loss': 0.19811658596919074}
2022-12-31 11:53:18,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:18,080 INFO:     Epoch: 97
2022-12-31 11:53:19,663 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36499454180399576, 'Total loss': 0.36499454180399576} | train loss {'Reaction outcome loss': 0.19851538384618767, 'Total loss': 0.19851538384618767}
2022-12-31 11:53:19,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:19,664 INFO:     Epoch: 98
2022-12-31 11:53:21,262 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39501679837703707, 'Total loss': 0.39501679837703707} | train loss {'Reaction outcome loss': 0.19840726209464518, 'Total loss': 0.19840726209464518}
2022-12-31 11:53:21,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:21,262 INFO:     Epoch: 99
2022-12-31 11:53:22,862 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3826519280672073, 'Total loss': 0.3826519280672073} | train loss {'Reaction outcome loss': 0.19960800791159272, 'Total loss': 0.19960800791159272}
2022-12-31 11:53:22,862 INFO:     Best model found after epoch 62 of 100.
2022-12-31 11:53:22,862 INFO:   Done with stage: TRAINING
2022-12-31 11:53:22,862 INFO:   Starting stage: EVALUATION
2022-12-31 11:53:22,998 INFO:   Done with stage: EVALUATION
2022-12-31 11:53:22,998 INFO:   Leaving out SEQ value Fold_3
2022-12-31 11:53:23,011 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 11:53:23,011 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:53:23,653 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:53:23,653 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:53:23,720 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:53:23,721 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:53:23,721 INFO:     No hyperparam tuning for this model
2022-12-31 11:53:23,721 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:53:23,721 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:53:23,721 INFO:     None feature selector for col prot
2022-12-31 11:53:23,722 INFO:     None feature selector for col prot
2022-12-31 11:53:23,722 INFO:     None feature selector for col prot
2022-12-31 11:53:23,722 INFO:     None feature selector for col chem
2022-12-31 11:53:23,722 INFO:     None feature selector for col chem
2022-12-31 11:53:23,722 INFO:     None feature selector for col chem
2022-12-31 11:53:23,722 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:53:23,722 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:53:23,724 INFO:     Number of params in model 223921
2022-12-31 11:53:23,727 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:53:23,727 INFO:   Starting stage: TRAINING
2022-12-31 11:53:23,771 INFO:     Val loss before train {'Reaction outcome loss': 0.9593588431676229, 'Total loss': 0.9593588431676229}
2022-12-31 11:53:23,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:23,771 INFO:     Epoch: 0
2022-12-31 11:53:25,393 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.639681077003479, 'Total loss': 0.639681077003479} | train loss {'Reaction outcome loss': 0.8324319019422426, 'Total loss': 0.8324319019422426}
2022-12-31 11:53:25,393 INFO:     Found new best model at epoch 0
2022-12-31 11:53:25,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:25,394 INFO:     Epoch: 1
2022-12-31 11:53:27,016 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5540272355079651, 'Total loss': 0.5540272355079651} | train loss {'Reaction outcome loss': 0.6126400258514907, 'Total loss': 0.6126400258514907}
2022-12-31 11:53:27,016 INFO:     Found new best model at epoch 1
2022-12-31 11:53:27,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:27,017 INFO:     Epoch: 2
2022-12-31 11:53:28,591 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5241960287094116, 'Total loss': 0.5241960287094116} | train loss {'Reaction outcome loss': 0.5383946433281287, 'Total loss': 0.5383946433281287}
2022-12-31 11:53:28,591 INFO:     Found new best model at epoch 2
2022-12-31 11:53:28,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:28,592 INFO:     Epoch: 3
2022-12-31 11:53:30,184 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47203664779663085, 'Total loss': 0.47203664779663085} | train loss {'Reaction outcome loss': 0.5129579042012875, 'Total loss': 0.5129579042012875}
2022-12-31 11:53:30,185 INFO:     Found new best model at epoch 3
2022-12-31 11:53:30,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:30,186 INFO:     Epoch: 4
2022-12-31 11:53:31,783 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4555780291557312, 'Total loss': 0.4555780291557312} | train loss {'Reaction outcome loss': 0.4991804212877602, 'Total loss': 0.4991804212877602}
2022-12-31 11:53:31,783 INFO:     Found new best model at epoch 4
2022-12-31 11:53:31,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:31,784 INFO:     Epoch: 5
2022-12-31 11:53:33,413 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44617159565289816, 'Total loss': 0.44617159565289816} | train loss {'Reaction outcome loss': 0.48733335910808473, 'Total loss': 0.48733335910808473}
2022-12-31 11:53:33,413 INFO:     Found new best model at epoch 5
2022-12-31 11:53:33,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:33,414 INFO:     Epoch: 6
2022-12-31 11:53:35,005 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5092613677183787, 'Total loss': 0.5092613677183787} | train loss {'Reaction outcome loss': 0.48102866740890476, 'Total loss': 0.48102866740890476}
2022-12-31 11:53:35,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:35,006 INFO:     Epoch: 7
2022-12-31 11:53:36,585 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44294761419296264, 'Total loss': 0.44294761419296264} | train loss {'Reaction outcome loss': 0.475480963022281, 'Total loss': 0.475480963022281}
2022-12-31 11:53:36,586 INFO:     Found new best model at epoch 7
2022-12-31 11:53:36,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:36,587 INFO:     Epoch: 8
2022-12-31 11:53:38,178 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4382969876130422, 'Total loss': 0.4382969876130422} | train loss {'Reaction outcome loss': 0.4691516486825524, 'Total loss': 0.4691516486825524}
2022-12-31 11:53:38,179 INFO:     Found new best model at epoch 8
2022-12-31 11:53:38,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:38,180 INFO:     Epoch: 9
2022-12-31 11:53:39,766 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46269174516201017, 'Total loss': 0.46269174516201017} | train loss {'Reaction outcome loss': 0.4574512453961285, 'Total loss': 0.4574512453961285}
2022-12-31 11:53:39,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:39,766 INFO:     Epoch: 10
2022-12-31 11:53:41,342 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4236444264650345, 'Total loss': 0.4236444264650345} | train loss {'Reaction outcome loss': 0.45449343170875156, 'Total loss': 0.45449343170875156}
2022-12-31 11:53:41,342 INFO:     Found new best model at epoch 10
2022-12-31 11:53:41,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:41,343 INFO:     Epoch: 11
2022-12-31 11:53:42,936 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41885103384653727, 'Total loss': 0.41885103384653727} | train loss {'Reaction outcome loss': 0.45162469929172877, 'Total loss': 0.45162469929172877}
2022-12-31 11:53:42,936 INFO:     Found new best model at epoch 11
2022-12-31 11:53:42,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:42,937 INFO:     Epoch: 12
2022-12-31 11:53:44,531 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4192859262228012, 'Total loss': 0.4192859262228012} | train loss {'Reaction outcome loss': 0.44237386140522067, 'Total loss': 0.44237386140522067}
2022-12-31 11:53:44,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:44,531 INFO:     Epoch: 13
2022-12-31 11:53:46,134 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41333351532618207, 'Total loss': 0.41333351532618207} | train loss {'Reaction outcome loss': 0.43359453770103473, 'Total loss': 0.43359453770103473}
2022-12-31 11:53:46,134 INFO:     Found new best model at epoch 13
2022-12-31 11:53:46,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:46,135 INFO:     Epoch: 14
2022-12-31 11:53:47,774 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4305949250857035, 'Total loss': 0.4305949250857035} | train loss {'Reaction outcome loss': 0.4273295861297038, 'Total loss': 0.4273295861297038}
2022-12-31 11:53:47,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:47,774 INFO:     Epoch: 15
2022-12-31 11:53:49,354 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42648620108763374, 'Total loss': 0.42648620108763374} | train loss {'Reaction outcome loss': 0.42130372807001454, 'Total loss': 0.42130372807001454}
2022-12-31 11:53:49,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:49,355 INFO:     Epoch: 16
2022-12-31 11:53:50,985 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44933564265569054, 'Total loss': 0.44933564265569054} | train loss {'Reaction outcome loss': 0.4138853362464643, 'Total loss': 0.4138853362464643}
2022-12-31 11:53:50,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:50,986 INFO:     Epoch: 17
2022-12-31 11:53:52,635 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42415034770965576, 'Total loss': 0.42415034770965576} | train loss {'Reaction outcome loss': 0.4135028500205431, 'Total loss': 0.4135028500205431}
2022-12-31 11:53:52,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:52,635 INFO:     Epoch: 18
2022-12-31 11:53:54,230 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4440225899219513, 'Total loss': 0.4440225899219513} | train loss {'Reaction outcome loss': 0.40271031125124557, 'Total loss': 0.40271031125124557}
2022-12-31 11:53:54,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:54,230 INFO:     Epoch: 19
2022-12-31 11:53:55,814 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40833208660284676, 'Total loss': 0.40833208660284676} | train loss {'Reaction outcome loss': 0.39953256253794434, 'Total loss': 0.39953256253794434}
2022-12-31 11:53:55,815 INFO:     Found new best model at epoch 19
2022-12-31 11:53:55,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:55,816 INFO:     Epoch: 20
2022-12-31 11:53:57,410 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4026979645093282, 'Total loss': 0.4026979645093282} | train loss {'Reaction outcome loss': 0.39438868700884855, 'Total loss': 0.39438868700884855}
2022-12-31 11:53:57,410 INFO:     Found new best model at epoch 20
2022-12-31 11:53:57,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:57,411 INFO:     Epoch: 21
2022-12-31 11:53:59,016 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4054745296637217, 'Total loss': 0.4054745296637217} | train loss {'Reaction outcome loss': 0.38348767920073135, 'Total loss': 0.38348767920073135}
2022-12-31 11:53:59,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:53:59,017 INFO:     Epoch: 22
2022-12-31 11:54:00,637 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.432232141494751, 'Total loss': 0.432232141494751} | train loss {'Reaction outcome loss': 0.38172715026271214, 'Total loss': 0.38172715026271214}
2022-12-31 11:54:00,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:00,637 INFO:     Epoch: 23
2022-12-31 11:54:02,233 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4444824253519376, 'Total loss': 0.4444824253519376} | train loss {'Reaction outcome loss': 0.38380005213367197, 'Total loss': 0.38380005213367197}
2022-12-31 11:54:02,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:02,233 INFO:     Epoch: 24
2022-12-31 11:54:03,816 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3942388286193212, 'Total loss': 0.3942388286193212} | train loss {'Reaction outcome loss': 0.3750325623804178, 'Total loss': 0.3750325623804178}
2022-12-31 11:54:03,816 INFO:     Found new best model at epoch 24
2022-12-31 11:54:03,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:03,817 INFO:     Epoch: 25
2022-12-31 11:54:05,418 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41873855392138165, 'Total loss': 0.41873855392138165} | train loss {'Reaction outcome loss': 0.36667917341321377, 'Total loss': 0.36667917341321377}
2022-12-31 11:54:05,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:05,420 INFO:     Epoch: 26
2022-12-31 11:54:07,031 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4097932736078898, 'Total loss': 0.4097932736078898} | train loss {'Reaction outcome loss': 0.3595152269271049, 'Total loss': 0.3595152269271049}
2022-12-31 11:54:07,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:07,031 INFO:     Epoch: 27
2022-12-31 11:54:08,614 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4325615743796031, 'Total loss': 0.4325615743796031} | train loss {'Reaction outcome loss': 0.35694472371658564, 'Total loss': 0.35694472371658564}
2022-12-31 11:54:08,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:08,614 INFO:     Epoch: 28
2022-12-31 11:54:10,216 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4149784843126933, 'Total loss': 0.4149784843126933} | train loss {'Reaction outcome loss': 0.3555562620907476, 'Total loss': 0.3555562620907476}
2022-12-31 11:54:10,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:10,216 INFO:     Epoch: 29
2022-12-31 11:54:11,820 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39281882892052333, 'Total loss': 0.39281882892052333} | train loss {'Reaction outcome loss': 0.347015812037847, 'Total loss': 0.347015812037847}
2022-12-31 11:54:11,821 INFO:     Found new best model at epoch 29
2022-12-31 11:54:11,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:11,822 INFO:     Epoch: 30
2022-12-31 11:54:13,398 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38256522665421167, 'Total loss': 0.38256522665421167} | train loss {'Reaction outcome loss': 0.34125183080578897, 'Total loss': 0.34125183080578897}
2022-12-31 11:54:13,398 INFO:     Found new best model at epoch 30
2022-12-31 11:54:13,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:13,399 INFO:     Epoch: 31
2022-12-31 11:54:14,993 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3822862168153127, 'Total loss': 0.3822862168153127} | train loss {'Reaction outcome loss': 0.3369185412814329, 'Total loss': 0.3369185412814329}
2022-12-31 11:54:14,993 INFO:     Found new best model at epoch 31
2022-12-31 11:54:14,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:14,994 INFO:     Epoch: 32
2022-12-31 11:54:16,611 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43935712774594626, 'Total loss': 0.43935712774594626} | train loss {'Reaction outcome loss': 0.3324757099642858, 'Total loss': 0.3324757099642858}
2022-12-31 11:54:16,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:16,611 INFO:     Epoch: 33
2022-12-31 11:54:18,232 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4332916647195816, 'Total loss': 0.4332916647195816} | train loss {'Reaction outcome loss': 0.32621313424119147, 'Total loss': 0.32621313424119147}
2022-12-31 11:54:18,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:18,232 INFO:     Epoch: 34
2022-12-31 11:54:19,864 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4055260161558787, 'Total loss': 0.4055260161558787} | train loss {'Reaction outcome loss': 0.33064204691858085, 'Total loss': 0.33064204691858085}
2022-12-31 11:54:19,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:19,864 INFO:     Epoch: 35
2022-12-31 11:54:21,463 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3573792134722074, 'Total loss': 0.3573792134722074} | train loss {'Reaction outcome loss': 0.320734439683812, 'Total loss': 0.320734439683812}
2022-12-31 11:54:21,463 INFO:     Found new best model at epoch 35
2022-12-31 11:54:21,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:21,464 INFO:     Epoch: 36
2022-12-31 11:54:23,066 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4023696353038152, 'Total loss': 0.4023696353038152} | train loss {'Reaction outcome loss': 0.31515534918059357, 'Total loss': 0.31515534918059357}
2022-12-31 11:54:23,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:23,067 INFO:     Epoch: 37
2022-12-31 11:54:24,692 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3910450935829431, 'Total loss': 0.3910450935829431} | train loss {'Reaction outcome loss': 0.305081747540515, 'Total loss': 0.305081747540515}
2022-12-31 11:54:24,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:24,693 INFO:     Epoch: 38
2022-12-31 11:54:26,264 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40664780934651695, 'Total loss': 0.40664780934651695} | train loss {'Reaction outcome loss': 0.30680044063609163, 'Total loss': 0.30680044063609163}
2022-12-31 11:54:26,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:26,264 INFO:     Epoch: 39
2022-12-31 11:54:27,855 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35474432905515035, 'Total loss': 0.35474432905515035} | train loss {'Reaction outcome loss': 0.29837798076125727, 'Total loss': 0.29837798076125727}
2022-12-31 11:54:27,855 INFO:     Found new best model at epoch 39
2022-12-31 11:54:27,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:27,856 INFO:     Epoch: 40
2022-12-31 11:54:29,453 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46087552706400553, 'Total loss': 0.46087552706400553} | train loss {'Reaction outcome loss': 0.2961426684240582, 'Total loss': 0.2961426684240582}
2022-12-31 11:54:29,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:29,453 INFO:     Epoch: 41
2022-12-31 11:54:31,044 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42738560289144517, 'Total loss': 0.42738560289144517} | train loss {'Reaction outcome loss': 0.2922016890112297, 'Total loss': 0.2922016890112297}
2022-12-31 11:54:31,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:31,044 INFO:     Epoch: 42
2022-12-31 11:54:32,646 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4047649309039116, 'Total loss': 0.4047649309039116} | train loss {'Reaction outcome loss': 0.29077507042404493, 'Total loss': 0.29077507042404493}
2022-12-31 11:54:32,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:32,646 INFO:     Epoch: 43
2022-12-31 11:54:34,258 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4121379738052686, 'Total loss': 0.4121379738052686} | train loss {'Reaction outcome loss': 0.2803681479569102, 'Total loss': 0.2803681479569102}
2022-12-31 11:54:34,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:34,258 INFO:     Epoch: 44
2022-12-31 11:54:35,828 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3820175141096115, 'Total loss': 0.3820175141096115} | train loss {'Reaction outcome loss': 0.2797057984512804, 'Total loss': 0.2797057984512804}
2022-12-31 11:54:35,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:35,829 INFO:     Epoch: 45
2022-12-31 11:54:37,423 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4117373377084732, 'Total loss': 0.4117373377084732} | train loss {'Reaction outcome loss': 0.27445474927460317, 'Total loss': 0.27445474927460317}
2022-12-31 11:54:37,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:37,423 INFO:     Epoch: 46
2022-12-31 11:54:39,013 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3913620591163635, 'Total loss': 0.3913620591163635} | train loss {'Reaction outcome loss': 0.27316449421556876, 'Total loss': 0.27316449421556876}
2022-12-31 11:54:39,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:39,013 INFO:     Epoch: 47
2022-12-31 11:54:40,586 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40139206598202387, 'Total loss': 0.40139206598202387} | train loss {'Reaction outcome loss': 0.26429422387355195, 'Total loss': 0.26429422387355195}
2022-12-31 11:54:40,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:40,587 INFO:     Epoch: 48
2022-12-31 11:54:42,181 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3655158758163452, 'Total loss': 0.3655158758163452} | train loss {'Reaction outcome loss': 0.2685406070898522, 'Total loss': 0.2685406070898522}
2022-12-31 11:54:42,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:42,182 INFO:     Epoch: 49
2022-12-31 11:54:43,784 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41160347561041516, 'Total loss': 0.41160347561041516} | train loss {'Reaction outcome loss': 0.25872527200715006, 'Total loss': 0.25872527200715006}
2022-12-31 11:54:43,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:43,784 INFO:     Epoch: 50
2022-12-31 11:54:45,391 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3705598384141922, 'Total loss': 0.3705598384141922} | train loss {'Reaction outcome loss': 0.26402254970300765, 'Total loss': 0.26402254970300765}
2022-12-31 11:54:45,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:45,391 INFO:     Epoch: 51
2022-12-31 11:54:46,982 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3940257598956426, 'Total loss': 0.3940257598956426} | train loss {'Reaction outcome loss': 0.2575969162103703, 'Total loss': 0.2575969162103703}
2022-12-31 11:54:46,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:46,982 INFO:     Epoch: 52
2022-12-31 11:54:48,579 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3764926848312219, 'Total loss': 0.3764926848312219} | train loss {'Reaction outcome loss': 0.26267225865697685, 'Total loss': 0.26267225865697685}
2022-12-31 11:54:48,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:48,579 INFO:     Epoch: 53
2022-12-31 11:54:50,183 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3949235608180364, 'Total loss': 0.3949235608180364} | train loss {'Reaction outcome loss': 0.2633844854467081, 'Total loss': 0.2633844854467081}
2022-12-31 11:54:50,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:50,184 INFO:     Epoch: 54
2022-12-31 11:54:51,768 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3724716583887736, 'Total loss': 0.3724716583887736} | train loss {'Reaction outcome loss': 0.25523499688031254, 'Total loss': 0.25523499688031254}
2022-12-31 11:54:51,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:51,768 INFO:     Epoch: 55
2022-12-31 11:54:53,369 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3868202845255534, 'Total loss': 0.3868202845255534} | train loss {'Reaction outcome loss': 0.2582125733077744, 'Total loss': 0.2582125733077744}
2022-12-31 11:54:53,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:53,369 INFO:     Epoch: 56
2022-12-31 11:54:54,979 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3712351160744826, 'Total loss': 0.3712351160744826} | train loss {'Reaction outcome loss': 0.2518326148796731, 'Total loss': 0.2518326148796731}
2022-12-31 11:54:54,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:54,980 INFO:     Epoch: 57
2022-12-31 11:54:56,559 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40314251482486724, 'Total loss': 0.40314251482486724} | train loss {'Reaction outcome loss': 0.24643862888817386, 'Total loss': 0.24643862888817386}
2022-12-31 11:54:56,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:56,559 INFO:     Epoch: 58
2022-12-31 11:54:58,166 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39341243704160056, 'Total loss': 0.39341243704160056} | train loss {'Reaction outcome loss': 0.2553479561220595, 'Total loss': 0.2553479561220595}
2022-12-31 11:54:58,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:58,166 INFO:     Epoch: 59
2022-12-31 11:54:59,793 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3850286781787872, 'Total loss': 0.3850286781787872} | train loss {'Reaction outcome loss': 0.23776808780901162, 'Total loss': 0.23776808780901162}
2022-12-31 11:54:59,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:54:59,793 INFO:     Epoch: 60
2022-12-31 11:55:01,386 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4060459643602371, 'Total loss': 0.4060459643602371} | train loss {'Reaction outcome loss': 0.23711357904332026, 'Total loss': 0.23711357904332026}
2022-12-31 11:55:01,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:01,386 INFO:     Epoch: 61
2022-12-31 11:55:02,953 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4174244344234467, 'Total loss': 0.4174244344234467} | train loss {'Reaction outcome loss': 0.24343842491780446, 'Total loss': 0.24343842491780446}
2022-12-31 11:55:02,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:02,953 INFO:     Epoch: 62
2022-12-31 11:55:04,545 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4037541627883911, 'Total loss': 0.4037541627883911} | train loss {'Reaction outcome loss': 0.23727755844183676, 'Total loss': 0.23727755844183676}
2022-12-31 11:55:04,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:04,545 INFO:     Epoch: 63
2022-12-31 11:55:06,168 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3679921487967173, 'Total loss': 0.3679921487967173} | train loss {'Reaction outcome loss': 0.23260063021665528, 'Total loss': 0.23260063021665528}
2022-12-31 11:55:06,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:06,168 INFO:     Epoch: 64
2022-12-31 11:55:07,759 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3812825803955396, 'Total loss': 0.3812825803955396} | train loss {'Reaction outcome loss': 0.2306787894813569, 'Total loss': 0.2306787894813569}
2022-12-31 11:55:07,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:07,760 INFO:     Epoch: 65
2022-12-31 11:55:09,404 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43248812556266786, 'Total loss': 0.43248812556266786} | train loss {'Reaction outcome loss': 0.2328622285140194, 'Total loss': 0.2328622285140194}
2022-12-31 11:55:09,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:09,404 INFO:     Epoch: 66
2022-12-31 11:55:11,010 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3590972164024909, 'Total loss': 0.3590972164024909} | train loss {'Reaction outcome loss': 0.2295110322698787, 'Total loss': 0.2295110322698787}
2022-12-31 11:55:11,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:11,011 INFO:     Epoch: 67
2022-12-31 11:55:12,603 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40046339531739555, 'Total loss': 0.40046339531739555} | train loss {'Reaction outcome loss': 0.22496226738333266, 'Total loss': 0.22496226738333266}
2022-12-31 11:55:12,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:12,603 INFO:     Epoch: 68
2022-12-31 11:55:14,212 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3854521572589874, 'Total loss': 0.3854521572589874} | train loss {'Reaction outcome loss': 0.2344157115552888, 'Total loss': 0.2344157115552888}
2022-12-31 11:55:14,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:14,213 INFO:     Epoch: 69
2022-12-31 11:55:15,823 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3829708188772202, 'Total loss': 0.3829708188772202} | train loss {'Reaction outcome loss': 0.22912663738533254, 'Total loss': 0.22912663738533254}
2022-12-31 11:55:15,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:15,823 INFO:     Epoch: 70
2022-12-31 11:55:17,446 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.412597252925237, 'Total loss': 0.412597252925237} | train loss {'Reaction outcome loss': 0.23783460303359824, 'Total loss': 0.23783460303359824}
2022-12-31 11:55:17,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:17,447 INFO:     Epoch: 71
2022-12-31 11:55:19,081 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45593351672093074, 'Total loss': 0.45593351672093074} | train loss {'Reaction outcome loss': 0.21784174571925904, 'Total loss': 0.21784174571925904}
2022-12-31 11:55:19,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:19,082 INFO:     Epoch: 72
2022-12-31 11:55:20,668 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42389214237531025, 'Total loss': 0.42389214237531025} | train loss {'Reaction outcome loss': 0.22266577813951743, 'Total loss': 0.22266577813951743}
2022-12-31 11:55:20,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:20,668 INFO:     Epoch: 73
2022-12-31 11:55:22,262 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4068185370415449, 'Total loss': 0.4068185370415449} | train loss {'Reaction outcome loss': 0.22131404013888084, 'Total loss': 0.22131404013888084}
2022-12-31 11:55:22,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:22,262 INFO:     Epoch: 74
2022-12-31 11:55:23,855 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4377958834171295, 'Total loss': 0.4377958834171295} | train loss {'Reaction outcome loss': 0.22736473349792943, 'Total loss': 0.22736473349792943}
2022-12-31 11:55:23,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:23,855 INFO:     Epoch: 75
2022-12-31 11:55:25,437 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38214613844950995, 'Total loss': 0.38214613844950995} | train loss {'Reaction outcome loss': 0.21512840117153886, 'Total loss': 0.21512840117153886}
2022-12-31 11:55:25,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:25,437 INFO:     Epoch: 76
2022-12-31 11:55:27,030 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.380427148938179, 'Total loss': 0.380427148938179} | train loss {'Reaction outcome loss': 0.21218906389378803, 'Total loss': 0.21218906389378803}
2022-12-31 11:55:27,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:27,031 INFO:     Epoch: 77
2022-12-31 11:55:28,624 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37872804775834085, 'Total loss': 0.37872804775834085} | train loss {'Reaction outcome loss': 0.2167279066785747, 'Total loss': 0.2167279066785747}
2022-12-31 11:55:28,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:28,625 INFO:     Epoch: 78
2022-12-31 11:55:30,197 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3993941883246104, 'Total loss': 0.3993941883246104} | train loss {'Reaction outcome loss': 0.21651816761527115, 'Total loss': 0.21651816761527115}
2022-12-31 11:55:30,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:30,197 INFO:     Epoch: 79
2022-12-31 11:55:31,802 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4024646629889806, 'Total loss': 0.4024646629889806} | train loss {'Reaction outcome loss': 0.2162256579583463, 'Total loss': 0.2162256579583463}
2022-12-31 11:55:31,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:31,803 INFO:     Epoch: 80
2022-12-31 11:55:33,415 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3935883412758509, 'Total loss': 0.3935883412758509} | train loss {'Reaction outcome loss': 0.21781239061677768, 'Total loss': 0.21781239061677768}
2022-12-31 11:55:33,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:33,415 INFO:     Epoch: 81
2022-12-31 11:55:35,004 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3858546555042267, 'Total loss': 0.3858546555042267} | train loss {'Reaction outcome loss': 0.20951563364147266, 'Total loss': 0.20951563364147266}
2022-12-31 11:55:35,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:35,004 INFO:     Epoch: 82
2022-12-31 11:55:36,640 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41520776847998303, 'Total loss': 0.41520776847998303} | train loss {'Reaction outcome loss': 0.21359903029688113, 'Total loss': 0.21359903029688113}
2022-12-31 11:55:36,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:36,640 INFO:     Epoch: 83
2022-12-31 11:55:38,251 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.388347398241361, 'Total loss': 0.388347398241361} | train loss {'Reaction outcome loss': 0.21880470577204403, 'Total loss': 0.21880470577204403}
2022-12-31 11:55:38,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:38,251 INFO:     Epoch: 84
2022-12-31 11:55:39,879 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36817725136255225, 'Total loss': 0.36817725136255225} | train loss {'Reaction outcome loss': 0.21364358748776682, 'Total loss': 0.21364358748776682}
2022-12-31 11:55:39,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:39,879 INFO:     Epoch: 85
2022-12-31 11:55:41,512 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4302590678135554, 'Total loss': 0.4302590678135554} | train loss {'Reaction outcome loss': 0.21242346220236996, 'Total loss': 0.21242346220236996}
2022-12-31 11:55:41,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:41,513 INFO:     Epoch: 86
2022-12-31 11:55:43,137 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43259825706481936, 'Total loss': 0.43259825706481936} | train loss {'Reaction outcome loss': 0.21258538852926795, 'Total loss': 0.21258538852926795}
2022-12-31 11:55:43,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:43,138 INFO:     Epoch: 87
2022-12-31 11:55:44,274 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39142063856124876, 'Total loss': 0.39142063856124876} | train loss {'Reaction outcome loss': 0.20105829972077857, 'Total loss': 0.20105829972077857}
2022-12-31 11:55:44,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:44,275 INFO:     Epoch: 88
2022-12-31 11:55:45,361 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39992024153470995, 'Total loss': 0.39992024153470995} | train loss {'Reaction outcome loss': 0.21009717625139396, 'Total loss': 0.21009717625139396}
2022-12-31 11:55:45,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:45,362 INFO:     Epoch: 89
2022-12-31 11:55:46,453 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4042832707365354, 'Total loss': 0.4042832707365354} | train loss {'Reaction outcome loss': 0.20272957785532641, 'Total loss': 0.20272957785532641}
2022-12-31 11:55:46,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:46,454 INFO:     Epoch: 90
2022-12-31 11:55:47,536 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4046854148308436, 'Total loss': 0.4046854148308436} | train loss {'Reaction outcome loss': 0.20560596815750495, 'Total loss': 0.20560596815750495}
2022-12-31 11:55:47,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:47,536 INFO:     Epoch: 91
2022-12-31 11:55:49,047 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43268218686183296, 'Total loss': 0.43268218686183296} | train loss {'Reaction outcome loss': 0.20569193966331936, 'Total loss': 0.20569193966331936}
2022-12-31 11:55:49,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:49,047 INFO:     Epoch: 92
2022-12-31 11:55:50,680 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4312463422616323, 'Total loss': 0.4312463422616323} | train loss {'Reaction outcome loss': 0.20541092256704965, 'Total loss': 0.20541092256704965}
2022-12-31 11:55:50,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:50,681 INFO:     Epoch: 93
2022-12-31 11:55:52,300 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.391596881300211, 'Total loss': 0.391596881300211} | train loss {'Reaction outcome loss': 0.20616235810881242, 'Total loss': 0.20616235810881242}
2022-12-31 11:55:52,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:52,300 INFO:     Epoch: 94
2022-12-31 11:55:53,931 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41705204248428346, 'Total loss': 0.41705204248428346} | train loss {'Reaction outcome loss': 0.20700058290537024, 'Total loss': 0.20700058290537024}
2022-12-31 11:55:53,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:53,931 INFO:     Epoch: 95
2022-12-31 11:55:55,538 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4010978559652964, 'Total loss': 0.4010978559652964} | train loss {'Reaction outcome loss': 0.20190936676311844, 'Total loss': 0.20190936676311844}
2022-12-31 11:55:55,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:55,538 INFO:     Epoch: 96
2022-12-31 11:55:57,153 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37682091891765596, 'Total loss': 0.37682091891765596} | train loss {'Reaction outcome loss': 0.20247160418866536, 'Total loss': 0.20247160418866536}
2022-12-31 11:55:57,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:57,154 INFO:     Epoch: 97
2022-12-31 11:55:58,786 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39691182374954226, 'Total loss': 0.39691182374954226} | train loss {'Reaction outcome loss': 0.20145015912505734, 'Total loss': 0.20145015912505734}
2022-12-31 11:55:58,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:55:58,787 INFO:     Epoch: 98
2022-12-31 11:56:00,423 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3829023478552699, 'Total loss': 0.3829023478552699} | train loss {'Reaction outcome loss': 0.20627056219147674, 'Total loss': 0.20627056219147674}
2022-12-31 11:56:00,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:00,423 INFO:     Epoch: 99
2022-12-31 11:56:02,055 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4021917392810186, 'Total loss': 0.4021917392810186} | train loss {'Reaction outcome loss': 0.19845847975148823, 'Total loss': 0.19845847975148823}
2022-12-31 11:56:02,056 INFO:     Best model found after epoch 40 of 100.
2022-12-31 11:56:02,056 INFO:   Done with stage: TRAINING
2022-12-31 11:56:02,056 INFO:   Starting stage: EVALUATION
2022-12-31 11:56:02,196 INFO:   Done with stage: EVALUATION
2022-12-31 11:56:02,196 INFO:   Leaving out SEQ value Fold_4
2022-12-31 11:56:02,209 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 11:56:02,209 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:56:02,864 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:56:02,865 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:56:02,933 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:56:02,934 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:56:02,934 INFO:     No hyperparam tuning for this model
2022-12-31 11:56:02,934 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:56:02,934 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:56:02,934 INFO:     None feature selector for col prot
2022-12-31 11:56:02,935 INFO:     None feature selector for col prot
2022-12-31 11:56:02,935 INFO:     None feature selector for col prot
2022-12-31 11:56:02,935 INFO:     None feature selector for col chem
2022-12-31 11:56:02,935 INFO:     None feature selector for col chem
2022-12-31 11:56:02,935 INFO:     None feature selector for col chem
2022-12-31 11:56:02,935 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:56:02,935 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:56:02,937 INFO:     Number of params in model 223921
2022-12-31 11:56:02,940 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:56:02,940 INFO:   Starting stage: TRAINING
2022-12-31 11:56:02,982 INFO:     Val loss before train {'Reaction outcome loss': 1.0063842296600343, 'Total loss': 1.0063842296600343}
2022-12-31 11:56:02,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:02,982 INFO:     Epoch: 0
2022-12-31 11:56:04,583 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.66786381204923, 'Total loss': 0.66786381204923} | train loss {'Reaction outcome loss': 0.8061714873847549, 'Total loss': 0.8061714873847549}
2022-12-31 11:56:04,583 INFO:     Found new best model at epoch 0
2022-12-31 11:56:04,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:04,584 INFO:     Epoch: 1
2022-12-31 11:56:06,191 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5519719779491424, 'Total loss': 0.5519719779491424} | train loss {'Reaction outcome loss': 0.5887199993167973, 'Total loss': 0.5887199993167973}
2022-12-31 11:56:06,191 INFO:     Found new best model at epoch 1
2022-12-31 11:56:06,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:06,192 INFO:     Epoch: 2
2022-12-31 11:56:07,807 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.526821517944336, 'Total loss': 0.526821517944336} | train loss {'Reaction outcome loss': 0.5256832970931642, 'Total loss': 0.5256832970931642}
2022-12-31 11:56:07,807 INFO:     Found new best model at epoch 2
2022-12-31 11:56:07,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:07,808 INFO:     Epoch: 3
2022-12-31 11:56:09,423 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5334783633550008, 'Total loss': 0.5334783633550008} | train loss {'Reaction outcome loss': 0.5065598318400366, 'Total loss': 0.5065598318400366}
2022-12-31 11:56:09,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:09,423 INFO:     Epoch: 4
2022-12-31 11:56:11,039 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5157587071259816, 'Total loss': 0.5157587071259816} | train loss {'Reaction outcome loss': 0.49081449560310003, 'Total loss': 0.49081449560310003}
2022-12-31 11:56:11,039 INFO:     Found new best model at epoch 4
2022-12-31 11:56:11,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:11,041 INFO:     Epoch: 5
2022-12-31 11:56:12,633 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4978529344002406, 'Total loss': 0.4978529344002406} | train loss {'Reaction outcome loss': 0.4729537830456069, 'Total loss': 0.4729537830456069}
2022-12-31 11:56:12,633 INFO:     Found new best model at epoch 5
2022-12-31 11:56:12,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:12,634 INFO:     Epoch: 6
2022-12-31 11:56:14,264 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.520399421453476, 'Total loss': 0.520399421453476} | train loss {'Reaction outcome loss': 0.47029082369503133, 'Total loss': 0.47029082369503133}
2022-12-31 11:56:14,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:14,265 INFO:     Epoch: 7
2022-12-31 11:56:15,888 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5056946257750193, 'Total loss': 0.5056946257750193} | train loss {'Reaction outcome loss': 0.46200658528920974, 'Total loss': 0.46200658528920974}
2022-12-31 11:56:15,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:15,888 INFO:     Epoch: 8
2022-12-31 11:56:17,518 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46963490049044293, 'Total loss': 0.46963490049044293} | train loss {'Reaction outcome loss': 0.45512775458153404, 'Total loss': 0.45512775458153404}
2022-12-31 11:56:17,518 INFO:     Found new best model at epoch 8
2022-12-31 11:56:17,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:17,519 INFO:     Epoch: 9
2022-12-31 11:56:19,129 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48562953571478523, 'Total loss': 0.48562953571478523} | train loss {'Reaction outcome loss': 0.44549167166978443, 'Total loss': 0.44549167166978443}
2022-12-31 11:56:19,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:19,129 INFO:     Epoch: 10
2022-12-31 11:56:20,744 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4672002116839091, 'Total loss': 0.4672002116839091} | train loss {'Reaction outcome loss': 0.4367634148911879, 'Total loss': 0.4367634148911879}
2022-12-31 11:56:20,745 INFO:     Found new best model at epoch 10
2022-12-31 11:56:20,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:20,746 INFO:     Epoch: 11
2022-12-31 11:56:22,339 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46705060253540676, 'Total loss': 0.46705060253540676} | train loss {'Reaction outcome loss': 0.43260177832755803, 'Total loss': 0.43260177832755803}
2022-12-31 11:56:22,339 INFO:     Found new best model at epoch 11
2022-12-31 11:56:22,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:22,340 INFO:     Epoch: 12
2022-12-31 11:56:23,936 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4865765005350113, 'Total loss': 0.4865765005350113} | train loss {'Reaction outcome loss': 0.43061330952153737, 'Total loss': 0.43061330952153737}
2022-12-31 11:56:23,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:23,936 INFO:     Epoch: 13
2022-12-31 11:56:25,586 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4668389101823171, 'Total loss': 0.4668389101823171} | train loss {'Reaction outcome loss': 0.4222761048844575, 'Total loss': 0.4222761048844575}
2022-12-31 11:56:25,586 INFO:     Found new best model at epoch 13
2022-12-31 11:56:25,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:25,588 INFO:     Epoch: 14
2022-12-31 11:56:27,233 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47000362823406855, 'Total loss': 0.47000362823406855} | train loss {'Reaction outcome loss': 0.41946845455935716, 'Total loss': 0.41946845455935716}
2022-12-31 11:56:27,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:27,233 INFO:     Epoch: 15
2022-12-31 11:56:28,876 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47187471787134805, 'Total loss': 0.47187471787134805} | train loss {'Reaction outcome loss': 0.4051050075635798, 'Total loss': 0.4051050075635798}
2022-12-31 11:56:28,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:28,876 INFO:     Epoch: 16
2022-12-31 11:56:30,487 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45392654339472455, 'Total loss': 0.45392654339472455} | train loss {'Reaction outcome loss': 0.4048173090288355, 'Total loss': 0.4048173090288355}
2022-12-31 11:56:30,487 INFO:     Found new best model at epoch 16
2022-12-31 11:56:30,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:30,488 INFO:     Epoch: 17
2022-12-31 11:56:32,113 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4603076716264089, 'Total loss': 0.4603076716264089} | train loss {'Reaction outcome loss': 0.39706349838188837, 'Total loss': 0.39706349838188837}
2022-12-31 11:56:32,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:32,113 INFO:     Epoch: 18
2022-12-31 11:56:33,718 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4494183291991552, 'Total loss': 0.4494183291991552} | train loss {'Reaction outcome loss': 0.3928035689443888, 'Total loss': 0.3928035689443888}
2022-12-31 11:56:33,719 INFO:     Found new best model at epoch 18
2022-12-31 11:56:33,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:33,720 INFO:     Epoch: 19
2022-12-31 11:56:35,346 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44925999840100606, 'Total loss': 0.44925999840100606} | train loss {'Reaction outcome loss': 0.39200492195166403, 'Total loss': 0.39200492195166403}
2022-12-31 11:56:35,346 INFO:     Found new best model at epoch 19
2022-12-31 11:56:35,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:35,347 INFO:     Epoch: 20
2022-12-31 11:56:36,957 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4591206898291906, 'Total loss': 0.4591206898291906} | train loss {'Reaction outcome loss': 0.3914673254969748, 'Total loss': 0.3914673254969748}
2022-12-31 11:56:36,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:36,957 INFO:     Epoch: 21
2022-12-31 11:56:38,601 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45174269924561183, 'Total loss': 0.45174269924561183} | train loss {'Reaction outcome loss': 0.37550385339380604, 'Total loss': 0.37550385339380604}
2022-12-31 11:56:38,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:38,601 INFO:     Epoch: 22
2022-12-31 11:56:40,209 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47721163630485536, 'Total loss': 0.47721163630485536} | train loss {'Reaction outcome loss': 0.3677947084664868, 'Total loss': 0.3677947084664868}
2022-12-31 11:56:40,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:40,210 INFO:     Epoch: 23
2022-12-31 11:56:41,823 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47650039990743004, 'Total loss': 0.47650039990743004} | train loss {'Reaction outcome loss': 0.3669236562204705, 'Total loss': 0.3669236562204705}
2022-12-31 11:56:41,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:41,823 INFO:     Epoch: 24
2022-12-31 11:56:43,424 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4569693684577942, 'Total loss': 0.4569693684577942} | train loss {'Reaction outcome loss': 0.3622585304000748, 'Total loss': 0.3622585304000748}
2022-12-31 11:56:43,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:43,424 INFO:     Epoch: 25
2022-12-31 11:56:45,030 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4412057677904765, 'Total loss': 0.4412057677904765} | train loss {'Reaction outcome loss': 0.3587384567417823, 'Total loss': 0.3587384567417823}
2022-12-31 11:56:45,030 INFO:     Found new best model at epoch 25
2022-12-31 11:56:45,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:45,031 INFO:     Epoch: 26
2022-12-31 11:56:46,640 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43591522177060443, 'Total loss': 0.43591522177060443} | train loss {'Reaction outcome loss': 0.3520084228164883, 'Total loss': 0.3520084228164883}
2022-12-31 11:56:46,640 INFO:     Found new best model at epoch 26
2022-12-31 11:56:46,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:46,641 INFO:     Epoch: 27
2022-12-31 11:56:48,239 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42305007576942444, 'Total loss': 0.42305007576942444} | train loss {'Reaction outcome loss': 0.3464405465642468, 'Total loss': 0.3464405465642468}
2022-12-31 11:56:48,240 INFO:     Found new best model at epoch 27
2022-12-31 11:56:48,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:48,241 INFO:     Epoch: 28
2022-12-31 11:56:49,855 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4131118605534236, 'Total loss': 0.4131118605534236} | train loss {'Reaction outcome loss': 0.34216388288064986, 'Total loss': 0.34216388288064986}
2022-12-31 11:56:49,856 INFO:     Found new best model at epoch 28
2022-12-31 11:56:49,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:49,857 INFO:     Epoch: 29
2022-12-31 11:56:51,456 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43014610310395557, 'Total loss': 0.43014610310395557} | train loss {'Reaction outcome loss': 0.34683899153763637, 'Total loss': 0.34683899153763637}
2022-12-31 11:56:51,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:51,456 INFO:     Epoch: 30
2022-12-31 11:56:53,069 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.437396631638209, 'Total loss': 0.437396631638209} | train loss {'Reaction outcome loss': 0.3359459081012419, 'Total loss': 0.3359459081012419}
2022-12-31 11:56:53,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:53,069 INFO:     Epoch: 31
2022-12-31 11:56:54,682 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44274126887321474, 'Total loss': 0.44274126887321474} | train loss {'Reaction outcome loss': 0.32937086190665243, 'Total loss': 0.32937086190665243}
2022-12-31 11:56:54,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:54,682 INFO:     Epoch: 32
2022-12-31 11:56:56,295 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44567191004753115, 'Total loss': 0.44567191004753115} | train loss {'Reaction outcome loss': 0.33111985419147283, 'Total loss': 0.33111985419147283}
2022-12-31 11:56:56,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:56,296 INFO:     Epoch: 33
2022-12-31 11:56:57,899 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4378670394420624, 'Total loss': 0.4378670394420624} | train loss {'Reaction outcome loss': 0.3145291833240633, 'Total loss': 0.3145291833240633}
2022-12-31 11:56:57,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:57,899 INFO:     Epoch: 34
2022-12-31 11:56:59,541 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.417276664574941, 'Total loss': 0.417276664574941} | train loss {'Reaction outcome loss': 0.3084919599123595, 'Total loss': 0.3084919599123595}
2022-12-31 11:56:59,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:56:59,541 INFO:     Epoch: 35
2022-12-31 11:57:01,162 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4400330742200216, 'Total loss': 0.4400330742200216} | train loss {'Reaction outcome loss': 0.3026439429728133, 'Total loss': 0.3026439429728133}
2022-12-31 11:57:01,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:01,162 INFO:     Epoch: 36
2022-12-31 11:57:02,786 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3980566014846166, 'Total loss': 0.3980566014846166} | train loss {'Reaction outcome loss': 0.3067706085418751, 'Total loss': 0.3067706085418751}
2022-12-31 11:57:02,786 INFO:     Found new best model at epoch 36
2022-12-31 11:57:02,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:02,787 INFO:     Epoch: 37
2022-12-31 11:57:04,397 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45662325620651245, 'Total loss': 0.45662325620651245} | train loss {'Reaction outcome loss': 0.3021733958260677, 'Total loss': 0.3021733958260677}
2022-12-31 11:57:04,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:04,397 INFO:     Epoch: 38
2022-12-31 11:57:06,007 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45691967805226646, 'Total loss': 0.45691967805226646} | train loss {'Reaction outcome loss': 0.301077903561052, 'Total loss': 0.301077903561052}
2022-12-31 11:57:06,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:06,008 INFO:     Epoch: 39
2022-12-31 11:57:07,600 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42053092022736865, 'Total loss': 0.42053092022736865} | train loss {'Reaction outcome loss': 0.29448805631067776, 'Total loss': 0.29448805631067776}
2022-12-31 11:57:07,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:07,600 INFO:     Epoch: 40
2022-12-31 11:57:09,202 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.446303653717041, 'Total loss': 0.446303653717041} | train loss {'Reaction outcome loss': 0.2955640485032801, 'Total loss': 0.2955640485032801}
2022-12-31 11:57:09,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:09,203 INFO:     Epoch: 41
2022-12-31 11:57:10,804 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4355565051237742, 'Total loss': 0.4355565051237742} | train loss {'Reaction outcome loss': 0.2917337023824561, 'Total loss': 0.2917337023824561}
2022-12-31 11:57:10,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:10,805 INFO:     Epoch: 42
2022-12-31 11:57:12,421 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4242666323979696, 'Total loss': 0.4242666323979696} | train loss {'Reaction outcome loss': 0.2833100653485486, 'Total loss': 0.2833100653485486}
2022-12-31 11:57:12,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:12,421 INFO:     Epoch: 43
2022-12-31 11:57:14,034 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43421918849150337, 'Total loss': 0.43421918849150337} | train loss {'Reaction outcome loss': 0.2798795550658169, 'Total loss': 0.2798795550658169}
2022-12-31 11:57:14,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:14,034 INFO:     Epoch: 44
2022-12-31 11:57:15,626 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43792153199513756, 'Total loss': 0.43792153199513756} | train loss {'Reaction outcome loss': 0.28138057069873124, 'Total loss': 0.28138057069873124}
2022-12-31 11:57:15,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:15,627 INFO:     Epoch: 45
2022-12-31 11:57:17,267 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4127544085184733, 'Total loss': 0.4127544085184733} | train loss {'Reaction outcome loss': 0.2846168336535834, 'Total loss': 0.2846168336535834}
2022-12-31 11:57:17,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:17,267 INFO:     Epoch: 46
2022-12-31 11:57:18,895 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40106236437956494, 'Total loss': 0.40106236437956494} | train loss {'Reaction outcome loss': 0.2811577271818039, 'Total loss': 0.2811577271818039}
2022-12-31 11:57:18,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:18,895 INFO:     Epoch: 47
2022-12-31 11:57:20,560 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3974957416454951, 'Total loss': 0.3974957416454951} | train loss {'Reaction outcome loss': 0.2657059606581604, 'Total loss': 0.2657059606581604}
2022-12-31 11:57:20,560 INFO:     Found new best model at epoch 47
2022-12-31 11:57:20,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:20,561 INFO:     Epoch: 48
2022-12-31 11:57:22,216 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41376804411411283, 'Total loss': 0.41376804411411283} | train loss {'Reaction outcome loss': 0.26426249942893587, 'Total loss': 0.26426249942893587}
2022-12-31 11:57:22,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:22,216 INFO:     Epoch: 49
2022-12-31 11:57:23,882 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4148018608490626, 'Total loss': 0.4148018608490626} | train loss {'Reaction outcome loss': 0.2635410551976964, 'Total loss': 0.2635410551976964}
2022-12-31 11:57:23,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:23,882 INFO:     Epoch: 50
2022-12-31 11:57:25,524 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.386570272843043, 'Total loss': 0.386570272843043} | train loss {'Reaction outcome loss': 0.2630789547163442, 'Total loss': 0.2630789547163442}
2022-12-31 11:57:25,526 INFO:     Found new best model at epoch 50
2022-12-31 11:57:25,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:25,527 INFO:     Epoch: 51
2022-12-31 11:57:27,185 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42436170975367227, 'Total loss': 0.42436170975367227} | train loss {'Reaction outcome loss': 0.25713405053430516, 'Total loss': 0.25713405053430516}
2022-12-31 11:57:27,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:27,185 INFO:     Epoch: 52
2022-12-31 11:57:28,798 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41184513916571935, 'Total loss': 0.41184513916571935} | train loss {'Reaction outcome loss': 0.26115815699208084, 'Total loss': 0.26115815699208084}
2022-12-31 11:57:28,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:28,798 INFO:     Epoch: 53
2022-12-31 11:57:30,419 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3760958880186081, 'Total loss': 0.3760958880186081} | train loss {'Reaction outcome loss': 0.2605774285614706, 'Total loss': 0.2605774285614706}
2022-12-31 11:57:30,419 INFO:     Found new best model at epoch 53
2022-12-31 11:57:30,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:30,420 INFO:     Epoch: 54
2022-12-31 11:57:32,040 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3959352771441142, 'Total loss': 0.3959352771441142} | train loss {'Reaction outcome loss': 0.25534251759951726, 'Total loss': 0.25534251759951726}
2022-12-31 11:57:32,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:32,041 INFO:     Epoch: 55
2022-12-31 11:57:33,650 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4433724383513133, 'Total loss': 0.4433724383513133} | train loss {'Reaction outcome loss': 0.2436343006493813, 'Total loss': 0.2436343006493813}
2022-12-31 11:57:33,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:33,650 INFO:     Epoch: 56
2022-12-31 11:57:35,258 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45085385044415793, 'Total loss': 0.45085385044415793} | train loss {'Reaction outcome loss': 0.2519073095542483, 'Total loss': 0.2519073095542483}
2022-12-31 11:57:35,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:35,258 INFO:     Epoch: 57
2022-12-31 11:57:36,862 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4042821988463402, 'Total loss': 0.4042821988463402} | train loss {'Reaction outcome loss': 0.24861739106503206, 'Total loss': 0.24861739106503206}
2022-12-31 11:57:36,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:36,863 INFO:     Epoch: 58
2022-12-31 11:57:38,535 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4353187461694082, 'Total loss': 0.4353187461694082} | train loss {'Reaction outcome loss': 0.25134595565578566, 'Total loss': 0.25134595565578566}
2022-12-31 11:57:38,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:38,536 INFO:     Epoch: 59
2022-12-31 11:57:40,183 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3935428281625112, 'Total loss': 0.3935428281625112} | train loss {'Reaction outcome loss': 0.2538871753369105, 'Total loss': 0.2538871753369105}
2022-12-31 11:57:40,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:40,183 INFO:     Epoch: 60
2022-12-31 11:57:41,808 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4318895866473516, 'Total loss': 0.4318895866473516} | train loss {'Reaction outcome loss': 0.24105251214672083, 'Total loss': 0.24105251214672083}
2022-12-31 11:57:41,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:41,808 INFO:     Epoch: 61
2022-12-31 11:57:43,410 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4259589980045954, 'Total loss': 0.4259589980045954} | train loss {'Reaction outcome loss': 0.23945631956957308, 'Total loss': 0.23945631956957308}
2022-12-31 11:57:43,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:43,411 INFO:     Epoch: 62
2022-12-31 11:57:45,034 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41050050059954324, 'Total loss': 0.41050050059954324} | train loss {'Reaction outcome loss': 0.24167997250165318, 'Total loss': 0.24167997250165318}
2022-12-31 11:57:45,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:45,034 INFO:     Epoch: 63
2022-12-31 11:57:46,646 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3926020761330922, 'Total loss': 0.3926020761330922} | train loss {'Reaction outcome loss': 0.23474674632214682, 'Total loss': 0.23474674632214682}
2022-12-31 11:57:46,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:46,646 INFO:     Epoch: 64
2022-12-31 11:57:48,269 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.402116126815478, 'Total loss': 0.402116126815478} | train loss {'Reaction outcome loss': 0.24452264892065137, 'Total loss': 0.24452264892065137}
2022-12-31 11:57:48,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:48,269 INFO:     Epoch: 65
2022-12-31 11:57:49,891 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42556935648123423, 'Total loss': 0.42556935648123423} | train loss {'Reaction outcome loss': 0.23701390260931388, 'Total loss': 0.23701390260931388}
2022-12-31 11:57:49,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:49,891 INFO:     Epoch: 66
2022-12-31 11:57:51,513 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3823907067378362, 'Total loss': 0.3823907067378362} | train loss {'Reaction outcome loss': 0.24188823312090624, 'Total loss': 0.24188823312090624}
2022-12-31 11:57:51,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:51,513 INFO:     Epoch: 67
2022-12-31 11:57:53,122 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4184951066970825, 'Total loss': 0.4184951066970825} | train loss {'Reaction outcome loss': 0.23155913935026107, 'Total loss': 0.23155913935026107}
2022-12-31 11:57:53,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:53,122 INFO:     Epoch: 68
2022-12-31 11:57:54,728 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3987612009048462, 'Total loss': 0.3987612009048462} | train loss {'Reaction outcome loss': 0.23032391127804125, 'Total loss': 0.23032391127804125}
2022-12-31 11:57:54,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:54,728 INFO:     Epoch: 69
2022-12-31 11:57:56,350 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3771722473204136, 'Total loss': 0.3771722473204136} | train loss {'Reaction outcome loss': 0.22782390067750583, 'Total loss': 0.22782390067750583}
2022-12-31 11:57:56,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:56,351 INFO:     Epoch: 70
2022-12-31 11:57:57,973 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40230155090490977, 'Total loss': 0.40230155090490977} | train loss {'Reaction outcome loss': 0.23110679583455895, 'Total loss': 0.23110679583455895}
2022-12-31 11:57:57,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:57,973 INFO:     Epoch: 71
2022-12-31 11:57:59,604 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3864928960800171, 'Total loss': 0.3864928960800171} | train loss {'Reaction outcome loss': 0.22478582580247725, 'Total loss': 0.22478582580247725}
2022-12-31 11:57:59,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:57:59,604 INFO:     Epoch: 72
2022-12-31 11:58:01,238 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38625740110874174, 'Total loss': 0.38625740110874174} | train loss {'Reaction outcome loss': 0.22742506347273878, 'Total loss': 0.22742506347273878}
2022-12-31 11:58:01,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:01,238 INFO:     Epoch: 73
2022-12-31 11:58:02,892 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3875945101181666, 'Total loss': 0.3875945101181666} | train loss {'Reaction outcome loss': 0.22235216641469122, 'Total loss': 0.22235216641469122}
2022-12-31 11:58:02,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:02,893 INFO:     Epoch: 74
2022-12-31 11:58:04,502 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3970074941714605, 'Total loss': 0.3970074941714605} | train loss {'Reaction outcome loss': 0.2263617330375346, 'Total loss': 0.2263617330375346}
2022-12-31 11:58:04,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:04,502 INFO:     Epoch: 75
2022-12-31 11:58:06,124 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3885152970751127, 'Total loss': 0.3885152970751127} | train loss {'Reaction outcome loss': 0.2255140308236925, 'Total loss': 0.2255140308236925}
2022-12-31 11:58:06,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:06,125 INFO:     Epoch: 76
2022-12-31 11:58:07,747 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.422744615872701, 'Total loss': 0.422744615872701} | train loss {'Reaction outcome loss': 0.21981475075928744, 'Total loss': 0.21981475075928744}
2022-12-31 11:58:07,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:07,747 INFO:     Epoch: 77
2022-12-31 11:58:09,370 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36592758297920225, 'Total loss': 0.36592758297920225} | train loss {'Reaction outcome loss': 0.2242177091269932, 'Total loss': 0.2242177091269932}
2022-12-31 11:58:09,370 INFO:     Found new best model at epoch 77
2022-12-31 11:58:09,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:09,371 INFO:     Epoch: 78
2022-12-31 11:58:10,969 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4258877704540888, 'Total loss': 0.4258877704540888} | train loss {'Reaction outcome loss': 0.21920191371537717, 'Total loss': 0.21920191371537717}
2022-12-31 11:58:10,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:10,969 INFO:     Epoch: 79
2022-12-31 11:58:12,571 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43910005887349446, 'Total loss': 0.43910005887349446} | train loss {'Reaction outcome loss': 0.22191632276784212, 'Total loss': 0.22191632276784212}
2022-12-31 11:58:12,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:12,571 INFO:     Epoch: 80
2022-12-31 11:58:14,237 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41469390988349913, 'Total loss': 0.41469390988349913} | train loss {'Reaction outcome loss': 0.21473635707575062, 'Total loss': 0.21473635707575062}
2022-12-31 11:58:14,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:14,237 INFO:     Epoch: 81
2022-12-31 11:58:15,860 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3914748946825663, 'Total loss': 0.3914748946825663} | train loss {'Reaction outcome loss': 0.22000429465263974, 'Total loss': 0.22000429465263974}
2022-12-31 11:58:15,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:15,861 INFO:     Epoch: 82
2022-12-31 11:58:17,493 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36701870361963906, 'Total loss': 0.36701870361963906} | train loss {'Reaction outcome loss': 0.21364965599151295, 'Total loss': 0.21364965599151295}
2022-12-31 11:58:17,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:17,493 INFO:     Epoch: 83
2022-12-31 11:58:19,134 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3837459077437719, 'Total loss': 0.3837459077437719} | train loss {'Reaction outcome loss': 0.210296017571692, 'Total loss': 0.210296017571692}
2022-12-31 11:58:19,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:19,134 INFO:     Epoch: 84
2022-12-31 11:58:20,746 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39567444920539857, 'Total loss': 0.39567444920539857} | train loss {'Reaction outcome loss': 0.21813708947910945, 'Total loss': 0.21813708947910945}
2022-12-31 11:58:20,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:20,746 INFO:     Epoch: 85
2022-12-31 11:58:22,362 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3659279497961203, 'Total loss': 0.3659279497961203} | train loss {'Reaction outcome loss': 0.20417790202296168, 'Total loss': 0.20417790202296168}
2022-12-31 11:58:22,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:22,363 INFO:     Epoch: 86
2022-12-31 11:58:24,018 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39966916739940644, 'Total loss': 0.39966916739940644} | train loss {'Reaction outcome loss': 0.21375099716149942, 'Total loss': 0.21375099716149942}
2022-12-31 11:58:24,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:24,019 INFO:     Epoch: 87
2022-12-31 11:58:25,663 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3733545253674189, 'Total loss': 0.3733545253674189} | train loss {'Reaction outcome loss': 0.2097986905300983, 'Total loss': 0.2097986905300983}
2022-12-31 11:58:25,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:25,663 INFO:     Epoch: 88
2022-12-31 11:58:27,331 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.380156135559082, 'Total loss': 0.380156135559082} | train loss {'Reaction outcome loss': 0.20923748768408806, 'Total loss': 0.20923748768408806}
2022-12-31 11:58:27,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:27,332 INFO:     Epoch: 89
2022-12-31 11:58:28,962 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3829340482751528, 'Total loss': 0.3829340482751528} | train loss {'Reaction outcome loss': 0.20685747903284182, 'Total loss': 0.20685747903284182}
2022-12-31 11:58:28,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:28,962 INFO:     Epoch: 90
2022-12-31 11:58:30,577 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3945261259873708, 'Total loss': 0.3945261259873708} | train loss {'Reaction outcome loss': 0.20440511322422256, 'Total loss': 0.20440511322422256}
2022-12-31 11:58:30,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:30,577 INFO:     Epoch: 91
2022-12-31 11:58:32,202 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3913286526997884, 'Total loss': 0.3913286526997884} | train loss {'Reaction outcome loss': 0.20410215912137974, 'Total loss': 0.20410215912137974}
2022-12-31 11:58:32,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:32,203 INFO:     Epoch: 92
2022-12-31 11:58:33,820 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41491652627786, 'Total loss': 0.41491652627786} | train loss {'Reaction outcome loss': 0.20138586981605322, 'Total loss': 0.20138586981605322}
2022-12-31 11:58:33,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:33,820 INFO:     Epoch: 93
2022-12-31 11:58:35,438 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4557374139626821, 'Total loss': 0.4557374139626821} | train loss {'Reaction outcome loss': 0.20726633055088536, 'Total loss': 0.20726633055088536}
2022-12-31 11:58:35,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:35,438 INFO:     Epoch: 94
2022-12-31 11:58:37,056 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4537254472573598, 'Total loss': 0.4537254472573598} | train loss {'Reaction outcome loss': 0.20889640524344594, 'Total loss': 0.20889640524344594}
2022-12-31 11:58:37,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:37,057 INFO:     Epoch: 95
2022-12-31 11:58:38,692 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38141185641288755, 'Total loss': 0.38141185641288755} | train loss {'Reaction outcome loss': 0.2101028668038574, 'Total loss': 0.2101028668038574}
2022-12-31 11:58:38,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:38,693 INFO:     Epoch: 96
2022-12-31 11:58:40,299 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42007282078266145, 'Total loss': 0.42007282078266145} | train loss {'Reaction outcome loss': 0.200274017118321, 'Total loss': 0.200274017118321}
2022-12-31 11:58:40,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:40,299 INFO:     Epoch: 97
2022-12-31 11:58:41,918 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36995838160316147, 'Total loss': 0.36995838160316147} | train loss {'Reaction outcome loss': 0.20253888661519284, 'Total loss': 0.20253888661519284}
2022-12-31 11:58:41,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:41,918 INFO:     Epoch: 98
2022-12-31 11:58:43,537 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43257539669672646, 'Total loss': 0.43257539669672646} | train loss {'Reaction outcome loss': 0.194883107197629, 'Total loss': 0.194883107197629}
2022-12-31 11:58:43,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:43,537 INFO:     Epoch: 99
2022-12-31 11:58:45,156 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41860610495011014, 'Total loss': 0.41860610495011014} | train loss {'Reaction outcome loss': 0.20396500878331894, 'Total loss': 0.20396500878331894}
2022-12-31 11:58:45,156 INFO:     Best model found after epoch 78 of 100.
2022-12-31 11:58:45,156 INFO:   Done with stage: TRAINING
2022-12-31 11:58:45,156 INFO:   Starting stage: EVALUATION
2022-12-31 11:58:45,277 INFO:   Done with stage: EVALUATION
2022-12-31 11:58:45,277 INFO:   Leaving out SEQ value Fold_5
2022-12-31 11:58:45,290 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 11:58:45,290 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:58:45,942 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:58:45,942 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:58:46,011 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:58:46,011 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:58:46,011 INFO:     No hyperparam tuning for this model
2022-12-31 11:58:46,011 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:58:46,011 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:58:46,012 INFO:     None feature selector for col prot
2022-12-31 11:58:46,012 INFO:     None feature selector for col prot
2022-12-31 11:58:46,012 INFO:     None feature selector for col prot
2022-12-31 11:58:46,013 INFO:     None feature selector for col chem
2022-12-31 11:58:46,013 INFO:     None feature selector for col chem
2022-12-31 11:58:46,013 INFO:     None feature selector for col chem
2022-12-31 11:58:46,013 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:58:46,013 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:58:46,015 INFO:     Number of params in model 223921
2022-12-31 11:58:46,018 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:58:46,018 INFO:   Starting stage: TRAINING
2022-12-31 11:58:46,063 INFO:     Val loss before train {'Reaction outcome loss': 0.9886361519495647, 'Total loss': 0.9886361519495647}
2022-12-31 11:58:46,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:46,063 INFO:     Epoch: 0
2022-12-31 11:58:47,666 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.644554607073466, 'Total loss': 0.644554607073466} | train loss {'Reaction outcome loss': 0.8262896963835623, 'Total loss': 0.8262896963835623}
2022-12-31 11:58:47,666 INFO:     Found new best model at epoch 0
2022-12-31 11:58:47,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:47,667 INFO:     Epoch: 1
2022-12-31 11:58:49,272 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5239170710245769, 'Total loss': 0.5239170710245769} | train loss {'Reaction outcome loss': 0.6110430967721698, 'Total loss': 0.6110430967721698}
2022-12-31 11:58:49,272 INFO:     Found new best model at epoch 1
2022-12-31 11:58:49,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:49,273 INFO:     Epoch: 2
2022-12-31 11:58:50,892 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4739818572998047, 'Total loss': 0.4739818572998047} | train loss {'Reaction outcome loss': 0.5425106516168436, 'Total loss': 0.5425106516168436}
2022-12-31 11:58:50,893 INFO:     Found new best model at epoch 2
2022-12-31 11:58:50,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:50,894 INFO:     Epoch: 3
2022-12-31 11:58:52,511 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4632680892944336, 'Total loss': 0.4632680892944336} | train loss {'Reaction outcome loss': 0.5085486442065842, 'Total loss': 0.5085486442065842}
2022-12-31 11:58:52,512 INFO:     Found new best model at epoch 3
2022-12-31 11:58:52,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:52,512 INFO:     Epoch: 4
2022-12-31 11:58:54,132 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.480913104613622, 'Total loss': 0.480913104613622} | train loss {'Reaction outcome loss': 0.4965001943954922, 'Total loss': 0.4965001943954922}
2022-12-31 11:58:54,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:54,132 INFO:     Epoch: 5
2022-12-31 11:58:55,734 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4550778567790985, 'Total loss': 0.4550778567790985} | train loss {'Reaction outcome loss': 0.48387158282827386, 'Total loss': 0.48387158282827386}
2022-12-31 11:58:55,734 INFO:     Found new best model at epoch 5
2022-12-31 11:58:55,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:55,735 INFO:     Epoch: 6
2022-12-31 11:58:57,355 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45887656410535177, 'Total loss': 0.45887656410535177} | train loss {'Reaction outcome loss': 0.4691231338448473, 'Total loss': 0.4691231338448473}
2022-12-31 11:58:57,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:57,356 INFO:     Epoch: 7
2022-12-31 11:58:58,963 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4476578623056412, 'Total loss': 0.4476578623056412} | train loss {'Reaction outcome loss': 0.4627716994780496, 'Total loss': 0.4627716994780496}
2022-12-31 11:58:58,963 INFO:     Found new best model at epoch 7
2022-12-31 11:58:58,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:58:58,964 INFO:     Epoch: 8
2022-12-31 11:59:00,582 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4676061153411865, 'Total loss': 0.4676061153411865} | train loss {'Reaction outcome loss': 0.457424128744146, 'Total loss': 0.457424128744146}
2022-12-31 11:59:00,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:00,582 INFO:     Epoch: 9
2022-12-31 11:59:02,202 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44729793469111123, 'Total loss': 0.44729793469111123} | train loss {'Reaction outcome loss': 0.45215813966219176, 'Total loss': 0.45215813966219176}
2022-12-31 11:59:02,203 INFO:     Found new best model at epoch 9
2022-12-31 11:59:02,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:02,204 INFO:     Epoch: 10
2022-12-31 11:59:03,823 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4387539823849996, 'Total loss': 0.4387539823849996} | train loss {'Reaction outcome loss': 0.43736950095595006, 'Total loss': 0.43736950095595006}
2022-12-31 11:59:03,823 INFO:     Found new best model at epoch 10
2022-12-31 11:59:03,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:03,824 INFO:     Epoch: 11
2022-12-31 11:59:05,457 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4492697457472483, 'Total loss': 0.4492697457472483} | train loss {'Reaction outcome loss': 0.44180934760544704, 'Total loss': 0.44180934760544704}
2022-12-31 11:59:05,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:05,457 INFO:     Epoch: 12
2022-12-31 11:59:07,068 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4397473176320394, 'Total loss': 0.4397473176320394} | train loss {'Reaction outcome loss': 0.4291515301926472, 'Total loss': 0.4291515301926472}
2022-12-31 11:59:07,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:07,068 INFO:     Epoch: 13
2022-12-31 11:59:08,689 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42588550647099815, 'Total loss': 0.42588550647099815} | train loss {'Reaction outcome loss': 0.43131456091085496, 'Total loss': 0.43131456091085496}
2022-12-31 11:59:08,690 INFO:     Found new best model at epoch 13
2022-12-31 11:59:08,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:08,691 INFO:     Epoch: 14
2022-12-31 11:59:10,309 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4253348390261332, 'Total loss': 0.4253348390261332} | train loss {'Reaction outcome loss': 0.4218414960839258, 'Total loss': 0.4218414960839258}
2022-12-31 11:59:10,309 INFO:     Found new best model at epoch 14
2022-12-31 11:59:10,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:10,310 INFO:     Epoch: 15
2022-12-31 11:59:11,930 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4402220716079076, 'Total loss': 0.4402220716079076} | train loss {'Reaction outcome loss': 0.40674368910733544, 'Total loss': 0.40674368910733544}
2022-12-31 11:59:11,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:11,930 INFO:     Epoch: 16
2022-12-31 11:59:13,534 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44929739137490593, 'Total loss': 0.44929739137490593} | train loss {'Reaction outcome loss': 0.41112947256879256, 'Total loss': 0.41112947256879256}
2022-12-31 11:59:13,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:13,534 INFO:     Epoch: 17
2022-12-31 11:59:15,139 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4075422644615173, 'Total loss': 0.4075422644615173} | train loss {'Reaction outcome loss': 0.40539219394487597, 'Total loss': 0.40539219394487597}
2022-12-31 11:59:15,139 INFO:     Found new best model at epoch 17
2022-12-31 11:59:15,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:15,140 INFO:     Epoch: 18
2022-12-31 11:59:16,739 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43156922856966656, 'Total loss': 0.43156922856966656} | train loss {'Reaction outcome loss': 0.39518959987034435, 'Total loss': 0.39518959987034435}
2022-12-31 11:59:16,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:16,739 INFO:     Epoch: 19
2022-12-31 11:59:18,354 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4253282487392426, 'Total loss': 0.4253282487392426} | train loss {'Reaction outcome loss': 0.3914098504002774, 'Total loss': 0.3914098504002774}
2022-12-31 11:59:18,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:18,354 INFO:     Epoch: 20
2022-12-31 11:59:20,027 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4098631113767624, 'Total loss': 0.4098631113767624} | train loss {'Reaction outcome loss': 0.3828826719888281, 'Total loss': 0.3828826719888281}
2022-12-31 11:59:20,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:20,027 INFO:     Epoch: 21
2022-12-31 11:59:21,667 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41330343782901763, 'Total loss': 0.41330343782901763} | train loss {'Reaction outcome loss': 0.3802777747169729, 'Total loss': 0.3802777747169729}
2022-12-31 11:59:21,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:21,668 INFO:     Epoch: 22
2022-12-31 11:59:23,289 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44325089553991953, 'Total loss': 0.44325089553991953} | train loss {'Reaction outcome loss': 0.3706233090173036, 'Total loss': 0.3706233090173036}
2022-12-31 11:59:23,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:23,289 INFO:     Epoch: 23
2022-12-31 11:59:24,894 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.401580082376798, 'Total loss': 0.401580082376798} | train loss {'Reaction outcome loss': 0.36974222839739346, 'Total loss': 0.36974222839739346}
2022-12-31 11:59:24,894 INFO:     Found new best model at epoch 23
2022-12-31 11:59:24,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:24,895 INFO:     Epoch: 24
2022-12-31 11:59:26,513 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4033604383468628, 'Total loss': 0.4033604383468628} | train loss {'Reaction outcome loss': 0.3619097784591926, 'Total loss': 0.3619097784591926}
2022-12-31 11:59:26,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:26,513 INFO:     Epoch: 25
2022-12-31 11:59:28,169 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4208492706219355, 'Total loss': 0.4208492706219355} | train loss {'Reaction outcome loss': 0.3588477524286573, 'Total loss': 0.3588477524286573}
2022-12-31 11:59:28,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:28,169 INFO:     Epoch: 26
2022-12-31 11:59:29,791 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41334254046281177, 'Total loss': 0.41334254046281177} | train loss {'Reaction outcome loss': 0.3537434806327742, 'Total loss': 0.3537434806327742}
2022-12-31 11:59:29,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:29,791 INFO:     Epoch: 27
2022-12-31 11:59:31,405 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38481006224950154, 'Total loss': 0.38481006224950154} | train loss {'Reaction outcome loss': 0.3396170943814064, 'Total loss': 0.3396170943814064}
2022-12-31 11:59:31,405 INFO:     Found new best model at epoch 27
2022-12-31 11:59:31,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:31,406 INFO:     Epoch: 28
2022-12-31 11:59:33,045 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39032868643601737, 'Total loss': 0.39032868643601737} | train loss {'Reaction outcome loss': 0.3407207381128189, 'Total loss': 0.3407207381128189}
2022-12-31 11:59:33,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:33,045 INFO:     Epoch: 29
2022-12-31 11:59:34,652 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3684459020694097, 'Total loss': 0.3684459020694097} | train loss {'Reaction outcome loss': 0.33950105647048795, 'Total loss': 0.33950105647048795}
2022-12-31 11:59:34,652 INFO:     Found new best model at epoch 29
2022-12-31 11:59:34,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:34,653 INFO:     Epoch: 30
2022-12-31 11:59:36,271 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3843773846824964, 'Total loss': 0.3843773846824964} | train loss {'Reaction outcome loss': 0.3331227075537189, 'Total loss': 0.3331227075537189}
2022-12-31 11:59:36,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:36,271 INFO:     Epoch: 31
2022-12-31 11:59:37,903 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3954241385062536, 'Total loss': 0.3954241385062536} | train loss {'Reaction outcome loss': 0.32578478694392454, 'Total loss': 0.32578478694392454}
2022-12-31 11:59:37,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:37,903 INFO:     Epoch: 32
2022-12-31 11:59:39,556 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41668639381726585, 'Total loss': 0.41668639381726585} | train loss {'Reaction outcome loss': 0.3239477341086856, 'Total loss': 0.3239477341086856}
2022-12-31 11:59:39,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:39,557 INFO:     Epoch: 33
2022-12-31 11:59:41,163 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3987610459327698, 'Total loss': 0.3987610459327698} | train loss {'Reaction outcome loss': 0.3190656021398758, 'Total loss': 0.3190656021398758}
2022-12-31 11:59:41,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:41,163 INFO:     Epoch: 34
2022-12-31 11:59:42,821 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3877416332562765, 'Total loss': 0.3877416332562765} | train loss {'Reaction outcome loss': 0.31717099488749834, 'Total loss': 0.31717099488749834}
2022-12-31 11:59:42,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:42,821 INFO:     Epoch: 35
2022-12-31 11:59:44,434 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3973533789316813, 'Total loss': 0.3973533789316813} | train loss {'Reaction outcome loss': 0.3096854057606807, 'Total loss': 0.3096854057606807}
2022-12-31 11:59:44,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:44,434 INFO:     Epoch: 36
2022-12-31 11:59:46,056 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40426718990008037, 'Total loss': 0.40426718990008037} | train loss {'Reaction outcome loss': 0.31099081547789625, 'Total loss': 0.31099081547789625}
2022-12-31 11:59:46,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:46,057 INFO:     Epoch: 37
2022-12-31 11:59:47,677 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39441094199816384, 'Total loss': 0.39441094199816384} | train loss {'Reaction outcome loss': 0.299818155997927, 'Total loss': 0.299818155997927}
2022-12-31 11:59:47,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:47,678 INFO:     Epoch: 38
2022-12-31 11:59:49,302 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39242830574512483, 'Total loss': 0.39242830574512483} | train loss {'Reaction outcome loss': 0.29925432900767035, 'Total loss': 0.29925432900767035}
2022-12-31 11:59:49,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:49,302 INFO:     Epoch: 39
2022-12-31 11:59:50,921 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3780665318171183, 'Total loss': 0.3780665318171183} | train loss {'Reaction outcome loss': 0.29136071448291684, 'Total loss': 0.29136071448291684}
2022-12-31 11:59:50,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:50,921 INFO:     Epoch: 40
2022-12-31 11:59:52,521 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39019276599089303, 'Total loss': 0.39019276599089303} | train loss {'Reaction outcome loss': 0.28971464400741165, 'Total loss': 0.28971464400741165}
2022-12-31 11:59:52,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:52,522 INFO:     Epoch: 41
2022-12-31 11:59:54,146 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3994360307852427, 'Total loss': 0.3994360307852427} | train loss {'Reaction outcome loss': 0.29009213981753224, 'Total loss': 0.29009213981753224}
2022-12-31 11:59:54,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:54,146 INFO:     Epoch: 42
2022-12-31 11:59:55,770 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3914351721604665, 'Total loss': 0.3914351721604665} | train loss {'Reaction outcome loss': 0.28221978467724385, 'Total loss': 0.28221978467724385}
2022-12-31 11:59:55,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:55,770 INFO:     Epoch: 43
2022-12-31 11:59:57,392 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3818803787231445, 'Total loss': 0.3818803787231445} | train loss {'Reaction outcome loss': 0.27929176511209364, 'Total loss': 0.27929176511209364}
2022-12-31 11:59:57,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:57,393 INFO:     Epoch: 44
2022-12-31 11:59:58,995 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3863382657368978, 'Total loss': 0.3863382657368978} | train loss {'Reaction outcome loss': 0.2790668761956132, 'Total loss': 0.2790668761956132}
2022-12-31 11:59:58,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:59:58,996 INFO:     Epoch: 45
2022-12-31 12:00:00,604 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36876270969708763, 'Total loss': 0.36876270969708763} | train loss {'Reaction outcome loss': 0.27788181491330644, 'Total loss': 0.27788181491330644}
2022-12-31 12:00:00,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:00,604 INFO:     Epoch: 46
2022-12-31 12:00:02,208 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3853871027628581, 'Total loss': 0.3853871027628581} | train loss {'Reaction outcome loss': 0.26836109062528996, 'Total loss': 0.26836109062528996}
2022-12-31 12:00:02,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:02,208 INFO:     Epoch: 47
2022-12-31 12:00:03,846 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34819979667663575, 'Total loss': 0.34819979667663575} | train loss {'Reaction outcome loss': 0.27060613336061745, 'Total loss': 0.27060613336061745}
2022-12-31 12:00:03,846 INFO:     Found new best model at epoch 47
2022-12-31 12:00:03,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:03,847 INFO:     Epoch: 48
2022-12-31 12:00:05,508 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37647698918978373, 'Total loss': 0.37647698918978373} | train loss {'Reaction outcome loss': 0.26269076373226374, 'Total loss': 0.26269076373226374}
2022-12-31 12:00:05,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:05,508 INFO:     Epoch: 49
2022-12-31 12:00:07,136 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36618003497521084, 'Total loss': 0.36618003497521084} | train loss {'Reaction outcome loss': 0.2622149322679542, 'Total loss': 0.2622149322679542}
2022-12-31 12:00:07,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:07,136 INFO:     Epoch: 50
2022-12-31 12:00:08,758 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4012985686461131, 'Total loss': 0.4012985686461131} | train loss {'Reaction outcome loss': 0.26088855692625906, 'Total loss': 0.26088855692625906}
2022-12-31 12:00:08,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:08,758 INFO:     Epoch: 51
2022-12-31 12:00:10,358 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36002442240715027, 'Total loss': 0.36002442240715027} | train loss {'Reaction outcome loss': 0.2563777484860446, 'Total loss': 0.2563777484860446}
2022-12-31 12:00:10,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:10,358 INFO:     Epoch: 52
2022-12-31 12:00:11,982 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3660731335481008, 'Total loss': 0.3660731335481008} | train loss {'Reaction outcome loss': 0.2535801143503146, 'Total loss': 0.2535801143503146}
2022-12-31 12:00:11,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:11,982 INFO:     Epoch: 53
2022-12-31 12:00:13,605 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40186190903186797, 'Total loss': 0.40186190903186797} | train loss {'Reaction outcome loss': 0.2601317712895922, 'Total loss': 0.2601317712895922}
2022-12-31 12:00:13,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:13,605 INFO:     Epoch: 54
2022-12-31 12:00:15,228 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.35701689273118975, 'Total loss': 0.35701689273118975} | train loss {'Reaction outcome loss': 0.25402801232378835, 'Total loss': 0.25402801232378835}
2022-12-31 12:00:15,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:15,229 INFO:     Epoch: 55
2022-12-31 12:00:16,839 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3772116561730703, 'Total loss': 0.3772116561730703} | train loss {'Reaction outcome loss': 0.25064718045482565, 'Total loss': 0.25064718045482565}
2022-12-31 12:00:16,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:16,839 INFO:     Epoch: 56
2022-12-31 12:00:18,496 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3626305729150772, 'Total loss': 0.3626305729150772} | train loss {'Reaction outcome loss': 0.24855101730553467, 'Total loss': 0.24855101730553467}
2022-12-31 12:00:18,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:18,496 INFO:     Epoch: 57
2022-12-31 12:00:20,107 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37611711223920186, 'Total loss': 0.37611711223920186} | train loss {'Reaction outcome loss': 0.2452430217140203, 'Total loss': 0.2452430217140203}
2022-12-31 12:00:20,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:20,107 INFO:     Epoch: 58
2022-12-31 12:00:21,730 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38403667906920114, 'Total loss': 0.38403667906920114} | train loss {'Reaction outcome loss': 0.24081386044782851, 'Total loss': 0.24081386044782851}
2022-12-31 12:00:21,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:21,731 INFO:     Epoch: 59
2022-12-31 12:00:23,354 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38958740830421446, 'Total loss': 0.38958740830421446} | train loss {'Reaction outcome loss': 0.24206028104716046, 'Total loss': 0.24206028104716046}
2022-12-31 12:00:23,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:23,354 INFO:     Epoch: 60
2022-12-31 12:00:24,978 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3635442147652308, 'Total loss': 0.3635442147652308} | train loss {'Reaction outcome loss': 0.23955323775752788, 'Total loss': 0.23955323775752788}
2022-12-31 12:00:24,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:24,978 INFO:     Epoch: 61
2022-12-31 12:00:26,590 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37973071336746217, 'Total loss': 0.37973071336746217} | train loss {'Reaction outcome loss': 0.24001900720601693, 'Total loss': 0.24001900720601693}
2022-12-31 12:00:26,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:26,590 INFO:     Epoch: 62
2022-12-31 12:00:28,206 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.377540197968483, 'Total loss': 0.377540197968483} | train loss {'Reaction outcome loss': 0.24494229508597498, 'Total loss': 0.24494229508597498}
2022-12-31 12:00:28,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:28,206 INFO:     Epoch: 63
2022-12-31 12:00:29,852 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3563601583242416, 'Total loss': 0.3563601583242416} | train loss {'Reaction outcome loss': 0.23387657287480168, 'Total loss': 0.23387657287480168}
2022-12-31 12:00:29,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:29,853 INFO:     Epoch: 64
2022-12-31 12:00:31,479 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36307131946086885, 'Total loss': 0.36307131946086885} | train loss {'Reaction outcome loss': 0.2354165962914052, 'Total loss': 0.2354165962914052}
2022-12-31 12:00:31,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:31,479 INFO:     Epoch: 65
2022-12-31 12:00:33,104 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37390475571155546, 'Total loss': 0.37390475571155546} | train loss {'Reaction outcome loss': 0.2315199768527105, 'Total loss': 0.2315199768527105}
2022-12-31 12:00:33,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:33,104 INFO:     Epoch: 66
2022-12-31 12:00:34,730 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.369139297803243, 'Total loss': 0.369139297803243} | train loss {'Reaction outcome loss': 0.23069884126420917, 'Total loss': 0.23069884126420917}
2022-12-31 12:00:34,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:34,731 INFO:     Epoch: 67
2022-12-31 12:00:36,332 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36645754277706144, 'Total loss': 0.36645754277706144} | train loss {'Reaction outcome loss': 0.23095432548558453, 'Total loss': 0.23095432548558453}
2022-12-31 12:00:36,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:36,332 INFO:     Epoch: 68
2022-12-31 12:00:37,955 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34356313832104207, 'Total loss': 0.34356313832104207} | train loss {'Reaction outcome loss': 0.23086246240225078, 'Total loss': 0.23086246240225078}
2022-12-31 12:00:37,955 INFO:     Found new best model at epoch 68
2022-12-31 12:00:37,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:37,956 INFO:     Epoch: 69
2022-12-31 12:00:39,611 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3861901700496674, 'Total loss': 0.3861901700496674} | train loss {'Reaction outcome loss': 0.22654135238769252, 'Total loss': 0.22654135238769252}
2022-12-31 12:00:39,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:39,611 INFO:     Epoch: 70
2022-12-31 12:00:41,237 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3837820967038473, 'Total loss': 0.3837820967038473} | train loss {'Reaction outcome loss': 0.22633560838359357, 'Total loss': 0.22633560838359357}
2022-12-31 12:00:41,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:41,238 INFO:     Epoch: 71
2022-12-31 12:00:42,864 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38616470942894615, 'Total loss': 0.38616470942894615} | train loss {'Reaction outcome loss': 0.2265027303463823, 'Total loss': 0.2265027303463823}
2022-12-31 12:00:42,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:42,864 INFO:     Epoch: 72
2022-12-31 12:00:44,465 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4019363919893901, 'Total loss': 0.4019363919893901} | train loss {'Reaction outcome loss': 0.22395069063355347, 'Total loss': 0.22395069063355347}
2022-12-31 12:00:44,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:44,466 INFO:     Epoch: 73
2022-12-31 12:00:46,125 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3794741203387578, 'Total loss': 0.3794741203387578} | train loss {'Reaction outcome loss': 0.21733860527619128, 'Total loss': 0.21733860527619128}
2022-12-31 12:00:46,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:46,125 INFO:     Epoch: 74
2022-12-31 12:00:47,752 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3819953759511312, 'Total loss': 0.3819953759511312} | train loss {'Reaction outcome loss': 0.2275472701348983, 'Total loss': 0.2275472701348983}
2022-12-31 12:00:47,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:47,752 INFO:     Epoch: 75
2022-12-31 12:00:49,379 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39440943896770475, 'Total loss': 0.39440943896770475} | train loss {'Reaction outcome loss': 0.2190038093268226, 'Total loss': 0.2190038093268226}
2022-12-31 12:00:49,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:49,379 INFO:     Epoch: 76
2022-12-31 12:00:51,006 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38821892539660136, 'Total loss': 0.38821892539660136} | train loss {'Reaction outcome loss': 0.21929392964992714, 'Total loss': 0.21929392964992714}
2022-12-31 12:00:51,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:51,007 INFO:     Epoch: 77
2022-12-31 12:00:52,632 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3896365687251091, 'Total loss': 0.3896365687251091} | train loss {'Reaction outcome loss': 0.2119811781772853, 'Total loss': 0.2119811781772853}
2022-12-31 12:00:52,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:52,632 INFO:     Epoch: 78
2022-12-31 12:00:54,268 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4021509031454722, 'Total loss': 0.4021509031454722} | train loss {'Reaction outcome loss': 0.2161328915963857, 'Total loss': 0.2161328915963857}
2022-12-31 12:00:54,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:54,268 INFO:     Epoch: 79
2022-12-31 12:00:55,906 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36475174824396767, 'Total loss': 0.36475174824396767} | train loss {'Reaction outcome loss': 0.21559678441727204, 'Total loss': 0.21559678441727204}
2022-12-31 12:00:55,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:55,906 INFO:     Epoch: 80
2022-12-31 12:00:57,528 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3814343283573786, 'Total loss': 0.3814343283573786} | train loss {'Reaction outcome loss': 0.2155832805963307, 'Total loss': 0.2155832805963307}
2022-12-31 12:00:57,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:57,529 INFO:     Epoch: 81
2022-12-31 12:00:59,148 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38021910389264424, 'Total loss': 0.38021910389264424} | train loss {'Reaction outcome loss': 0.21227372794778554, 'Total loss': 0.21227372794778554}
2022-12-31 12:00:59,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:00:59,148 INFO:     Epoch: 82
2022-12-31 12:01:00,767 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39216207365194955, 'Total loss': 0.39216207365194955} | train loss {'Reaction outcome loss': 0.2114301108711463, 'Total loss': 0.2114301108711463}
2022-12-31 12:01:00,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:00,767 INFO:     Epoch: 83
2022-12-31 12:01:02,372 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.368010621269544, 'Total loss': 0.368010621269544} | train loss {'Reaction outcome loss': 0.2156582549483337, 'Total loss': 0.2156582549483337}
2022-12-31 12:01:02,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:02,372 INFO:     Epoch: 84
2022-12-31 12:01:03,995 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3795120803018411, 'Total loss': 0.3795120803018411} | train loss {'Reaction outcome loss': 0.20689979007312967, 'Total loss': 0.20689979007312967}
2022-12-31 12:01:03,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:03,995 INFO:     Epoch: 85
2022-12-31 12:01:05,599 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4035560597976049, 'Total loss': 0.4035560597976049} | train loss {'Reaction outcome loss': 0.20497833201762572, 'Total loss': 0.20497833201762572}
2022-12-31 12:01:05,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:05,600 INFO:     Epoch: 86
2022-12-31 12:01:07,227 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39672626157601676, 'Total loss': 0.39672626157601676} | train loss {'Reaction outcome loss': 0.20376448279468592, 'Total loss': 0.20376448279468592}
2022-12-31 12:01:07,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:07,227 INFO:     Epoch: 87
2022-12-31 12:01:08,863 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37992495596408843, 'Total loss': 0.37992495596408843} | train loss {'Reaction outcome loss': 0.20276544891324716, 'Total loss': 0.20276544891324716}
2022-12-31 12:01:08,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:08,863 INFO:     Epoch: 88
2022-12-31 12:01:10,492 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36319218774636586, 'Total loss': 0.36319218774636586} | train loss {'Reaction outcome loss': 0.20409389456149044, 'Total loss': 0.20409389456149044}
2022-12-31 12:01:10,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:10,493 INFO:     Epoch: 89
2022-12-31 12:01:12,114 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4001299818356832, 'Total loss': 0.4001299818356832} | train loss {'Reaction outcome loss': 0.20201648178675113, 'Total loss': 0.20201648178675113}
2022-12-31 12:01:12,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:12,114 INFO:     Epoch: 90
2022-12-31 12:01:13,719 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39685151825348536, 'Total loss': 0.39685151825348536} | train loss {'Reaction outcome loss': 0.20624817017506175, 'Total loss': 0.20624817017506175}
2022-12-31 12:01:13,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:13,720 INFO:     Epoch: 91
2022-12-31 12:01:15,345 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3969020555416743, 'Total loss': 0.3969020555416743} | train loss {'Reaction outcome loss': 0.20297957818941734, 'Total loss': 0.20297957818941734}
2022-12-31 12:01:15,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:15,345 INFO:     Epoch: 92
2022-12-31 12:01:17,003 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3772929713129997, 'Total loss': 0.3772929713129997} | train loss {'Reaction outcome loss': 0.1968512517880877, 'Total loss': 0.1968512517880877}
2022-12-31 12:01:17,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:17,003 INFO:     Epoch: 93
2022-12-31 12:01:18,656 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39817794859409333, 'Total loss': 0.39817794859409333} | train loss {'Reaction outcome loss': 0.203363534009306, 'Total loss': 0.203363534009306}
2022-12-31 12:01:18,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:18,656 INFO:     Epoch: 94
2022-12-31 12:01:20,282 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4113988061745962, 'Total loss': 0.4113988061745962} | train loss {'Reaction outcome loss': 0.19896991854863047, 'Total loss': 0.19896991854863047}
2022-12-31 12:01:20,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:20,282 INFO:     Epoch: 95
2022-12-31 12:01:21,883 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38033439715703327, 'Total loss': 0.38033439715703327} | train loss {'Reaction outcome loss': 0.20377189360074832, 'Total loss': 0.20377189360074832}
2022-12-31 12:01:21,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:21,883 INFO:     Epoch: 96
2022-12-31 12:01:23,490 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4255095581213633, 'Total loss': 0.4255095581213633} | train loss {'Reaction outcome loss': 0.20041111567551909, 'Total loss': 0.20041111567551909}
2022-12-31 12:01:23,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:23,490 INFO:     Epoch: 97
2022-12-31 12:01:25,117 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3414036865035693, 'Total loss': 0.3414036865035693} | train loss {'Reaction outcome loss': 0.20190599200312412, 'Total loss': 0.20190599200312412}
2022-12-31 12:01:25,117 INFO:     Found new best model at epoch 97
2022-12-31 12:01:25,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:25,118 INFO:     Epoch: 98
2022-12-31 12:01:26,744 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4034906287988027, 'Total loss': 0.4034906287988027} | train loss {'Reaction outcome loss': 0.1928114936239883, 'Total loss': 0.1928114936239883}
2022-12-31 12:01:26,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:26,745 INFO:     Epoch: 99
2022-12-31 12:01:28,399 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36890093286832176, 'Total loss': 0.36890093286832176} | train loss {'Reaction outcome loss': 0.19776492201410475, 'Total loss': 0.19776492201410475}
2022-12-31 12:01:28,399 INFO:     Best model found after epoch 98 of 100.
2022-12-31 12:01:28,399 INFO:   Done with stage: TRAINING
2022-12-31 12:01:28,399 INFO:   Starting stage: EVALUATION
2022-12-31 12:01:28,522 INFO:   Done with stage: EVALUATION
2022-12-31 12:01:28,522 INFO:   Leaving out SEQ value Fold_6
2022-12-31 12:01:28,535 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 12:01:28,535 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:01:29,187 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:01:29,187 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:01:29,257 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:01:29,257 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:01:29,257 INFO:     No hyperparam tuning for this model
2022-12-31 12:01:29,258 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:01:29,258 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:01:29,258 INFO:     None feature selector for col prot
2022-12-31 12:01:29,258 INFO:     None feature selector for col prot
2022-12-31 12:01:29,259 INFO:     None feature selector for col prot
2022-12-31 12:01:29,259 INFO:     None feature selector for col chem
2022-12-31 12:01:29,259 INFO:     None feature selector for col chem
2022-12-31 12:01:29,259 INFO:     None feature selector for col chem
2022-12-31 12:01:29,259 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:01:29,259 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:01:29,261 INFO:     Number of params in model 223921
2022-12-31 12:01:29,264 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:01:29,265 INFO:   Starting stage: TRAINING
2022-12-31 12:01:29,307 INFO:     Val loss before train {'Reaction outcome loss': 0.9483972827593485, 'Total loss': 0.9483972827593485}
2022-12-31 12:01:29,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:29,307 INFO:     Epoch: 0
2022-12-31 12:01:30,963 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6051051080226898, 'Total loss': 0.6051051080226898} | train loss {'Reaction outcome loss': 0.8172509721900582, 'Total loss': 0.8172509721900582}
2022-12-31 12:01:30,963 INFO:     Found new best model at epoch 0
2022-12-31 12:01:30,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:30,964 INFO:     Epoch: 1
2022-12-31 12:01:32,575 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.539818478624026, 'Total loss': 0.539818478624026} | train loss {'Reaction outcome loss': 0.5979891092876235, 'Total loss': 0.5979891092876235}
2022-12-31 12:01:32,575 INFO:     Found new best model at epoch 1
2022-12-31 12:01:32,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:32,576 INFO:     Epoch: 2
2022-12-31 12:01:34,224 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48419314821561177, 'Total loss': 0.48419314821561177} | train loss {'Reaction outcome loss': 0.5338424959552848, 'Total loss': 0.5338424959552848}
2022-12-31 12:01:34,225 INFO:     Found new best model at epoch 2
2022-12-31 12:01:34,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:34,226 INFO:     Epoch: 3
2022-12-31 12:01:35,879 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4895179241895676, 'Total loss': 0.4895179241895676} | train loss {'Reaction outcome loss': 0.5030859127802109, 'Total loss': 0.5030859127802109}
2022-12-31 12:01:35,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:35,879 INFO:     Epoch: 4
2022-12-31 12:01:37,519 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48098681966463724, 'Total loss': 0.48098681966463724} | train loss {'Reaction outcome loss': 0.49107652579834316, 'Total loss': 0.49107652579834316}
2022-12-31 12:01:37,519 INFO:     Found new best model at epoch 4
2022-12-31 12:01:37,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:37,520 INFO:     Epoch: 5
2022-12-31 12:01:39,167 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49140695532162987, 'Total loss': 0.49140695532162987} | train loss {'Reaction outcome loss': 0.4772392309099328, 'Total loss': 0.4772392309099328}
2022-12-31 12:01:39,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:39,167 INFO:     Epoch: 6
2022-12-31 12:01:40,838 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46620216766993205, 'Total loss': 0.46620216766993205} | train loss {'Reaction outcome loss': 0.47261180021272237, 'Total loss': 0.47261180021272237}
2022-12-31 12:01:40,838 INFO:     Found new best model at epoch 6
2022-12-31 12:01:40,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:40,839 INFO:     Epoch: 7
2022-12-31 12:01:42,531 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4754039088884989, 'Total loss': 0.4754039088884989} | train loss {'Reaction outcome loss': 0.46262780533908504, 'Total loss': 0.46262780533908504}
2022-12-31 12:01:42,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:42,532 INFO:     Epoch: 8
2022-12-31 12:01:44,224 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4222359895706177, 'Total loss': 0.4222359895706177} | train loss {'Reaction outcome loss': 0.46094875016152215, 'Total loss': 0.46094875016152215}
2022-12-31 12:01:44,224 INFO:     Found new best model at epoch 8
2022-12-31 12:01:44,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:44,226 INFO:     Epoch: 9
2022-12-31 12:01:45,931 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4513211538394292, 'Total loss': 0.4513211538394292} | train loss {'Reaction outcome loss': 0.44955763479002114, 'Total loss': 0.44955763479002114}
2022-12-31 12:01:45,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:45,931 INFO:     Epoch: 10
2022-12-31 12:01:47,641 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4302569707234701, 'Total loss': 0.4302569707234701} | train loss {'Reaction outcome loss': 0.44476133283725283, 'Total loss': 0.44476133283725283}
2022-12-31 12:01:47,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:47,642 INFO:     Epoch: 11
2022-12-31 12:01:49,313 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42216345965862273, 'Total loss': 0.42216345965862273} | train loss {'Reaction outcome loss': 0.433700945510761, 'Total loss': 0.433700945510761}
2022-12-31 12:01:49,314 INFO:     Found new best model at epoch 11
2022-12-31 12:01:49,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:49,315 INFO:     Epoch: 12
2022-12-31 12:01:50,991 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4362703780333201, 'Total loss': 0.4362703780333201} | train loss {'Reaction outcome loss': 0.4274274225377004, 'Total loss': 0.4274274225377004}
2022-12-31 12:01:50,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:50,991 INFO:     Epoch: 13
2022-12-31 12:01:52,665 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4067896684010824, 'Total loss': 0.4067896684010824} | train loss {'Reaction outcome loss': 0.4276082985614181, 'Total loss': 0.4276082985614181}
2022-12-31 12:01:52,665 INFO:     Found new best model at epoch 13
2022-12-31 12:01:52,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:52,666 INFO:     Epoch: 14
2022-12-31 12:01:54,284 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.421747961640358, 'Total loss': 0.421747961640358} | train loss {'Reaction outcome loss': 0.4164483290878444, 'Total loss': 0.4164483290878444}
2022-12-31 12:01:54,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:54,285 INFO:     Epoch: 15
2022-12-31 12:01:55,904 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4371304412682851, 'Total loss': 0.4371304412682851} | train loss {'Reaction outcome loss': 0.41892143164085566, 'Total loss': 0.41892143164085566}
2022-12-31 12:01:55,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:55,905 INFO:     Epoch: 16
2022-12-31 12:01:57,525 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41392682790756224, 'Total loss': 0.41392682790756224} | train loss {'Reaction outcome loss': 0.40828247553927804, 'Total loss': 0.40828247553927804}
2022-12-31 12:01:57,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:57,526 INFO:     Epoch: 17
2022-12-31 12:01:59,139 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40511701901753744, 'Total loss': 0.40511701901753744} | train loss {'Reaction outcome loss': 0.4002070717970817, 'Total loss': 0.4002070717970817}
2022-12-31 12:01:59,139 INFO:     Found new best model at epoch 17
2022-12-31 12:01:59,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:01:59,140 INFO:     Epoch: 18
2022-12-31 12:02:00,763 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40414074261983235, 'Total loss': 0.40414074261983235} | train loss {'Reaction outcome loss': 0.3949347069413008, 'Total loss': 0.3949347069413008}
2022-12-31 12:02:00,763 INFO:     Found new best model at epoch 18
2022-12-31 12:02:00,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:00,764 INFO:     Epoch: 19
2022-12-31 12:02:02,390 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4199755400419235, 'Total loss': 0.4199755400419235} | train loss {'Reaction outcome loss': 0.3906741692324838, 'Total loss': 0.3906741692324838}
2022-12-31 12:02:02,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:02,391 INFO:     Epoch: 20
2022-12-31 12:02:04,061 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4035175070166588, 'Total loss': 0.4035175070166588} | train loss {'Reaction outcome loss': 0.3837810251794567, 'Total loss': 0.3837810251794567}
2022-12-31 12:02:04,061 INFO:     Found new best model at epoch 20
2022-12-31 12:02:04,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:04,062 INFO:     Epoch: 21
2022-12-31 12:02:05,731 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3974190453688304, 'Total loss': 0.3974190453688304} | train loss {'Reaction outcome loss': 0.37416231642991626, 'Total loss': 0.37416231642991626}
2022-12-31 12:02:05,731 INFO:     Found new best model at epoch 21
2022-12-31 12:02:05,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:05,732 INFO:     Epoch: 22
2022-12-31 12:02:07,346 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4048801769812902, 'Total loss': 0.4048801769812902} | train loss {'Reaction outcome loss': 0.37230129082710733, 'Total loss': 0.37230129082710733}
2022-12-31 12:02:07,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:07,346 INFO:     Epoch: 23
2022-12-31 12:02:08,977 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38446526825428007, 'Total loss': 0.38446526825428007} | train loss {'Reaction outcome loss': 0.36594128272486076, 'Total loss': 0.36594128272486076}
2022-12-31 12:02:08,977 INFO:     Found new best model at epoch 23
2022-12-31 12:02:08,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:08,978 INFO:     Epoch: 24
2022-12-31 12:02:10,599 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4119808614253998, 'Total loss': 0.4119808614253998} | train loss {'Reaction outcome loss': 0.360238553034915, 'Total loss': 0.360238553034915}
2022-12-31 12:02:10,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:10,599 INFO:     Epoch: 25
2022-12-31 12:02:12,221 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3758160094420115, 'Total loss': 0.3758160094420115} | train loss {'Reaction outcome loss': 0.35764937917785955, 'Total loss': 0.35764937917785955}
2022-12-31 12:02:12,221 INFO:     Found new best model at epoch 25
2022-12-31 12:02:12,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:12,222 INFO:     Epoch: 26
2022-12-31 12:02:13,844 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38208088278770447, 'Total loss': 0.38208088278770447} | train loss {'Reaction outcome loss': 0.3508143728793958, 'Total loss': 0.3508143728793958}
2022-12-31 12:02:13,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:13,844 INFO:     Epoch: 27
2022-12-31 12:02:15,452 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4007411648829778, 'Total loss': 0.4007411648829778} | train loss {'Reaction outcome loss': 0.34272971639026373, 'Total loss': 0.34272971639026373}
2022-12-31 12:02:15,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:15,452 INFO:     Epoch: 28
2022-12-31 12:02:17,084 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40952671070893604, 'Total loss': 0.40952671070893604} | train loss {'Reaction outcome loss': 0.33509095976068654, 'Total loss': 0.33509095976068654}
2022-12-31 12:02:17,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:17,084 INFO:     Epoch: 29
2022-12-31 12:02:18,722 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.416742080450058, 'Total loss': 0.416742080450058} | train loss {'Reaction outcome loss': 0.33756376041724795, 'Total loss': 0.33756376041724795}
2022-12-31 12:02:18,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:18,723 INFO:     Epoch: 30
2022-12-31 12:02:20,332 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41739745140075685, 'Total loss': 0.41739745140075685} | train loss {'Reaction outcome loss': 0.3296928313234653, 'Total loss': 0.3296928313234653}
2022-12-31 12:02:20,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:20,333 INFO:     Epoch: 31
2022-12-31 12:02:22,007 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41176685492197673, 'Total loss': 0.41176685492197673} | train loss {'Reaction outcome loss': 0.32356261604529424, 'Total loss': 0.32356261604529424}
2022-12-31 12:02:22,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:22,008 INFO:     Epoch: 32
2022-12-31 12:02:23,678 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3868353654940923, 'Total loss': 0.3868353654940923} | train loss {'Reaction outcome loss': 0.3213135493576311, 'Total loss': 0.3213135493576311}
2022-12-31 12:02:23,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:23,678 INFO:     Epoch: 33
2022-12-31 12:02:25,308 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3804036766290665, 'Total loss': 0.3804036766290665} | train loss {'Reaction outcome loss': 0.3157393658257994, 'Total loss': 0.3157393658257994}
2022-12-31 12:02:25,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:25,309 INFO:     Epoch: 34
2022-12-31 12:02:26,937 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3808112919330597, 'Total loss': 0.3808112919330597} | train loss {'Reaction outcome loss': 0.31433304208280377, 'Total loss': 0.31433304208280377}
2022-12-31 12:02:26,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:26,937 INFO:     Epoch: 35
2022-12-31 12:02:28,561 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40128899812698365, 'Total loss': 0.40128899812698365} | train loss {'Reaction outcome loss': 0.3066493133318338, 'Total loss': 0.3066493133318338}
2022-12-31 12:02:28,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:28,561 INFO:     Epoch: 36
2022-12-31 12:02:30,184 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4056653122107188, 'Total loss': 0.4056653122107188} | train loss {'Reaction outcome loss': 0.30587038150332896, 'Total loss': 0.30587038150332896}
2022-12-31 12:02:30,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:30,185 INFO:     Epoch: 37
2022-12-31 12:02:31,805 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36975980202356973, 'Total loss': 0.36975980202356973} | train loss {'Reaction outcome loss': 0.3012149395010962, 'Total loss': 0.3012149395010962}
2022-12-31 12:02:31,806 INFO:     Found new best model at epoch 37
2022-12-31 12:02:31,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:31,807 INFO:     Epoch: 38
2022-12-31 12:02:33,425 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39726139008998873, 'Total loss': 0.39726139008998873} | train loss {'Reaction outcome loss': 0.29802471049641016, 'Total loss': 0.29802471049641016}
2022-12-31 12:02:33,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:33,425 INFO:     Epoch: 39
2022-12-31 12:02:35,025 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3746513615051905, 'Total loss': 0.3746513615051905} | train loss {'Reaction outcome loss': 0.2931940716553466, 'Total loss': 0.2931940716553466}
2022-12-31 12:02:35,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:35,025 INFO:     Epoch: 40
2022-12-31 12:02:36,622 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4060033619403839, 'Total loss': 0.4060033619403839} | train loss {'Reaction outcome loss': 0.29510084839557915, 'Total loss': 0.29510084839557915}
2022-12-31 12:02:36,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:36,622 INFO:     Epoch: 41
2022-12-31 12:02:38,238 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38105874359607694, 'Total loss': 0.38105874359607694} | train loss {'Reaction outcome loss': 0.2884543759459193, 'Total loss': 0.2884543759459193}
2022-12-31 12:02:38,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:38,239 INFO:     Epoch: 42
2022-12-31 12:02:39,867 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.406551589568456, 'Total loss': 0.406551589568456} | train loss {'Reaction outcome loss': 0.2820423554346665, 'Total loss': 0.2820423554346665}
2022-12-31 12:02:39,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:39,867 INFO:     Epoch: 43
2022-12-31 12:02:41,515 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40368363658587136, 'Total loss': 0.40368363658587136} | train loss {'Reaction outcome loss': 0.28101280276471957, 'Total loss': 0.28101280276471957}
2022-12-31 12:02:41,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:41,515 INFO:     Epoch: 44
2022-12-31 12:02:43,133 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42102676729361216, 'Total loss': 0.42102676729361216} | train loss {'Reaction outcome loss': 0.2831967636431813, 'Total loss': 0.2831967636431813}
2022-12-31 12:02:43,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:43,133 INFO:     Epoch: 45
2022-12-31 12:02:44,746 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3821333905061086, 'Total loss': 0.3821333905061086} | train loss {'Reaction outcome loss': 0.2776239689452984, 'Total loss': 0.2776239689452984}
2022-12-31 12:02:44,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:44,747 INFO:     Epoch: 46
2022-12-31 12:02:46,386 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36210457384586336, 'Total loss': 0.36210457384586336} | train loss {'Reaction outcome loss': 0.28026506390812594, 'Total loss': 0.28026506390812594}
2022-12-31 12:02:46,386 INFO:     Found new best model at epoch 46
2022-12-31 12:02:46,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:46,387 INFO:     Epoch: 47
2022-12-31 12:02:48,032 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3924837609132131, 'Total loss': 0.3924837609132131} | train loss {'Reaction outcome loss': 0.27287981829972474, 'Total loss': 0.27287981829972474}
2022-12-31 12:02:48,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:48,032 INFO:     Epoch: 48
2022-12-31 12:02:49,675 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3983656053741773, 'Total loss': 0.3983656053741773} | train loss {'Reaction outcome loss': 0.26662469288125795, 'Total loss': 0.26662469288125795}
2022-12-31 12:02:49,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:49,676 INFO:     Epoch: 49
2022-12-31 12:02:51,320 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38212130864461263, 'Total loss': 0.38212130864461263} | train loss {'Reaction outcome loss': 0.2722215901804745, 'Total loss': 0.2722215901804745}
2022-12-31 12:02:51,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:51,321 INFO:     Epoch: 50
2022-12-31 12:02:52,951 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3588196794191996, 'Total loss': 0.3588196794191996} | train loss {'Reaction outcome loss': 0.26776302506346994, 'Total loss': 0.26776302506346994}
2022-12-31 12:02:52,952 INFO:     Found new best model at epoch 50
2022-12-31 12:02:52,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:52,953 INFO:     Epoch: 51
2022-12-31 12:02:54,591 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3835158109664917, 'Total loss': 0.3835158109664917} | train loss {'Reaction outcome loss': 0.26412623222339027, 'Total loss': 0.26412623222339027}
2022-12-31 12:02:54,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:54,592 INFO:     Epoch: 52
2022-12-31 12:02:56,240 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3944875160853068, 'Total loss': 0.3944875160853068} | train loss {'Reaction outcome loss': 0.2562114059360234, 'Total loss': 0.2562114059360234}
2022-12-31 12:02:56,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:56,240 INFO:     Epoch: 53
2022-12-31 12:02:57,899 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4000560402870178, 'Total loss': 0.4000560402870178} | train loss {'Reaction outcome loss': 0.25790140136323253, 'Total loss': 0.25790140136323253}
2022-12-31 12:02:57,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:57,900 INFO:     Epoch: 54
2022-12-31 12:02:59,553 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.418646510442098, 'Total loss': 0.418646510442098} | train loss {'Reaction outcome loss': 0.2630768449647547, 'Total loss': 0.2630768449647547}
2022-12-31 12:02:59,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:02:59,553 INFO:     Epoch: 55
2022-12-31 12:03:01,194 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3984617600838343, 'Total loss': 0.3984617600838343} | train loss {'Reaction outcome loss': 0.254856111313677, 'Total loss': 0.254856111313677}
2022-12-31 12:03:01,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:01,195 INFO:     Epoch: 56
2022-12-31 12:03:02,818 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36715023467938107, 'Total loss': 0.36715023467938107} | train loss {'Reaction outcome loss': 0.2520126549372389, 'Total loss': 0.2520126549372389}
2022-12-31 12:03:02,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:02,819 INFO:     Epoch: 57
2022-12-31 12:03:04,436 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3710154434045156, 'Total loss': 0.3710154434045156} | train loss {'Reaction outcome loss': 0.24962259133746478, 'Total loss': 0.24962259133746478}
2022-12-31 12:03:04,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:04,436 INFO:     Epoch: 58
2022-12-31 12:03:06,094 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3840686947107315, 'Total loss': 0.3840686947107315} | train loss {'Reaction outcome loss': 0.24919622982532755, 'Total loss': 0.24919622982532755}
2022-12-31 12:03:06,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:06,094 INFO:     Epoch: 59
2022-12-31 12:03:07,749 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4127157151699066, 'Total loss': 0.4127157151699066} | train loss {'Reaction outcome loss': 0.2504373434998283, 'Total loss': 0.2504373434998283}
2022-12-31 12:03:07,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:07,750 INFO:     Epoch: 60
2022-12-31 12:03:09,396 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36449644565582273, 'Total loss': 0.36449644565582273} | train loss {'Reaction outcome loss': 0.2519031033753703, 'Total loss': 0.2519031033753703}
2022-12-31 12:03:09,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:09,397 INFO:     Epoch: 61
2022-12-31 12:03:11,016 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38676983217398325, 'Total loss': 0.38676983217398325} | train loss {'Reaction outcome loss': 0.24361407152958725, 'Total loss': 0.24361407152958725}
2022-12-31 12:03:11,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:11,016 INFO:     Epoch: 62
2022-12-31 12:03:12,636 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4153550505638123, 'Total loss': 0.4153550505638123} | train loss {'Reaction outcome loss': 0.2475652140212188, 'Total loss': 0.2475652140212188}
2022-12-31 12:03:12,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:12,636 INFO:     Epoch: 63
2022-12-31 12:03:14,276 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39674126704533896, 'Total loss': 0.39674126704533896} | train loss {'Reaction outcome loss': 0.2475395440006299, 'Total loss': 0.2475395440006299}
2022-12-31 12:03:14,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:14,277 INFO:     Epoch: 64
2022-12-31 12:03:15,918 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37074232697486875, 'Total loss': 0.37074232697486875} | train loss {'Reaction outcome loss': 0.24277858224290588, 'Total loss': 0.24277858224290588}
2022-12-31 12:03:15,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:15,918 INFO:     Epoch: 65
2022-12-31 12:03:17,561 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38967133065064746, 'Total loss': 0.38967133065064746} | train loss {'Reaction outcome loss': 0.23860970768902706, 'Total loss': 0.23860970768902706}
2022-12-31 12:03:17,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:17,561 INFO:     Epoch: 66
2022-12-31 12:03:19,208 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40027556419372556, 'Total loss': 0.40027556419372556} | train loss {'Reaction outcome loss': 0.2305104958855073, 'Total loss': 0.2305104958855073}
2022-12-31 12:03:19,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:19,208 INFO:     Epoch: 67
2022-12-31 12:03:20,835 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37881228029727937, 'Total loss': 0.37881228029727937} | train loss {'Reaction outcome loss': 0.23818531955192235, 'Total loss': 0.23818531955192235}
2022-12-31 12:03:20,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:20,836 INFO:     Epoch: 68
2022-12-31 12:03:22,441 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38923788368701934, 'Total loss': 0.38923788368701934} | train loss {'Reaction outcome loss': 0.2344369578447583, 'Total loss': 0.2344369578447583}
2022-12-31 12:03:22,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:22,441 INFO:     Epoch: 69
2022-12-31 12:03:24,097 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3874726821978887, 'Total loss': 0.3874726821978887} | train loss {'Reaction outcome loss': 0.23858131337171212, 'Total loss': 0.23858131337171212}
2022-12-31 12:03:24,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:24,098 INFO:     Epoch: 70
2022-12-31 12:03:25,693 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38642417391141254, 'Total loss': 0.38642417391141254} | train loss {'Reaction outcome loss': 0.22969989295685764, 'Total loss': 0.22969989295685764}
2022-12-31 12:03:25,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:25,693 INFO:     Epoch: 71
2022-12-31 12:03:27,342 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3825780967871348, 'Total loss': 0.3825780967871348} | train loss {'Reaction outcome loss': 0.2329553488292311, 'Total loss': 0.2329553488292311}
2022-12-31 12:03:27,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:27,343 INFO:     Epoch: 72
2022-12-31 12:03:28,982 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3847952743371328, 'Total loss': 0.3847952743371328} | train loss {'Reaction outcome loss': 0.22396471853694117, 'Total loss': 0.22396471853694117}
2022-12-31 12:03:28,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:28,982 INFO:     Epoch: 73
2022-12-31 12:03:30,635 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3574352517724037, 'Total loss': 0.3574352517724037} | train loss {'Reaction outcome loss': 0.24009286941765448, 'Total loss': 0.24009286941765448}
2022-12-31 12:03:30,635 INFO:     Found new best model at epoch 73
2022-12-31 12:03:30,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:30,636 INFO:     Epoch: 74
2022-12-31 12:03:32,225 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39040347933769226, 'Total loss': 0.39040347933769226} | train loss {'Reaction outcome loss': 0.22143461439583706, 'Total loss': 0.22143461439583706}
2022-12-31 12:03:32,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:32,225 INFO:     Epoch: 75
2022-12-31 12:03:33,874 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3802192836999893, 'Total loss': 0.3802192836999893} | train loss {'Reaction outcome loss': 0.22503401934831582, 'Total loss': 0.22503401934831582}
2022-12-31 12:03:33,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:33,875 INFO:     Epoch: 76
2022-12-31 12:03:35,469 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3877644201119741, 'Total loss': 0.3877644201119741} | train loss {'Reaction outcome loss': 0.22655426748500404, 'Total loss': 0.22655426748500404}
2022-12-31 12:03:35,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:35,469 INFO:     Epoch: 77
2022-12-31 12:03:37,120 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35042112569014233, 'Total loss': 0.35042112569014233} | train loss {'Reaction outcome loss': 0.22313011614504918, 'Total loss': 0.22313011614504918}
2022-12-31 12:03:37,120 INFO:     Found new best model at epoch 77
2022-12-31 12:03:37,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:37,121 INFO:     Epoch: 78
2022-12-31 12:03:38,728 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4030994216601054, 'Total loss': 0.4030994216601054} | train loss {'Reaction outcome loss': 0.22442201732082917, 'Total loss': 0.22442201732082917}
2022-12-31 12:03:38,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:38,728 INFO:     Epoch: 79
2022-12-31 12:03:40,332 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43717159479856493, 'Total loss': 0.43717159479856493} | train loss {'Reaction outcome loss': 0.2234150299849493, 'Total loss': 0.2234150299849493}
2022-12-31 12:03:40,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:40,332 INFO:     Epoch: 80
2022-12-31 12:03:41,992 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37936954696973163, 'Total loss': 0.37936954696973163} | train loss {'Reaction outcome loss': 0.22030021684304793, 'Total loss': 0.22030021684304793}
2022-12-31 12:03:41,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:41,993 INFO:     Epoch: 81
2022-12-31 12:03:43,659 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35167111456394196, 'Total loss': 0.35167111456394196} | train loss {'Reaction outcome loss': 0.21702183905437536, 'Total loss': 0.21702183905437536}
2022-12-31 12:03:43,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:43,659 INFO:     Epoch: 82
2022-12-31 12:03:45,310 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3820802638928095, 'Total loss': 0.3820802638928095} | train loss {'Reaction outcome loss': 0.21959044333775982, 'Total loss': 0.21959044333775982}
2022-12-31 12:03:45,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:45,310 INFO:     Epoch: 83
2022-12-31 12:03:46,937 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4007541765769323, 'Total loss': 0.4007541765769323} | train loss {'Reaction outcome loss': 0.21907649660610765, 'Total loss': 0.21907649660610765}
2022-12-31 12:03:46,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:46,937 INFO:     Epoch: 84
2022-12-31 12:03:48,539 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36175096010168395, 'Total loss': 0.36175096010168395} | train loss {'Reaction outcome loss': 0.2206348287755294, 'Total loss': 0.2206348287755294}
2022-12-31 12:03:48,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:48,539 INFO:     Epoch: 85
2022-12-31 12:03:50,139 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4014484624067942, 'Total loss': 0.4014484624067942} | train loss {'Reaction outcome loss': 0.20780294704577124, 'Total loss': 0.20780294704577124}
2022-12-31 12:03:50,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:50,140 INFO:     Epoch: 86
2022-12-31 12:03:51,758 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4270379900932312, 'Total loss': 0.4270379900932312} | train loss {'Reaction outcome loss': 0.21776167826478232, 'Total loss': 0.21776167826478232}
2022-12-31 12:03:51,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:51,758 INFO:     Epoch: 87
2022-12-31 12:03:53,409 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37175089965264, 'Total loss': 0.37175089965264} | train loss {'Reaction outcome loss': 0.2115064840696564, 'Total loss': 0.2115064840696564}
2022-12-31 12:03:53,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:53,409 INFO:     Epoch: 88
2022-12-31 12:03:55,064 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37850738565127057, 'Total loss': 0.37850738565127057} | train loss {'Reaction outcome loss': 0.207367921241354, 'Total loss': 0.207367921241354}
2022-12-31 12:03:55,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:55,064 INFO:     Epoch: 89
2022-12-31 12:03:56,692 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3951859032114347, 'Total loss': 0.3951859032114347} | train loss {'Reaction outcome loss': 0.21048853495948366, 'Total loss': 0.21048853495948366}
2022-12-31 12:03:56,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:56,693 INFO:     Epoch: 90
2022-12-31 12:03:58,315 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.367339355746905, 'Total loss': 0.367339355746905} | train loss {'Reaction outcome loss': 0.20869659243104474, 'Total loss': 0.20869659243104474}
2022-12-31 12:03:58,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:58,315 INFO:     Epoch: 91
2022-12-31 12:03:59,931 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3623145322004954, 'Total loss': 0.3623145322004954} | train loss {'Reaction outcome loss': 0.21638657166773878, 'Total loss': 0.21638657166773878}
2022-12-31 12:03:59,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:03:59,931 INFO:     Epoch: 92
2022-12-31 12:04:01,547 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3704175849755605, 'Total loss': 0.3704175849755605} | train loss {'Reaction outcome loss': 0.21234494892187714, 'Total loss': 0.21234494892187714}
2022-12-31 12:04:01,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:01,547 INFO:     Epoch: 93
2022-12-31 12:04:03,187 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39671539664268496, 'Total loss': 0.39671539664268496} | train loss {'Reaction outcome loss': 0.20628092193216194, 'Total loss': 0.20628092193216194}
2022-12-31 12:04:03,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:03,187 INFO:     Epoch: 94
2022-12-31 12:04:04,796 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3901398852467537, 'Total loss': 0.3901398852467537} | train loss {'Reaction outcome loss': 0.20892885856545573, 'Total loss': 0.20892885856545573}
2022-12-31 12:04:04,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:04,797 INFO:     Epoch: 95
2022-12-31 12:04:06,428 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4340374012788137, 'Total loss': 0.4340374012788137} | train loss {'Reaction outcome loss': 0.20168399651423904, 'Total loss': 0.20168399651423904}
2022-12-31 12:04:06,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:06,428 INFO:     Epoch: 96
2022-12-31 12:04:08,028 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3926705131928126, 'Total loss': 0.3926705131928126} | train loss {'Reaction outcome loss': 0.20817670568702776, 'Total loss': 0.20817670568702776}
2022-12-31 12:04:08,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:08,028 INFO:     Epoch: 97
2022-12-31 12:04:09,681 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43405510584513346, 'Total loss': 0.43405510584513346} | train loss {'Reaction outcome loss': 0.19995132646782304, 'Total loss': 0.19995132646782304}
2022-12-31 12:04:09,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:09,682 INFO:     Epoch: 98
2022-12-31 12:04:11,352 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38003741999467217, 'Total loss': 0.38003741999467217} | train loss {'Reaction outcome loss': 0.20073108816189886, 'Total loss': 0.20073108816189886}
2022-12-31 12:04:11,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:11,353 INFO:     Epoch: 99
2022-12-31 12:04:13,002 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3785797166327635, 'Total loss': 0.3785797166327635} | train loss {'Reaction outcome loss': 0.20759803281310232, 'Total loss': 0.20759803281310232}
2022-12-31 12:04:13,002 INFO:     Best model found after epoch 78 of 100.
2022-12-31 12:04:13,002 INFO:   Done with stage: TRAINING
2022-12-31 12:04:13,003 INFO:   Starting stage: EVALUATION
2022-12-31 12:04:13,125 INFO:   Done with stage: EVALUATION
2022-12-31 12:04:13,125 INFO:   Leaving out SEQ value Fold_7
2022-12-31 12:04:13,137 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 12:04:13,138 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:04:13,783 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:04:13,783 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:04:13,850 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:04:13,850 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:04:13,850 INFO:     No hyperparam tuning for this model
2022-12-31 12:04:13,850 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:04:13,851 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:04:13,851 INFO:     None feature selector for col prot
2022-12-31 12:04:13,851 INFO:     None feature selector for col prot
2022-12-31 12:04:13,852 INFO:     None feature selector for col prot
2022-12-31 12:04:13,852 INFO:     None feature selector for col chem
2022-12-31 12:04:13,852 INFO:     None feature selector for col chem
2022-12-31 12:04:13,852 INFO:     None feature selector for col chem
2022-12-31 12:04:13,852 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:04:13,853 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:04:13,854 INFO:     Number of params in model 223921
2022-12-31 12:04:13,858 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:04:13,858 INFO:   Starting stage: TRAINING
2022-12-31 12:04:13,903 INFO:     Val loss before train {'Reaction outcome loss': 1.0393340150515238, 'Total loss': 1.0393340150515238}
2022-12-31 12:04:13,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:13,903 INFO:     Epoch: 0
2022-12-31 12:04:15,478 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6983769039312998, 'Total loss': 0.6983769039312998} | train loss {'Reaction outcome loss': 0.8007813197570842, 'Total loss': 0.8007813197570842}
2022-12-31 12:04:15,478 INFO:     Found new best model at epoch 0
2022-12-31 12:04:15,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:15,479 INFO:     Epoch: 1
2022-12-31 12:04:17,060 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5518821736176809, 'Total loss': 0.5518821736176809} | train loss {'Reaction outcome loss': 0.5990790921253163, 'Total loss': 0.5990790921253163}
2022-12-31 12:04:17,060 INFO:     Found new best model at epoch 1
2022-12-31 12:04:17,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:17,061 INFO:     Epoch: 2
2022-12-31 12:04:18,660 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5201613565286001, 'Total loss': 0.5201613565286001} | train loss {'Reaction outcome loss': 0.530881731010182, 'Total loss': 0.530881731010182}
2022-12-31 12:04:18,660 INFO:     Found new best model at epoch 2
2022-12-31 12:04:18,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:18,661 INFO:     Epoch: 3
2022-12-31 12:04:20,269 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5306705832481384, 'Total loss': 0.5306705832481384} | train loss {'Reaction outcome loss': 0.4974733573067319, 'Total loss': 0.4974733573067319}
2022-12-31 12:04:20,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:20,270 INFO:     Epoch: 4
2022-12-31 12:04:21,897 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5171036809682846, 'Total loss': 0.5171036809682846} | train loss {'Reaction outcome loss': 0.48204764096073177, 'Total loss': 0.48204764096073177}
2022-12-31 12:04:21,897 INFO:     Found new best model at epoch 4
2022-12-31 12:04:21,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:21,898 INFO:     Epoch: 5
2022-12-31 12:04:23,509 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5154753466447194, 'Total loss': 0.5154753466447194} | train loss {'Reaction outcome loss': 0.47081928037025117, 'Total loss': 0.47081928037025117}
2022-12-31 12:04:23,509 INFO:     Found new best model at epoch 5
2022-12-31 12:04:23,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:23,510 INFO:     Epoch: 6
2022-12-31 12:04:25,099 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.504196298122406, 'Total loss': 0.504196298122406} | train loss {'Reaction outcome loss': 0.46683870556153656, 'Total loss': 0.46683870556153656}
2022-12-31 12:04:25,100 INFO:     Found new best model at epoch 6
2022-12-31 12:04:25,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:25,101 INFO:     Epoch: 7
2022-12-31 12:04:26,718 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5187779664993286, 'Total loss': 0.5187779664993286} | train loss {'Reaction outcome loss': 0.45106812293603743, 'Total loss': 0.45106812293603743}
2022-12-31 12:04:26,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:26,718 INFO:     Epoch: 8
2022-12-31 12:04:28,309 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5022247155507406, 'Total loss': 0.5022247155507406} | train loss {'Reaction outcome loss': 0.44303101082861207, 'Total loss': 0.44303101082861207}
2022-12-31 12:04:28,309 INFO:     Found new best model at epoch 8
2022-12-31 12:04:28,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:28,310 INFO:     Epoch: 9
2022-12-31 12:04:29,902 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5132754802703857, 'Total loss': 0.5132754802703857} | train loss {'Reaction outcome loss': 0.4364776285467567, 'Total loss': 0.4364776285467567}
2022-12-31 12:04:29,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:29,902 INFO:     Epoch: 10
2022-12-31 12:04:31,497 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5091075142224629, 'Total loss': 0.5091075142224629} | train loss {'Reaction outcome loss': 0.43501231920369815, 'Total loss': 0.43501231920369815}
2022-12-31 12:04:31,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:31,498 INFO:     Epoch: 11
2022-12-31 12:04:33,087 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5270211040973664, 'Total loss': 0.5270211040973664} | train loss {'Reaction outcome loss': 0.4263738832085124, 'Total loss': 0.4263738832085124}
2022-12-31 12:04:33,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:33,087 INFO:     Epoch: 12
2022-12-31 12:04:34,689 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5016957779725393, 'Total loss': 0.5016957779725393} | train loss {'Reaction outcome loss': 0.4154065428199349, 'Total loss': 0.4154065428199349}
2022-12-31 12:04:34,689 INFO:     Found new best model at epoch 12
2022-12-31 12:04:34,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:34,690 INFO:     Epoch: 13
2022-12-31 12:04:36,283 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5159736275672913, 'Total loss': 0.5159736275672913} | train loss {'Reaction outcome loss': 0.4076618732058958, 'Total loss': 0.4076618732058958}
2022-12-31 12:04:36,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:36,283 INFO:     Epoch: 14
2022-12-31 12:04:37,876 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4940474311510722, 'Total loss': 0.4940474311510722} | train loss {'Reaction outcome loss': 0.4028187122318771, 'Total loss': 0.4028187122318771}
2022-12-31 12:04:37,876 INFO:     Found new best model at epoch 14
2022-12-31 12:04:37,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:37,877 INFO:     Epoch: 15
2022-12-31 12:04:39,469 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5216351191202799, 'Total loss': 0.5216351191202799} | train loss {'Reaction outcome loss': 0.40360180214866176, 'Total loss': 0.40360180214866176}
2022-12-31 12:04:39,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:39,470 INFO:     Epoch: 16
2022-12-31 12:04:41,063 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4732301414012909, 'Total loss': 0.4732301414012909} | train loss {'Reaction outcome loss': 0.3963770275532981, 'Total loss': 0.3963770275532981}
2022-12-31 12:04:41,063 INFO:     Found new best model at epoch 16
2022-12-31 12:04:41,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:41,064 INFO:     Epoch: 17
2022-12-31 12:04:42,642 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4695424556732178, 'Total loss': 0.4695424556732178} | train loss {'Reaction outcome loss': 0.38724050654487296, 'Total loss': 0.38724050654487296}
2022-12-31 12:04:42,642 INFO:     Found new best model at epoch 17
2022-12-31 12:04:42,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:42,643 INFO:     Epoch: 18
2022-12-31 12:04:44,263 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48378356695175173, 'Total loss': 0.48378356695175173} | train loss {'Reaction outcome loss': 0.38399421813942136, 'Total loss': 0.38399421813942136}
2022-12-31 12:04:44,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:44,264 INFO:     Epoch: 19
2022-12-31 12:04:45,914 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48880930145581564, 'Total loss': 0.48880930145581564} | train loss {'Reaction outcome loss': 0.37733655125448556, 'Total loss': 0.37733655125448556}
2022-12-31 12:04:45,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:45,914 INFO:     Epoch: 20
2022-12-31 12:04:47,512 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45193752845128377, 'Total loss': 0.45193752845128377} | train loss {'Reaction outcome loss': 0.37062942332182175, 'Total loss': 0.37062942332182175}
2022-12-31 12:04:47,513 INFO:     Found new best model at epoch 20
2022-12-31 12:04:47,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:47,514 INFO:     Epoch: 21
2022-12-31 12:04:49,106 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44830416043599447, 'Total loss': 0.44830416043599447} | train loss {'Reaction outcome loss': 0.36213153696213013, 'Total loss': 0.36213153696213013}
2022-12-31 12:04:49,107 INFO:     Found new best model at epoch 21
2022-12-31 12:04:49,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:49,107 INFO:     Epoch: 22
2022-12-31 12:04:50,678 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46644605894883473, 'Total loss': 0.46644605894883473} | train loss {'Reaction outcome loss': 0.36116878711533196, 'Total loss': 0.36116878711533196}
2022-12-31 12:04:50,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:50,678 INFO:     Epoch: 23
2022-12-31 12:04:52,254 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4661183108886083, 'Total loss': 0.4661183108886083} | train loss {'Reaction outcome loss': 0.3527613501081537, 'Total loss': 0.3527613501081537}
2022-12-31 12:04:52,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:52,254 INFO:     Epoch: 24
2022-12-31 12:04:53,871 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46001725594202675, 'Total loss': 0.46001725594202675} | train loss {'Reaction outcome loss': 0.35019190052708427, 'Total loss': 0.35019190052708427}
2022-12-31 12:04:53,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:53,872 INFO:     Epoch: 25
2022-12-31 12:04:55,479 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4638906240463257, 'Total loss': 0.4638906240463257} | train loss {'Reaction outcome loss': 0.3435582250302091, 'Total loss': 0.3435582250302091}
2022-12-31 12:04:55,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:55,480 INFO:     Epoch: 26
2022-12-31 12:04:57,122 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48326112230618795, 'Total loss': 0.48326112230618795} | train loss {'Reaction outcome loss': 0.3415927196760754, 'Total loss': 0.3415927196760754}
2022-12-31 12:04:57,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:57,122 INFO:     Epoch: 27
2022-12-31 12:04:58,745 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47453574538230897, 'Total loss': 0.47453574538230897} | train loss {'Reaction outcome loss': 0.33258209855128557, 'Total loss': 0.33258209855128557}
2022-12-31 12:04:58,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:04:58,746 INFO:     Epoch: 28
2022-12-31 12:05:00,320 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44603120485941566, 'Total loss': 0.44603120485941566} | train loss {'Reaction outcome loss': 0.33200131550485834, 'Total loss': 0.33200131550485834}
2022-12-31 12:05:00,320 INFO:     Found new best model at epoch 28
2022-12-31 12:05:00,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:00,321 INFO:     Epoch: 29
2022-12-31 12:05:01,899 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47930715382099154, 'Total loss': 0.47930715382099154} | train loss {'Reaction outcome loss': 0.32589077654775683, 'Total loss': 0.32589077654775683}
2022-12-31 12:05:01,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:01,900 INFO:     Epoch: 30
2022-12-31 12:05:03,494 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43321798543135326, 'Total loss': 0.43321798543135326} | train loss {'Reaction outcome loss': 0.3239412033869015, 'Total loss': 0.3239412033869015}
2022-12-31 12:05:03,494 INFO:     Found new best model at epoch 30
2022-12-31 12:05:03,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:03,495 INFO:     Epoch: 31
2022-12-31 12:05:05,085 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4495805780092875, 'Total loss': 0.4495805780092875} | train loss {'Reaction outcome loss': 0.3171907650654788, 'Total loss': 0.3171907650654788}
2022-12-31 12:05:05,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:05,085 INFO:     Epoch: 32
2022-12-31 12:05:06,673 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48492169976234434, 'Total loss': 0.48492169976234434} | train loss {'Reaction outcome loss': 0.30873345478605, 'Total loss': 0.30873345478605}
2022-12-31 12:05:06,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:06,673 INFO:     Epoch: 33
2022-12-31 12:05:08,263 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4555477579434713, 'Total loss': 0.4555477579434713} | train loss {'Reaction outcome loss': 0.3080618124960106, 'Total loss': 0.3080618124960106}
2022-12-31 12:05:08,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:08,263 INFO:     Epoch: 34
2022-12-31 12:05:09,880 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45695711572964987, 'Total loss': 0.45695711572964987} | train loss {'Reaction outcome loss': 0.29858700399911337, 'Total loss': 0.29858700399911337}
2022-12-31 12:05:09,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:09,880 INFO:     Epoch: 35
2022-12-31 12:05:11,473 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4393482486406962, 'Total loss': 0.4393482486406962} | train loss {'Reaction outcome loss': 0.29561896509603486, 'Total loss': 0.29561896509603486}
2022-12-31 12:05:11,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:11,473 INFO:     Epoch: 36
2022-12-31 12:05:13,064 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4362823764483134, 'Total loss': 0.4362823764483134} | train loss {'Reaction outcome loss': 0.29812586250213474, 'Total loss': 0.29812586250213474}
2022-12-31 12:05:13,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:13,064 INFO:     Epoch: 37
2022-12-31 12:05:14,659 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43146532674630483, 'Total loss': 0.43146532674630483} | train loss {'Reaction outcome loss': 0.2957521148926609, 'Total loss': 0.2957521148926609}
2022-12-31 12:05:14,660 INFO:     Found new best model at epoch 37
2022-12-31 12:05:14,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:14,661 INFO:     Epoch: 38
2022-12-31 12:05:16,253 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4465859830379486, 'Total loss': 0.4465859830379486} | train loss {'Reaction outcome loss': 0.29020380044540206, 'Total loss': 0.29020380044540206}
2022-12-31 12:05:16,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:16,253 INFO:     Epoch: 39
2022-12-31 12:05:17,833 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4743845482667287, 'Total loss': 0.4743845482667287} | train loss {'Reaction outcome loss': 0.2898886241087001, 'Total loss': 0.2898886241087001}
2022-12-31 12:05:17,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:17,833 INFO:     Epoch: 40
2022-12-31 12:05:19,450 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4648817221323649, 'Total loss': 0.4648817221323649} | train loss {'Reaction outcome loss': 0.29312060805440165, 'Total loss': 0.29312060805440165}
2022-12-31 12:05:19,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:19,450 INFO:     Epoch: 41
2022-12-31 12:05:21,046 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47288846770922344, 'Total loss': 0.47288846770922344} | train loss {'Reaction outcome loss': 0.285675031770935, 'Total loss': 0.285675031770935}
2022-12-31 12:05:21,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:21,046 INFO:     Epoch: 42
2022-12-31 12:05:22,641 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4681958630681038, 'Total loss': 0.4681958630681038} | train loss {'Reaction outcome loss': 0.2913447751325893, 'Total loss': 0.2913447751325893}
2022-12-31 12:05:22,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:22,642 INFO:     Epoch: 43
2022-12-31 12:05:24,235 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4188705692688624, 'Total loss': 0.4188705692688624} | train loss {'Reaction outcome loss': 0.27732472094424043, 'Total loss': 0.27732472094424043}
2022-12-31 12:05:24,235 INFO:     Found new best model at epoch 43
2022-12-31 12:05:24,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:24,236 INFO:     Epoch: 44
2022-12-31 12:05:25,825 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46464520891507466, 'Total loss': 0.46464520891507466} | train loss {'Reaction outcome loss': 0.283059204345221, 'Total loss': 0.283059204345221}
2022-12-31 12:05:25,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:25,825 INFO:     Epoch: 45
2022-12-31 12:05:27,398 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4585543155670166, 'Total loss': 0.4585543155670166} | train loss {'Reaction outcome loss': 0.27002390119291486, 'Total loss': 0.27002390119291486}
2022-12-31 12:05:27,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:27,398 INFO:     Epoch: 46
2022-12-31 12:05:28,996 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4696048309405645, 'Total loss': 0.4696048309405645} | train loss {'Reaction outcome loss': 0.27321877215917295, 'Total loss': 0.27321877215917295}
2022-12-31 12:05:28,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:28,997 INFO:     Epoch: 47
2022-12-31 12:05:30,600 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4756325344244639, 'Total loss': 0.4756325344244639} | train loss {'Reaction outcome loss': 0.26830807305026405, 'Total loss': 0.26830807305026405}
2022-12-31 12:05:30,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:30,600 INFO:     Epoch: 48
2022-12-31 12:05:32,189 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40480008025964104, 'Total loss': 0.40480008025964104} | train loss {'Reaction outcome loss': 0.2684511925083595, 'Total loss': 0.2684511925083595}
2022-12-31 12:05:32,190 INFO:     Found new best model at epoch 48
2022-12-31 12:05:32,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:32,191 INFO:     Epoch: 49
2022-12-31 12:05:33,780 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43506091038386024, 'Total loss': 0.43506091038386024} | train loss {'Reaction outcome loss': 0.26142120952189185, 'Total loss': 0.26142120952189185}
2022-12-31 12:05:33,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:33,780 INFO:     Epoch: 50
2022-12-31 12:05:35,373 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47302716275056206, 'Total loss': 0.47302716275056206} | train loss {'Reaction outcome loss': 0.2613614524404208, 'Total loss': 0.2613614524404208}
2022-12-31 12:05:35,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:35,373 INFO:     Epoch: 51
2022-12-31 12:05:36,953 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4637854263186455, 'Total loss': 0.4637854263186455} | train loss {'Reaction outcome loss': 0.263260432965917, 'Total loss': 0.263260432965917}
2022-12-31 12:05:36,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:36,953 INFO:     Epoch: 52
2022-12-31 12:05:38,534 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5089246531327566, 'Total loss': 0.5089246531327566} | train loss {'Reaction outcome loss': 0.25620611611030475, 'Total loss': 0.25620611611030475}
2022-12-31 12:05:38,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:38,535 INFO:     Epoch: 53
2022-12-31 12:05:40,127 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4403295705715815, 'Total loss': 0.4403295705715815} | train loss {'Reaction outcome loss': 0.2630124363072571, 'Total loss': 0.2630124363072571}
2022-12-31 12:05:40,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:40,128 INFO:     Epoch: 54
2022-12-31 12:05:41,723 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4866747016708056, 'Total loss': 0.4866747016708056} | train loss {'Reaction outcome loss': 0.2521626013894003, 'Total loss': 0.2521626013894003}
2022-12-31 12:05:41,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:41,723 INFO:     Epoch: 55
2022-12-31 12:05:43,316 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4593501925468445, 'Total loss': 0.4593501925468445} | train loss {'Reaction outcome loss': 0.24751482809801678, 'Total loss': 0.24751482809801678}
2022-12-31 12:05:43,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:43,316 INFO:     Epoch: 56
2022-12-31 12:05:44,891 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4630548616250356, 'Total loss': 0.4630548616250356} | train loss {'Reaction outcome loss': 0.24370851206692148, 'Total loss': 0.24370851206692148}
2022-12-31 12:05:44,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:44,892 INFO:     Epoch: 57
2022-12-31 12:05:46,475 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44327299247185387, 'Total loss': 0.44327299247185387} | train loss {'Reaction outcome loss': 0.24344444333579077, 'Total loss': 0.24344444333579077}
2022-12-31 12:05:46,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:46,476 INFO:     Epoch: 58
2022-12-31 12:05:48,107 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49688897728919984, 'Total loss': 0.49688897728919984} | train loss {'Reaction outcome loss': 0.24629033749390924, 'Total loss': 0.24629033749390924}
2022-12-31 12:05:48,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:48,107 INFO:     Epoch: 59
2022-12-31 12:05:49,749 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4450515955686569, 'Total loss': 0.4450515955686569} | train loss {'Reaction outcome loss': 0.24259404013199465, 'Total loss': 0.24259404013199465}
2022-12-31 12:05:49,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:49,749 INFO:     Epoch: 60
2022-12-31 12:05:51,350 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4393946170806885, 'Total loss': 0.4393946170806885} | train loss {'Reaction outcome loss': 0.24165947196302395, 'Total loss': 0.24165947196302395}
2022-12-31 12:05:51,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:51,351 INFO:     Epoch: 61
2022-12-31 12:05:52,946 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4608926902214686, 'Total loss': 0.4608926902214686} | train loss {'Reaction outcome loss': 0.23414494251088672, 'Total loss': 0.23414494251088672}
2022-12-31 12:05:52,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:52,946 INFO:     Epoch: 62
2022-12-31 12:05:54,555 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44399116933345795, 'Total loss': 0.44399116933345795} | train loss {'Reaction outcome loss': 0.23779522097454622, 'Total loss': 0.23779522097454622}
2022-12-31 12:05:54,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:54,555 INFO:     Epoch: 63
2022-12-31 12:05:56,134 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4570916920900345, 'Total loss': 0.4570916920900345} | train loss {'Reaction outcome loss': 0.2350424795715145, 'Total loss': 0.2350424795715145}
2022-12-31 12:05:56,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:56,134 INFO:     Epoch: 64
2022-12-31 12:05:57,731 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4804081122080485, 'Total loss': 0.4804081122080485} | train loss {'Reaction outcome loss': 0.23389468317503456, 'Total loss': 0.23389468317503456}
2022-12-31 12:05:57,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:57,731 INFO:     Epoch: 65
2022-12-31 12:05:59,328 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.413864071170489, 'Total loss': 0.413864071170489} | train loss {'Reaction outcome loss': 0.23150238471153456, 'Total loss': 0.23150238471153456}
2022-12-31 12:05:59,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:05:59,328 INFO:     Epoch: 66
2022-12-31 12:06:00,926 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47151391903559364, 'Total loss': 0.47151391903559364} | train loss {'Reaction outcome loss': 0.23754279254065766, 'Total loss': 0.23754279254065766}
2022-12-31 12:06:00,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:00,926 INFO:     Epoch: 67
2022-12-31 12:06:02,523 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45834077994028727, 'Total loss': 0.45834077994028727} | train loss {'Reaction outcome loss': 0.23483692292437885, 'Total loss': 0.23483692292437885}
2022-12-31 12:06:02,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:02,524 INFO:     Epoch: 68
2022-12-31 12:06:04,101 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4569555550813675, 'Total loss': 0.4569555550813675} | train loss {'Reaction outcome loss': 0.226395356349456, 'Total loss': 0.226395356349456}
2022-12-31 12:06:04,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:04,102 INFO:     Epoch: 69
2022-12-31 12:06:05,722 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4669113824764887, 'Total loss': 0.4669113824764887} | train loss {'Reaction outcome loss': 0.22972968920055545, 'Total loss': 0.22972968920055545}
2022-12-31 12:06:05,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:05,723 INFO:     Epoch: 70
2022-12-31 12:06:07,368 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4722145954767863, 'Total loss': 0.4722145954767863} | train loss {'Reaction outcome loss': 0.22457213188101957, 'Total loss': 0.22457213188101957}
2022-12-31 12:06:07,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:07,369 INFO:     Epoch: 71
2022-12-31 12:06:09,007 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43529363671938576, 'Total loss': 0.43529363671938576} | train loss {'Reaction outcome loss': 0.22040156088087148, 'Total loss': 0.22040156088087148}
2022-12-31 12:06:09,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:09,007 INFO:     Epoch: 72
2022-12-31 12:06:10,650 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45909128387769066, 'Total loss': 0.45909128387769066} | train loss {'Reaction outcome loss': 0.23047487014024468, 'Total loss': 0.23047487014024468}
2022-12-31 12:06:10,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:10,650 INFO:     Epoch: 73
2022-12-31 12:06:12,244 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4496345082918803, 'Total loss': 0.4496345082918803} | train loss {'Reaction outcome loss': 0.22233844506503134, 'Total loss': 0.22233844506503134}
2022-12-31 12:06:12,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:12,244 INFO:     Epoch: 74
2022-12-31 12:06:13,329 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.464277180035909, 'Total loss': 0.464277180035909} | train loss {'Reaction outcome loss': 0.22344884339160534, 'Total loss': 0.22344884339160534}
2022-12-31 12:06:13,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:13,329 INFO:     Epoch: 75
2022-12-31 12:06:14,403 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.430807767311732, 'Total loss': 0.430807767311732} | train loss {'Reaction outcome loss': 0.22007489913985842, 'Total loss': 0.22007489913985842}
2022-12-31 12:06:14,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:14,404 INFO:     Epoch: 76
2022-12-31 12:06:15,475 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43855479955673216, 'Total loss': 0.43855479955673216} | train loss {'Reaction outcome loss': 0.21393260358740668, 'Total loss': 0.21393260358740668}
2022-12-31 12:06:15,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:15,475 INFO:     Epoch: 77
2022-12-31 12:06:16,549 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4583112716674805, 'Total loss': 0.4583112716674805} | train loss {'Reaction outcome loss': 0.21116188805782315, 'Total loss': 0.21116188805782315}
2022-12-31 12:06:16,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:16,549 INFO:     Epoch: 78
2022-12-31 12:06:18,074 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41370297173659004, 'Total loss': 0.41370297173659004} | train loss {'Reaction outcome loss': 0.22861168869249113, 'Total loss': 0.22861168869249113}
2022-12-31 12:06:18,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:18,074 INFO:     Epoch: 79
2022-12-31 12:06:19,724 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4544782241185506, 'Total loss': 0.4544782241185506} | train loss {'Reaction outcome loss': 0.21654284473904323, 'Total loss': 0.21654284473904323}
2022-12-31 12:06:19,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:19,724 INFO:     Epoch: 80
2022-12-31 12:06:21,320 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44744572043418884, 'Total loss': 0.44744572043418884} | train loss {'Reaction outcome loss': 0.20721568621613168, 'Total loss': 0.20721568621613168}
2022-12-31 12:06:21,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:21,320 INFO:     Epoch: 81
2022-12-31 12:06:22,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43270029226938883, 'Total loss': 0.43270029226938883} | train loss {'Reaction outcome loss': 0.21695223049475595, 'Total loss': 0.21695223049475595}
2022-12-31 12:06:22,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:22,961 INFO:     Epoch: 82
2022-12-31 12:06:24,534 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4782967150211334, 'Total loss': 0.4782967150211334} | train loss {'Reaction outcome loss': 0.21258335281163454, 'Total loss': 0.21258335281163454}
2022-12-31 12:06:24,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:24,534 INFO:     Epoch: 83
2022-12-31 12:06:26,150 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4782901128133138, 'Total loss': 0.4782901128133138} | train loss {'Reaction outcome loss': 0.2097438515024089, 'Total loss': 0.2097438515024089}
2022-12-31 12:06:26,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:26,151 INFO:     Epoch: 84
2022-12-31 12:06:27,763 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46505800187587737, 'Total loss': 0.46505800187587737} | train loss {'Reaction outcome loss': 0.21162026394636202, 'Total loss': 0.21162026394636202}
2022-12-31 12:06:27,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:27,763 INFO:     Epoch: 85
2022-12-31 12:06:29,365 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4321161150932312, 'Total loss': 0.4321161150932312} | train loss {'Reaction outcome loss': 0.20131528535141394, 'Total loss': 0.20131528535141394}
2022-12-31 12:06:29,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:29,365 INFO:     Epoch: 86
2022-12-31 12:06:30,926 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47291794419288635, 'Total loss': 0.47291794419288635} | train loss {'Reaction outcome loss': 0.21223089876738224, 'Total loss': 0.21223089876738224}
2022-12-31 12:06:30,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:30,926 INFO:     Epoch: 87
2022-12-31 12:06:32,540 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45576447347799937, 'Total loss': 0.45576447347799937} | train loss {'Reaction outcome loss': 0.21170366345307765, 'Total loss': 0.21170366345307765}
2022-12-31 12:06:32,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:32,541 INFO:     Epoch: 88
2022-12-31 12:06:34,148 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4383766680955887, 'Total loss': 0.4383766680955887} | train loss {'Reaction outcome loss': 0.19975877282356386, 'Total loss': 0.19975877282356386}
2022-12-31 12:06:34,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:34,148 INFO:     Epoch: 89
2022-12-31 12:06:35,738 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43088463445504505, 'Total loss': 0.43088463445504505} | train loss {'Reaction outcome loss': 0.2054258135485125, 'Total loss': 0.2054258135485125}
2022-12-31 12:06:35,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:35,739 INFO:     Epoch: 90
2022-12-31 12:06:37,355 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4353151480356852, 'Total loss': 0.4353151480356852} | train loss {'Reaction outcome loss': 0.20746626307839874, 'Total loss': 0.20746626307839874}
2022-12-31 12:06:37,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:37,355 INFO:     Epoch: 91
2022-12-31 12:06:38,942 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44692613979180656, 'Total loss': 0.44692613979180656} | train loss {'Reaction outcome loss': 0.20856327757976212, 'Total loss': 0.20856327757976212}
2022-12-31 12:06:38,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:38,943 INFO:     Epoch: 92
2022-12-31 12:06:40,524 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45950628916422526, 'Total loss': 0.45950628916422526} | train loss {'Reaction outcome loss': 0.21012585046581733, 'Total loss': 0.21012585046581733}
2022-12-31 12:06:40,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:40,524 INFO:     Epoch: 93
2022-12-31 12:06:42,107 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4578373541434606, 'Total loss': 0.4578373541434606} | train loss {'Reaction outcome loss': 0.20454667749449665, 'Total loss': 0.20454667749449665}
2022-12-31 12:06:42,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:42,107 INFO:     Epoch: 94
2022-12-31 12:06:43,725 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46938432653745016, 'Total loss': 0.46938432653745016} | train loss {'Reaction outcome loss': 0.20477925349477227, 'Total loss': 0.20477925349477227}
2022-12-31 12:06:43,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:43,725 INFO:     Epoch: 95
2022-12-31 12:06:45,297 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4541095475355784, 'Total loss': 0.4541095475355784} | train loss {'Reaction outcome loss': 0.20681832721218085, 'Total loss': 0.20681832721218085}
2022-12-31 12:06:45,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:45,298 INFO:     Epoch: 96
2022-12-31 12:06:46,917 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46787814497947694, 'Total loss': 0.46787814497947694} | train loss {'Reaction outcome loss': 0.18946300788130951, 'Total loss': 0.18946300788130951}
2022-12-31 12:06:46,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:46,917 INFO:     Epoch: 97
2022-12-31 12:06:48,508 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41789750655492147, 'Total loss': 0.41789750655492147} | train loss {'Reaction outcome loss': 0.19669152203360538, 'Total loss': 0.19669152203360538}
2022-12-31 12:06:48,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:48,508 INFO:     Epoch: 98
2022-12-31 12:06:50,145 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45353869944810865, 'Total loss': 0.45353869944810865} | train loss {'Reaction outcome loss': 0.1932921032711263, 'Total loss': 0.1932921032711263}
2022-12-31 12:06:50,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:50,146 INFO:     Epoch: 99
2022-12-31 12:06:51,728 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44695667127768196, 'Total loss': 0.44695667127768196} | train loss {'Reaction outcome loss': 0.2007971159199546, 'Total loss': 0.2007971159199546}
2022-12-31 12:06:51,728 INFO:     Best model found after epoch 49 of 100.
2022-12-31 12:06:51,729 INFO:   Done with stage: TRAINING
2022-12-31 12:06:51,729 INFO:   Starting stage: EVALUATION
2022-12-31 12:06:51,870 INFO:   Done with stage: EVALUATION
2022-12-31 12:06:51,870 INFO:   Leaving out SEQ value Fold_8
2022-12-31 12:06:51,882 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 12:06:51,883 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:06:52,529 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:06:52,529 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:06:52,596 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:06:52,597 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:06:52,597 INFO:     No hyperparam tuning for this model
2022-12-31 12:06:52,597 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:06:52,597 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:06:52,598 INFO:     None feature selector for col prot
2022-12-31 12:06:52,598 INFO:     None feature selector for col prot
2022-12-31 12:06:52,598 INFO:     None feature selector for col prot
2022-12-31 12:06:52,598 INFO:     None feature selector for col chem
2022-12-31 12:06:52,599 INFO:     None feature selector for col chem
2022-12-31 12:06:52,599 INFO:     None feature selector for col chem
2022-12-31 12:06:52,599 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:06:52,599 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:06:52,601 INFO:     Number of params in model 223921
2022-12-31 12:06:52,604 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:06:52,604 INFO:   Starting stage: TRAINING
2022-12-31 12:06:52,649 INFO:     Val loss before train {'Reaction outcome loss': 0.9442236661911011, 'Total loss': 0.9442236661911011}
2022-12-31 12:06:52,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:52,649 INFO:     Epoch: 0
2022-12-31 12:06:54,282 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6608284016450247, 'Total loss': 0.6608284016450247} | train loss {'Reaction outcome loss': 0.8208277842048488, 'Total loss': 0.8208277842048488}
2022-12-31 12:06:54,282 INFO:     Found new best model at epoch 0
2022-12-31 12:06:54,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:54,283 INFO:     Epoch: 1
2022-12-31 12:06:55,913 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5507544795672099, 'Total loss': 0.5507544795672099} | train loss {'Reaction outcome loss': 0.6014230257858508, 'Total loss': 0.6014230257858508}
2022-12-31 12:06:55,913 INFO:     Found new best model at epoch 1
2022-12-31 12:06:55,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:55,915 INFO:     Epoch: 2
2022-12-31 12:06:57,543 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5004762411117554, 'Total loss': 0.5004762411117554} | train loss {'Reaction outcome loss': 0.5323964897273243, 'Total loss': 0.5323964897273243}
2022-12-31 12:06:57,544 INFO:     Found new best model at epoch 2
2022-12-31 12:06:57,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:57,545 INFO:     Epoch: 3
2022-12-31 12:06:59,184 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49105239311854043, 'Total loss': 0.49105239311854043} | train loss {'Reaction outcome loss': 0.5338301395700462, 'Total loss': 0.5338301395700462}
2022-12-31 12:06:59,184 INFO:     Found new best model at epoch 3
2022-12-31 12:06:59,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:06:59,185 INFO:     Epoch: 4
2022-12-31 12:07:00,804 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49456238746643066, 'Total loss': 0.49456238746643066} | train loss {'Reaction outcome loss': 0.4986511990503894, 'Total loss': 0.4986511990503894}
2022-12-31 12:07:00,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:00,804 INFO:     Epoch: 5
2022-12-31 12:07:02,398 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5138637522856394, 'Total loss': 0.5138637522856394} | train loss {'Reaction outcome loss': 0.4785099224712515, 'Total loss': 0.4785099224712515}
2022-12-31 12:07:02,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:02,398 INFO:     Epoch: 6
2022-12-31 12:07:04,012 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5248309175173441, 'Total loss': 0.5248309175173441} | train loss {'Reaction outcome loss': 0.47325602747445955, 'Total loss': 0.47325602747445955}
2022-12-31 12:07:04,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:04,013 INFO:     Epoch: 7
2022-12-31 12:07:05,612 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4901967406272888, 'Total loss': 0.4901967406272888} | train loss {'Reaction outcome loss': 0.46184776207783085, 'Total loss': 0.46184776207783085}
2022-12-31 12:07:05,612 INFO:     Found new best model at epoch 7
2022-12-31 12:07:05,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:05,613 INFO:     Epoch: 8
2022-12-31 12:07:07,260 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4977595806121826, 'Total loss': 0.4977595806121826} | train loss {'Reaction outcome loss': 0.45267899806723383, 'Total loss': 0.45267899806723383}
2022-12-31 12:07:07,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:07,261 INFO:     Epoch: 9
2022-12-31 12:07:08,896 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4706173916657766, 'Total loss': 0.4706173916657766} | train loss {'Reaction outcome loss': 0.449032675879805, 'Total loss': 0.449032675879805}
2022-12-31 12:07:08,896 INFO:     Found new best model at epoch 9
2022-12-31 12:07:08,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:08,897 INFO:     Epoch: 10
2022-12-31 12:07:10,508 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5021528075138728, 'Total loss': 0.5021528075138728} | train loss {'Reaction outcome loss': 0.46435703634135966, 'Total loss': 0.46435703634135966}
2022-12-31 12:07:10,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:10,509 INFO:     Epoch: 11
2022-12-31 12:07:12,129 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46535348196824394, 'Total loss': 0.46535348196824394} | train loss {'Reaction outcome loss': 0.49982267022990173, 'Total loss': 0.49982267022990173}
2022-12-31 12:07:12,130 INFO:     Found new best model at epoch 11
2022-12-31 12:07:12,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:12,131 INFO:     Epoch: 12
2022-12-31 12:07:13,785 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4717251102129618, 'Total loss': 0.4717251102129618} | train loss {'Reaction outcome loss': 0.4356698193553619, 'Total loss': 0.4356698193553619}
2022-12-31 12:07:13,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:13,787 INFO:     Epoch: 13
2022-12-31 12:07:15,402 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4809197713931402, 'Total loss': 0.4809197713931402} | train loss {'Reaction outcome loss': 0.43108889247641724, 'Total loss': 0.43108889247641724}
2022-12-31 12:07:15,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:15,402 INFO:     Epoch: 14
2022-12-31 12:07:17,028 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45611622631549836, 'Total loss': 0.45611622631549836} | train loss {'Reaction outcome loss': 0.42410454358163197, 'Total loss': 0.42410454358163197}
2022-12-31 12:07:17,028 INFO:     Found new best model at epoch 14
2022-12-31 12:07:17,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:17,029 INFO:     Epoch: 15
2022-12-31 12:07:18,644 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4689244955778122, 'Total loss': 0.4689244955778122} | train loss {'Reaction outcome loss': 0.4137526949061135, 'Total loss': 0.4137526949061135}
2022-12-31 12:07:18,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:18,645 INFO:     Epoch: 16
2022-12-31 12:07:20,249 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4543864369392395, 'Total loss': 0.4543864369392395} | train loss {'Reaction outcome loss': 0.414666106455379, 'Total loss': 0.414666106455379}
2022-12-31 12:07:20,249 INFO:     Found new best model at epoch 16
2022-12-31 12:07:20,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:20,250 INFO:     Epoch: 17
2022-12-31 12:07:21,911 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42987846036752064, 'Total loss': 0.42987846036752064} | train loss {'Reaction outcome loss': 0.40620801722009975, 'Total loss': 0.40620801722009975}
2022-12-31 12:07:21,912 INFO:     Found new best model at epoch 17
2022-12-31 12:07:21,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:21,912 INFO:     Epoch: 18
2022-12-31 12:07:23,539 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42698579331239067, 'Total loss': 0.42698579331239067} | train loss {'Reaction outcome loss': 0.40028318709464394, 'Total loss': 0.40028318709464394}
2022-12-31 12:07:23,539 INFO:     Found new best model at epoch 18
2022-12-31 12:07:23,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:23,540 INFO:     Epoch: 19
2022-12-31 12:07:25,146 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4658167282740275, 'Total loss': 0.4658167282740275} | train loss {'Reaction outcome loss': 0.39461331449422066, 'Total loss': 0.39461331449422066}
2022-12-31 12:07:25,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:25,146 INFO:     Epoch: 20
2022-12-31 12:07:26,795 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4244701494773229, 'Total loss': 0.4244701494773229} | train loss {'Reaction outcome loss': 0.39505106426456577, 'Total loss': 0.39505106426456577}
2022-12-31 12:07:26,795 INFO:     Found new best model at epoch 20
2022-12-31 12:07:26,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:26,796 INFO:     Epoch: 21
2022-12-31 12:07:28,410 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4302514255046844, 'Total loss': 0.4302514255046844} | train loss {'Reaction outcome loss': 0.3863667325130191, 'Total loss': 0.3863667325130191}
2022-12-31 12:07:28,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:28,411 INFO:     Epoch: 22
2022-12-31 12:07:30,020 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4375013420979182, 'Total loss': 0.4375013420979182} | train loss {'Reaction outcome loss': 0.3792033872884664, 'Total loss': 0.3792033872884664}
2022-12-31 12:07:30,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:30,020 INFO:     Epoch: 23
2022-12-31 12:07:31,639 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44055922627449035, 'Total loss': 0.44055922627449035} | train loss {'Reaction outcome loss': 0.37500241019702313, 'Total loss': 0.37500241019702313}
2022-12-31 12:07:31,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:31,639 INFO:     Epoch: 24
2022-12-31 12:07:33,244 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44917717774709065, 'Total loss': 0.44917717774709065} | train loss {'Reaction outcome loss': 0.3706061847687111, 'Total loss': 0.3706061847687111}
2022-12-31 12:07:33,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:33,245 INFO:     Epoch: 25
2022-12-31 12:07:34,906 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4508853902419408, 'Total loss': 0.4508853902419408} | train loss {'Reaction outcome loss': 0.36514881095828733, 'Total loss': 0.36514881095828733}
2022-12-31 12:07:34,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:34,906 INFO:     Epoch: 26
2022-12-31 12:07:36,526 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4307095448176066, 'Total loss': 0.4307095448176066} | train loss {'Reaction outcome loss': 0.3530226466735231, 'Total loss': 0.3530226466735231}
2022-12-31 12:07:36,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:36,526 INFO:     Epoch: 27
2022-12-31 12:07:38,144 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43547385931015015, 'Total loss': 0.43547385931015015} | train loss {'Reaction outcome loss': 0.3538848428676526, 'Total loss': 0.3538848428676526}
2022-12-31 12:07:38,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:38,144 INFO:     Epoch: 28
2022-12-31 12:07:39,778 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43637059032917025, 'Total loss': 0.43637059032917025} | train loss {'Reaction outcome loss': 0.35223443125901016, 'Total loss': 0.35223443125901016}
2022-12-31 12:07:39,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:39,778 INFO:     Epoch: 29
2022-12-31 12:07:41,427 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4536167566974958, 'Total loss': 0.4536167566974958} | train loss {'Reaction outcome loss': 0.34483846175203325, 'Total loss': 0.34483846175203325}
2022-12-31 12:07:41,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:41,428 INFO:     Epoch: 30
2022-12-31 12:07:43,027 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44861148794492084, 'Total loss': 0.44861148794492084} | train loss {'Reaction outcome loss': 0.3358113221082654, 'Total loss': 0.3358113221082654}
2022-12-31 12:07:43,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:43,027 INFO:     Epoch: 31
2022-12-31 12:07:44,652 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4442294895648956, 'Total loss': 0.4442294895648956} | train loss {'Reaction outcome loss': 0.3352801992960335, 'Total loss': 0.3352801992960335}
2022-12-31 12:07:44,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:44,653 INFO:     Epoch: 32
2022-12-31 12:07:46,319 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4343044062455495, 'Total loss': 0.4343044062455495} | train loss {'Reaction outcome loss': 0.33243922262951947, 'Total loss': 0.33243922262951947}
2022-12-31 12:07:46,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:46,319 INFO:     Epoch: 33
2022-12-31 12:07:47,966 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4337739119927088, 'Total loss': 0.4337739119927088} | train loss {'Reaction outcome loss': 0.3644676747026624, 'Total loss': 0.3644676747026624}
2022-12-31 12:07:47,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:47,967 INFO:     Epoch: 34
2022-12-31 12:07:49,623 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43660430759191515, 'Total loss': 0.43660430759191515} | train loss {'Reaction outcome loss': 0.3297262525293922, 'Total loss': 0.3297262525293922}
2022-12-31 12:07:49,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:49,624 INFO:     Epoch: 35
2022-12-31 12:07:51,278 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46579186817010243, 'Total loss': 0.46579186817010243} | train loss {'Reaction outcome loss': 0.33848233990695165, 'Total loss': 0.33848233990695165}
2022-12-31 12:07:51,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:51,278 INFO:     Epoch: 36
2022-12-31 12:07:52,893 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4041854341824849, 'Total loss': 0.4041854341824849} | train loss {'Reaction outcome loss': 0.32679357692815253, 'Total loss': 0.32679357692815253}
2022-12-31 12:07:52,893 INFO:     Found new best model at epoch 36
2022-12-31 12:07:52,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:52,894 INFO:     Epoch: 37
2022-12-31 12:07:54,549 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4006113092104594, 'Total loss': 0.4006113092104594} | train loss {'Reaction outcome loss': 0.32879454732306657, 'Total loss': 0.32879454732306657}
2022-12-31 12:07:54,549 INFO:     Found new best model at epoch 37
2022-12-31 12:07:54,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:54,550 INFO:     Epoch: 38
2022-12-31 12:07:56,185 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4749159783124924, 'Total loss': 0.4749159783124924} | train loss {'Reaction outcome loss': 0.3192144399103911, 'Total loss': 0.3192144399103911}
2022-12-31 12:07:56,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:56,185 INFO:     Epoch: 39
2022-12-31 12:07:57,806 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48505356709162395, 'Total loss': 0.48505356709162395} | train loss {'Reaction outcome loss': 0.4322022584303235, 'Total loss': 0.4322022584303235}
2022-12-31 12:07:57,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:57,806 INFO:     Epoch: 40
2022-12-31 12:07:59,462 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44447040756543477, 'Total loss': 0.44447040756543477} | train loss {'Reaction outcome loss': 0.3463186932376761, 'Total loss': 0.3463186932376761}
2022-12-31 12:07:59,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:07:59,462 INFO:     Epoch: 41
2022-12-31 12:08:01,082 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4448888123035431, 'Total loss': 0.4448888123035431} | train loss {'Reaction outcome loss': 0.32086709695927246, 'Total loss': 0.32086709695927246}
2022-12-31 12:08:01,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:01,082 INFO:     Epoch: 42
2022-12-31 12:08:02,754 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45222928126653034, 'Total loss': 0.45222928126653034} | train loss {'Reaction outcome loss': 0.3179499341606878, 'Total loss': 0.3179499341606878}
2022-12-31 12:08:02,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:02,754 INFO:     Epoch: 43
2022-12-31 12:08:04,380 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4361577977736791, 'Total loss': 0.4361577977736791} | train loss {'Reaction outcome loss': 0.33335364617380325, 'Total loss': 0.33335364617380325}
2022-12-31 12:08:04,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:04,380 INFO:     Epoch: 44
2022-12-31 12:08:05,989 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4126982351144155, 'Total loss': 0.4126982351144155} | train loss {'Reaction outcome loss': 0.3041161681011663, 'Total loss': 0.3041161681011663}
2022-12-31 12:08:05,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:05,990 INFO:     Epoch: 45
2022-12-31 12:08:07,645 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45231217543284097, 'Total loss': 0.45231217543284097} | train loss {'Reaction outcome loss': 0.2960471777714438, 'Total loss': 0.2960471777714438}
2022-12-31 12:08:07,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:07,645 INFO:     Epoch: 46
2022-12-31 12:08:09,277 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4196681797504425, 'Total loss': 0.4196681797504425} | train loss {'Reaction outcome loss': 0.2921437202154345, 'Total loss': 0.2921437202154345}
2022-12-31 12:08:09,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:09,278 INFO:     Epoch: 47
2022-12-31 12:08:10,909 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4129096577564875, 'Total loss': 0.4129096577564875} | train loss {'Reaction outcome loss': 0.2996657944074115, 'Total loss': 0.2996657944074115}
2022-12-31 12:08:10,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:10,910 INFO:     Epoch: 48
2022-12-31 12:08:12,579 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4460889418919881, 'Total loss': 0.4460889418919881} | train loss {'Reaction outcome loss': 0.28617698715353745, 'Total loss': 0.28617698715353745}
2022-12-31 12:08:12,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:12,580 INFO:     Epoch: 49
2022-12-31 12:08:14,229 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4406292339166005, 'Total loss': 0.4406292339166005} | train loss {'Reaction outcome loss': 0.286767386924138, 'Total loss': 0.286767386924138}
2022-12-31 12:08:14,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:14,229 INFO:     Epoch: 50
2022-12-31 12:08:15,835 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.434215738872687, 'Total loss': 0.434215738872687} | train loss {'Reaction outcome loss': 0.2812760098459955, 'Total loss': 0.2812760098459955}
2022-12-31 12:08:15,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:15,835 INFO:     Epoch: 51
2022-12-31 12:08:17,498 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41971892267465594, 'Total loss': 0.41971892267465594} | train loss {'Reaction outcome loss': 0.2823952105085271, 'Total loss': 0.2823952105085271}
2022-12-31 12:08:17,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:17,498 INFO:     Epoch: 52
2022-12-31 12:08:19,095 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41481437484423317, 'Total loss': 0.41481437484423317} | train loss {'Reaction outcome loss': 0.28032703790813684, 'Total loss': 0.28032703790813684}
2022-12-31 12:08:19,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:19,095 INFO:     Epoch: 53
2022-12-31 12:08:20,720 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4634050170580546, 'Total loss': 0.4634050170580546} | train loss {'Reaction outcome loss': 0.27687631317826017, 'Total loss': 0.27687631317826017}
2022-12-31 12:08:20,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:20,720 INFO:     Epoch: 54
2022-12-31 12:08:22,345 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4222812920808792, 'Total loss': 0.4222812920808792} | train loss {'Reaction outcome loss': 0.27391750481120136, 'Total loss': 0.27391750481120136}
2022-12-31 12:08:22,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:22,345 INFO:     Epoch: 55
2022-12-31 12:08:23,965 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4405917872985204, 'Total loss': 0.4405917872985204} | train loss {'Reaction outcome loss': 0.271517369639406, 'Total loss': 0.271517369639406}
2022-12-31 12:08:23,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:23,965 INFO:     Epoch: 56
2022-12-31 12:08:25,592 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39699861804644265, 'Total loss': 0.39699861804644265} | train loss {'Reaction outcome loss': 0.2793616860821519, 'Total loss': 0.2793616860821519}
2022-12-31 12:08:25,593 INFO:     Found new best model at epoch 56
2022-12-31 12:08:25,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:25,594 INFO:     Epoch: 57
2022-12-31 12:08:27,225 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4227964371442795, 'Total loss': 0.4227964371442795} | train loss {'Reaction outcome loss': 0.300186910774083, 'Total loss': 0.300186910774083}
2022-12-31 12:08:27,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:27,226 INFO:     Epoch: 58
2022-12-31 12:08:28,833 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46523150280117986, 'Total loss': 0.46523150280117986} | train loss {'Reaction outcome loss': 0.27126464515627513, 'Total loss': 0.27126464515627513}
2022-12-31 12:08:28,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:28,833 INFO:     Epoch: 59
2022-12-31 12:08:30,498 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39884563386440275, 'Total loss': 0.39884563386440275} | train loss {'Reaction outcome loss': 0.26816445944047923, 'Total loss': 0.26816445944047923}
2022-12-31 12:08:30,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:30,498 INFO:     Epoch: 60
2022-12-31 12:08:32,137 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46794121662775673, 'Total loss': 0.46794121662775673} | train loss {'Reaction outcome loss': 0.29496316492989444, 'Total loss': 0.29496316492989444}
2022-12-31 12:08:32,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:32,138 INFO:     Epoch: 61
2022-12-31 12:08:33,748 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46299836337566375, 'Total loss': 0.46299836337566375} | train loss {'Reaction outcome loss': 0.2600613513567478, 'Total loss': 0.2600613513567478}
2022-12-31 12:08:33,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:33,749 INFO:     Epoch: 62
2022-12-31 12:08:35,429 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43724416494369506, 'Total loss': 0.43724416494369506} | train loss {'Reaction outcome loss': 0.26146942641492427, 'Total loss': 0.26146942641492427}
2022-12-31 12:08:35,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:35,429 INFO:     Epoch: 63
2022-12-31 12:08:37,095 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41882659296194713, 'Total loss': 0.41882659296194713} | train loss {'Reaction outcome loss': 0.26159831361365976, 'Total loss': 0.26159831361365976}
2022-12-31 12:08:37,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:37,095 INFO:     Epoch: 64
2022-12-31 12:08:38,754 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4321020523707072, 'Total loss': 0.4321020523707072} | train loss {'Reaction outcome loss': 0.26285026541259815, 'Total loss': 0.26285026541259815}
2022-12-31 12:08:38,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:38,754 INFO:     Epoch: 65
2022-12-31 12:08:40,396 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4343175247311592, 'Total loss': 0.4343175247311592} | train loss {'Reaction outcome loss': 0.2556386758696517, 'Total loss': 0.2556386758696517}
2022-12-31 12:08:40,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:40,396 INFO:     Epoch: 66
2022-12-31 12:08:42,111 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4344679246346156, 'Total loss': 0.4344679246346156} | train loss {'Reaction outcome loss': 0.25312129723417875, 'Total loss': 0.25312129723417875}
2022-12-31 12:08:42,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:42,111 INFO:     Epoch: 67
2022-12-31 12:08:43,736 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.415780571103096, 'Total loss': 0.415780571103096} | train loss {'Reaction outcome loss': 0.2530397860707877, 'Total loss': 0.2530397860707877}
2022-12-31 12:08:43,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:43,736 INFO:     Epoch: 68
2022-12-31 12:08:45,369 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4379682948191961, 'Total loss': 0.4379682948191961} | train loss {'Reaction outcome loss': 0.24485786996640102, 'Total loss': 0.24485786996640102}
2022-12-31 12:08:45,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:45,370 INFO:     Epoch: 69
2022-12-31 12:08:46,967 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40385665024320283, 'Total loss': 0.40385665024320283} | train loss {'Reaction outcome loss': 0.2457103145096208, 'Total loss': 0.2457103145096208}
2022-12-31 12:08:46,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:46,967 INFO:     Epoch: 70
2022-12-31 12:08:48,592 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4104300945997238, 'Total loss': 0.4104300945997238} | train loss {'Reaction outcome loss': 0.24782528992290137, 'Total loss': 0.24782528992290137}
2022-12-31 12:08:48,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:48,592 INFO:     Epoch: 71
2022-12-31 12:08:50,254 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41720222532749174, 'Total loss': 0.41720222532749174} | train loss {'Reaction outcome loss': 0.24924113422732092, 'Total loss': 0.24924113422732092}
2022-12-31 12:08:50,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:50,254 INFO:     Epoch: 72
2022-12-31 12:08:51,884 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44012583593527477, 'Total loss': 0.44012583593527477} | train loss {'Reaction outcome loss': 0.24283483059590924, 'Total loss': 0.24283483059590924}
2022-12-31 12:08:51,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:51,884 INFO:     Epoch: 73
2022-12-31 12:08:53,501 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40960588256518043, 'Total loss': 0.40960588256518043} | train loss {'Reaction outcome loss': 0.24174559857763836, 'Total loss': 0.24174559857763836}
2022-12-31 12:08:53,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:53,501 INFO:     Epoch: 74
2022-12-31 12:08:55,118 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3927616854508718, 'Total loss': 0.3927616854508718} | train loss {'Reaction outcome loss': 0.24201789353906678, 'Total loss': 0.24201789353906678}
2022-12-31 12:08:55,118 INFO:     Found new best model at epoch 74
2022-12-31 12:08:55,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:55,119 INFO:     Epoch: 75
2022-12-31 12:08:56,736 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4414595743020376, 'Total loss': 0.4414595743020376} | train loss {'Reaction outcome loss': 0.23512311458036486, 'Total loss': 0.23512311458036486}
2022-12-31 12:08:56,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:56,737 INFO:     Epoch: 76
2022-12-31 12:08:58,351 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.422217658162117, 'Total loss': 0.422217658162117} | train loss {'Reaction outcome loss': 0.24294253614599534, 'Total loss': 0.24294253614599534}
2022-12-31 12:08:58,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:58,351 INFO:     Epoch: 77
2022-12-31 12:08:59,994 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4080865482489268, 'Total loss': 0.4080865482489268} | train loss {'Reaction outcome loss': 0.23666194588809775, 'Total loss': 0.23666194588809775}
2022-12-31 12:08:59,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:08:59,994 INFO:     Epoch: 78
2022-12-31 12:09:01,622 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3863438715537389, 'Total loss': 0.3863438715537389} | train loss {'Reaction outcome loss': 0.23277906266085283, 'Total loss': 0.23277906266085283}
2022-12-31 12:09:01,622 INFO:     Found new best model at epoch 78
2022-12-31 12:09:01,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:01,623 INFO:     Epoch: 79
2022-12-31 12:09:03,245 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3731027623017629, 'Total loss': 0.3731027623017629} | train loss {'Reaction outcome loss': 0.2325009703817541, 'Total loss': 0.2325009703817541}
2022-12-31 12:09:03,246 INFO:     Found new best model at epoch 79
2022-12-31 12:09:03,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:03,247 INFO:     Epoch: 80
2022-12-31 12:09:04,838 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38892951905727385, 'Total loss': 0.38892951905727385} | train loss {'Reaction outcome loss': 0.22813163532376074, 'Total loss': 0.22813163532376074}
2022-12-31 12:09:04,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:04,838 INFO:     Epoch: 81
2022-12-31 12:09:06,481 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38507344722747805, 'Total loss': 0.38507344722747805} | train loss {'Reaction outcome loss': 0.23714725729550465, 'Total loss': 0.23714725729550465}
2022-12-31 12:09:06,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:06,481 INFO:     Epoch: 82
2022-12-31 12:09:08,095 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41365865568319954, 'Total loss': 0.41365865568319954} | train loss {'Reaction outcome loss': 0.23459101913064934, 'Total loss': 0.23459101913064934}
2022-12-31 12:09:08,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:08,095 INFO:     Epoch: 83
2022-12-31 12:09:09,708 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4351662079493205, 'Total loss': 0.4351662079493205} | train loss {'Reaction outcome loss': 0.22985028836368313, 'Total loss': 0.22985028836368313}
2022-12-31 12:09:09,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:09,708 INFO:     Epoch: 84
2022-12-31 12:09:11,305 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41567301551500957, 'Total loss': 0.41567301551500957} | train loss {'Reaction outcome loss': 0.22163319261744618, 'Total loss': 0.22163319261744618}
2022-12-31 12:09:11,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:11,305 INFO:     Epoch: 85
2022-12-31 12:09:12,925 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4023565500974655, 'Total loss': 0.4023565500974655} | train loss {'Reaction outcome loss': 0.23626768202930049, 'Total loss': 0.23626768202930049}
2022-12-31 12:09:12,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:12,925 INFO:     Epoch: 86
2022-12-31 12:09:14,553 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41507336497306824, 'Total loss': 0.41507336497306824} | train loss {'Reaction outcome loss': 0.22180427149936988, 'Total loss': 0.22180427149936988}
2022-12-31 12:09:14,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:14,554 INFO:     Epoch: 87
2022-12-31 12:09:16,196 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37988383571306866, 'Total loss': 0.37988383571306866} | train loss {'Reaction outcome loss': 0.22126812552702124, 'Total loss': 0.22126812552702124}
2022-12-31 12:09:16,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:16,197 INFO:     Epoch: 88
2022-12-31 12:09:17,858 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4112661838531494, 'Total loss': 0.4112661838531494} | train loss {'Reaction outcome loss': 0.2354289927316131, 'Total loss': 0.2354289927316131}
2022-12-31 12:09:17,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:17,859 INFO:     Epoch: 89
2022-12-31 12:09:19,476 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4416001081466675, 'Total loss': 0.4416001081466675} | train loss {'Reaction outcome loss': 0.216611364882814, 'Total loss': 0.216611364882814}
2022-12-31 12:09:19,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:19,477 INFO:     Epoch: 90
2022-12-31 12:09:21,094 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4617810184756915, 'Total loss': 0.4617810184756915} | train loss {'Reaction outcome loss': 0.2253514565451516, 'Total loss': 0.2253514565451516}
2022-12-31 12:09:21,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:21,094 INFO:     Epoch: 91
2022-12-31 12:09:22,688 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44049515823523205, 'Total loss': 0.44049515823523205} | train loss {'Reaction outcome loss': 0.22660810052521824, 'Total loss': 0.22660810052521824}
2022-12-31 12:09:22,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:22,689 INFO:     Epoch: 92
2022-12-31 12:09:24,315 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3671018570661545, 'Total loss': 0.3671018570661545} | train loss {'Reaction outcome loss': 0.22106564317937885, 'Total loss': 0.22106564317937885}
2022-12-31 12:09:24,315 INFO:     Found new best model at epoch 92
2022-12-31 12:09:24,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:24,316 INFO:     Epoch: 93
2022-12-31 12:09:25,955 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4074608792861303, 'Total loss': 0.4074608792861303} | train loss {'Reaction outcome loss': 0.2138759619830534, 'Total loss': 0.2138759619830534}
2022-12-31 12:09:25,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:25,955 INFO:     Epoch: 94
2022-12-31 12:09:27,584 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39548631608486173, 'Total loss': 0.39548631608486173} | train loss {'Reaction outcome loss': 0.21439671688911377, 'Total loss': 0.21439671688911377}
2022-12-31 12:09:27,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:27,585 INFO:     Epoch: 95
2022-12-31 12:09:29,207 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42984482645988464, 'Total loss': 0.42984482645988464} | train loss {'Reaction outcome loss': 0.21393128204436979, 'Total loss': 0.21393128204436979}
2022-12-31 12:09:29,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:29,207 INFO:     Epoch: 96
2022-12-31 12:09:30,830 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41871828908721603, 'Total loss': 0.41871828908721603} | train loss {'Reaction outcome loss': 0.2163015063118281, 'Total loss': 0.2163015063118281}
2022-12-31 12:09:30,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:30,831 INFO:     Epoch: 97
2022-12-31 12:09:32,456 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3802651271224022, 'Total loss': 0.3802651271224022} | train loss {'Reaction outcome loss': 0.21575777563249585, 'Total loss': 0.21575777563249585}
2022-12-31 12:09:32,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:32,456 INFO:     Epoch: 98
2022-12-31 12:09:34,071 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38347709476947783, 'Total loss': 0.38347709476947783} | train loss {'Reaction outcome loss': 0.21346756086666943, 'Total loss': 0.21346756086666943}
2022-12-31 12:09:34,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:34,072 INFO:     Epoch: 99
2022-12-31 12:09:35,687 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3639510333538055, 'Total loss': 0.3639510333538055} | train loss {'Reaction outcome loss': 0.20743097587947504, 'Total loss': 0.20743097587947504}
2022-12-31 12:09:35,687 INFO:     Found new best model at epoch 99
2022-12-31 12:09:35,688 INFO:     Best model found after epoch 100 of 100.
2022-12-31 12:09:35,688 INFO:   Done with stage: TRAINING
2022-12-31 12:09:35,688 INFO:   Starting stage: EVALUATION
2022-12-31 12:09:35,817 INFO:   Done with stage: EVALUATION
2022-12-31 12:09:35,817 INFO:   Leaving out SEQ value Fold_9
2022-12-31 12:09:35,829 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 12:09:35,829 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:09:36,475 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:09:36,475 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:09:36,543 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:09:36,543 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:09:36,543 INFO:     No hyperparam tuning for this model
2022-12-31 12:09:36,544 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:09:36,544 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:09:36,544 INFO:     None feature selector for col prot
2022-12-31 12:09:36,544 INFO:     None feature selector for col prot
2022-12-31 12:09:36,544 INFO:     None feature selector for col prot
2022-12-31 12:09:36,545 INFO:     None feature selector for col chem
2022-12-31 12:09:36,545 INFO:     None feature selector for col chem
2022-12-31 12:09:36,545 INFO:     None feature selector for col chem
2022-12-31 12:09:36,545 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:09:36,545 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:09:36,547 INFO:     Number of params in model 223921
2022-12-31 12:09:36,550 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:09:36,550 INFO:   Starting stage: TRAINING
2022-12-31 12:09:36,598 INFO:     Val loss before train {'Reaction outcome loss': 1.0146049737930298, 'Total loss': 1.0146049737930298}
2022-12-31 12:09:36,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:36,598 INFO:     Epoch: 0
2022-12-31 12:09:38,200 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6529467940330506, 'Total loss': 0.6529467940330506} | train loss {'Reaction outcome loss': 0.7999115579018573, 'Total loss': 0.7999115579018573}
2022-12-31 12:09:38,201 INFO:     Found new best model at epoch 0
2022-12-31 12:09:38,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:38,201 INFO:     Epoch: 1
2022-12-31 12:09:39,840 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5199017763137818, 'Total loss': 0.5199017763137818} | train loss {'Reaction outcome loss': 0.5863745539192704, 'Total loss': 0.5863745539192704}
2022-12-31 12:09:39,840 INFO:     Found new best model at epoch 1
2022-12-31 12:09:39,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:39,841 INFO:     Epoch: 2
2022-12-31 12:09:41,446 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4834980547428131, 'Total loss': 0.4834980547428131} | train loss {'Reaction outcome loss': 0.5329943884272075, 'Total loss': 0.5329943884272075}
2022-12-31 12:09:41,446 INFO:     Found new best model at epoch 2
2022-12-31 12:09:41,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:41,447 INFO:     Epoch: 3
2022-12-31 12:09:43,061 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4383212198813756, 'Total loss': 0.4383212198813756} | train loss {'Reaction outcome loss': 0.5168284289673835, 'Total loss': 0.5168284289673835}
2022-12-31 12:09:43,061 INFO:     Found new best model at epoch 3
2022-12-31 12:09:43,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:43,062 INFO:     Epoch: 4
2022-12-31 12:09:44,677 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4765736391146978, 'Total loss': 0.4765736391146978} | train loss {'Reaction outcome loss': 0.5024930346703184, 'Total loss': 0.5024930346703184}
2022-12-31 12:09:44,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:44,677 INFO:     Epoch: 5
2022-12-31 12:09:46,294 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46362849871317546, 'Total loss': 0.46362849871317546} | train loss {'Reaction outcome loss': 0.4838783540459269, 'Total loss': 0.4838783540459269}
2022-12-31 12:09:46,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:46,295 INFO:     Epoch: 6
2022-12-31 12:09:47,925 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43875783880551655, 'Total loss': 0.43875783880551655} | train loss {'Reaction outcome loss': 0.46337651567317656, 'Total loss': 0.46337651567317656}
2022-12-31 12:09:47,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:47,925 INFO:     Epoch: 7
2022-12-31 12:09:49,585 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44076424042383827, 'Total loss': 0.44076424042383827} | train loss {'Reaction outcome loss': 0.4568440466478089, 'Total loss': 0.4568440466478089}
2022-12-31 12:09:49,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:49,585 INFO:     Epoch: 8
2022-12-31 12:09:51,183 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48508572777112324, 'Total loss': 0.48508572777112324} | train loss {'Reaction outcome loss': 0.4468639058590718, 'Total loss': 0.4468639058590718}
2022-12-31 12:09:51,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:51,183 INFO:     Epoch: 9
2022-12-31 12:09:52,796 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4341588119665782, 'Total loss': 0.4341588119665782} | train loss {'Reaction outcome loss': 0.4433218500158493, 'Total loss': 0.4433218500158493}
2022-12-31 12:09:52,796 INFO:     Found new best model at epoch 9
2022-12-31 12:09:52,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:52,797 INFO:     Epoch: 10
2022-12-31 12:09:54,407 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4483352541923523, 'Total loss': 0.4483352541923523} | train loss {'Reaction outcome loss': 0.43612235499060026, 'Total loss': 0.43612235499060026}
2022-12-31 12:09:54,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:54,408 INFO:     Epoch: 11
2022-12-31 12:09:56,005 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.423618295788765, 'Total loss': 0.423618295788765} | train loss {'Reaction outcome loss': 0.43522475751629774, 'Total loss': 0.43522475751629774}
2022-12-31 12:09:56,005 INFO:     Found new best model at epoch 11
2022-12-31 12:09:56,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:56,006 INFO:     Epoch: 12
2022-12-31 12:09:57,623 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41830988725026447, 'Total loss': 0.41830988725026447} | train loss {'Reaction outcome loss': 0.43295429267448565, 'Total loss': 0.43295429267448565}
2022-12-31 12:09:57,624 INFO:     Found new best model at epoch 12
2022-12-31 12:09:57,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:57,625 INFO:     Epoch: 13
2022-12-31 12:09:59,263 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43197597563266754, 'Total loss': 0.43197597563266754} | train loss {'Reaction outcome loss': 0.4195803393191401, 'Total loss': 0.4195803393191401}
2022-12-31 12:09:59,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:09:59,263 INFO:     Epoch: 14
2022-12-31 12:10:00,880 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42999877432982125, 'Total loss': 0.42999877432982125} | train loss {'Reaction outcome loss': 0.4222124785562788, 'Total loss': 0.4222124785562788}
2022-12-31 12:10:00,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:00,880 INFO:     Epoch: 15
2022-12-31 12:10:02,491 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43927036424477894, 'Total loss': 0.43927036424477894} | train loss {'Reaction outcome loss': 0.41875457155612716, 'Total loss': 0.41875457155612716}
2022-12-31 12:10:02,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:02,491 INFO:     Epoch: 16
2022-12-31 12:10:04,104 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4368275006612142, 'Total loss': 0.4368275006612142} | train loss {'Reaction outcome loss': 0.40726558278159547, 'Total loss': 0.40726558278159547}
2022-12-31 12:10:04,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:04,105 INFO:     Epoch: 17
2022-12-31 12:10:05,696 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45910219053427376, 'Total loss': 0.45910219053427376} | train loss {'Reaction outcome loss': 0.3945447180919565, 'Total loss': 0.3945447180919565}
2022-12-31 12:10:05,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:05,697 INFO:     Epoch: 18
2022-12-31 12:10:07,309 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46395874917507174, 'Total loss': 0.46395874917507174} | train loss {'Reaction outcome loss': 0.3932457520488137, 'Total loss': 0.3932457520488137}
2022-12-31 12:10:07,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:07,310 INFO:     Epoch: 19
2022-12-31 12:10:08,912 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4341786523660024, 'Total loss': 0.4341786523660024} | train loss {'Reaction outcome loss': 0.40412810064204363, 'Total loss': 0.40412810064204363}
2022-12-31 12:10:08,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:08,912 INFO:     Epoch: 20
2022-12-31 12:10:10,524 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40524833103020985, 'Total loss': 0.40524833103020985} | train loss {'Reaction outcome loss': 0.41336597029568517, 'Total loss': 0.41336597029568517}
2022-12-31 12:10:10,524 INFO:     Found new best model at epoch 20
2022-12-31 12:10:10,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:10,525 INFO:     Epoch: 21
2022-12-31 12:10:12,137 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4299773017565409, 'Total loss': 0.4299773017565409} | train loss {'Reaction outcome loss': 0.3871016671638126, 'Total loss': 0.3871016671638126}
2022-12-31 12:10:12,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:12,137 INFO:     Epoch: 22
2022-12-31 12:10:13,733 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40617504517237346, 'Total loss': 0.40617504517237346} | train loss {'Reaction outcome loss': 0.38034873393505975, 'Total loss': 0.38034873393505975}
2022-12-31 12:10:13,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:13,734 INFO:     Epoch: 23
2022-12-31 12:10:15,370 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41885408759117126, 'Total loss': 0.41885408759117126} | train loss {'Reaction outcome loss': 0.3729227392222379, 'Total loss': 0.3729227392222379}
2022-12-31 12:10:15,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:15,370 INFO:     Epoch: 24
2022-12-31 12:10:16,967 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39380008180936177, 'Total loss': 0.39380008180936177} | train loss {'Reaction outcome loss': 0.36544312417601654, 'Total loss': 0.36544312417601654}
2022-12-31 12:10:16,968 INFO:     Found new best model at epoch 24
2022-12-31 12:10:16,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:16,969 INFO:     Epoch: 25
2022-12-31 12:10:18,572 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.402517302831014, 'Total loss': 0.402517302831014} | train loss {'Reaction outcome loss': 0.35907316931643174, 'Total loss': 0.35907316931643174}
2022-12-31 12:10:18,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:18,572 INFO:     Epoch: 26
2022-12-31 12:10:20,182 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4114591866731644, 'Total loss': 0.4114591866731644} | train loss {'Reaction outcome loss': 0.35768446728816605, 'Total loss': 0.35768446728816605}
2022-12-31 12:10:20,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:20,183 INFO:     Epoch: 27
2022-12-31 12:10:21,791 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3724898546934128, 'Total loss': 0.3724898546934128} | train loss {'Reaction outcome loss': 0.3474453719791727, 'Total loss': 0.3474453719791727}
2022-12-31 12:10:21,791 INFO:     Found new best model at epoch 27
2022-12-31 12:10:21,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:21,792 INFO:     Epoch: 28
2022-12-31 12:10:23,397 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3986563781897227, 'Total loss': 0.3986563781897227} | train loss {'Reaction outcome loss': 0.343091988955891, 'Total loss': 0.343091988955891}
2022-12-31 12:10:23,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:23,397 INFO:     Epoch: 29
2022-12-31 12:10:25,025 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38417967160542804, 'Total loss': 0.38417967160542804} | train loss {'Reaction outcome loss': 0.3387043575810663, 'Total loss': 0.3387043575810663}
2022-12-31 12:10:25,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:25,026 INFO:     Epoch: 30
2022-12-31 12:10:26,623 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42030773162841795, 'Total loss': 0.42030773162841795} | train loss {'Reaction outcome loss': 0.3272680973067232, 'Total loss': 0.3272680973067232}
2022-12-31 12:10:26,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:26,623 INFO:     Epoch: 31
2022-12-31 12:10:28,233 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3864387820164363, 'Total loss': 0.3864387820164363} | train loss {'Reaction outcome loss': 0.3278431230818556, 'Total loss': 0.3278431230818556}
2022-12-31 12:10:28,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:28,233 INFO:     Epoch: 32
2022-12-31 12:10:29,850 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3613466461499532, 'Total loss': 0.3613466461499532} | train loss {'Reaction outcome loss': 0.3192796374812884, 'Total loss': 0.3192796374812884}
2022-12-31 12:10:29,850 INFO:     Found new best model at epoch 32
2022-12-31 12:10:29,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:29,851 INFO:     Epoch: 33
2022-12-31 12:10:31,500 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45153475403785703, 'Total loss': 0.45153475403785703} | train loss {'Reaction outcome loss': 0.3202258779423099, 'Total loss': 0.3202258779423099}
2022-12-31 12:10:31,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:31,501 INFO:     Epoch: 34
2022-12-31 12:10:33,132 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37275643448034923, 'Total loss': 0.37275643448034923} | train loss {'Reaction outcome loss': 0.31570205573444726, 'Total loss': 0.31570205573444726}
2022-12-31 12:10:33,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:33,132 INFO:     Epoch: 35
2022-12-31 12:10:34,749 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41084629744291307, 'Total loss': 0.41084629744291307} | train loss {'Reaction outcome loss': 0.3154251200106481, 'Total loss': 0.3154251200106481}
2022-12-31 12:10:34,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:34,750 INFO:     Epoch: 36
2022-12-31 12:10:36,379 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3989586700995763, 'Total loss': 0.3989586700995763} | train loss {'Reaction outcome loss': 0.3587798750517573, 'Total loss': 0.3587798750517573}
2022-12-31 12:10:36,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:36,379 INFO:     Epoch: 37
2022-12-31 12:10:38,028 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3964201534787814, 'Total loss': 0.3964201534787814} | train loss {'Reaction outcome loss': 0.3090396568839661, 'Total loss': 0.3090396568839661}
2022-12-31 12:10:38,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:38,028 INFO:     Epoch: 38
2022-12-31 12:10:39,682 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4079942852258682, 'Total loss': 0.4079942852258682} | train loss {'Reaction outcome loss': 0.30078203514879703, 'Total loss': 0.30078203514879703}
2022-12-31 12:10:39,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:39,682 INFO:     Epoch: 39
2022-12-31 12:10:41,304 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36765934228897096, 'Total loss': 0.36765934228897096} | train loss {'Reaction outcome loss': 0.29374519561415713, 'Total loss': 0.29374519561415713}
2022-12-31 12:10:41,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:41,305 INFO:     Epoch: 40
2022-12-31 12:10:42,926 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3665639122327169, 'Total loss': 0.3665639122327169} | train loss {'Reaction outcome loss': 0.2945581091596556, 'Total loss': 0.2945581091596556}
2022-12-31 12:10:42,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:42,926 INFO:     Epoch: 41
2022-12-31 12:10:44,520 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3627272218465805, 'Total loss': 0.3627272218465805} | train loss {'Reaction outcome loss': 0.28306037032313686, 'Total loss': 0.28306037032313686}
2022-12-31 12:10:44,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:44,521 INFO:     Epoch: 42
2022-12-31 12:10:46,191 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36016407509644827, 'Total loss': 0.36016407509644827} | train loss {'Reaction outcome loss': 0.27844628784932074, 'Total loss': 0.27844628784932074}
2022-12-31 12:10:46,192 INFO:     Found new best model at epoch 42
2022-12-31 12:10:46,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:46,192 INFO:     Epoch: 43
2022-12-31 12:10:47,863 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3933018426100413, 'Total loss': 0.3933018426100413} | train loss {'Reaction outcome loss': 0.2767631726708952, 'Total loss': 0.2767631726708952}
2022-12-31 12:10:47,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:47,864 INFO:     Epoch: 44
2022-12-31 12:10:49,507 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36716722647349037, 'Total loss': 0.36716722647349037} | train loss {'Reaction outcome loss': 0.2774728567852382, 'Total loss': 0.2774728567852382}
2022-12-31 12:10:49,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:49,507 INFO:     Epoch: 45
2022-12-31 12:10:51,148 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36847367907563844, 'Total loss': 0.36847367907563844} | train loss {'Reaction outcome loss': 0.2719272665436501, 'Total loss': 0.2719272665436501}
2022-12-31 12:10:51,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:51,148 INFO:     Epoch: 46
2022-12-31 12:10:52,764 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3963590850432714, 'Total loss': 0.3963590850432714} | train loss {'Reaction outcome loss': 0.28834517163804907, 'Total loss': 0.28834517163804907}
2022-12-31 12:10:52,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:52,764 INFO:     Epoch: 47
2022-12-31 12:10:54,064 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3616057070593039, 'Total loss': 0.3616057070593039} | train loss {'Reaction outcome loss': 0.265889842785301, 'Total loss': 0.265889842785301}
2022-12-31 12:10:54,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:54,065 INFO:     Epoch: 48
2022-12-31 12:10:55,133 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3635059386491776, 'Total loss': 0.3635059386491776} | train loss {'Reaction outcome loss': 0.26664187401932565, 'Total loss': 0.26664187401932565}
2022-12-31 12:10:55,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:55,133 INFO:     Epoch: 49
2022-12-31 12:10:56,198 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3675919691721598, 'Total loss': 0.3675919691721598} | train loss {'Reaction outcome loss': 0.26480913172354514, 'Total loss': 0.26480913172354514}
2022-12-31 12:10:56,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:56,199 INFO:     Epoch: 50
2022-12-31 12:10:57,267 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.440078334013621, 'Total loss': 0.440078334013621} | train loss {'Reaction outcome loss': 0.25486761832101934, 'Total loss': 0.25486761832101934}
2022-12-31 12:10:57,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:57,267 INFO:     Epoch: 51
2022-12-31 12:10:58,567 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3672652766108513, 'Total loss': 0.3672652766108513} | train loss {'Reaction outcome loss': 0.2562481522074212, 'Total loss': 0.2562481522074212}
2022-12-31 12:10:58,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:10:58,568 INFO:     Epoch: 52
2022-12-31 12:11:00,177 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3604343389471372, 'Total loss': 0.3604343389471372} | train loss {'Reaction outcome loss': 0.25694753449626156, 'Total loss': 0.25694753449626156}
2022-12-31 12:11:00,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:00,177 INFO:     Epoch: 53
2022-12-31 12:11:01,785 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40043822924296063, 'Total loss': 0.40043822924296063} | train loss {'Reaction outcome loss': 0.2549780588529572, 'Total loss': 0.2549780588529572}
2022-12-31 12:11:01,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:01,785 INFO:     Epoch: 54
2022-12-31 12:11:03,394 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4063405394554138, 'Total loss': 0.4063405394554138} | train loss {'Reaction outcome loss': 0.2470538757085139, 'Total loss': 0.2470538757085139}
2022-12-31 12:11:03,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:03,394 INFO:     Epoch: 55
2022-12-31 12:11:05,003 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3683016896247864, 'Total loss': 0.3683016896247864} | train loss {'Reaction outcome loss': 0.24862992264052478, 'Total loss': 0.24862992264052478}
2022-12-31 12:11:05,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:05,004 INFO:     Epoch: 56
2022-12-31 12:11:06,596 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3824198395013809, 'Total loss': 0.3824198395013809} | train loss {'Reaction outcome loss': 0.2411134631965188, 'Total loss': 0.2411134631965188}
2022-12-31 12:11:06,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:06,597 INFO:     Epoch: 57
2022-12-31 12:11:08,214 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3517520981530348, 'Total loss': 0.3517520981530348} | train loss {'Reaction outcome loss': 0.24323082584347847, 'Total loss': 0.24323082584347847}
2022-12-31 12:11:08,214 INFO:     Found new best model at epoch 57
2022-12-31 12:11:08,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:08,215 INFO:     Epoch: 58
2022-12-31 12:11:09,824 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.386912547548612, 'Total loss': 0.386912547548612} | train loss {'Reaction outcome loss': 0.2662601633085127, 'Total loss': 0.2662601633085127}
2022-12-31 12:11:09,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:09,825 INFO:     Epoch: 59
2022-12-31 12:11:11,431 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41045970022678374, 'Total loss': 0.41045970022678374} | train loss {'Reaction outcome loss': 0.24533302323771236, 'Total loss': 0.24533302323771236}
2022-12-31 12:11:11,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:11,432 INFO:     Epoch: 60
2022-12-31 12:11:13,041 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35637860298156737, 'Total loss': 0.35637860298156737} | train loss {'Reaction outcome loss': 0.24256054013592115, 'Total loss': 0.24256054013592115}
2022-12-31 12:11:13,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:13,041 INFO:     Epoch: 61
2022-12-31 12:11:14,649 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3855836808681488, 'Total loss': 0.3855836808681488} | train loss {'Reaction outcome loss': 0.23057276289910078, 'Total loss': 0.23057276289910078}
2022-12-31 12:11:14,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:14,649 INFO:     Epoch: 62
2022-12-31 12:11:16,225 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38751071294148765, 'Total loss': 0.38751071294148765} | train loss {'Reaction outcome loss': 0.23906639023113277, 'Total loss': 0.23906639023113277}
2022-12-31 12:11:16,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:16,225 INFO:     Epoch: 63
2022-12-31 12:11:17,887 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3602843046188354, 'Total loss': 0.3602843046188354} | train loss {'Reaction outcome loss': 0.2303074249488207, 'Total loss': 0.2303074249488207}
2022-12-31 12:11:17,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:17,888 INFO:     Epoch: 64
2022-12-31 12:11:19,544 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37392876942952474, 'Total loss': 0.37392876942952474} | train loss {'Reaction outcome loss': 0.2306757633830758, 'Total loss': 0.2306757633830758}
2022-12-31 12:11:19,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:19,544 INFO:     Epoch: 65
2022-12-31 12:11:21,163 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3916587606072426, 'Total loss': 0.3916587606072426} | train loss {'Reaction outcome loss': 0.2831398328712237, 'Total loss': 0.2831398328712237}
2022-12-31 12:11:21,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:21,163 INFO:     Epoch: 66
2022-12-31 12:11:22,781 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38403935035069786, 'Total loss': 0.38403935035069786} | train loss {'Reaction outcome loss': 0.2440316067849565, 'Total loss': 0.2440316067849565}
2022-12-31 12:11:22,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:22,781 INFO:     Epoch: 67
2022-12-31 12:11:24,377 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3600731501976649, 'Total loss': 0.3600731501976649} | train loss {'Reaction outcome loss': 0.23303221652041312, 'Total loss': 0.23303221652041312}
2022-12-31 12:11:24,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:24,377 INFO:     Epoch: 68
2022-12-31 12:11:26,007 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40122472792863845, 'Total loss': 0.40122472792863845} | train loss {'Reaction outcome loss': 0.22633882327194232, 'Total loss': 0.22633882327194232}
2022-12-31 12:11:26,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:26,007 INFO:     Epoch: 69
2022-12-31 12:11:27,643 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39201090633869173, 'Total loss': 0.39201090633869173} | train loss {'Reaction outcome loss': 0.22884798072028797, 'Total loss': 0.22884798072028797}
2022-12-31 12:11:27,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:27,643 INFO:     Epoch: 70
2022-12-31 12:11:29,295 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37689338624477386, 'Total loss': 0.37689338624477386} | train loss {'Reaction outcome loss': 0.22515133768320084, 'Total loss': 0.22515133768320084}
2022-12-31 12:11:29,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:29,296 INFO:     Epoch: 71
2022-12-31 12:11:30,890 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4026037057240804, 'Total loss': 0.4026037057240804} | train loss {'Reaction outcome loss': 0.30794546322257427, 'Total loss': 0.30794546322257427}
2022-12-31 12:11:30,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:30,890 INFO:     Epoch: 72
2022-12-31 12:11:32,515 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4185515900452932, 'Total loss': 0.4185515900452932} | train loss {'Reaction outcome loss': 0.24012944035228534, 'Total loss': 0.24012944035228534}
2022-12-31 12:11:32,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:32,516 INFO:     Epoch: 73
2022-12-31 12:11:34,120 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3833598345518112, 'Total loss': 0.3833598345518112} | train loss {'Reaction outcome loss': 0.23279615654947533, 'Total loss': 0.23279615654947533}
2022-12-31 12:11:34,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:34,120 INFO:     Epoch: 74
2022-12-31 12:11:35,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35960503766934077, 'Total loss': 0.35960503766934077} | train loss {'Reaction outcome loss': 0.22746661298678836, 'Total loss': 0.22746661298678836}
2022-12-31 12:11:35,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:35,717 INFO:     Epoch: 75
2022-12-31 12:11:37,368 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41310759584108986, 'Total loss': 0.41310759584108986} | train loss {'Reaction outcome loss': 0.21834345353841933, 'Total loss': 0.21834345353841933}
2022-12-31 12:11:37,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:37,369 INFO:     Epoch: 76
2022-12-31 12:11:39,037 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40295044183731077, 'Total loss': 0.40295044183731077} | train loss {'Reaction outcome loss': 0.22262757235169545, 'Total loss': 0.22262757235169545}
2022-12-31 12:11:39,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:39,038 INFO:     Epoch: 77
2022-12-31 12:11:40,661 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36003377636273703, 'Total loss': 0.36003377636273703} | train loss {'Reaction outcome loss': 0.22190541704564923, 'Total loss': 0.22190541704564923}
2022-12-31 12:11:40,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:40,662 INFO:     Epoch: 78
2022-12-31 12:11:42,274 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36484122077624004, 'Total loss': 0.36484122077624004} | train loss {'Reaction outcome loss': 0.2182747875270687, 'Total loss': 0.2182747875270687}
2022-12-31 12:11:42,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:42,275 INFO:     Epoch: 79
2022-12-31 12:11:43,861 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3500651443998019, 'Total loss': 0.3500651443998019} | train loss {'Reaction outcome loss': 0.21722086761619194, 'Total loss': 0.21722086761619194}
2022-12-31 12:11:43,861 INFO:     Found new best model at epoch 79
2022-12-31 12:11:43,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:43,862 INFO:     Epoch: 80
2022-12-31 12:11:45,530 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3991831600666046, 'Total loss': 0.3991831600666046} | train loss {'Reaction outcome loss': 0.21182797475974413, 'Total loss': 0.21182797475974413}
2022-12-31 12:11:45,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:45,530 INFO:     Epoch: 81
2022-12-31 12:11:47,182 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38291430175304414, 'Total loss': 0.38291430175304414} | train loss {'Reaction outcome loss': 0.2230676763718003, 'Total loss': 0.2230676763718003}
2022-12-31 12:11:47,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:47,183 INFO:     Epoch: 82
2022-12-31 12:11:48,808 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37047367890675864, 'Total loss': 0.37047367890675864} | train loss {'Reaction outcome loss': 0.21774453962382762, 'Total loss': 0.21774453962382762}
2022-12-31 12:11:48,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:48,809 INFO:     Epoch: 83
2022-12-31 12:11:50,422 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39246182441711425, 'Total loss': 0.39246182441711425} | train loss {'Reaction outcome loss': 0.2178486501629316, 'Total loss': 0.2178486501629316}
2022-12-31 12:11:50,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:50,422 INFO:     Epoch: 84
2022-12-31 12:11:52,012 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35734969973564146, 'Total loss': 0.35734969973564146} | train loss {'Reaction outcome loss': 0.2170098488903655, 'Total loss': 0.2170098488903655}
2022-12-31 12:11:52,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:52,012 INFO:     Epoch: 85
2022-12-31 12:11:53,637 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3554242839415868, 'Total loss': 0.3554242839415868} | train loss {'Reaction outcome loss': 0.21178790634576874, 'Total loss': 0.21178790634576874}
2022-12-31 12:11:53,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:53,637 INFO:     Epoch: 86
2022-12-31 12:11:55,308 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38250489830970763, 'Total loss': 0.38250489830970763} | train loss {'Reaction outcome loss': 0.20917399093572833, 'Total loss': 0.20917399093572833}
2022-12-31 12:11:55,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:55,308 INFO:     Epoch: 87
2022-12-31 12:11:56,976 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4069697618484497, 'Total loss': 0.4069697618484497} | train loss {'Reaction outcome loss': 0.2076932778261413, 'Total loss': 0.2076932778261413}
2022-12-31 12:11:56,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:56,976 INFO:     Epoch: 88
2022-12-31 12:11:58,620 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38617581501603127, 'Total loss': 0.38617581501603127} | train loss {'Reaction outcome loss': 0.21239229809978735, 'Total loss': 0.21239229809978735}
2022-12-31 12:11:58,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:11:58,620 INFO:     Epoch: 89
2022-12-31 12:12:00,232 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35374086697896323, 'Total loss': 0.35374086697896323} | train loss {'Reaction outcome loss': 0.21346449498357117, 'Total loss': 0.21346449498357117}
2022-12-31 12:12:00,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:00,233 INFO:     Epoch: 90
2022-12-31 12:12:01,828 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3680440172553062, 'Total loss': 0.3680440172553062} | train loss {'Reaction outcome loss': 0.20107471963864806, 'Total loss': 0.20107471963864806}
2022-12-31 12:12:01,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:01,828 INFO:     Epoch: 91
2022-12-31 12:12:03,500 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36917354067166647, 'Total loss': 0.36917354067166647} | train loss {'Reaction outcome loss': 0.21221689868337085, 'Total loss': 0.21221689868337085}
2022-12-31 12:12:03,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:03,500 INFO:     Epoch: 92
2022-12-31 12:12:05,144 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3530277447154125, 'Total loss': 0.3530277447154125} | train loss {'Reaction outcome loss': 0.20526839928799376, 'Total loss': 0.20526839928799376}
2022-12-31 12:12:05,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:05,145 INFO:     Epoch: 93
2022-12-31 12:12:06,817 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37082209090391793, 'Total loss': 0.37082209090391793} | train loss {'Reaction outcome loss': 0.20218610344739357, 'Total loss': 0.20218610344739357}
2022-12-31 12:12:06,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:06,817 INFO:     Epoch: 94
2022-12-31 12:12:08,454 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3760631615916888, 'Total loss': 0.3760631615916888} | train loss {'Reaction outcome loss': 0.1986640266879239, 'Total loss': 0.1986640266879239}
2022-12-31 12:12:08,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:08,455 INFO:     Epoch: 95
2022-12-31 12:12:10,047 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41492431064446766, 'Total loss': 0.41492431064446766} | train loss {'Reaction outcome loss': 0.19860687120250287, 'Total loss': 0.19860687120250287}
2022-12-31 12:12:10,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:10,047 INFO:     Epoch: 96
2022-12-31 12:12:11,670 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37425105075041454, 'Total loss': 0.37425105075041454} | train loss {'Reaction outcome loss': 0.20363735271098118, 'Total loss': 0.20363735271098118}
2022-12-31 12:12:11,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:11,671 INFO:     Epoch: 97
2022-12-31 12:12:13,335 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37092994650204975, 'Total loss': 0.37092994650204975} | train loss {'Reaction outcome loss': 0.20174562677815286, 'Total loss': 0.20174562677815286}
2022-12-31 12:12:13,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:13,335 INFO:     Epoch: 98
2022-12-31 12:12:14,988 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3521678586800893, 'Total loss': 0.3521678586800893} | train loss {'Reaction outcome loss': 0.19381850988534954, 'Total loss': 0.19381850988534954}
2022-12-31 12:12:14,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:14,989 INFO:     Epoch: 99
2022-12-31 12:12:16,653 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40671218956510224, 'Total loss': 0.40671218956510224} | train loss {'Reaction outcome loss': 0.20007708764013302, 'Total loss': 0.20007708764013302}
2022-12-31 12:12:16,653 INFO:     Best model found after epoch 80 of 100.
2022-12-31 12:12:16,653 INFO:   Done with stage: TRAINING
2022-12-31 12:12:16,653 INFO:   Starting stage: EVALUATION
2022-12-31 12:12:16,782 INFO:   Done with stage: EVALUATION
2022-12-31 12:12:16,790 INFO:   Leaving out SEQ value Fold_0
2022-12-31 12:12:16,803 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 12:12:16,803 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:12:17,442 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:12:17,442 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:12:17,511 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:12:17,511 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:12:17,511 INFO:     No hyperparam tuning for this model
2022-12-31 12:12:17,511 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:12:17,511 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:12:17,512 INFO:     None feature selector for col prot
2022-12-31 12:12:17,512 INFO:     None feature selector for col prot
2022-12-31 12:12:17,512 INFO:     None feature selector for col prot
2022-12-31 12:12:17,513 INFO:     None feature selector for col chem
2022-12-31 12:12:17,513 INFO:     None feature selector for col chem
2022-12-31 12:12:17,513 INFO:     None feature selector for col chem
2022-12-31 12:12:17,513 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:12:17,513 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:12:17,515 INFO:     Number of params in model 223921
2022-12-31 12:12:17,518 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:12:17,518 INFO:   Starting stage: TRAINING
2022-12-31 12:12:17,563 INFO:     Val loss before train {'Reaction outcome loss': 0.9992415587107341, 'Total loss': 0.9992415587107341}
2022-12-31 12:12:17,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:17,563 INFO:     Epoch: 0
2022-12-31 12:12:19,176 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7049165884653728, 'Total loss': 0.7049165884653728} | train loss {'Reaction outcome loss': 0.8049940399798579, 'Total loss': 0.8049940399798579}
2022-12-31 12:12:19,177 INFO:     Found new best model at epoch 0
2022-12-31 12:12:19,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:19,178 INFO:     Epoch: 1
2022-12-31 12:12:20,770 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5347628057003021, 'Total loss': 0.5347628057003021} | train loss {'Reaction outcome loss': 0.6027189778708988, 'Total loss': 0.6027189778708988}
2022-12-31 12:12:20,770 INFO:     Found new best model at epoch 1
2022-12-31 12:12:20,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:20,771 INFO:     Epoch: 2
2022-12-31 12:12:22,381 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4926850080490112, 'Total loss': 0.4926850080490112} | train loss {'Reaction outcome loss': 0.5235322320083957, 'Total loss': 0.5235322320083957}
2022-12-31 12:12:22,381 INFO:     Found new best model at epoch 2
2022-12-31 12:12:22,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:22,382 INFO:     Epoch: 3
2022-12-31 12:12:23,994 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4713150878747304, 'Total loss': 0.4713150878747304} | train loss {'Reaction outcome loss': 0.4938799683612002, 'Total loss': 0.4938799683612002}
2022-12-31 12:12:23,994 INFO:     Found new best model at epoch 3
2022-12-31 12:12:23,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:23,995 INFO:     Epoch: 4
2022-12-31 12:12:25,605 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45850260456403097, 'Total loss': 0.45850260456403097} | train loss {'Reaction outcome loss': 0.4839588545154834, 'Total loss': 0.4839588545154834}
2022-12-31 12:12:25,605 INFO:     Found new best model at epoch 4
2022-12-31 12:12:25,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:25,606 INFO:     Epoch: 5
2022-12-31 12:12:27,218 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4501073330640793, 'Total loss': 0.4501073330640793} | train loss {'Reaction outcome loss': 0.4873058734920578, 'Total loss': 0.4873058734920578}
2022-12-31 12:12:27,218 INFO:     Found new best model at epoch 5
2022-12-31 12:12:27,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:27,219 INFO:     Epoch: 6
2022-12-31 12:12:28,789 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4618172506491343, 'Total loss': 0.4618172506491343} | train loss {'Reaction outcome loss': 0.49010842419701856, 'Total loss': 0.49010842419701856}
2022-12-31 12:12:28,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:28,789 INFO:     Epoch: 7
2022-12-31 12:12:30,418 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4355163464943568, 'Total loss': 0.4355163464943568} | train loss {'Reaction outcome loss': 0.4567391466673302, 'Total loss': 0.4567391466673302}
2022-12-31 12:12:30,418 INFO:     Found new best model at epoch 7
2022-12-31 12:12:30,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:30,419 INFO:     Epoch: 8
2022-12-31 12:12:32,029 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42096614042917885, 'Total loss': 0.42096614042917885} | train loss {'Reaction outcome loss': 0.4527146012481788, 'Total loss': 0.4527146012481788}
2022-12-31 12:12:32,030 INFO:     Found new best model at epoch 8
2022-12-31 12:12:32,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:32,031 INFO:     Epoch: 9
2022-12-31 12:12:33,639 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4576111992200216, 'Total loss': 0.4576111992200216} | train loss {'Reaction outcome loss': 0.440423098973174, 'Total loss': 0.440423098973174}
2022-12-31 12:12:33,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:33,640 INFO:     Epoch: 10
2022-12-31 12:12:35,251 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4463262250026067, 'Total loss': 0.4463262250026067} | train loss {'Reaction outcome loss': 0.44047856179700384, 'Total loss': 0.44047856179700384}
2022-12-31 12:12:35,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:35,251 INFO:     Epoch: 11
2022-12-31 12:12:36,848 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41905998190244037, 'Total loss': 0.41905998190244037} | train loss {'Reaction outcome loss': 0.4345425602181079, 'Total loss': 0.4345425602181079}
2022-12-31 12:12:36,848 INFO:     Found new best model at epoch 11
2022-12-31 12:12:36,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:36,849 INFO:     Epoch: 12
2022-12-31 12:12:38,459 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.443455704053243, 'Total loss': 0.443455704053243} | train loss {'Reaction outcome loss': 0.4268551692299113, 'Total loss': 0.4268551692299113}
2022-12-31 12:12:38,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:38,460 INFO:     Epoch: 13
2022-12-31 12:12:40,080 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45909445782502495, 'Total loss': 0.45909445782502495} | train loss {'Reaction outcome loss': 0.41823006051582406, 'Total loss': 0.41823006051582406}
2022-12-31 12:12:40,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:40,081 INFO:     Epoch: 14
2022-12-31 12:12:41,693 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4075685034195582, 'Total loss': 0.4075685034195582} | train loss {'Reaction outcome loss': 0.41508508699020685, 'Total loss': 0.41508508699020685}
2022-12-31 12:12:41,693 INFO:     Found new best model at epoch 14
2022-12-31 12:12:41,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:41,694 INFO:     Epoch: 15
2022-12-31 12:12:43,304 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4423490107059479, 'Total loss': 0.4423490107059479} | train loss {'Reaction outcome loss': 0.40726705430669413, 'Total loss': 0.40726705430669413}
2022-12-31 12:12:43,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:43,304 INFO:     Epoch: 16
2022-12-31 12:12:44,912 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4122926354408264, 'Total loss': 0.4122926354408264} | train loss {'Reaction outcome loss': 0.40313961531669984, 'Total loss': 0.40313961531669984}
2022-12-31 12:12:44,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:44,912 INFO:     Epoch: 17
2022-12-31 12:12:46,524 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.397404208779335, 'Total loss': 0.397404208779335} | train loss {'Reaction outcome loss': 0.4011112533179044, 'Total loss': 0.4011112533179044}
2022-12-31 12:12:46,525 INFO:     Found new best model at epoch 17
2022-12-31 12:12:46,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:46,526 INFO:     Epoch: 18
2022-12-31 12:12:48,128 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4164924840132395, 'Total loss': 0.4164924840132395} | train loss {'Reaction outcome loss': 0.394840338581623, 'Total loss': 0.394840338581623}
2022-12-31 12:12:48,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:48,129 INFO:     Epoch: 19
2022-12-31 12:12:49,771 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4077767829100291, 'Total loss': 0.4077767829100291} | train loss {'Reaction outcome loss': 0.3892571088736472, 'Total loss': 0.3892571088736472}
2022-12-31 12:12:49,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:49,771 INFO:     Epoch: 20
2022-12-31 12:12:51,411 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39473903576533, 'Total loss': 0.39473903576533} | train loss {'Reaction outcome loss': 0.39112535717330227, 'Total loss': 0.39112535717330227}
2022-12-31 12:12:51,411 INFO:     Found new best model at epoch 20
2022-12-31 12:12:51,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:51,412 INFO:     Epoch: 21
2022-12-31 12:12:53,045 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3722363794843356, 'Total loss': 0.3722363794843356} | train loss {'Reaction outcome loss': 0.3777235731266547, 'Total loss': 0.3777235731266547}
2022-12-31 12:12:53,046 INFO:     Found new best model at epoch 21
2022-12-31 12:12:53,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:53,047 INFO:     Epoch: 22
2022-12-31 12:12:54,669 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.379109005133311, 'Total loss': 0.379109005133311} | train loss {'Reaction outcome loss': 0.389490322624097, 'Total loss': 0.389490322624097}
2022-12-31 12:12:54,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:54,669 INFO:     Epoch: 23
2022-12-31 12:12:56,259 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3911596645911535, 'Total loss': 0.3911596645911535} | train loss {'Reaction outcome loss': 0.36372765794436895, 'Total loss': 0.36372765794436895}
2022-12-31 12:12:56,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:56,259 INFO:     Epoch: 24
2022-12-31 12:12:57,868 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39689016044139863, 'Total loss': 0.39689016044139863} | train loss {'Reaction outcome loss': 0.36403962601300166, 'Total loss': 0.36403962601300166}
2022-12-31 12:12:57,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:57,868 INFO:     Epoch: 25
2022-12-31 12:12:59,479 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3876687467098236, 'Total loss': 0.3876687467098236} | train loss {'Reaction outcome loss': 0.3551374198598922, 'Total loss': 0.3551374198598922}
2022-12-31 12:12:59,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:12:59,479 INFO:     Epoch: 26
2022-12-31 12:13:01,089 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43827959299087527, 'Total loss': 0.43827959299087527} | train loss {'Reaction outcome loss': 0.3530212222409529, 'Total loss': 0.3530212222409529}
2022-12-31 12:13:01,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:01,089 INFO:     Epoch: 27
2022-12-31 12:13:02,699 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3995309998591741, 'Total loss': 0.3995309998591741} | train loss {'Reaction outcome loss': 0.35011427100423886, 'Total loss': 0.35011427100423886}
2022-12-31 12:13:02,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:02,699 INFO:     Epoch: 28
2022-12-31 12:13:04,289 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3659598410129547, 'Total loss': 0.3659598410129547} | train loss {'Reaction outcome loss': 0.3461657430085799, 'Total loss': 0.3461657430085799}
2022-12-31 12:13:04,290 INFO:     Found new best model at epoch 28
2022-12-31 12:13:04,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:04,291 INFO:     Epoch: 29
2022-12-31 12:13:05,894 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37968691686789197, 'Total loss': 0.37968691686789197} | train loss {'Reaction outcome loss': 0.34191489617502235, 'Total loss': 0.34191489617502235}
2022-12-31 12:13:05,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:05,895 INFO:     Epoch: 30
2022-12-31 12:13:07,480 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41933030982812247, 'Total loss': 0.41933030982812247} | train loss {'Reaction outcome loss': 0.3356340815923919, 'Total loss': 0.3356340815923919}
2022-12-31 12:13:07,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:07,480 INFO:     Epoch: 31
2022-12-31 12:13:09,125 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38224302728970844, 'Total loss': 0.38224302728970844} | train loss {'Reaction outcome loss': 0.3353280317362236, 'Total loss': 0.3353280317362236}
2022-12-31 12:13:09,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:09,126 INFO:     Epoch: 32
2022-12-31 12:13:10,713 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3747571736574173, 'Total loss': 0.3747571736574173} | train loss {'Reaction outcome loss': 0.3307828907787368, 'Total loss': 0.3307828907787368}
2022-12-31 12:13:10,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:10,713 INFO:     Epoch: 33
2022-12-31 12:13:12,347 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36654765804608663, 'Total loss': 0.36654765804608663} | train loss {'Reaction outcome loss': 0.32364196973848613, 'Total loss': 0.32364196973848613}
2022-12-31 12:13:12,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:12,348 INFO:     Epoch: 34
2022-12-31 12:13:13,921 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35368950565656027, 'Total loss': 0.35368950565656027} | train loss {'Reaction outcome loss': 0.31544197033192334, 'Total loss': 0.31544197033192334}
2022-12-31 12:13:13,921 INFO:     Found new best model at epoch 34
2022-12-31 12:13:13,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:13,922 INFO:     Epoch: 35
2022-12-31 12:13:15,533 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3359399437904358, 'Total loss': 0.3359399437904358} | train loss {'Reaction outcome loss': 0.3104364984886991, 'Total loss': 0.3104364984886991}
2022-12-31 12:13:15,533 INFO:     Found new best model at epoch 35
2022-12-31 12:13:15,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:15,534 INFO:     Epoch: 36
2022-12-31 12:13:17,142 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3465415279070536, 'Total loss': 0.3465415279070536} | train loss {'Reaction outcome loss': 0.3102148459225461, 'Total loss': 0.3102148459225461}
2022-12-31 12:13:17,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:17,142 INFO:     Epoch: 37
2022-12-31 12:13:18,787 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3449156577388445, 'Total loss': 0.3449156577388445} | train loss {'Reaction outcome loss': 0.30590579189036204, 'Total loss': 0.30590579189036204}
2022-12-31 12:13:18,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:18,788 INFO:     Epoch: 38
2022-12-31 12:13:20,437 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3797955890496572, 'Total loss': 0.3797955890496572} | train loss {'Reaction outcome loss': 0.3068127270140078, 'Total loss': 0.3068127270140078}
2022-12-31 12:13:20,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:20,437 INFO:     Epoch: 39
2022-12-31 12:13:22,042 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3522940968473752, 'Total loss': 0.3522940968473752} | train loss {'Reaction outcome loss': 0.3015081080280336, 'Total loss': 0.3015081080280336}
2022-12-31 12:13:22,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:22,042 INFO:     Epoch: 40
2022-12-31 12:13:23,632 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3678720350066821, 'Total loss': 0.3678720350066821} | train loss {'Reaction outcome loss': 0.29776865332889324, 'Total loss': 0.29776865332889324}
2022-12-31 12:13:23,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:23,633 INFO:     Epoch: 41
2022-12-31 12:13:25,243 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.32874920666217805, 'Total loss': 0.32874920666217805} | train loss {'Reaction outcome loss': 0.2976606718398018, 'Total loss': 0.2976606718398018}
2022-12-31 12:13:25,243 INFO:     Found new best model at epoch 41
2022-12-31 12:13:25,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:25,244 INFO:     Epoch: 42
2022-12-31 12:13:26,877 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3330252135793368, 'Total loss': 0.3330252135793368} | train loss {'Reaction outcome loss': 0.2885209348835591, 'Total loss': 0.2885209348835591}
2022-12-31 12:13:26,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:26,878 INFO:     Epoch: 43
2022-12-31 12:13:28,496 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.32737280428409576, 'Total loss': 0.32737280428409576} | train loss {'Reaction outcome loss': 0.2805151267017683, 'Total loss': 0.2805151267017683}
2022-12-31 12:13:28,496 INFO:     Found new best model at epoch 43
2022-12-31 12:13:28,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:28,497 INFO:     Epoch: 44
2022-12-31 12:13:30,107 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3192475865284602, 'Total loss': 0.3192475865284602} | train loss {'Reaction outcome loss': 0.2808366984581749, 'Total loss': 0.2808366984581749}
2022-12-31 12:13:30,107 INFO:     Found new best model at epoch 44
2022-12-31 12:13:30,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:30,108 INFO:     Epoch: 45
2022-12-31 12:13:31,703 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35872843662897747, 'Total loss': 0.35872843662897747} | train loss {'Reaction outcome loss': 0.27956018426187296, 'Total loss': 0.27956018426187296}
2022-12-31 12:13:31,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:31,703 INFO:     Epoch: 46
2022-12-31 12:13:33,335 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34687985529502235, 'Total loss': 0.34687985529502235} | train loss {'Reaction outcome loss': 0.2834852454657464, 'Total loss': 0.2834852454657464}
2022-12-31 12:13:33,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:33,335 INFO:     Epoch: 47
2022-12-31 12:13:34,968 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3482414518793424, 'Total loss': 0.3482414518793424} | train loss {'Reaction outcome loss': 0.2700495072707966, 'Total loss': 0.2700495072707966}
2022-12-31 12:13:34,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:34,968 INFO:     Epoch: 48
2022-12-31 12:13:36,621 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.33188993657628696, 'Total loss': 0.33188993657628696} | train loss {'Reaction outcome loss': 0.26980094452000747, 'Total loss': 0.26980094452000747}
2022-12-31 12:13:36,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:36,621 INFO:     Epoch: 49
2022-12-31 12:13:38,238 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38517524898052213, 'Total loss': 0.38517524898052213} | train loss {'Reaction outcome loss': 0.268088159961221, 'Total loss': 0.268088159961221}
2022-12-31 12:13:38,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:38,238 INFO:     Epoch: 50
2022-12-31 12:13:39,870 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3577926297982534, 'Total loss': 0.3577926297982534} | train loss {'Reaction outcome loss': 0.27756074801141367, 'Total loss': 0.27756074801141367}
2022-12-31 12:13:39,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:39,870 INFO:     Epoch: 51
2022-12-31 12:13:41,449 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3849572201569875, 'Total loss': 0.3849572201569875} | train loss {'Reaction outcome loss': 0.32910550727198523, 'Total loss': 0.32910550727198523}
2022-12-31 12:13:41,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:41,449 INFO:     Epoch: 52
2022-12-31 12:13:43,088 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3652563194433848, 'Total loss': 0.3652563194433848} | train loss {'Reaction outcome loss': 0.289924395134331, 'Total loss': 0.289924395134331}
2022-12-31 12:13:43,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:43,089 INFO:     Epoch: 53
2022-12-31 12:13:44,741 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39012496223052345, 'Total loss': 0.39012496223052345} | train loss {'Reaction outcome loss': 0.2739603851105262, 'Total loss': 0.2739603851105262}
2022-12-31 12:13:44,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:44,742 INFO:     Epoch: 54
2022-12-31 12:13:46,361 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37927879095077516, 'Total loss': 0.37927879095077516} | train loss {'Reaction outcome loss': 0.26593550871262595, 'Total loss': 0.26593550871262595}
2022-12-31 12:13:46,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:46,362 INFO:     Epoch: 55
2022-12-31 12:13:47,965 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.34110436340173084, 'Total loss': 0.34110436340173084} | train loss {'Reaction outcome loss': 0.263967820185391, 'Total loss': 0.263967820185391}
2022-12-31 12:13:47,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:47,965 INFO:     Epoch: 56
2022-12-31 12:13:49,547 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.33901391724745433, 'Total loss': 0.33901391724745433} | train loss {'Reaction outcome loss': 0.260381513864875, 'Total loss': 0.260381513864875}
2022-12-31 12:13:49,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:49,548 INFO:     Epoch: 57
2022-12-31 12:13:51,163 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.34798726439476013, 'Total loss': 0.34798726439476013} | train loss {'Reaction outcome loss': 0.2522597718120053, 'Total loss': 0.2522597718120053}
2022-12-31 12:13:51,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:51,163 INFO:     Epoch: 58
2022-12-31 12:13:52,770 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35724452435970305, 'Total loss': 0.35724452435970305} | train loss {'Reaction outcome loss': 0.24995098965988238, 'Total loss': 0.24995098965988238}
2022-12-31 12:13:52,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:52,771 INFO:     Epoch: 59
2022-12-31 12:13:54,384 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3767499705155691, 'Total loss': 0.3767499705155691} | train loss {'Reaction outcome loss': 0.24948485681038027, 'Total loss': 0.24948485681038027}
2022-12-31 12:13:54,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:54,384 INFO:     Epoch: 60
2022-12-31 12:13:55,999 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34015649457772573, 'Total loss': 0.34015649457772573} | train loss {'Reaction outcome loss': 0.250199512389583, 'Total loss': 0.250199512389583}
2022-12-31 12:13:55,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:55,999 INFO:     Epoch: 61
2022-12-31 12:13:57,613 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3625380357106527, 'Total loss': 0.3625380357106527} | train loss {'Reaction outcome loss': 0.255053662636783, 'Total loss': 0.255053662636783}
2022-12-31 12:13:57,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:57,613 INFO:     Epoch: 62
2022-12-31 12:13:59,181 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3889644940694173, 'Total loss': 0.3889644940694173} | train loss {'Reaction outcome loss': 0.2418500356029983, 'Total loss': 0.2418500356029983}
2022-12-31 12:13:59,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:13:59,182 INFO:     Epoch: 63
2022-12-31 12:14:00,794 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35688486297925315, 'Total loss': 0.35688486297925315} | train loss {'Reaction outcome loss': 0.24332233930033617, 'Total loss': 0.24332233930033617}
2022-12-31 12:14:00,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:00,794 INFO:     Epoch: 64
2022-12-31 12:14:02,409 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35231874709328015, 'Total loss': 0.35231874709328015} | train loss {'Reaction outcome loss': 0.24005313242450674, 'Total loss': 0.24005313242450674}
2022-12-31 12:14:02,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:02,409 INFO:     Epoch: 65
2022-12-31 12:14:04,024 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36765927573045093, 'Total loss': 0.36765927573045093} | train loss {'Reaction outcome loss': 0.2360349700075871, 'Total loss': 0.2360349700075871}
2022-12-31 12:14:04,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:04,025 INFO:     Epoch: 66
2022-12-31 12:14:05,640 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3643015811840693, 'Total loss': 0.3643015811840693} | train loss {'Reaction outcome loss': 0.23893473997610482, 'Total loss': 0.23893473997610482}
2022-12-31 12:14:05,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:05,641 INFO:     Epoch: 67
2022-12-31 12:14:07,256 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3447808394829432, 'Total loss': 0.3447808394829432} | train loss {'Reaction outcome loss': 0.23631706285727822, 'Total loss': 0.23631706285727822}
2022-12-31 12:14:07,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:07,257 INFO:     Epoch: 68
2022-12-31 12:14:08,832 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36903547048568724, 'Total loss': 0.36903547048568724} | train loss {'Reaction outcome loss': 0.2360694978463774, 'Total loss': 0.2360694978463774}
2022-12-31 12:14:08,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:08,832 INFO:     Epoch: 69
2022-12-31 12:14:10,446 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.360888068874677, 'Total loss': 0.360888068874677} | train loss {'Reaction outcome loss': 0.22782028290321646, 'Total loss': 0.22782028290321646}
2022-12-31 12:14:10,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:10,446 INFO:     Epoch: 70
2022-12-31 12:14:12,061 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36091023981571196, 'Total loss': 0.36091023981571196} | train loss {'Reaction outcome loss': 0.2280732307768578, 'Total loss': 0.2280732307768578}
2022-12-31 12:14:12,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:12,061 INFO:     Epoch: 71
2022-12-31 12:14:13,678 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.347820795327425, 'Total loss': 0.347820795327425} | train loss {'Reaction outcome loss': 0.22117127569399073, 'Total loss': 0.22117127569399073}
2022-12-31 12:14:13,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:13,678 INFO:     Epoch: 72
2022-12-31 12:14:15,289 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3196348706881205, 'Total loss': 0.3196348706881205} | train loss {'Reaction outcome loss': 0.22946957372587876, 'Total loss': 0.22946957372587876}
2022-12-31 12:14:15,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:15,289 INFO:     Epoch: 73
2022-12-31 12:14:16,878 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3704476336638133, 'Total loss': 0.3704476336638133} | train loss {'Reaction outcome loss': 0.2544016167251528, 'Total loss': 0.2544016167251528}
2022-12-31 12:14:16,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:16,879 INFO:     Epoch: 74
2022-12-31 12:14:18,500 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3671513040860494, 'Total loss': 0.3671513040860494} | train loss {'Reaction outcome loss': 0.23329110373405443, 'Total loss': 0.23329110373405443}
2022-12-31 12:14:18,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:18,501 INFO:     Epoch: 75
2022-12-31 12:14:20,114 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.31836872895558677, 'Total loss': 0.31836872895558677} | train loss {'Reaction outcome loss': 0.22881827307243502, 'Total loss': 0.22881827307243502}
2022-12-31 12:14:20,114 INFO:     Found new best model at epoch 75
2022-12-31 12:14:20,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:20,115 INFO:     Epoch: 76
2022-12-31 12:14:21,744 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36731297969818116, 'Total loss': 0.36731297969818116} | train loss {'Reaction outcome loss': 0.22560006542387756, 'Total loss': 0.22560006542387756}
2022-12-31 12:14:21,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:21,745 INFO:     Epoch: 77
2022-12-31 12:14:23,363 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.33601951599121094, 'Total loss': 0.33601951599121094} | train loss {'Reaction outcome loss': 0.22541314702939944, 'Total loss': 0.22541314702939944}
2022-12-31 12:14:23,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:23,364 INFO:     Epoch: 78
2022-12-31 12:14:24,981 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.381602784494559, 'Total loss': 0.381602784494559} | train loss {'Reaction outcome loss': 0.22020128176001785, 'Total loss': 0.22020128176001785}
2022-12-31 12:14:24,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:24,981 INFO:     Epoch: 79
2022-12-31 12:14:26,565 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3517652908960978, 'Total loss': 0.3517652908960978} | train loss {'Reaction outcome loss': 0.22196930455232877, 'Total loss': 0.22196930455232877}
2022-12-31 12:14:26,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:26,565 INFO:     Epoch: 80
2022-12-31 12:14:28,182 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3540400346120199, 'Total loss': 0.3540400346120199} | train loss {'Reaction outcome loss': 0.23157118813580144, 'Total loss': 0.23157118813580144}
2022-12-31 12:14:28,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:28,183 INFO:     Epoch: 81
2022-12-31 12:14:29,798 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36892364819844564, 'Total loss': 0.36892364819844564} | train loss {'Reaction outcome loss': 0.23456466661182407, 'Total loss': 0.23456466661182407}
2022-12-31 12:14:29,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:29,799 INFO:     Epoch: 82
2022-12-31 12:14:31,417 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.30700985838969547, 'Total loss': 0.30700985838969547} | train loss {'Reaction outcome loss': 0.21815693501275088, 'Total loss': 0.21815693501275088}
2022-12-31 12:14:31,417 INFO:     Found new best model at epoch 82
2022-12-31 12:14:31,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:31,418 INFO:     Epoch: 83
2022-12-31 12:14:33,057 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3332980441550414, 'Total loss': 0.3332980441550414} | train loss {'Reaction outcome loss': 0.21098990579807636, 'Total loss': 0.21098990579807636}
2022-12-31 12:14:33,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:33,057 INFO:     Epoch: 84
2022-12-31 12:14:34,677 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.34388954093058904, 'Total loss': 0.34388954093058904} | train loss {'Reaction outcome loss': 0.21107243439874382, 'Total loss': 0.21107243439874382}
2022-12-31 12:14:34,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:34,678 INFO:     Epoch: 85
2022-12-31 12:14:36,280 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3614846676588058, 'Total loss': 0.3614846676588058} | train loss {'Reaction outcome loss': 0.20558169746808466, 'Total loss': 0.20558169746808466}
2022-12-31 12:14:36,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:36,280 INFO:     Epoch: 86
2022-12-31 12:14:37,931 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3460667639970779, 'Total loss': 0.3460667639970779} | train loss {'Reaction outcome loss': 0.207150608027418, 'Total loss': 0.207150608027418}
2022-12-31 12:14:37,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:37,931 INFO:     Epoch: 87
2022-12-31 12:14:39,546 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.31465628842512766, 'Total loss': 0.31465628842512766} | train loss {'Reaction outcome loss': 0.20986522471598026, 'Total loss': 0.20986522471598026}
2022-12-31 12:14:39,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:39,546 INFO:     Epoch: 88
2022-12-31 12:14:41,161 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3670702278614044, 'Total loss': 0.3670702278614044} | train loss {'Reaction outcome loss': 0.2179320806340463, 'Total loss': 0.2179320806340463}
2022-12-31 12:14:41,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:41,162 INFO:     Epoch: 89
2022-12-31 12:14:42,776 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40398402214050294, 'Total loss': 0.40398402214050294} | train loss {'Reaction outcome loss': 0.30393556890118384, 'Total loss': 0.30393556890118384}
2022-12-31 12:14:42,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:42,777 INFO:     Epoch: 90
2022-12-31 12:14:44,358 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36630034148693086, 'Total loss': 0.36630034148693086} | train loss {'Reaction outcome loss': 0.30206413515775965, 'Total loss': 0.30206413515775965}
2022-12-31 12:14:44,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:44,358 INFO:     Epoch: 91
2022-12-31 12:14:45,993 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36748891572157544, 'Total loss': 0.36748891572157544} | train loss {'Reaction outcome loss': 0.2640695524506568, 'Total loss': 0.2640695524506568}
2022-12-31 12:14:45,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:45,994 INFO:     Epoch: 92
2022-12-31 12:14:47,648 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3253690481185913, 'Total loss': 0.3253690481185913} | train loss {'Reaction outcome loss': 0.2372831846880507, 'Total loss': 0.2372831846880507}
2022-12-31 12:14:47,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:47,648 INFO:     Epoch: 93
2022-12-31 12:14:49,265 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3467596252759298, 'Total loss': 0.3467596252759298} | train loss {'Reaction outcome loss': 0.23106712914929065, 'Total loss': 0.23106712914929065}
2022-12-31 12:14:49,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:49,265 INFO:     Epoch: 94
2022-12-31 12:14:50,876 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39187755684057873, 'Total loss': 0.39187755684057873} | train loss {'Reaction outcome loss': 0.23259003827537317, 'Total loss': 0.23259003827537317}
2022-12-31 12:14:50,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:50,876 INFO:     Epoch: 95
2022-12-31 12:14:52,484 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3645549659927686, 'Total loss': 0.3645549659927686} | train loss {'Reaction outcome loss': 0.238097957831443, 'Total loss': 0.238097957831443}
2022-12-31 12:14:52,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:52,484 INFO:     Epoch: 96
2022-12-31 12:14:54,068 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3716219445069631, 'Total loss': 0.3716219445069631} | train loss {'Reaction outcome loss': 0.2207885597540619, 'Total loss': 0.2207885597540619}
2022-12-31 12:14:54,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:54,069 INFO:     Epoch: 97
2022-12-31 12:14:55,678 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3444894254207611, 'Total loss': 0.3444894254207611} | train loss {'Reaction outcome loss': 0.22105424679086907, 'Total loss': 0.22105424679086907}
2022-12-31 12:14:55,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:55,678 INFO:     Epoch: 98
2022-12-31 12:14:57,287 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3598441700140635, 'Total loss': 0.3598441700140635} | train loss {'Reaction outcome loss': 0.22212305323109435, 'Total loss': 0.22212305323109435}
2022-12-31 12:14:57,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:57,288 INFO:     Epoch: 99
2022-12-31 12:14:58,897 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.321552108724912, 'Total loss': 0.321552108724912} | train loss {'Reaction outcome loss': 0.22158038889756426, 'Total loss': 0.22158038889756426}
2022-12-31 12:14:58,897 INFO:     Best model found after epoch 83 of 100.
2022-12-31 12:14:58,897 INFO:   Done with stage: TRAINING
2022-12-31 12:14:58,897 INFO:   Starting stage: EVALUATION
2022-12-31 12:14:59,026 INFO:   Done with stage: EVALUATION
2022-12-31 12:14:59,026 INFO:   Leaving out SEQ value Fold_1
2022-12-31 12:14:59,039 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 12:14:59,039 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:14:59,695 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:14:59,696 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:14:59,764 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:14:59,764 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:14:59,764 INFO:     No hyperparam tuning for this model
2022-12-31 12:14:59,764 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:14:59,764 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:14:59,765 INFO:     None feature selector for col prot
2022-12-31 12:14:59,765 INFO:     None feature selector for col prot
2022-12-31 12:14:59,765 INFO:     None feature selector for col prot
2022-12-31 12:14:59,766 INFO:     None feature selector for col chem
2022-12-31 12:14:59,766 INFO:     None feature selector for col chem
2022-12-31 12:14:59,766 INFO:     None feature selector for col chem
2022-12-31 12:14:59,766 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:14:59,766 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:14:59,768 INFO:     Number of params in model 223921
2022-12-31 12:14:59,771 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:14:59,771 INFO:   Starting stage: TRAINING
2022-12-31 12:14:59,818 INFO:     Val loss before train {'Reaction outcome loss': 1.0102998296419778, 'Total loss': 1.0102998296419778}
2022-12-31 12:14:59,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:14:59,818 INFO:     Epoch: 0
2022-12-31 12:15:01,426 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7050132910410564, 'Total loss': 0.7050132910410564} | train loss {'Reaction outcome loss': 0.8359958554307619, 'Total loss': 0.8359958554307619}
2022-12-31 12:15:01,426 INFO:     Found new best model at epoch 0
2022-12-31 12:15:01,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:01,427 INFO:     Epoch: 1
2022-12-31 12:15:03,021 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5585578650236129, 'Total loss': 0.5585578650236129} | train loss {'Reaction outcome loss': 0.6192112003547557, 'Total loss': 0.6192112003547557}
2022-12-31 12:15:03,021 INFO:     Found new best model at epoch 1
2022-12-31 12:15:03,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:03,022 INFO:     Epoch: 2
2022-12-31 12:15:04,630 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48397491375605267, 'Total loss': 0.48397491375605267} | train loss {'Reaction outcome loss': 0.5343797237260234, 'Total loss': 0.5343797237260234}
2022-12-31 12:15:04,630 INFO:     Found new best model at epoch 2
2022-12-31 12:15:04,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:04,631 INFO:     Epoch: 3
2022-12-31 12:15:06,238 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.513772181669871, 'Total loss': 0.513772181669871} | train loss {'Reaction outcome loss': 0.5075236724831326, 'Total loss': 0.5075236724831326}
2022-12-31 12:15:06,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:06,240 INFO:     Epoch: 4
2022-12-31 12:15:07,880 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4602985163529714, 'Total loss': 0.4602985163529714} | train loss {'Reaction outcome loss': 0.489218871217167, 'Total loss': 0.489218871217167}
2022-12-31 12:15:07,880 INFO:     Found new best model at epoch 4
2022-12-31 12:15:07,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:07,881 INFO:     Epoch: 5
2022-12-31 12:15:09,495 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44873046477635703, 'Total loss': 0.44873046477635703} | train loss {'Reaction outcome loss': 0.47870141012000217, 'Total loss': 0.47870141012000217}
2022-12-31 12:15:09,495 INFO:     Found new best model at epoch 5
2022-12-31 12:15:09,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:09,496 INFO:     Epoch: 6
2022-12-31 12:15:11,075 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4596734801928202, 'Total loss': 0.4596734801928202} | train loss {'Reaction outcome loss': 0.4693772916548039, 'Total loss': 0.4693772916548039}
2022-12-31 12:15:11,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:11,075 INFO:     Epoch: 7
2022-12-31 12:15:12,699 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4909136136372884, 'Total loss': 0.4909136136372884} | train loss {'Reaction outcome loss': 0.46163452168305713, 'Total loss': 0.46163452168305713}
2022-12-31 12:15:12,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:12,700 INFO:     Epoch: 8
2022-12-31 12:15:14,306 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44122015734513603, 'Total loss': 0.44122015734513603} | train loss {'Reaction outcome loss': 0.4626533063466026, 'Total loss': 0.4626533063466026}
2022-12-31 12:15:14,306 INFO:     Found new best model at epoch 8
2022-12-31 12:15:14,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:14,307 INFO:     Epoch: 9
2022-12-31 12:15:15,914 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4782056093215942, 'Total loss': 0.4782056093215942} | train loss {'Reaction outcome loss': 0.4475229702943909, 'Total loss': 0.4475229702943909}
2022-12-31 12:15:15,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:15,914 INFO:     Epoch: 10
2022-12-31 12:15:17,523 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4551648885011673, 'Total loss': 0.4551648885011673} | train loss {'Reaction outcome loss': 0.440225815464594, 'Total loss': 0.440225815464594}
2022-12-31 12:15:17,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:17,523 INFO:     Epoch: 11
2022-12-31 12:15:19,133 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4471161991357803, 'Total loss': 0.4471161991357803} | train loss {'Reaction outcome loss': 0.43591020279732684, 'Total loss': 0.43591020279732684}
2022-12-31 12:15:19,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:19,133 INFO:     Epoch: 12
2022-12-31 12:15:20,716 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4890266001224518, 'Total loss': 0.4890266001224518} | train loss {'Reaction outcome loss': 0.4290511519960263, 'Total loss': 0.4290511519960263}
2022-12-31 12:15:20,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:20,717 INFO:     Epoch: 13
2022-12-31 12:15:22,348 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4121238092581431, 'Total loss': 0.4121238092581431} | train loss {'Reaction outcome loss': 0.4260291926591468, 'Total loss': 0.4260291926591468}
2022-12-31 12:15:22,349 INFO:     Found new best model at epoch 13
2022-12-31 12:15:22,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:22,350 INFO:     Epoch: 14
2022-12-31 12:15:23,960 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44069323539733884, 'Total loss': 0.44069323539733884} | train loss {'Reaction outcome loss': 0.4176037619801481, 'Total loss': 0.4176037619801481}
2022-12-31 12:15:23,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:23,960 INFO:     Epoch: 15
2022-12-31 12:15:25,569 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4278357287247976, 'Total loss': 0.4278357287247976} | train loss {'Reaction outcome loss': 0.41342298647108744, 'Total loss': 0.41342298647108744}
2022-12-31 12:15:25,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:25,570 INFO:     Epoch: 16
2022-12-31 12:15:27,175 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43967138330141703, 'Total loss': 0.43967138330141703} | train loss {'Reaction outcome loss': 0.4094387915363346, 'Total loss': 0.4094387915363346}
2022-12-31 12:15:27,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:27,175 INFO:     Epoch: 17
2022-12-31 12:15:28,802 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43637144565582275, 'Total loss': 0.43637144565582275} | train loss {'Reaction outcome loss': 0.4158590435171905, 'Total loss': 0.4158590435171905}
2022-12-31 12:15:28,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:28,802 INFO:     Epoch: 18
2022-12-31 12:15:30,396 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42274638811747234, 'Total loss': 0.42274638811747234} | train loss {'Reaction outcome loss': 0.40009637344358623, 'Total loss': 0.40009637344358623}
2022-12-31 12:15:30,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:30,396 INFO:     Epoch: 19
2022-12-31 12:15:32,006 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41241250932216644, 'Total loss': 0.41241250932216644} | train loss {'Reaction outcome loss': 0.4043254785550137, 'Total loss': 0.4043254785550137}
2022-12-31 12:15:32,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:32,006 INFO:     Epoch: 20
2022-12-31 12:15:33,616 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4123525728782018, 'Total loss': 0.4123525728782018} | train loss {'Reaction outcome loss': 0.383329303017345, 'Total loss': 0.383329303017345}
2022-12-31 12:15:33,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:33,617 INFO:     Epoch: 21
2022-12-31 12:15:35,227 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3908597379922867, 'Total loss': 0.3908597379922867} | train loss {'Reaction outcome loss': 0.3805323082175902, 'Total loss': 0.3805323082175902}
2022-12-31 12:15:35,227 INFO:     Found new best model at epoch 21
2022-12-31 12:15:35,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:35,228 INFO:     Epoch: 22
2022-12-31 12:15:36,838 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40722189048926033, 'Total loss': 0.40722189048926033} | train loss {'Reaction outcome loss': 0.3711721245258493, 'Total loss': 0.3711721245258493}
2022-12-31 12:15:36,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:36,838 INFO:     Epoch: 23
2022-12-31 12:15:38,410 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4074976752201716, 'Total loss': 0.4074976752201716} | train loss {'Reaction outcome loss': 0.3678411541526578, 'Total loss': 0.3678411541526578}
2022-12-31 12:15:38,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:38,410 INFO:     Epoch: 24
2022-12-31 12:15:40,018 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4122976114352544, 'Total loss': 0.4122976114352544} | train loss {'Reaction outcome loss': 0.36606116070512484, 'Total loss': 0.36606116070512484}
2022-12-31 12:15:40,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:40,019 INFO:     Epoch: 25
2022-12-31 12:15:41,628 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4175258209307989, 'Total loss': 0.4175258209307989} | train loss {'Reaction outcome loss': 0.36013512283671595, 'Total loss': 0.36013512283671595}
2022-12-31 12:15:41,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:41,629 INFO:     Epoch: 26
2022-12-31 12:15:43,238 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3794784635305405, 'Total loss': 0.3794784635305405} | train loss {'Reaction outcome loss': 0.3688445769358372, 'Total loss': 0.3688445769358372}
2022-12-31 12:15:43,238 INFO:     Found new best model at epoch 26
2022-12-31 12:15:43,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:43,239 INFO:     Epoch: 27
2022-12-31 12:15:44,847 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4085237850745519, 'Total loss': 0.4085237850745519} | train loss {'Reaction outcome loss': 0.36259906134986575, 'Total loss': 0.36259906134986575}
2022-12-31 12:15:44,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:44,847 INFO:     Epoch: 28
2022-12-31 12:15:46,454 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4064926207065582, 'Total loss': 0.4064926207065582} | train loss {'Reaction outcome loss': 0.3657115587991649, 'Total loss': 0.3657115587991649}
2022-12-31 12:15:46,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:46,455 INFO:     Epoch: 29
2022-12-31 12:15:48,044 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3883166511853536, 'Total loss': 0.3883166511853536} | train loss {'Reaction outcome loss': 0.3549502734769993, 'Total loss': 0.3549502734769993}
2022-12-31 12:15:48,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:48,045 INFO:     Epoch: 30
2022-12-31 12:15:49,696 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4051218807697296, 'Total loss': 0.4051218807697296} | train loss {'Reaction outcome loss': 0.3401827872419718, 'Total loss': 0.3401827872419718}
2022-12-31 12:15:49,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:49,696 INFO:     Epoch: 31
2022-12-31 12:15:51,310 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42700950503349305, 'Total loss': 0.42700950503349305} | train loss {'Reaction outcome loss': 0.32656904867774533, 'Total loss': 0.32656904867774533}
2022-12-31 12:15:51,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:51,310 INFO:     Epoch: 32
2022-12-31 12:15:52,920 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39594367345174153, 'Total loss': 0.39594367345174153} | train loss {'Reaction outcome loss': 0.3223521884638762, 'Total loss': 0.3223521884638762}
2022-12-31 12:15:52,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:52,920 INFO:     Epoch: 33
2022-12-31 12:15:54,529 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3645875712235769, 'Total loss': 0.3645875712235769} | train loss {'Reaction outcome loss': 0.32482200224878227, 'Total loss': 0.32482200224878227}
2022-12-31 12:15:54,530 INFO:     Found new best model at epoch 33
2022-12-31 12:15:54,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:54,531 INFO:     Epoch: 34
2022-12-31 12:15:56,109 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39147361516952517, 'Total loss': 0.39147361516952517} | train loss {'Reaction outcome loss': 0.3141539277739998, 'Total loss': 0.3141539277739998}
2022-12-31 12:15:56,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:56,109 INFO:     Epoch: 35
2022-12-31 12:15:57,751 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.436888313293457, 'Total loss': 0.436888313293457} | train loss {'Reaction outcome loss': 0.3239846698183944, 'Total loss': 0.3239846698183944}
2022-12-31 12:15:57,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:57,751 INFO:     Epoch: 36
2022-12-31 12:15:59,397 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41057409743467965, 'Total loss': 0.41057409743467965} | train loss {'Reaction outcome loss': 0.3316185701287527, 'Total loss': 0.3316185701287527}
2022-12-31 12:15:59,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:15:59,397 INFO:     Epoch: 37
2022-12-31 12:16:01,052 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40594801505406697, 'Total loss': 0.40594801505406697} | train loss {'Reaction outcome loss': 0.3170751634499301, 'Total loss': 0.3170751634499301}
2022-12-31 12:16:01,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:01,053 INFO:     Epoch: 38
2022-12-31 12:16:02,675 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4162173976500829, 'Total loss': 0.4162173976500829} | train loss {'Reaction outcome loss': 0.3167881126723512, 'Total loss': 0.3167881126723512}
2022-12-31 12:16:02,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:02,676 INFO:     Epoch: 39
2022-12-31 12:16:04,297 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40894402662913004, 'Total loss': 0.40894402662913004} | train loss {'Reaction outcome loss': 0.3062665734939493, 'Total loss': 0.3062665734939493}
2022-12-31 12:16:04,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:04,298 INFO:     Epoch: 40
2022-12-31 12:16:05,893 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39594752391179405, 'Total loss': 0.39594752391179405} | train loss {'Reaction outcome loss': 0.3224078240682897, 'Total loss': 0.3224078240682897}
2022-12-31 12:16:05,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:05,893 INFO:     Epoch: 41
2022-12-31 12:16:07,507 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41185847520828245, 'Total loss': 0.41185847520828245} | train loss {'Reaction outcome loss': 0.35990868149317634, 'Total loss': 0.35990868149317634}
2022-12-31 12:16:07,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:07,507 INFO:     Epoch: 42
2022-12-31 12:16:09,122 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3955377866824468, 'Total loss': 0.3955377866824468} | train loss {'Reaction outcome loss': 0.3058474790709822, 'Total loss': 0.3058474790709822}
2022-12-31 12:16:09,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:09,122 INFO:     Epoch: 43
2022-12-31 12:16:10,735 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4415599415699641, 'Total loss': 0.4415599415699641} | train loss {'Reaction outcome loss': 0.29655383933340607, 'Total loss': 0.29655383933340607}
2022-12-31 12:16:10,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:10,735 INFO:     Epoch: 44
2022-12-31 12:16:12,345 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3487139036258062, 'Total loss': 0.3487139036258062} | train loss {'Reaction outcome loss': 0.2897804955214994, 'Total loss': 0.2897804955214994}
2022-12-31 12:16:12,345 INFO:     Found new best model at epoch 44
2022-12-31 12:16:12,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:12,346 INFO:     Epoch: 45
2022-12-31 12:16:13,953 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38889293372631073, 'Total loss': 0.38889293372631073} | train loss {'Reaction outcome loss': 0.288073623132811, 'Total loss': 0.288073623132811}
2022-12-31 12:16:13,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:13,953 INFO:     Epoch: 46
2022-12-31 12:16:15,516 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40921558837095895, 'Total loss': 0.40921558837095895} | train loss {'Reaction outcome loss': 0.2865017483384862, 'Total loss': 0.2865017483384862}
2022-12-31 12:16:15,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:15,516 INFO:     Epoch: 47
2022-12-31 12:16:17,126 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3849118222792943, 'Total loss': 0.3849118222792943} | train loss {'Reaction outcome loss': 0.28779766753575753, 'Total loss': 0.28779766753575753}
2022-12-31 12:16:17,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:17,127 INFO:     Epoch: 48
2022-12-31 12:16:18,735 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44560799598693845, 'Total loss': 0.44560799598693845} | train loss {'Reaction outcome loss': 0.27978866091133026, 'Total loss': 0.27978866091133026}
2022-12-31 12:16:18,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:18,735 INFO:     Epoch: 49
2022-12-31 12:16:20,344 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37110959390799203, 'Total loss': 0.37110959390799203} | train loss {'Reaction outcome loss': 0.3088071345203165, 'Total loss': 0.3088071345203165}
2022-12-31 12:16:20,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:20,344 INFO:     Epoch: 50
2022-12-31 12:16:21,953 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3709639807542165, 'Total loss': 0.3709639807542165} | train loss {'Reaction outcome loss': 0.3098861449600562, 'Total loss': 0.3098861449600562}
2022-12-31 12:16:21,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:21,954 INFO:     Epoch: 51
2022-12-31 12:16:23,507 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3744281858205795, 'Total loss': 0.3744281858205795} | train loss {'Reaction outcome loss': 0.2829495568254914, 'Total loss': 0.2829495568254914}
2022-12-31 12:16:23,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:23,507 INFO:     Epoch: 52
2022-12-31 12:16:25,133 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40992762247721354, 'Total loss': 0.40992762247721354} | train loss {'Reaction outcome loss': 0.2742589726039101, 'Total loss': 0.2742589726039101}
2022-12-31 12:16:25,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:25,133 INFO:     Epoch: 53
2022-12-31 12:16:26,743 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3877433747053146, 'Total loss': 0.3877433747053146} | train loss {'Reaction outcome loss': 0.26465734633603605, 'Total loss': 0.26465734633603605}
2022-12-31 12:16:26,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:26,743 INFO:     Epoch: 54
2022-12-31 12:16:28,376 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3701645423968633, 'Total loss': 0.3701645423968633} | train loss {'Reaction outcome loss': 0.2731102551198632, 'Total loss': 0.2731102551198632}
2022-12-31 12:16:28,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:28,376 INFO:     Epoch: 55
2022-12-31 12:16:29,985 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38980387449264525, 'Total loss': 0.38980387449264525} | train loss {'Reaction outcome loss': 0.2651539969950175, 'Total loss': 0.2651539969950175}
2022-12-31 12:16:29,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:29,986 INFO:     Epoch: 56
2022-12-31 12:16:31,596 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37331317613522214, 'Total loss': 0.37331317613522214} | train loss {'Reaction outcome loss': 0.27301888023777193, 'Total loss': 0.27301888023777193}
2022-12-31 12:16:31,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:31,596 INFO:     Epoch: 57
2022-12-31 12:16:33,128 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37671726842721304, 'Total loss': 0.37671726842721304} | train loss {'Reaction outcome loss': 0.2721597311724706, 'Total loss': 0.2721597311724706}
2022-12-31 12:16:33,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:33,128 INFO:     Epoch: 58
2022-12-31 12:16:34,747 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41183046301205956, 'Total loss': 0.41183046301205956} | train loss {'Reaction outcome loss': 0.2637163688149472, 'Total loss': 0.2637163688149472}
2022-12-31 12:16:34,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:34,748 INFO:     Epoch: 59
2022-12-31 12:16:36,357 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38049652179082233, 'Total loss': 0.38049652179082233} | train loss {'Reaction outcome loss': 0.26077761661163357, 'Total loss': 0.26077761661163357}
2022-12-31 12:16:36,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:36,358 INFO:     Epoch: 60
2022-12-31 12:16:37,968 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3559187928835551, 'Total loss': 0.3559187928835551} | train loss {'Reaction outcome loss': 0.26120559335876076, 'Total loss': 0.26120559335876076}
2022-12-31 12:16:37,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:37,968 INFO:     Epoch: 61
2022-12-31 12:16:39,579 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3415953100969394, 'Total loss': 0.3415953100969394} | train loss {'Reaction outcome loss': 0.258303208766478, 'Total loss': 0.258303208766478}
2022-12-31 12:16:39,579 INFO:     Found new best model at epoch 61
2022-12-31 12:16:39,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:39,580 INFO:     Epoch: 62
2022-12-31 12:16:41,196 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38712891687949497, 'Total loss': 0.38712891687949497} | train loss {'Reaction outcome loss': 0.2503825523662786, 'Total loss': 0.2503825523662786}
2022-12-31 12:16:41,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:41,196 INFO:     Epoch: 63
2022-12-31 12:16:42,772 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3736669277151426, 'Total loss': 0.3736669277151426} | train loss {'Reaction outcome loss': 0.2765462590327513, 'Total loss': 0.2765462590327513}
2022-12-31 12:16:42,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:42,773 INFO:     Epoch: 64
2022-12-31 12:16:44,384 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3884380400180817, 'Total loss': 0.3884380400180817} | train loss {'Reaction outcome loss': 0.2915248391833249, 'Total loss': 0.2915248391833249}
2022-12-31 12:16:44,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:44,384 INFO:     Epoch: 65
2022-12-31 12:16:46,040 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3727387885252635, 'Total loss': 0.3727387885252635} | train loss {'Reaction outcome loss': 0.25552135676253535, 'Total loss': 0.25552135676253535}
2022-12-31 12:16:46,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:46,041 INFO:     Epoch: 66
2022-12-31 12:16:47,696 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3850952168305715, 'Total loss': 0.3850952168305715} | train loss {'Reaction outcome loss': 0.2521558463458728, 'Total loss': 0.2521558463458728}
2022-12-31 12:16:47,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:47,697 INFO:     Epoch: 67
2022-12-31 12:16:49,363 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36375526090463, 'Total loss': 0.36375526090463} | train loss {'Reaction outcome loss': 0.2588365725846877, 'Total loss': 0.2588365725846877}
2022-12-31 12:16:49,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:49,363 INFO:     Epoch: 68
2022-12-31 12:16:50,934 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.413490721086661, 'Total loss': 0.413490721086661} | train loss {'Reaction outcome loss': 0.24738758876818515, 'Total loss': 0.24738758876818515}
2022-12-31 12:16:50,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:50,934 INFO:     Epoch: 69
2022-12-31 12:16:52,548 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3938714991013209, 'Total loss': 0.3938714991013209} | train loss {'Reaction outcome loss': 0.2502780013968257, 'Total loss': 0.2502780013968257}
2022-12-31 12:16:52,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:52,548 INFO:     Epoch: 70
2022-12-31 12:16:54,162 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40530532201131186, 'Total loss': 0.40530532201131186} | train loss {'Reaction outcome loss': 0.24518126170912274, 'Total loss': 0.24518126170912274}
2022-12-31 12:16:54,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:54,163 INFO:     Epoch: 71
2022-12-31 12:16:55,776 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40619599918524424, 'Total loss': 0.40619599918524424} | train loss {'Reaction outcome loss': 0.2432524933230024, 'Total loss': 0.2432524933230024}
2022-12-31 12:16:55,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:55,776 INFO:     Epoch: 72
2022-12-31 12:16:57,394 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41024550596872966, 'Total loss': 0.41024550596872966} | train loss {'Reaction outcome loss': 0.2403423890759966, 'Total loss': 0.2403423890759966}
2022-12-31 12:16:57,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:57,394 INFO:     Epoch: 73
2022-12-31 12:16:59,013 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37270660847425463, 'Total loss': 0.37270660847425463} | train loss {'Reaction outcome loss': 0.24478411419956989, 'Total loss': 0.24478411419956989}
2022-12-31 12:16:59,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:16:59,013 INFO:     Epoch: 74
2022-12-31 12:17:00,574 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3925095597902934, 'Total loss': 0.3925095597902934} | train loss {'Reaction outcome loss': 0.2411914566806458, 'Total loss': 0.2411914566806458}
2022-12-31 12:17:00,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:00,575 INFO:     Epoch: 75
2022-12-31 12:17:02,223 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4037171632051468, 'Total loss': 0.4037171632051468} | train loss {'Reaction outcome loss': 0.2382674128478528, 'Total loss': 0.2382674128478528}
2022-12-31 12:17:02,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:02,223 INFO:     Epoch: 76
2022-12-31 12:17:03,883 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37981660664081573, 'Total loss': 0.37981660664081573} | train loss {'Reaction outcome loss': 0.2360209320744405, 'Total loss': 0.2360209320744405}
2022-12-31 12:17:03,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:03,883 INFO:     Epoch: 77
2022-12-31 12:17:05,498 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37308095892270404, 'Total loss': 0.37308095892270404} | train loss {'Reaction outcome loss': 0.2342861372665578, 'Total loss': 0.2342861372665578}
2022-12-31 12:17:05,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:05,498 INFO:     Epoch: 78
2022-12-31 12:17:07,118 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3816366265217463, 'Total loss': 0.3816366265217463} | train loss {'Reaction outcome loss': 0.23476061213211546, 'Total loss': 0.23476061213211546}
2022-12-31 12:17:07,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:07,119 INFO:     Epoch: 79
2022-12-31 12:17:08,666 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39660972158114116, 'Total loss': 0.39660972158114116} | train loss {'Reaction outcome loss': 0.2311045873194825, 'Total loss': 0.2311045873194825}
2022-12-31 12:17:08,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:08,666 INFO:     Epoch: 80
2022-12-31 12:17:10,298 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4140174994866053, 'Total loss': 0.4140174994866053} | train loss {'Reaction outcome loss': 0.24576991509377916, 'Total loss': 0.24576991509377916}
2022-12-31 12:17:10,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:10,298 INFO:     Epoch: 81
2022-12-31 12:17:11,940 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4123042186101278, 'Total loss': 0.4123042186101278} | train loss {'Reaction outcome loss': 0.23343925398544146, 'Total loss': 0.23343925398544146}
2022-12-31 12:17:11,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:11,940 INFO:     Epoch: 82
2022-12-31 12:17:13,554 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35866269369920095, 'Total loss': 0.35866269369920095} | train loss {'Reaction outcome loss': 0.232326420729278, 'Total loss': 0.232326420729278}
2022-12-31 12:17:13,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:13,555 INFO:     Epoch: 83
2022-12-31 12:17:15,168 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3747854342063268, 'Total loss': 0.3747854342063268} | train loss {'Reaction outcome loss': 0.23142445806002218, 'Total loss': 0.23142445806002218}
2022-12-31 12:17:15,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:15,168 INFO:     Epoch: 84
2022-12-31 12:17:16,780 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3644146571556727, 'Total loss': 0.3644146571556727} | train loss {'Reaction outcome loss': 0.2292435778748557, 'Total loss': 0.2292435778748557}
2022-12-31 12:17:16,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:16,781 INFO:     Epoch: 85
2022-12-31 12:17:18,303 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4150553544362386, 'Total loss': 0.4150553544362386} | train loss {'Reaction outcome loss': 0.22896607746910033, 'Total loss': 0.22896607746910033}
2022-12-31 12:17:18,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:18,304 INFO:     Epoch: 86
2022-12-31 12:17:19,910 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41001864870389304, 'Total loss': 0.41001864870389304} | train loss {'Reaction outcome loss': 0.22144412565055815, 'Total loss': 0.22144412565055815}
2022-12-31 12:17:19,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:19,911 INFO:     Epoch: 87
2022-12-31 12:17:21,520 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4181682288646698, 'Total loss': 0.4181682288646698} | train loss {'Reaction outcome loss': 0.22375264104458978, 'Total loss': 0.22375264104458978}
2022-12-31 12:17:21,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:21,521 INFO:     Epoch: 88
2022-12-31 12:17:23,132 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37312427957852684, 'Total loss': 0.37312427957852684} | train loss {'Reaction outcome loss': 0.22517307163911607, 'Total loss': 0.22517307163911607}
2022-12-31 12:17:23,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:23,132 INFO:     Epoch: 89
2022-12-31 12:17:24,745 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3683698425690333, 'Total loss': 0.3683698425690333} | train loss {'Reaction outcome loss': 0.22095146368925284, 'Total loss': 0.22095146368925284}
2022-12-31 12:17:24,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:24,746 INFO:     Epoch: 90
2022-12-31 12:17:26,358 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4160815507173538, 'Total loss': 0.4160815507173538} | train loss {'Reaction outcome loss': 0.22446501553096584, 'Total loss': 0.22446501553096584}
2022-12-31 12:17:26,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:26,359 INFO:     Epoch: 91
2022-12-31 12:17:27,898 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4083535293738047, 'Total loss': 0.4083535293738047} | train loss {'Reaction outcome loss': 0.22654878358150818, 'Total loss': 0.22654878358150818}
2022-12-31 12:17:27,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:27,898 INFO:     Epoch: 92
2022-12-31 12:17:29,512 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39923288573821386, 'Total loss': 0.39923288573821386} | train loss {'Reaction outcome loss': 0.2221104136349269, 'Total loss': 0.2221104136349269}
2022-12-31 12:17:29,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:29,512 INFO:     Epoch: 93
2022-12-31 12:17:31,122 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41966496109962464, 'Total loss': 0.41966496109962464} | train loss {'Reaction outcome loss': 0.22337858959070983, 'Total loss': 0.22337858959070983}
2022-12-31 12:17:31,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:31,122 INFO:     Epoch: 94
2022-12-31 12:17:32,734 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38387546439965564, 'Total loss': 0.38387546439965564} | train loss {'Reaction outcome loss': 0.21237652594546502, 'Total loss': 0.21237652594546502}
2022-12-31 12:17:32,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:32,735 INFO:     Epoch: 95
2022-12-31 12:17:34,345 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3809298644463221, 'Total loss': 0.3809298644463221} | train loss {'Reaction outcome loss': 0.2325316848422306, 'Total loss': 0.2325316848422306}
2022-12-31 12:17:34,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:34,346 INFO:     Epoch: 96
2022-12-31 12:17:35,863 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4312100867430369, 'Total loss': 0.4312100867430369} | train loss {'Reaction outcome loss': 0.29690616774757433, 'Total loss': 0.29690616774757433}
2022-12-31 12:17:35,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:35,863 INFO:     Epoch: 97
2022-12-31 12:17:37,477 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36365701506535214, 'Total loss': 0.36365701506535214} | train loss {'Reaction outcome loss': 0.24416487742274656, 'Total loss': 0.24416487742274656}
2022-12-31 12:17:37,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:37,477 INFO:     Epoch: 98
2022-12-31 12:17:39,087 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3861599196990331, 'Total loss': 0.3861599196990331} | train loss {'Reaction outcome loss': 0.22943621134048875, 'Total loss': 0.22943621134048875}
2022-12-31 12:17:39,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:39,087 INFO:     Epoch: 99
2022-12-31 12:17:40,710 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3870790938536326, 'Total loss': 0.3870790938536326} | train loss {'Reaction outcome loss': 0.2250678384443745, 'Total loss': 0.2250678384443745}
2022-12-31 12:17:40,710 INFO:     Best model found after epoch 62 of 100.
2022-12-31 12:17:40,711 INFO:   Done with stage: TRAINING
2022-12-31 12:17:40,711 INFO:   Starting stage: EVALUATION
2022-12-31 12:17:40,840 INFO:   Done with stage: EVALUATION
2022-12-31 12:17:40,840 INFO:   Leaving out SEQ value Fold_2
2022-12-31 12:17:40,852 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 12:17:40,853 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:17:41,499 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:17:41,499 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:17:41,566 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:17:41,566 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:17:41,566 INFO:     No hyperparam tuning for this model
2022-12-31 12:17:41,567 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:17:41,567 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:17:41,567 INFO:     None feature selector for col prot
2022-12-31 12:17:41,567 INFO:     None feature selector for col prot
2022-12-31 12:17:41,567 INFO:     None feature selector for col prot
2022-12-31 12:17:41,568 INFO:     None feature selector for col chem
2022-12-31 12:17:41,568 INFO:     None feature selector for col chem
2022-12-31 12:17:41,568 INFO:     None feature selector for col chem
2022-12-31 12:17:41,568 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:17:41,568 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:17:41,570 INFO:     Number of params in model 223921
2022-12-31 12:17:41,573 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:17:41,573 INFO:   Starting stage: TRAINING
2022-12-31 12:17:41,617 INFO:     Val loss before train {'Reaction outcome loss': 1.054375946521759, 'Total loss': 1.054375946521759}
2022-12-31 12:17:41,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:41,617 INFO:     Epoch: 0
2022-12-31 12:17:43,268 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7138085107008616, 'Total loss': 0.7138085107008616} | train loss {'Reaction outcome loss': 0.8008388178798306, 'Total loss': 0.8008388178798306}
2022-12-31 12:17:43,268 INFO:     Found new best model at epoch 0
2022-12-31 12:17:43,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:43,269 INFO:     Epoch: 1
2022-12-31 12:17:44,797 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6120384256045024, 'Total loss': 0.6120384256045024} | train loss {'Reaction outcome loss': 0.6025652682388222, 'Total loss': 0.6025652682388222}
2022-12-31 12:17:44,798 INFO:     Found new best model at epoch 1
2022-12-31 12:17:44,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:44,799 INFO:     Epoch: 2
2022-12-31 12:17:46,403 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.567451826731364, 'Total loss': 0.567451826731364} | train loss {'Reaction outcome loss': 0.529901073147089, 'Total loss': 0.529901073147089}
2022-12-31 12:17:46,403 INFO:     Found new best model at epoch 2
2022-12-31 12:17:46,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:46,404 INFO:     Epoch: 3
2022-12-31 12:17:48,033 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5578724463780721, 'Total loss': 0.5578724463780721} | train loss {'Reaction outcome loss': 0.5044875277049375, 'Total loss': 0.5044875277049375}
2022-12-31 12:17:48,033 INFO:     Found new best model at epoch 3
2022-12-31 12:17:48,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:48,034 INFO:     Epoch: 4
2022-12-31 12:17:49,677 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5179871519406637, 'Total loss': 0.5179871519406637} | train loss {'Reaction outcome loss': 0.49095729146248257, 'Total loss': 0.49095729146248257}
2022-12-31 12:17:49,678 INFO:     Found new best model at epoch 4
2022-12-31 12:17:49,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:49,679 INFO:     Epoch: 5
2022-12-31 12:17:51,316 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5376347303390503, 'Total loss': 0.5376347303390503} | train loss {'Reaction outcome loss': 0.480403755228598, 'Total loss': 0.480403755228598}
2022-12-31 12:17:51,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:51,316 INFO:     Epoch: 6
2022-12-31 12:17:52,950 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5097911631067594, 'Total loss': 0.5097911631067594} | train loss {'Reaction outcome loss': 0.4689111921376798, 'Total loss': 0.4689111921376798}
2022-12-31 12:17:52,950 INFO:     Found new best model at epoch 6
2022-12-31 12:17:52,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:52,951 INFO:     Epoch: 7
2022-12-31 12:17:54,469 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5040037895242373, 'Total loss': 0.5040037895242373} | train loss {'Reaction outcome loss': 0.46447719417976374, 'Total loss': 0.46447719417976374}
2022-12-31 12:17:54,469 INFO:     Found new best model at epoch 7
2022-12-31 12:17:54,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:54,470 INFO:     Epoch: 8
2022-12-31 12:17:56,066 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5028596182664236, 'Total loss': 0.5028596182664236} | train loss {'Reaction outcome loss': 0.45156618827210243, 'Total loss': 0.45156618827210243}
2022-12-31 12:17:56,067 INFO:     Found new best model at epoch 8
2022-12-31 12:17:56,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:56,068 INFO:     Epoch: 9
2022-12-31 12:17:57,662 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5078087369600932, 'Total loss': 0.5078087369600932} | train loss {'Reaction outcome loss': 0.44795557851101453, 'Total loss': 0.44795557851101453}
2022-12-31 12:17:57,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:57,662 INFO:     Epoch: 10
2022-12-31 12:17:59,262 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49265190958976746, 'Total loss': 0.49265190958976746} | train loss {'Reaction outcome loss': 0.4405187189633593, 'Total loss': 0.4405187189633593}
2022-12-31 12:17:59,262 INFO:     Found new best model at epoch 10
2022-12-31 12:17:59,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:17:59,263 INFO:     Epoch: 11
2022-12-31 12:18:00,858 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49135035077730815, 'Total loss': 0.49135035077730815} | train loss {'Reaction outcome loss': 0.4393750502294673, 'Total loss': 0.4393750502294673}
2022-12-31 12:18:00,859 INFO:     Found new best model at epoch 11
2022-12-31 12:18:00,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:00,859 INFO:     Epoch: 12
2022-12-31 12:18:02,456 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49749892155329384, 'Total loss': 0.49749892155329384} | train loss {'Reaction outcome loss': 0.42855399186576243, 'Total loss': 0.42855399186576243}
2022-12-31 12:18:02,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:02,456 INFO:     Epoch: 13
2022-12-31 12:18:03,957 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5111633102099101, 'Total loss': 0.5111633102099101} | train loss {'Reaction outcome loss': 0.4198798372686564, 'Total loss': 0.4198798372686564}
2022-12-31 12:18:03,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:03,957 INFO:     Epoch: 14
2022-12-31 12:18:05,556 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48500684797763827, 'Total loss': 0.48500684797763827} | train loss {'Reaction outcome loss': 0.42079467072591675, 'Total loss': 0.42079467072591675}
2022-12-31 12:18:05,556 INFO:     Found new best model at epoch 14
2022-12-31 12:18:05,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:05,557 INFO:     Epoch: 15
2022-12-31 12:18:07,154 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4839803874492645, 'Total loss': 0.4839803874492645} | train loss {'Reaction outcome loss': 0.41336678784518016, 'Total loss': 0.41336678784518016}
2022-12-31 12:18:07,154 INFO:     Found new best model at epoch 15
2022-12-31 12:18:07,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:07,155 INFO:     Epoch: 16
2022-12-31 12:18:08,752 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46759301821390786, 'Total loss': 0.46759301821390786} | train loss {'Reaction outcome loss': 0.4079786940535783, 'Total loss': 0.4079786940535783}
2022-12-31 12:18:08,753 INFO:     Found new best model at epoch 16
2022-12-31 12:18:08,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:08,754 INFO:     Epoch: 17
2022-12-31 12:18:10,350 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4914020558198293, 'Total loss': 0.4914020558198293} | train loss {'Reaction outcome loss': 0.3982839811142984, 'Total loss': 0.3982839811142984}
2022-12-31 12:18:10,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:10,351 INFO:     Epoch: 18
2022-12-31 12:18:11,848 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47715751429398856, 'Total loss': 0.47715751429398856} | train loss {'Reaction outcome loss': 0.39627246468604266, 'Total loss': 0.39627246468604266}
2022-12-31 12:18:11,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:11,848 INFO:     Epoch: 19
2022-12-31 12:18:13,450 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4773495435714722, 'Total loss': 0.4773495435714722} | train loss {'Reaction outcome loss': 0.39325242061099724, 'Total loss': 0.39325242061099724}
2022-12-31 12:18:13,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:13,451 INFO:     Epoch: 20
2022-12-31 12:18:15,051 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44557801286379495, 'Total loss': 0.44557801286379495} | train loss {'Reaction outcome loss': 0.38028551589001663, 'Total loss': 0.38028551589001663}
2022-12-31 12:18:15,051 INFO:     Found new best model at epoch 20
2022-12-31 12:18:15,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:15,052 INFO:     Epoch: 21
2022-12-31 12:18:16,668 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47892706195513407, 'Total loss': 0.47892706195513407} | train loss {'Reaction outcome loss': 0.37560836596912517, 'Total loss': 0.37560836596912517}
2022-12-31 12:18:16,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:16,668 INFO:     Epoch: 22
2022-12-31 12:18:18,323 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.465409846107165, 'Total loss': 0.465409846107165} | train loss {'Reaction outcome loss': 0.37149459279173025, 'Total loss': 0.37149459279173025}
2022-12-31 12:18:18,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:18,323 INFO:     Epoch: 23
2022-12-31 12:18:19,954 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4846365268031756, 'Total loss': 0.4846365268031756} | train loss {'Reaction outcome loss': 0.36730676815732494, 'Total loss': 0.36730676815732494}
2022-12-31 12:18:19,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:19,954 INFO:     Epoch: 24
2022-12-31 12:18:21,474 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4652823070685069, 'Total loss': 0.4652823070685069} | train loss {'Reaction outcome loss': 0.35910939041784395, 'Total loss': 0.35910939041784395}
2022-12-31 12:18:21,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:21,475 INFO:     Epoch: 25
2022-12-31 12:18:23,078 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4793528546889623, 'Total loss': 0.4793528546889623} | train loss {'Reaction outcome loss': 0.3560291656971851, 'Total loss': 0.3560291656971851}
2022-12-31 12:18:23,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:23,078 INFO:     Epoch: 26
2022-12-31 12:18:24,679 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.475019442041715, 'Total loss': 0.475019442041715} | train loss {'Reaction outcome loss': 0.35520449185218567, 'Total loss': 0.35520449185218567}
2022-12-31 12:18:24,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:24,680 INFO:     Epoch: 27
2022-12-31 12:18:26,282 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4796754032373428, 'Total loss': 0.4796754032373428} | train loss {'Reaction outcome loss': 0.3511493674892209, 'Total loss': 0.3511493674892209}
2022-12-31 12:18:26,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:26,282 INFO:     Epoch: 28
2022-12-31 12:18:27,880 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4789417793353399, 'Total loss': 0.4789417793353399} | train loss {'Reaction outcome loss': 0.3425453631377919, 'Total loss': 0.3425453631377919}
2022-12-31 12:18:27,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:27,881 INFO:     Epoch: 29
2022-12-31 12:18:29,480 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4728731354077657, 'Total loss': 0.4728731354077657} | train loss {'Reaction outcome loss': 0.33393863222865394, 'Total loss': 0.33393863222865394}
2022-12-31 12:18:29,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:29,480 INFO:     Epoch: 30
2022-12-31 12:18:30,984 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4640223205089569, 'Total loss': 0.4640223205089569} | train loss {'Reaction outcome loss': 0.33490470487064933, 'Total loss': 0.33490470487064933}
2022-12-31 12:18:30,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:30,985 INFO:     Epoch: 31
2022-12-31 12:18:32,614 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46919348935286204, 'Total loss': 0.46919348935286204} | train loss {'Reaction outcome loss': 0.3325678638076826, 'Total loss': 0.3325678638076826}
2022-12-31 12:18:32,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:32,614 INFO:     Epoch: 32
2022-12-31 12:18:34,224 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4512073228756587, 'Total loss': 0.4512073228756587} | train loss {'Reaction outcome loss': 0.3266104625149088, 'Total loss': 0.3266104625149088}
2022-12-31 12:18:34,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:34,224 INFO:     Epoch: 33
2022-12-31 12:18:35,833 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4519073704878489, 'Total loss': 0.4519073704878489} | train loss {'Reaction outcome loss': 0.32701175725394555, 'Total loss': 0.32701175725394555}
2022-12-31 12:18:35,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:35,833 INFO:     Epoch: 34
2022-12-31 12:18:37,458 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4818377435207367, 'Total loss': 0.4818377435207367} | train loss {'Reaction outcome loss': 0.31657003993407273, 'Total loss': 0.31657003993407273}
2022-12-31 12:18:37,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:37,458 INFO:     Epoch: 35
2022-12-31 12:18:39,031 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4598645806312561, 'Total loss': 0.4598645806312561} | train loss {'Reaction outcome loss': 0.3168596246794903, 'Total loss': 0.3168596246794903}
2022-12-31 12:18:39,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:39,031 INFO:     Epoch: 36
2022-12-31 12:18:40,617 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4697272539138794, 'Total loss': 0.4697272539138794} | train loss {'Reaction outcome loss': 0.3191333235047021, 'Total loss': 0.3191333235047021}
2022-12-31 12:18:40,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:40,618 INFO:     Epoch: 37
2022-12-31 12:18:42,224 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4871289889017741, 'Total loss': 0.4871289889017741} | train loss {'Reaction outcome loss': 0.30523977087530896, 'Total loss': 0.30523977087530896}
2022-12-31 12:18:42,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:42,224 INFO:     Epoch: 38
2022-12-31 12:18:43,820 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4410738875468572, 'Total loss': 0.4410738875468572} | train loss {'Reaction outcome loss': 0.30402570674980517, 'Total loss': 0.30402570674980517}
2022-12-31 12:18:43,821 INFO:     Found new best model at epoch 38
2022-12-31 12:18:43,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:43,822 INFO:     Epoch: 39
2022-12-31 12:18:45,422 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45343552629152933, 'Total loss': 0.45343552629152933} | train loss {'Reaction outcome loss': 0.2916006747728739, 'Total loss': 0.2916006747728739}
2022-12-31 12:18:45,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:45,422 INFO:     Epoch: 40
2022-12-31 12:18:47,055 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48060835897922516, 'Total loss': 0.48060835897922516} | train loss {'Reaction outcome loss': 0.2938152083055877, 'Total loss': 0.2938152083055877}
2022-12-31 12:18:47,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:47,055 INFO:     Epoch: 41
2022-12-31 12:18:48,593 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44507894416650134, 'Total loss': 0.44507894416650134} | train loss {'Reaction outcome loss': 0.2935427480237388, 'Total loss': 0.2935427480237388}
2022-12-31 12:18:48,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:48,593 INFO:     Epoch: 42
2022-12-31 12:18:50,195 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44792602260907494, 'Total loss': 0.44792602260907494} | train loss {'Reaction outcome loss': 0.28672490741088713, 'Total loss': 0.28672490741088713}
2022-12-31 12:18:50,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:50,196 INFO:     Epoch: 43
2022-12-31 12:18:51,791 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4388974756002426, 'Total loss': 0.4388974756002426} | train loss {'Reaction outcome loss': 0.28433087429256887, 'Total loss': 0.28433087429256887}
2022-12-31 12:18:51,791 INFO:     Found new best model at epoch 43
2022-12-31 12:18:51,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:51,792 INFO:     Epoch: 44
2022-12-31 12:18:53,389 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5107769330342611, 'Total loss': 0.5107769330342611} | train loss {'Reaction outcome loss': 0.2802762976769126, 'Total loss': 0.2802762976769126}
2022-12-31 12:18:53,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:53,390 INFO:     Epoch: 45
2022-12-31 12:18:54,989 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46480374534924823, 'Total loss': 0.46480374534924823} | train loss {'Reaction outcome loss': 0.28233860865671995, 'Total loss': 0.28233860865671995}
2022-12-31 12:18:54,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:54,989 INFO:     Epoch: 46
2022-12-31 12:18:56,586 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4921825170516968, 'Total loss': 0.4921825170516968} | train loss {'Reaction outcome loss': 0.28027685017976567, 'Total loss': 0.28027685017976567}
2022-12-31 12:18:56,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:56,587 INFO:     Epoch: 47
2022-12-31 12:18:58,145 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4494785686333974, 'Total loss': 0.4494785686333974} | train loss {'Reaction outcome loss': 0.2772104408278133, 'Total loss': 0.2772104408278133}
2022-12-31 12:18:58,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:58,145 INFO:     Epoch: 48
2022-12-31 12:18:59,747 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4443836522599061, 'Total loss': 0.4443836522599061} | train loss {'Reaction outcome loss': 0.27061945098987866, 'Total loss': 0.27061945098987866}
2022-12-31 12:18:59,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:18:59,747 INFO:     Epoch: 49
2022-12-31 12:19:01,344 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47338351408640544, 'Total loss': 0.47338351408640544} | train loss {'Reaction outcome loss': 0.26817370574552934, 'Total loss': 0.26817370574552934}
2022-12-31 12:19:01,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:01,344 INFO:     Epoch: 50
2022-12-31 12:19:02,972 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44358603060245516, 'Total loss': 0.44358603060245516} | train loss {'Reaction outcome loss': 0.263377045659901, 'Total loss': 0.263377045659901}
2022-12-31 12:19:02,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:02,973 INFO:     Epoch: 51
2022-12-31 12:19:04,547 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4572334080934525, 'Total loss': 0.4572334080934525} | train loss {'Reaction outcome loss': 0.2581510891482889, 'Total loss': 0.2581510891482889}
2022-12-31 12:19:04,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:04,547 INFO:     Epoch: 52
2022-12-31 12:19:06,152 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43452147344748177, 'Total loss': 0.43452147344748177} | train loss {'Reaction outcome loss': 0.2596179001006015, 'Total loss': 0.2596179001006015}
2022-12-31 12:19:06,152 INFO:     Found new best model at epoch 52
2022-12-31 12:19:06,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:06,153 INFO:     Epoch: 53
2022-12-31 12:19:07,697 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4889887024958928, 'Total loss': 0.4889887024958928} | train loss {'Reaction outcome loss': 0.2608410645917658, 'Total loss': 0.2608410645917658}
2022-12-31 12:19:07,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:07,697 INFO:     Epoch: 54
2022-12-31 12:19:09,336 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4709925750891368, 'Total loss': 0.4709925750891368} | train loss {'Reaction outcome loss': 0.25559528788804137, 'Total loss': 0.25559528788804137}
2022-12-31 12:19:09,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:09,336 INFO:     Epoch: 55
2022-12-31 12:19:10,961 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4997772455215454, 'Total loss': 0.4997772455215454} | train loss {'Reaction outcome loss': 0.25448943886073516, 'Total loss': 0.25448943886073516}
2022-12-31 12:19:10,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:10,961 INFO:     Epoch: 56
2022-12-31 12:19:12,597 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4461890568335851, 'Total loss': 0.4461890568335851} | train loss {'Reaction outcome loss': 0.25887002981516904, 'Total loss': 0.25887002981516904}
2022-12-31 12:19:12,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:12,597 INFO:     Epoch: 57
2022-12-31 12:19:14,209 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4194511118034522, 'Total loss': 0.4194511118034522} | train loss {'Reaction outcome loss': 0.24712935070278663, 'Total loss': 0.24712935070278663}
2022-12-31 12:19:14,209 INFO:     Found new best model at epoch 57
2022-12-31 12:19:14,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:14,210 INFO:     Epoch: 58
2022-12-31 12:19:15,773 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4601929177840551, 'Total loss': 0.4601929177840551} | train loss {'Reaction outcome loss': 0.24603278241751395, 'Total loss': 0.24603278241751395}
2022-12-31 12:19:15,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:15,774 INFO:     Epoch: 59
2022-12-31 12:19:17,409 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45654611587524413, 'Total loss': 0.45654611587524413} | train loss {'Reaction outcome loss': 0.2428962904414087, 'Total loss': 0.2428962904414087}
2022-12-31 12:19:17,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:17,410 INFO:     Epoch: 60
2022-12-31 12:19:19,020 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46770583192507426, 'Total loss': 0.46770583192507426} | train loss {'Reaction outcome loss': 0.2476889683759256, 'Total loss': 0.2476889683759256}
2022-12-31 12:19:19,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:19,020 INFO:     Epoch: 61
2022-12-31 12:19:20,661 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4459724485874176, 'Total loss': 0.4459724485874176} | train loss {'Reaction outcome loss': 0.23777487618173218, 'Total loss': 0.23777487618173218}
2022-12-31 12:19:20,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:20,661 INFO:     Epoch: 62
2022-12-31 12:19:22,266 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.511703226963679, 'Total loss': 0.511703226963679} | train loss {'Reaction outcome loss': 0.23584712573050798, 'Total loss': 0.23584712573050798}
2022-12-31 12:19:22,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:22,266 INFO:     Epoch: 63
2022-12-31 12:19:23,863 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42670182983080546, 'Total loss': 0.42670182983080546} | train loss {'Reaction outcome loss': 0.24693163272825788, 'Total loss': 0.24693163272825788}
2022-12-31 12:19:23,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:23,863 INFO:     Epoch: 64
2022-12-31 12:19:25,396 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43519522150357565, 'Total loss': 0.43519522150357565} | train loss {'Reaction outcome loss': 0.23353626146475912, 'Total loss': 0.23353626146475912}
2022-12-31 12:19:25,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:25,397 INFO:     Epoch: 65
2022-12-31 12:19:26,994 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4772471308708191, 'Total loss': 0.4772471308708191} | train loss {'Reaction outcome loss': 0.23956010853632903, 'Total loss': 0.23956010853632903}
2022-12-31 12:19:26,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:26,994 INFO:     Epoch: 66
2022-12-31 12:19:28,593 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47154171764850616, 'Total loss': 0.47154171764850616} | train loss {'Reaction outcome loss': 0.2408437882396546, 'Total loss': 0.2408437882396546}
2022-12-31 12:19:28,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:28,593 INFO:     Epoch: 67
2022-12-31 12:19:30,192 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.441025847196579, 'Total loss': 0.441025847196579} | train loss {'Reaction outcome loss': 0.23153704762349636, 'Total loss': 0.23153704762349636}
2022-12-31 12:19:30,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:30,192 INFO:     Epoch: 68
2022-12-31 12:19:31,793 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45064596831798553, 'Total loss': 0.45064596831798553} | train loss {'Reaction outcome loss': 0.22696390851731701, 'Total loss': 0.22696390851731701}
2022-12-31 12:19:31,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:31,794 INFO:     Epoch: 69
2022-12-31 12:19:33,391 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4752727518479029, 'Total loss': 0.4752727518479029} | train loss {'Reaction outcome loss': 0.23568485106849846, 'Total loss': 0.23568485106849846}
2022-12-31 12:19:33,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:33,391 INFO:     Epoch: 70
2022-12-31 12:19:34,964 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46322024464607237, 'Total loss': 0.46322024464607237} | train loss {'Reaction outcome loss': 0.2221865219391555, 'Total loss': 0.2221865219391555}
2022-12-31 12:19:34,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:34,964 INFO:     Epoch: 71
2022-12-31 12:19:36,597 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4247129519780477, 'Total loss': 0.4247129519780477} | train loss {'Reaction outcome loss': 0.22169059329417162, 'Total loss': 0.22169059329417162}
2022-12-31 12:19:36,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:36,597 INFO:     Epoch: 72
2022-12-31 12:19:38,172 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4579173813263575, 'Total loss': 0.4579173813263575} | train loss {'Reaction outcome loss': 0.23081594077877074, 'Total loss': 0.23081594077877074}
2022-12-31 12:19:38,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:38,172 INFO:     Epoch: 73
2022-12-31 12:19:39,772 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.447654848297437, 'Total loss': 0.447654848297437} | train loss {'Reaction outcome loss': 0.2265315353529248, 'Total loss': 0.2265315353529248}
2022-12-31 12:19:39,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:39,772 INFO:     Epoch: 74
2022-12-31 12:19:41,368 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48673776586850487, 'Total loss': 0.48673776586850487} | train loss {'Reaction outcome loss': 0.22354710300285846, 'Total loss': 0.22354710300285846}
2022-12-31 12:19:41,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:41,369 INFO:     Epoch: 75
2022-12-31 12:19:42,898 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46715614597002664, 'Total loss': 0.46715614597002664} | train loss {'Reaction outcome loss': 0.22714759764899484, 'Total loss': 0.22714759764899484}
2022-12-31 12:19:42,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:42,899 INFO:     Epoch: 76
2022-12-31 12:19:44,491 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46825083196163175, 'Total loss': 0.46825083196163175} | train loss {'Reaction outcome loss': 0.2177530454655925, 'Total loss': 0.2177530454655925}
2022-12-31 12:19:44,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:44,491 INFO:     Epoch: 77
2022-12-31 12:19:46,086 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4579283068577448, 'Total loss': 0.4579283068577448} | train loss {'Reaction outcome loss': 0.22295666627940677, 'Total loss': 0.22295666627940677}
2022-12-31 12:19:46,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:46,086 INFO:     Epoch: 78
2022-12-31 12:19:47,694 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.465463321407636, 'Total loss': 0.465463321407636} | train loss {'Reaction outcome loss': 0.22006950605210368, 'Total loss': 0.22006950605210368}
2022-12-31 12:19:47,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:47,694 INFO:     Epoch: 79
2022-12-31 12:19:49,294 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4605189929405848, 'Total loss': 0.4605189929405848} | train loss {'Reaction outcome loss': 0.22021113383846405, 'Total loss': 0.22021113383846405}
2022-12-31 12:19:49,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:49,294 INFO:     Epoch: 80
2022-12-31 12:19:50,906 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43975587487220763, 'Total loss': 0.43975587487220763} | train loss {'Reaction outcome loss': 0.2111333411002716, 'Total loss': 0.2111333411002716}
2022-12-31 12:19:50,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:50,907 INFO:     Epoch: 81
2022-12-31 12:19:52,451 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47246471444765725, 'Total loss': 0.47246471444765725} | train loss {'Reaction outcome loss': 0.21464746242607416, 'Total loss': 0.21464746242607416}
2022-12-31 12:19:52,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:52,451 INFO:     Epoch: 82
2022-12-31 12:19:54,049 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46828967332839966, 'Total loss': 0.46828967332839966} | train loss {'Reaction outcome loss': 0.21050914977387195, 'Total loss': 0.21050914977387195}
2022-12-31 12:19:54,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:54,049 INFO:     Epoch: 83
2022-12-31 12:19:55,665 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4677044173081716, 'Total loss': 0.4677044173081716} | train loss {'Reaction outcome loss': 0.21268442367295642, 'Total loss': 0.21268442367295642}
2022-12-31 12:19:55,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:55,666 INFO:     Epoch: 84
2022-12-31 12:19:57,264 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45924106041590373, 'Total loss': 0.45924106041590373} | train loss {'Reaction outcome loss': 0.2095560931887191, 'Total loss': 0.2095560931887191}
2022-12-31 12:19:57,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:57,265 INFO:     Epoch: 85
2022-12-31 12:19:58,875 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5225603719552357, 'Total loss': 0.5225603719552357} | train loss {'Reaction outcome loss': 0.21424910239875317, 'Total loss': 0.21424910239875317}
2022-12-31 12:19:58,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:19:58,875 INFO:     Epoch: 86
2022-12-31 12:20:00,478 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4581775983174642, 'Total loss': 0.4581775983174642} | train loss {'Reaction outcome loss': 0.21032517945100537, 'Total loss': 0.21032517945100537}
2022-12-31 12:20:00,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:00,478 INFO:     Epoch: 87
2022-12-31 12:20:02,027 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48838096459706626, 'Total loss': 0.48838096459706626} | train loss {'Reaction outcome loss': 0.21542717699957636, 'Total loss': 0.21542717699957636}
2022-12-31 12:20:02,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:02,028 INFO:     Epoch: 88
2022-12-31 12:20:03,625 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4638865222533544, 'Total loss': 0.4638865222533544} | train loss {'Reaction outcome loss': 0.20192966237664223, 'Total loss': 0.20192966237664223}
2022-12-31 12:20:03,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:03,626 INFO:     Epoch: 89
2022-12-31 12:20:05,233 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48076799511909485, 'Total loss': 0.48076799511909485} | train loss {'Reaction outcome loss': 0.20606138460310824, 'Total loss': 0.20606138460310824}
2022-12-31 12:20:05,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:05,233 INFO:     Epoch: 90
2022-12-31 12:20:06,852 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4973329663276672, 'Total loss': 0.4973329663276672} | train loss {'Reaction outcome loss': 0.20694932069684013, 'Total loss': 0.20694932069684013}
2022-12-31 12:20:06,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:06,852 INFO:     Epoch: 91
2022-12-31 12:20:08,445 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4509540965159734, 'Total loss': 0.4509540965159734} | train loss {'Reaction outcome loss': 0.20889933499415497, 'Total loss': 0.20889933499415497}
2022-12-31 12:20:08,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:08,445 INFO:     Epoch: 92
2022-12-31 12:20:09,999 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4561488370100657, 'Total loss': 0.4561488370100657} | train loss {'Reaction outcome loss': 0.1976678354440482, 'Total loss': 0.1976678354440482}
2022-12-31 12:20:09,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:09,999 INFO:     Epoch: 93
2022-12-31 12:20:11,605 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47929969628651936, 'Total loss': 0.47929969628651936} | train loss {'Reaction outcome loss': 0.20773815925168249, 'Total loss': 0.20773815925168249}
2022-12-31 12:20:11,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:11,605 INFO:     Epoch: 94
2022-12-31 12:20:13,206 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5252572019894918, 'Total loss': 0.5252572019894918} | train loss {'Reaction outcome loss': 0.20799385076695745, 'Total loss': 0.20799385076695745}
2022-12-31 12:20:13,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:13,206 INFO:     Epoch: 95
2022-12-31 12:20:14,808 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4726798444986343, 'Total loss': 0.4726798444986343} | train loss {'Reaction outcome loss': 0.19760572859819556, 'Total loss': 0.19760572859819556}
2022-12-31 12:20:14,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:14,809 INFO:     Epoch: 96
2022-12-31 12:20:16,400 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4789628451069196, 'Total loss': 0.4789628451069196} | train loss {'Reaction outcome loss': 0.2018975234716694, 'Total loss': 0.2018975234716694}
2022-12-31 12:20:16,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:16,401 INFO:     Epoch: 97
2022-12-31 12:20:18,026 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4347657283147176, 'Total loss': 0.4347657283147176} | train loss {'Reaction outcome loss': 0.19919610058636347, 'Total loss': 0.19919610058636347}
2022-12-31 12:20:18,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:18,026 INFO:     Epoch: 98
2022-12-31 12:20:19,593 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4824774036804835, 'Total loss': 0.4824774036804835} | train loss {'Reaction outcome loss': 0.20203099758688348, 'Total loss': 0.20203099758688348}
2022-12-31 12:20:19,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:19,593 INFO:     Epoch: 99
2022-12-31 12:20:21,203 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4585586339235306, 'Total loss': 0.4585586339235306} | train loss {'Reaction outcome loss': 0.20200275300213924, 'Total loss': 0.20200275300213924}
2022-12-31 12:20:21,204 INFO:     Best model found after epoch 58 of 100.
2022-12-31 12:20:21,204 INFO:   Done with stage: TRAINING
2022-12-31 12:20:21,204 INFO:   Starting stage: EVALUATION
2022-12-31 12:20:21,344 INFO:   Done with stage: EVALUATION
2022-12-31 12:20:21,344 INFO:   Leaving out SEQ value Fold_3
2022-12-31 12:20:21,357 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 12:20:21,357 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:20:22,017 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:20:22,017 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:20:22,085 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:20:22,085 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:20:22,085 INFO:     No hyperparam tuning for this model
2022-12-31 12:20:22,085 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:20:22,085 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:20:22,086 INFO:     None feature selector for col prot
2022-12-31 12:20:22,086 INFO:     None feature selector for col prot
2022-12-31 12:20:22,086 INFO:     None feature selector for col prot
2022-12-31 12:20:22,087 INFO:     None feature selector for col chem
2022-12-31 12:20:22,087 INFO:     None feature selector for col chem
2022-12-31 12:20:22,087 INFO:     None feature selector for col chem
2022-12-31 12:20:22,087 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:20:22,087 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:20:22,089 INFO:     Number of params in model 223921
2022-12-31 12:20:22,092 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:20:22,092 INFO:   Starting stage: TRAINING
2022-12-31 12:20:22,138 INFO:     Val loss before train {'Reaction outcome loss': 0.9926205476125082, 'Total loss': 0.9926205476125082}
2022-12-31 12:20:22,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:22,138 INFO:     Epoch: 0
2022-12-31 12:20:23,737 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6758247375488281, 'Total loss': 0.6758247375488281} | train loss {'Reaction outcome loss': 0.8257277301193153, 'Total loss': 0.8257277301193153}
2022-12-31 12:20:23,737 INFO:     Found new best model at epoch 0
2022-12-31 12:20:23,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:23,738 INFO:     Epoch: 1
2022-12-31 12:20:25,358 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5321871727705002, 'Total loss': 0.5321871727705002} | train loss {'Reaction outcome loss': 0.6093799307616088, 'Total loss': 0.6093799307616088}
2022-12-31 12:20:25,358 INFO:     Found new best model at epoch 1
2022-12-31 12:20:25,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:25,359 INFO:     Epoch: 2
2022-12-31 12:20:26,961 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5108444551626842, 'Total loss': 0.5108444551626842} | train loss {'Reaction outcome loss': 0.5416555429679634, 'Total loss': 0.5416555429679634}
2022-12-31 12:20:26,961 INFO:     Found new best model at epoch 2
2022-12-31 12:20:26,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:26,962 INFO:     Epoch: 3
2022-12-31 12:20:28,530 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5215098182360332, 'Total loss': 0.5215098182360332} | train loss {'Reaction outcome loss': 0.51559298349558, 'Total loss': 0.51559298349558}
2022-12-31 12:20:28,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:28,530 INFO:     Epoch: 4
2022-12-31 12:20:30,132 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5124459703763325, 'Total loss': 0.5124459703763325} | train loss {'Reaction outcome loss': 0.4943828834016828, 'Total loss': 0.4943828834016828}
2022-12-31 12:20:30,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:30,132 INFO:     Epoch: 5
2022-12-31 12:20:31,736 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4844256639480591, 'Total loss': 0.4844256639480591} | train loss {'Reaction outcome loss': 0.48398324820029476, 'Total loss': 0.48398324820029476}
2022-12-31 12:20:31,736 INFO:     Found new best model at epoch 5
2022-12-31 12:20:31,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:31,737 INFO:     Epoch: 6
2022-12-31 12:20:33,338 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49430442055066426, 'Total loss': 0.49430442055066426} | train loss {'Reaction outcome loss': 0.47777340653603967, 'Total loss': 0.47777340653603967}
2022-12-31 12:20:33,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:33,340 INFO:     Epoch: 7
2022-12-31 12:20:34,941 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5111536095539729, 'Total loss': 0.5111536095539729} | train loss {'Reaction outcome loss': 0.46624905768319636, 'Total loss': 0.46624905768319636}
2022-12-31 12:20:34,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:34,941 INFO:     Epoch: 8
2022-12-31 12:20:36,540 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4864742815494537, 'Total loss': 0.4864742815494537} | train loss {'Reaction outcome loss': 0.4591851250751175, 'Total loss': 0.4591851250751175}
2022-12-31 12:20:36,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:36,540 INFO:     Epoch: 9
2022-12-31 12:20:38,111 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5122786581516265, 'Total loss': 0.5122786581516265} | train loss {'Reaction outcome loss': 0.4485865222276562, 'Total loss': 0.4485865222276562}
2022-12-31 12:20:38,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:38,112 INFO:     Epoch: 10
2022-12-31 12:20:39,797 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4839050889015198, 'Total loss': 0.4839050889015198} | train loss {'Reaction outcome loss': 0.44974197561505935, 'Total loss': 0.44974197561505935}
2022-12-31 12:20:39,798 INFO:     Found new best model at epoch 10
2022-12-31 12:20:39,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:39,800 INFO:     Epoch: 11
2022-12-31 12:20:41,457 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48235766887664794, 'Total loss': 0.48235766887664794} | train loss {'Reaction outcome loss': 0.43827329002266385, 'Total loss': 0.43827329002266385}
2022-12-31 12:20:41,457 INFO:     Found new best model at epoch 11
2022-12-31 12:20:41,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:41,458 INFO:     Epoch: 12
2022-12-31 12:20:43,092 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4772635261217753, 'Total loss': 0.4772635261217753} | train loss {'Reaction outcome loss': 0.4362032576634066, 'Total loss': 0.4362032576634066}
2022-12-31 12:20:43,092 INFO:     Found new best model at epoch 12
2022-12-31 12:20:43,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:43,093 INFO:     Epoch: 13
2022-12-31 12:20:44,704 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48489846686522164, 'Total loss': 0.48489846686522164} | train loss {'Reaction outcome loss': 0.42597882854786234, 'Total loss': 0.42597882854786234}
2022-12-31 12:20:44,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:44,704 INFO:     Epoch: 14
2022-12-31 12:20:46,282 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49202585220336914, 'Total loss': 0.49202585220336914} | train loss {'Reaction outcome loss': 0.41892784926360543, 'Total loss': 0.41892784926360543}
2022-12-31 12:20:46,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:46,282 INFO:     Epoch: 15
2022-12-31 12:20:47,880 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4327627698580424, 'Total loss': 0.4327627698580424} | train loss {'Reaction outcome loss': 0.4180578525810346, 'Total loss': 0.4180578525810346}
2022-12-31 12:20:47,880 INFO:     Found new best model at epoch 15
2022-12-31 12:20:47,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:47,881 INFO:     Epoch: 16
2022-12-31 12:20:49,477 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.435946058233579, 'Total loss': 0.435946058233579} | train loss {'Reaction outcome loss': 0.4097155478041973, 'Total loss': 0.4097155478041973}
2022-12-31 12:20:49,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:49,477 INFO:     Epoch: 17
2022-12-31 12:20:51,057 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45815236469109855, 'Total loss': 0.45815236469109855} | train loss {'Reaction outcome loss': 0.3995572124628255, 'Total loss': 0.3995572124628255}
2022-12-31 12:20:51,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:51,057 INFO:     Epoch: 18
2022-12-31 12:20:52,691 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45289083023866017, 'Total loss': 0.45289083023866017} | train loss {'Reaction outcome loss': 0.4005370769296249, 'Total loss': 0.4005370769296249}
2022-12-31 12:20:52,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:52,692 INFO:     Epoch: 19
2022-12-31 12:20:54,351 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4292066812515259, 'Total loss': 0.4292066812515259} | train loss {'Reaction outcome loss': 0.3914250031004857, 'Total loss': 0.3914250031004857}
2022-12-31 12:20:54,351 INFO:     Found new best model at epoch 19
2022-12-31 12:20:54,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:54,352 INFO:     Epoch: 20
2022-12-31 12:20:55,930 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4681632210810979, 'Total loss': 0.4681632210810979} | train loss {'Reaction outcome loss': 0.3840186902097542, 'Total loss': 0.3840186902097542}
2022-12-31 12:20:55,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:55,930 INFO:     Epoch: 21
2022-12-31 12:20:57,530 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49767664074897766, 'Total loss': 0.49767664074897766} | train loss {'Reaction outcome loss': 0.3813460108409398, 'Total loss': 0.3813460108409398}
2022-12-31 12:20:57,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:57,530 INFO:     Epoch: 22
2022-12-31 12:20:59,143 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46410760283470154, 'Total loss': 0.46410760283470154} | train loss {'Reaction outcome loss': 0.3738193261253573, 'Total loss': 0.3738193261253573}
2022-12-31 12:20:59,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:20:59,143 INFO:     Epoch: 23
2022-12-31 12:21:00,800 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4412048816680908, 'Total loss': 0.4412048816680908} | train loss {'Reaction outcome loss': 0.37094620726730704, 'Total loss': 0.37094620726730704}
2022-12-31 12:21:00,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:00,801 INFO:     Epoch: 24
2022-12-31 12:21:02,458 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45249735911687217, 'Total loss': 0.45249735911687217} | train loss {'Reaction outcome loss': 0.36372678033518097, 'Total loss': 0.36372678033518097}
2022-12-31 12:21:02,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:02,459 INFO:     Epoch: 25
2022-12-31 12:21:04,100 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44558089673519136, 'Total loss': 0.44558089673519136} | train loss {'Reaction outcome loss': 0.36455455792211267, 'Total loss': 0.36455455792211267}
2022-12-31 12:21:04,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:04,100 INFO:     Epoch: 26
2022-12-31 12:21:05,713 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.408143417040507, 'Total loss': 0.408143417040507} | train loss {'Reaction outcome loss': 0.3541976495435203, 'Total loss': 0.3541976495435203}
2022-12-31 12:21:05,713 INFO:     Found new best model at epoch 26
2022-12-31 12:21:05,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:05,714 INFO:     Epoch: 27
2022-12-31 12:21:07,291 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3906872649987539, 'Total loss': 0.3906872649987539} | train loss {'Reaction outcome loss': 0.3489845076942966, 'Total loss': 0.3489845076942966}
2022-12-31 12:21:07,291 INFO:     Found new best model at epoch 27
2022-12-31 12:21:07,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:07,292 INFO:     Epoch: 28
2022-12-31 12:21:08,921 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4167973001797994, 'Total loss': 0.4167973001797994} | train loss {'Reaction outcome loss': 0.34310377469408687, 'Total loss': 0.34310377469408687}
2022-12-31 12:21:08,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:08,922 INFO:     Epoch: 29
2022-12-31 12:21:10,540 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4546650807062785, 'Total loss': 0.4546650807062785} | train loss {'Reaction outcome loss': 0.33825111269515795, 'Total loss': 0.33825111269515795}
2022-12-31 12:21:10,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:10,540 INFO:     Epoch: 30
2022-12-31 12:21:12,141 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44427456955115, 'Total loss': 0.44427456955115} | train loss {'Reaction outcome loss': 0.33929677076474596, 'Total loss': 0.33929677076474596}
2022-12-31 12:21:12,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:12,141 INFO:     Epoch: 31
2022-12-31 12:21:13,722 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4619587481021881, 'Total loss': 0.4619587481021881} | train loss {'Reaction outcome loss': 0.33312688966410875, 'Total loss': 0.33312688966410875}
2022-12-31 12:21:13,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:13,722 INFO:     Epoch: 32
2022-12-31 12:21:15,323 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4006404270728429, 'Total loss': 0.4006404270728429} | train loss {'Reaction outcome loss': 0.3282817190200308, 'Total loss': 0.3282817190200308}
2022-12-31 12:21:15,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:15,324 INFO:     Epoch: 33
2022-12-31 12:21:16,925 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4069252987702688, 'Total loss': 0.4069252987702688} | train loss {'Reaction outcome loss': 0.31906047433505963, 'Total loss': 0.31906047433505963}
2022-12-31 12:21:16,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:16,925 INFO:     Epoch: 34
2022-12-31 12:21:18,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41378238300482434, 'Total loss': 0.41378238300482434} | train loss {'Reaction outcome loss': 0.32220154764117115, 'Total loss': 0.32220154764117115}
2022-12-31 12:21:18,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:18,528 INFO:     Epoch: 35
2022-12-31 12:21:20,128 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3943347970644633, 'Total loss': 0.3943347970644633} | train loss {'Reaction outcome loss': 0.31867145420643533, 'Total loss': 0.31867145420643533}
2022-12-31 12:21:20,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:20,129 INFO:     Epoch: 36
2022-12-31 12:21:21,729 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42740557293097176, 'Total loss': 0.42740557293097176} | train loss {'Reaction outcome loss': 0.3139953164071062, 'Total loss': 0.3139953164071062}
2022-12-31 12:21:21,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:21,730 INFO:     Epoch: 37
2022-12-31 12:21:23,080 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4144988665978114, 'Total loss': 0.4144988665978114} | train loss {'Reaction outcome loss': 0.3103805530381246, 'Total loss': 0.3103805530381246}
2022-12-31 12:21:23,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:23,080 INFO:     Epoch: 38
2022-12-31 12:21:24,144 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42788761854171753, 'Total loss': 0.42788761854171753} | train loss {'Reaction outcome loss': 0.30074522241841267, 'Total loss': 0.30074522241841267}
2022-12-31 12:21:24,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:24,144 INFO:     Epoch: 39
2022-12-31 12:21:25,205 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3935117890437444, 'Total loss': 0.3935117890437444} | train loss {'Reaction outcome loss': 0.2976120574957263, 'Total loss': 0.2976120574957263}
2022-12-31 12:21:25,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:25,205 INFO:     Epoch: 40
2022-12-31 12:21:26,273 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3993657941619555, 'Total loss': 0.3993657941619555} | train loss {'Reaction outcome loss': 0.2927709496750014, 'Total loss': 0.2927709496750014}
2022-12-31 12:21:26,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:26,273 INFO:     Epoch: 41
2022-12-31 12:21:27,450 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47145056327184043, 'Total loss': 0.47145056327184043} | train loss {'Reaction outcome loss': 0.290179830302831, 'Total loss': 0.290179830302831}
2022-12-31 12:21:27,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:27,451 INFO:     Epoch: 42
2022-12-31 12:21:29,027 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38341709077358244, 'Total loss': 0.38341709077358244} | train loss {'Reaction outcome loss': 0.2939726873742838, 'Total loss': 0.2939726873742838}
2022-12-31 12:21:29,027 INFO:     Found new best model at epoch 42
2022-12-31 12:21:29,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:29,028 INFO:     Epoch: 43
2022-12-31 12:21:30,605 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4124947994947433, 'Total loss': 0.4124947994947433} | train loss {'Reaction outcome loss': 0.28246567418703633, 'Total loss': 0.28246567418703633}
2022-12-31 12:21:30,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:30,606 INFO:     Epoch: 44
2022-12-31 12:21:32,228 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4431325286626816, 'Total loss': 0.4431325286626816} | train loss {'Reaction outcome loss': 0.2843698776007569, 'Total loss': 0.2843698776007569}
2022-12-31 12:21:32,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:32,228 INFO:     Epoch: 45
2022-12-31 12:21:33,850 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39179715315500896, 'Total loss': 0.39179715315500896} | train loss {'Reaction outcome loss': 0.2819844105274138, 'Total loss': 0.2819844105274138}
2022-12-31 12:21:33,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:33,851 INFO:     Epoch: 46
2022-12-31 12:21:35,501 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4010935773452123, 'Total loss': 0.4010935773452123} | train loss {'Reaction outcome loss': 0.27968428860398103, 'Total loss': 0.27968428860398103}
2022-12-31 12:21:35,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:35,501 INFO:     Epoch: 47
2022-12-31 12:21:37,122 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38320282598336536, 'Total loss': 0.38320282598336536} | train loss {'Reaction outcome loss': 0.27365382781157094, 'Total loss': 0.27365382781157094}
2022-12-31 12:21:37,123 INFO:     Found new best model at epoch 47
2022-12-31 12:21:37,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:37,123 INFO:     Epoch: 48
2022-12-31 12:21:38,717 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3899243732293447, 'Total loss': 0.3899243732293447} | train loss {'Reaction outcome loss': 0.26969533710040317, 'Total loss': 0.26969533710040317}
2022-12-31 12:21:38,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:38,717 INFO:     Epoch: 49
2022-12-31 12:21:40,343 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38202306628227234, 'Total loss': 0.38202306628227234} | train loss {'Reaction outcome loss': 0.26755933248757446, 'Total loss': 0.26755933248757446}
2022-12-31 12:21:40,345 INFO:     Found new best model at epoch 49
2022-12-31 12:21:40,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:40,346 INFO:     Epoch: 50
2022-12-31 12:21:41,977 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3826458225647608, 'Total loss': 0.3826458225647608} | train loss {'Reaction outcome loss': 0.26671676103868625, 'Total loss': 0.26671676103868625}
2022-12-31 12:21:41,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:41,977 INFO:     Epoch: 51
2022-12-31 12:21:43,620 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42293159365653993, 'Total loss': 0.42293159365653993} | train loss {'Reaction outcome loss': 0.2581463268257841, 'Total loss': 0.2581463268257841}
2022-12-31 12:21:43,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:43,620 INFO:     Epoch: 52
2022-12-31 12:21:45,216 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44320354660352074, 'Total loss': 0.44320354660352074} | train loss {'Reaction outcome loss': 0.2567041950830578, 'Total loss': 0.2567041950830578}
2022-12-31 12:21:45,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:45,216 INFO:     Epoch: 53
2022-12-31 12:21:46,811 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4332076986630758, 'Total loss': 0.4332076986630758} | train loss {'Reaction outcome loss': 0.26163599988187314, 'Total loss': 0.26163599988187314}
2022-12-31 12:21:46,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:46,811 INFO:     Epoch: 54
2022-12-31 12:21:48,392 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40539044539133706, 'Total loss': 0.40539044539133706} | train loss {'Reaction outcome loss': 0.25883355667053237, 'Total loss': 0.25883355667053237}
2022-12-31 12:21:48,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:48,392 INFO:     Epoch: 55
2022-12-31 12:21:49,988 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4108325779438019, 'Total loss': 0.4108325779438019} | train loss {'Reaction outcome loss': 0.2485024529325701, 'Total loss': 0.2485024529325701}
2022-12-31 12:21:49,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:49,988 INFO:     Epoch: 56
2022-12-31 12:21:51,582 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4085534373919169, 'Total loss': 0.4085534373919169} | train loss {'Reaction outcome loss': 0.250485013150712, 'Total loss': 0.250485013150712}
2022-12-31 12:21:51,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:51,582 INFO:     Epoch: 57
2022-12-31 12:21:53,178 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38386279344558716, 'Total loss': 0.38386279344558716} | train loss {'Reaction outcome loss': 0.2469851229829292, 'Total loss': 0.2469851229829292}
2022-12-31 12:21:53,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:53,178 INFO:     Epoch: 58
2022-12-31 12:21:54,757 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38612346053123475, 'Total loss': 0.38612346053123475} | train loss {'Reaction outcome loss': 0.25020581351960225, 'Total loss': 0.25020581351960225}
2022-12-31 12:21:54,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:54,757 INFO:     Epoch: 59
2022-12-31 12:21:56,345 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40983609308799107, 'Total loss': 0.40983609308799107} | train loss {'Reaction outcome loss': 0.24806955889084914, 'Total loss': 0.24806955889084914}
2022-12-31 12:21:56,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:56,346 INFO:     Epoch: 60
2022-12-31 12:21:57,940 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3899565994739532, 'Total loss': 0.3899565994739532} | train loss {'Reaction outcome loss': 0.2462171175428768, 'Total loss': 0.2462171175428768}
2022-12-31 12:21:57,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:57,940 INFO:     Epoch: 61
2022-12-31 12:21:59,535 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39084814190864564, 'Total loss': 0.39084814190864564} | train loss {'Reaction outcome loss': 0.24292576268152163, 'Total loss': 0.24292576268152163}
2022-12-31 12:21:59,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:21:59,536 INFO:     Epoch: 62
2022-12-31 12:22:01,130 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3786270091931025, 'Total loss': 0.3786270091931025} | train loss {'Reaction outcome loss': 0.24312899620646108, 'Total loss': 0.24312899620646108}
2022-12-31 12:22:01,130 INFO:     Found new best model at epoch 62
2022-12-31 12:22:01,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:01,131 INFO:     Epoch: 63
2022-12-31 12:22:02,724 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.396122465779384, 'Total loss': 0.396122465779384} | train loss {'Reaction outcome loss': 0.23738698553919357, 'Total loss': 0.23738698553919357}
2022-12-31 12:22:02,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:02,725 INFO:     Epoch: 64
2022-12-31 12:22:04,325 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40279377102851865, 'Total loss': 0.40279377102851865} | train loss {'Reaction outcome loss': 0.23802205592557027, 'Total loss': 0.23802205592557027}
2022-12-31 12:22:04,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:04,326 INFO:     Epoch: 65
2022-12-31 12:22:05,911 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42342575192451476, 'Total loss': 0.42342575192451476} | train loss {'Reaction outcome loss': 0.2268243828978743, 'Total loss': 0.2268243828978743}
2022-12-31 12:22:05,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:05,911 INFO:     Epoch: 66
2022-12-31 12:22:07,544 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4050974726676941, 'Total loss': 0.4050974726676941} | train loss {'Reaction outcome loss': 0.22896750365812196, 'Total loss': 0.22896750365812196}
2022-12-31 12:22:07,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:07,544 INFO:     Epoch: 67
2022-12-31 12:22:09,155 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39845645626386006, 'Total loss': 0.39845645626386006} | train loss {'Reaction outcome loss': 0.22665286492420375, 'Total loss': 0.22665286492420375}
2022-12-31 12:22:09,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:09,155 INFO:     Epoch: 68
2022-12-31 12:22:10,749 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3712840681274732, 'Total loss': 0.3712840681274732} | train loss {'Reaction outcome loss': 0.22950377689851245, 'Total loss': 0.22950377689851245}
2022-12-31 12:22:10,749 INFO:     Found new best model at epoch 68
2022-12-31 12:22:10,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:10,750 INFO:     Epoch: 69
2022-12-31 12:22:12,344 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41998656491438546, 'Total loss': 0.41998656491438546} | train loss {'Reaction outcome loss': 0.23045851419387509, 'Total loss': 0.23045851419387509}
2022-12-31 12:22:12,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:12,344 INFO:     Epoch: 70
2022-12-31 12:22:13,966 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4291786606113116, 'Total loss': 0.4291786606113116} | train loss {'Reaction outcome loss': 0.2244197708846879, 'Total loss': 0.2244197708846879}
2022-12-31 12:22:13,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:13,967 INFO:     Epoch: 71
2022-12-31 12:22:15,593 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39516682326793673, 'Total loss': 0.39516682326793673} | train loss {'Reaction outcome loss': 0.2279673116485568, 'Total loss': 0.2279673116485568}
2022-12-31 12:22:15,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:15,595 INFO:     Epoch: 72
2022-12-31 12:22:17,167 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39145403504371645, 'Total loss': 0.39145403504371645} | train loss {'Reaction outcome loss': 0.22743487961753442, 'Total loss': 0.22743487961753442}
2022-12-31 12:22:17,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:17,167 INFO:     Epoch: 73
2022-12-31 12:22:18,802 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3838320841391881, 'Total loss': 0.3838320841391881} | train loss {'Reaction outcome loss': 0.22018610210885314, 'Total loss': 0.22018610210885314}
2022-12-31 12:22:18,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:18,802 INFO:     Epoch: 74
2022-12-31 12:22:20,444 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4049479951461156, 'Total loss': 0.4049479951461156} | train loss {'Reaction outcome loss': 0.22572983731345755, 'Total loss': 0.22572983731345755}
2022-12-31 12:22:20,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:20,445 INFO:     Epoch: 75
2022-12-31 12:22:22,013 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43273360232512154, 'Total loss': 0.43273360232512154} | train loss {'Reaction outcome loss': 0.2158882020442427, 'Total loss': 0.2158882020442427}
2022-12-31 12:22:22,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:22,014 INFO:     Epoch: 76
2022-12-31 12:22:23,596 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43656547168890636, 'Total loss': 0.43656547168890636} | train loss {'Reaction outcome loss': 0.22068593019524413, 'Total loss': 0.22068593019524413}
2022-12-31 12:22:23,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:23,596 INFO:     Epoch: 77
2022-12-31 12:22:25,193 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4115889976421992, 'Total loss': 0.4115889976421992} | train loss {'Reaction outcome loss': 0.21717212215936096, 'Total loss': 0.21717212215936096}
2022-12-31 12:22:25,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:25,193 INFO:     Epoch: 78
2022-12-31 12:22:26,791 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39509116957585017, 'Total loss': 0.39509116957585017} | train loss {'Reaction outcome loss': 0.21858426413233698, 'Total loss': 0.21858426413233698}
2022-12-31 12:22:26,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:26,791 INFO:     Epoch: 79
2022-12-31 12:22:28,388 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4292418281237284, 'Total loss': 0.4292418281237284} | train loss {'Reaction outcome loss': 0.2090595493120325, 'Total loss': 0.2090595493120325}
2022-12-31 12:22:28,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:28,388 INFO:     Epoch: 80
2022-12-31 12:22:29,985 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38734889527161914, 'Total loss': 0.38734889527161914} | train loss {'Reaction outcome loss': 0.21848053547016677, 'Total loss': 0.21848053547016677}
2022-12-31 12:22:29,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:29,985 INFO:     Epoch: 81
2022-12-31 12:22:31,594 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3569595714410146, 'Total loss': 0.3569595714410146} | train loss {'Reaction outcome loss': 0.21518383081322603, 'Total loss': 0.21518383081322603}
2022-12-31 12:22:31,595 INFO:     Found new best model at epoch 81
2022-12-31 12:22:31,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:31,595 INFO:     Epoch: 82
2022-12-31 12:22:33,211 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38755554556846616, 'Total loss': 0.38755554556846616} | train loss {'Reaction outcome loss': 0.21340477765694152, 'Total loss': 0.21340477765694152}
2022-12-31 12:22:33,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:33,212 INFO:     Epoch: 83
2022-12-31 12:22:34,863 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4085552314917246, 'Total loss': 0.4085552314917246} | train loss {'Reaction outcome loss': 0.20685864926526581, 'Total loss': 0.20685864926526581}
2022-12-31 12:22:34,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:34,864 INFO:     Epoch: 84
2022-12-31 12:22:36,484 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3703479260206223, 'Total loss': 0.3703479260206223} | train loss {'Reaction outcome loss': 0.20624356498656266, 'Total loss': 0.20624356498656266}
2022-12-31 12:22:36,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:36,484 INFO:     Epoch: 85
2022-12-31 12:22:38,081 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.401231250166893, 'Total loss': 0.401231250166893} | train loss {'Reaction outcome loss': 0.21076026111569282, 'Total loss': 0.21076026111569282}
2022-12-31 12:22:38,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:38,081 INFO:     Epoch: 86
2022-12-31 12:22:39,670 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3849220499396324, 'Total loss': 0.3849220499396324} | train loss {'Reaction outcome loss': 0.218620144157079, 'Total loss': 0.218620144157079}
2022-12-31 12:22:39,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:39,671 INFO:     Epoch: 87
2022-12-31 12:22:41,283 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4093164086341858, 'Total loss': 0.4093164086341858} | train loss {'Reaction outcome loss': 0.2048976608674402, 'Total loss': 0.2048976608674402}
2022-12-31 12:22:41,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:41,283 INFO:     Epoch: 88
2022-12-31 12:22:42,877 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4094441165526708, 'Total loss': 0.4094441165526708} | train loss {'Reaction outcome loss': 0.20357796271759881, 'Total loss': 0.20357796271759881}
2022-12-31 12:22:42,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:42,878 INFO:     Epoch: 89
2022-12-31 12:22:44,477 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3961614737908045, 'Total loss': 0.3961614737908045} | train loss {'Reaction outcome loss': 0.2083099489474166, 'Total loss': 0.2083099489474166}
2022-12-31 12:22:44,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:44,478 INFO:     Epoch: 90
2022-12-31 12:22:46,100 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.413966104388237, 'Total loss': 0.413966104388237} | train loss {'Reaction outcome loss': 0.20117803239501522, 'Total loss': 0.20117803239501522}
2022-12-31 12:22:46,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:46,101 INFO:     Epoch: 91
2022-12-31 12:22:47,710 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.405216908454895, 'Total loss': 0.405216908454895} | train loss {'Reaction outcome loss': 0.19968546750907698, 'Total loss': 0.19968546750907698}
2022-12-31 12:22:47,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:47,710 INFO:     Epoch: 92
2022-12-31 12:22:49,289 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43565609653790793, 'Total loss': 0.43565609653790793} | train loss {'Reaction outcome loss': 0.1996483940930262, 'Total loss': 0.1996483940930262}
2022-12-31 12:22:49,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:49,289 INFO:     Epoch: 93
2022-12-31 12:22:50,887 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41389747659365334, 'Total loss': 0.41389747659365334} | train loss {'Reaction outcome loss': 0.20029892736746774, 'Total loss': 0.20029892736746774}
2022-12-31 12:22:50,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:50,887 INFO:     Epoch: 94
2022-12-31 12:22:52,487 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37982735435167947, 'Total loss': 0.37982735435167947} | train loss {'Reaction outcome loss': 0.2037057920093954, 'Total loss': 0.2037057920093954}
2022-12-31 12:22:52,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:52,488 INFO:     Epoch: 95
2022-12-31 12:22:54,090 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37529801030953724, 'Total loss': 0.37529801030953724} | train loss {'Reaction outcome loss': 0.20179735328050424, 'Total loss': 0.20179735328050424}
2022-12-31 12:22:54,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:54,090 INFO:     Epoch: 96
2022-12-31 12:22:55,690 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4262322853008906, 'Total loss': 0.4262322853008906} | train loss {'Reaction outcome loss': 0.19450177887223496, 'Total loss': 0.19450177887223496}
2022-12-31 12:22:55,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:55,691 INFO:     Epoch: 97
2022-12-31 12:22:57,292 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4278406570355097, 'Total loss': 0.4278406570355097} | train loss {'Reaction outcome loss': 0.20261104916813819, 'Total loss': 0.20261104916813819}
2022-12-31 12:22:57,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:57,292 INFO:     Epoch: 98
2022-12-31 12:22:58,900 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39113962948322295, 'Total loss': 0.39113962948322295} | train loss {'Reaction outcome loss': 0.19312682733565134, 'Total loss': 0.19312682733565134}
2022-12-31 12:22:58,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:22:58,900 INFO:     Epoch: 99
2022-12-31 12:23:00,487 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.403864374011755, 'Total loss': 0.403864374011755} | train loss {'Reaction outcome loss': 0.19624736627740583, 'Total loss': 0.19624736627740583}
2022-12-31 12:23:00,487 INFO:     Best model found after epoch 82 of 100.
2022-12-31 12:23:00,487 INFO:   Done with stage: TRAINING
2022-12-31 12:23:00,487 INFO:   Starting stage: EVALUATION
2022-12-31 12:23:00,621 INFO:   Done with stage: EVALUATION
2022-12-31 12:23:00,621 INFO:   Leaving out SEQ value Fold_4
2022-12-31 12:23:00,633 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 12:23:00,633 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:23:01,276 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:23:01,276 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:23:01,344 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:23:01,344 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:23:01,344 INFO:     No hyperparam tuning for this model
2022-12-31 12:23:01,344 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:23:01,344 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:23:01,345 INFO:     None feature selector for col prot
2022-12-31 12:23:01,345 INFO:     None feature selector for col prot
2022-12-31 12:23:01,345 INFO:     None feature selector for col prot
2022-12-31 12:23:01,346 INFO:     None feature selector for col chem
2022-12-31 12:23:01,346 INFO:     None feature selector for col chem
2022-12-31 12:23:01,346 INFO:     None feature selector for col chem
2022-12-31 12:23:01,346 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:23:01,346 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:23:01,348 INFO:     Number of params in model 223921
2022-12-31 12:23:01,351 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:23:01,351 INFO:   Starting stage: TRAINING
2022-12-31 12:23:01,397 INFO:     Val loss before train {'Reaction outcome loss': 1.0465783516565959, 'Total loss': 1.0465783516565959}
2022-12-31 12:23:01,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:01,398 INFO:     Epoch: 0
2022-12-31 12:23:03,024 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6324376106262207, 'Total loss': 0.6324376106262207} | train loss {'Reaction outcome loss': 0.8250383993921181, 'Total loss': 0.8250383993921181}
2022-12-31 12:23:03,025 INFO:     Found new best model at epoch 0
2022-12-31 12:23:03,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:03,026 INFO:     Epoch: 1
2022-12-31 12:23:04,638 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5364346474409103, 'Total loss': 0.5364346474409103} | train loss {'Reaction outcome loss': 0.6096876387221172, 'Total loss': 0.6096876387221172}
2022-12-31 12:23:04,638 INFO:     Found new best model at epoch 1
2022-12-31 12:23:04,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:04,639 INFO:     Epoch: 2
2022-12-31 12:23:06,251 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4726616978645325, 'Total loss': 0.4726616978645325} | train loss {'Reaction outcome loss': 0.543372525246409, 'Total loss': 0.543372525246409}
2022-12-31 12:23:06,251 INFO:     Found new best model at epoch 2
2022-12-31 12:23:06,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:06,252 INFO:     Epoch: 3
2022-12-31 12:23:07,854 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4674016426006953, 'Total loss': 0.4674016426006953} | train loss {'Reaction outcome loss': 0.5150419435315374, 'Total loss': 0.5150419435315374}
2022-12-31 12:23:07,854 INFO:     Found new best model at epoch 3
2022-12-31 12:23:07,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:07,855 INFO:     Epoch: 4
2022-12-31 12:23:09,451 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47420585751533506, 'Total loss': 0.47420585751533506} | train loss {'Reaction outcome loss': 0.5061094373248626, 'Total loss': 0.5061094373248626}
2022-12-31 12:23:09,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:09,451 INFO:     Epoch: 5
2022-12-31 12:23:11,068 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45571099321047465, 'Total loss': 0.45571099321047465} | train loss {'Reaction outcome loss': 0.4858135083231373, 'Total loss': 0.4858135083231373}
2022-12-31 12:23:11,068 INFO:     Found new best model at epoch 5
2022-12-31 12:23:11,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:11,069 INFO:     Epoch: 6
2022-12-31 12:23:12,734 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45667805671691897, 'Total loss': 0.45667805671691897} | train loss {'Reaction outcome loss': 0.49189274299187935, 'Total loss': 0.49189274299187935}
2022-12-31 12:23:12,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:12,734 INFO:     Epoch: 7
2022-12-31 12:23:14,354 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4317337175210317, 'Total loss': 0.4317337175210317} | train loss {'Reaction outcome loss': 0.4895177064649086, 'Total loss': 0.4895177064649086}
2022-12-31 12:23:14,354 INFO:     Found new best model at epoch 7
2022-12-31 12:23:14,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:14,355 INFO:     Epoch: 8
2022-12-31 12:23:15,948 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4413922131061554, 'Total loss': 0.4413922131061554} | train loss {'Reaction outcome loss': 0.46726779061862256, 'Total loss': 0.46726779061862256}
2022-12-31 12:23:15,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:15,948 INFO:     Epoch: 9
2022-12-31 12:23:17,539 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4773602326711019, 'Total loss': 0.4773602326711019} | train loss {'Reaction outcome loss': 0.4568836893076482, 'Total loss': 0.4568836893076482}
2022-12-31 12:23:17,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:17,540 INFO:     Epoch: 10
2022-12-31 12:23:19,160 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4178926487763723, 'Total loss': 0.4178926487763723} | train loss {'Reaction outcome loss': 0.4544806741717933, 'Total loss': 0.4544806741717933}
2022-12-31 12:23:19,160 INFO:     Found new best model at epoch 10
2022-12-31 12:23:19,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:19,161 INFO:     Epoch: 11
2022-12-31 12:23:20,777 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41847398479779563, 'Total loss': 0.41847398479779563} | train loss {'Reaction outcome loss': 0.45047933786459593, 'Total loss': 0.45047933786459593}
2022-12-31 12:23:20,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:20,778 INFO:     Epoch: 12
2022-12-31 12:23:22,395 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4366214007139206, 'Total loss': 0.4366214007139206} | train loss {'Reaction outcome loss': 0.4451260108001314, 'Total loss': 0.4451260108001314}
2022-12-31 12:23:22,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:22,395 INFO:     Epoch: 13
2022-12-31 12:23:24,010 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4136493941148122, 'Total loss': 0.4136493941148122} | train loss {'Reaction outcome loss': 0.43723885076978797, 'Total loss': 0.43723885076978797}
2022-12-31 12:23:24,011 INFO:     Found new best model at epoch 13
2022-12-31 12:23:24,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:24,012 INFO:     Epoch: 14
2022-12-31 12:23:25,607 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42754280467828115, 'Total loss': 0.42754280467828115} | train loss {'Reaction outcome loss': 0.4260676337601752, 'Total loss': 0.4260676337601752}
2022-12-31 12:23:25,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:25,607 INFO:     Epoch: 15
2022-12-31 12:23:27,202 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4068244069814682, 'Total loss': 0.4068244069814682} | train loss {'Reaction outcome loss': 0.4260969510284232, 'Total loss': 0.4260969510284232}
2022-12-31 12:23:27,202 INFO:     Found new best model at epoch 15
2022-12-31 12:23:27,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:27,203 INFO:     Epoch: 16
2022-12-31 12:23:28,817 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4477493017911911, 'Total loss': 0.4477493017911911} | train loss {'Reaction outcome loss': 0.41732810471275233, 'Total loss': 0.41732810471275233}
2022-12-31 12:23:28,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:28,817 INFO:     Epoch: 17
2022-12-31 12:23:30,435 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3846472988526026, 'Total loss': 0.3846472988526026} | train loss {'Reaction outcome loss': 0.4165601667718611, 'Total loss': 0.4165601667718611}
2022-12-31 12:23:30,435 INFO:     Found new best model at epoch 17
2022-12-31 12:23:30,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:30,436 INFO:     Epoch: 18
2022-12-31 12:23:32,054 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4021045476198196, 'Total loss': 0.4021045476198196} | train loss {'Reaction outcome loss': 0.41007788854546373, 'Total loss': 0.41007788854546373}
2022-12-31 12:23:32,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:32,054 INFO:     Epoch: 19
2022-12-31 12:23:33,672 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4157187600930532, 'Total loss': 0.4157187600930532} | train loss {'Reaction outcome loss': 0.400572886974787, 'Total loss': 0.400572886974787}
2022-12-31 12:23:33,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:33,672 INFO:     Epoch: 20
2022-12-31 12:23:35,266 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3830301831165949, 'Total loss': 0.3830301831165949} | train loss {'Reaction outcome loss': 0.4023254210048396, 'Total loss': 0.4023254210048396}
2022-12-31 12:23:35,267 INFO:     Found new best model at epoch 20
2022-12-31 12:23:35,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:35,268 INFO:     Epoch: 21
2022-12-31 12:23:36,874 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39599687854448956, 'Total loss': 0.39599687854448956} | train loss {'Reaction outcome loss': 0.39283407254961145, 'Total loss': 0.39283407254961145}
2022-12-31 12:23:36,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:36,875 INFO:     Epoch: 22
2022-12-31 12:23:38,492 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4292188713947932, 'Total loss': 0.4292188713947932} | train loss {'Reaction outcome loss': 0.388187432486186, 'Total loss': 0.388187432486186}
2022-12-31 12:23:38,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:38,492 INFO:     Epoch: 23
2022-12-31 12:23:40,110 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36229049613078435, 'Total loss': 0.36229049613078435} | train loss {'Reaction outcome loss': 0.38090855132587964, 'Total loss': 0.38090855132587964}
2022-12-31 12:23:40,110 INFO:     Found new best model at epoch 23
2022-12-31 12:23:40,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:40,111 INFO:     Epoch: 24
2022-12-31 12:23:41,733 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35935392578442893, 'Total loss': 0.35935392578442893} | train loss {'Reaction outcome loss': 0.3737934941478222, 'Total loss': 0.3737934941478222}
2022-12-31 12:23:41,733 INFO:     Found new best model at epoch 24
2022-12-31 12:23:41,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:41,734 INFO:     Epoch: 25
2022-12-31 12:23:43,361 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38442293703556063, 'Total loss': 0.38442293703556063} | train loss {'Reaction outcome loss': 0.3769592917288073, 'Total loss': 0.3769592917288073}
2022-12-31 12:23:43,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:43,361 INFO:     Epoch: 26
2022-12-31 12:23:44,952 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3419203778107961, 'Total loss': 0.3419203778107961} | train loss {'Reaction outcome loss': 0.3720805860602, 'Total loss': 0.3720805860602}
2022-12-31 12:23:44,952 INFO:     Found new best model at epoch 26
2022-12-31 12:23:44,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:44,953 INFO:     Epoch: 27
2022-12-31 12:23:46,582 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39492135047912597, 'Total loss': 0.39492135047912597} | train loss {'Reaction outcome loss': 0.3613763688800395, 'Total loss': 0.3613763688800395}
2022-12-31 12:23:46,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:46,582 INFO:     Epoch: 28
2022-12-31 12:23:48,195 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3837313435971737, 'Total loss': 0.3837313435971737} | train loss {'Reaction outcome loss': 0.3615163301482149, 'Total loss': 0.3615163301482149}
2022-12-31 12:23:48,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:48,197 INFO:     Epoch: 29
2022-12-31 12:23:49,812 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3668276528517405, 'Total loss': 0.3668276528517405} | train loss {'Reaction outcome loss': 0.37033333113767963, 'Total loss': 0.37033333113767963}
2022-12-31 12:23:49,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:49,812 INFO:     Epoch: 30
2022-12-31 12:23:51,430 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3754735747973124, 'Total loss': 0.3754735747973124} | train loss {'Reaction outcome loss': 0.3571641403047935, 'Total loss': 0.3571641403047935}
2022-12-31 12:23:51,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:51,430 INFO:     Epoch: 31
2022-12-31 12:23:53,028 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3909272323052088, 'Total loss': 0.3909272323052088} | train loss {'Reaction outcome loss': 0.3637344094560198, 'Total loss': 0.3637344094560198}
2022-12-31 12:23:53,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:53,029 INFO:     Epoch: 32
2022-12-31 12:23:54,627 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4162427634000778, 'Total loss': 0.4162427634000778} | train loss {'Reaction outcome loss': 0.4080915814400583, 'Total loss': 0.4080915814400583}
2022-12-31 12:23:54,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:54,628 INFO:     Epoch: 33
2022-12-31 12:23:56,248 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3668440302213033, 'Total loss': 0.3668440302213033} | train loss {'Reaction outcome loss': 0.3436637908881243, 'Total loss': 0.3436637908881243}
2022-12-31 12:23:56,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:56,248 INFO:     Epoch: 34
2022-12-31 12:23:57,862 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3579029013713201, 'Total loss': 0.3579029013713201} | train loss {'Reaction outcome loss': 0.3353058323804019, 'Total loss': 0.3353058323804019}
2022-12-31 12:23:57,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:57,862 INFO:     Epoch: 35
2022-12-31 12:23:59,475 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35139776865641276, 'Total loss': 0.35139776865641276} | train loss {'Reaction outcome loss': 0.3380869938587041, 'Total loss': 0.3380869938587041}
2022-12-31 12:23:59,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:23:59,476 INFO:     Epoch: 36
2022-12-31 12:24:01,082 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4032576988140742, 'Total loss': 0.4032576988140742} | train loss {'Reaction outcome loss': 0.32853428789319983, 'Total loss': 0.32853428789319983}
2022-12-31 12:24:01,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:01,082 INFO:     Epoch: 37
2022-12-31 12:24:02,665 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37120146254698433, 'Total loss': 0.37120146254698433} | train loss {'Reaction outcome loss': 0.3219979150124583, 'Total loss': 0.3219979150124583}
2022-12-31 12:24:02,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:02,665 INFO:     Epoch: 38
2022-12-31 12:24:04,285 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3751041491826375, 'Total loss': 0.3751041491826375} | train loss {'Reaction outcome loss': 0.31944392226042523, 'Total loss': 0.31944392226042523}
2022-12-31 12:24:04,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:04,285 INFO:     Epoch: 39
2022-12-31 12:24:05,904 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3954536527395248, 'Total loss': 0.3954536527395248} | train loss {'Reaction outcome loss': 0.3135365659431757, 'Total loss': 0.3135365659431757}
2022-12-31 12:24:05,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:05,905 INFO:     Epoch: 40
2022-12-31 12:24:07,517 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3591193159421285, 'Total loss': 0.3591193159421285} | train loss {'Reaction outcome loss': 0.31103333066878974, 'Total loss': 0.31103333066878974}
2022-12-31 12:24:07,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:07,518 INFO:     Epoch: 41
2022-12-31 12:24:09,127 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35492837578058245, 'Total loss': 0.35492837578058245} | train loss {'Reaction outcome loss': 0.3323113080923972, 'Total loss': 0.3323113080923972}
2022-12-31 12:24:09,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:09,127 INFO:     Epoch: 42
2022-12-31 12:24:10,723 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38703112254540123, 'Total loss': 0.38703112254540123} | train loss {'Reaction outcome loss': 0.3151695812256008, 'Total loss': 0.3151695812256008}
2022-12-31 12:24:10,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:10,723 INFO:     Epoch: 43
2022-12-31 12:24:12,321 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3862875064214071, 'Total loss': 0.3862875064214071} | train loss {'Reaction outcome loss': 0.35321241708985274, 'Total loss': 0.35321241708985274}
2022-12-31 12:24:12,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:12,322 INFO:     Epoch: 44
2022-12-31 12:24:13,931 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3648987223704656, 'Total loss': 0.3648987223704656} | train loss {'Reaction outcome loss': 0.3192959309030878, 'Total loss': 0.3192959309030878}
2022-12-31 12:24:13,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:13,931 INFO:     Epoch: 45
2022-12-31 12:24:15,540 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3378970007101695, 'Total loss': 0.3378970007101695} | train loss {'Reaction outcome loss': 0.29797448905562796, 'Total loss': 0.29797448905562796}
2022-12-31 12:24:15,540 INFO:     Found new best model at epoch 45
2022-12-31 12:24:15,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:15,541 INFO:     Epoch: 46
2022-12-31 12:24:17,150 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3478066066900889, 'Total loss': 0.3478066066900889} | train loss {'Reaction outcome loss': 0.29613022260583827, 'Total loss': 0.29613022260583827}
2022-12-31 12:24:17,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:17,150 INFO:     Epoch: 47
2022-12-31 12:24:18,760 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4081202020247777, 'Total loss': 0.4081202020247777} | train loss {'Reaction outcome loss': 0.327417731945002, 'Total loss': 0.327417731945002}
2022-12-31 12:24:18,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:18,760 INFO:     Epoch: 48
2022-12-31 12:24:20,349 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3412639995416005, 'Total loss': 0.3412639995416005} | train loss {'Reaction outcome loss': 0.2982570174811543, 'Total loss': 0.2982570174811543}
2022-12-31 12:24:20,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:20,349 INFO:     Epoch: 49
2022-12-31 12:24:21,959 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.381737165649732, 'Total loss': 0.381737165649732} | train loss {'Reaction outcome loss': 0.2899747853153858, 'Total loss': 0.2899747853153858}
2022-12-31 12:24:21,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:21,959 INFO:     Epoch: 50
2022-12-31 12:24:23,581 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3425010770559311, 'Total loss': 0.3425010770559311} | train loss {'Reaction outcome loss': 0.29082685382024426, 'Total loss': 0.29082685382024426}
2022-12-31 12:24:23,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:23,581 INFO:     Epoch: 51
2022-12-31 12:24:25,190 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3751695384581884, 'Total loss': 0.3751695384581884} | train loss {'Reaction outcome loss': 0.28254468371227814, 'Total loss': 0.28254468371227814}
2022-12-31 12:24:25,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:25,191 INFO:     Epoch: 52
2022-12-31 12:24:26,801 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3882528613011042, 'Total loss': 0.3882528613011042} | train loss {'Reaction outcome loss': 0.2776474428423883, 'Total loss': 0.2776474428423883}
2022-12-31 12:24:26,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:26,801 INFO:     Epoch: 53
2022-12-31 12:24:28,389 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3648857682943344, 'Total loss': 0.3648857682943344} | train loss {'Reaction outcome loss': 0.27426802957943175, 'Total loss': 0.27426802957943175}
2022-12-31 12:24:28,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:28,389 INFO:     Epoch: 54
2022-12-31 12:24:30,016 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3828916778167089, 'Total loss': 0.3828916778167089} | train loss {'Reaction outcome loss': 0.2803036123917319, 'Total loss': 0.2803036123917319}
2022-12-31 12:24:30,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:30,016 INFO:     Epoch: 55
2022-12-31 12:24:31,630 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3601167634129524, 'Total loss': 0.3601167634129524} | train loss {'Reaction outcome loss': 0.2644750995365768, 'Total loss': 0.2644750995365768}
2022-12-31 12:24:31,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:31,631 INFO:     Epoch: 56
2022-12-31 12:24:33,237 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4066277106602987, 'Total loss': 0.4066277106602987} | train loss {'Reaction outcome loss': 0.27132282048325473, 'Total loss': 0.27132282048325473}
2022-12-31 12:24:33,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:33,238 INFO:     Epoch: 57
2022-12-31 12:24:34,872 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36499724388122556, 'Total loss': 0.36499724388122556} | train loss {'Reaction outcome loss': 0.2726978981357905, 'Total loss': 0.2726978981357905}
2022-12-31 12:24:34,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:34,872 INFO:     Epoch: 58
2022-12-31 12:24:36,501 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37911295692125957, 'Total loss': 0.37911295692125957} | train loss {'Reaction outcome loss': 0.26573425355920754, 'Total loss': 0.26573425355920754}
2022-12-31 12:24:36,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:36,502 INFO:     Epoch: 59
2022-12-31 12:24:38,106 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38970275819301603, 'Total loss': 0.38970275819301603} | train loss {'Reaction outcome loss': 0.27223936920526665, 'Total loss': 0.27223936920526665}
2022-12-31 12:24:38,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:38,106 INFO:     Epoch: 60
2022-12-31 12:24:39,719 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35406794051329293, 'Total loss': 0.35406794051329293} | train loss {'Reaction outcome loss': 0.2784390360980794, 'Total loss': 0.2784390360980794}
2022-12-31 12:24:39,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:39,719 INFO:     Epoch: 61
2022-12-31 12:24:41,369 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3623340457677841, 'Total loss': 0.3623340457677841} | train loss {'Reaction outcome loss': 0.28396128767264495, 'Total loss': 0.28396128767264495}
2022-12-31 12:24:41,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:41,370 INFO:     Epoch: 62
2022-12-31 12:24:43,059 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37666971459984777, 'Total loss': 0.37666971459984777} | train loss {'Reaction outcome loss': 0.2649655499410363, 'Total loss': 0.2649655499410363}
2022-12-31 12:24:43,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:43,059 INFO:     Epoch: 63
2022-12-31 12:24:44,698 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3697270353635152, 'Total loss': 0.3697270353635152} | train loss {'Reaction outcome loss': 0.25983012789283355, 'Total loss': 0.25983012789283355}
2022-12-31 12:24:44,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:44,699 INFO:     Epoch: 64
2022-12-31 12:24:46,361 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3621812671422958, 'Total loss': 0.3621812671422958} | train loss {'Reaction outcome loss': 0.2571121386360962, 'Total loss': 0.2571121386360962}
2022-12-31 12:24:46,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:46,362 INFO:     Epoch: 65
2022-12-31 12:24:47,949 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3399254158139229, 'Total loss': 0.3399254158139229} | train loss {'Reaction outcome loss': 0.2516970472288844, 'Total loss': 0.2516970472288844}
2022-12-31 12:24:47,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:47,950 INFO:     Epoch: 66
2022-12-31 12:24:49,557 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3653563866391778, 'Total loss': 0.3653563866391778} | train loss {'Reaction outcome loss': 0.2526004789177787, 'Total loss': 0.2526004789177787}
2022-12-31 12:24:49,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:49,557 INFO:     Epoch: 67
2022-12-31 12:24:51,167 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37791938533385594, 'Total loss': 0.37791938533385594} | train loss {'Reaction outcome loss': 0.2486735791966751, 'Total loss': 0.2486735791966751}
2022-12-31 12:24:51,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:51,167 INFO:     Epoch: 68
2022-12-31 12:24:52,778 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.367916202545166, 'Total loss': 0.367916202545166} | train loss {'Reaction outcome loss': 0.25715084867229104, 'Total loss': 0.25715084867229104}
2022-12-31 12:24:52,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:52,778 INFO:     Epoch: 69
2022-12-31 12:24:54,389 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3470400998989741, 'Total loss': 0.3470400998989741} | train loss {'Reaction outcome loss': 0.24924569772364508, 'Total loss': 0.24924569772364508}
2022-12-31 12:24:54,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:54,389 INFO:     Epoch: 70
2022-12-31 12:24:55,979 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4147962510585785, 'Total loss': 0.4147962510585785} | train loss {'Reaction outcome loss': 0.24868759963715423, 'Total loss': 0.24868759963715423}
2022-12-31 12:24:55,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:55,980 INFO:     Epoch: 71
2022-12-31 12:24:57,577 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34135895272096, 'Total loss': 0.34135895272096} | train loss {'Reaction outcome loss': 0.24606382960885548, 'Total loss': 0.24606382960885548}
2022-12-31 12:24:57,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:57,578 INFO:     Epoch: 72
2022-12-31 12:24:59,188 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3675931135813395, 'Total loss': 0.3675931135813395} | train loss {'Reaction outcome loss': 0.24198501322256483, 'Total loss': 0.24198501322256483}
2022-12-31 12:24:59,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:24:59,188 INFO:     Epoch: 73
2022-12-31 12:25:00,800 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3413495202859243, 'Total loss': 0.3413495202859243} | train loss {'Reaction outcome loss': 0.25841309697083803, 'Total loss': 0.25841309697083803}
2022-12-31 12:25:00,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:00,802 INFO:     Epoch: 74
2022-12-31 12:25:02,410 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39902727901935575, 'Total loss': 0.39902727901935575} | train loss {'Reaction outcome loss': 0.36004228182339476, 'Total loss': 0.36004228182339476}
2022-12-31 12:25:02,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:02,410 INFO:     Epoch: 75
2022-12-31 12:25:04,023 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3803677986065547, 'Total loss': 0.3803677986065547} | train loss {'Reaction outcome loss': 0.29124593943782634, 'Total loss': 0.29124593943782634}
2022-12-31 12:25:04,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:04,023 INFO:     Epoch: 76
2022-12-31 12:25:05,638 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.32888447542985283, 'Total loss': 0.32888447542985283} | train loss {'Reaction outcome loss': 0.2677636065976306, 'Total loss': 0.2677636065976306}
2022-12-31 12:25:05,638 INFO:     Found new best model at epoch 76
2022-12-31 12:25:05,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:05,639 INFO:     Epoch: 77
2022-12-31 12:25:07,233 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3894098271926244, 'Total loss': 0.3894098271926244} | train loss {'Reaction outcome loss': 0.25989200855753775, 'Total loss': 0.25989200855753775}
2022-12-31 12:25:07,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:07,234 INFO:     Epoch: 78
2022-12-31 12:25:08,823 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3536911750833193, 'Total loss': 0.3536911750833193} | train loss {'Reaction outcome loss': 0.25722271140556835, 'Total loss': 0.25722271140556835}
2022-12-31 12:25:08,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:08,824 INFO:     Epoch: 79
2022-12-31 12:25:10,454 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38085656861464184, 'Total loss': 0.38085656861464184} | train loss {'Reaction outcome loss': 0.2510531828806236, 'Total loss': 0.2510531828806236}
2022-12-31 12:25:10,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:10,454 INFO:     Epoch: 80
2022-12-31 12:25:12,069 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35786055674155554, 'Total loss': 0.35786055674155554} | train loss {'Reaction outcome loss': 0.30144713936881645, 'Total loss': 0.30144713936881645}
2022-12-31 12:25:12,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:12,069 INFO:     Epoch: 81
2022-12-31 12:25:13,658 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36946584433317187, 'Total loss': 0.36946584433317187} | train loss {'Reaction outcome loss': 0.2566061841485941, 'Total loss': 0.2566061841485941}
2022-12-31 12:25:13,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:13,658 INFO:     Epoch: 82
2022-12-31 12:25:15,282 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3558743933836619, 'Total loss': 0.3558743933836619} | train loss {'Reaction outcome loss': 0.2547910860628334, 'Total loss': 0.2547910860628334}
2022-12-31 12:25:15,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:15,283 INFO:     Epoch: 83
2022-12-31 12:25:16,900 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34438688854376476, 'Total loss': 0.34438688854376476} | train loss {'Reaction outcome loss': 0.24618917493595238, 'Total loss': 0.24618917493595238}
2022-12-31 12:25:16,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:16,901 INFO:     Epoch: 84
2022-12-31 12:25:18,530 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3738058974345525, 'Total loss': 0.3738058974345525} | train loss {'Reaction outcome loss': 0.24832730025535557, 'Total loss': 0.24832730025535557}
2022-12-31 12:25:18,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:18,530 INFO:     Epoch: 85
2022-12-31 12:25:20,140 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3493252868453662, 'Total loss': 0.3493252868453662} | train loss {'Reaction outcome loss': 0.2390483089866525, 'Total loss': 0.2390483089866525}
2022-12-31 12:25:20,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:20,141 INFO:     Epoch: 86
2022-12-31 12:25:21,750 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.412521043419838, 'Total loss': 0.412521043419838} | train loss {'Reaction outcome loss': 0.23593252839687603, 'Total loss': 0.23593252839687603}
2022-12-31 12:25:21,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:21,750 INFO:     Epoch: 87
2022-12-31 12:25:23,341 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3540357540051142, 'Total loss': 0.3540357540051142} | train loss {'Reaction outcome loss': 0.2363604132016548, 'Total loss': 0.2363604132016548}
2022-12-31 12:25:23,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:23,341 INFO:     Epoch: 88
2022-12-31 12:25:24,974 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37870394984881084, 'Total loss': 0.37870394984881084} | train loss {'Reaction outcome loss': 0.22241971919987444, 'Total loss': 0.22241971919987444}
2022-12-31 12:25:24,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:24,975 INFO:     Epoch: 89
2022-12-31 12:25:26,612 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37131440043449404, 'Total loss': 0.37131440043449404} | train loss {'Reaction outcome loss': 0.22907546819592622, 'Total loss': 0.22907546819592622}
2022-12-31 12:25:26,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:26,613 INFO:     Epoch: 90
2022-12-31 12:25:28,283 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.35845831347008544, 'Total loss': 0.35845831347008544} | train loss {'Reaction outcome loss': 0.23718188373722893, 'Total loss': 0.23718188373722893}
2022-12-31 12:25:28,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:28,283 INFO:     Epoch: 91
2022-12-31 12:25:29,924 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3677755415439606, 'Total loss': 0.3677755415439606} | train loss {'Reaction outcome loss': 0.2703875725602974, 'Total loss': 0.2703875725602974}
2022-12-31 12:25:29,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:29,924 INFO:     Epoch: 92
2022-12-31 12:25:31,554 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37236738155285515, 'Total loss': 0.37236738155285515} | train loss {'Reaction outcome loss': 0.23713100621935682, 'Total loss': 0.23713100621935682}
2022-12-31 12:25:31,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:31,555 INFO:     Epoch: 93
2022-12-31 12:25:33,145 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3575808117787043, 'Total loss': 0.3575808117787043} | train loss {'Reaction outcome loss': 0.23764836859239344, 'Total loss': 0.23764836859239344}
2022-12-31 12:25:33,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:33,145 INFO:     Epoch: 94
2022-12-31 12:25:34,755 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41518219709396365, 'Total loss': 0.41518219709396365} | train loss {'Reaction outcome loss': 0.23316598177442086, 'Total loss': 0.23316598177442086}
2022-12-31 12:25:34,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:34,755 INFO:     Epoch: 95
2022-12-31 12:25:36,364 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3346145495772362, 'Total loss': 0.3346145495772362} | train loss {'Reaction outcome loss': 0.2466516529911778, 'Total loss': 0.2466516529911778}
2022-12-31 12:25:36,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:36,364 INFO:     Epoch: 96
2022-12-31 12:25:37,971 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36688884142786266, 'Total loss': 0.36688884142786266} | train loss {'Reaction outcome loss': 0.28708364359656535, 'Total loss': 0.28708364359656535}
2022-12-31 12:25:37,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:37,971 INFO:     Epoch: 97
2022-12-31 12:25:39,577 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3749561160802841, 'Total loss': 0.3749561160802841} | train loss {'Reaction outcome loss': 0.27408345954398206, 'Total loss': 0.27408345954398206}
2022-12-31 12:25:39,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:39,577 INFO:     Epoch: 98
2022-12-31 12:25:41,164 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3555065780878067, 'Total loss': 0.3555065780878067} | train loss {'Reaction outcome loss': 0.23751671082404294, 'Total loss': 0.23751671082404294}
2022-12-31 12:25:41,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:41,165 INFO:     Epoch: 99
2022-12-31 12:25:42,759 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3589651356140772, 'Total loss': 0.3589651356140772} | train loss {'Reaction outcome loss': 0.2310081122416085, 'Total loss': 0.2310081122416085}
2022-12-31 12:25:42,760 INFO:     Best model found after epoch 77 of 100.
2022-12-31 12:25:42,760 INFO:   Done with stage: TRAINING
2022-12-31 12:25:42,760 INFO:   Starting stage: EVALUATION
2022-12-31 12:25:42,888 INFO:   Done with stage: EVALUATION
2022-12-31 12:25:42,888 INFO:   Leaving out SEQ value Fold_5
2022-12-31 12:25:42,901 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 12:25:42,901 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:25:43,560 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:25:43,560 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:25:43,628 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:25:43,628 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:25:43,629 INFO:     No hyperparam tuning for this model
2022-12-31 12:25:43,629 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:25:43,629 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:25:43,629 INFO:     None feature selector for col prot
2022-12-31 12:25:43,630 INFO:     None feature selector for col prot
2022-12-31 12:25:43,630 INFO:     None feature selector for col prot
2022-12-31 12:25:43,630 INFO:     None feature selector for col chem
2022-12-31 12:25:43,630 INFO:     None feature selector for col chem
2022-12-31 12:25:43,630 INFO:     None feature selector for col chem
2022-12-31 12:25:43,630 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:25:43,630 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:25:43,632 INFO:     Number of params in model 223921
2022-12-31 12:25:43,635 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:25:43,635 INFO:   Starting stage: TRAINING
2022-12-31 12:25:43,682 INFO:     Val loss before train {'Reaction outcome loss': 0.8118433217207591, 'Total loss': 0.8118433217207591}
2022-12-31 12:25:43,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:43,682 INFO:     Epoch: 0
2022-12-31 12:25:45,292 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5944125831127167, 'Total loss': 0.5944125831127167} | train loss {'Reaction outcome loss': 0.831357586254712, 'Total loss': 0.831357586254712}
2022-12-31 12:25:45,292 INFO:     Found new best model at epoch 0
2022-12-31 12:25:45,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:45,293 INFO:     Epoch: 1
2022-12-31 12:25:46,905 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4741245239973068, 'Total loss': 0.4741245239973068} | train loss {'Reaction outcome loss': 0.598968320590064, 'Total loss': 0.598968320590064}
2022-12-31 12:25:46,905 INFO:     Found new best model at epoch 1
2022-12-31 12:25:46,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:46,906 INFO:     Epoch: 2
2022-12-31 12:25:48,524 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.461195049683253, 'Total loss': 0.461195049683253} | train loss {'Reaction outcome loss': 0.5295742507553273, 'Total loss': 0.5295742507553273}
2022-12-31 12:25:48,524 INFO:     Found new best model at epoch 2
2022-12-31 12:25:48,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:48,525 INFO:     Epoch: 3
2022-12-31 12:25:50,124 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41393907368183136, 'Total loss': 0.41393907368183136} | train loss {'Reaction outcome loss': 0.5029014557169663, 'Total loss': 0.5029014557169663}
2022-12-31 12:25:50,125 INFO:     Found new best model at epoch 3
2022-12-31 12:25:50,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:50,126 INFO:     Epoch: 4
2022-12-31 12:25:51,728 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4156993478536606, 'Total loss': 0.4156993478536606} | train loss {'Reaction outcome loss': 0.4885666359094937, 'Total loss': 0.4885666359094937}
2022-12-31 12:25:51,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:51,728 INFO:     Epoch: 5
2022-12-31 12:25:53,348 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41652196447054546, 'Total loss': 0.41652196447054546} | train loss {'Reaction outcome loss': 0.4809976790086887, 'Total loss': 0.4809976790086887}
2022-12-31 12:25:53,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:53,349 INFO:     Epoch: 6
2022-12-31 12:25:54,968 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3936336914698283, 'Total loss': 0.3936336914698283} | train loss {'Reaction outcome loss': 0.4740049163894963, 'Total loss': 0.4740049163894963}
2022-12-31 12:25:54,968 INFO:     Found new best model at epoch 6
2022-12-31 12:25:54,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:54,969 INFO:     Epoch: 7
2022-12-31 12:25:56,588 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.384015088280042, 'Total loss': 0.384015088280042} | train loss {'Reaction outcome loss': 0.4603994026080796, 'Total loss': 0.4603994026080796}
2022-12-31 12:25:56,588 INFO:     Found new best model at epoch 7
2022-12-31 12:25:56,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:56,589 INFO:     Epoch: 8
2022-12-31 12:25:58,207 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4230029692252477, 'Total loss': 0.4230029692252477} | train loss {'Reaction outcome loss': 0.4568098292884413, 'Total loss': 0.4568098292884413}
2022-12-31 12:25:58,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:58,207 INFO:     Epoch: 9
2022-12-31 12:25:59,805 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3996180832386017, 'Total loss': 0.3996180832386017} | train loss {'Reaction outcome loss': 0.4494908194356877, 'Total loss': 0.4494908194356877}
2022-12-31 12:25:59,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:25:59,805 INFO:     Epoch: 10
2022-12-31 12:26:00,923 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38215094010035194, 'Total loss': 0.38215094010035194} | train loss {'Reaction outcome loss': 0.44391221195351777, 'Total loss': 0.44391221195351777}
2022-12-31 12:26:00,923 INFO:     Found new best model at epoch 10
2022-12-31 12:26:00,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:00,924 INFO:     Epoch: 11
2022-12-31 12:26:02,013 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3730916659037272, 'Total loss': 0.3730916659037272} | train loss {'Reaction outcome loss': 0.43512383875326127, 'Total loss': 0.43512383875326127}
2022-12-31 12:26:02,014 INFO:     Found new best model at epoch 11
2022-12-31 12:26:02,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:02,015 INFO:     Epoch: 12
2022-12-31 12:26:03,092 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3833903690179189, 'Total loss': 0.3833903690179189} | train loss {'Reaction outcome loss': 0.4280344001437783, 'Total loss': 0.4280344001437783}
2022-12-31 12:26:03,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:03,093 INFO:     Epoch: 13
2022-12-31 12:26:04,177 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3791620800892512, 'Total loss': 0.3791620800892512} | train loss {'Reaction outcome loss': 0.4254018325721744, 'Total loss': 0.4254018325721744}
2022-12-31 12:26:04,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:04,177 INFO:     Epoch: 14
2022-12-31 12:26:05,661 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3790290256341298, 'Total loss': 0.3790290256341298} | train loss {'Reaction outcome loss': 0.4170256201110592, 'Total loss': 0.4170256201110592}
2022-12-31 12:26:05,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:05,661 INFO:     Epoch: 15
2022-12-31 12:26:07,347 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41019262770811715, 'Total loss': 0.41019262770811715} | train loss {'Reaction outcome loss': 0.4080657490700591, 'Total loss': 0.4080657490700591}
2022-12-31 12:26:07,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:07,347 INFO:     Epoch: 16
2022-12-31 12:26:09,017 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3838386336962382, 'Total loss': 0.3838386336962382} | train loss {'Reaction outcome loss': 0.40492528639330333, 'Total loss': 0.40492528639330333}
2022-12-31 12:26:09,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:09,018 INFO:     Epoch: 17
2022-12-31 12:26:10,638 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3837416042884191, 'Total loss': 0.3837416042884191} | train loss {'Reaction outcome loss': 0.40148069515878115, 'Total loss': 0.40148069515878115}
2022-12-31 12:26:10,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:10,638 INFO:     Epoch: 18
2022-12-31 12:26:12,259 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3866761475801468, 'Total loss': 0.3866761475801468} | train loss {'Reaction outcome loss': 0.39686678565150996, 'Total loss': 0.39686678565150996}
2022-12-31 12:26:12,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:12,259 INFO:     Epoch: 19
2022-12-31 12:26:13,858 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36092603305975596, 'Total loss': 0.36092603305975596} | train loss {'Reaction outcome loss': 0.3930089803755499, 'Total loss': 0.3930089803755499}
2022-12-31 12:26:13,858 INFO:     Found new best model at epoch 19
2022-12-31 12:26:13,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:13,859 INFO:     Epoch: 20
2022-12-31 12:26:15,471 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37764068245887755, 'Total loss': 0.37764068245887755} | train loss {'Reaction outcome loss': 0.3878541709552603, 'Total loss': 0.3878541709552603}
2022-12-31 12:26:15,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:15,471 INFO:     Epoch: 21
2022-12-31 12:26:17,092 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3519723365704219, 'Total loss': 0.3519723365704219} | train loss {'Reaction outcome loss': 0.37944172831111006, 'Total loss': 0.37944172831111006}
2022-12-31 12:26:17,093 INFO:     Found new best model at epoch 21
2022-12-31 12:26:17,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:17,094 INFO:     Epoch: 22
2022-12-31 12:26:18,714 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3614382088184357, 'Total loss': 0.3614382088184357} | train loss {'Reaction outcome loss': 0.37215163596377904, 'Total loss': 0.37215163596377904}
2022-12-31 12:26:18,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:18,715 INFO:     Epoch: 23
2022-12-31 12:26:20,336 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.33979245920976003, 'Total loss': 0.33979245920976003} | train loss {'Reaction outcome loss': 0.3727826720325525, 'Total loss': 0.3727826720325525}
2022-12-31 12:26:20,336 INFO:     Found new best model at epoch 23
2022-12-31 12:26:20,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:20,337 INFO:     Epoch: 24
2022-12-31 12:26:21,958 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3844569365183512, 'Total loss': 0.3844569365183512} | train loss {'Reaction outcome loss': 0.36302955589838837, 'Total loss': 0.36302955589838837}
2022-12-31 12:26:21,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:21,959 INFO:     Epoch: 25
2022-12-31 12:26:23,554 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3895177235205968, 'Total loss': 0.3895177235205968} | train loss {'Reaction outcome loss': 0.3629203353763057, 'Total loss': 0.3629203353763057}
2022-12-31 12:26:23,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:23,554 INFO:     Epoch: 26
2022-12-31 12:26:25,205 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3613926450411479, 'Total loss': 0.3613926450411479} | train loss {'Reaction outcome loss': 0.3577285455237227, 'Total loss': 0.3577285455237227}
2022-12-31 12:26:25,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:25,205 INFO:     Epoch: 27
2022-12-31 12:26:26,869 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38732833564281466, 'Total loss': 0.38732833564281466} | train loss {'Reaction outcome loss': 0.35159325911680284, 'Total loss': 0.35159325911680284}
2022-12-31 12:26:26,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:26,869 INFO:     Epoch: 28
2022-12-31 12:26:28,501 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3686039835214615, 'Total loss': 0.3686039835214615} | train loss {'Reaction outcome loss': 0.34964080797743713, 'Total loss': 0.34964080797743713}
2022-12-31 12:26:28,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:28,501 INFO:     Epoch: 29
2022-12-31 12:26:30,157 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3586014916499456, 'Total loss': 0.3586014916499456} | train loss {'Reaction outcome loss': 0.3396698795527973, 'Total loss': 0.3396698795527973}
2022-12-31 12:26:30,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:30,157 INFO:     Epoch: 30
2022-12-31 12:26:31,766 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36834588448206584, 'Total loss': 0.36834588448206584} | train loss {'Reaction outcome loss': 0.34274729284783995, 'Total loss': 0.34274729284783995}
2022-12-31 12:26:31,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:31,767 INFO:     Epoch: 31
2022-12-31 12:26:33,374 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4071574151515961, 'Total loss': 0.4071574151515961} | train loss {'Reaction outcome loss': 0.33771968979912975, 'Total loss': 0.33771968979912975}
2022-12-31 12:26:33,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:33,374 INFO:     Epoch: 32
2022-12-31 12:26:35,026 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.33725678324699404, 'Total loss': 0.33725678324699404} | train loss {'Reaction outcome loss': 0.33073011102551586, 'Total loss': 0.33073011102551586}
2022-12-31 12:26:35,026 INFO:     Found new best model at epoch 32
2022-12-31 12:26:35,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:35,027 INFO:     Epoch: 33
2022-12-31 12:26:36,635 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3610052665074666, 'Total loss': 0.3610052665074666} | train loss {'Reaction outcome loss': 0.3272179515783537, 'Total loss': 0.3272179515783537}
2022-12-31 12:26:36,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:36,635 INFO:     Epoch: 34
2022-12-31 12:26:38,284 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36292559703191124, 'Total loss': 0.36292559703191124} | train loss {'Reaction outcome loss': 0.32273984073731876, 'Total loss': 0.32273984073731876}
2022-12-31 12:26:38,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:38,285 INFO:     Epoch: 35
2022-12-31 12:26:39,892 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3699370284875234, 'Total loss': 0.3699370284875234} | train loss {'Reaction outcome loss': 0.3148451919267324, 'Total loss': 0.3148451919267324}
2022-12-31 12:26:39,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:39,893 INFO:     Epoch: 36
2022-12-31 12:26:41,517 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3479026844104131, 'Total loss': 0.3479026844104131} | train loss {'Reaction outcome loss': 0.3211601402355015, 'Total loss': 0.3211601402355015}
2022-12-31 12:26:41,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:41,517 INFO:     Epoch: 37
2022-12-31 12:26:43,151 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36532618006070455, 'Total loss': 0.36532618006070455} | train loss {'Reaction outcome loss': 0.3063393396859995, 'Total loss': 0.3063393396859995}
2022-12-31 12:26:43,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:43,151 INFO:     Epoch: 38
2022-12-31 12:26:44,801 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35144893725713094, 'Total loss': 0.35144893725713094} | train loss {'Reaction outcome loss': 0.3062722703663881, 'Total loss': 0.3062722703663881}
2022-12-31 12:26:44,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:44,801 INFO:     Epoch: 39
2022-12-31 12:26:46,397 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37523507376511894, 'Total loss': 0.37523507376511894} | train loss {'Reaction outcome loss': 0.30444889800750824, 'Total loss': 0.30444889800750824}
2022-12-31 12:26:46,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:46,397 INFO:     Epoch: 40
2022-12-31 12:26:48,045 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3520857026179632, 'Total loss': 0.3520857026179632} | train loss {'Reaction outcome loss': 0.2983397435033795, 'Total loss': 0.2983397435033795}
2022-12-31 12:26:48,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:48,045 INFO:     Epoch: 41
2022-12-31 12:26:49,675 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37359456221262616, 'Total loss': 0.37359456221262616} | train loss {'Reaction outcome loss': 0.2948126896462716, 'Total loss': 0.2948126896462716}
2022-12-31 12:26:49,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:49,675 INFO:     Epoch: 42
2022-12-31 12:26:51,251 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.33144713242848717, 'Total loss': 0.33144713242848717} | train loss {'Reaction outcome loss': 0.29797672219439963, 'Total loss': 0.29797672219439963}
2022-12-31 12:26:51,251 INFO:     Found new best model at epoch 42
2022-12-31 12:26:51,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:51,252 INFO:     Epoch: 43
2022-12-31 12:26:52,899 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35679183204968773, 'Total loss': 0.35679183204968773} | train loss {'Reaction outcome loss': 0.28807579240818854, 'Total loss': 0.28807579240818854}
2022-12-31 12:26:52,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:52,899 INFO:     Epoch: 44
2022-12-31 12:26:54,517 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3406627483665943, 'Total loss': 0.3406627483665943} | train loss {'Reaction outcome loss': 0.2857606039258117, 'Total loss': 0.2857606039258117}
2022-12-31 12:26:54,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:54,518 INFO:     Epoch: 45
2022-12-31 12:26:56,135 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35636558185021083, 'Total loss': 0.35636558185021083} | train loss {'Reaction outcome loss': 0.2906511834610778, 'Total loss': 0.2906511834610778}
2022-12-31 12:26:56,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:56,136 INFO:     Epoch: 46
2022-12-31 12:26:57,754 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.344234444697698, 'Total loss': 0.344234444697698} | train loss {'Reaction outcome loss': 0.2900669429895034, 'Total loss': 0.2900669429895034}
2022-12-31 12:26:57,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:57,755 INFO:     Epoch: 47
2022-12-31 12:26:59,352 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.33606680234273273, 'Total loss': 0.33606680234273273} | train loss {'Reaction outcome loss': 0.2809777284303297, 'Total loss': 0.2809777284303297}
2022-12-31 12:26:59,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:26:59,352 INFO:     Epoch: 48
2022-12-31 12:27:00,964 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3357295016447703, 'Total loss': 0.3357295016447703} | train loss {'Reaction outcome loss': 0.2780860874277375, 'Total loss': 0.2780860874277375}
2022-12-31 12:27:00,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:00,964 INFO:     Epoch: 49
2022-12-31 12:27:02,580 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.32522295316060384, 'Total loss': 0.32522295316060384} | train loss {'Reaction outcome loss': 0.2716313101458851, 'Total loss': 0.2716313101458851}
2022-12-31 12:27:02,581 INFO:     Found new best model at epoch 49
2022-12-31 12:27:02,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:02,581 INFO:     Epoch: 50
2022-12-31 12:27:04,197 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37521132280429204, 'Total loss': 0.37521132280429204} | train loss {'Reaction outcome loss': 0.2633149847119293, 'Total loss': 0.2633149847119293}
2022-12-31 12:27:04,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:04,198 INFO:     Epoch: 51
2022-12-31 12:27:05,813 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.33253109951814014, 'Total loss': 0.33253109951814014} | train loss {'Reaction outcome loss': 0.2713777254258252, 'Total loss': 0.2713777254258252}
2022-12-31 12:27:05,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:05,813 INFO:     Epoch: 52
2022-12-31 12:27:07,431 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3333531756574909, 'Total loss': 0.3333531756574909} | train loss {'Reaction outcome loss': 0.26035401923077633, 'Total loss': 0.26035401923077633}
2022-12-31 12:27:07,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:07,431 INFO:     Epoch: 53
2022-12-31 12:27:09,019 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3383148769537608, 'Total loss': 0.3383148769537608} | train loss {'Reaction outcome loss': 0.2636816897278228, 'Total loss': 0.2636816897278228}
2022-12-31 12:27:09,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:09,019 INFO:     Epoch: 54
2022-12-31 12:27:10,629 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.30554776067535083, 'Total loss': 0.30554776067535083} | train loss {'Reaction outcome loss': 0.26172459952950156, 'Total loss': 0.26172459952950156}
2022-12-31 12:27:10,629 INFO:     Found new best model at epoch 54
2022-12-31 12:27:10,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:10,630 INFO:     Epoch: 55
2022-12-31 12:27:12,245 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.32888092497984567, 'Total loss': 0.32888092497984567} | train loss {'Reaction outcome loss': 0.2579109616685215, 'Total loss': 0.2579109616685215}
2022-12-31 12:27:12,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:12,245 INFO:     Epoch: 56
2022-12-31 12:27:13,862 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.358972575267156, 'Total loss': 0.358972575267156} | train loss {'Reaction outcome loss': 0.25973480011904715, 'Total loss': 0.25973480011904715}
2022-12-31 12:27:13,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:13,863 INFO:     Epoch: 57
2022-12-31 12:27:15,480 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3196375797192256, 'Total loss': 0.3196375797192256} | train loss {'Reaction outcome loss': 0.26135852920826164, 'Total loss': 0.26135852920826164}
2022-12-31 12:27:15,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:15,480 INFO:     Epoch: 58
2022-12-31 12:27:17,103 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.33034458458423616, 'Total loss': 0.33034458458423616} | train loss {'Reaction outcome loss': 0.2524952554692, 'Total loss': 0.2524952554692}
2022-12-31 12:27:17,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:17,103 INFO:     Epoch: 59
2022-12-31 12:27:18,726 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3610585560401281, 'Total loss': 0.3610585560401281} | train loss {'Reaction outcome loss': 0.24534492821362044, 'Total loss': 0.24534492821362044}
2022-12-31 12:27:18,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:18,726 INFO:     Epoch: 60
2022-12-31 12:27:20,345 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34779727359612783, 'Total loss': 0.34779727359612783} | train loss {'Reaction outcome loss': 0.2521205402856915, 'Total loss': 0.2521205402856915}
2022-12-31 12:27:20,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:20,346 INFO:     Epoch: 61
2022-12-31 12:27:21,960 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.333275497953097, 'Total loss': 0.333275497953097} | train loss {'Reaction outcome loss': 0.24582636134450186, 'Total loss': 0.24582636134450186}
2022-12-31 12:27:21,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:21,960 INFO:     Epoch: 62
2022-12-31 12:27:23,577 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.340350087483724, 'Total loss': 0.340350087483724} | train loss {'Reaction outcome loss': 0.24277635120084032, 'Total loss': 0.24277635120084032}
2022-12-31 12:27:23,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:23,577 INFO:     Epoch: 63
2022-12-31 12:27:25,194 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.34852102150519687, 'Total loss': 0.34852102150519687} | train loss {'Reaction outcome loss': 0.24157864319342137, 'Total loss': 0.24157864319342137}
2022-12-31 12:27:25,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:25,194 INFO:     Epoch: 64
2022-12-31 12:27:26,801 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.29952372585733733, 'Total loss': 0.29952372585733733} | train loss {'Reaction outcome loss': 0.24540006471562473, 'Total loss': 0.24540006471562473}
2022-12-31 12:27:26,801 INFO:     Found new best model at epoch 64
2022-12-31 12:27:26,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:26,802 INFO:     Epoch: 65
2022-12-31 12:27:28,424 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.326431014140447, 'Total loss': 0.326431014140447} | train loss {'Reaction outcome loss': 0.24507038672505088, 'Total loss': 0.24507038672505088}
2022-12-31 12:27:28,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:28,424 INFO:     Epoch: 66
2022-12-31 12:27:30,044 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3746096978584925, 'Total loss': 0.3746096978584925} | train loss {'Reaction outcome loss': 0.24015585326048333, 'Total loss': 0.24015585326048333}
2022-12-31 12:27:30,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:30,044 INFO:     Epoch: 67
2022-12-31 12:27:31,659 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36181986729303994, 'Total loss': 0.36181986729303994} | train loss {'Reaction outcome loss': 0.23241651387690207, 'Total loss': 0.23241651387690207}
2022-12-31 12:27:31,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:31,659 INFO:     Epoch: 68
2022-12-31 12:27:33,274 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34845481713612875, 'Total loss': 0.34845481713612875} | train loss {'Reaction outcome loss': 0.2347751270966194, 'Total loss': 0.2347751270966194}
2022-12-31 12:27:33,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:33,275 INFO:     Epoch: 69
2022-12-31 12:27:34,914 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3703395888209343, 'Total loss': 0.3703395888209343} | train loss {'Reaction outcome loss': 0.23075026494286122, 'Total loss': 0.23075026494286122}
2022-12-31 12:27:34,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:34,914 INFO:     Epoch: 70
2022-12-31 12:27:36,498 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.29430635025103885, 'Total loss': 0.29430635025103885} | train loss {'Reaction outcome loss': 0.23186639307019727, 'Total loss': 0.23186639307019727}
2022-12-31 12:27:36,498 INFO:     Found new best model at epoch 70
2022-12-31 12:27:36,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:36,499 INFO:     Epoch: 71
2022-12-31 12:27:38,117 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34544964830080666, 'Total loss': 0.34544964830080666} | train loss {'Reaction outcome loss': 0.2358183928156803, 'Total loss': 0.2358183928156803}
2022-12-31 12:27:38,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:38,117 INFO:     Epoch: 72
2022-12-31 12:27:39,753 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3562544087568919, 'Total loss': 0.3562544087568919} | train loss {'Reaction outcome loss': 0.2281832996056506, 'Total loss': 0.2281832996056506}
2022-12-31 12:27:39,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:39,754 INFO:     Epoch: 73
2022-12-31 12:27:41,373 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.31849485834439595, 'Total loss': 0.31849485834439595} | train loss {'Reaction outcome loss': 0.227682105289093, 'Total loss': 0.227682105289093}
2022-12-31 12:27:41,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:41,373 INFO:     Epoch: 74
2022-12-31 12:27:42,994 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34205073515574136, 'Total loss': 0.34205073515574136} | train loss {'Reaction outcome loss': 0.22171189618508738, 'Total loss': 0.22171189618508738}
2022-12-31 12:27:42,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:42,995 INFO:     Epoch: 75
2022-12-31 12:27:44,596 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.34623110890388487, 'Total loss': 0.34623110890388487} | train loss {'Reaction outcome loss': 0.2236941553221928, 'Total loss': 0.2236941553221928}
2022-12-31 12:27:44,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:44,597 INFO:     Epoch: 76
2022-12-31 12:27:46,213 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.32432734270890556, 'Total loss': 0.32432734270890556} | train loss {'Reaction outcome loss': 0.2266549402847886, 'Total loss': 0.2266549402847886}
2022-12-31 12:27:46,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:46,213 INFO:     Epoch: 77
2022-12-31 12:27:47,837 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3373208984732628, 'Total loss': 0.3373208984732628} | train loss {'Reaction outcome loss': 0.231438057463522, 'Total loss': 0.231438057463522}
2022-12-31 12:27:47,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:47,837 INFO:     Epoch: 78
2022-12-31 12:27:49,461 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34348600208759306, 'Total loss': 0.34348600208759306} | train loss {'Reaction outcome loss': 0.21702337231392896, 'Total loss': 0.21702337231392896}
2022-12-31 12:27:49,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:49,461 INFO:     Epoch: 79
2022-12-31 12:27:51,085 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3437987188498179, 'Total loss': 0.3437987188498179} | train loss {'Reaction outcome loss': 0.22335682846673022, 'Total loss': 0.22335682846673022}
2022-12-31 12:27:51,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:51,085 INFO:     Epoch: 80
2022-12-31 12:27:52,711 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.30940443525711697, 'Total loss': 0.30940443525711697} | train loss {'Reaction outcome loss': 0.22170006747387808, 'Total loss': 0.22170006747387808}
2022-12-31 12:27:52,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:52,712 INFO:     Epoch: 81
2022-12-31 12:27:54,327 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35421110192934674, 'Total loss': 0.35421110192934674} | train loss {'Reaction outcome loss': 0.216070151407043, 'Total loss': 0.216070151407043}
2022-12-31 12:27:54,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:54,327 INFO:     Epoch: 82
2022-12-31 12:27:55,966 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3255742798248927, 'Total loss': 0.3255742798248927} | train loss {'Reaction outcome loss': 0.21270898807565228, 'Total loss': 0.21270898807565228}
2022-12-31 12:27:55,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:55,967 INFO:     Epoch: 83
2022-12-31 12:27:57,591 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3078276639183362, 'Total loss': 0.3078276639183362} | train loss {'Reaction outcome loss': 0.21437193930740822, 'Total loss': 0.21437193930740822}
2022-12-31 12:27:57,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:57,591 INFO:     Epoch: 84
2022-12-31 12:27:59,216 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3589944789807002, 'Total loss': 0.3589944789807002} | train loss {'Reaction outcome loss': 0.21581833697317523, 'Total loss': 0.21581833697317523}
2022-12-31 12:27:59,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:27:59,216 INFO:     Epoch: 85
2022-12-31 12:28:00,841 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.330312916636467, 'Total loss': 0.330312916636467} | train loss {'Reaction outcome loss': 0.2149870280405029, 'Total loss': 0.2149870280405029}
2022-12-31 12:28:00,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:00,841 INFO:     Epoch: 86
2022-12-31 12:28:02,446 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3158018151919047, 'Total loss': 0.3158018151919047} | train loss {'Reaction outcome loss': 0.21221443885661634, 'Total loss': 0.21221443885661634}
2022-12-31 12:28:02,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:02,447 INFO:     Epoch: 87
2022-12-31 12:28:04,046 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3180600717663765, 'Total loss': 0.3180600717663765} | train loss {'Reaction outcome loss': 0.20963590615008712, 'Total loss': 0.20963590615008712}
2022-12-31 12:28:04,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:04,047 INFO:     Epoch: 88
2022-12-31 12:28:05,670 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3372125715017319, 'Total loss': 0.3372125715017319} | train loss {'Reaction outcome loss': 0.21174442324289777, 'Total loss': 0.21174442324289777}
2022-12-31 12:28:05,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:05,670 INFO:     Epoch: 89
2022-12-31 12:28:07,291 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.32945353438456854, 'Total loss': 0.32945353438456854} | train loss {'Reaction outcome loss': 0.20449123904109, 'Total loss': 0.20449123904109}
2022-12-31 12:28:07,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:07,292 INFO:     Epoch: 90
2022-12-31 12:28:08,911 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.34987011601527535, 'Total loss': 0.34987011601527535} | train loss {'Reaction outcome loss': 0.2112836546402438, 'Total loss': 0.2112836546402438}
2022-12-31 12:28:08,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:08,911 INFO:     Epoch: 91
2022-12-31 12:28:10,530 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.334840335448583, 'Total loss': 0.334840335448583} | train loss {'Reaction outcome loss': 0.21109409244320884, 'Total loss': 0.21109409244320884}
2022-12-31 12:28:10,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:10,531 INFO:     Epoch: 92
2022-12-31 12:28:12,134 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35226173102855685, 'Total loss': 0.35226173102855685} | train loss {'Reaction outcome loss': 0.20143811819933705, 'Total loss': 0.20143811819933705}
2022-12-31 12:28:12,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:12,134 INFO:     Epoch: 93
2022-12-31 12:28:13,733 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.31143034299214684, 'Total loss': 0.31143034299214684} | train loss {'Reaction outcome loss': 0.21067708573347824, 'Total loss': 0.21067708573347824}
2022-12-31 12:28:13,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:13,733 INFO:     Epoch: 94
2022-12-31 12:28:15,354 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3702055498957634, 'Total loss': 0.3702055498957634} | train loss {'Reaction outcome loss': 0.19934262796590904, 'Total loss': 0.19934262796590904}
2022-12-31 12:28:15,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:15,355 INFO:     Epoch: 95
2022-12-31 12:28:16,972 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35609345336755116, 'Total loss': 0.35609345336755116} | train loss {'Reaction outcome loss': 0.20552780695044393, 'Total loss': 0.20552780695044393}
2022-12-31 12:28:16,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:16,972 INFO:     Epoch: 96
2022-12-31 12:28:18,593 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3159631182750066, 'Total loss': 0.3159631182750066} | train loss {'Reaction outcome loss': 0.1987478358516409, 'Total loss': 0.1987478358516409}
2022-12-31 12:28:18,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:18,593 INFO:     Epoch: 97
2022-12-31 12:28:20,197 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3396351983149846, 'Total loss': 0.3396351983149846} | train loss {'Reaction outcome loss': 0.20788411663623277, 'Total loss': 0.20788411663623277}
2022-12-31 12:28:20,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:20,198 INFO:     Epoch: 98
2022-12-31 12:28:21,797 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.32483027651906016, 'Total loss': 0.32483027651906016} | train loss {'Reaction outcome loss': 0.2022012890340081, 'Total loss': 0.2022012890340081}
2022-12-31 12:28:21,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:21,797 INFO:     Epoch: 99
2022-12-31 12:28:23,470 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.31559054081638654, 'Total loss': 0.31559054081638654} | train loss {'Reaction outcome loss': 0.1996742368268945, 'Total loss': 0.1996742368268945}
2022-12-31 12:28:23,470 INFO:     Best model found after epoch 71 of 100.
2022-12-31 12:28:23,470 INFO:   Done with stage: TRAINING
2022-12-31 12:28:23,470 INFO:   Starting stage: EVALUATION
2022-12-31 12:28:23,595 INFO:   Done with stage: EVALUATION
2022-12-31 12:28:23,595 INFO:   Leaving out SEQ value Fold_6
2022-12-31 12:28:23,608 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 12:28:23,608 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:28:24,262 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:28:24,262 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:28:24,331 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:28:24,331 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:28:24,331 INFO:     No hyperparam tuning for this model
2022-12-31 12:28:24,331 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:28:24,331 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:28:24,332 INFO:     None feature selector for col prot
2022-12-31 12:28:24,332 INFO:     None feature selector for col prot
2022-12-31 12:28:24,332 INFO:     None feature selector for col prot
2022-12-31 12:28:24,333 INFO:     None feature selector for col chem
2022-12-31 12:28:24,333 INFO:     None feature selector for col chem
2022-12-31 12:28:24,333 INFO:     None feature selector for col chem
2022-12-31 12:28:24,333 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:28:24,333 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:28:24,335 INFO:     Number of params in model 223921
2022-12-31 12:28:24,338 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:28:24,338 INFO:   Starting stage: TRAINING
2022-12-31 12:28:24,381 INFO:     Val loss before train {'Reaction outcome loss': 0.9626562158266704, 'Total loss': 0.9626562158266704}
2022-12-31 12:28:24,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:24,382 INFO:     Epoch: 0
2022-12-31 12:28:26,037 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6046227713425955, 'Total loss': 0.6046227713425955} | train loss {'Reaction outcome loss': 0.8150095648139063, 'Total loss': 0.8150095648139063}
2022-12-31 12:28:26,037 INFO:     Found new best model at epoch 0
2022-12-31 12:28:26,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:26,038 INFO:     Epoch: 1
2022-12-31 12:28:27,633 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4928560177485148, 'Total loss': 0.4928560177485148} | train loss {'Reaction outcome loss': 0.591457009804945, 'Total loss': 0.591457009804945}
2022-12-31 12:28:27,633 INFO:     Found new best model at epoch 1
2022-12-31 12:28:27,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:27,635 INFO:     Epoch: 2
2022-12-31 12:28:29,236 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4535684088865916, 'Total loss': 0.4535684088865916} | train loss {'Reaction outcome loss': 0.5284732478487231, 'Total loss': 0.5284732478487231}
2022-12-31 12:28:29,236 INFO:     Found new best model at epoch 2
2022-12-31 12:28:29,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:29,237 INFO:     Epoch: 3
2022-12-31 12:28:30,826 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.443164579073588, 'Total loss': 0.443164579073588} | train loss {'Reaction outcome loss': 0.5011211433549867, 'Total loss': 0.5011211433549867}
2022-12-31 12:28:30,826 INFO:     Found new best model at epoch 3
2022-12-31 12:28:30,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:30,827 INFO:     Epoch: 4
2022-12-31 12:28:32,427 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4475696543852488, 'Total loss': 0.4475696543852488} | train loss {'Reaction outcome loss': 0.487996335338502, 'Total loss': 0.487996335338502}
2022-12-31 12:28:32,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:32,427 INFO:     Epoch: 5
2022-12-31 12:28:34,026 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4396185725927353, 'Total loss': 0.4396185725927353} | train loss {'Reaction outcome loss': 0.4770103467315653, 'Total loss': 0.4770103467315653}
2022-12-31 12:28:34,027 INFO:     Found new best model at epoch 5
2022-12-31 12:28:34,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:34,028 INFO:     Epoch: 6
2022-12-31 12:28:35,623 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4195741017659505, 'Total loss': 0.4195741017659505} | train loss {'Reaction outcome loss': 0.4654267533634701, 'Total loss': 0.4654267533634701}
2022-12-31 12:28:35,623 INFO:     Found new best model at epoch 6
2022-12-31 12:28:35,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:35,624 INFO:     Epoch: 7
2022-12-31 12:28:37,219 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4226109822591146, 'Total loss': 0.4226109822591146} | train loss {'Reaction outcome loss': 0.45786476396296144, 'Total loss': 0.45786476396296144}
2022-12-31 12:28:37,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:37,219 INFO:     Epoch: 8
2022-12-31 12:28:38,818 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4506121357282003, 'Total loss': 0.4506121357282003} | train loss {'Reaction outcome loss': 0.4529682391860189, 'Total loss': 0.4529682391860189}
2022-12-31 12:28:38,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:38,818 INFO:     Epoch: 9
2022-12-31 12:28:40,395 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3854824473460515, 'Total loss': 0.3854824473460515} | train loss {'Reaction outcome loss': 0.4488675684606942, 'Total loss': 0.4488675684606942}
2022-12-31 12:28:40,395 INFO:     Found new best model at epoch 9
2022-12-31 12:28:40,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:40,396 INFO:     Epoch: 10
2022-12-31 12:28:42,000 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3999727110068003, 'Total loss': 0.3999727110068003} | train loss {'Reaction outcome loss': 0.4386937578555441, 'Total loss': 0.4386937578555441}
2022-12-31 12:28:42,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:42,001 INFO:     Epoch: 11
2022-12-31 12:28:43,611 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43235868910948433, 'Total loss': 0.43235868910948433} | train loss {'Reaction outcome loss': 0.4351214619122282, 'Total loss': 0.4351214619122282}
2022-12-31 12:28:43,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:43,611 INFO:     Epoch: 12
2022-12-31 12:28:45,222 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39895211160182953, 'Total loss': 0.39895211160182953} | train loss {'Reaction outcome loss': 0.42640548106962745, 'Total loss': 0.42640548106962745}
2022-12-31 12:28:45,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:45,223 INFO:     Epoch: 13
2022-12-31 12:28:46,822 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4182951867580414, 'Total loss': 0.4182951867580414} | train loss {'Reaction outcome loss': 0.4237581203236197, 'Total loss': 0.4237581203236197}
2022-12-31 12:28:46,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:46,823 INFO:     Epoch: 14
2022-12-31 12:28:48,390 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3729631930589676, 'Total loss': 0.3729631930589676} | train loss {'Reaction outcome loss': 0.418283178151524, 'Total loss': 0.418283178151524}
2022-12-31 12:28:48,390 INFO:     Found new best model at epoch 14
2022-12-31 12:28:48,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:48,391 INFO:     Epoch: 15
2022-12-31 12:28:49,998 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4054793337980906, 'Total loss': 0.4054793337980906} | train loss {'Reaction outcome loss': 0.41311699059540335, 'Total loss': 0.41311699059540335}
2022-12-31 12:28:49,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:49,998 INFO:     Epoch: 16
2022-12-31 12:28:51,605 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4095924933751424, 'Total loss': 0.4095924933751424} | train loss {'Reaction outcome loss': 0.40694769936865266, 'Total loss': 0.40694769936865266}
2022-12-31 12:28:51,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:51,606 INFO:     Epoch: 17
2022-12-31 12:28:53,212 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4078817735115687, 'Total loss': 0.4078817735115687} | train loss {'Reaction outcome loss': 0.39745559488987403, 'Total loss': 0.39745559488987403}
2022-12-31 12:28:53,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:53,212 INFO:     Epoch: 18
2022-12-31 12:28:54,818 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39807902574539183, 'Total loss': 0.39807902574539183} | train loss {'Reaction outcome loss': 0.39706439372614355, 'Total loss': 0.39706439372614355}
2022-12-31 12:28:54,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:54,818 INFO:     Epoch: 19
2022-12-31 12:28:56,415 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42390338480472567, 'Total loss': 0.42390338480472567} | train loss {'Reaction outcome loss': 0.3908999128280765, 'Total loss': 0.3908999128280765}
2022-12-31 12:28:56,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:56,415 INFO:     Epoch: 20
2022-12-31 12:28:58,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3734625866015752, 'Total loss': 0.3734625866015752} | train loss {'Reaction outcome loss': 0.385636446548857, 'Total loss': 0.385636446548857}
2022-12-31 12:28:58,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:58,020 INFO:     Epoch: 21
2022-12-31 12:28:59,625 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38293377161026, 'Total loss': 0.38293377161026} | train loss {'Reaction outcome loss': 0.3805365298677535, 'Total loss': 0.3805365298677535}
2022-12-31 12:28:59,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:28:59,625 INFO:     Epoch: 22
2022-12-31 12:29:01,229 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4063083122173945, 'Total loss': 0.4063083122173945} | train loss {'Reaction outcome loss': 0.37542402048180573, 'Total loss': 0.37542402048180573}
2022-12-31 12:29:01,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:01,229 INFO:     Epoch: 23
2022-12-31 12:29:02,832 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37928186655044555, 'Total loss': 0.37928186655044555} | train loss {'Reaction outcome loss': 0.3702057632923561, 'Total loss': 0.3702057632923561}
2022-12-31 12:29:02,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:02,832 INFO:     Epoch: 24
2022-12-31 12:29:04,451 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35144109427928927, 'Total loss': 0.35144109427928927} | train loss {'Reaction outcome loss': 0.36596982953322194, 'Total loss': 0.36596982953322194}
2022-12-31 12:29:04,451 INFO:     Found new best model at epoch 24
2022-12-31 12:29:04,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:04,452 INFO:     Epoch: 25
2022-12-31 12:29:06,068 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3740678787231445, 'Total loss': 0.3740678787231445} | train loss {'Reaction outcome loss': 0.36690138549591506, 'Total loss': 0.36690138549591506}
2022-12-31 12:29:06,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:06,068 INFO:     Epoch: 26
2022-12-31 12:29:07,672 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37070832202831905, 'Total loss': 0.37070832202831905} | train loss {'Reaction outcome loss': 0.3609817420968609, 'Total loss': 0.3609817420968609}
2022-12-31 12:29:07,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:07,672 INFO:     Epoch: 27
2022-12-31 12:29:09,275 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3764966279268265, 'Total loss': 0.3764966279268265} | train loss {'Reaction outcome loss': 0.35151317449164216, 'Total loss': 0.35151317449164216}
2022-12-31 12:29:09,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:09,275 INFO:     Epoch: 28
2022-12-31 12:29:10,879 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37284949918588, 'Total loss': 0.37284949918588} | train loss {'Reaction outcome loss': 0.3523267844596701, 'Total loss': 0.3523267844596701}
2022-12-31 12:29:10,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:10,879 INFO:     Epoch: 29
2022-12-31 12:29:12,483 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41385465264320376, 'Total loss': 0.41385465264320376} | train loss {'Reaction outcome loss': 0.3475476432401333, 'Total loss': 0.3475476432401333}
2022-12-31 12:29:12,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:12,483 INFO:     Epoch: 30
2022-12-31 12:29:14,077 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3598912239074707, 'Total loss': 0.3598912239074707} | train loss {'Reaction outcome loss': 0.34333341257361166, 'Total loss': 0.34333341257361166}
2022-12-31 12:29:14,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:14,077 INFO:     Epoch: 31
2022-12-31 12:29:15,655 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3591369420289993, 'Total loss': 0.3591369420289993} | train loss {'Reaction outcome loss': 0.3391985922480804, 'Total loss': 0.3391985922480804}
2022-12-31 12:29:15,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:15,655 INFO:     Epoch: 32
2022-12-31 12:29:17,268 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.354321277141571, 'Total loss': 0.354321277141571} | train loss {'Reaction outcome loss': 0.3270173911141218, 'Total loss': 0.3270173911141218}
2022-12-31 12:29:17,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:17,268 INFO:     Epoch: 33
2022-12-31 12:29:18,879 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40014507075150807, 'Total loss': 0.40014507075150807} | train loss {'Reaction outcome loss': 0.31911073528556494, 'Total loss': 0.31911073528556494}
2022-12-31 12:29:18,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:18,880 INFO:     Epoch: 34
2022-12-31 12:29:20,490 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36674075822035473, 'Total loss': 0.36674075822035473} | train loss {'Reaction outcome loss': 0.3211173528846163, 'Total loss': 0.3211173528846163}
2022-12-31 12:29:20,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:20,490 INFO:     Epoch: 35
2022-12-31 12:29:22,101 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3336329738299052, 'Total loss': 0.3336329738299052} | train loss {'Reaction outcome loss': 0.3173545233796548, 'Total loss': 0.3173545233796548}
2022-12-31 12:29:22,102 INFO:     Found new best model at epoch 35
2022-12-31 12:29:22,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:22,103 INFO:     Epoch: 36
2022-12-31 12:29:23,698 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37005707720915476, 'Total loss': 0.37005707720915476} | train loss {'Reaction outcome loss': 0.3130567763952443, 'Total loss': 0.3130567763952443}
2022-12-31 12:29:23,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:23,698 INFO:     Epoch: 37
2022-12-31 12:29:25,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.34525048087040583, 'Total loss': 0.34525048087040583} | train loss {'Reaction outcome loss': 0.3088025648119676, 'Total loss': 0.3088025648119676}
2022-12-31 12:29:25,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:25,285 INFO:     Epoch: 38
2022-12-31 12:29:26,897 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3491093282898267, 'Total loss': 0.3491093282898267} | train loss {'Reaction outcome loss': 0.30313609825977444, 'Total loss': 0.30313609825977444}
2022-12-31 12:29:26,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:26,897 INFO:     Epoch: 39
2022-12-31 12:29:28,510 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3455575784047445, 'Total loss': 0.3455575784047445} | train loss {'Reaction outcome loss': 0.30145497285645373, 'Total loss': 0.30145497285645373}
2022-12-31 12:29:28,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:28,511 INFO:     Epoch: 40
2022-12-31 12:29:30,123 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40326300958792366, 'Total loss': 0.40326300958792366} | train loss {'Reaction outcome loss': 0.3021947274079723, 'Total loss': 0.3021947274079723}
2022-12-31 12:29:30,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:30,123 INFO:     Epoch: 41
2022-12-31 12:29:31,735 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3439349740743637, 'Total loss': 0.3439349740743637} | train loss {'Reaction outcome loss': 0.2949049773007414, 'Total loss': 0.2949049773007414}
2022-12-31 12:29:31,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:31,735 INFO:     Epoch: 42
2022-12-31 12:29:33,332 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3347405398885409, 'Total loss': 0.3347405398885409} | train loss {'Reaction outcome loss': 0.2938293747223207, 'Total loss': 0.2938293747223207}
2022-12-31 12:29:33,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:33,332 INFO:     Epoch: 43
2022-12-31 12:29:34,921 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3254716177781423, 'Total loss': 0.3254716177781423} | train loss {'Reaction outcome loss': 0.29283779889453937, 'Total loss': 0.29283779889453937}
2022-12-31 12:29:34,922 INFO:     Found new best model at epoch 43
2022-12-31 12:29:34,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:34,922 INFO:     Epoch: 44
2022-12-31 12:29:36,533 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3861408631006877, 'Total loss': 0.3861408631006877} | train loss {'Reaction outcome loss': 0.28570657446436637, 'Total loss': 0.28570657446436637}
2022-12-31 12:29:36,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:36,533 INFO:     Epoch: 45
2022-12-31 12:29:38,145 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3733124623696009, 'Total loss': 0.3733124623696009} | train loss {'Reaction outcome loss': 0.2892888416910041, 'Total loss': 0.2892888416910041}
2022-12-31 12:29:38,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:38,146 INFO:     Epoch: 46
2022-12-31 12:29:39,755 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.324312882622083, 'Total loss': 0.324312882622083} | train loss {'Reaction outcome loss': 0.28503325334104307, 'Total loss': 0.28503325334104307}
2022-12-31 12:29:39,755 INFO:     Found new best model at epoch 46
2022-12-31 12:29:39,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:39,756 INFO:     Epoch: 47
2022-12-31 12:29:41,354 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.32449341962734857, 'Total loss': 0.32449341962734857} | train loss {'Reaction outcome loss': 0.2765233668423917, 'Total loss': 0.2765233668423917}
2022-12-31 12:29:41,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:41,355 INFO:     Epoch: 48
2022-12-31 12:29:42,944 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36194069186846417, 'Total loss': 0.36194069186846417} | train loss {'Reaction outcome loss': 0.27412791528405933, 'Total loss': 0.27412791528405933}
2022-12-31 12:29:42,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:42,944 INFO:     Epoch: 49
2022-12-31 12:29:44,557 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36362587014834086, 'Total loss': 0.36362587014834086} | train loss {'Reaction outcome loss': 0.2756149003921199, 'Total loss': 0.2756149003921199}
2022-12-31 12:29:44,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:44,558 INFO:     Epoch: 50
2022-12-31 12:29:46,169 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36531857450803124, 'Total loss': 0.36531857450803124} | train loss {'Reaction outcome loss': 0.26685501518149446, 'Total loss': 0.26685501518149446}
2022-12-31 12:29:46,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:46,169 INFO:     Epoch: 51
2022-12-31 12:29:47,781 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34070833325386046, 'Total loss': 0.34070833325386046} | train loss {'Reaction outcome loss': 0.2721828205619741, 'Total loss': 0.2721828205619741}
2022-12-31 12:29:47,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:47,781 INFO:     Epoch: 52
2022-12-31 12:29:49,394 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34403929511706033, 'Total loss': 0.34403929511706033} | train loss {'Reaction outcome loss': 0.26586818204254564, 'Total loss': 0.26586818204254564}
2022-12-31 12:29:49,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:49,394 INFO:     Epoch: 53
2022-12-31 12:29:51,003 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3598335156838099, 'Total loss': 0.3598335156838099} | train loss {'Reaction outcome loss': 0.2662211980697882, 'Total loss': 0.2662211980697882}
2022-12-31 12:29:51,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:51,003 INFO:     Epoch: 54
2022-12-31 12:29:52,617 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3524687925974528, 'Total loss': 0.3524687925974528} | train loss {'Reaction outcome loss': 0.2641474458450166, 'Total loss': 0.2641474458450166}
2022-12-31 12:29:52,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:52,618 INFO:     Epoch: 55
2022-12-31 12:29:54,275 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.338508732120196, 'Total loss': 0.338508732120196} | train loss {'Reaction outcome loss': 0.2699108450014117, 'Total loss': 0.2699108450014117}
2022-12-31 12:29:54,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:54,275 INFO:     Epoch: 56
2022-12-31 12:29:55,929 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3727402846018473, 'Total loss': 0.3727402846018473} | train loss {'Reaction outcome loss': 0.2590192647338131, 'Total loss': 0.2590192647338131}
2022-12-31 12:29:55,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:55,929 INFO:     Epoch: 57
2022-12-31 12:29:57,502 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35145003298918404, 'Total loss': 0.35145003298918404} | train loss {'Reaction outcome loss': 0.2500828292737477, 'Total loss': 0.2500828292737477}
2022-12-31 12:29:57,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:57,504 INFO:     Epoch: 58
2022-12-31 12:29:59,118 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34335862994194033, 'Total loss': 0.34335862994194033} | train loss {'Reaction outcome loss': 0.2544837462559451, 'Total loss': 0.2544837462559451}
2022-12-31 12:29:59,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:29:59,119 INFO:     Epoch: 59
2022-12-31 12:30:00,705 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3711769459148248, 'Total loss': 0.3711769459148248} | train loss {'Reaction outcome loss': 0.2535047941861579, 'Total loss': 0.2535047941861579}
2022-12-31 12:30:00,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:00,705 INFO:     Epoch: 60
2022-12-31 12:30:02,301 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36393614783883094, 'Total loss': 0.36393614783883094} | train loss {'Reaction outcome loss': 0.25269092533764614, 'Total loss': 0.25269092533764614}
2022-12-31 12:30:02,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:02,301 INFO:     Epoch: 61
2022-12-31 12:30:03,909 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.33290434777736666, 'Total loss': 0.33290434777736666} | train loss {'Reaction outcome loss': 0.24533974266794584, 'Total loss': 0.24533974266794584}
2022-12-31 12:30:03,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:03,910 INFO:     Epoch: 62
2022-12-31 12:30:05,517 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.35909882684548694, 'Total loss': 0.35909882684548694} | train loss {'Reaction outcome loss': 0.25532792002153004, 'Total loss': 0.25532792002153004}
2022-12-31 12:30:05,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:05,517 INFO:     Epoch: 63
2022-12-31 12:30:07,125 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3454765339692434, 'Total loss': 0.3454765339692434} | train loss {'Reaction outcome loss': 0.24768268542676947, 'Total loss': 0.24768268542676947}
2022-12-31 12:30:07,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:07,125 INFO:     Epoch: 64
2022-12-31 12:30:08,713 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3930247207482656, 'Total loss': 0.3930247207482656} | train loss {'Reaction outcome loss': 0.2457353944081242, 'Total loss': 0.2457353944081242}
2022-12-31 12:30:08,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:08,713 INFO:     Epoch: 65
2022-12-31 12:30:10,309 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34003970250487325, 'Total loss': 0.34003970250487325} | train loss {'Reaction outcome loss': 0.2353223952036487, 'Total loss': 0.2353223952036487}
2022-12-31 12:30:10,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:10,309 INFO:     Epoch: 66
2022-12-31 12:30:11,918 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.347062803308169, 'Total loss': 0.347062803308169} | train loss {'Reaction outcome loss': 0.24748379992742608, 'Total loss': 0.24748379992742608}
2022-12-31 12:30:11,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:11,919 INFO:     Epoch: 67
2022-12-31 12:30:13,527 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.32509345014890034, 'Total loss': 0.32509345014890034} | train loss {'Reaction outcome loss': 0.2439757509796071, 'Total loss': 0.2439757509796071}
2022-12-31 12:30:13,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:13,527 INFO:     Epoch: 68
2022-12-31 12:30:15,135 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36468197107315065, 'Total loss': 0.36468197107315065} | train loss {'Reaction outcome loss': 0.23553287897286188, 'Total loss': 0.23553287897286188}
2022-12-31 12:30:15,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:15,136 INFO:     Epoch: 69
2022-12-31 12:30:16,782 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.32938039153814314, 'Total loss': 0.32938039153814314} | train loss {'Reaction outcome loss': 0.2350138052618199, 'Total loss': 0.2350138052618199}
2022-12-31 12:30:16,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:16,783 INFO:     Epoch: 70
2022-12-31 12:30:18,379 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3456880822777748, 'Total loss': 0.3456880822777748} | train loss {'Reaction outcome loss': 0.23115692192511836, 'Total loss': 0.23115692192511836}
2022-12-31 12:30:18,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:18,380 INFO:     Epoch: 71
2022-12-31 12:30:19,966 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3564117948214213, 'Total loss': 0.3564117948214213} | train loss {'Reaction outcome loss': 0.23489439277399848, 'Total loss': 0.23489439277399848}
2022-12-31 12:30:19,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:19,966 INFO:     Epoch: 72
2022-12-31 12:30:21,574 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.32038491517305373, 'Total loss': 0.32038491517305373} | train loss {'Reaction outcome loss': 0.22861044804980285, 'Total loss': 0.22861044804980285}
2022-12-31 12:30:21,574 INFO:     Found new best model at epoch 72
2022-12-31 12:30:21,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:21,575 INFO:     Epoch: 73
2022-12-31 12:30:23,182 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3650498573978742, 'Total loss': 0.3650498573978742} | train loss {'Reaction outcome loss': 0.22727415881996607, 'Total loss': 0.22727415881996607}
2022-12-31 12:30:23,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:23,182 INFO:     Epoch: 74
2022-12-31 12:30:24,792 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3531652649243673, 'Total loss': 0.3531652649243673} | train loss {'Reaction outcome loss': 0.22631915857893053, 'Total loss': 0.22631915857893053}
2022-12-31 12:30:24,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:24,792 INFO:     Epoch: 75
2022-12-31 12:30:26,411 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3578557223081589, 'Total loss': 0.3578557223081589} | train loss {'Reaction outcome loss': 0.22950351881339168, 'Total loss': 0.22950351881339168}
2022-12-31 12:30:26,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:26,411 INFO:     Epoch: 76
2022-12-31 12:30:27,997 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34342207411924996, 'Total loss': 0.34342207411924996} | train loss {'Reaction outcome loss': 0.23293792832996288, 'Total loss': 0.23293792832996288}
2022-12-31 12:30:27,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:27,998 INFO:     Epoch: 77
2022-12-31 12:30:29,597 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.32347175975640613, 'Total loss': 0.32347175975640613} | train loss {'Reaction outcome loss': 0.22475648060930473, 'Total loss': 0.22475648060930473}
2022-12-31 12:30:29,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:29,598 INFO:     Epoch: 78
2022-12-31 12:30:31,206 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3543006916840871, 'Total loss': 0.3543006916840871} | train loss {'Reaction outcome loss': 0.22881269019885656, 'Total loss': 0.22881269019885656}
2022-12-31 12:30:31,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:31,206 INFO:     Epoch: 79
2022-12-31 12:30:32,813 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.344310620923837, 'Total loss': 0.344310620923837} | train loss {'Reaction outcome loss': 0.22923234291374683, 'Total loss': 0.22923234291374683}
2022-12-31 12:30:32,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:32,813 INFO:     Epoch: 80
2022-12-31 12:30:34,420 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.34216909607251483, 'Total loss': 0.34216909607251483} | train loss {'Reaction outcome loss': 0.21734353288138, 'Total loss': 0.21734353288138}
2022-12-31 12:30:34,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:34,421 INFO:     Epoch: 81
2022-12-31 12:30:36,012 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3446947753429413, 'Total loss': 0.3446947753429413} | train loss {'Reaction outcome loss': 0.22125593004544286, 'Total loss': 0.22125593004544286}
2022-12-31 12:30:36,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:36,013 INFO:     Epoch: 82
2022-12-31 12:30:37,603 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35550861606995265, 'Total loss': 0.35550861606995265} | train loss {'Reaction outcome loss': 0.22524611775620576, 'Total loss': 0.22524611775620576}
2022-12-31 12:30:37,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:37,603 INFO:     Epoch: 83
2022-12-31 12:30:39,210 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35850882629553477, 'Total loss': 0.35850882629553477} | train loss {'Reaction outcome loss': 0.2257660280532428, 'Total loss': 0.2257660280532428}
2022-12-31 12:30:39,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:39,210 INFO:     Epoch: 84
2022-12-31 12:30:40,817 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3281830290953318, 'Total loss': 0.3281830290953318} | train loss {'Reaction outcome loss': 0.22359520769304167, 'Total loss': 0.22359520769304167}
2022-12-31 12:30:40,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:40,817 INFO:     Epoch: 85
2022-12-31 12:30:42,424 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3215174823999405, 'Total loss': 0.3215174823999405} | train loss {'Reaction outcome loss': 0.22200649937302092, 'Total loss': 0.22200649937302092}
2022-12-31 12:30:42,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:42,424 INFO:     Epoch: 86
2022-12-31 12:30:44,031 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34537926415602366, 'Total loss': 0.34537926415602366} | train loss {'Reaction outcome loss': 0.2177901141087178, 'Total loss': 0.2177901141087178}
2022-12-31 12:30:44,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:44,031 INFO:     Epoch: 87
2022-12-31 12:30:45,625 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.309497033059597, 'Total loss': 0.309497033059597} | train loss {'Reaction outcome loss': 0.21788371321711228, 'Total loss': 0.21788371321711228}
2022-12-31 12:30:45,626 INFO:     Found new best model at epoch 87
2022-12-31 12:30:45,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:45,626 INFO:     Epoch: 88
2022-12-31 12:30:47,244 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.31730217188596727, 'Total loss': 0.31730217188596727} | train loss {'Reaction outcome loss': 0.2168012157585608, 'Total loss': 0.2168012157585608}
2022-12-31 12:30:47,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:47,244 INFO:     Epoch: 89
2022-12-31 12:30:48,857 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3467302610476812, 'Total loss': 0.3467302610476812} | train loss {'Reaction outcome loss': 0.21285730939236108, 'Total loss': 0.21285730939236108}
2022-12-31 12:30:48,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:48,857 INFO:     Epoch: 90
2022-12-31 12:30:50,456 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3421683172384898, 'Total loss': 0.3421683172384898} | train loss {'Reaction outcome loss': 0.21751509527301918, 'Total loss': 0.21751509527301918}
2022-12-31 12:30:50,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:50,456 INFO:     Epoch: 91
2022-12-31 12:30:52,056 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3831722845633825, 'Total loss': 0.3831722845633825} | train loss {'Reaction outcome loss': 0.21920265201615155, 'Total loss': 0.21920265201615155}
2022-12-31 12:30:52,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:52,056 INFO:     Epoch: 92
2022-12-31 12:30:53,641 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.32104850113391875, 'Total loss': 0.32104850113391875} | train loss {'Reaction outcome loss': 0.21311232242325362, 'Total loss': 0.21311232242325362}
2022-12-31 12:30:53,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:53,641 INFO:     Epoch: 93
2022-12-31 12:30:55,224 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37399183412392933, 'Total loss': 0.37399183412392933} | train loss {'Reaction outcome loss': 0.2034648710107227, 'Total loss': 0.2034648710107227}
2022-12-31 12:30:55,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:55,224 INFO:     Epoch: 94
2022-12-31 12:30:56,820 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35627575119336446, 'Total loss': 0.35627575119336446} | train loss {'Reaction outcome loss': 0.205037126936236, 'Total loss': 0.205037126936236}
2022-12-31 12:30:56,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:56,820 INFO:     Epoch: 95
2022-12-31 12:30:58,421 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.356669619679451, 'Total loss': 0.356669619679451} | train loss {'Reaction outcome loss': 0.21158104965694413, 'Total loss': 0.21158104965694413}
2022-12-31 12:30:58,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:30:58,421 INFO:     Epoch: 96
2022-12-31 12:31:00,022 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35241084347168605, 'Total loss': 0.35241084347168605} | train loss {'Reaction outcome loss': 0.21421661094701203, 'Total loss': 0.21421661094701203}
2022-12-31 12:31:00,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:00,024 INFO:     Epoch: 97
2022-12-31 12:31:01,623 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3395247220993042, 'Total loss': 0.3395247220993042} | train loss {'Reaction outcome loss': 0.20698759050863066, 'Total loss': 0.20698759050863066}
2022-12-31 12:31:01,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:01,623 INFO:     Epoch: 98
2022-12-31 12:31:03,230 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3050097163145741, 'Total loss': 0.3050097163145741} | train loss {'Reaction outcome loss': 0.2039694697766082, 'Total loss': 0.2039694697766082}
2022-12-31 12:31:03,230 INFO:     Found new best model at epoch 98
2022-12-31 12:31:03,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:03,231 INFO:     Epoch: 99
2022-12-31 12:31:04,852 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34295767843723296, 'Total loss': 0.34295767843723296} | train loss {'Reaction outcome loss': 0.20083797526593408, 'Total loss': 0.20083797526593408}
2022-12-31 12:31:04,852 INFO:     Best model found after epoch 99 of 100.
2022-12-31 12:31:04,852 INFO:   Done with stage: TRAINING
2022-12-31 12:31:04,852 INFO:   Starting stage: EVALUATION
2022-12-31 12:31:04,987 INFO:   Done with stage: EVALUATION
2022-12-31 12:31:04,987 INFO:   Leaving out SEQ value Fold_7
2022-12-31 12:31:04,999 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 12:31:04,999 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:31:05,639 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:31:05,639 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:31:05,707 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:31:05,707 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:31:05,707 INFO:     No hyperparam tuning for this model
2022-12-31 12:31:05,707 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:31:05,708 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:31:05,708 INFO:     None feature selector for col prot
2022-12-31 12:31:05,708 INFO:     None feature selector for col prot
2022-12-31 12:31:05,708 INFO:     None feature selector for col prot
2022-12-31 12:31:05,709 INFO:     None feature selector for col chem
2022-12-31 12:31:05,709 INFO:     None feature selector for col chem
2022-12-31 12:31:05,709 INFO:     None feature selector for col chem
2022-12-31 12:31:05,709 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:31:05,709 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:31:05,711 INFO:     Number of params in model 223921
2022-12-31 12:31:05,714 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:31:05,714 INFO:   Starting stage: TRAINING
2022-12-31 12:31:05,759 INFO:     Val loss before train {'Reaction outcome loss': 1.050389862060547, 'Total loss': 1.050389862060547}
2022-12-31 12:31:05,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:05,759 INFO:     Epoch: 0
2022-12-31 12:31:07,372 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6751160045464834, 'Total loss': 0.6751160045464834} | train loss {'Reaction outcome loss': 0.8114552048653582, 'Total loss': 0.8114552048653582}
2022-12-31 12:31:07,373 INFO:     Found new best model at epoch 0
2022-12-31 12:31:07,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:07,374 INFO:     Epoch: 1
2022-12-31 12:31:08,970 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5283935944239299, 'Total loss': 0.5283935944239299} | train loss {'Reaction outcome loss': 0.6007167644200534, 'Total loss': 0.6007167644200534}
2022-12-31 12:31:08,970 INFO:     Found new best model at epoch 1
2022-12-31 12:31:08,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:08,971 INFO:     Epoch: 2
2022-12-31 12:31:10,570 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5269175320863724, 'Total loss': 0.5269175320863724} | train loss {'Reaction outcome loss': 0.5313977696490984, 'Total loss': 0.5313977696490984}
2022-12-31 12:31:10,570 INFO:     Found new best model at epoch 2
2022-12-31 12:31:10,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:10,571 INFO:     Epoch: 3
2022-12-31 12:31:12,148 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5278887510299682, 'Total loss': 0.5278887510299682} | train loss {'Reaction outcome loss': 0.502697354740035, 'Total loss': 0.502697354740035}
2022-12-31 12:31:12,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:12,149 INFO:     Epoch: 4
2022-12-31 12:31:13,740 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5056531171003977, 'Total loss': 0.5056531171003977} | train loss {'Reaction outcome loss': 0.486097956715274, 'Total loss': 0.486097956715274}
2022-12-31 12:31:13,740 INFO:     Found new best model at epoch 4
2022-12-31 12:31:13,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:13,741 INFO:     Epoch: 5
2022-12-31 12:31:15,332 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.497640069325765, 'Total loss': 0.497640069325765} | train loss {'Reaction outcome loss': 0.47724563019336574, 'Total loss': 0.47724563019336574}
2022-12-31 12:31:15,332 INFO:     Found new best model at epoch 5
2022-12-31 12:31:15,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:15,333 INFO:     Epoch: 6
2022-12-31 12:31:16,928 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49293261071046196, 'Total loss': 0.49293261071046196} | train loss {'Reaction outcome loss': 0.4674580627440536, 'Total loss': 0.4674580627440536}
2022-12-31 12:31:16,928 INFO:     Found new best model at epoch 6
2022-12-31 12:31:16,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:16,929 INFO:     Epoch: 7
2022-12-31 12:31:18,524 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4809824456771215, 'Total loss': 0.4809824456771215} | train loss {'Reaction outcome loss': 0.4655367153948241, 'Total loss': 0.4655367153948241}
2022-12-31 12:31:18,524 INFO:     Found new best model at epoch 7
2022-12-31 12:31:18,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:18,525 INFO:     Epoch: 8
2022-12-31 12:31:20,116 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48255896170934043, 'Total loss': 0.48255896170934043} | train loss {'Reaction outcome loss': 0.4533809941180431, 'Total loss': 0.4533809941180431}
2022-12-31 12:31:20,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:20,117 INFO:     Epoch: 9
2022-12-31 12:31:21,704 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5018826246261596, 'Total loss': 0.5018826246261596} | train loss {'Reaction outcome loss': 0.45033478682493644, 'Total loss': 0.45033478682493644}
2022-12-31 12:31:21,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:21,704 INFO:     Epoch: 10
2022-12-31 12:31:23,285 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46047914524873096, 'Total loss': 0.46047914524873096} | train loss {'Reaction outcome loss': 0.43922025128437653, 'Total loss': 0.43922025128437653}
2022-12-31 12:31:23,285 INFO:     Found new best model at epoch 10
2022-12-31 12:31:23,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:23,286 INFO:     Epoch: 11
2022-12-31 12:31:24,880 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5147913614908854, 'Total loss': 0.5147913614908854} | train loss {'Reaction outcome loss': 0.4345785478932144, 'Total loss': 0.4345785478932144}
2022-12-31 12:31:24,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:24,881 INFO:     Epoch: 12
2022-12-31 12:31:26,476 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4826039433479309, 'Total loss': 0.4826039433479309} | train loss {'Reaction outcome loss': 0.4272896735011226, 'Total loss': 0.4272896735011226}
2022-12-31 12:31:26,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:26,477 INFO:     Epoch: 13
2022-12-31 12:31:28,073 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45744435787200927, 'Total loss': 0.45744435787200927} | train loss {'Reaction outcome loss': 0.4223470474137877, 'Total loss': 0.4223470474137877}
2022-12-31 12:31:28,073 INFO:     Found new best model at epoch 13
2022-12-31 12:31:28,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:28,074 INFO:     Epoch: 14
2022-12-31 12:31:29,662 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4646429042021433, 'Total loss': 0.4646429042021433} | train loss {'Reaction outcome loss': 0.4165060297470458, 'Total loss': 0.4165060297470458}
2022-12-31 12:31:29,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:29,662 INFO:     Epoch: 15
2022-12-31 12:31:31,284 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45792288780212403, 'Total loss': 0.45792288780212403} | train loss {'Reaction outcome loss': 0.4105555530447159, 'Total loss': 0.4105555530447159}
2022-12-31 12:31:31,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:31,284 INFO:     Epoch: 16
2022-12-31 12:31:32,893 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5012043376763662, 'Total loss': 0.5012043376763662} | train loss {'Reaction outcome loss': 0.4012274382649547, 'Total loss': 0.4012274382649547}
2022-12-31 12:31:32,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:32,893 INFO:     Epoch: 17
2022-12-31 12:31:34,491 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4513806054989497, 'Total loss': 0.4513806054989497} | train loss {'Reaction outcome loss': 0.3982374658604173, 'Total loss': 0.3982374658604173}
2022-12-31 12:31:34,492 INFO:     Found new best model at epoch 17
2022-12-31 12:31:34,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:34,493 INFO:     Epoch: 18
2022-12-31 12:31:36,090 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43200368533531824, 'Total loss': 0.43200368533531824} | train loss {'Reaction outcome loss': 0.39148805407385756, 'Total loss': 0.39148805407385756}
2022-12-31 12:31:36,090 INFO:     Found new best model at epoch 18
2022-12-31 12:31:36,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:36,091 INFO:     Epoch: 19
2022-12-31 12:31:37,687 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44731536209583284, 'Total loss': 0.44731536209583284} | train loss {'Reaction outcome loss': 0.3856915351900741, 'Total loss': 0.3856915351900741}
2022-12-31 12:31:37,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:37,687 INFO:     Epoch: 20
2022-12-31 12:31:39,286 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45020290116469064, 'Total loss': 0.45020290116469064} | train loss {'Reaction outcome loss': 0.38112130472912403, 'Total loss': 0.38112130472912403}
2022-12-31 12:31:39,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:39,287 INFO:     Epoch: 21
2022-12-31 12:31:40,881 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42365133166313174, 'Total loss': 0.42365133166313174} | train loss {'Reaction outcome loss': 0.38622465979878917, 'Total loss': 0.38622465979878917}
2022-12-31 12:31:40,882 INFO:     Found new best model at epoch 21
2022-12-31 12:31:40,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:40,883 INFO:     Epoch: 22
2022-12-31 12:31:42,478 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46613889435927075, 'Total loss': 0.46613889435927075} | train loss {'Reaction outcome loss': 0.3713864630808795, 'Total loss': 0.3713864630808795}
2022-12-31 12:31:42,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:42,479 INFO:     Epoch: 23
2022-12-31 12:31:44,076 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45263205021619796, 'Total loss': 0.45263205021619796} | train loss {'Reaction outcome loss': 0.3726448191560968, 'Total loss': 0.3726448191560968}
2022-12-31 12:31:44,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:44,077 INFO:     Epoch: 24
2022-12-31 12:31:45,674 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44279173811276756, 'Total loss': 0.44279173811276756} | train loss {'Reaction outcome loss': 0.36733221635222435, 'Total loss': 0.36733221635222435}
2022-12-31 12:31:45,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:45,674 INFO:     Epoch: 25
2022-12-31 12:31:47,255 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4329557617505391, 'Total loss': 0.4329557617505391} | train loss {'Reaction outcome loss': 0.3635660766685096, 'Total loss': 0.3635660766685096}
2022-12-31 12:31:47,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:47,256 INFO:     Epoch: 26
2022-12-31 12:31:48,842 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4556597183148066, 'Total loss': 0.4556597183148066} | train loss {'Reaction outcome loss': 0.3550986657123061, 'Total loss': 0.3550986657123061}
2022-12-31 12:31:48,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:48,842 INFO:     Epoch: 27
2022-12-31 12:31:50,471 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45381144285202024, 'Total loss': 0.45381144285202024} | train loss {'Reaction outcome loss': 0.3512604163320613, 'Total loss': 0.3512604163320613}
2022-12-31 12:31:50,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:50,471 INFO:     Epoch: 28
2022-12-31 12:31:52,090 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4553370585044225, 'Total loss': 0.4553370585044225} | train loss {'Reaction outcome loss': 0.34905202455655504, 'Total loss': 0.34905202455655504}
2022-12-31 12:31:52,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:52,090 INFO:     Epoch: 29
2022-12-31 12:31:53,688 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4245464344819387, 'Total loss': 0.4245464344819387} | train loss {'Reaction outcome loss': 0.34243350913816123, 'Total loss': 0.34243350913816123}
2022-12-31 12:31:53,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:53,689 INFO:     Epoch: 30
2022-12-31 12:31:55,286 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42367042501767477, 'Total loss': 0.42367042501767477} | train loss {'Reaction outcome loss': 0.3375825262526526, 'Total loss': 0.3375825262526526}
2022-12-31 12:31:55,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:55,287 INFO:     Epoch: 31
2022-12-31 12:31:56,873 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43506547808647156, 'Total loss': 0.43506547808647156} | train loss {'Reaction outcome loss': 0.33767576978616687, 'Total loss': 0.33767576978616687}
2022-12-31 12:31:56,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:56,873 INFO:     Epoch: 32
2022-12-31 12:31:58,454 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4245424677928289, 'Total loss': 0.4245424677928289} | train loss {'Reaction outcome loss': 0.33219263436150376, 'Total loss': 0.33219263436150376}
2022-12-31 12:31:58,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:31:58,454 INFO:     Epoch: 33
2022-12-31 12:32:00,095 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4252190113067627, 'Total loss': 0.4252190113067627} | train loss {'Reaction outcome loss': 0.3306773882903104, 'Total loss': 0.3306773882903104}
2022-12-31 12:32:00,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:00,095 INFO:     Epoch: 34
2022-12-31 12:32:01,691 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4194796284039815, 'Total loss': 0.4194796284039815} | train loss {'Reaction outcome loss': 0.32410886772248865, 'Total loss': 0.32410886772248865}
2022-12-31 12:32:01,691 INFO:     Found new best model at epoch 34
2022-12-31 12:32:01,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:01,692 INFO:     Epoch: 35
2022-12-31 12:32:03,285 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41055725167195, 'Total loss': 0.41055725167195} | train loss {'Reaction outcome loss': 0.3127402250457854, 'Total loss': 0.3127402250457854}
2022-12-31 12:32:03,285 INFO:     Found new best model at epoch 35
2022-12-31 12:32:03,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:03,286 INFO:     Epoch: 36
2022-12-31 12:32:04,881 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4072656571865082, 'Total loss': 0.4072656571865082} | train loss {'Reaction outcome loss': 0.3160614226366917, 'Total loss': 0.3160614226366917}
2022-12-31 12:32:04,881 INFO:     Found new best model at epoch 36
2022-12-31 12:32:04,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:04,882 INFO:     Epoch: 37
2022-12-31 12:32:06,485 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4106386115153631, 'Total loss': 0.4106386115153631} | train loss {'Reaction outcome loss': 0.3122481310019528, 'Total loss': 0.3122481310019528}
2022-12-31 12:32:06,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:06,485 INFO:     Epoch: 38
2022-12-31 12:32:08,102 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4052745848894119, 'Total loss': 0.4052745848894119} | train loss {'Reaction outcome loss': 0.311313487670935, 'Total loss': 0.311313487670935}
2022-12-31 12:32:08,102 INFO:     Found new best model at epoch 38
2022-12-31 12:32:08,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:08,103 INFO:     Epoch: 39
2022-12-31 12:32:09,725 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4041572948296865, 'Total loss': 0.4041572948296865} | train loss {'Reaction outcome loss': 0.314372243889927, 'Total loss': 0.314372243889927}
2022-12-31 12:32:09,725 INFO:     Found new best model at epoch 39
2022-12-31 12:32:09,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:09,726 INFO:     Epoch: 40
2022-12-31 12:32:11,319 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4044007529815038, 'Total loss': 0.4044007529815038} | train loss {'Reaction outcome loss': 0.3030274979919739, 'Total loss': 0.3030274979919739}
2022-12-31 12:32:11,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:11,320 INFO:     Epoch: 41
2022-12-31 12:32:12,913 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40101086894671123, 'Total loss': 0.40101086894671123} | train loss {'Reaction outcome loss': 0.2964065668519831, 'Total loss': 0.2964065668519831}
2022-12-31 12:32:12,913 INFO:     Found new best model at epoch 41
2022-12-31 12:32:12,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:12,914 INFO:     Epoch: 42
2022-12-31 12:32:14,492 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4215518554051717, 'Total loss': 0.4215518554051717} | train loss {'Reaction outcome loss': 0.3018999332766028, 'Total loss': 0.3018999332766028}
2022-12-31 12:32:14,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:14,492 INFO:     Epoch: 43
2022-12-31 12:32:16,089 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42467680970827737, 'Total loss': 0.42467680970827737} | train loss {'Reaction outcome loss': 0.2944399322362712, 'Total loss': 0.2944399322362712}
2022-12-31 12:32:16,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:16,090 INFO:     Epoch: 44
2022-12-31 12:32:17,720 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46193342804908755, 'Total loss': 0.46193342804908755} | train loss {'Reaction outcome loss': 0.29282136849488005, 'Total loss': 0.29282136849488005}
2022-12-31 12:32:17,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:17,721 INFO:     Epoch: 45
2022-12-31 12:32:19,371 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40989442070325216, 'Total loss': 0.40989442070325216} | train loss {'Reaction outcome loss': 0.29605106589296004, 'Total loss': 0.29605106589296004}
2022-12-31 12:32:19,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:19,371 INFO:     Epoch: 46
2022-12-31 12:32:20,964 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4124422033627828, 'Total loss': 0.4124422033627828} | train loss {'Reaction outcome loss': 0.28699664583932744, 'Total loss': 0.28699664583932744}
2022-12-31 12:32:20,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:20,964 INFO:     Epoch: 47
2022-12-31 12:32:22,563 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40659070561329524, 'Total loss': 0.40659070561329524} | train loss {'Reaction outcome loss': 0.27923325980829933, 'Total loss': 0.27923325980829933}
2022-12-31 12:32:22,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:22,563 INFO:     Epoch: 48
2022-12-31 12:32:24,146 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40741601983706155, 'Total loss': 0.40741601983706155} | train loss {'Reaction outcome loss': 0.28038928621061093, 'Total loss': 0.28038928621061093}
2022-12-31 12:32:24,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:24,146 INFO:     Epoch: 49
2022-12-31 12:32:25,739 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4103007028500239, 'Total loss': 0.4103007028500239} | train loss {'Reaction outcome loss': 0.2745312979567225, 'Total loss': 0.2745312979567225}
2022-12-31 12:32:25,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:25,739 INFO:     Epoch: 50
2022-12-31 12:32:27,396 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3961318035920461, 'Total loss': 0.3961318035920461} | train loss {'Reaction outcome loss': 0.2744324651349635, 'Total loss': 0.2744324651349635}
2022-12-31 12:32:27,396 INFO:     Found new best model at epoch 50
2022-12-31 12:32:27,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:27,397 INFO:     Epoch: 51
2022-12-31 12:32:29,047 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3855494946241379, 'Total loss': 0.3855494946241379} | train loss {'Reaction outcome loss': 0.2721315066255357, 'Total loss': 0.2721315066255357}
2022-12-31 12:32:29,047 INFO:     Found new best model at epoch 51
2022-12-31 12:32:29,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:29,048 INFO:     Epoch: 52
2022-12-31 12:32:30,642 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41604852229356765, 'Total loss': 0.41604852229356765} | train loss {'Reaction outcome loss': 0.2684135862700913, 'Total loss': 0.2684135862700913}
2022-12-31 12:32:30,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:30,643 INFO:     Epoch: 53
2022-12-31 12:32:32,243 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39401448965072633, 'Total loss': 0.39401448965072633} | train loss {'Reaction outcome loss': 0.2716277063327984, 'Total loss': 0.2716277063327984}
2022-12-31 12:32:32,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:32,243 INFO:     Epoch: 54
2022-12-31 12:32:33,841 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4202535688877106, 'Total loss': 0.4202535688877106} | train loss {'Reaction outcome loss': 0.2676166073031669, 'Total loss': 0.2676166073031669}
2022-12-31 12:32:33,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:33,841 INFO:     Epoch: 55
2022-12-31 12:32:35,443 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36764659782250725, 'Total loss': 0.36764659782250725} | train loss {'Reaction outcome loss': 0.2597230721237886, 'Total loss': 0.2597230721237886}
2022-12-31 12:32:35,443 INFO:     Found new best model at epoch 55
2022-12-31 12:32:35,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:35,444 INFO:     Epoch: 56
2022-12-31 12:32:37,045 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.444079519311587, 'Total loss': 0.444079519311587} | train loss {'Reaction outcome loss': 0.2613180718609016, 'Total loss': 0.2613180718609016}
2022-12-31 12:32:37,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:37,046 INFO:     Epoch: 57
2022-12-31 12:32:38,650 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3733922326316436, 'Total loss': 0.3733922326316436} | train loss {'Reaction outcome loss': 0.2589562578181172, 'Total loss': 0.2589562578181172}
2022-12-31 12:32:38,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:38,650 INFO:     Epoch: 58
2022-12-31 12:32:40,253 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38181194265683494, 'Total loss': 0.38181194265683494} | train loss {'Reaction outcome loss': 0.25585488140256735, 'Total loss': 0.25585488140256735}
2022-12-31 12:32:40,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:40,253 INFO:     Epoch: 59
2022-12-31 12:32:41,838 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3927574962377548, 'Total loss': 0.3927574962377548} | train loss {'Reaction outcome loss': 0.2498693389913244, 'Total loss': 0.2498693389913244}
2022-12-31 12:32:41,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:41,838 INFO:     Epoch: 60
2022-12-31 12:32:43,473 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37290684729814527, 'Total loss': 0.37290684729814527} | train loss {'Reaction outcome loss': 0.2550847972233365, 'Total loss': 0.2550847972233365}
2022-12-31 12:32:43,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:43,473 INFO:     Epoch: 61
2022-12-31 12:32:45,068 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39188132832447686, 'Total loss': 0.39188132832447686} | train loss {'Reaction outcome loss': 0.24378537184076152, 'Total loss': 0.24378537184076152}
2022-12-31 12:32:45,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:45,069 INFO:     Epoch: 62
2022-12-31 12:32:46,671 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39682007481654485, 'Total loss': 0.39682007481654485} | train loss {'Reaction outcome loss': 0.24636632769647307, 'Total loss': 0.24636632769647307}
2022-12-31 12:32:46,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:46,672 INFO:     Epoch: 63
2022-12-31 12:32:48,275 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39142345587412514, 'Total loss': 0.39142345587412514} | train loss {'Reaction outcome loss': 0.240715474311779, 'Total loss': 0.240715474311779}
2022-12-31 12:32:48,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:48,275 INFO:     Epoch: 64
2022-12-31 12:32:49,900 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.429313259323438, 'Total loss': 0.429313259323438} | train loss {'Reaction outcome loss': 0.2386071445270829, 'Total loss': 0.2386071445270829}
2022-12-31 12:32:49,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:49,900 INFO:     Epoch: 65
2022-12-31 12:32:51,490 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3791198360423247, 'Total loss': 0.3791198360423247} | train loss {'Reaction outcome loss': 0.24807389145785005, 'Total loss': 0.24807389145785005}
2022-12-31 12:32:51,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:51,490 INFO:     Epoch: 66
2022-12-31 12:32:53,086 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3668910158177217, 'Total loss': 0.3668910158177217} | train loss {'Reaction outcome loss': 0.23441173125357523, 'Total loss': 0.23441173125357523}
2022-12-31 12:32:53,087 INFO:     Found new best model at epoch 66
2022-12-31 12:32:53,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:53,088 INFO:     Epoch: 67
2022-12-31 12:32:54,728 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4156506230433782, 'Total loss': 0.4156506230433782} | train loss {'Reaction outcome loss': 0.24521433049473015, 'Total loss': 0.24521433049473015}
2022-12-31 12:32:54,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:54,728 INFO:     Epoch: 68
2022-12-31 12:32:56,389 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3564763857672612, 'Total loss': 0.3564763857672612} | train loss {'Reaction outcome loss': 0.23691018478414655, 'Total loss': 0.23691018478414655}
2022-12-31 12:32:56,389 INFO:     Found new best model at epoch 68
2022-12-31 12:32:56,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:56,390 INFO:     Epoch: 69
2022-12-31 12:32:58,048 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3981005320946375, 'Total loss': 0.3981005320946375} | train loss {'Reaction outcome loss': 0.23500786890296171, 'Total loss': 0.23500786890296171}
2022-12-31 12:32:58,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:58,048 INFO:     Epoch: 70
2022-12-31 12:32:59,642 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43095549841721853, 'Total loss': 0.43095549841721853} | train loss {'Reaction outcome loss': 0.23725506903970764, 'Total loss': 0.23725506903970764}
2022-12-31 12:32:59,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:32:59,642 INFO:     Epoch: 71
2022-12-31 12:33:01,211 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3646855851014455, 'Total loss': 0.3646855851014455} | train loss {'Reaction outcome loss': 0.2330301169537171, 'Total loss': 0.2330301169537171}
2022-12-31 12:33:01,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:01,211 INFO:     Epoch: 72
2022-12-31 12:33:02,800 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41212290624777476, 'Total loss': 0.41212290624777476} | train loss {'Reaction outcome loss': 0.22932466117488423, 'Total loss': 0.22932466117488423}
2022-12-31 12:33:02,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:02,800 INFO:     Epoch: 73
2022-12-31 12:33:04,404 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40156135757764183, 'Total loss': 0.40156135757764183} | train loss {'Reaction outcome loss': 0.22794942909946841, 'Total loss': 0.22794942909946841}
2022-12-31 12:33:04,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:04,405 INFO:     Epoch: 74
2022-12-31 12:33:06,010 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3805727044741313, 'Total loss': 0.3805727044741313} | train loss {'Reaction outcome loss': 0.2241314707534646, 'Total loss': 0.2241314707534646}
2022-12-31 12:33:06,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:06,011 INFO:     Epoch: 75
2022-12-31 12:33:07,615 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37884672582149503, 'Total loss': 0.37884672582149503} | train loss {'Reaction outcome loss': 0.22782123782909916, 'Total loss': 0.22782123782909916}
2022-12-31 12:33:07,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:07,616 INFO:     Epoch: 76
2022-12-31 12:33:09,206 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3987665206193924, 'Total loss': 0.3987665206193924} | train loss {'Reaction outcome loss': 0.23069316324825487, 'Total loss': 0.23069316324825487}
2022-12-31 12:33:09,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:09,206 INFO:     Epoch: 77
2022-12-31 12:33:10,833 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4450927192966143, 'Total loss': 0.4450927192966143} | train loss {'Reaction outcome loss': 0.2189782248388459, 'Total loss': 0.2189782248388459}
2022-12-31 12:33:10,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:10,833 INFO:     Epoch: 78
2022-12-31 12:33:12,491 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3953018898765246, 'Total loss': 0.3953018898765246} | train loss {'Reaction outcome loss': 0.2217944621781472, 'Total loss': 0.2217944621781472}
2022-12-31 12:33:12,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:12,491 INFO:     Epoch: 79
2022-12-31 12:33:14,150 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39965055088202156, 'Total loss': 0.39965055088202156} | train loss {'Reaction outcome loss': 0.22066106354260315, 'Total loss': 0.22066106354260315}
2022-12-31 12:33:14,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:14,150 INFO:     Epoch: 80
2022-12-31 12:33:15,809 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3713672533631325, 'Total loss': 0.3713672533631325} | train loss {'Reaction outcome loss': 0.22015963800686555, 'Total loss': 0.22015963800686555}
2022-12-31 12:33:15,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:15,809 INFO:     Epoch: 81
2022-12-31 12:33:17,468 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4185527183115482, 'Total loss': 0.4185527183115482} | train loss {'Reaction outcome loss': 0.21398455228139884, 'Total loss': 0.21398455228139884}
2022-12-31 12:33:17,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:17,469 INFO:     Epoch: 82
2022-12-31 12:33:19,047 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3786943299074968, 'Total loss': 0.3786943299074968} | train loss {'Reaction outcome loss': 0.2185105980394313, 'Total loss': 0.2185105980394313}
2022-12-31 12:33:19,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:19,047 INFO:     Epoch: 83
2022-12-31 12:33:20,634 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39760627746582033, 'Total loss': 0.39760627746582033} | train loss {'Reaction outcome loss': 0.21239887073935165, 'Total loss': 0.21239887073935165}
2022-12-31 12:33:20,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:20,634 INFO:     Epoch: 84
2022-12-31 12:33:22,240 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.396161213517189, 'Total loss': 0.396161213517189} | train loss {'Reaction outcome loss': 0.2123345886765007, 'Total loss': 0.2123345886765007}
2022-12-31 12:33:22,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:22,241 INFO:     Epoch: 85
2022-12-31 12:33:23,848 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4333790883421898, 'Total loss': 0.4333790883421898} | train loss {'Reaction outcome loss': 0.20988553644151148, 'Total loss': 0.20988553644151148}
2022-12-31 12:33:23,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:23,849 INFO:     Epoch: 86
2022-12-31 12:33:25,455 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4142081876595815, 'Total loss': 0.4142081876595815} | train loss {'Reaction outcome loss': 0.2150174447260525, 'Total loss': 0.2150174447260525}
2022-12-31 12:33:25,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:25,455 INFO:     Epoch: 87
2022-12-31 12:33:27,049 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4010399306813876, 'Total loss': 0.4010399306813876} | train loss {'Reaction outcome loss': 0.20949996289300876, 'Total loss': 0.20949996289300876}
2022-12-31 12:33:27,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:27,049 INFO:     Epoch: 88
2022-12-31 12:33:28,653 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3904523879289627, 'Total loss': 0.3904523879289627} | train loss {'Reaction outcome loss': 0.21674753851291254, 'Total loss': 0.21674753851291254}
2022-12-31 12:33:28,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:28,654 INFO:     Epoch: 89
2022-12-31 12:33:30,242 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3746933067838351, 'Total loss': 0.3746933067838351} | train loss {'Reaction outcome loss': 0.2138225904183231, 'Total loss': 0.2138225904183231}
2022-12-31 12:33:30,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:30,242 INFO:     Epoch: 90
2022-12-31 12:33:31,850 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3859543378154437, 'Total loss': 0.3859543378154437} | train loss {'Reaction outcome loss': 0.20699490777413992, 'Total loss': 0.20699490777413992}
2022-12-31 12:33:31,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:31,851 INFO:     Epoch: 91
2022-12-31 12:33:33,460 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4153766681750615, 'Total loss': 0.4153766681750615} | train loss {'Reaction outcome loss': 0.20569133088944386, 'Total loss': 0.20569133088944386}
2022-12-31 12:33:33,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:33,461 INFO:     Epoch: 92
2022-12-31 12:33:35,068 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36334865565101304, 'Total loss': 0.36334865565101304} | train loss {'Reaction outcome loss': 0.2094072908108687, 'Total loss': 0.2094072908108687}
2022-12-31 12:33:35,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:35,069 INFO:     Epoch: 93
2022-12-31 12:33:36,655 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3983763853708903, 'Total loss': 0.3983763853708903} | train loss {'Reaction outcome loss': 0.20524264269773543, 'Total loss': 0.20524264269773543}
2022-12-31 12:33:36,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:36,656 INFO:     Epoch: 94
2022-12-31 12:33:38,239 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3939888084928195, 'Total loss': 0.3939888084928195} | train loss {'Reaction outcome loss': 0.20600184321362716, 'Total loss': 0.20600184321362716}
2022-12-31 12:33:38,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:38,240 INFO:     Epoch: 95
2022-12-31 12:33:39,844 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3963399628798167, 'Total loss': 0.3963399628798167} | train loss {'Reaction outcome loss': 0.20258856213304902, 'Total loss': 0.20258856213304902}
2022-12-31 12:33:39,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:39,844 INFO:     Epoch: 96
2022-12-31 12:33:41,452 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3762463003396988, 'Total loss': 0.3762463003396988} | train loss {'Reaction outcome loss': 0.2038275460902955, 'Total loss': 0.2038275460902955}
2022-12-31 12:33:41,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:41,452 INFO:     Epoch: 97
2022-12-31 12:33:43,055 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4047200858592987, 'Total loss': 0.4047200858592987} | train loss {'Reaction outcome loss': 0.20331124723447067, 'Total loss': 0.20331124723447067}
2022-12-31 12:33:43,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:43,055 INFO:     Epoch: 98
2022-12-31 12:33:44,656 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3771066943804423, 'Total loss': 0.3771066943804423} | train loss {'Reaction outcome loss': 0.211782050312218, 'Total loss': 0.211782050312218}
2022-12-31 12:33:44,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:44,656 INFO:     Epoch: 99
2022-12-31 12:33:46,256 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4073809494574865, 'Total loss': 0.4073809494574865} | train loss {'Reaction outcome loss': 0.1972409197992652, 'Total loss': 0.1972409197992652}
2022-12-31 12:33:46,256 INFO:     Best model found after epoch 69 of 100.
2022-12-31 12:33:46,257 INFO:   Done with stage: TRAINING
2022-12-31 12:33:46,257 INFO:   Starting stage: EVALUATION
2022-12-31 12:33:46,394 INFO:   Done with stage: EVALUATION
2022-12-31 12:33:46,394 INFO:   Leaving out SEQ value Fold_8
2022-12-31 12:33:46,406 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 12:33:46,407 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:33:47,057 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:33:47,058 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:33:47,126 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:33:47,126 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:33:47,126 INFO:     No hyperparam tuning for this model
2022-12-31 12:33:47,126 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:33:47,126 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:33:47,127 INFO:     None feature selector for col prot
2022-12-31 12:33:47,127 INFO:     None feature selector for col prot
2022-12-31 12:33:47,127 INFO:     None feature selector for col prot
2022-12-31 12:33:47,128 INFO:     None feature selector for col chem
2022-12-31 12:33:47,128 INFO:     None feature selector for col chem
2022-12-31 12:33:47,128 INFO:     None feature selector for col chem
2022-12-31 12:33:47,128 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:33:47,128 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:33:47,130 INFO:     Number of params in model 223921
2022-12-31 12:33:47,133 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:33:47,133 INFO:   Starting stage: TRAINING
2022-12-31 12:33:47,178 INFO:     Val loss before train {'Reaction outcome loss': 0.8364374756813049, 'Total loss': 0.8364374756813049}
2022-12-31 12:33:47,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:47,178 INFO:     Epoch: 0
2022-12-31 12:33:48,837 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5330441335837046, 'Total loss': 0.5330441335837046} | train loss {'Reaction outcome loss': 0.8277540074573958, 'Total loss': 0.8277540074573958}
2022-12-31 12:33:48,838 INFO:     Found new best model at epoch 0
2022-12-31 12:33:48,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:48,839 INFO:     Epoch: 1
2022-12-31 12:33:50,475 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4415228525797526, 'Total loss': 0.4415228525797526} | train loss {'Reaction outcome loss': 0.5945837061973255, 'Total loss': 0.5945837061973255}
2022-12-31 12:33:50,475 INFO:     Found new best model at epoch 1
2022-12-31 12:33:50,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:50,476 INFO:     Epoch: 2
2022-12-31 12:33:52,100 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4229917267958323, 'Total loss': 0.4229917267958323} | train loss {'Reaction outcome loss': 0.5353258205342379, 'Total loss': 0.5353258205342379}
2022-12-31 12:33:52,101 INFO:     Found new best model at epoch 2
2022-12-31 12:33:52,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:52,102 INFO:     Epoch: 3
2022-12-31 12:33:53,726 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4380634903907776, 'Total loss': 0.4380634903907776} | train loss {'Reaction outcome loss': 0.5074264265946533, 'Total loss': 0.5074264265946533}
2022-12-31 12:33:53,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:53,726 INFO:     Epoch: 4
2022-12-31 12:33:55,354 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4298741936683655, 'Total loss': 0.4298741936683655} | train loss {'Reaction outcome loss': 0.48996335536994656, 'Total loss': 0.48996335536994656}
2022-12-31 12:33:55,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:55,355 INFO:     Epoch: 5
2022-12-31 12:33:56,991 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41598272522290547, 'Total loss': 0.41598272522290547} | train loss {'Reaction outcome loss': 0.4878254860962341, 'Total loss': 0.4878254860962341}
2022-12-31 12:33:56,991 INFO:     Found new best model at epoch 5
2022-12-31 12:33:56,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:56,992 INFO:     Epoch: 6
2022-12-31 12:33:58,663 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42730072140693665, 'Total loss': 0.42730072140693665} | train loss {'Reaction outcome loss': 0.47244092036670726, 'Total loss': 0.47244092036670726}
2022-12-31 12:33:58,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:33:58,663 INFO:     Epoch: 7
2022-12-31 12:34:00,287 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4320631444454193, 'Total loss': 0.4320631444454193} | train loss {'Reaction outcome loss': 0.46557768563393653, 'Total loss': 0.46557768563393653}
2022-12-31 12:34:00,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:00,287 INFO:     Epoch: 8
2022-12-31 12:34:01,909 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43082128564516703, 'Total loss': 0.43082128564516703} | train loss {'Reaction outcome loss': 0.4640751772355087, 'Total loss': 0.4640751772355087}
2022-12-31 12:34:01,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:01,910 INFO:     Epoch: 9
2022-12-31 12:34:03,514 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42690174182256063, 'Total loss': 0.42690174182256063} | train loss {'Reaction outcome loss': 0.4491709689155813, 'Total loss': 0.4491709689155813}
2022-12-31 12:34:03,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:03,515 INFO:     Epoch: 10
2022-12-31 12:34:05,113 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4014671246210734, 'Total loss': 0.4014671246210734} | train loss {'Reaction outcome loss': 0.44513498042249505, 'Total loss': 0.44513498042249505}
2022-12-31 12:34:05,114 INFO:     Found new best model at epoch 10
2022-12-31 12:34:05,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:05,115 INFO:     Epoch: 11
2022-12-31 12:34:06,738 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4269047478834788, 'Total loss': 0.4269047478834788} | train loss {'Reaction outcome loss': 0.4368973296633266, 'Total loss': 0.4368973296633266}
2022-12-31 12:34:06,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:06,738 INFO:     Epoch: 12
2022-12-31 12:34:08,361 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.405544646581014, 'Total loss': 0.405544646581014} | train loss {'Reaction outcome loss': 0.42890979774592153, 'Total loss': 0.42890979774592153}
2022-12-31 12:34:08,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:08,362 INFO:     Epoch: 13
2022-12-31 12:34:09,985 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4063248028357824, 'Total loss': 0.4063248028357824} | train loss {'Reaction outcome loss': 0.4327895883672504, 'Total loss': 0.4327895883672504}
2022-12-31 12:34:09,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:09,985 INFO:     Epoch: 14
2022-12-31 12:34:11,609 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4156111498673757, 'Total loss': 0.4156111498673757} | train loss {'Reaction outcome loss': 0.42123327697442325, 'Total loss': 0.42123327697442325}
2022-12-31 12:34:11,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:11,610 INFO:     Epoch: 15
2022-12-31 12:34:13,216 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3997142215569814, 'Total loss': 0.3997142215569814} | train loss {'Reaction outcome loss': 0.4201864912998375, 'Total loss': 0.4201864912998375}
2022-12-31 12:34:13,216 INFO:     Found new best model at epoch 15
2022-12-31 12:34:13,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:13,217 INFO:     Epoch: 16
2022-12-31 12:34:14,836 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40231568515300753, 'Total loss': 0.40231568515300753} | train loss {'Reaction outcome loss': 0.4087550842912619, 'Total loss': 0.4087550842912619}
2022-12-31 12:34:14,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:14,836 INFO:     Epoch: 17
2022-12-31 12:34:16,449 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3908791810274124, 'Total loss': 0.3908791810274124} | train loss {'Reaction outcome loss': 0.4045207082203149, 'Total loss': 0.4045207082203149}
2022-12-31 12:34:16,450 INFO:     Found new best model at epoch 17
2022-12-31 12:34:16,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:16,451 INFO:     Epoch: 18
2022-12-31 12:34:18,070 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3847730189561844, 'Total loss': 0.3847730189561844} | train loss {'Reaction outcome loss': 0.4000370193689739, 'Total loss': 0.4000370193689739}
2022-12-31 12:34:18,070 INFO:     Found new best model at epoch 18
2022-12-31 12:34:18,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:18,071 INFO:     Epoch: 19
2022-12-31 12:34:19,692 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41922880013783775, 'Total loss': 0.41922880013783775} | train loss {'Reaction outcome loss': 0.3978706602854419, 'Total loss': 0.3978706602854419}
2022-12-31 12:34:19,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:19,693 INFO:     Epoch: 20
2022-12-31 12:34:21,297 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40188194264968236, 'Total loss': 0.40188194264968236} | train loss {'Reaction outcome loss': 0.38838106937141625, 'Total loss': 0.38838106937141625}
2022-12-31 12:34:21,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:21,297 INFO:     Epoch: 21
2022-12-31 12:34:22,918 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.418877245982488, 'Total loss': 0.418877245982488} | train loss {'Reaction outcome loss': 0.39185665698473204, 'Total loss': 0.39185665698473204}
2022-12-31 12:34:22,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:22,918 INFO:     Epoch: 22
2022-12-31 12:34:24,518 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39970629910628, 'Total loss': 0.39970629910628} | train loss {'Reaction outcome loss': 0.3795532662192837, 'Total loss': 0.3795532662192837}
2022-12-31 12:34:24,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:24,518 INFO:     Epoch: 23
2022-12-31 12:34:26,138 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39046175678571066, 'Total loss': 0.39046175678571066} | train loss {'Reaction outcome loss': 0.3723602058762678, 'Total loss': 0.3723602058762678}
2022-12-31 12:34:26,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:26,139 INFO:     Epoch: 24
2022-12-31 12:34:27,761 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3792029549057285, 'Total loss': 0.3792029549057285} | train loss {'Reaction outcome loss': 0.3627196019145556, 'Total loss': 0.3627196019145556}
2022-12-31 12:34:27,761 INFO:     Found new best model at epoch 24
2022-12-31 12:34:27,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:27,762 INFO:     Epoch: 25
2022-12-31 12:34:29,384 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38991256852944695, 'Total loss': 0.38991256852944695} | train loss {'Reaction outcome loss': 0.3616071893473825, 'Total loss': 0.3616071893473825}
2022-12-31 12:34:29,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:29,384 INFO:     Epoch: 26
2022-12-31 12:34:30,991 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3821363051732381, 'Total loss': 0.3821363051732381} | train loss {'Reaction outcome loss': 0.34712157600192817, 'Total loss': 0.34712157600192817}
2022-12-31 12:34:30,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:30,992 INFO:     Epoch: 27
2022-12-31 12:34:32,603 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3938668042421341, 'Total loss': 0.3938668042421341} | train loss {'Reaction outcome loss': 0.34473923125744727, 'Total loss': 0.34473923125744727}
2022-12-31 12:34:32,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:32,603 INFO:     Epoch: 28
2022-12-31 12:34:34,236 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37290827681620914, 'Total loss': 0.37290827681620914} | train loss {'Reaction outcome loss': 0.34442053724497235, 'Total loss': 0.34442053724497235}
2022-12-31 12:34:34,236 INFO:     Found new best model at epoch 28
2022-12-31 12:34:34,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:34,237 INFO:     Epoch: 29
2022-12-31 12:34:35,860 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3752807483077049, 'Total loss': 0.3752807483077049} | train loss {'Reaction outcome loss': 0.33891780518452613, 'Total loss': 0.33891780518452613}
2022-12-31 12:34:35,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:35,860 INFO:     Epoch: 30
2022-12-31 12:34:37,483 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3919692764679591, 'Total loss': 0.3919692764679591} | train loss {'Reaction outcome loss': 0.33226680820169, 'Total loss': 0.33226680820169}
2022-12-31 12:34:37,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:37,484 INFO:     Epoch: 31
2022-12-31 12:34:39,100 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3607314869761467, 'Total loss': 0.3607314869761467} | train loss {'Reaction outcome loss': 0.330269865234406, 'Total loss': 0.330269865234406}
2022-12-31 12:34:39,101 INFO:     Found new best model at epoch 31
2022-12-31 12:34:39,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:39,102 INFO:     Epoch: 32
2022-12-31 12:34:40,708 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35350308219591775, 'Total loss': 0.35350308219591775} | train loss {'Reaction outcome loss': 0.3249549657805732, 'Total loss': 0.3249549657805732}
2022-12-31 12:34:40,708 INFO:     Found new best model at epoch 32
2022-12-31 12:34:40,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:40,709 INFO:     Epoch: 33
2022-12-31 12:34:42,308 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.35934317062298454, 'Total loss': 0.35934317062298454} | train loss {'Reaction outcome loss': 0.31945012707518755, 'Total loss': 0.31945012707518755}
2022-12-31 12:34:42,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:42,308 INFO:     Epoch: 34
2022-12-31 12:34:43,931 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38255807061990105, 'Total loss': 0.38255807061990105} | train loss {'Reaction outcome loss': 0.31475182934681, 'Total loss': 0.31475182934681}
2022-12-31 12:34:43,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:43,931 INFO:     Epoch: 35
2022-12-31 12:34:45,552 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38070747007926303, 'Total loss': 0.38070747007926303} | train loss {'Reaction outcome loss': 0.32086940444602435, 'Total loss': 0.32086940444602435}
2022-12-31 12:34:45,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:45,553 INFO:     Epoch: 36
2022-12-31 12:34:47,174 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3734597623348236, 'Total loss': 0.3734597623348236} | train loss {'Reaction outcome loss': 0.30630378793615726, 'Total loss': 0.30630378793615726}
2022-12-31 12:34:47,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:47,174 INFO:     Epoch: 37
2022-12-31 12:34:48,779 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3761318400502205, 'Total loss': 0.3761318400502205} | train loss {'Reaction outcome loss': 0.30268587133030167, 'Total loss': 0.30268587133030167}
2022-12-31 12:34:48,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:48,779 INFO:     Epoch: 38
2022-12-31 12:34:50,378 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34671634435653687, 'Total loss': 0.34671634435653687} | train loss {'Reaction outcome loss': 0.29972646713579604, 'Total loss': 0.29972646713579604}
2022-12-31 12:34:50,379 INFO:     Found new best model at epoch 38
2022-12-31 12:34:50,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:50,380 INFO:     Epoch: 39
2022-12-31 12:34:52,023 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3449204752842585, 'Total loss': 0.3449204752842585} | train loss {'Reaction outcome loss': 0.299080164625649, 'Total loss': 0.299080164625649}
2022-12-31 12:34:52,023 INFO:     Found new best model at epoch 39
2022-12-31 12:34:52,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:52,024 INFO:     Epoch: 40
2022-12-31 12:34:53,646 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37169219354788463, 'Total loss': 0.37169219354788463} | train loss {'Reaction outcome loss': 0.2944291502452499, 'Total loss': 0.2944291502452499}
2022-12-31 12:34:53,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:53,646 INFO:     Epoch: 41
2022-12-31 12:34:55,270 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37495006769895556, 'Total loss': 0.37495006769895556} | train loss {'Reaction outcome loss': 0.28695587885132334, 'Total loss': 0.28695587885132334}
2022-12-31 12:34:55,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:55,271 INFO:     Epoch: 42
2022-12-31 12:34:56,894 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36703881522019705, 'Total loss': 0.36703881522019705} | train loss {'Reaction outcome loss': 0.2863117420393637, 'Total loss': 0.2863117420393637}
2022-12-31 12:34:56,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:56,894 INFO:     Epoch: 43
2022-12-31 12:34:58,496 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3527016580104828, 'Total loss': 0.3527016580104828} | train loss {'Reaction outcome loss': 0.29032926640678397, 'Total loss': 0.29032926640678397}
2022-12-31 12:34:58,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:34:58,496 INFO:     Epoch: 44
2022-12-31 12:35:00,128 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.33354317446549736, 'Total loss': 0.33354317446549736} | train loss {'Reaction outcome loss': 0.2801206459691378, 'Total loss': 0.2801206459691378}
2022-12-31 12:35:00,128 INFO:     Found new best model at epoch 44
2022-12-31 12:35:00,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:00,129 INFO:     Epoch: 45
2022-12-31 12:35:01,751 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39249948809544244, 'Total loss': 0.39249948809544244} | train loss {'Reaction outcome loss': 0.2731896850821774, 'Total loss': 0.2731896850821774}
2022-12-31 12:35:01,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:01,752 INFO:     Epoch: 46
2022-12-31 12:35:03,373 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3728293697039286, 'Total loss': 0.3728293697039286} | train loss {'Reaction outcome loss': 0.27299975906414675, 'Total loss': 0.27299975906414675}
2022-12-31 12:35:03,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:03,373 INFO:     Epoch: 47
2022-12-31 12:35:05,001 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3732069830099742, 'Total loss': 0.3732069830099742} | train loss {'Reaction outcome loss': 0.2660365890213944, 'Total loss': 0.2660365890213944}
2022-12-31 12:35:05,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:05,002 INFO:     Epoch: 48
2022-12-31 12:35:06,603 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3578684374690056, 'Total loss': 0.3578684374690056} | train loss {'Reaction outcome loss': 0.26289110034973184, 'Total loss': 0.26289110034973184}
2022-12-31 12:35:06,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:06,604 INFO:     Epoch: 49
2022-12-31 12:35:08,215 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36132262150446576, 'Total loss': 0.36132262150446576} | train loss {'Reaction outcome loss': 0.26533650332517145, 'Total loss': 0.26533650332517145}
2022-12-31 12:35:08,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:08,216 INFO:     Epoch: 50
2022-12-31 12:35:09,826 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.350288525223732, 'Total loss': 0.350288525223732} | train loss {'Reaction outcome loss': 0.26595249107705987, 'Total loss': 0.26595249107705987}
2022-12-31 12:35:09,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:09,826 INFO:     Epoch: 51
2022-12-31 12:35:11,450 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40054290294647216, 'Total loss': 0.40054290294647216} | train loss {'Reaction outcome loss': 0.2595746442204886, 'Total loss': 0.2595746442204886}
2022-12-31 12:35:11,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:11,450 INFO:     Epoch: 52
2022-12-31 12:35:13,074 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.33756863375504814, 'Total loss': 0.33756863375504814} | train loss {'Reaction outcome loss': 0.2636134026148474, 'Total loss': 0.2636134026148474}
2022-12-31 12:35:13,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:13,074 INFO:     Epoch: 53
2022-12-31 12:35:14,698 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36187468071778617, 'Total loss': 0.36187468071778617} | train loss {'Reaction outcome loss': 0.25291002299703846, 'Total loss': 0.25291002299703846}
2022-12-31 12:35:14,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:14,699 INFO:     Epoch: 54
2022-12-31 12:35:16,301 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.354896479845047, 'Total loss': 0.354896479845047} | train loss {'Reaction outcome loss': 0.25920668472653585, 'Total loss': 0.25920668472653585}
2022-12-31 12:35:16,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:16,301 INFO:     Epoch: 55
2022-12-31 12:35:17,907 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3542986214160919, 'Total loss': 0.3542986214160919} | train loss {'Reaction outcome loss': 0.2516474895690322, 'Total loss': 0.2516474895690322}
2022-12-31 12:35:17,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:17,907 INFO:     Epoch: 56
2022-12-31 12:35:19,535 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37054126262664794, 'Total loss': 0.37054126262664794} | train loss {'Reaction outcome loss': 0.24887641558309323, 'Total loss': 0.24887641558309323}
2022-12-31 12:35:19,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:19,535 INFO:     Epoch: 57
2022-12-31 12:35:21,171 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3835962990919749, 'Total loss': 0.3835962990919749} | train loss {'Reaction outcome loss': 0.25296541393502525, 'Total loss': 0.25296541393502525}
2022-12-31 12:35:21,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:21,171 INFO:     Epoch: 58
2022-12-31 12:35:22,796 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.368390898903211, 'Total loss': 0.368390898903211} | train loss {'Reaction outcome loss': 0.24202933512789462, 'Total loss': 0.24202933512789462}
2022-12-31 12:35:22,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:22,796 INFO:     Epoch: 59
2022-12-31 12:35:24,398 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.34239886899789174, 'Total loss': 0.34239886899789174} | train loss {'Reaction outcome loss': 0.24154900220165615, 'Total loss': 0.24154900220165615}
2022-12-31 12:35:24,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:24,398 INFO:     Epoch: 60
2022-12-31 12:35:26,019 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35936547418435416, 'Total loss': 0.35936547418435416} | train loss {'Reaction outcome loss': 0.24165259129519068, 'Total loss': 0.24165259129519068}
2022-12-31 12:35:26,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:26,019 INFO:     Epoch: 61
2022-12-31 12:35:27,637 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3527378956476847, 'Total loss': 0.3527378956476847} | train loss {'Reaction outcome loss': 0.2361774461659929, 'Total loss': 0.2361774461659929}
2022-12-31 12:35:27,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:27,638 INFO:     Epoch: 62
2022-12-31 12:35:29,295 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3508942570537329, 'Total loss': 0.3508942570537329} | train loss {'Reaction outcome loss': 0.237765325266962, 'Total loss': 0.237765325266962}
2022-12-31 12:35:29,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:29,296 INFO:     Epoch: 63
2022-12-31 12:35:30,963 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38583438098430634, 'Total loss': 0.38583438098430634} | train loss {'Reaction outcome loss': 0.23787334699197152, 'Total loss': 0.23787334699197152}
2022-12-31 12:35:30,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:30,964 INFO:     Epoch: 64
2022-12-31 12:35:32,584 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3406199024369319, 'Total loss': 0.3406199024369319} | train loss {'Reaction outcome loss': 0.240745305120676, 'Total loss': 0.240745305120676}
2022-12-31 12:35:32,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:32,584 INFO:     Epoch: 65
2022-12-31 12:35:34,193 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3659853200117747, 'Total loss': 0.3659853200117747} | train loss {'Reaction outcome loss': 0.24073826866594247, 'Total loss': 0.24073826866594247}
2022-12-31 12:35:34,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:34,193 INFO:     Epoch: 66
2022-12-31 12:35:35,791 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3906126216053963, 'Total loss': 0.3906126216053963} | train loss {'Reaction outcome loss': 0.23389817122706222, 'Total loss': 0.23389817122706222}
2022-12-31 12:35:35,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:35,791 INFO:     Epoch: 67
2022-12-31 12:35:37,456 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35396575133005775, 'Total loss': 0.35396575133005775} | train loss {'Reaction outcome loss': 0.23935653690235278, 'Total loss': 0.23935653690235278}
2022-12-31 12:35:37,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:37,457 INFO:     Epoch: 68
2022-12-31 12:35:39,082 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3512445047497749, 'Total loss': 0.3512445047497749} | train loss {'Reaction outcome loss': 0.23174756161518906, 'Total loss': 0.23174756161518906}
2022-12-31 12:35:39,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:39,082 INFO:     Epoch: 69
2022-12-31 12:35:40,704 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3830328534046809, 'Total loss': 0.3830328534046809} | train loss {'Reaction outcome loss': 0.22257780706987376, 'Total loss': 0.22257780706987376}
2022-12-31 12:35:40,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:40,704 INFO:     Epoch: 70
2022-12-31 12:35:42,327 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34846317370732627, 'Total loss': 0.34846317370732627} | train loss {'Reaction outcome loss': 0.22867587776283063, 'Total loss': 0.22867587776283063}
2022-12-31 12:35:42,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:42,327 INFO:     Epoch: 71
2022-12-31 12:35:43,928 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3763040085633596, 'Total loss': 0.3763040085633596} | train loss {'Reaction outcome loss': 0.22356681974221437, 'Total loss': 0.22356681974221437}
2022-12-31 12:35:43,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:43,928 INFO:     Epoch: 72
2022-12-31 12:35:45,526 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3357423317929109, 'Total loss': 0.3357423317929109} | train loss {'Reaction outcome loss': 0.2232452330956175, 'Total loss': 0.2232452330956175}
2022-12-31 12:35:45,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:45,526 INFO:     Epoch: 73
2022-12-31 12:35:47,148 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3552661289771398, 'Total loss': 0.3552661289771398} | train loss {'Reaction outcome loss': 0.22494263273230097, 'Total loss': 0.22494263273230097}
2022-12-31 12:35:47,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:47,149 INFO:     Epoch: 74
2022-12-31 12:35:48,769 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34341313938299817, 'Total loss': 0.34341313938299817} | train loss {'Reaction outcome loss': 0.22006390072970183, 'Total loss': 0.22006390072970183}
2022-12-31 12:35:48,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:48,769 INFO:     Epoch: 75
2022-12-31 12:35:50,392 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3754444867372513, 'Total loss': 0.3754444867372513} | train loss {'Reaction outcome loss': 0.22190624875577994, 'Total loss': 0.22190624875577994}
2022-12-31 12:35:50,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:50,393 INFO:     Epoch: 76
2022-12-31 12:35:52,001 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38082026938597363, 'Total loss': 0.38082026938597363} | train loss {'Reaction outcome loss': 0.2224430064754796, 'Total loss': 0.2224430064754796}
2022-12-31 12:35:52,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:52,001 INFO:     Epoch: 77
2022-12-31 12:35:53,644 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36488805860280993, 'Total loss': 0.36488805860280993} | train loss {'Reaction outcome loss': 0.21912822326383005, 'Total loss': 0.21912822326383005}
2022-12-31 12:35:53,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:53,644 INFO:     Epoch: 78
2022-12-31 12:35:55,297 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3422478834788005, 'Total loss': 0.3422478834788005} | train loss {'Reaction outcome loss': 0.22549130809947257, 'Total loss': 0.22549130809947257}
2022-12-31 12:35:55,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:55,297 INFO:     Epoch: 79
2022-12-31 12:35:56,963 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3494056304295858, 'Total loss': 0.3494056304295858} | train loss {'Reaction outcome loss': 0.2221436762731751, 'Total loss': 0.2221436762731751}
2022-12-31 12:35:56,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:56,963 INFO:     Epoch: 80
2022-12-31 12:35:58,611 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3459090347091357, 'Total loss': 0.3459090347091357} | train loss {'Reaction outcome loss': 0.2142596436187033, 'Total loss': 0.2142596436187033}
2022-12-31 12:35:58,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:35:58,611 INFO:     Epoch: 81
2022-12-31 12:36:00,234 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3578718091050784, 'Total loss': 0.3578718091050784} | train loss {'Reaction outcome loss': 0.2123545368575232, 'Total loss': 0.2123545368575232}
2022-12-31 12:36:00,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:00,234 INFO:     Epoch: 82
2022-12-31 12:36:01,832 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.33374834259351094, 'Total loss': 0.33374834259351094} | train loss {'Reaction outcome loss': 0.21065242228094852, 'Total loss': 0.21065242228094852}
2022-12-31 12:36:01,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:01,833 INFO:     Epoch: 83
2022-12-31 12:36:03,427 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4029290646314621, 'Total loss': 0.4029290646314621} | train loss {'Reaction outcome loss': 0.21189202338672286, 'Total loss': 0.21189202338672286}
2022-12-31 12:36:03,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:03,428 INFO:     Epoch: 84
2022-12-31 12:36:05,045 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3498376573125521, 'Total loss': 0.3498376573125521} | train loss {'Reaction outcome loss': 0.20832903028233818, 'Total loss': 0.20832903028233818}
2022-12-31 12:36:05,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:05,046 INFO:     Epoch: 85
2022-12-31 12:36:06,662 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.354766624669234, 'Total loss': 0.354766624669234} | train loss {'Reaction outcome loss': 0.21524948624739362, 'Total loss': 0.21524948624739362}
2022-12-31 12:36:06,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:06,663 INFO:     Epoch: 86
2022-12-31 12:36:08,278 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3820086191097895, 'Total loss': 0.3820086191097895} | train loss {'Reaction outcome loss': 0.2084640592625802, 'Total loss': 0.2084640592625802}
2022-12-31 12:36:08,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:08,278 INFO:     Epoch: 87
2022-12-31 12:36:09,878 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3572727272907893, 'Total loss': 0.3572727272907893} | train loss {'Reaction outcome loss': 0.21543403374643103, 'Total loss': 0.21543403374643103}
2022-12-31 12:36:09,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:09,879 INFO:     Epoch: 88
2022-12-31 12:36:11,551 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35102767050266265, 'Total loss': 0.35102767050266265} | train loss {'Reaction outcome loss': 0.20657282032825672, 'Total loss': 0.20657282032825672}
2022-12-31 12:36:11,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:11,551 INFO:     Epoch: 89
2022-12-31 12:36:13,146 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.34652532562613486, 'Total loss': 0.34652532562613486} | train loss {'Reaction outcome loss': 0.20925615622329152, 'Total loss': 0.20925615622329152}
2022-12-31 12:36:13,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:13,146 INFO:     Epoch: 90
2022-12-31 12:36:14,765 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.33242815310756363, 'Total loss': 0.33242815310756363} | train loss {'Reaction outcome loss': 0.19950745736890968, 'Total loss': 0.19950745736890968}
2022-12-31 12:36:14,765 INFO:     Found new best model at epoch 90
2022-12-31 12:36:14,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:14,766 INFO:     Epoch: 91
2022-12-31 12:36:16,425 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3643359531958898, 'Total loss': 0.3643359531958898} | train loss {'Reaction outcome loss': 0.20146790501873416, 'Total loss': 0.20146790501873416}
2022-12-31 12:36:16,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:16,425 INFO:     Epoch: 92
2022-12-31 12:36:18,098 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3642048448324203, 'Total loss': 0.3642048448324203} | train loss {'Reaction outcome loss': 0.20372982459674027, 'Total loss': 0.20372982459674027}
2022-12-31 12:36:18,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:18,098 INFO:     Epoch: 93
2022-12-31 12:36:19,709 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3870400423804919, 'Total loss': 0.3870400423804919} | train loss {'Reaction outcome loss': 0.20537830893259618, 'Total loss': 0.20537830893259618}
2022-12-31 12:36:19,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:19,709 INFO:     Epoch: 94
2022-12-31 12:36:21,348 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36970681746800743, 'Total loss': 0.36970681746800743} | train loss {'Reaction outcome loss': 0.2027575361646631, 'Total loss': 0.2027575361646631}
2022-12-31 12:36:21,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:21,349 INFO:     Epoch: 95
2022-12-31 12:36:22,971 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.33791221529245374, 'Total loss': 0.33791221529245374} | train loss {'Reaction outcome loss': 0.2109873849942285, 'Total loss': 0.2109873849942285}
2022-12-31 12:36:22,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:22,971 INFO:     Epoch: 96
2022-12-31 12:36:24,593 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3453437944253286, 'Total loss': 0.3453437944253286} | train loss {'Reaction outcome loss': 0.19622353738718515, 'Total loss': 0.19622353738718515}
2022-12-31 12:36:24,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:24,594 INFO:     Epoch: 97
2022-12-31 12:36:26,214 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.34103407052656015, 'Total loss': 0.34103407052656015} | train loss {'Reaction outcome loss': 0.2036103011320752, 'Total loss': 0.2036103011320752}
2022-12-31 12:36:26,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:26,215 INFO:     Epoch: 98
2022-12-31 12:36:27,821 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37697299222151437, 'Total loss': 0.37697299222151437} | train loss {'Reaction outcome loss': 0.20303629289317324, 'Total loss': 0.20303629289317324}
2022-12-31 12:36:27,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:27,821 INFO:     Epoch: 99
2022-12-31 12:36:29,430 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37178977131843566, 'Total loss': 0.37178977131843566} | train loss {'Reaction outcome loss': 0.1979947579009223, 'Total loss': 0.1979947579009223}
2022-12-31 12:36:29,430 INFO:     Best model found after epoch 91 of 100.
2022-12-31 12:36:29,430 INFO:   Done with stage: TRAINING
2022-12-31 12:36:29,430 INFO:   Starting stage: EVALUATION
2022-12-31 12:36:29,552 INFO:   Done with stage: EVALUATION
2022-12-31 12:36:29,552 INFO:   Leaving out SEQ value Fold_9
2022-12-31 12:36:29,565 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 12:36:29,565 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:36:30,206 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:36:30,206 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:36:30,275 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:36:30,275 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:36:30,275 INFO:     No hyperparam tuning for this model
2022-12-31 12:36:30,275 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:36:30,275 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:36:30,276 INFO:     None feature selector for col prot
2022-12-31 12:36:30,276 INFO:     None feature selector for col prot
2022-12-31 12:36:30,276 INFO:     None feature selector for col prot
2022-12-31 12:36:30,277 INFO:     None feature selector for col chem
2022-12-31 12:36:30,277 INFO:     None feature selector for col chem
2022-12-31 12:36:30,277 INFO:     None feature selector for col chem
2022-12-31 12:36:30,277 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:36:30,277 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:36:30,279 INFO:     Number of params in model 223921
2022-12-31 12:36:30,282 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:36:30,282 INFO:   Starting stage: TRAINING
2022-12-31 12:36:30,318 INFO:     Val loss before train {'Reaction outcome loss': 0.9821491161982219, 'Total loss': 0.9821491161982219}
2022-12-31 12:36:30,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:30,318 INFO:     Epoch: 0
2022-12-31 12:36:31,387 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6640181104342143, 'Total loss': 0.6640181104342143} | train loss {'Reaction outcome loss': 0.8104996364699663, 'Total loss': 0.8104996364699663}
2022-12-31 12:36:31,387 INFO:     Found new best model at epoch 0
2022-12-31 12:36:31,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:31,388 INFO:     Epoch: 1
2022-12-31 12:36:32,451 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5802568515141805, 'Total loss': 0.5802568515141805} | train loss {'Reaction outcome loss': 0.5980032673717415, 'Total loss': 0.5980032673717415}
2022-12-31 12:36:32,451 INFO:     Found new best model at epoch 1
2022-12-31 12:36:32,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:32,452 INFO:     Epoch: 2
2022-12-31 12:36:33,510 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.544030906756719, 'Total loss': 0.544030906756719} | train loss {'Reaction outcome loss': 0.5273687949363333, 'Total loss': 0.5273687949363333}
2022-12-31 12:36:33,510 INFO:     Found new best model at epoch 2
2022-12-31 12:36:33,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:33,511 INFO:     Epoch: 3
2022-12-31 12:36:34,616 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5745368262132009, 'Total loss': 0.5745368262132009} | train loss {'Reaction outcome loss': 0.5061746025933836, 'Total loss': 0.5061746025933836}
2022-12-31 12:36:34,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:34,616 INFO:     Epoch: 4
2022-12-31 12:36:36,216 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5443665405114492, 'Total loss': 0.5443665405114492} | train loss {'Reaction outcome loss': 0.48639241513544623, 'Total loss': 0.48639241513544623}
2022-12-31 12:36:36,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:36,216 INFO:     Epoch: 5
2022-12-31 12:36:37,813 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5010205984115601, 'Total loss': 0.5010205984115601} | train loss {'Reaction outcome loss': 0.47426150173601445, 'Total loss': 0.47426150173601445}
2022-12-31 12:36:37,815 INFO:     Found new best model at epoch 5
2022-12-31 12:36:37,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:37,816 INFO:     Epoch: 6
2022-12-31 12:36:39,408 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5247354348500569, 'Total loss': 0.5247354348500569} | train loss {'Reaction outcome loss': 0.4613301156863679, 'Total loss': 0.4613301156863679}
2022-12-31 12:36:39,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:39,408 INFO:     Epoch: 7
2022-12-31 12:36:41,000 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5036401510238647, 'Total loss': 0.5036401510238647} | train loss {'Reaction outcome loss': 0.45562493850062363, 'Total loss': 0.45562493850062363}
2022-12-31 12:36:41,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:41,000 INFO:     Epoch: 8
2022-12-31 12:36:42,571 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4860680321852366, 'Total loss': 0.4860680321852366} | train loss {'Reaction outcome loss': 0.4460284634880776, 'Total loss': 0.4460284634880776}
2022-12-31 12:36:42,571 INFO:     Found new best model at epoch 8
2022-12-31 12:36:42,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:42,572 INFO:     Epoch: 9
2022-12-31 12:36:44,152 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5379580676555633, 'Total loss': 0.5379580676555633} | train loss {'Reaction outcome loss': 0.44136834438264805, 'Total loss': 0.44136834438264805}
2022-12-31 12:36:44,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:44,153 INFO:     Epoch: 10
2022-12-31 12:36:45,745 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4933988293011983, 'Total loss': 0.4933988293011983} | train loss {'Reaction outcome loss': 0.43742469899410746, 'Total loss': 0.43742469899410746}
2022-12-31 12:36:45,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:45,746 INFO:     Epoch: 11
2022-12-31 12:36:47,339 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5135270655155182, 'Total loss': 0.5135270655155182} | train loss {'Reaction outcome loss': 0.4287797665889681, 'Total loss': 0.4287797665889681}
2022-12-31 12:36:47,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:47,339 INFO:     Epoch: 12
2022-12-31 12:36:48,931 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46682786345481875, 'Total loss': 0.46682786345481875} | train loss {'Reaction outcome loss': 0.4260140867346395, 'Total loss': 0.4260140867346395}
2022-12-31 12:36:48,931 INFO:     Found new best model at epoch 12
2022-12-31 12:36:48,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:48,932 INFO:     Epoch: 13
2022-12-31 12:36:50,520 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4869973182678223, 'Total loss': 0.4869973182678223} | train loss {'Reaction outcome loss': 0.4132351176201427, 'Total loss': 0.4132351176201427}
2022-12-31 12:36:50,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:50,521 INFO:     Epoch: 14
2022-12-31 12:36:52,141 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47904365658760073, 'Total loss': 0.47904365658760073} | train loss {'Reaction outcome loss': 0.4097582095567762, 'Total loss': 0.4097582095567762}
2022-12-31 12:36:52,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:52,141 INFO:     Epoch: 15
2022-12-31 12:36:53,728 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4615877638260523, 'Total loss': 0.4615877638260523} | train loss {'Reaction outcome loss': 0.40649547748757103, 'Total loss': 0.40649547748757103}
2022-12-31 12:36:53,728 INFO:     Found new best model at epoch 15
2022-12-31 12:36:53,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:53,729 INFO:     Epoch: 16
2022-12-31 12:36:55,327 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4568791111310323, 'Total loss': 0.4568791111310323} | train loss {'Reaction outcome loss': 0.3979397497690507, 'Total loss': 0.3979397497690507}
2022-12-31 12:36:55,327 INFO:     Found new best model at epoch 16
2022-12-31 12:36:55,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:55,328 INFO:     Epoch: 17
2022-12-31 12:36:56,928 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4468945741653442, 'Total loss': 0.4468945741653442} | train loss {'Reaction outcome loss': 0.3966195384570717, 'Total loss': 0.3966195384570717}
2022-12-31 12:36:56,929 INFO:     Found new best model at epoch 17
2022-12-31 12:36:56,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:56,930 INFO:     Epoch: 18
2022-12-31 12:36:58,554 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4687795420487722, 'Total loss': 0.4687795420487722} | train loss {'Reaction outcome loss': 0.38814785932428647, 'Total loss': 0.38814785932428647}
2022-12-31 12:36:58,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:36:58,554 INFO:     Epoch: 19
2022-12-31 12:37:00,192 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47238832314809165, 'Total loss': 0.47238832314809165} | train loss {'Reaction outcome loss': 0.3824612020521703, 'Total loss': 0.3824612020521703}
2022-12-31 12:37:00,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:00,192 INFO:     Epoch: 20
2022-12-31 12:37:01,797 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45848384698232014, 'Total loss': 0.45848384698232014} | train loss {'Reaction outcome loss': 0.38283294202746265, 'Total loss': 0.38283294202746265}
2022-12-31 12:37:01,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:01,798 INFO:     Epoch: 21
2022-12-31 12:37:03,440 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45914114514986676, 'Total loss': 0.45914114514986676} | train loss {'Reaction outcome loss': 0.36967331013322746, 'Total loss': 0.36967331013322746}
2022-12-31 12:37:03,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:03,440 INFO:     Epoch: 22
2022-12-31 12:37:05,083 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44346342782179515, 'Total loss': 0.44346342782179515} | train loss {'Reaction outcome loss': 0.36786047464413363, 'Total loss': 0.36786047464413363}
2022-12-31 12:37:05,083 INFO:     Found new best model at epoch 22
2022-12-31 12:37:05,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:05,084 INFO:     Epoch: 23
2022-12-31 12:37:06,735 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45287970900535585, 'Total loss': 0.45287970900535585} | train loss {'Reaction outcome loss': 0.37107353807039506, 'Total loss': 0.37107353807039506}
2022-12-31 12:37:06,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:06,735 INFO:     Epoch: 24
2022-12-31 12:37:08,350 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44679917097091676, 'Total loss': 0.44679917097091676} | train loss {'Reaction outcome loss': 0.3578672617891409, 'Total loss': 0.3578672617891409}
2022-12-31 12:37:08,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:08,351 INFO:     Epoch: 25
2022-12-31 12:37:09,947 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43760605255762736, 'Total loss': 0.43760605255762736} | train loss {'Reaction outcome loss': 0.3528741941834888, 'Total loss': 0.3528741941834888}
2022-12-31 12:37:09,947 INFO:     Found new best model at epoch 25
2022-12-31 12:37:09,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:09,948 INFO:     Epoch: 26
2022-12-31 12:37:11,538 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46400712529818217, 'Total loss': 0.46400712529818217} | train loss {'Reaction outcome loss': 0.3438197926339442, 'Total loss': 0.3438197926339442}
2022-12-31 12:37:11,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:11,538 INFO:     Epoch: 27
2022-12-31 12:37:13,186 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4180426334341367, 'Total loss': 0.4180426334341367} | train loss {'Reaction outcome loss': 0.3455410222420945, 'Total loss': 0.3455410222420945}
2022-12-31 12:37:13,187 INFO:     Found new best model at epoch 27
2022-12-31 12:37:13,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:13,188 INFO:     Epoch: 28
2022-12-31 12:37:14,816 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.445836611588796, 'Total loss': 0.445836611588796} | train loss {'Reaction outcome loss': 0.337550352769394, 'Total loss': 0.337550352769394}
2022-12-31 12:37:14,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:14,817 INFO:     Epoch: 29
2022-12-31 12:37:16,439 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42639559507369995, 'Total loss': 0.42639559507369995} | train loss {'Reaction outcome loss': 0.33831717982126847, 'Total loss': 0.33831717982126847}
2022-12-31 12:37:16,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:16,439 INFO:     Epoch: 30
2022-12-31 12:37:18,044 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43898741056521734, 'Total loss': 0.43898741056521734} | train loss {'Reaction outcome loss': 0.3338605158139754, 'Total loss': 0.3338605158139754}
2022-12-31 12:37:18,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:18,044 INFO:     Epoch: 31
2022-12-31 12:37:19,641 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39698507885138196, 'Total loss': 0.39698507885138196} | train loss {'Reaction outcome loss': 0.3270180663433823, 'Total loss': 0.3270180663433823}
2022-12-31 12:37:19,641 INFO:     Found new best model at epoch 31
2022-12-31 12:37:19,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:19,642 INFO:     Epoch: 32
2022-12-31 12:37:21,227 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39045282602310183, 'Total loss': 0.39045282602310183} | train loss {'Reaction outcome loss': 0.32157105805665037, 'Total loss': 0.32157105805665037}
2022-12-31 12:37:21,228 INFO:     Found new best model at epoch 32
2022-12-31 12:37:21,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:21,229 INFO:     Epoch: 33
2022-12-31 12:37:22,827 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4342367718617121, 'Total loss': 0.4342367718617121} | train loss {'Reaction outcome loss': 0.3170281945299493, 'Total loss': 0.3170281945299493}
2022-12-31 12:37:22,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:22,827 INFO:     Epoch: 34
2022-12-31 12:37:24,444 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4328492184480031, 'Total loss': 0.4328492184480031} | train loss {'Reaction outcome loss': 0.31470391379982016, 'Total loss': 0.31470391379982016}
2022-12-31 12:37:24,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:24,445 INFO:     Epoch: 35
2022-12-31 12:37:26,044 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4125793615976969, 'Total loss': 0.4125793615976969} | train loss {'Reaction outcome loss': 0.31054511323679973, 'Total loss': 0.31054511323679973}
2022-12-31 12:37:26,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:26,044 INFO:     Epoch: 36
2022-12-31 12:37:27,639 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3975669453541438, 'Total loss': 0.3975669453541438} | train loss {'Reaction outcome loss': 0.30775353661908283, 'Total loss': 0.30775353661908283}
2022-12-31 12:37:27,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:27,640 INFO:     Epoch: 37
2022-12-31 12:37:29,203 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3991482446591059, 'Total loss': 0.3991482446591059} | train loss {'Reaction outcome loss': 0.29861049294254205, 'Total loss': 0.29861049294254205}
2022-12-31 12:37:29,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:29,203 INFO:     Epoch: 38
2022-12-31 12:37:30,826 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39335126082102456, 'Total loss': 0.39335126082102456} | train loss {'Reaction outcome loss': 0.29909136964783184, 'Total loss': 0.29909136964783184}
2022-12-31 12:37:30,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:30,826 INFO:     Epoch: 39
2022-12-31 12:37:32,428 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41838830908139546, 'Total loss': 0.41838830908139546} | train loss {'Reaction outcome loss': 0.301100690407257, 'Total loss': 0.301100690407257}
2022-12-31 12:37:32,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:32,429 INFO:     Epoch: 40
2022-12-31 12:37:34,028 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37914867103099825, 'Total loss': 0.37914867103099825} | train loss {'Reaction outcome loss': 0.29355168187596503, 'Total loss': 0.29355168187596503}
2022-12-31 12:37:34,028 INFO:     Found new best model at epoch 40
2022-12-31 12:37:34,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:34,029 INFO:     Epoch: 41
2022-12-31 12:37:35,624 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41003140757481255, 'Total loss': 0.41003140757481255} | train loss {'Reaction outcome loss': 0.29373548194820426, 'Total loss': 0.29373548194820426}
2022-12-31 12:37:35,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:35,625 INFO:     Epoch: 42
2022-12-31 12:37:37,221 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43515132665634154, 'Total loss': 0.43515132665634154} | train loss {'Reaction outcome loss': 0.2833286315257097, 'Total loss': 0.2833286315257097}
2022-12-31 12:37:37,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:37,221 INFO:     Epoch: 43
2022-12-31 12:37:38,790 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3947830172876517, 'Total loss': 0.3947830172876517} | train loss {'Reaction outcome loss': 0.295006139489421, 'Total loss': 0.295006139489421}
2022-12-31 12:37:38,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:38,790 INFO:     Epoch: 44
2022-12-31 12:37:40,438 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.421572744846344, 'Total loss': 0.421572744846344} | train loss {'Reaction outcome loss': 0.28673311057126655, 'Total loss': 0.28673311057126655}
2022-12-31 12:37:40,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:40,438 INFO:     Epoch: 45
2022-12-31 12:37:42,082 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3912683958808581, 'Total loss': 0.3912683958808581} | train loss {'Reaction outcome loss': 0.27996002884078636, 'Total loss': 0.27996002884078636}
2022-12-31 12:37:42,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:42,083 INFO:     Epoch: 46
2022-12-31 12:37:43,688 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4086285168925921, 'Total loss': 0.4086285168925921} | train loss {'Reaction outcome loss': 0.2861284381118569, 'Total loss': 0.2861284381118569}
2022-12-31 12:37:43,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:43,689 INFO:     Epoch: 47
2022-12-31 12:37:45,286 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3925884107748667, 'Total loss': 0.3925884107748667} | train loss {'Reaction outcome loss': 0.2780734033724905, 'Total loss': 0.2780734033724905}
2022-12-31 12:37:45,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:45,286 INFO:     Epoch: 48
2022-12-31 12:37:46,879 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3956451386213303, 'Total loss': 0.3956451386213303} | train loss {'Reaction outcome loss': 0.27555699189649013, 'Total loss': 0.27555699189649013}
2022-12-31 12:37:46,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:46,879 INFO:     Epoch: 49
2022-12-31 12:37:48,452 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41607235570748646, 'Total loss': 0.41607235570748646} | train loss {'Reaction outcome loss': 0.26887145720041583, 'Total loss': 0.26887145720041583}
2022-12-31 12:37:48,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:48,453 INFO:     Epoch: 50
2022-12-31 12:37:50,065 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3959498306115468, 'Total loss': 0.3959498306115468} | train loss {'Reaction outcome loss': 0.26913877611259257, 'Total loss': 0.26913877611259257}
2022-12-31 12:37:50,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:50,066 INFO:     Epoch: 51
2022-12-31 12:37:51,714 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41590641538302103, 'Total loss': 0.41590641538302103} | train loss {'Reaction outcome loss': 0.26612833646690326, 'Total loss': 0.26612833646690326}
2022-12-31 12:37:51,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:51,714 INFO:     Epoch: 52
2022-12-31 12:37:53,363 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39233709971110026, 'Total loss': 0.39233709971110026} | train loss {'Reaction outcome loss': 0.2670388975228271, 'Total loss': 0.2670388975228271}
2022-12-31 12:37:53,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:53,363 INFO:     Epoch: 53
2022-12-31 12:37:55,010 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3713218539953232, 'Total loss': 0.3713218539953232} | train loss {'Reaction outcome loss': 0.261910021644983, 'Total loss': 0.261910021644983}
2022-12-31 12:37:55,010 INFO:     Found new best model at epoch 53
2022-12-31 12:37:55,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:55,011 INFO:     Epoch: 54
2022-12-31 12:37:56,561 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.391303018728892, 'Total loss': 0.391303018728892} | train loss {'Reaction outcome loss': 0.2654457044291453, 'Total loss': 0.2654457044291453}
2022-12-31 12:37:56,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:56,561 INFO:     Epoch: 55
2022-12-31 12:37:58,207 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4132470597823461, 'Total loss': 0.4132470597823461} | train loss {'Reaction outcome loss': 0.26423131296560715, 'Total loss': 0.26423131296560715}
2022-12-31 12:37:58,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:58,208 INFO:     Epoch: 56
2022-12-31 12:37:59,842 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3717304805914561, 'Total loss': 0.3717304805914561} | train loss {'Reaction outcome loss': 0.26212534506934404, 'Total loss': 0.26212534506934404}
2022-12-31 12:37:59,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:37:59,843 INFO:     Epoch: 57
2022-12-31 12:38:01,440 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3901772409677505, 'Total loss': 0.3901772409677505} | train loss {'Reaction outcome loss': 0.2634409116649062, 'Total loss': 0.2634409116649062}
2022-12-31 12:38:01,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:01,440 INFO:     Epoch: 58
2022-12-31 12:38:03,040 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3845928817987442, 'Total loss': 0.3845928817987442} | train loss {'Reaction outcome loss': 0.2545386284154697, 'Total loss': 0.2545386284154697}
2022-12-31 12:38:03,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:03,041 INFO:     Epoch: 59
2022-12-31 12:38:04,642 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4025399009386698, 'Total loss': 0.4025399009386698} | train loss {'Reaction outcome loss': 0.25132846896176353, 'Total loss': 0.25132846896176353}
2022-12-31 12:38:04,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:04,642 INFO:     Epoch: 60
2022-12-31 12:38:06,212 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3801766484975815, 'Total loss': 0.3801766484975815} | train loss {'Reaction outcome loss': 0.2561465649029417, 'Total loss': 0.2561465649029417}
2022-12-31 12:38:06,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:06,213 INFO:     Epoch: 61
2022-12-31 12:38:07,816 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4106505716840426, 'Total loss': 0.4106505716840426} | train loss {'Reaction outcome loss': 0.2508733726385301, 'Total loss': 0.2508733726385301}
2022-12-31 12:38:07,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:07,816 INFO:     Epoch: 62
2022-12-31 12:38:09,431 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3807368328173955, 'Total loss': 0.3807368328173955} | train loss {'Reaction outcome loss': 0.2519030306678619, 'Total loss': 0.2519030306678619}
2022-12-31 12:38:09,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:09,432 INFO:     Epoch: 63
2022-12-31 12:38:11,053 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41559695104757943, 'Total loss': 0.41559695104757943} | train loss {'Reaction outcome loss': 0.25166030504135756, 'Total loss': 0.25166030504135756}
2022-12-31 12:38:11,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:11,053 INFO:     Epoch: 64
2022-12-31 12:38:12,654 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3643996755282084, 'Total loss': 0.3643996755282084} | train loss {'Reaction outcome loss': 0.2463922936904387, 'Total loss': 0.2463922936904387}
2022-12-31 12:38:12,654 INFO:     Found new best model at epoch 64
2022-12-31 12:38:12,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:12,655 INFO:     Epoch: 65
2022-12-31 12:38:14,240 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4070803225040436, 'Total loss': 0.4070803225040436} | train loss {'Reaction outcome loss': 0.24958089270703768, 'Total loss': 0.24958089270703768}
2022-12-31 12:38:14,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:14,241 INFO:     Epoch: 66
2022-12-31 12:38:15,858 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40854588051637014, 'Total loss': 0.40854588051637014} | train loss {'Reaction outcome loss': 0.24040885076579385, 'Total loss': 0.24040885076579385}
2022-12-31 12:38:15,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:15,858 INFO:     Epoch: 67
2022-12-31 12:38:17,511 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38383765518665314, 'Total loss': 0.38383765518665314} | train loss {'Reaction outcome loss': 0.24498212582220996, 'Total loss': 0.24498212582220996}
2022-12-31 12:38:17,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:17,511 INFO:     Epoch: 68
2022-12-31 12:38:19,164 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4124047895272573, 'Total loss': 0.4124047895272573} | train loss {'Reaction outcome loss': 0.2458648694420818, 'Total loss': 0.2458648694420818}
2022-12-31 12:38:19,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:19,164 INFO:     Epoch: 69
2022-12-31 12:38:20,807 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40754347791274387, 'Total loss': 0.40754347791274387} | train loss {'Reaction outcome loss': 0.244982800371673, 'Total loss': 0.244982800371673}
2022-12-31 12:38:20,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:20,808 INFO:     Epoch: 70
2022-12-31 12:38:22,408 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3895407825708389, 'Total loss': 0.3895407825708389} | train loss {'Reaction outcome loss': 0.23847621003587316, 'Total loss': 0.23847621003587316}
2022-12-31 12:38:22,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:22,409 INFO:     Epoch: 71
2022-12-31 12:38:23,973 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3696996718645096, 'Total loss': 0.3696996718645096} | train loss {'Reaction outcome loss': 0.23380350778355216, 'Total loss': 0.23380350778355216}
2022-12-31 12:38:23,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:23,973 INFO:     Epoch: 72
2022-12-31 12:38:25,577 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4044991989930471, 'Total loss': 0.4044991989930471} | train loss {'Reaction outcome loss': 0.2360498110090729, 'Total loss': 0.2360498110090729}
2022-12-31 12:38:25,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:25,577 INFO:     Epoch: 73
2022-12-31 12:38:27,179 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4278378744920095, 'Total loss': 0.4278378744920095} | train loss {'Reaction outcome loss': 0.23602323566502245, 'Total loss': 0.23602323566502245}
2022-12-31 12:38:27,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:27,179 INFO:     Epoch: 74
2022-12-31 12:38:28,782 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36073680892586707, 'Total loss': 0.36073680892586707} | train loss {'Reaction outcome loss': 0.22643811745147635, 'Total loss': 0.22643811745147635}
2022-12-31 12:38:28,782 INFO:     Found new best model at epoch 74
2022-12-31 12:38:28,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:28,783 INFO:     Epoch: 75
2022-12-31 12:38:30,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3895162428418795, 'Total loss': 0.3895162428418795} | train loss {'Reaction outcome loss': 0.2374488738684976, 'Total loss': 0.2374488738684976}
2022-12-31 12:38:30,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:30,385 INFO:     Epoch: 76
2022-12-31 12:38:31,989 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38978363859156767, 'Total loss': 0.38978363859156767} | train loss {'Reaction outcome loss': 0.23136482602597153, 'Total loss': 0.23136482602597153}
2022-12-31 12:38:31,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:31,990 INFO:     Epoch: 77
2022-12-31 12:38:33,561 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3827911208073298, 'Total loss': 0.3827911208073298} | train loss {'Reaction outcome loss': 0.23185127001446093, 'Total loss': 0.23185127001446093}
2022-12-31 12:38:33,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:33,562 INFO:     Epoch: 78
2022-12-31 12:38:35,163 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4037708272536596, 'Total loss': 0.4037708272536596} | train loss {'Reaction outcome loss': 0.23165666658676018, 'Total loss': 0.23165666658676018}
2022-12-31 12:38:35,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:35,164 INFO:     Epoch: 79
2022-12-31 12:38:36,766 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4028017898400625, 'Total loss': 0.4028017898400625} | train loss {'Reaction outcome loss': 0.22669003699926565, 'Total loss': 0.22669003699926565}
2022-12-31 12:38:36,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:36,766 INFO:     Epoch: 80
2022-12-31 12:38:38,369 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3815682123104731, 'Total loss': 0.3815682123104731} | train loss {'Reaction outcome loss': 0.22794337057080255, 'Total loss': 0.22794337057080255}
2022-12-31 12:38:38,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:38,369 INFO:     Epoch: 81
2022-12-31 12:38:39,972 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40308634837468466, 'Total loss': 0.40308634837468466} | train loss {'Reaction outcome loss': 0.22354865835530915, 'Total loss': 0.22354865835530915}
2022-12-31 12:38:39,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:39,972 INFO:     Epoch: 82
2022-12-31 12:38:41,562 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4090725223223368, 'Total loss': 0.4090725223223368} | train loss {'Reaction outcome loss': 0.22894003715393316, 'Total loss': 0.22894003715393316}
2022-12-31 12:38:41,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:41,563 INFO:     Epoch: 83
2022-12-31 12:38:43,189 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3601823647816976, 'Total loss': 0.3601823647816976} | train loss {'Reaction outcome loss': 0.22370836068706138, 'Total loss': 0.22370836068706138}
2022-12-31 12:38:43,189 INFO:     Found new best model at epoch 83
2022-12-31 12:38:43,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:43,190 INFO:     Epoch: 84
2022-12-31 12:38:44,814 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.34877369503180183, 'Total loss': 0.34877369503180183} | train loss {'Reaction outcome loss': 0.2169406211588287, 'Total loss': 0.2169406211588287}
2022-12-31 12:38:44,815 INFO:     Found new best model at epoch 84
2022-12-31 12:38:44,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:44,816 INFO:     Epoch: 85
2022-12-31 12:38:46,416 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3691074232260386, 'Total loss': 0.3691074232260386} | train loss {'Reaction outcome loss': 0.22367535074696923, 'Total loss': 0.22367535074696923}
2022-12-31 12:38:46,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:46,416 INFO:     Epoch: 86
2022-12-31 12:38:48,012 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.350520717104276, 'Total loss': 0.350520717104276} | train loss {'Reaction outcome loss': 0.2188628262357555, 'Total loss': 0.2188628262357555}
2022-12-31 12:38:48,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:48,012 INFO:     Epoch: 87
2022-12-31 12:38:49,651 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40470418880383174, 'Total loss': 0.40470418880383174} | train loss {'Reaction outcome loss': 0.21711878902040913, 'Total loss': 0.21711878902040913}
2022-12-31 12:38:49,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:49,651 INFO:     Epoch: 88
2022-12-31 12:38:51,229 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3581305096546809, 'Total loss': 0.3581305096546809} | train loss {'Reaction outcome loss': 0.21373523736413377, 'Total loss': 0.21373523736413377}
2022-12-31 12:38:51,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:51,230 INFO:     Epoch: 89
2022-12-31 12:38:52,879 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4058306306600571, 'Total loss': 0.4058306306600571} | train loss {'Reaction outcome loss': 0.22123383755122658, 'Total loss': 0.22123383755122658}
2022-12-31 12:38:52,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:52,879 INFO:     Epoch: 90
2022-12-31 12:38:54,520 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36066821167866386, 'Total loss': 0.36066821167866386} | train loss {'Reaction outcome loss': 0.21751070885246035, 'Total loss': 0.21751070885246035}
2022-12-31 12:38:54,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:54,521 INFO:     Epoch: 91
2022-12-31 12:38:56,171 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.402273494998614, 'Total loss': 0.402273494998614} | train loss {'Reaction outcome loss': 0.21481622928196062, 'Total loss': 0.21481622928196062}
2022-12-31 12:38:56,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:56,171 INFO:     Epoch: 92
2022-12-31 12:38:57,821 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3637571258159975, 'Total loss': 0.3637571258159975} | train loss {'Reaction outcome loss': 0.22342881182358212, 'Total loss': 0.22342881182358212}
2022-12-31 12:38:57,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:57,821 INFO:     Epoch: 93
2022-12-31 12:38:59,463 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40224090218544006, 'Total loss': 0.40224090218544006} | train loss {'Reaction outcome loss': 0.2150881848413579, 'Total loss': 0.2150881848413579}
2022-12-31 12:38:59,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:38:59,463 INFO:     Epoch: 94
2022-12-31 12:39:01,036 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3751430888970693, 'Total loss': 0.3751430888970693} | train loss {'Reaction outcome loss': 0.21653472411915334, 'Total loss': 0.21653472411915334}
2022-12-31 12:39:01,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:01,036 INFO:     Epoch: 95
2022-12-31 12:39:02,637 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3728223775823911, 'Total loss': 0.3728223775823911} | train loss {'Reaction outcome loss': 0.211009392752754, 'Total loss': 0.211009392752754}
2022-12-31 12:39:02,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:02,637 INFO:     Epoch: 96
2022-12-31 12:39:04,238 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37165442407131194, 'Total loss': 0.37165442407131194} | train loss {'Reaction outcome loss': 0.209406823620037, 'Total loss': 0.209406823620037}
2022-12-31 12:39:04,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:04,239 INFO:     Epoch: 97
2022-12-31 12:39:05,840 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36215632061163583, 'Total loss': 0.36215632061163583} | train loss {'Reaction outcome loss': 0.20631167669882522, 'Total loss': 0.20631167669882522}
2022-12-31 12:39:05,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:05,840 INFO:     Epoch: 98
2022-12-31 12:39:07,488 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4005897581577301, 'Total loss': 0.4005897581577301} | train loss {'Reaction outcome loss': 0.20920105034444672, 'Total loss': 0.20920105034444672}
2022-12-31 12:39:07,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:07,488 INFO:     Epoch: 99
2022-12-31 12:39:09,076 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4004151731729507, 'Total loss': 0.4004151731729507} | train loss {'Reaction outcome loss': 0.20367836387977548, 'Total loss': 0.20367836387977548}
2022-12-31 12:39:09,076 INFO:     Best model found after epoch 85 of 100.
2022-12-31 12:39:09,076 INFO:   Done with stage: TRAINING
2022-12-31 12:39:09,076 INFO:   Starting stage: EVALUATION
2022-12-31 12:39:09,209 INFO:   Done with stage: EVALUATION
2022-12-31 12:39:09,217 INFO:   Leaving out SEQ value Fold_0
2022-12-31 12:39:09,230 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 12:39:09,230 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:39:09,870 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:39:09,870 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:39:09,937 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:39:09,937 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:39:09,938 INFO:     No hyperparam tuning for this model
2022-12-31 12:39:09,938 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:39:09,938 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:39:09,938 INFO:     None feature selector for col prot
2022-12-31 12:39:09,938 INFO:     None feature selector for col prot
2022-12-31 12:39:09,939 INFO:     None feature selector for col prot
2022-12-31 12:39:09,939 INFO:     None feature selector for col chem
2022-12-31 12:39:09,939 INFO:     None feature selector for col chem
2022-12-31 12:39:09,939 INFO:     None feature selector for col chem
2022-12-31 12:39:09,939 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:39:09,939 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:39:09,941 INFO:     Number of params in model 223921
2022-12-31 12:39:09,944 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:39:09,944 INFO:   Starting stage: TRAINING
2022-12-31 12:39:09,990 INFO:     Val loss before train {'Reaction outcome loss': 1.0571426272392273, 'Total loss': 1.0571426272392273}
2022-12-31 12:39:09,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:09,990 INFO:     Epoch: 0
2022-12-31 12:39:11,589 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.719079593817393, 'Total loss': 0.719079593817393} | train loss {'Reaction outcome loss': 0.8254080413680374, 'Total loss': 0.8254080413680374}
2022-12-31 12:39:11,589 INFO:     Found new best model at epoch 0
2022-12-31 12:39:11,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:11,590 INFO:     Epoch: 1
2022-12-31 12:39:13,187 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6136437098185221, 'Total loss': 0.6136437098185221} | train loss {'Reaction outcome loss': 0.6059457333314986, 'Total loss': 0.6059457333314986}
2022-12-31 12:39:13,188 INFO:     Found new best model at epoch 1
2022-12-31 12:39:13,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:13,188 INFO:     Epoch: 2
2022-12-31 12:39:14,831 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5715355416138966, 'Total loss': 0.5715355416138966} | train loss {'Reaction outcome loss': 0.533517334760327, 'Total loss': 0.533517334760327}
2022-12-31 12:39:14,831 INFO:     Found new best model at epoch 2
2022-12-31 12:39:14,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:14,832 INFO:     Epoch: 3
2022-12-31 12:39:16,462 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5273691515127817, 'Total loss': 0.5273691515127817} | train loss {'Reaction outcome loss': 0.5039879358731784, 'Total loss': 0.5039879358731784}
2022-12-31 12:39:16,463 INFO:     Found new best model at epoch 3
2022-12-31 12:39:16,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:16,464 INFO:     Epoch: 4
2022-12-31 12:39:18,023 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5393872519334157, 'Total loss': 0.5393872519334157} | train loss {'Reaction outcome loss': 0.4845240033221441, 'Total loss': 0.4845240033221441}
2022-12-31 12:39:18,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:18,023 INFO:     Epoch: 5
2022-12-31 12:39:19,613 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5216301143169403, 'Total loss': 0.5216301143169403} | train loss {'Reaction outcome loss': 0.4713001644764191, 'Total loss': 0.4713001644764191}
2022-12-31 12:39:19,613 INFO:     Found new best model at epoch 5
2022-12-31 12:39:19,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:19,614 INFO:     Epoch: 6
2022-12-31 12:39:21,209 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5171063204606374, 'Total loss': 0.5171063204606374} | train loss {'Reaction outcome loss': 0.46696820101895176, 'Total loss': 0.46696820101895176}
2022-12-31 12:39:21,209 INFO:     Found new best model at epoch 6
2022-12-31 12:39:21,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:21,210 INFO:     Epoch: 7
2022-12-31 12:39:22,806 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5576485494772593, 'Total loss': 0.5576485494772593} | train loss {'Reaction outcome loss': 0.45493841875385455, 'Total loss': 0.45493841875385455}
2022-12-31 12:39:22,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:22,807 INFO:     Epoch: 8
2022-12-31 12:39:24,402 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5209452430407207, 'Total loss': 0.5209452430407207} | train loss {'Reaction outcome loss': 0.45241876383185825, 'Total loss': 0.45241876383185825}
2022-12-31 12:39:24,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:24,402 INFO:     Epoch: 9
2022-12-31 12:39:25,998 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5138825808962186, 'Total loss': 0.5138825808962186} | train loss {'Reaction outcome loss': 0.44635245826218156, 'Total loss': 0.44635245826218156}
2022-12-31 12:39:25,998 INFO:     Found new best model at epoch 9
2022-12-31 12:39:25,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:25,999 INFO:     Epoch: 10
2022-12-31 12:39:27,560 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5336141467094422, 'Total loss': 0.5336141467094422} | train loss {'Reaction outcome loss': 0.44172618117852086, 'Total loss': 0.44172618117852086}
2022-12-31 12:39:27,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:27,560 INFO:     Epoch: 11
2022-12-31 12:39:29,154 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48851509590943654, 'Total loss': 0.48851509590943654} | train loss {'Reaction outcome loss': 0.42611118796325864, 'Total loss': 0.42611118796325864}
2022-12-31 12:39:29,154 INFO:     Found new best model at epoch 11
2022-12-31 12:39:29,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:29,155 INFO:     Epoch: 12
2022-12-31 12:39:30,750 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4945073703924815, 'Total loss': 0.4945073703924815} | train loss {'Reaction outcome loss': 0.4234879439894533, 'Total loss': 0.4234879439894533}
2022-12-31 12:39:30,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:30,750 INFO:     Epoch: 13
2022-12-31 12:39:32,346 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5047219693660736, 'Total loss': 0.5047219693660736} | train loss {'Reaction outcome loss': 0.41797051540552044, 'Total loss': 0.41797051540552044}
2022-12-31 12:39:32,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:32,346 INFO:     Epoch: 14
2022-12-31 12:39:33,942 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47001981536547344, 'Total loss': 0.47001981536547344} | train loss {'Reaction outcome loss': 0.41256987153392133, 'Total loss': 0.41256987153392133}
2022-12-31 12:39:33,942 INFO:     Found new best model at epoch 14
2022-12-31 12:39:33,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:33,943 INFO:     Epoch: 15
2022-12-31 12:39:35,536 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4922858218352, 'Total loss': 0.4922858218352} | train loss {'Reaction outcome loss': 0.40668641846804393, 'Total loss': 0.40668641846804393}
2022-12-31 12:39:35,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:35,537 INFO:     Epoch: 16
2022-12-31 12:39:37,124 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4697091579437256, 'Total loss': 0.4697091579437256} | train loss {'Reaction outcome loss': 0.40225024150186406, 'Total loss': 0.40225024150186406}
2022-12-31 12:39:37,124 INFO:     Found new best model at epoch 16
2022-12-31 12:39:37,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:37,125 INFO:     Epoch: 17
2022-12-31 12:39:38,758 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5057131747404734, 'Total loss': 0.5057131747404734} | train loss {'Reaction outcome loss': 0.3999745067440983, 'Total loss': 0.3999745067440983}
2022-12-31 12:39:38,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:38,758 INFO:     Epoch: 18
2022-12-31 12:39:40,413 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4765479495127996, 'Total loss': 0.4765479495127996} | train loss {'Reaction outcome loss': 0.3873448499065616, 'Total loss': 0.3873448499065616}
2022-12-31 12:39:40,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:40,413 INFO:     Epoch: 19
2022-12-31 12:39:42,053 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49507858554522194, 'Total loss': 0.49507858554522194} | train loss {'Reaction outcome loss': 0.3894947885702818, 'Total loss': 0.3894947885702818}
2022-12-31 12:39:42,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:42,053 INFO:     Epoch: 20
2022-12-31 12:39:43,710 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4981007238229116, 'Total loss': 0.4981007238229116} | train loss {'Reaction outcome loss': 0.37958108871192725, 'Total loss': 0.37958108871192725}
2022-12-31 12:39:43,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:43,711 INFO:     Epoch: 21
2022-12-31 12:39:45,297 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41878708998362224, 'Total loss': 0.41878708998362224} | train loss {'Reaction outcome loss': 0.3774056494399741, 'Total loss': 0.3774056494399741}
2022-12-31 12:39:45,297 INFO:     Found new best model at epoch 21
2022-12-31 12:39:45,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:45,298 INFO:     Epoch: 22
2022-12-31 12:39:46,922 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45969104766845703, 'Total loss': 0.45969104766845703} | train loss {'Reaction outcome loss': 0.36651761316943354, 'Total loss': 0.36651761316943354}
2022-12-31 12:39:46,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:46,922 INFO:     Epoch: 23
2022-12-31 12:39:48,519 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4506910969813665, 'Total loss': 0.4506910969813665} | train loss {'Reaction outcome loss': 0.3659753626410341, 'Total loss': 0.3659753626410341}
2022-12-31 12:39:48,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:48,520 INFO:     Epoch: 24
2022-12-31 12:39:50,117 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4937663475672404, 'Total loss': 0.4937663475672404} | train loss {'Reaction outcome loss': 0.35656657055593455, 'Total loss': 0.35656657055593455}
2022-12-31 12:39:50,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:50,117 INFO:     Epoch: 25
2022-12-31 12:39:51,714 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5052392313877742, 'Total loss': 0.5052392313877742} | train loss {'Reaction outcome loss': 0.3555526931193613, 'Total loss': 0.3555526931193613}
2022-12-31 12:39:51,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:51,716 INFO:     Epoch: 26
2022-12-31 12:39:53,312 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44113883723815284, 'Total loss': 0.44113883723815284} | train loss {'Reaction outcome loss': 0.3475371403790219, 'Total loss': 0.3475371403790219}
2022-12-31 12:39:53,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:53,312 INFO:     Epoch: 27
2022-12-31 12:39:54,878 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4858356028795242, 'Total loss': 0.4858356028795242} | train loss {'Reaction outcome loss': 0.3467852189154415, 'Total loss': 0.3467852189154415}
2022-12-31 12:39:54,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:54,879 INFO:     Epoch: 28
2022-12-31 12:39:56,478 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4301945149898529, 'Total loss': 0.4301945149898529} | train loss {'Reaction outcome loss': 0.33525366966541, 'Total loss': 0.33525366966541}
2022-12-31 12:39:56,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:56,478 INFO:     Epoch: 29
2022-12-31 12:39:58,079 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42116445759311316, 'Total loss': 0.42116445759311316} | train loss {'Reaction outcome loss': 0.3326909828337503, 'Total loss': 0.3326909828337503}
2022-12-31 12:39:58,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:58,080 INFO:     Epoch: 30
2022-12-31 12:39:59,678 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49055466850598656, 'Total loss': 0.49055466850598656} | train loss {'Reaction outcome loss': 0.32793247879861476, 'Total loss': 0.32793247879861476}
2022-12-31 12:39:59,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:39:59,678 INFO:     Epoch: 31
2022-12-31 12:40:01,277 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4699927091598511, 'Total loss': 0.4699927091598511} | train loss {'Reaction outcome loss': 0.327391627234417, 'Total loss': 0.327391627234417}
2022-12-31 12:40:01,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:01,278 INFO:     Epoch: 32
2022-12-31 12:40:02,871 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43979663252830503, 'Total loss': 0.43979663252830503} | train loss {'Reaction outcome loss': 0.3214348429070288, 'Total loss': 0.3214348429070288}
2022-12-31 12:40:02,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:02,871 INFO:     Epoch: 33
2022-12-31 12:40:04,463 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4516419013341268, 'Total loss': 0.4516419013341268} | train loss {'Reaction outcome loss': 0.31357779401617175, 'Total loss': 0.31357779401617175}
2022-12-31 12:40:04,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:04,464 INFO:     Epoch: 34
2022-12-31 12:40:06,122 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.431050048271815, 'Total loss': 0.431050048271815} | train loss {'Reaction outcome loss': 0.3152523732338196, 'Total loss': 0.3152523732338196}
2022-12-31 12:40:06,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:06,122 INFO:     Epoch: 35
2022-12-31 12:40:07,725 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4735784669717153, 'Total loss': 0.4735784669717153} | train loss {'Reaction outcome loss': 0.31329016644002755, 'Total loss': 0.31329016644002755}
2022-12-31 12:40:07,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:07,725 INFO:     Epoch: 36
2022-12-31 12:40:09,323 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40435974995295204, 'Total loss': 0.40435974995295204} | train loss {'Reaction outcome loss': 0.30768758157479675, 'Total loss': 0.30768758157479675}
2022-12-31 12:40:09,323 INFO:     Found new best model at epoch 36
2022-12-31 12:40:09,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:09,324 INFO:     Epoch: 37
2022-12-31 12:40:10,922 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46905714869499204, 'Total loss': 0.46905714869499204} | train loss {'Reaction outcome loss': 0.3050113523399437, 'Total loss': 0.3050113523399437}
2022-12-31 12:40:10,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:10,923 INFO:     Epoch: 38
2022-12-31 12:40:12,498 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4065545459588369, 'Total loss': 0.4065545459588369} | train loss {'Reaction outcome loss': 0.3005056013609027, 'Total loss': 0.3005056013609027}
2022-12-31 12:40:12,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:12,498 INFO:     Epoch: 39
2022-12-31 12:40:14,077 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4398172984520594, 'Total loss': 0.4398172984520594} | train loss {'Reaction outcome loss': 0.29886149705111326, 'Total loss': 0.29886149705111326}
2022-12-31 12:40:14,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:14,077 INFO:     Epoch: 40
2022-12-31 12:40:15,676 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4097502628962199, 'Total loss': 0.4097502628962199} | train loss {'Reaction outcome loss': 0.2953943357915505, 'Total loss': 0.2953943357915505}
2022-12-31 12:40:15,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:15,676 INFO:     Epoch: 41
2022-12-31 12:40:17,274 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42960187544425327, 'Total loss': 0.42960187544425327} | train loss {'Reaction outcome loss': 0.2917283934646801, 'Total loss': 0.2917283934646801}
2022-12-31 12:40:17,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:17,274 INFO:     Epoch: 42
2022-12-31 12:40:18,871 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39429103831450146, 'Total loss': 0.39429103831450146} | train loss {'Reaction outcome loss': 0.2884790778054341, 'Total loss': 0.2884790778054341}
2022-12-31 12:40:18,871 INFO:     Found new best model at epoch 42
2022-12-31 12:40:18,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:18,872 INFO:     Epoch: 43
2022-12-31 12:40:20,470 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48731780250867207, 'Total loss': 0.48731780250867207} | train loss {'Reaction outcome loss': 0.28274618834257126, 'Total loss': 0.28274618834257126}
2022-12-31 12:40:20,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:20,470 INFO:     Epoch: 44
2022-12-31 12:40:22,035 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42670393983523053, 'Total loss': 0.42670393983523053} | train loss {'Reaction outcome loss': 0.2843420162196561, 'Total loss': 0.2843420162196561}
2022-12-31 12:40:22,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:22,036 INFO:     Epoch: 45
2022-12-31 12:40:23,620 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45440447330474854, 'Total loss': 0.45440447330474854} | train loss {'Reaction outcome loss': 0.27513848146894476, 'Total loss': 0.27513848146894476}
2022-12-31 12:40:23,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:23,621 INFO:     Epoch: 46
2022-12-31 12:40:25,218 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37070603569348654, 'Total loss': 0.37070603569348654} | train loss {'Reaction outcome loss': 0.2710291240637228, 'Total loss': 0.2710291240637228}
2022-12-31 12:40:25,219 INFO:     Found new best model at epoch 46
2022-12-31 12:40:25,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:25,220 INFO:     Epoch: 47
2022-12-31 12:40:26,815 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4115979477763176, 'Total loss': 0.4115979477763176} | train loss {'Reaction outcome loss': 0.27011348473610897, 'Total loss': 0.27011348473610897}
2022-12-31 12:40:26,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:26,815 INFO:     Epoch: 48
2022-12-31 12:40:28,413 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4040297249952952, 'Total loss': 0.4040297249952952} | train loss {'Reaction outcome loss': 0.2715551591727323, 'Total loss': 0.2715551591727323}
2022-12-31 12:40:28,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:28,413 INFO:     Epoch: 49
2022-12-31 12:40:30,005 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44231734971205394, 'Total loss': 0.44231734971205394} | train loss {'Reaction outcome loss': 0.2687624392437411, 'Total loss': 0.2687624392437411}
2022-12-31 12:40:30,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:30,005 INFO:     Epoch: 50
2022-12-31 12:40:31,601 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44489537477493285, 'Total loss': 0.44489537477493285} | train loss {'Reaction outcome loss': 0.26649553448835134, 'Total loss': 0.26649553448835134}
2022-12-31 12:40:31,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:31,601 INFO:     Epoch: 51
2022-12-31 12:40:33,213 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3930809626976649, 'Total loss': 0.3930809626976649} | train loss {'Reaction outcome loss': 0.26069100965292025, 'Total loss': 0.26069100965292025}
2022-12-31 12:40:33,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:33,213 INFO:     Epoch: 52
2022-12-31 12:40:34,813 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41767398913701376, 'Total loss': 0.41767398913701376} | train loss {'Reaction outcome loss': 0.2534524983702562, 'Total loss': 0.2534524983702562}
2022-12-31 12:40:34,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:34,814 INFO:     Epoch: 53
2022-12-31 12:40:36,413 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42162317832310997, 'Total loss': 0.42162317832310997} | train loss {'Reaction outcome loss': 0.25906165738354675, 'Total loss': 0.25906165738354675}
2022-12-31 12:40:36,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:36,413 INFO:     Epoch: 54
2022-12-31 12:40:38,013 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4445486863454183, 'Total loss': 0.4445486863454183} | train loss {'Reaction outcome loss': 0.2523066020355775, 'Total loss': 0.2523066020355775}
2022-12-31 12:40:38,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:38,013 INFO:     Epoch: 55
2022-12-31 12:40:39,598 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45386975606282554, 'Total loss': 0.45386975606282554} | train loss {'Reaction outcome loss': 0.2586504335041011, 'Total loss': 0.2586504335041011}
2022-12-31 12:40:39,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:39,598 INFO:     Epoch: 56
2022-12-31 12:40:41,201 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43768258194128673, 'Total loss': 0.43768258194128673} | train loss {'Reaction outcome loss': 0.2689482609198971, 'Total loss': 0.2689482609198971}
2022-12-31 12:40:41,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:41,202 INFO:     Epoch: 57
2022-12-31 12:40:42,799 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45062835812568663, 'Total loss': 0.45062835812568663} | train loss {'Reaction outcome loss': 0.2523250099264713, 'Total loss': 0.2523250099264713}
2022-12-31 12:40:42,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:42,800 INFO:     Epoch: 58
2022-12-31 12:40:44,397 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43492129544417063, 'Total loss': 0.43492129544417063} | train loss {'Reaction outcome loss': 0.25050210902269504, 'Total loss': 0.25050210902269504}
2022-12-31 12:40:44,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:44,397 INFO:     Epoch: 59
2022-12-31 12:40:46,011 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3963471496477723, 'Total loss': 0.3963471496477723} | train loss {'Reaction outcome loss': 0.24481439147649448, 'Total loss': 0.24481439147649448}
2022-12-31 12:40:46,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:46,012 INFO:     Epoch: 60
2022-12-31 12:40:47,637 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3888552521665891, 'Total loss': 0.3888552521665891} | train loss {'Reaction outcome loss': 0.24630168484244155, 'Total loss': 0.24630168484244155}
2022-12-31 12:40:47,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:47,638 INFO:     Epoch: 61
2022-12-31 12:40:49,208 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42301557858784994, 'Total loss': 0.42301557858784994} | train loss {'Reaction outcome loss': 0.24702637748717715, 'Total loss': 0.24702637748717715}
2022-12-31 12:40:49,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:49,209 INFO:     Epoch: 62
2022-12-31 12:40:50,863 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43276599297920865, 'Total loss': 0.43276599297920865} | train loss {'Reaction outcome loss': 0.24605648701280464, 'Total loss': 0.24605648701280464}
2022-12-31 12:40:50,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:50,863 INFO:     Epoch: 63
2022-12-31 12:40:52,432 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3527154753605525, 'Total loss': 0.3527154753605525} | train loss {'Reaction outcome loss': 0.24286374311907824, 'Total loss': 0.24286374311907824}
2022-12-31 12:40:52,432 INFO:     Found new best model at epoch 63
2022-12-31 12:40:52,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:52,433 INFO:     Epoch: 64
2022-12-31 12:40:54,053 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43400521179040275, 'Total loss': 0.43400521179040275} | train loss {'Reaction outcome loss': 0.24998684479230707, 'Total loss': 0.24998684479230707}
2022-12-31 12:40:54,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:54,054 INFO:     Epoch: 65
2022-12-31 12:40:55,678 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4352408289909363, 'Total loss': 0.4352408289909363} | train loss {'Reaction outcome loss': 0.23930353306970753, 'Total loss': 0.23930353306970753}
2022-12-31 12:40:55,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:55,678 INFO:     Epoch: 66
2022-12-31 12:40:57,276 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4420117015639941, 'Total loss': 0.4420117015639941} | train loss {'Reaction outcome loss': 0.2418984646871413, 'Total loss': 0.2418984646871413}
2022-12-31 12:40:57,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:57,276 INFO:     Epoch: 67
2022-12-31 12:40:58,833 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4567355881134669, 'Total loss': 0.4567355881134669} | train loss {'Reaction outcome loss': 0.22935593990615874, 'Total loss': 0.22935593990615874}
2022-12-31 12:40:58,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:40:58,834 INFO:     Epoch: 68
2022-12-31 12:41:00,462 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38938577895363174, 'Total loss': 0.38938577895363174} | train loss {'Reaction outcome loss': 0.2298587086992577, 'Total loss': 0.2298587086992577}
2022-12-31 12:41:00,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:00,463 INFO:     Epoch: 69
2022-12-31 12:41:02,075 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40402848124504087, 'Total loss': 0.40402848124504087} | train loss {'Reaction outcome loss': 0.23188734376605177, 'Total loss': 0.23188734376605177}
2022-12-31 12:41:02,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:02,076 INFO:     Epoch: 70
2022-12-31 12:41:03,677 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39961795806884765, 'Total loss': 0.39961795806884765} | train loss {'Reaction outcome loss': 0.23105677091704183, 'Total loss': 0.23105677091704183}
2022-12-31 12:41:03,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:03,677 INFO:     Epoch: 71
2022-12-31 12:41:05,311 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4039831096927325, 'Total loss': 0.4039831096927325} | train loss {'Reaction outcome loss': 0.22524766318991288, 'Total loss': 0.22524766318991288}
2022-12-31 12:41:05,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:05,312 INFO:     Epoch: 72
2022-12-31 12:41:06,772 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42731715043385826, 'Total loss': 0.42731715043385826} | train loss {'Reaction outcome loss': 0.22848597961740616, 'Total loss': 0.22848597961740616}
2022-12-31 12:41:06,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:06,772 INFO:     Epoch: 73
2022-12-31 12:41:07,833 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3992157717545827, 'Total loss': 0.3992157717545827} | train loss {'Reaction outcome loss': 0.22711806472786616, 'Total loss': 0.22711806472786616}
2022-12-31 12:41:07,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:07,833 INFO:     Epoch: 74
2022-12-31 12:41:08,889 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4027114342277249, 'Total loss': 0.4027114342277249} | train loss {'Reaction outcome loss': 0.23432127662658037, 'Total loss': 0.23432127662658037}
2022-12-31 12:41:08,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:08,889 INFO:     Epoch: 75
2022-12-31 12:41:09,945 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4410498480002085, 'Total loss': 0.4410498480002085} | train loss {'Reaction outcome loss': 0.22780675876326176, 'Total loss': 0.22780675876326176}
2022-12-31 12:41:09,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:09,945 INFO:     Epoch: 76
2022-12-31 12:41:11,014 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4592481732368469, 'Total loss': 0.4592481732368469} | train loss {'Reaction outcome loss': 0.22495950121200564, 'Total loss': 0.22495950121200564}
2022-12-31 12:41:11,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:11,014 INFO:     Epoch: 77
2022-12-31 12:41:12,602 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36620827466249467, 'Total loss': 0.36620827466249467} | train loss {'Reaction outcome loss': 0.22616073982483084, 'Total loss': 0.22616073982483084}
2022-12-31 12:41:12,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:12,603 INFO:     Epoch: 78
2022-12-31 12:41:14,181 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4174671192963918, 'Total loss': 0.4174671192963918} | train loss {'Reaction outcome loss': 0.23159055387935576, 'Total loss': 0.23159055387935576}
2022-12-31 12:41:14,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:14,181 INFO:     Epoch: 79
2022-12-31 12:41:15,781 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3941460738579432, 'Total loss': 0.3941460738579432} | train loss {'Reaction outcome loss': 0.22730397507411876, 'Total loss': 0.22730397507411876}
2022-12-31 12:41:15,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:15,781 INFO:     Epoch: 80
2022-12-31 12:41:17,372 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38542450666427613, 'Total loss': 0.38542450666427613} | train loss {'Reaction outcome loss': 0.22540013630611774, 'Total loss': 0.22540013630611774}
2022-12-31 12:41:17,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:17,372 INFO:     Epoch: 81
2022-12-31 12:41:18,959 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4079065283139547, 'Total loss': 0.4079065283139547} | train loss {'Reaction outcome loss': 0.21739011723889318, 'Total loss': 0.21739011723889318}
2022-12-31 12:41:18,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:18,960 INFO:     Epoch: 82
2022-12-31 12:41:20,535 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35396060918768246, 'Total loss': 0.35396060918768246} | train loss {'Reaction outcome loss': 0.22291327101748176, 'Total loss': 0.22291327101748176}
2022-12-31 12:41:20,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:20,535 INFO:     Epoch: 83
2022-12-31 12:41:22,153 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3835545778274536, 'Total loss': 0.3835545778274536} | train loss {'Reaction outcome loss': 0.2144549637828227, 'Total loss': 0.2144549637828227}
2022-12-31 12:41:22,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:22,153 INFO:     Epoch: 84
2022-12-31 12:41:23,726 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3898733923832575, 'Total loss': 0.3898733923832575} | train loss {'Reaction outcome loss': 0.21728444904525637, 'Total loss': 0.21728444904525637}
2022-12-31 12:41:23,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:23,727 INFO:     Epoch: 85
2022-12-31 12:41:25,320 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4282569577296575, 'Total loss': 0.4282569577296575} | train loss {'Reaction outcome loss': 0.21567602436511946, 'Total loss': 0.21567602436511946}
2022-12-31 12:41:25,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:25,320 INFO:     Epoch: 86
2022-12-31 12:41:26,914 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4215909441312154, 'Total loss': 0.4215909441312154} | train loss {'Reaction outcome loss': 0.2121442971143858, 'Total loss': 0.2121442971143858}
2022-12-31 12:41:26,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:26,914 INFO:     Epoch: 87
2022-12-31 12:41:28,506 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40283538003762565, 'Total loss': 0.40283538003762565} | train loss {'Reaction outcome loss': 0.22096007558152134, 'Total loss': 0.22096007558152134}
2022-12-31 12:41:28,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:28,507 INFO:     Epoch: 88
2022-12-31 12:41:30,100 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4256353974342346, 'Total loss': 0.4256353974342346} | train loss {'Reaction outcome loss': 0.21597004748348678, 'Total loss': 0.21597004748348678}
2022-12-31 12:41:30,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:30,100 INFO:     Epoch: 89
2022-12-31 12:41:31,714 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40093780954678854, 'Total loss': 0.40093780954678854} | train loss {'Reaction outcome loss': 0.21075124372711113, 'Total loss': 0.21075124372711113}
2022-12-31 12:41:31,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:31,714 INFO:     Epoch: 90
2022-12-31 12:41:33,298 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3981845289468765, 'Total loss': 0.3981845289468765} | train loss {'Reaction outcome loss': 0.20885196049789806, 'Total loss': 0.20885196049789806}
2022-12-31 12:41:33,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:33,298 INFO:     Epoch: 91
2022-12-31 12:41:34,897 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4253334204355876, 'Total loss': 0.4253334204355876} | train loss {'Reaction outcome loss': 0.21030714800206077, 'Total loss': 0.21030714800206077}
2022-12-31 12:41:34,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:34,898 INFO:     Epoch: 92
2022-12-31 12:41:36,495 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4080841340124607, 'Total loss': 0.4080841340124607} | train loss {'Reaction outcome loss': 0.21079496962219585, 'Total loss': 0.21079496962219585}
2022-12-31 12:41:36,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:36,496 INFO:     Epoch: 93
2022-12-31 12:41:38,087 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4141926780343056, 'Total loss': 0.4141926780343056} | train loss {'Reaction outcome loss': 0.20812802877782027, 'Total loss': 0.20812802877782027}
2022-12-31 12:41:38,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:38,087 INFO:     Epoch: 94
2022-12-31 12:41:39,674 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42250125408172606, 'Total loss': 0.42250125408172606} | train loss {'Reaction outcome loss': 0.21232138954157576, 'Total loss': 0.21232138954157576}
2022-12-31 12:41:39,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:39,674 INFO:     Epoch: 95
2022-12-31 12:41:41,248 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3909580444296201, 'Total loss': 0.3909580444296201} | train loss {'Reaction outcome loss': 0.2102743637212467, 'Total loss': 0.2102743637212467}
2022-12-31 12:41:41,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:41,248 INFO:     Epoch: 96
2022-12-31 12:41:42,843 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4223923484484355, 'Total loss': 0.4223923484484355} | train loss {'Reaction outcome loss': 0.20276745282209072, 'Total loss': 0.20276745282209072}
2022-12-31 12:41:42,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:42,844 INFO:     Epoch: 97
2022-12-31 12:41:44,438 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4047509402036667, 'Total loss': 0.4047509402036667} | train loss {'Reaction outcome loss': 0.20290776271877925, 'Total loss': 0.20290776271877925}
2022-12-31 12:41:44,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:44,439 INFO:     Epoch: 98
2022-12-31 12:41:46,032 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4088247776031494, 'Total loss': 0.4088247776031494} | train loss {'Reaction outcome loss': 0.2006338500757207, 'Total loss': 0.2006338500757207}
2022-12-31 12:41:46,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:46,032 INFO:     Epoch: 99
2022-12-31 12:41:47,617 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3974539111057917, 'Total loss': 0.3974539111057917} | train loss {'Reaction outcome loss': 0.20659237501685654, 'Total loss': 0.20659237501685654}
2022-12-31 12:41:47,618 INFO:     Best model found after epoch 64 of 100.
2022-12-31 12:41:47,618 INFO:   Done with stage: TRAINING
2022-12-31 12:41:47,618 INFO:   Starting stage: EVALUATION
2022-12-31 12:41:47,758 INFO:   Done with stage: EVALUATION
2022-12-31 12:41:47,758 INFO:   Leaving out SEQ value Fold_1
2022-12-31 12:41:47,771 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 12:41:47,771 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:41:48,422 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:41:48,422 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:41:48,490 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:41:48,490 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:41:48,490 INFO:     No hyperparam tuning for this model
2022-12-31 12:41:48,490 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:41:48,490 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:41:48,491 INFO:     None feature selector for col prot
2022-12-31 12:41:48,491 INFO:     None feature selector for col prot
2022-12-31 12:41:48,491 INFO:     None feature selector for col prot
2022-12-31 12:41:48,492 INFO:     None feature selector for col chem
2022-12-31 12:41:48,492 INFO:     None feature selector for col chem
2022-12-31 12:41:48,492 INFO:     None feature selector for col chem
2022-12-31 12:41:48,492 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:41:48,492 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:41:48,494 INFO:     Number of params in model 223921
2022-12-31 12:41:48,497 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:41:48,497 INFO:   Starting stage: TRAINING
2022-12-31 12:41:48,542 INFO:     Val loss before train {'Reaction outcome loss': 1.0493754386901855, 'Total loss': 1.0493754386901855}
2022-12-31 12:41:48,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:48,542 INFO:     Epoch: 0
2022-12-31 12:41:50,124 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6966973582903544, 'Total loss': 0.6966973582903544} | train loss {'Reaction outcome loss': 0.8098566199306154, 'Total loss': 0.8098566199306154}
2022-12-31 12:41:50,125 INFO:     Found new best model at epoch 0
2022-12-31 12:41:50,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:50,126 INFO:     Epoch: 1
2022-12-31 12:41:51,776 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5863077402114868, 'Total loss': 0.5863077402114868} | train loss {'Reaction outcome loss': 0.6047918122180187, 'Total loss': 0.6047918122180187}
2022-12-31 12:41:51,776 INFO:     Found new best model at epoch 1
2022-12-31 12:41:51,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:51,777 INFO:     Epoch: 2
2022-12-31 12:41:53,429 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5620298624038697, 'Total loss': 0.5620298624038697} | train loss {'Reaction outcome loss': 0.5322718203176547, 'Total loss': 0.5322718203176547}
2022-12-31 12:41:53,429 INFO:     Found new best model at epoch 2
2022-12-31 12:41:53,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:53,430 INFO:     Epoch: 3
2022-12-31 12:41:55,008 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5570219059785207, 'Total loss': 0.5570219059785207} | train loss {'Reaction outcome loss': 0.5079150442305925, 'Total loss': 0.5079150442305925}
2022-12-31 12:41:55,008 INFO:     Found new best model at epoch 3
2022-12-31 12:41:55,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:55,009 INFO:     Epoch: 4
2022-12-31 12:41:56,590 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5552938004334768, 'Total loss': 0.5552938004334768} | train loss {'Reaction outcome loss': 0.48924988181921686, 'Total loss': 0.48924988181921686}
2022-12-31 12:41:56,590 INFO:     Found new best model at epoch 4
2022-12-31 12:41:56,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:56,591 INFO:     Epoch: 5
2022-12-31 12:41:58,193 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5196396678686142, 'Total loss': 0.5196396678686142} | train loss {'Reaction outcome loss': 0.4857951457047985, 'Total loss': 0.4857951457047985}
2022-12-31 12:41:58,193 INFO:     Found new best model at epoch 5
2022-12-31 12:41:58,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:58,194 INFO:     Epoch: 6
2022-12-31 12:41:59,808 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5553469816843669, 'Total loss': 0.5553469816843669} | train loss {'Reaction outcome loss': 0.47169299271419973, 'Total loss': 0.47169299271419973}
2022-12-31 12:41:59,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:41:59,809 INFO:     Epoch: 7
2022-12-31 12:42:01,383 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48558744192123415, 'Total loss': 0.48558744192123415} | train loss {'Reaction outcome loss': 0.4633631409846083, 'Total loss': 0.4633631409846083}
2022-12-31 12:42:01,383 INFO:     Found new best model at epoch 7
2022-12-31 12:42:01,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:01,384 INFO:     Epoch: 8
2022-12-31 12:42:03,010 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5159479002157847, 'Total loss': 0.5159479002157847} | train loss {'Reaction outcome loss': 0.46081960992547716, 'Total loss': 0.46081960992547716}
2022-12-31 12:42:03,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:03,010 INFO:     Epoch: 9
2022-12-31 12:42:04,626 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4718003292878469, 'Total loss': 0.4718003292878469} | train loss {'Reaction outcome loss': 0.4482703455281954, 'Total loss': 0.4482703455281954}
2022-12-31 12:42:04,626 INFO:     Found new best model at epoch 9
2022-12-31 12:42:04,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:04,627 INFO:     Epoch: 10
2022-12-31 12:42:06,195 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5170131305853526, 'Total loss': 0.5170131305853526} | train loss {'Reaction outcome loss': 0.4442873027746695, 'Total loss': 0.4442873027746695}
2022-12-31 12:42:06,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:06,196 INFO:     Epoch: 11
2022-12-31 12:42:07,773 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5229481418927511, 'Total loss': 0.5229481418927511} | train loss {'Reaction outcome loss': 0.43562823028242503, 'Total loss': 0.43562823028242503}
2022-12-31 12:42:07,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:07,773 INFO:     Epoch: 12
2022-12-31 12:42:09,428 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47676537533601127, 'Total loss': 0.47676537533601127} | train loss {'Reaction outcome loss': 0.43090887957789603, 'Total loss': 0.43090887957789603}
2022-12-31 12:42:09,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:09,428 INFO:     Epoch: 13
2022-12-31 12:42:11,031 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4660080701112747, 'Total loss': 0.4660080701112747} | train loss {'Reaction outcome loss': 0.42080850447833973, 'Total loss': 0.42080850447833973}
2022-12-31 12:42:11,031 INFO:     Found new best model at epoch 13
2022-12-31 12:42:11,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:11,032 INFO:     Epoch: 14
2022-12-31 12:42:12,631 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4695411443710327, 'Total loss': 0.4695411443710327} | train loss {'Reaction outcome loss': 0.4182472528114806, 'Total loss': 0.4182472528114806}
2022-12-31 12:42:12,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:12,631 INFO:     Epoch: 15
2022-12-31 12:42:14,219 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47093893885612487, 'Total loss': 0.47093893885612487} | train loss {'Reaction outcome loss': 0.40948598075957193, 'Total loss': 0.40948598075957193}
2022-12-31 12:42:14,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:14,220 INFO:     Epoch: 16
2022-12-31 12:42:15,824 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49834261735280355, 'Total loss': 0.49834261735280355} | train loss {'Reaction outcome loss': 0.4043637153277867, 'Total loss': 0.4043637153277867}
2022-12-31 12:42:15,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:15,824 INFO:     Epoch: 17
2022-12-31 12:42:17,416 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46256442070007325, 'Total loss': 0.46256442070007325} | train loss {'Reaction outcome loss': 0.39650070958220174, 'Total loss': 0.39650070958220174}
2022-12-31 12:42:17,416 INFO:     Found new best model at epoch 17
2022-12-31 12:42:17,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:17,417 INFO:     Epoch: 18
2022-12-31 12:42:19,016 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4728260338306427, 'Total loss': 0.4728260338306427} | train loss {'Reaction outcome loss': 0.39282554719787444, 'Total loss': 0.39282554719787444}
2022-12-31 12:42:19,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:19,017 INFO:     Epoch: 19
2022-12-31 12:42:20,618 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4700282424688339, 'Total loss': 0.4700282424688339} | train loss {'Reaction outcome loss': 0.3874126031559749, 'Total loss': 0.3874126031559749}
2022-12-31 12:42:20,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:20,618 INFO:     Epoch: 20
2022-12-31 12:42:22,222 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4925212929646174, 'Total loss': 0.4925212929646174} | train loss {'Reaction outcome loss': 0.38241711884301943, 'Total loss': 0.38241711884301943}
2022-12-31 12:42:22,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:22,222 INFO:     Epoch: 21
2022-12-31 12:42:23,830 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47157347400983174, 'Total loss': 0.47157347400983174} | train loss {'Reaction outcome loss': 0.37721745865623446, 'Total loss': 0.37721745865623446}
2022-12-31 12:42:23,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:23,830 INFO:     Epoch: 22
2022-12-31 12:42:25,434 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4648716986179352, 'Total loss': 0.4648716986179352} | train loss {'Reaction outcome loss': 0.3732557762006338, 'Total loss': 0.3732557762006338}
2022-12-31 12:42:25,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:25,434 INFO:     Epoch: 23
2022-12-31 12:42:27,014 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.473947548866272, 'Total loss': 0.473947548866272} | train loss {'Reaction outcome loss': 0.3678957022944071, 'Total loss': 0.3678957022944071}
2022-12-31 12:42:27,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:27,014 INFO:     Epoch: 24
2022-12-31 12:42:28,616 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47131258447964985, 'Total loss': 0.47131258447964985} | train loss {'Reaction outcome loss': 0.3591749519925483, 'Total loss': 0.3591749519925483}
2022-12-31 12:42:28,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:28,616 INFO:     Epoch: 25
2022-12-31 12:42:30,218 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4405669212341309, 'Total loss': 0.4405669212341309} | train loss {'Reaction outcome loss': 0.3582814903318012, 'Total loss': 0.3582814903318012}
2022-12-31 12:42:30,219 INFO:     Found new best model at epoch 25
2022-12-31 12:42:30,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:30,220 INFO:     Epoch: 26
2022-12-31 12:42:31,814 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4966466645399729, 'Total loss': 0.4966466645399729} | train loss {'Reaction outcome loss': 0.3514300564671085, 'Total loss': 0.3514300564671085}
2022-12-31 12:42:31,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:31,815 INFO:     Epoch: 27
2022-12-31 12:42:33,413 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4508128474156062, 'Total loss': 0.4508128474156062} | train loss {'Reaction outcome loss': 0.3497544020332777, 'Total loss': 0.3497544020332777}
2022-12-31 12:42:33,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:33,413 INFO:     Epoch: 28
2022-12-31 12:42:35,031 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48314740757147473, 'Total loss': 0.48314740757147473} | train loss {'Reaction outcome loss': 0.3444195987425581, 'Total loss': 0.3444195987425581}
2022-12-31 12:42:35,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:35,031 INFO:     Epoch: 29
2022-12-31 12:42:36,633 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48310582141081493, 'Total loss': 0.48310582141081493} | train loss {'Reaction outcome loss': 0.3356386905087389, 'Total loss': 0.3356386905087389}
2022-12-31 12:42:36,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:36,634 INFO:     Epoch: 30
2022-12-31 12:42:38,236 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4466540584961573, 'Total loss': 0.4466540584961573} | train loss {'Reaction outcome loss': 0.3385971484393099, 'Total loss': 0.3385971484393099}
2022-12-31 12:42:38,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:38,237 INFO:     Epoch: 31
2022-12-31 12:42:39,839 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.463945343097051, 'Total loss': 0.463945343097051} | train loss {'Reaction outcome loss': 0.33224427632062975, 'Total loss': 0.33224427632062975}
2022-12-31 12:42:39,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:39,839 INFO:     Epoch: 32
2022-12-31 12:42:41,453 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5220557729403178, 'Total loss': 0.5220557729403178} | train loss {'Reaction outcome loss': 0.32275110001872925, 'Total loss': 0.32275110001872925}
2022-12-31 12:42:41,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:41,454 INFO:     Epoch: 33
2022-12-31 12:42:43,080 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4625867615143458, 'Total loss': 0.4625867615143458} | train loss {'Reaction outcome loss': 0.31731055426771626, 'Total loss': 0.31731055426771626}
2022-12-31 12:42:43,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:43,081 INFO:     Epoch: 34
2022-12-31 12:42:44,680 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5288579781850179, 'Total loss': 0.5288579781850179} | train loss {'Reaction outcome loss': 0.3249012782326797, 'Total loss': 0.3249012782326797}
2022-12-31 12:42:44,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:44,680 INFO:     Epoch: 35
2022-12-31 12:42:46,339 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5034426569938659, 'Total loss': 0.5034426569938659} | train loss {'Reaction outcome loss': 0.31115857677629394, 'Total loss': 0.31115857677629394}
2022-12-31 12:42:46,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:46,339 INFO:     Epoch: 36
2022-12-31 12:42:47,975 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4723565439383189, 'Total loss': 0.4723565439383189} | train loss {'Reaction outcome loss': 0.30979971054696687, 'Total loss': 0.30979971054696687}
2022-12-31 12:42:47,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:47,975 INFO:     Epoch: 37
2022-12-31 12:42:49,577 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46726585924625397, 'Total loss': 0.46726585924625397} | train loss {'Reaction outcome loss': 0.3063284341708152, 'Total loss': 0.3063284341708152}
2022-12-31 12:42:49,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:49,578 INFO:     Epoch: 38
2022-12-31 12:42:51,183 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4732191781202952, 'Total loss': 0.4732191781202952} | train loss {'Reaction outcome loss': 0.3008049845858647, 'Total loss': 0.3008049845858647}
2022-12-31 12:42:51,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:51,184 INFO:     Epoch: 39
2022-12-31 12:42:52,842 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4283838967482249, 'Total loss': 0.4283838967482249} | train loss {'Reaction outcome loss': 0.29581232355350123, 'Total loss': 0.29581232355350123}
2022-12-31 12:42:52,842 INFO:     Found new best model at epoch 39
2022-12-31 12:42:52,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:52,843 INFO:     Epoch: 40
2022-12-31 12:42:54,434 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43837281738718353, 'Total loss': 0.43837281738718353} | train loss {'Reaction outcome loss': 0.2987462409031, 'Total loss': 0.2987462409031}
2022-12-31 12:42:54,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:54,434 INFO:     Epoch: 41
2022-12-31 12:42:56,040 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47935142914454143, 'Total loss': 0.47935142914454143} | train loss {'Reaction outcome loss': 0.2940071283900825, 'Total loss': 0.2940071283900825}
2022-12-31 12:42:56,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:56,040 INFO:     Epoch: 42
2022-12-31 12:42:57,645 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4264492173989614, 'Total loss': 0.4264492173989614} | train loss {'Reaction outcome loss': 0.29255197702968205, 'Total loss': 0.29255197702968205}
2022-12-31 12:42:57,646 INFO:     Found new best model at epoch 42
2022-12-31 12:42:57,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:57,647 INFO:     Epoch: 43
2022-12-31 12:42:59,249 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5086646099885305, 'Total loss': 0.5086646099885305} | train loss {'Reaction outcome loss': 0.2809701305304239, 'Total loss': 0.2809701305304239}
2022-12-31 12:42:59,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:42:59,249 INFO:     Epoch: 44
2022-12-31 12:43:00,860 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43648014093438786, 'Total loss': 0.43648014093438786} | train loss {'Reaction outcome loss': 0.28173779599694876, 'Total loss': 0.28173779599694876}
2022-12-31 12:43:00,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:00,861 INFO:     Epoch: 45
2022-12-31 12:43:02,460 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46856487492720283, 'Total loss': 0.46856487492720283} | train loss {'Reaction outcome loss': 0.27588500252442205, 'Total loss': 0.27588500252442205}
2022-12-31 12:43:02,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:02,461 INFO:     Epoch: 46
2022-12-31 12:43:04,104 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4542457362016042, 'Total loss': 0.4542457362016042} | train loss {'Reaction outcome loss': 0.2761102550438721, 'Total loss': 0.2761102550438721}
2022-12-31 12:43:04,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:04,104 INFO:     Epoch: 47
2022-12-31 12:43:05,741 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44896541237831117, 'Total loss': 0.44896541237831117} | train loss {'Reaction outcome loss': 0.2697372723262023, 'Total loss': 0.2697372723262023}
2022-12-31 12:43:05,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:05,742 INFO:     Epoch: 48
2022-12-31 12:43:07,370 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4408318589131037, 'Total loss': 0.4408318589131037} | train loss {'Reaction outcome loss': 0.27370940415311035, 'Total loss': 0.27370940415311035}
2022-12-31 12:43:07,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:07,371 INFO:     Epoch: 49
2022-12-31 12:43:08,995 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49305594762166344, 'Total loss': 0.49305594762166344} | train loss {'Reaction outcome loss': 0.26456358241610717, 'Total loss': 0.26456358241610717}
2022-12-31 12:43:08,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:08,995 INFO:     Epoch: 50
2022-12-31 12:43:10,622 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47208389242490134, 'Total loss': 0.47208389242490134} | train loss {'Reaction outcome loss': 0.271267685046705, 'Total loss': 0.271267685046705}
2022-12-31 12:43:10,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:10,623 INFO:     Epoch: 51
2022-12-31 12:43:12,239 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46684711972872417, 'Total loss': 0.46684711972872417} | train loss {'Reaction outcome loss': 0.26529809604160975, 'Total loss': 0.26529809604160975}
2022-12-31 12:43:12,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:12,239 INFO:     Epoch: 52
2022-12-31 12:43:13,851 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4758783986171087, 'Total loss': 0.4758783986171087} | train loss {'Reaction outcome loss': 0.2608901006951384, 'Total loss': 0.2608901006951384}
2022-12-31 12:43:13,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:13,851 INFO:     Epoch: 53
2022-12-31 12:43:15,453 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45918886562188466, 'Total loss': 0.45918886562188466} | train loss {'Reaction outcome loss': 0.2589316124599563, 'Total loss': 0.2589316124599563}
2022-12-31 12:43:15,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:15,453 INFO:     Epoch: 54
2022-12-31 12:43:17,102 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47297070597608887, 'Total loss': 0.47297070597608887} | train loss {'Reaction outcome loss': 0.25498805654636264, 'Total loss': 0.25498805654636264}
2022-12-31 12:43:17,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:17,102 INFO:     Epoch: 55
2022-12-31 12:43:18,717 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47028020918369295, 'Total loss': 0.47028020918369295} | train loss {'Reaction outcome loss': 0.2501690878675584, 'Total loss': 0.2501690878675584}
2022-12-31 12:43:18,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:18,718 INFO:     Epoch: 56
2022-12-31 12:43:20,358 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45679847498734794, 'Total loss': 0.45679847498734794} | train loss {'Reaction outcome loss': 0.25535089103844916, 'Total loss': 0.25535089103844916}
2022-12-31 12:43:20,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:20,359 INFO:     Epoch: 57
2022-12-31 12:43:21,985 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48444872299830116, 'Total loss': 0.48444872299830116} | train loss {'Reaction outcome loss': 0.2511649350125859, 'Total loss': 0.2511649350125859}
2022-12-31 12:43:21,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:21,985 INFO:     Epoch: 58
2022-12-31 12:43:23,622 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48227084055542946, 'Total loss': 0.48227084055542946} | train loss {'Reaction outcome loss': 0.25296462684815385, 'Total loss': 0.25296462684815385}
2022-12-31 12:43:23,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:23,622 INFO:     Epoch: 59
2022-12-31 12:43:25,223 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5020317206780116, 'Total loss': 0.5020317206780116} | train loss {'Reaction outcome loss': 0.24968037455186357, 'Total loss': 0.24968037455186357}
2022-12-31 12:43:25,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:25,223 INFO:     Epoch: 60
2022-12-31 12:43:26,810 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5231625854969024, 'Total loss': 0.5231625854969024} | train loss {'Reaction outcome loss': 0.24069605843864217, 'Total loss': 0.24069605843864217}
2022-12-31 12:43:26,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:26,810 INFO:     Epoch: 61
2022-12-31 12:43:28,410 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4493363261222839, 'Total loss': 0.4493363261222839} | train loss {'Reaction outcome loss': 0.2467777292876348, 'Total loss': 0.2467777292876348}
2022-12-31 12:43:28,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:28,410 INFO:     Epoch: 62
2022-12-31 12:43:29,991 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5214164276917775, 'Total loss': 0.5214164276917775} | train loss {'Reaction outcome loss': 0.24615695712285757, 'Total loss': 0.24615695712285757}
2022-12-31 12:43:29,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:29,992 INFO:     Epoch: 63
2022-12-31 12:43:31,592 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4563530733187993, 'Total loss': 0.4563530733187993} | train loss {'Reaction outcome loss': 0.24323379890789298, 'Total loss': 0.24323379890789298}
2022-12-31 12:43:31,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:31,593 INFO:     Epoch: 64
2022-12-31 12:43:33,192 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48126319944858553, 'Total loss': 0.48126319944858553} | train loss {'Reaction outcome loss': 0.2440829342571053, 'Total loss': 0.2440829342571053}
2022-12-31 12:43:33,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:33,192 INFO:     Epoch: 65
2022-12-31 12:43:34,803 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49919329782327015, 'Total loss': 0.49919329782327015} | train loss {'Reaction outcome loss': 0.2393567310714156, 'Total loss': 0.2393567310714156}
2022-12-31 12:43:34,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:34,803 INFO:     Epoch: 66
2022-12-31 12:43:36,399 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5032820641994477, 'Total loss': 0.5032820641994477} | train loss {'Reaction outcome loss': 0.23799752270000696, 'Total loss': 0.23799752270000696}
2022-12-31 12:43:36,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:36,399 INFO:     Epoch: 67
2022-12-31 12:43:38,000 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4438242902358373, 'Total loss': 0.4438242902358373} | train loss {'Reaction outcome loss': 0.23329015078199825, 'Total loss': 0.23329015078199825}
2022-12-31 12:43:38,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:38,001 INFO:     Epoch: 68
2022-12-31 12:43:39,598 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4444260666767756, 'Total loss': 0.4444260666767756} | train loss {'Reaction outcome loss': 0.23467226493015994, 'Total loss': 0.23467226493015994}
2022-12-31 12:43:39,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:39,598 INFO:     Epoch: 69
2022-12-31 12:43:41,217 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44589510063330334, 'Total loss': 0.44589510063330334} | train loss {'Reaction outcome loss': 0.23465460594607532, 'Total loss': 0.23465460594607532}
2022-12-31 12:43:41,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:41,218 INFO:     Epoch: 70
2022-12-31 12:43:42,873 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4742033729950587, 'Total loss': 0.4742033729950587} | train loss {'Reaction outcome loss': 0.22965735747703236, 'Total loss': 0.22965735747703236}
2022-12-31 12:43:42,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:42,873 INFO:     Epoch: 71
2022-12-31 12:43:44,535 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46602532317241036, 'Total loss': 0.46602532317241036} | train loss {'Reaction outcome loss': 0.22219493708498503, 'Total loss': 0.22219493708498503}
2022-12-31 12:43:44,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:44,535 INFO:     Epoch: 72
2022-12-31 12:43:46,124 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46116400162378945, 'Total loss': 0.46116400162378945} | train loss {'Reaction outcome loss': 0.2265686251590178, 'Total loss': 0.2265686251590178}
2022-12-31 12:43:46,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:46,124 INFO:     Epoch: 73
2022-12-31 12:43:47,729 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44349832038084663, 'Total loss': 0.44349832038084663} | train loss {'Reaction outcome loss': 0.22458073278603546, 'Total loss': 0.22458073278603546}
2022-12-31 12:43:47,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:47,729 INFO:     Epoch: 74
2022-12-31 12:43:49,315 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4766082594792048, 'Total loss': 0.4766082594792048} | train loss {'Reaction outcome loss': 0.22191646990848937, 'Total loss': 0.22191646990848937}
2022-12-31 12:43:49,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:49,315 INFO:     Epoch: 75
2022-12-31 12:43:50,922 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5007171094417572, 'Total loss': 0.5007171094417572} | train loss {'Reaction outcome loss': 0.23401119775499088, 'Total loss': 0.23401119775499088}
2022-12-31 12:43:50,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:50,923 INFO:     Epoch: 76
2022-12-31 12:43:52,545 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4663197269042333, 'Total loss': 0.4663197269042333} | train loss {'Reaction outcome loss': 0.23250836413353682, 'Total loss': 0.23250836413353682}
2022-12-31 12:43:52,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:52,546 INFO:     Epoch: 77
2022-12-31 12:43:54,165 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46476133465766906, 'Total loss': 0.46476133465766906} | train loss {'Reaction outcome loss': 0.2210318362952149, 'Total loss': 0.2210318362952149}
2022-12-31 12:43:54,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:54,165 INFO:     Epoch: 78
2022-12-31 12:43:55,790 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4860869268576304, 'Total loss': 0.4860869268576304} | train loss {'Reaction outcome loss': 0.22103196171785358, 'Total loss': 0.22103196171785358}
2022-12-31 12:43:55,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:55,791 INFO:     Epoch: 79
2022-12-31 12:43:57,408 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4635983159144719, 'Total loss': 0.4635983159144719} | train loss {'Reaction outcome loss': 0.21196636599726484, 'Total loss': 0.21196636599726484}
2022-12-31 12:43:57,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:57,408 INFO:     Epoch: 80
2022-12-31 12:43:59,012 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48827761014302573, 'Total loss': 0.48827761014302573} | train loss {'Reaction outcome loss': 0.21705046589452312, 'Total loss': 0.21705046589452312}
2022-12-31 12:43:59,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:43:59,012 INFO:     Epoch: 81
2022-12-31 12:44:00,639 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48648000955581666, 'Total loss': 0.48648000955581666} | train loss {'Reaction outcome loss': 0.22298607973205128, 'Total loss': 0.22298607973205128}
2022-12-31 12:44:00,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:00,639 INFO:     Epoch: 82
2022-12-31 12:44:02,285 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47003659506638845, 'Total loss': 0.47003659506638845} | train loss {'Reaction outcome loss': 0.2211820638065573, 'Total loss': 0.2211820638065573}
2022-12-31 12:44:02,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:02,286 INFO:     Epoch: 83
2022-12-31 12:44:03,887 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47242740392684934, 'Total loss': 0.47242740392684934} | train loss {'Reaction outcome loss': 0.2165250048571586, 'Total loss': 0.2165250048571586}
2022-12-31 12:44:03,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:03,887 INFO:     Epoch: 84
2022-12-31 12:44:05,512 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4717126985390981, 'Total loss': 0.4717126985390981} | train loss {'Reaction outcome loss': 0.2133937420078764, 'Total loss': 0.2133937420078764}
2022-12-31 12:44:05,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:05,512 INFO:     Epoch: 85
2022-12-31 12:44:07,119 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46277142663796744, 'Total loss': 0.46277142663796744} | train loss {'Reaction outcome loss': 0.21464401877818318, 'Total loss': 0.21464401877818318}
2022-12-31 12:44:07,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:07,119 INFO:     Epoch: 86
2022-12-31 12:44:08,743 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4791744033495585, 'Total loss': 0.4791744033495585} | train loss {'Reaction outcome loss': 0.21585404821229678, 'Total loss': 0.21585404821229678}
2022-12-31 12:44:08,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:08,744 INFO:     Epoch: 87
2022-12-31 12:44:10,358 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4333919664223989, 'Total loss': 0.4333919664223989} | train loss {'Reaction outcome loss': 0.20767740797876877, 'Total loss': 0.20767740797876877}
2022-12-31 12:44:10,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:10,358 INFO:     Epoch: 88
2022-12-31 12:44:11,978 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45486802955468497, 'Total loss': 0.45486802955468497} | train loss {'Reaction outcome loss': 0.2131219649802975, 'Total loss': 0.2131219649802975}
2022-12-31 12:44:11,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:11,979 INFO:     Epoch: 89
2022-12-31 12:44:13,579 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5145682096481323, 'Total loss': 0.5145682096481323} | train loss {'Reaction outcome loss': 0.20878008867947073, 'Total loss': 0.20878008867947073}
2022-12-31 12:44:13,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:13,579 INFO:     Epoch: 90
2022-12-31 12:44:15,177 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5030890762805938, 'Total loss': 0.5030890762805938} | train loss {'Reaction outcome loss': 0.21324384185301998, 'Total loss': 0.21324384185301998}
2022-12-31 12:44:15,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:15,177 INFO:     Epoch: 91
2022-12-31 12:44:16,793 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45669005513191224, 'Total loss': 0.45669005513191224} | train loss {'Reaction outcome loss': 0.21018406385080005, 'Total loss': 0.21018406385080005}
2022-12-31 12:44:16,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:16,794 INFO:     Epoch: 92
2022-12-31 12:44:18,403 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45073181092739106, 'Total loss': 0.45073181092739106} | train loss {'Reaction outcome loss': 0.20514518806343748, 'Total loss': 0.20514518806343748}
2022-12-31 12:44:18,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:18,403 INFO:     Epoch: 93
2022-12-31 12:44:20,017 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47176097830136615, 'Total loss': 0.47176097830136615} | train loss {'Reaction outcome loss': 0.20098578502648395, 'Total loss': 0.20098578502648395}
2022-12-31 12:44:20,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:20,018 INFO:     Epoch: 94
2022-12-31 12:44:21,623 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47051169276237487, 'Total loss': 0.47051169276237487} | train loss {'Reaction outcome loss': 0.20286497615114615, 'Total loss': 0.20286497615114615}
2022-12-31 12:44:21,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:21,624 INFO:     Epoch: 95
2022-12-31 12:44:23,245 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4845030248165131, 'Total loss': 0.4845030248165131} | train loss {'Reaction outcome loss': 0.20254003639965162, 'Total loss': 0.20254003639965162}
2022-12-31 12:44:23,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:23,245 INFO:     Epoch: 96
2022-12-31 12:44:24,828 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.498750631014506, 'Total loss': 0.498750631014506} | train loss {'Reaction outcome loss': 0.2098178701155758, 'Total loss': 0.2098178701155758}
2022-12-31 12:44:24,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:24,828 INFO:     Epoch: 97
2022-12-31 12:44:26,470 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46230406959851583, 'Total loss': 0.46230406959851583} | train loss {'Reaction outcome loss': 0.2030736324377358, 'Total loss': 0.2030736324377358}
2022-12-31 12:44:26,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:26,470 INFO:     Epoch: 98
2022-12-31 12:44:28,096 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4552687567969163, 'Total loss': 0.4552687567969163} | train loss {'Reaction outcome loss': 0.20274084009719592, 'Total loss': 0.20274084009719592}
2022-12-31 12:44:28,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:28,096 INFO:     Epoch: 99
2022-12-31 12:44:29,726 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47520203987757365, 'Total loss': 0.47520203987757365} | train loss {'Reaction outcome loss': 0.19995032037424781, 'Total loss': 0.19995032037424781}
2022-12-31 12:44:29,726 INFO:     Best model found after epoch 43 of 100.
2022-12-31 12:44:29,726 INFO:   Done with stage: TRAINING
2022-12-31 12:44:29,726 INFO:   Starting stage: EVALUATION
2022-12-31 12:44:29,861 INFO:   Done with stage: EVALUATION
2022-12-31 12:44:29,862 INFO:   Leaving out SEQ value Fold_2
2022-12-31 12:44:29,874 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 12:44:29,875 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:44:30,519 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:44:30,519 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:44:30,587 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:44:30,587 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:44:30,587 INFO:     No hyperparam tuning for this model
2022-12-31 12:44:30,587 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:44:30,587 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:44:30,588 INFO:     None feature selector for col prot
2022-12-31 12:44:30,588 INFO:     None feature selector for col prot
2022-12-31 12:44:30,588 INFO:     None feature selector for col prot
2022-12-31 12:44:30,589 INFO:     None feature selector for col chem
2022-12-31 12:44:30,589 INFO:     None feature selector for col chem
2022-12-31 12:44:30,589 INFO:     None feature selector for col chem
2022-12-31 12:44:30,589 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:44:30,589 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:44:30,591 INFO:     Number of params in model 223921
2022-12-31 12:44:30,594 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:44:30,594 INFO:   Starting stage: TRAINING
2022-12-31 12:44:30,638 INFO:     Val loss before train {'Reaction outcome loss': 0.9968458930651347, 'Total loss': 0.9968458930651347}
2022-12-31 12:44:30,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:30,638 INFO:     Epoch: 0
2022-12-31 12:44:32,248 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6978654901186625, 'Total loss': 0.6978654901186625} | train loss {'Reaction outcome loss': 0.8199702469638852, 'Total loss': 0.8199702469638852}
2022-12-31 12:44:32,248 INFO:     Found new best model at epoch 0
2022-12-31 12:44:32,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:32,249 INFO:     Epoch: 1
2022-12-31 12:44:33,830 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5471242527167003, 'Total loss': 0.5471242527167003} | train loss {'Reaction outcome loss': 0.6140379993033497, 'Total loss': 0.6140379993033497}
2022-12-31 12:44:33,831 INFO:     Found new best model at epoch 1
2022-12-31 12:44:33,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:33,832 INFO:     Epoch: 2
2022-12-31 12:44:35,438 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48605504135290784, 'Total loss': 0.48605504135290784} | train loss {'Reaction outcome loss': 0.53872828742305, 'Total loss': 0.53872828742305}
2022-12-31 12:44:35,438 INFO:     Found new best model at epoch 2
2022-12-31 12:44:35,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:35,439 INFO:     Epoch: 3
2022-12-31 12:44:37,031 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5045012176036835, 'Total loss': 0.5045012176036835} | train loss {'Reaction outcome loss': 0.5106319440972238, 'Total loss': 0.5106319440972238}
2022-12-31 12:44:37,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:37,032 INFO:     Epoch: 4
2022-12-31 12:44:38,625 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47822560866673786, 'Total loss': 0.47822560866673786} | train loss {'Reaction outcome loss': 0.48979439771983213, 'Total loss': 0.48979439771983213}
2022-12-31 12:44:38,625 INFO:     Found new best model at epoch 4
2022-12-31 12:44:38,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:38,626 INFO:     Epoch: 5
2022-12-31 12:44:40,203 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5077844083309173, 'Total loss': 0.5077844083309173} | train loss {'Reaction outcome loss': 0.48039637344988273, 'Total loss': 0.48039637344988273}
2022-12-31 12:44:40,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:40,204 INFO:     Epoch: 6
2022-12-31 12:44:41,809 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4898383895556132, 'Total loss': 0.4898383895556132} | train loss {'Reaction outcome loss': 0.47457634725850145, 'Total loss': 0.47457634725850145}
2022-12-31 12:44:41,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:41,809 INFO:     Epoch: 7
2022-12-31 12:44:43,415 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5170654455820719, 'Total loss': 0.5170654455820719} | train loss {'Reaction outcome loss': 0.4657115182487956, 'Total loss': 0.4657115182487956}
2022-12-31 12:44:43,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:43,415 INFO:     Epoch: 8
2022-12-31 12:44:45,030 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48180293242136635, 'Total loss': 0.48180293242136635} | train loss {'Reaction outcome loss': 0.45774796053821787, 'Total loss': 0.45774796053821787}
2022-12-31 12:44:45,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:45,030 INFO:     Epoch: 9
2022-12-31 12:44:46,645 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46229435205459596, 'Total loss': 0.46229435205459596} | train loss {'Reaction outcome loss': 0.4491128514046634, 'Total loss': 0.4491128514046634}
2022-12-31 12:44:46,645 INFO:     Found new best model at epoch 9
2022-12-31 12:44:46,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:46,646 INFO:     Epoch: 10
2022-12-31 12:44:48,273 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45888558427492776, 'Total loss': 0.45888558427492776} | train loss {'Reaction outcome loss': 0.4440514804461064, 'Total loss': 0.4440514804461064}
2022-12-31 12:44:48,273 INFO:     Found new best model at epoch 10
2022-12-31 12:44:48,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:48,274 INFO:     Epoch: 11
2022-12-31 12:44:49,901 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4701591153939565, 'Total loss': 0.4701591153939565} | train loss {'Reaction outcome loss': 0.4383704836442794, 'Total loss': 0.4383704836442794}
2022-12-31 12:44:49,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:49,901 INFO:     Epoch: 12
2022-12-31 12:44:51,494 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4456849694252014, 'Total loss': 0.4456849694252014} | train loss {'Reaction outcome loss': 0.43608673026055206, 'Total loss': 0.43608673026055206}
2022-12-31 12:44:51,494 INFO:     Found new best model at epoch 12
2022-12-31 12:44:51,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:51,495 INFO:     Epoch: 13
2022-12-31 12:44:53,088 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48344986935456596, 'Total loss': 0.48344986935456596} | train loss {'Reaction outcome loss': 0.4260112076124429, 'Total loss': 0.4260112076124429}
2022-12-31 12:44:53,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:53,089 INFO:     Epoch: 14
2022-12-31 12:44:54,700 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4941260288159052, 'Total loss': 0.4941260288159052} | train loss {'Reaction outcome loss': 0.4226040713789262, 'Total loss': 0.4226040713789262}
2022-12-31 12:44:54,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:54,700 INFO:     Epoch: 15
2022-12-31 12:44:56,303 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4607272297143936, 'Total loss': 0.4607272297143936} | train loss {'Reaction outcome loss': 0.41905825047484246, 'Total loss': 0.41905825047484246}
2022-12-31 12:44:56,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:56,303 INFO:     Epoch: 16
2022-12-31 12:44:57,885 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4838625570138296, 'Total loss': 0.4838625570138296} | train loss {'Reaction outcome loss': 0.40538999127162684, 'Total loss': 0.40538999127162684}
2022-12-31 12:44:57,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:57,885 INFO:     Epoch: 17
2022-12-31 12:44:59,490 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45066249271233877, 'Total loss': 0.45066249271233877} | train loss {'Reaction outcome loss': 0.3949472162422243, 'Total loss': 0.3949472162422243}
2022-12-31 12:44:59,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:44:59,490 INFO:     Epoch: 18
2022-12-31 12:45:01,081 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45556549231211346, 'Total loss': 0.45556549231211346} | train loss {'Reaction outcome loss': 0.391950854015001, 'Total loss': 0.391950854015001}
2022-12-31 12:45:01,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:01,081 INFO:     Epoch: 19
2022-12-31 12:45:02,684 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4689782400925954, 'Total loss': 0.4689782400925954} | train loss {'Reaction outcome loss': 0.3911147569834968, 'Total loss': 0.3911147569834968}
2022-12-31 12:45:02,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:02,685 INFO:     Epoch: 20
2022-12-31 12:45:04,325 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42412383755048116, 'Total loss': 0.42412383755048116} | train loss {'Reaction outcome loss': 0.3831988644714539, 'Total loss': 0.3831988644714539}
2022-12-31 12:45:04,327 INFO:     Found new best model at epoch 20
2022-12-31 12:45:04,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:04,328 INFO:     Epoch: 21
2022-12-31 12:45:05,958 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45053693453470867, 'Total loss': 0.45053693453470867} | train loss {'Reaction outcome loss': 0.3809566133188241, 'Total loss': 0.3809566133188241}
2022-12-31 12:45:05,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:05,958 INFO:     Epoch: 22
2022-12-31 12:45:07,556 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4509922444820404, 'Total loss': 0.4509922444820404} | train loss {'Reaction outcome loss': 0.37537237005683527, 'Total loss': 0.37537237005683527}
2022-12-31 12:45:07,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:07,556 INFO:     Epoch: 23
2022-12-31 12:45:09,159 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44435144861539205, 'Total loss': 0.44435144861539205} | train loss {'Reaction outcome loss': 0.36719843870772545, 'Total loss': 0.36719843870772545}
2022-12-31 12:45:09,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:09,159 INFO:     Epoch: 24
2022-12-31 12:45:10,742 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44052051901817324, 'Total loss': 0.44052051901817324} | train loss {'Reaction outcome loss': 0.36759561952544656, 'Total loss': 0.36759561952544656}
2022-12-31 12:45:10,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:10,743 INFO:     Epoch: 25
2022-12-31 12:45:12,345 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4611667434374491, 'Total loss': 0.4611667434374491} | train loss {'Reaction outcome loss': 0.35872819150487584, 'Total loss': 0.35872819150487584}
2022-12-31 12:45:12,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:12,345 INFO:     Epoch: 26
2022-12-31 12:45:13,949 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43280653953552245, 'Total loss': 0.43280653953552245} | train loss {'Reaction outcome loss': 0.3558041316358161, 'Total loss': 0.3558041316358161}
2022-12-31 12:45:13,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:13,949 INFO:     Epoch: 27
2022-12-31 12:45:15,539 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43508305549621584, 'Total loss': 0.43508305549621584} | train loss {'Reaction outcome loss': 0.3522961247480396, 'Total loss': 0.3522961247480396}
2022-12-31 12:45:15,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:15,539 INFO:     Epoch: 28
2022-12-31 12:45:17,143 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4102200256660581, 'Total loss': 0.4102200256660581} | train loss {'Reaction outcome loss': 0.34785698231432466, 'Total loss': 0.34785698231432466}
2022-12-31 12:45:17,143 INFO:     Found new best model at epoch 28
2022-12-31 12:45:17,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:17,144 INFO:     Epoch: 29
2022-12-31 12:45:18,737 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4344368581970533, 'Total loss': 0.4344368581970533} | train loss {'Reaction outcome loss': 0.34177063765761617, 'Total loss': 0.34177063765761617}
2022-12-31 12:45:18,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:18,737 INFO:     Epoch: 30
2022-12-31 12:45:20,360 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4383655846118927, 'Total loss': 0.4383655846118927} | train loss {'Reaction outcome loss': 0.3369121852538961, 'Total loss': 0.3369121852538961}
2022-12-31 12:45:20,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:20,361 INFO:     Epoch: 31
2022-12-31 12:45:21,999 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4330974539120992, 'Total loss': 0.4330974539120992} | train loss {'Reaction outcome loss': 0.3356178879956186, 'Total loss': 0.3356178879956186}
2022-12-31 12:45:22,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:22,000 INFO:     Epoch: 32
2022-12-31 12:45:23,607 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4624661862850189, 'Total loss': 0.4624661862850189} | train loss {'Reaction outcome loss': 0.32830909598659685, 'Total loss': 0.32830909598659685}
2022-12-31 12:45:23,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:23,608 INFO:     Epoch: 33
2022-12-31 12:45:25,192 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43404666781425477, 'Total loss': 0.43404666781425477} | train loss {'Reaction outcome loss': 0.32575912155456593, 'Total loss': 0.32575912155456593}
2022-12-31 12:45:25,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:25,192 INFO:     Epoch: 34
2022-12-31 12:45:26,796 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4197326014439265, 'Total loss': 0.4197326014439265} | train loss {'Reaction outcome loss': 0.31480570867548496, 'Total loss': 0.31480570867548496}
2022-12-31 12:45:26,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:26,796 INFO:     Epoch: 35
2022-12-31 12:45:28,382 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4149749666452408, 'Total loss': 0.4149749666452408} | train loss {'Reaction outcome loss': 0.3181370674417569, 'Total loss': 0.3181370674417569}
2022-12-31 12:45:28,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:28,382 INFO:     Epoch: 36
2022-12-31 12:45:30,005 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4381794343392054, 'Total loss': 0.4381794343392054} | train loss {'Reaction outcome loss': 0.3099183433385559, 'Total loss': 0.3099183433385559}
2022-12-31 12:45:30,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:30,006 INFO:     Epoch: 37
2022-12-31 12:45:31,609 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4167875329653422, 'Total loss': 0.4167875329653422} | train loss {'Reaction outcome loss': 0.31375998020472323, 'Total loss': 0.31375998020472323}
2022-12-31 12:45:31,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:31,609 INFO:     Epoch: 38
2022-12-31 12:45:33,211 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4207709841430187, 'Total loss': 0.4207709841430187} | train loss {'Reaction outcome loss': 0.3043879068579402, 'Total loss': 0.3043879068579402}
2022-12-31 12:45:33,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:33,211 INFO:     Epoch: 39
2022-12-31 12:45:34,796 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4347046931584676, 'Total loss': 0.4347046931584676} | train loss {'Reaction outcome loss': 0.30188842877854793, 'Total loss': 0.30188842877854793}
2022-12-31 12:45:34,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:34,796 INFO:     Epoch: 40
2022-12-31 12:45:36,399 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44682260155677794, 'Total loss': 0.44682260155677794} | train loss {'Reaction outcome loss': 0.29487986353672907, 'Total loss': 0.29487986353672907}
2022-12-31 12:45:36,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:36,399 INFO:     Epoch: 41
2022-12-31 12:45:38,001 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44623080690701805, 'Total loss': 0.44623080690701805} | train loss {'Reaction outcome loss': 0.3017818936771089, 'Total loss': 0.3017818936771089}
2022-12-31 12:45:38,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:38,001 INFO:     Epoch: 42
2022-12-31 12:45:39,609 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4150344381729762, 'Total loss': 0.4150344381729762} | train loss {'Reaction outcome loss': 0.2901363387403689, 'Total loss': 0.2901363387403689}
2022-12-31 12:45:39,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:39,610 INFO:     Epoch: 43
2022-12-31 12:45:41,232 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4515803317228953, 'Total loss': 0.4515803317228953} | train loss {'Reaction outcome loss': 0.29495211374082847, 'Total loss': 0.29495211374082847}
2022-12-31 12:45:41,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:41,232 INFO:     Epoch: 44
2022-12-31 12:45:42,825 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45253143906593324, 'Total loss': 0.45253143906593324} | train loss {'Reaction outcome loss': 0.2875737404798741, 'Total loss': 0.2875737404798741}
2022-12-31 12:45:42,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:42,825 INFO:     Epoch: 45
2022-12-31 12:45:44,432 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4012877901395162, 'Total loss': 0.4012877901395162} | train loss {'Reaction outcome loss': 0.2836842998834975, 'Total loss': 0.2836842998834975}
2022-12-31 12:45:44,432 INFO:     Found new best model at epoch 45
2022-12-31 12:45:44,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:44,433 INFO:     Epoch: 46
2022-12-31 12:45:46,023 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4614424169063568, 'Total loss': 0.4614424169063568} | train loss {'Reaction outcome loss': 0.2779940064900961, 'Total loss': 0.2779940064900961}
2022-12-31 12:45:46,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:46,024 INFO:     Epoch: 47
2022-12-31 12:45:47,614 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42054535895586015, 'Total loss': 0.42054535895586015} | train loss {'Reaction outcome loss': 0.27941008187803157, 'Total loss': 0.27941008187803157}
2022-12-31 12:45:47,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:47,614 INFO:     Epoch: 48
2022-12-31 12:45:49,219 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40695431232452395, 'Total loss': 0.40695431232452395} | train loss {'Reaction outcome loss': 0.27719751240569596, 'Total loss': 0.27719751240569596}
2022-12-31 12:45:49,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:49,219 INFO:     Epoch: 49
2022-12-31 12:45:50,821 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4265612602233887, 'Total loss': 0.4265612602233887} | train loss {'Reaction outcome loss': 0.26794021453831224, 'Total loss': 0.26794021453831224}
2022-12-31 12:45:50,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:50,821 INFO:     Epoch: 50
2022-12-31 12:45:52,412 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42015883326530457, 'Total loss': 0.42015883326530457} | train loss {'Reaction outcome loss': 0.2692874547899206, 'Total loss': 0.2692874547899206}
2022-12-31 12:45:52,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:52,412 INFO:     Epoch: 51
2022-12-31 12:45:54,017 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3961523319284121, 'Total loss': 0.3961523319284121} | train loss {'Reaction outcome loss': 0.26598369124116916, 'Total loss': 0.26598369124116916}
2022-12-31 12:45:54,017 INFO:     Found new best model at epoch 51
2022-12-31 12:45:54,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:54,018 INFO:     Epoch: 52
2022-12-31 12:45:55,610 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4315878103176753, 'Total loss': 0.4315878103176753} | train loss {'Reaction outcome loss': 0.2703294709952541, 'Total loss': 0.2703294709952541}
2022-12-31 12:45:55,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:55,610 INFO:     Epoch: 53
2022-12-31 12:45:57,251 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45057709912459054, 'Total loss': 0.45057709912459054} | train loss {'Reaction outcome loss': 0.2684562606225302, 'Total loss': 0.2684562606225302}
2022-12-31 12:45:57,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:57,252 INFO:     Epoch: 54
2022-12-31 12:45:58,888 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45039550463358563, 'Total loss': 0.45039550463358563} | train loss {'Reaction outcome loss': 0.2677685153489803, 'Total loss': 0.2677685153489803}
2022-12-31 12:45:58,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:45:58,889 INFO:     Epoch: 55
2022-12-31 12:46:00,492 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4332063555717468, 'Total loss': 0.4332063555717468} | train loss {'Reaction outcome loss': 0.2607266937856709, 'Total loss': 0.2607266937856709}
2022-12-31 12:46:00,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:00,492 INFO:     Epoch: 56
2022-12-31 12:46:02,082 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4718518098195394, 'Total loss': 0.4718518098195394} | train loss {'Reaction outcome loss': 0.2576446167360514, 'Total loss': 0.2576446167360514}
2022-12-31 12:46:02,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:02,082 INFO:     Epoch: 57
2022-12-31 12:46:03,688 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43194089929262797, 'Total loss': 0.43194089929262797} | train loss {'Reaction outcome loss': 0.25430884044412727, 'Total loss': 0.25430884044412727}
2022-12-31 12:46:03,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:03,689 INFO:     Epoch: 58
2022-12-31 12:46:05,296 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42900981307029723, 'Total loss': 0.42900981307029723} | train loss {'Reaction outcome loss': 0.246871668135836, 'Total loss': 0.246871668135836}
2022-12-31 12:46:05,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:05,296 INFO:     Epoch: 59
2022-12-31 12:46:06,902 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4429295778274536, 'Total loss': 0.4429295778274536} | train loss {'Reaction outcome loss': 0.2519301155602539, 'Total loss': 0.2519301155602539}
2022-12-31 12:46:06,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:06,902 INFO:     Epoch: 60
2022-12-31 12:46:08,509 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46937148372332255, 'Total loss': 0.46937148372332255} | train loss {'Reaction outcome loss': 0.24983179374110132, 'Total loss': 0.24983179374110132}
2022-12-31 12:46:08,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:08,509 INFO:     Epoch: 61
2022-12-31 12:46:10,097 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4475601812203725, 'Total loss': 0.4475601812203725} | train loss {'Reaction outcome loss': 0.24471985142091254, 'Total loss': 0.24471985142091254}
2022-12-31 12:46:10,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:10,098 INFO:     Epoch: 62
2022-12-31 12:46:11,736 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4334045303364595, 'Total loss': 0.4334045303364595} | train loss {'Reaction outcome loss': 0.24528021287623342, 'Total loss': 0.24528021287623342}
2022-12-31 12:46:11,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:11,736 INFO:     Epoch: 63
2022-12-31 12:46:13,340 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.417475422223409, 'Total loss': 0.417475422223409} | train loss {'Reaction outcome loss': 0.24216535024263047, 'Total loss': 0.24216535024263047}
2022-12-31 12:46:13,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:13,340 INFO:     Epoch: 64
2022-12-31 12:46:14,937 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.430738761027654, 'Total loss': 0.430738761027654} | train loss {'Reaction outcome loss': 0.24259983837918375, 'Total loss': 0.24259983837918375}
2022-12-31 12:46:14,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:14,937 INFO:     Epoch: 65
2022-12-31 12:46:16,546 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4468989322582881, 'Total loss': 0.4468989322582881} | train loss {'Reaction outcome loss': 0.2387425093178129, 'Total loss': 0.2387425093178129}
2022-12-31 12:46:16,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:16,547 INFO:     Epoch: 66
2022-12-31 12:46:18,154 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5022777040799459, 'Total loss': 0.5022777040799459} | train loss {'Reaction outcome loss': 0.2391141476757797, 'Total loss': 0.2391141476757797}
2022-12-31 12:46:18,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:18,154 INFO:     Epoch: 67
2022-12-31 12:46:19,745 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4585803618033727, 'Total loss': 0.4585803618033727} | train loss {'Reaction outcome loss': 0.24517503350754796, 'Total loss': 0.24517503350754796}
2022-12-31 12:46:19,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:19,745 INFO:     Epoch: 68
2022-12-31 12:46:21,354 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4389879951874415, 'Total loss': 0.4389879951874415} | train loss {'Reaction outcome loss': 0.23110707230429292, 'Total loss': 0.23110707230429292}
2022-12-31 12:46:21,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:21,354 INFO:     Epoch: 69
2022-12-31 12:46:22,943 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4345854123433431, 'Total loss': 0.4345854123433431} | train loss {'Reaction outcome loss': 0.23975946826539635, 'Total loss': 0.23975946826539635}
2022-12-31 12:46:22,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:22,944 INFO:     Epoch: 70
2022-12-31 12:46:24,590 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42394018471240996, 'Total loss': 0.42394018471240996} | train loss {'Reaction outcome loss': 0.2305088268043712, 'Total loss': 0.2305088268043712}
2022-12-31 12:46:24,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:24,590 INFO:     Epoch: 71
2022-12-31 12:46:26,216 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4613119532664617, 'Total loss': 0.4613119532664617} | train loss {'Reaction outcome loss': 0.23449501468571443, 'Total loss': 0.23449501468571443}
2022-12-31 12:46:26,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:26,216 INFO:     Epoch: 72
2022-12-31 12:46:27,816 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4593851963678996, 'Total loss': 0.4593851963678996} | train loss {'Reaction outcome loss': 0.22771331836595696, 'Total loss': 0.22771331836595696}
2022-12-31 12:46:27,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:27,816 INFO:     Epoch: 73
2022-12-31 12:46:29,402 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48205065925916035, 'Total loss': 0.48205065925916035} | train loss {'Reaction outcome loss': 0.23477685463788744, 'Total loss': 0.23477685463788744}
2022-12-31 12:46:29,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:29,403 INFO:     Epoch: 74
2022-12-31 12:46:31,003 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4112139125665029, 'Total loss': 0.4112139125665029} | train loss {'Reaction outcome loss': 0.22652707618043755, 'Total loss': 0.22652707618043755}
2022-12-31 12:46:31,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:31,003 INFO:     Epoch: 75
2022-12-31 12:46:32,608 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44468363324801125, 'Total loss': 0.44468363324801125} | train loss {'Reaction outcome loss': 0.22372366676291267, 'Total loss': 0.22372366676291267}
2022-12-31 12:46:32,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:32,608 INFO:     Epoch: 76
2022-12-31 12:46:34,207 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4279356598854065, 'Total loss': 0.4279356598854065} | train loss {'Reaction outcome loss': 0.21203548096857228, 'Total loss': 0.21203548096857228}
2022-12-31 12:46:34,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:34,207 INFO:     Epoch: 77
2022-12-31 12:46:35,812 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.435927181939284, 'Total loss': 0.435927181939284} | train loss {'Reaction outcome loss': 0.22189262635569215, 'Total loss': 0.22189262635569215}
2022-12-31 12:46:35,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:35,812 INFO:     Epoch: 78
2022-12-31 12:46:37,396 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4348283221324285, 'Total loss': 0.4348283221324285} | train loss {'Reaction outcome loss': 0.2251170770957684, 'Total loss': 0.2251170770957684}
2022-12-31 12:46:37,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:37,396 INFO:     Epoch: 79
2022-12-31 12:46:39,023 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43008140921592714, 'Total loss': 0.43008140921592714} | train loss {'Reaction outcome loss': 0.22461637127257528, 'Total loss': 0.22461637127257528}
2022-12-31 12:46:39,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:39,023 INFO:     Epoch: 80
2022-12-31 12:46:40,623 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4417035193492969, 'Total loss': 0.4417035193492969} | train loss {'Reaction outcome loss': 0.218751870361822, 'Total loss': 0.218751870361822}
2022-12-31 12:46:40,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:40,624 INFO:     Epoch: 81
2022-12-31 12:46:42,243 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4372651030619939, 'Total loss': 0.4372651030619939} | train loss {'Reaction outcome loss': 0.21975522785150742, 'Total loss': 0.21975522785150742}
2022-12-31 12:46:42,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:42,244 INFO:     Epoch: 82
2022-12-31 12:46:43,855 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4454203605651855, 'Total loss': 0.4454203605651855} | train loss {'Reaction outcome loss': 0.21665305334515186, 'Total loss': 0.21665305334515186}
2022-12-31 12:46:43,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:43,855 INFO:     Epoch: 83
2022-12-31 12:46:45,454 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4314011106888453, 'Total loss': 0.4314011106888453} | train loss {'Reaction outcome loss': 0.21825148751311033, 'Total loss': 0.21825148751311033}
2022-12-31 12:46:45,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:45,454 INFO:     Epoch: 84
2022-12-31 12:46:47,029 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40135391131043435, 'Total loss': 0.40135391131043435} | train loss {'Reaction outcome loss': 0.21635917954883732, 'Total loss': 0.21635917954883732}
2022-12-31 12:46:47,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:47,030 INFO:     Epoch: 85
2022-12-31 12:46:48,630 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40930266082286837, 'Total loss': 0.40930266082286837} | train loss {'Reaction outcome loss': 0.2167693855302347, 'Total loss': 0.2167693855302347}
2022-12-31 12:46:48,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:48,630 INFO:     Epoch: 86
2022-12-31 12:46:50,226 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38268615305423737, 'Total loss': 0.38268615305423737} | train loss {'Reaction outcome loss': 0.2103217583518107, 'Total loss': 0.2103217583518107}
2022-12-31 12:46:50,226 INFO:     Found new best model at epoch 86
2022-12-31 12:46:50,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:50,227 INFO:     Epoch: 87
2022-12-31 12:46:51,870 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4477829416592916, 'Total loss': 0.4477829416592916} | train loss {'Reaction outcome loss': 0.21323923647212675, 'Total loss': 0.21323923647212675}
2022-12-31 12:46:51,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:51,870 INFO:     Epoch: 88
2022-12-31 12:46:53,470 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4783308506011963, 'Total loss': 0.4783308506011963} | train loss {'Reaction outcome loss': 0.20792642751565346, 'Total loss': 0.20792642751565346}
2022-12-31 12:46:53,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:53,471 INFO:     Epoch: 89
2022-12-31 12:46:55,050 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48114875753720604, 'Total loss': 0.48114875753720604} | train loss {'Reaction outcome loss': 0.20944098956650975, 'Total loss': 0.20944098956650975}
2022-12-31 12:46:55,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:55,050 INFO:     Epoch: 90
2022-12-31 12:46:56,639 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42701848049958546, 'Total loss': 0.42701848049958546} | train loss {'Reaction outcome loss': 0.21686306241012754, 'Total loss': 0.21686306241012754}
2022-12-31 12:46:56,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:56,639 INFO:     Epoch: 91
2022-12-31 12:46:58,232 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46194020211696624, 'Total loss': 0.46194020211696624} | train loss {'Reaction outcome loss': 0.19965048111129158, 'Total loss': 0.19965048111129158}
2022-12-31 12:46:58,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:58,232 INFO:     Epoch: 92
2022-12-31 12:46:59,813 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4416956981023153, 'Total loss': 0.4416956981023153} | train loss {'Reaction outcome loss': 0.19870595266699667, 'Total loss': 0.19870595266699667}
2022-12-31 12:46:59,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:46:59,814 INFO:     Epoch: 93
2022-12-31 12:47:01,406 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.400118646522363, 'Total loss': 0.400118646522363} | train loss {'Reaction outcome loss': 0.200519860312752, 'Total loss': 0.200519860312752}
2022-12-31 12:47:01,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:01,406 INFO:     Epoch: 94
2022-12-31 12:47:02,998 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4356090188026428, 'Total loss': 0.4356090188026428} | train loss {'Reaction outcome loss': 0.21084419047654412, 'Total loss': 0.21084419047654412}
2022-12-31 12:47:02,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:02,998 INFO:     Epoch: 95
2022-12-31 12:47:04,576 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4130531986554464, 'Total loss': 0.4130531986554464} | train loss {'Reaction outcome loss': 0.20385999332485727, 'Total loss': 0.20385999332485727}
2022-12-31 12:47:04,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:04,576 INFO:     Epoch: 96
2022-12-31 12:47:06,190 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39573981761932375, 'Total loss': 0.39573981761932375} | train loss {'Reaction outcome loss': 0.20878783147440944, 'Total loss': 0.20878783147440944}
2022-12-31 12:47:06,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:06,191 INFO:     Epoch: 97
2022-12-31 12:47:07,782 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38757797578970593, 'Total loss': 0.38757797578970593} | train loss {'Reaction outcome loss': 0.20455950338925635, 'Total loss': 0.20455950338925635}
2022-12-31 12:47:07,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:07,783 INFO:     Epoch: 98
2022-12-31 12:47:09,361 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4056355009476344, 'Total loss': 0.4056355009476344} | train loss {'Reaction outcome loss': 0.20404435172949956, 'Total loss': 0.20404435172949956}
2022-12-31 12:47:09,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:09,361 INFO:     Epoch: 99
2022-12-31 12:47:10,980 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4038689186175664, 'Total loss': 0.4038689186175664} | train loss {'Reaction outcome loss': 0.21442238482963907, 'Total loss': 0.21442238482963907}
2022-12-31 12:47:10,980 INFO:     Best model found after epoch 87 of 100.
2022-12-31 12:47:10,980 INFO:   Done with stage: TRAINING
2022-12-31 12:47:10,980 INFO:   Starting stage: EVALUATION
2022-12-31 12:47:11,120 INFO:   Done with stage: EVALUATION
2022-12-31 12:47:11,120 INFO:   Leaving out SEQ value Fold_3
2022-12-31 12:47:11,133 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 12:47:11,133 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:47:11,784 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:47:11,784 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:47:11,852 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:47:11,852 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:47:11,852 INFO:     No hyperparam tuning for this model
2022-12-31 12:47:11,852 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:47:11,852 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:47:11,853 INFO:     None feature selector for col prot
2022-12-31 12:47:11,853 INFO:     None feature selector for col prot
2022-12-31 12:47:11,853 INFO:     None feature selector for col prot
2022-12-31 12:47:11,854 INFO:     None feature selector for col chem
2022-12-31 12:47:11,854 INFO:     None feature selector for col chem
2022-12-31 12:47:11,854 INFO:     None feature selector for col chem
2022-12-31 12:47:11,854 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:47:11,854 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:47:11,856 INFO:     Number of params in model 223921
2022-12-31 12:47:11,859 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:47:11,859 INFO:   Starting stage: TRAINING
2022-12-31 12:47:11,905 INFO:     Val loss before train {'Reaction outcome loss': 1.0645297567049663, 'Total loss': 1.0645297567049663}
2022-12-31 12:47:11,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:11,905 INFO:     Epoch: 0
2022-12-31 12:47:13,489 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6893168985843658, 'Total loss': 0.6893168985843658} | train loss {'Reaction outcome loss': 0.8188092173451055, 'Total loss': 0.8188092173451055}
2022-12-31 12:47:13,489 INFO:     Found new best model at epoch 0
2022-12-31 12:47:13,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:13,490 INFO:     Epoch: 1
2022-12-31 12:47:15,113 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5872507611910502, 'Total loss': 0.5872507611910502} | train loss {'Reaction outcome loss': 0.6025954965692367, 'Total loss': 0.6025954965692367}
2022-12-31 12:47:15,114 INFO:     Found new best model at epoch 1
2022-12-31 12:47:15,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:15,115 INFO:     Epoch: 2
2022-12-31 12:47:16,706 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.56928790807724, 'Total loss': 0.56928790807724} | train loss {'Reaction outcome loss': 0.535566984573855, 'Total loss': 0.535566984573855}
2022-12-31 12:47:16,707 INFO:     Found new best model at epoch 2
2022-12-31 12:47:16,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:16,708 INFO:     Epoch: 3
2022-12-31 12:47:18,290 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.505563975373904, 'Total loss': 0.505563975373904} | train loss {'Reaction outcome loss': 0.5060962465775274, 'Total loss': 0.5060962465775274}
2022-12-31 12:47:18,290 INFO:     Found new best model at epoch 3
2022-12-31 12:47:18,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:18,291 INFO:     Epoch: 4
2022-12-31 12:47:19,889 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4805848161379496, 'Total loss': 0.4805848161379496} | train loss {'Reaction outcome loss': 0.48931122913847874, 'Total loss': 0.48931122913847874}
2022-12-31 12:47:19,889 INFO:     Found new best model at epoch 4
2022-12-31 12:47:19,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:19,890 INFO:     Epoch: 5
2022-12-31 12:47:21,488 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48136205077171323, 'Total loss': 0.48136205077171323} | train loss {'Reaction outcome loss': 0.479118724482773, 'Total loss': 0.479118724482773}
2022-12-31 12:47:21,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:21,489 INFO:     Epoch: 6
2022-12-31 12:47:23,076 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48349417448043824, 'Total loss': 0.48349417448043824} | train loss {'Reaction outcome loss': 0.4722657523994898, 'Total loss': 0.4722657523994898}
2022-12-31 12:47:23,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:23,076 INFO:     Epoch: 7
2022-12-31 12:47:24,673 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45572851101557416, 'Total loss': 0.45572851101557416} | train loss {'Reaction outcome loss': 0.4684099184661886, 'Total loss': 0.4684099184661886}
2022-12-31 12:47:24,673 INFO:     Found new best model at epoch 7
2022-12-31 12:47:24,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:24,674 INFO:     Epoch: 8
2022-12-31 12:47:26,253 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4768918772538503, 'Total loss': 0.4768918772538503} | train loss {'Reaction outcome loss': 0.4537852063339992, 'Total loss': 0.4537852063339992}
2022-12-31 12:47:26,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:26,253 INFO:     Epoch: 9
2022-12-31 12:47:27,852 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46988603671391804, 'Total loss': 0.46988603671391804} | train loss {'Reaction outcome loss': 0.45088663452515637, 'Total loss': 0.45088663452515637}
2022-12-31 12:47:27,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:27,853 INFO:     Epoch: 10
2022-12-31 12:47:29,450 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4757783055305481, 'Total loss': 0.4757783055305481} | train loss {'Reaction outcome loss': 0.4426046032322584, 'Total loss': 0.4426046032322584}
2022-12-31 12:47:29,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:29,451 INFO:     Epoch: 11
2022-12-31 12:47:31,050 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47664493322372437, 'Total loss': 0.47664493322372437} | train loss {'Reaction outcome loss': 0.43507930340014234, 'Total loss': 0.43507930340014234}
2022-12-31 12:47:31,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:31,050 INFO:     Epoch: 12
2022-12-31 12:47:32,647 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45223108331362405, 'Total loss': 0.45223108331362405} | train loss {'Reaction outcome loss': 0.4286162041290833, 'Total loss': 0.4286162041290833}
2022-12-31 12:47:32,648 INFO:     Found new best model at epoch 12
2022-12-31 12:47:32,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:32,649 INFO:     Epoch: 13
2022-12-31 12:47:34,256 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4599917968114217, 'Total loss': 0.4599917968114217} | train loss {'Reaction outcome loss': 0.4246853643307721, 'Total loss': 0.4246853643307721}
2022-12-31 12:47:34,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:34,257 INFO:     Epoch: 14
2022-12-31 12:47:35,842 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4301865190267563, 'Total loss': 0.4301865190267563} | train loss {'Reaction outcome loss': 0.4169198233824577, 'Total loss': 0.4169198233824577}
2022-12-31 12:47:35,843 INFO:     Found new best model at epoch 14
2022-12-31 12:47:35,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:35,844 INFO:     Epoch: 15
2022-12-31 12:47:37,449 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4553827365239461, 'Total loss': 0.4553827365239461} | train loss {'Reaction outcome loss': 0.41265694103645584, 'Total loss': 0.41265694103645584}
2022-12-31 12:47:37,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:37,449 INFO:     Epoch: 16
2022-12-31 12:47:39,054 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47059000432491305, 'Total loss': 0.47059000432491305} | train loss {'Reaction outcome loss': 0.40989244469597824, 'Total loss': 0.40989244469597824}
2022-12-31 12:47:39,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:39,054 INFO:     Epoch: 17
2022-12-31 12:47:40,648 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4607463002204895, 'Total loss': 0.4607463002204895} | train loss {'Reaction outcome loss': 0.39749062061309814, 'Total loss': 0.39749062061309814}
2022-12-31 12:47:40,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:40,648 INFO:     Epoch: 18
2022-12-31 12:47:42,255 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4478590210278829, 'Total loss': 0.4478590210278829} | train loss {'Reaction outcome loss': 0.39083611165737586, 'Total loss': 0.39083611165737586}
2022-12-31 12:47:42,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:42,255 INFO:     Epoch: 19
2022-12-31 12:47:43,846 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46840418775876363, 'Total loss': 0.46840418775876363} | train loss {'Reaction outcome loss': 0.388109508493956, 'Total loss': 0.388109508493956}
2022-12-31 12:47:43,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:43,846 INFO:     Epoch: 20
2022-12-31 12:47:45,467 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4041557868321737, 'Total loss': 0.4041557868321737} | train loss {'Reaction outcome loss': 0.3839834606560477, 'Total loss': 0.3839834606560477}
2022-12-31 12:47:45,467 INFO:     Found new best model at epoch 20
2022-12-31 12:47:45,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:45,468 INFO:     Epoch: 21
2022-12-31 12:47:47,068 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44259280363718667, 'Total loss': 0.44259280363718667} | train loss {'Reaction outcome loss': 0.3767802039582799, 'Total loss': 0.3767802039582799}
2022-12-31 12:47:47,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:47,068 INFO:     Epoch: 22
2022-12-31 12:47:48,671 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4622245152791341, 'Total loss': 0.4622245152791341} | train loss {'Reaction outcome loss': 0.3699100529299165, 'Total loss': 0.3699100529299165}
2022-12-31 12:47:48,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:48,672 INFO:     Epoch: 23
2022-12-31 12:47:50,259 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4270407492915789, 'Total loss': 0.4270407492915789} | train loss {'Reaction outcome loss': 0.3589204554140133, 'Total loss': 0.3589204554140133}
2022-12-31 12:47:50,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:50,260 INFO:     Epoch: 24
2022-12-31 12:47:51,864 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4352363725503286, 'Total loss': 0.4352363725503286} | train loss {'Reaction outcome loss': 0.3519884850421961, 'Total loss': 0.3519884850421961}
2022-12-31 12:47:51,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:51,864 INFO:     Epoch: 25
2022-12-31 12:47:53,461 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4242512881755829, 'Total loss': 0.4242512881755829} | train loss {'Reaction outcome loss': 0.3506200376109485, 'Total loss': 0.3506200376109485}
2022-12-31 12:47:53,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:53,461 INFO:     Epoch: 26
2022-12-31 12:47:55,067 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4156229078769684, 'Total loss': 0.4156229078769684} | train loss {'Reaction outcome loss': 0.345222323398738, 'Total loss': 0.345222323398738}
2022-12-31 12:47:55,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:55,068 INFO:     Epoch: 27
2022-12-31 12:47:56,671 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43437712887922925, 'Total loss': 0.43437712887922925} | train loss {'Reaction outcome loss': 0.3390263013514507, 'Total loss': 0.3390263013514507}
2022-12-31 12:47:56,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:56,671 INFO:     Epoch: 28
2022-12-31 12:47:58,274 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4021679058670998, 'Total loss': 0.4021679058670998} | train loss {'Reaction outcome loss': 0.3331289405587816, 'Total loss': 0.3331289405587816}
2022-12-31 12:47:58,274 INFO:     Found new best model at epoch 28
2022-12-31 12:47:58,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:58,275 INFO:     Epoch: 29
2022-12-31 12:47:59,866 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39927706519762673, 'Total loss': 0.39927706519762673} | train loss {'Reaction outcome loss': 0.32864755677589536, 'Total loss': 0.32864755677589536}
2022-12-31 12:47:59,866 INFO:     Found new best model at epoch 29
2022-12-31 12:47:59,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:47:59,867 INFO:     Epoch: 30
2022-12-31 12:48:01,472 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.404847910006841, 'Total loss': 0.404847910006841} | train loss {'Reaction outcome loss': 0.32877281487640675, 'Total loss': 0.32877281487640675}
2022-12-31 12:48:01,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:01,473 INFO:     Epoch: 31
2022-12-31 12:48:03,062 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40142312049865725, 'Total loss': 0.40142312049865725} | train loss {'Reaction outcome loss': 0.326720855627073, 'Total loss': 0.326720855627073}
2022-12-31 12:48:03,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:03,062 INFO:     Epoch: 32
2022-12-31 12:48:04,669 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4320580000678698, 'Total loss': 0.4320580000678698} | train loss {'Reaction outcome loss': 0.31472208130642443, 'Total loss': 0.31472208130642443}
2022-12-31 12:48:04,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:04,669 INFO:     Epoch: 33
2022-12-31 12:48:06,277 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42648002207279206, 'Total loss': 0.42648002207279206} | train loss {'Reaction outcome loss': 0.31324916812897163, 'Total loss': 0.31324916812897163}
2022-12-31 12:48:06,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:06,277 INFO:     Epoch: 34
2022-12-31 12:48:07,863 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3916883071263631, 'Total loss': 0.3916883071263631} | train loss {'Reaction outcome loss': 0.30895595975818424, 'Total loss': 0.30895595975818424}
2022-12-31 12:48:07,863 INFO:     Found new best model at epoch 34
2022-12-31 12:48:07,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:07,864 INFO:     Epoch: 35
2022-12-31 12:48:09,479 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4408383051554362, 'Total loss': 0.4408383051554362} | train loss {'Reaction outcome loss': 0.31119343119054815, 'Total loss': 0.31119343119054815}
2022-12-31 12:48:09,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:09,479 INFO:     Epoch: 36
2022-12-31 12:48:11,068 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4063872362176577, 'Total loss': 0.4063872362176577} | train loss {'Reaction outcome loss': 0.2987169542479037, 'Total loss': 0.2987169542479037}
2022-12-31 12:48:11,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:11,068 INFO:     Epoch: 37
2022-12-31 12:48:12,675 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4203803767760595, 'Total loss': 0.4203803767760595} | train loss {'Reaction outcome loss': 0.2943391919843037, 'Total loss': 0.2943391919843037}
2022-12-31 12:48:12,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:12,675 INFO:     Epoch: 38
2022-12-31 12:48:14,284 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4320103665192922, 'Total loss': 0.4320103665192922} | train loss {'Reaction outcome loss': 0.29645326551403445, 'Total loss': 0.29645326551403445}
2022-12-31 12:48:14,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:14,284 INFO:     Epoch: 39
2022-12-31 12:48:15,892 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.396875058611234, 'Total loss': 0.396875058611234} | train loss {'Reaction outcome loss': 0.2898159041103438, 'Total loss': 0.2898159041103438}
2022-12-31 12:48:15,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:15,892 INFO:     Epoch: 40
2022-12-31 12:48:17,476 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.490813014904658, 'Total loss': 0.490813014904658} | train loss {'Reaction outcome loss': 0.27999921333398264, 'Total loss': 0.27999921333398264}
2022-12-31 12:48:17,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:17,477 INFO:     Epoch: 41
2022-12-31 12:48:19,084 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38628849883874256, 'Total loss': 0.38628849883874256} | train loss {'Reaction outcome loss': 0.284865798877321, 'Total loss': 0.284865798877321}
2022-12-31 12:48:19,084 INFO:     Found new best model at epoch 41
2022-12-31 12:48:19,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:19,085 INFO:     Epoch: 42
2022-12-31 12:48:20,675 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42591302196184794, 'Total loss': 0.42591302196184794} | train loss {'Reaction outcome loss': 0.279727819328108, 'Total loss': 0.279727819328108}
2022-12-31 12:48:20,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:20,676 INFO:     Epoch: 43
2022-12-31 12:48:22,285 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4223568697770437, 'Total loss': 0.4223568697770437} | train loss {'Reaction outcome loss': 0.2792799844522111, 'Total loss': 0.2792799844522111}
2022-12-31 12:48:22,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:22,285 INFO:     Epoch: 44
2022-12-31 12:48:23,890 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4692099988460541, 'Total loss': 0.4692099988460541} | train loss {'Reaction outcome loss': 0.2762214743742978, 'Total loss': 0.2762214743742978}
2022-12-31 12:48:23,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:23,891 INFO:     Epoch: 45
2022-12-31 12:48:25,490 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37868067622184753, 'Total loss': 0.37868067622184753} | train loss {'Reaction outcome loss': 0.27441576371363696, 'Total loss': 0.27441576371363696}
2022-12-31 12:48:25,490 INFO:     Found new best model at epoch 45
2022-12-31 12:48:25,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:25,491 INFO:     Epoch: 46
2022-12-31 12:48:27,091 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41978262066841127, 'Total loss': 0.41978262066841127} | train loss {'Reaction outcome loss': 0.2681206012634139, 'Total loss': 0.2681206012634139}
2022-12-31 12:48:27,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:27,091 INFO:     Epoch: 47
2022-12-31 12:48:28,700 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41514344116051993, 'Total loss': 0.41514344116051993} | train loss {'Reaction outcome loss': 0.2685407310126037, 'Total loss': 0.2685407310126037}
2022-12-31 12:48:28,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:28,700 INFO:     Epoch: 48
2022-12-31 12:48:30,307 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4056814064582189, 'Total loss': 0.4056814064582189} | train loss {'Reaction outcome loss': 0.268322340844974, 'Total loss': 0.268322340844974}
2022-12-31 12:48:30,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:30,308 INFO:     Epoch: 49
2022-12-31 12:48:31,914 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4063510855038961, 'Total loss': 0.4063510855038961} | train loss {'Reaction outcome loss': 0.2659740059289837, 'Total loss': 0.2659740059289837}
2022-12-31 12:48:31,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:31,914 INFO:     Epoch: 50
2022-12-31 12:48:33,517 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41476023495197295, 'Total loss': 0.41476023495197295} | train loss {'Reaction outcome loss': 0.2612039006457929, 'Total loss': 0.2612039006457929}
2022-12-31 12:48:33,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:33,517 INFO:     Epoch: 51
2022-12-31 12:48:35,098 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.453048009177049, 'Total loss': 0.453048009177049} | train loss {'Reaction outcome loss': 0.2542276965916483, 'Total loss': 0.2542276965916483}
2022-12-31 12:48:35,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:35,098 INFO:     Epoch: 52
2022-12-31 12:48:36,716 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4231451044480006, 'Total loss': 0.4231451044480006} | train loss {'Reaction outcome loss': 0.25366360744475014, 'Total loss': 0.25366360744475014}
2022-12-31 12:48:36,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:36,716 INFO:     Epoch: 53
2022-12-31 12:48:38,316 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.412944487730662, 'Total loss': 0.412944487730662} | train loss {'Reaction outcome loss': 0.25087237079376284, 'Total loss': 0.25087237079376284}
2022-12-31 12:48:38,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:38,316 INFO:     Epoch: 54
2022-12-31 12:48:39,939 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42010368704795836, 'Total loss': 0.42010368704795836} | train loss {'Reaction outcome loss': 0.2559948857384224, 'Total loss': 0.2559948857384224}
2022-12-31 12:48:39,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:39,940 INFO:     Epoch: 55
2022-12-31 12:48:41,564 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40138270060221354, 'Total loss': 0.40138270060221354} | train loss {'Reaction outcome loss': 0.25525618268408046, 'Total loss': 0.25525618268408046}
2022-12-31 12:48:41,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:41,565 INFO:     Epoch: 56
2022-12-31 12:48:43,176 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3947651281952858, 'Total loss': 0.3947651281952858} | train loss {'Reaction outcome loss': 0.24550981671433814, 'Total loss': 0.24550981671433814}
2022-12-31 12:48:43,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:43,177 INFO:     Epoch: 57
2022-12-31 12:48:44,783 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38345509668191274, 'Total loss': 0.38345509668191274} | train loss {'Reaction outcome loss': 0.24303650057595902, 'Total loss': 0.24303650057595902}
2022-12-31 12:48:44,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:44,784 INFO:     Epoch: 58
2022-12-31 12:48:46,416 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44887254138787586, 'Total loss': 0.44887254138787586} | train loss {'Reaction outcome loss': 0.2421616840781304, 'Total loss': 0.2421616840781304}
2022-12-31 12:48:46,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:46,417 INFO:     Epoch: 59
2022-12-31 12:48:48,005 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40993986626466117, 'Total loss': 0.40993986626466117} | train loss {'Reaction outcome loss': 0.24434742814161048, 'Total loss': 0.24434742814161048}
2022-12-31 12:48:48,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:48,005 INFO:     Epoch: 60
2022-12-31 12:48:49,626 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4008286754290263, 'Total loss': 0.4008286754290263} | train loss {'Reaction outcome loss': 0.23888941231544, 'Total loss': 0.23888941231544}
2022-12-31 12:48:49,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:49,627 INFO:     Epoch: 61
2022-12-31 12:48:51,234 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4288595631718636, 'Total loss': 0.4288595631718636} | train loss {'Reaction outcome loss': 0.23411628073693191, 'Total loss': 0.23411628073693191}
2022-12-31 12:48:51,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:51,234 INFO:     Epoch: 62
2022-12-31 12:48:52,833 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43886651198069254, 'Total loss': 0.43886651198069254} | train loss {'Reaction outcome loss': 0.23575344727966038, 'Total loss': 0.23575344727966038}
2022-12-31 12:48:52,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:52,834 INFO:     Epoch: 63
2022-12-31 12:48:54,446 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4362528160214424, 'Total loss': 0.4362528160214424} | train loss {'Reaction outcome loss': 0.24196875062397252, 'Total loss': 0.24196875062397252}
2022-12-31 12:48:54,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:54,448 INFO:     Epoch: 64
2022-12-31 12:48:56,058 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41886581977208454, 'Total loss': 0.41886581977208454} | train loss {'Reaction outcome loss': 0.23212618883155342, 'Total loss': 0.23212618883155342}
2022-12-31 12:48:56,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:56,058 INFO:     Epoch: 65
2022-12-31 12:48:57,643 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4382722566525141, 'Total loss': 0.4382722566525141} | train loss {'Reaction outcome loss': 0.2298170334598335, 'Total loss': 0.2298170334598335}
2022-12-31 12:48:57,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:57,643 INFO:     Epoch: 66
2022-12-31 12:48:59,250 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42248529692490894, 'Total loss': 0.42248529692490894} | train loss {'Reaction outcome loss': 0.2250487129509884, 'Total loss': 0.2250487129509884}
2022-12-31 12:48:59,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:48:59,250 INFO:     Epoch: 67
2022-12-31 12:49:00,866 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3943825970093409, 'Total loss': 0.3943825970093409} | train loss {'Reaction outcome loss': 0.23167463763188706, 'Total loss': 0.23167463763188706}
2022-12-31 12:49:00,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:00,867 INFO:     Epoch: 68
2022-12-31 12:49:02,484 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4352131386597951, 'Total loss': 0.4352131386597951} | train loss {'Reaction outcome loss': 0.22372383685497038, 'Total loss': 0.22372383685497038}
2022-12-31 12:49:02,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:02,484 INFO:     Epoch: 69
2022-12-31 12:49:04,116 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4133079489072164, 'Total loss': 0.4133079489072164} | train loss {'Reaction outcome loss': 0.2274617528012634, 'Total loss': 0.2274617528012634}
2022-12-31 12:49:04,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:04,116 INFO:     Epoch: 70
2022-12-31 12:49:05,701 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38451004574696224, 'Total loss': 0.38451004574696224} | train loss {'Reaction outcome loss': 0.21819865969383587, 'Total loss': 0.21819865969383587}
2022-12-31 12:49:05,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:05,701 INFO:     Epoch: 71
2022-12-31 12:49:07,314 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4396367291609446, 'Total loss': 0.4396367291609446} | train loss {'Reaction outcome loss': 0.21989699075148053, 'Total loss': 0.21989699075148053}
2022-12-31 12:49:07,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:07,315 INFO:     Epoch: 72
2022-12-31 12:49:08,923 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42463312645753226, 'Total loss': 0.42463312645753226} | train loss {'Reaction outcome loss': 0.2261706119688758, 'Total loss': 0.2261706119688758}
2022-12-31 12:49:08,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:08,923 INFO:     Epoch: 73
2022-12-31 12:49:10,568 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4474784076213837, 'Total loss': 0.4474784076213837} | train loss {'Reaction outcome loss': 0.22065129681714696, 'Total loss': 0.22065129681714696}
2022-12-31 12:49:10,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:10,569 INFO:     Epoch: 74
2022-12-31 12:49:12,158 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3733789493640264, 'Total loss': 0.3733789493640264} | train loss {'Reaction outcome loss': 0.21980765637309446, 'Total loss': 0.21980765637309446}
2022-12-31 12:49:12,158 INFO:     Found new best model at epoch 74
2022-12-31 12:49:12,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:12,159 INFO:     Epoch: 75
2022-12-31 12:49:13,803 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47563598056634265, 'Total loss': 0.47563598056634265} | train loss {'Reaction outcome loss': 0.2221944899753715, 'Total loss': 0.2221944899753715}
2022-12-31 12:49:13,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:13,804 INFO:     Epoch: 76
2022-12-31 12:49:15,417 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42730622192223866, 'Total loss': 0.42730622192223866} | train loss {'Reaction outcome loss': 0.2218659774053597, 'Total loss': 0.2218659774053597}
2022-12-31 12:49:15,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:15,417 INFO:     Epoch: 77
2022-12-31 12:49:17,023 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4690791596968969, 'Total loss': 0.4690791596968969} | train loss {'Reaction outcome loss': 0.21663773592126412, 'Total loss': 0.21663773592126412}
2022-12-31 12:49:17,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:17,024 INFO:     Epoch: 78
2022-12-31 12:49:18,642 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4663019220034281, 'Total loss': 0.4663019220034281} | train loss {'Reaction outcome loss': 0.2134633223206675, 'Total loss': 0.2134633223206675}
2022-12-31 12:49:18,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:18,642 INFO:     Epoch: 79
2022-12-31 12:49:20,240 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41130224863688153, 'Total loss': 0.41130224863688153} | train loss {'Reaction outcome loss': 0.2179924589139919, 'Total loss': 0.2179924589139919}
2022-12-31 12:49:20,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:20,240 INFO:     Epoch: 80
2022-12-31 12:49:21,840 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42332582275072733, 'Total loss': 0.42332582275072733} | train loss {'Reaction outcome loss': 0.21847626182461416, 'Total loss': 0.21847626182461416}
2022-12-31 12:49:21,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:21,840 INFO:     Epoch: 81
2022-12-31 12:49:23,450 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4237757886449496, 'Total loss': 0.4237757886449496} | train loss {'Reaction outcome loss': 0.21457473514941486, 'Total loss': 0.21457473514941486}
2022-12-31 12:49:23,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:23,450 INFO:     Epoch: 82
2022-12-31 12:49:25,042 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4607068161169688, 'Total loss': 0.4607068161169688} | train loss {'Reaction outcome loss': 0.2128738742525669, 'Total loss': 0.2128738742525669}
2022-12-31 12:49:25,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:25,043 INFO:     Epoch: 83
2022-12-31 12:49:26,646 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4431870847940445, 'Total loss': 0.4431870847940445} | train loss {'Reaction outcome loss': 0.21858261524271355, 'Total loss': 0.21858261524271355}
2022-12-31 12:49:26,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:26,646 INFO:     Epoch: 84
2022-12-31 12:49:28,257 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4368715137243271, 'Total loss': 0.4368715137243271} | train loss {'Reaction outcome loss': 0.20642296387983936, 'Total loss': 0.20642296387983936}
2022-12-31 12:49:28,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:28,257 INFO:     Epoch: 85
2022-12-31 12:49:29,842 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4153684298197428, 'Total loss': 0.4153684298197428} | train loss {'Reaction outcome loss': 0.20415742181404664, 'Total loss': 0.20415742181404664}
2022-12-31 12:49:29,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:29,842 INFO:     Epoch: 86
2022-12-31 12:49:31,479 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42462405959765115, 'Total loss': 0.42462405959765115} | train loss {'Reaction outcome loss': 0.20841444217783472, 'Total loss': 0.20841444217783472}
2022-12-31 12:49:31,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:31,480 INFO:     Epoch: 87
2022-12-31 12:49:33,069 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39382280011971793, 'Total loss': 0.39382280011971793} | train loss {'Reaction outcome loss': 0.2002165270833312, 'Total loss': 0.2002165270833312}
2022-12-31 12:49:33,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:33,070 INFO:     Epoch: 88
2022-12-31 12:49:34,677 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41666614810625713, 'Total loss': 0.41666614810625713} | train loss {'Reaction outcome loss': 0.20685664304688464, 'Total loss': 0.20685664304688464}
2022-12-31 12:49:34,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:34,678 INFO:     Epoch: 89
2022-12-31 12:49:36,316 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4147220631440481, 'Total loss': 0.4147220631440481} | train loss {'Reaction outcome loss': 0.20328690873010316, 'Total loss': 0.20328690873010316}
2022-12-31 12:49:36,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:36,316 INFO:     Epoch: 90
2022-12-31 12:49:37,924 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4194067696730296, 'Total loss': 0.4194067696730296} | train loss {'Reaction outcome loss': 0.19826953990697643, 'Total loss': 0.19826953990697643}
2022-12-31 12:49:37,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:37,925 INFO:     Epoch: 91
2022-12-31 12:49:39,510 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43993653655052184, 'Total loss': 0.43993653655052184} | train loss {'Reaction outcome loss': 0.20386922920979286, 'Total loss': 0.20386922920979286}
2022-12-31 12:49:39,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:39,510 INFO:     Epoch: 92
2022-12-31 12:49:41,124 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47836622496445974, 'Total loss': 0.47836622496445974} | train loss {'Reaction outcome loss': 0.20056129828856809, 'Total loss': 0.20056129828856809}
2022-12-31 12:49:41,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:41,124 INFO:     Epoch: 93
2022-12-31 12:49:42,712 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41612478892008464, 'Total loss': 0.41612478892008464} | train loss {'Reaction outcome loss': 0.2043186883938356, 'Total loss': 0.2043186883938356}
2022-12-31 12:49:42,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:42,712 INFO:     Epoch: 94
2022-12-31 12:49:44,312 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4138372752815485, 'Total loss': 0.4138372752815485} | train loss {'Reaction outcome loss': 0.20340241296012906, 'Total loss': 0.20340241296012906}
2022-12-31 12:49:44,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:44,313 INFO:     Epoch: 95
2022-12-31 12:49:45,911 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4598321954409281, 'Total loss': 0.4598321954409281} | train loss {'Reaction outcome loss': 0.20194699490157358, 'Total loss': 0.20194699490157358}
2022-12-31 12:49:45,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:45,911 INFO:     Epoch: 96
2022-12-31 12:49:47,500 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4035818063343565, 'Total loss': 0.4035818063343565} | train loss {'Reaction outcome loss': 0.19809439465621093, 'Total loss': 0.19809439465621093}
2022-12-31 12:49:47,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:47,500 INFO:     Epoch: 97
2022-12-31 12:49:49,109 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4451897700627645, 'Total loss': 0.4451897700627645} | train loss {'Reaction outcome loss': 0.20238500966751663, 'Total loss': 0.20238500966751663}
2022-12-31 12:49:49,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:49,109 INFO:     Epoch: 98
2022-12-31 12:49:50,707 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4441113034884135, 'Total loss': 0.4441113034884135} | train loss {'Reaction outcome loss': 0.1975549159938619, 'Total loss': 0.1975549159938619}
2022-12-31 12:49:50,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:50,707 INFO:     Epoch: 99
2022-12-31 12:49:52,291 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4091774582862854, 'Total loss': 0.4091774582862854} | train loss {'Reaction outcome loss': 0.19866640483076772, 'Total loss': 0.19866640483076772}
2022-12-31 12:49:52,291 INFO:     Best model found after epoch 75 of 100.
2022-12-31 12:49:52,292 INFO:   Done with stage: TRAINING
2022-12-31 12:49:52,292 INFO:   Starting stage: EVALUATION
2022-12-31 12:49:52,425 INFO:   Done with stage: EVALUATION
2022-12-31 12:49:52,425 INFO:   Leaving out SEQ value Fold_4
2022-12-31 12:49:52,438 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 12:49:52,438 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:49:53,094 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:49:53,094 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:49:53,161 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:49:53,162 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:49:53,162 INFO:     No hyperparam tuning for this model
2022-12-31 12:49:53,162 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:49:53,162 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:49:53,162 INFO:     None feature selector for col prot
2022-12-31 12:49:53,163 INFO:     None feature selector for col prot
2022-12-31 12:49:53,163 INFO:     None feature selector for col prot
2022-12-31 12:49:53,163 INFO:     None feature selector for col chem
2022-12-31 12:49:53,163 INFO:     None feature selector for col chem
2022-12-31 12:49:53,163 INFO:     None feature selector for col chem
2022-12-31 12:49:53,163 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:49:53,163 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:49:53,165 INFO:     Number of params in model 223921
2022-12-31 12:49:53,168 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:49:53,169 INFO:   Starting stage: TRAINING
2022-12-31 12:49:53,213 INFO:     Val loss before train {'Reaction outcome loss': 0.9555588106314341, 'Total loss': 0.9555588106314341}
2022-12-31 12:49:53,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:53,213 INFO:     Epoch: 0
2022-12-31 12:49:54,826 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6349684874216716, 'Total loss': 0.6349684874216716} | train loss {'Reaction outcome loss': 0.8227885591163151, 'Total loss': 0.8227885591163151}
2022-12-31 12:49:54,826 INFO:     Found new best model at epoch 0
2022-12-31 12:49:54,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:54,827 INFO:     Epoch: 1
2022-12-31 12:49:56,423 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5110583821932475, 'Total loss': 0.5110583821932475} | train loss {'Reaction outcome loss': 0.6027707836752676, 'Total loss': 0.6027707836752676}
2022-12-31 12:49:56,424 INFO:     Found new best model at epoch 1
2022-12-31 12:49:56,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:56,425 INFO:     Epoch: 2
2022-12-31 12:49:58,028 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4953002552191416, 'Total loss': 0.4953002552191416} | train loss {'Reaction outcome loss': 0.5274317004562666, 'Total loss': 0.5274317004562666}
2022-12-31 12:49:58,028 INFO:     Found new best model at epoch 2
2022-12-31 12:49:58,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:58,029 INFO:     Epoch: 3
2022-12-31 12:49:59,657 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5012711892525356, 'Total loss': 0.5012711892525356} | train loss {'Reaction outcome loss': 0.4987786553497574, 'Total loss': 0.4987786553497574}
2022-12-31 12:49:59,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:49:59,658 INFO:     Epoch: 4
2022-12-31 12:50:01,251 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5058984875679016, 'Total loss': 0.5058984875679016} | train loss {'Reaction outcome loss': 0.4827692046714272, 'Total loss': 0.4827692046714272}
2022-12-31 12:50:01,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:01,251 INFO:     Epoch: 5
2022-12-31 12:50:02,871 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5143499175707499, 'Total loss': 0.5143499175707499} | train loss {'Reaction outcome loss': 0.4741994419468938, 'Total loss': 0.4741994419468938}
2022-12-31 12:50:02,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:02,872 INFO:     Epoch: 6
2022-12-31 12:50:04,482 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46010802884896596, 'Total loss': 0.46010802884896596} | train loss {'Reaction outcome loss': 0.466980266560247, 'Total loss': 0.466980266560247}
2022-12-31 12:50:04,482 INFO:     Found new best model at epoch 6
2022-12-31 12:50:04,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:04,483 INFO:     Epoch: 7
2022-12-31 12:50:06,082 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.465422131617864, 'Total loss': 0.465422131617864} | train loss {'Reaction outcome loss': 0.4610168705491916, 'Total loss': 0.4610168705491916}
2022-12-31 12:50:06,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:06,082 INFO:     Epoch: 8
2022-12-31 12:50:07,694 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46478437383969623, 'Total loss': 0.46478437383969623} | train loss {'Reaction outcome loss': 0.45598292186796374, 'Total loss': 0.45598292186796374}
2022-12-31 12:50:07,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:07,695 INFO:     Epoch: 9
2022-12-31 12:50:09,297 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4792852838834127, 'Total loss': 0.4792852838834127} | train loss {'Reaction outcome loss': 0.45463735016359796, 'Total loss': 0.45463735016359796}
2022-12-31 12:50:09,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:09,297 INFO:     Epoch: 10
2022-12-31 12:50:10,901 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48128454287846884, 'Total loss': 0.48128454287846884} | train loss {'Reaction outcome loss': 0.46023755577511954, 'Total loss': 0.46023755577511954}
2022-12-31 12:50:10,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:10,902 INFO:     Epoch: 11
2022-12-31 12:50:12,539 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44842201471328735, 'Total loss': 0.44842201471328735} | train loss {'Reaction outcome loss': 0.4371892196122908, 'Total loss': 0.4371892196122908}
2022-12-31 12:50:12,540 INFO:     Found new best model at epoch 11
2022-12-31 12:50:12,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:12,540 INFO:     Epoch: 12
2022-12-31 12:50:14,150 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4365191861987114, 'Total loss': 0.4365191861987114} | train loss {'Reaction outcome loss': 0.42787358401667164, 'Total loss': 0.42787358401667164}
2022-12-31 12:50:14,150 INFO:     Found new best model at epoch 12
2022-12-31 12:50:14,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:14,151 INFO:     Epoch: 13
2022-12-31 12:50:15,750 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4706081648667653, 'Total loss': 0.4706081648667653} | train loss {'Reaction outcome loss': 0.41950809359010577, 'Total loss': 0.41950809359010577}
2022-12-31 12:50:15,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:15,750 INFO:     Epoch: 14
2022-12-31 12:50:17,361 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4500401596228282, 'Total loss': 0.4500401596228282} | train loss {'Reaction outcome loss': 0.42307924437657185, 'Total loss': 0.42307924437657185}
2022-12-31 12:50:17,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:17,361 INFO:     Epoch: 15
2022-12-31 12:50:18,981 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4754598617553711, 'Total loss': 0.4754598617553711} | train loss {'Reaction outcome loss': 0.4161402429723977, 'Total loss': 0.4161402429723977}
2022-12-31 12:50:18,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:18,982 INFO:     Epoch: 16
2022-12-31 12:50:20,634 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42450594504674277, 'Total loss': 0.42450594504674277} | train loss {'Reaction outcome loss': 0.41232054251367634, 'Total loss': 0.41232054251367634}
2022-12-31 12:50:20,634 INFO:     Found new best model at epoch 16
2022-12-31 12:50:20,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:20,635 INFO:     Epoch: 17
2022-12-31 12:50:22,272 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4830342988173167, 'Total loss': 0.4830342988173167} | train loss {'Reaction outcome loss': 0.4030306120892393, 'Total loss': 0.4030306120892393}
2022-12-31 12:50:22,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:22,273 INFO:     Epoch: 18
2022-12-31 12:50:23,882 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44608663419882455, 'Total loss': 0.44608663419882455} | train loss {'Reaction outcome loss': 0.39742671575378696, 'Total loss': 0.39742671575378696}
2022-12-31 12:50:23,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:23,882 INFO:     Epoch: 19
2022-12-31 12:50:25,480 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44813791712125145, 'Total loss': 0.44813791712125145} | train loss {'Reaction outcome loss': 0.39203805858404306, 'Total loss': 0.39203805858404306}
2022-12-31 12:50:25,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:25,481 INFO:     Epoch: 20
2022-12-31 12:50:27,072 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4352104365825653, 'Total loss': 0.4352104365825653} | train loss {'Reaction outcome loss': 0.3904148214471101, 'Total loss': 0.3904148214471101}
2022-12-31 12:50:27,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:27,073 INFO:     Epoch: 21
2022-12-31 12:50:28,711 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4481830100218455, 'Total loss': 0.4481830100218455} | train loss {'Reaction outcome loss': 0.3887496249695667, 'Total loss': 0.3887496249695667}
2022-12-31 12:50:28,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:28,711 INFO:     Epoch: 22
2022-12-31 12:50:30,358 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4266812731822332, 'Total loss': 0.4266812731822332} | train loss {'Reaction outcome loss': 0.38433508909698844, 'Total loss': 0.38433508909698844}
2022-12-31 12:50:30,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:30,358 INFO:     Epoch: 23
2022-12-31 12:50:31,952 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4462874005238215, 'Total loss': 0.4462874005238215} | train loss {'Reaction outcome loss': 0.4244464495106671, 'Total loss': 0.4244464495106671}
2022-12-31 12:50:31,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:31,952 INFO:     Epoch: 24
2022-12-31 12:50:33,559 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4241542756557465, 'Total loss': 0.4241542756557465} | train loss {'Reaction outcome loss': 0.3711571385139141, 'Total loss': 0.3711571385139141}
2022-12-31 12:50:33,560 INFO:     Found new best model at epoch 24
2022-12-31 12:50:33,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:33,561 INFO:     Epoch: 25
2022-12-31 12:50:35,209 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4157548685868581, 'Total loss': 0.4157548685868581} | train loss {'Reaction outcome loss': 0.36800221596891736, 'Total loss': 0.36800221596891736}
2022-12-31 12:50:35,209 INFO:     Found new best model at epoch 25
2022-12-31 12:50:35,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:35,210 INFO:     Epoch: 26
2022-12-31 12:50:36,828 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4587799688180288, 'Total loss': 0.4587799688180288} | train loss {'Reaction outcome loss': 0.3672400651553619, 'Total loss': 0.3672400651553619}
2022-12-31 12:50:36,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:36,828 INFO:     Epoch: 27
2022-12-31 12:50:38,476 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42521902918815613, 'Total loss': 0.42521902918815613} | train loss {'Reaction outcome loss': 0.402297541944553, 'Total loss': 0.402297541944553}
2022-12-31 12:50:38,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:38,477 INFO:     Epoch: 28
2022-12-31 12:50:40,107 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4556392729282379, 'Total loss': 0.4556392729282379} | train loss {'Reaction outcome loss': 0.35747471825469396, 'Total loss': 0.35747471825469396}
2022-12-31 12:50:40,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:40,107 INFO:     Epoch: 29
2022-12-31 12:50:41,729 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41795283506313957, 'Total loss': 0.41795283506313957} | train loss {'Reaction outcome loss': 0.34679428388303873, 'Total loss': 0.34679428388303873}
2022-12-31 12:50:41,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:41,729 INFO:     Epoch: 30
2022-12-31 12:50:43,372 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4201348582903544, 'Total loss': 0.4201348582903544} | train loss {'Reaction outcome loss': 0.34194162809728657, 'Total loss': 0.34194162809728657}
2022-12-31 12:50:43,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:43,372 INFO:     Epoch: 31
2022-12-31 12:50:44,974 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4187092423439026, 'Total loss': 0.4187092423439026} | train loss {'Reaction outcome loss': 0.3407767285724454, 'Total loss': 0.3407767285724454}
2022-12-31 12:50:44,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:44,974 INFO:     Epoch: 32
2022-12-31 12:50:46,603 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4522282868623734, 'Total loss': 0.4522282868623734} | train loss {'Reaction outcome loss': 0.3328844275320475, 'Total loss': 0.3328844275320475}
2022-12-31 12:50:46,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:46,604 INFO:     Epoch: 33
2022-12-31 12:50:48,199 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.396357050538063, 'Total loss': 0.396357050538063} | train loss {'Reaction outcome loss': 0.3301401571775584, 'Total loss': 0.3301401571775584}
2022-12-31 12:50:48,199 INFO:     Found new best model at epoch 33
2022-12-31 12:50:48,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:48,200 INFO:     Epoch: 34
2022-12-31 12:50:49,798 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41289590497811635, 'Total loss': 0.41289590497811635} | train loss {'Reaction outcome loss': 0.32852213122490526, 'Total loss': 0.32852213122490526}
2022-12-31 12:50:49,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:49,799 INFO:     Epoch: 35
2022-12-31 12:50:51,418 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.398561654984951, 'Total loss': 0.398561654984951} | train loss {'Reaction outcome loss': 0.3454079440106516, 'Total loss': 0.3454079440106516}
2022-12-31 12:50:51,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:51,418 INFO:     Epoch: 36
2022-12-31 12:50:53,057 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.425931715965271, 'Total loss': 0.425931715965271} | train loss {'Reaction outcome loss': 0.3597031167667845, 'Total loss': 0.3597031167667845}
2022-12-31 12:50:53,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:53,057 INFO:     Epoch: 37
2022-12-31 12:50:54,672 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4460782070954641, 'Total loss': 0.4460782070954641} | train loss {'Reaction outcome loss': 0.3611031731833582, 'Total loss': 0.3611031731833582}
2022-12-31 12:50:54,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:54,673 INFO:     Epoch: 38
2022-12-31 12:50:56,318 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4214375451207161, 'Total loss': 0.4214375451207161} | train loss {'Reaction outcome loss': 0.36525982323160017, 'Total loss': 0.36525982323160017}
2022-12-31 12:50:56,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:56,319 INFO:     Epoch: 39
2022-12-31 12:50:57,961 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40570707321166993, 'Total loss': 0.40570707321166993} | train loss {'Reaction outcome loss': 0.3255644829376884, 'Total loss': 0.3255644829376884}
2022-12-31 12:50:57,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:57,961 INFO:     Epoch: 40
2022-12-31 12:50:59,558 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4200104832649231, 'Total loss': 0.4200104832649231} | train loss {'Reaction outcome loss': 0.33021985889965855, 'Total loss': 0.33021985889965855}
2022-12-31 12:50:59,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:50:59,558 INFO:     Epoch: 41
2022-12-31 12:51:01,183 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3807316690683365, 'Total loss': 0.3807316690683365} | train loss {'Reaction outcome loss': 0.31111467683323374, 'Total loss': 0.31111467683323374}
2022-12-31 12:51:01,183 INFO:     Found new best model at epoch 41
2022-12-31 12:51:01,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:01,184 INFO:     Epoch: 42
2022-12-31 12:51:02,793 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40658872822920483, 'Total loss': 0.40658872822920483} | train loss {'Reaction outcome loss': 0.30689693192033557, 'Total loss': 0.30689693192033557}
2022-12-31 12:51:02,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:02,794 INFO:     Epoch: 43
2022-12-31 12:51:04,403 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4204436977704366, 'Total loss': 0.4204436977704366} | train loss {'Reaction outcome loss': 0.3037939664892569, 'Total loss': 0.3037939664892569}
2022-12-31 12:51:04,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:04,403 INFO:     Epoch: 44
2022-12-31 12:51:06,047 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45771480600039166, 'Total loss': 0.45771480600039166} | train loss {'Reaction outcome loss': 0.3048116879240758, 'Total loss': 0.3048116879240758}
2022-12-31 12:51:06,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:06,048 INFO:     Epoch: 45
2022-12-31 12:51:07,691 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4398346165815989, 'Total loss': 0.4398346165815989} | train loss {'Reaction outcome loss': 0.29751499379009033, 'Total loss': 0.29751499379009033}
2022-12-31 12:51:07,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:07,691 INFO:     Epoch: 46
2022-12-31 12:51:09,308 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4087043464183807, 'Total loss': 0.4087043464183807} | train loss {'Reaction outcome loss': 0.30011483111783216, 'Total loss': 0.30011483111783216}
2022-12-31 12:51:09,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:09,309 INFO:     Epoch: 47
2022-12-31 12:51:10,948 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4087796171506246, 'Total loss': 0.4087796171506246} | train loss {'Reaction outcome loss': 0.2913813877418853, 'Total loss': 0.2913813877418853}
2022-12-31 12:51:10,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:10,949 INFO:     Epoch: 48
2022-12-31 12:51:12,578 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4156585305929184, 'Total loss': 0.4156585305929184} | train loss {'Reaction outcome loss': 0.28605104733150505, 'Total loss': 0.28605104733150505}
2022-12-31 12:51:12,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:12,578 INFO:     Epoch: 49
2022-12-31 12:51:14,222 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4247461090485255, 'Total loss': 0.4247461090485255} | train loss {'Reaction outcome loss': 0.3041194786682077, 'Total loss': 0.3041194786682077}
2022-12-31 12:51:14,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:14,222 INFO:     Epoch: 50
2022-12-31 12:51:15,876 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37982582648595176, 'Total loss': 0.37982582648595176} | train loss {'Reaction outcome loss': 0.2844835147714126, 'Total loss': 0.2844835147714126}
2022-12-31 12:51:15,876 INFO:     Found new best model at epoch 50
2022-12-31 12:51:15,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:15,877 INFO:     Epoch: 51
2022-12-31 12:51:17,517 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4041833867629369, 'Total loss': 0.4041833867629369} | train loss {'Reaction outcome loss': 0.2798993319974861, 'Total loss': 0.2798993319974861}
2022-12-31 12:51:17,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:17,517 INFO:     Epoch: 52
2022-12-31 12:51:19,117 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37968453466892244, 'Total loss': 0.37968453466892244} | train loss {'Reaction outcome loss': 0.2870216264048434, 'Total loss': 0.2870216264048434}
2022-12-31 12:51:19,117 INFO:     Found new best model at epoch 52
2022-12-31 12:51:19,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:19,118 INFO:     Epoch: 53
2022-12-31 12:51:20,731 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42378578980763754, 'Total loss': 0.42378578980763754} | train loss {'Reaction outcome loss': 0.2838729729848927, 'Total loss': 0.2838729729848927}
2022-12-31 12:51:20,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:20,731 INFO:     Epoch: 54
2022-12-31 12:51:22,338 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.378754731019338, 'Total loss': 0.378754731019338} | train loss {'Reaction outcome loss': 0.3120674756423071, 'Total loss': 0.3120674756423071}
2022-12-31 12:51:22,339 INFO:     Found new best model at epoch 54
2022-12-31 12:51:22,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:22,339 INFO:     Epoch: 55
2022-12-31 12:51:23,988 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41020708680152895, 'Total loss': 0.41020708680152895} | train loss {'Reaction outcome loss': 0.28128726898453815, 'Total loss': 0.28128726898453815}
2022-12-31 12:51:23,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:23,988 INFO:     Epoch: 56
2022-12-31 12:51:25,622 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3797269374132156, 'Total loss': 0.3797269374132156} | train loss {'Reaction outcome loss': 0.27674231888638623, 'Total loss': 0.27674231888638623}
2022-12-31 12:51:25,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:25,622 INFO:     Epoch: 57
2022-12-31 12:51:27,219 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3689441800117493, 'Total loss': 0.3689441800117493} | train loss {'Reaction outcome loss': 0.27337581739909406, 'Total loss': 0.27337581739909406}
2022-12-31 12:51:27,219 INFO:     Found new best model at epoch 57
2022-12-31 12:51:27,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:27,220 INFO:     Epoch: 58
2022-12-31 12:51:28,860 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38925724824269614, 'Total loss': 0.38925724824269614} | train loss {'Reaction outcome loss': 0.27008525287543517, 'Total loss': 0.27008525287543517}
2022-12-31 12:51:28,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:28,861 INFO:     Epoch: 59
2022-12-31 12:51:30,472 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41710246006647744, 'Total loss': 0.41710246006647744} | train loss {'Reaction outcome loss': 0.2577923231545593, 'Total loss': 0.2577923231545593}
2022-12-31 12:51:30,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:30,473 INFO:     Epoch: 60
2022-12-31 12:51:32,085 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40477830171585083, 'Total loss': 0.40477830171585083} | train loss {'Reaction outcome loss': 0.2626544421533662, 'Total loss': 0.2626544421533662}
2022-12-31 12:51:32,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:32,085 INFO:     Epoch: 61
2022-12-31 12:51:33,707 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.395408754547437, 'Total loss': 0.395408754547437} | train loss {'Reaction outcome loss': 0.27265505983993626, 'Total loss': 0.27265505983993626}
2022-12-31 12:51:33,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:33,708 INFO:     Epoch: 62
2022-12-31 12:51:35,329 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45151998003323873, 'Total loss': 0.45151998003323873} | train loss {'Reaction outcome loss': 0.27282612737723166, 'Total loss': 0.27282612737723166}
2022-12-31 12:51:35,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:35,330 INFO:     Epoch: 63
2022-12-31 12:51:36,929 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42026894887288413, 'Total loss': 0.42026894887288413} | train loss {'Reaction outcome loss': 0.2573579255216485, 'Total loss': 0.2573579255216485}
2022-12-31 12:51:36,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:36,929 INFO:     Epoch: 64
2022-12-31 12:51:38,551 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4327760140101115, 'Total loss': 0.4327760140101115} | train loss {'Reaction outcome loss': 0.26660784360939177, 'Total loss': 0.26660784360939177}
2022-12-31 12:51:38,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:38,553 INFO:     Epoch: 65
2022-12-31 12:51:40,077 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4291730225086212, 'Total loss': 0.4291730225086212} | train loss {'Reaction outcome loss': 0.2873490191392931, 'Total loss': 0.2873490191392931}
2022-12-31 12:51:40,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:40,078 INFO:     Epoch: 66
2022-12-31 12:51:41,168 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39930691520373024, 'Total loss': 0.39930691520373024} | train loss {'Reaction outcome loss': 0.26397871324266103, 'Total loss': 0.26397871324266103}
2022-12-31 12:51:41,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:41,168 INFO:     Epoch: 67
2022-12-31 12:51:42,248 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37185838719209036, 'Total loss': 0.37185838719209036} | train loss {'Reaction outcome loss': 0.2553376991595344, 'Total loss': 0.2553376991595344}
2022-12-31 12:51:42,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:42,249 INFO:     Epoch: 68
2022-12-31 12:51:43,332 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39444654335578283, 'Total loss': 0.39444654335578283} | train loss {'Reaction outcome loss': 0.24810844345589378, 'Total loss': 0.24810844345589378}
2022-12-31 12:51:43,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:43,332 INFO:     Epoch: 69
2022-12-31 12:51:44,459 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4300088405609131, 'Total loss': 0.4300088405609131} | train loss {'Reaction outcome loss': 0.2540070583674368, 'Total loss': 0.2540070583674368}
2022-12-31 12:51:44,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:44,460 INFO:     Epoch: 70
2022-12-31 12:51:46,068 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43818953235944114, 'Total loss': 0.43818953235944114} | train loss {'Reaction outcome loss': 0.24429195817978377, 'Total loss': 0.24429195817978377}
2022-12-31 12:51:46,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:46,069 INFO:     Epoch: 71
2022-12-31 12:51:47,682 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39066648681958516, 'Total loss': 0.39066648681958516} | train loss {'Reaction outcome loss': 0.23724306354035987, 'Total loss': 0.23724306354035987}
2022-12-31 12:51:47,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:47,683 INFO:     Epoch: 72
2022-12-31 12:51:49,302 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39956278999646505, 'Total loss': 0.39956278999646505} | train loss {'Reaction outcome loss': 0.2540709166315155, 'Total loss': 0.2540709166315155}
2022-12-31 12:51:49,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:49,303 INFO:     Epoch: 73
2022-12-31 12:51:50,922 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.412497212489446, 'Total loss': 0.412497212489446} | train loss {'Reaction outcome loss': 0.27561993483222846, 'Total loss': 0.27561993483222846}
2022-12-31 12:51:50,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:50,922 INFO:     Epoch: 74
2022-12-31 12:51:52,524 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42317704210678736, 'Total loss': 0.42317704210678736} | train loss {'Reaction outcome loss': 0.2514785875596251, 'Total loss': 0.2514785875596251}
2022-12-31 12:51:52,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:52,524 INFO:     Epoch: 75
2022-12-31 12:51:54,131 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4312449057896932, 'Total loss': 0.4312449057896932} | train loss {'Reaction outcome loss': 0.24763635250375324, 'Total loss': 0.24763635250375324}
2022-12-31 12:51:54,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:54,131 INFO:     Epoch: 76
2022-12-31 12:51:55,754 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3911363919576009, 'Total loss': 0.3911363919576009} | train loss {'Reaction outcome loss': 0.2361741460846278, 'Total loss': 0.2361741460846278}
2022-12-31 12:51:55,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:55,754 INFO:     Epoch: 77
2022-12-31 12:51:57,403 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4249976893266042, 'Total loss': 0.4249976893266042} | train loss {'Reaction outcome loss': 0.2425109965261072, 'Total loss': 0.2425109965261072}
2022-12-31 12:51:57,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:57,403 INFO:     Epoch: 78
2022-12-31 12:51:59,032 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4284140557050705, 'Total loss': 0.4284140557050705} | train loss {'Reaction outcome loss': 0.23385598171549593, 'Total loss': 0.23385598171549593}
2022-12-31 12:51:59,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:51:59,032 INFO:     Epoch: 79
2022-12-31 12:52:00,649 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3732174346844355, 'Total loss': 0.3732174346844355} | train loss {'Reaction outcome loss': 0.253691041747621, 'Total loss': 0.253691041747621}
2022-12-31 12:52:00,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:00,649 INFO:     Epoch: 80
2022-12-31 12:52:02,263 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40547856291135154, 'Total loss': 0.40547856291135154} | train loss {'Reaction outcome loss': 0.24301886066551442, 'Total loss': 0.24301886066551442}
2022-12-31 12:52:02,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:02,263 INFO:     Epoch: 81
2022-12-31 12:52:03,886 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42531526982784273, 'Total loss': 0.42531526982784273} | train loss {'Reaction outcome loss': 0.22887946512934793, 'Total loss': 0.22887946512934793}
2022-12-31 12:52:03,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:03,886 INFO:     Epoch: 82
2022-12-31 12:52:05,527 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3919454991817474, 'Total loss': 0.3919454991817474} | train loss {'Reaction outcome loss': 0.23306936506296683, 'Total loss': 0.23306936506296683}
2022-12-31 12:52:05,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:05,527 INFO:     Epoch: 83
2022-12-31 12:52:07,146 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39085783759752907, 'Total loss': 0.39085783759752907} | train loss {'Reaction outcome loss': 0.23039131869386503, 'Total loss': 0.23039131869386503}
2022-12-31 12:52:07,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:07,146 INFO:     Epoch: 84
2022-12-31 12:52:08,759 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42619625528653465, 'Total loss': 0.42619625528653465} | train loss {'Reaction outcome loss': 0.23975283393393393, 'Total loss': 0.23975283393393393}
2022-12-31 12:52:08,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:08,760 INFO:     Epoch: 85
2022-12-31 12:52:10,359 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4223929891983668, 'Total loss': 0.4223929891983668} | train loss {'Reaction outcome loss': 0.2326746924334894, 'Total loss': 0.2326746924334894}
2022-12-31 12:52:10,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:10,359 INFO:     Epoch: 86
2022-12-31 12:52:11,960 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42036854326725004, 'Total loss': 0.42036854326725004} | train loss {'Reaction outcome loss': 0.2332831405379904, 'Total loss': 0.2332831405379904}
2022-12-31 12:52:11,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:11,960 INFO:     Epoch: 87
2022-12-31 12:52:13,580 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4022829353809357, 'Total loss': 0.4022829353809357} | train loss {'Reaction outcome loss': 0.22791553327840738, 'Total loss': 0.22791553327840738}
2022-12-31 12:52:13,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:13,581 INFO:     Epoch: 88
2022-12-31 12:52:15,197 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4013869047164917, 'Total loss': 0.4013869047164917} | train loss {'Reaction outcome loss': 0.2206702224779081, 'Total loss': 0.2206702224779081}
2022-12-31 12:52:15,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:15,197 INFO:     Epoch: 89
2022-12-31 12:52:16,814 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4016706424454848, 'Total loss': 0.4016706424454848} | train loss {'Reaction outcome loss': 0.22578901277713315, 'Total loss': 0.22578901277713315}
2022-12-31 12:52:16,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:16,815 INFO:     Epoch: 90
2022-12-31 12:52:18,465 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4119728714227676, 'Total loss': 0.4119728714227676} | train loss {'Reaction outcome loss': 0.22509558200566232, 'Total loss': 0.22509558200566232}
2022-12-31 12:52:18,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:18,465 INFO:     Epoch: 91
2022-12-31 12:52:20,084 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39959225753943123, 'Total loss': 0.39959225753943123} | train loss {'Reaction outcome loss': 0.23651226092055289, 'Total loss': 0.23651226092055289}
2022-12-31 12:52:20,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:20,085 INFO:     Epoch: 92
2022-12-31 12:52:21,699 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42374177277088165, 'Total loss': 0.42374177277088165} | train loss {'Reaction outcome loss': 0.21984167566077542, 'Total loss': 0.21984167566077542}
2022-12-31 12:52:21,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:21,700 INFO:     Epoch: 93
2022-12-31 12:52:23,369 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3873370309670766, 'Total loss': 0.3873370309670766} | train loss {'Reaction outcome loss': 0.22132225606617503, 'Total loss': 0.22132225606617503}
2022-12-31 12:52:23,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:23,369 INFO:     Epoch: 94
2022-12-31 12:52:25,028 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3709537734587987, 'Total loss': 0.3709537734587987} | train loss {'Reaction outcome loss': 0.21723694113999323, 'Total loss': 0.21723694113999323}
2022-12-31 12:52:25,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:25,028 INFO:     Epoch: 95
2022-12-31 12:52:26,698 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4093368122975031, 'Total loss': 0.4093368122975031} | train loss {'Reaction outcome loss': 0.21206082839626764, 'Total loss': 0.21206082839626764}
2022-12-31 12:52:26,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:26,698 INFO:     Epoch: 96
2022-12-31 12:52:28,367 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40602555871009827, 'Total loss': 0.40602555871009827} | train loss {'Reaction outcome loss': 0.21780711910817088, 'Total loss': 0.21780711910817088}
2022-12-31 12:52:28,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:28,367 INFO:     Epoch: 97
2022-12-31 12:52:29,985 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4550609568754832, 'Total loss': 0.4550609568754832} | train loss {'Reaction outcome loss': 0.2163045033820959, 'Total loss': 0.2163045033820959}
2022-12-31 12:52:29,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:29,985 INFO:     Epoch: 98
2022-12-31 12:52:31,608 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40265821715195976, 'Total loss': 0.40265821715195976} | train loss {'Reaction outcome loss': 0.2205502372133829, 'Total loss': 0.2205502372133829}
2022-12-31 12:52:31,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:31,608 INFO:     Epoch: 99
2022-12-31 12:52:33,269 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40797699689865113, 'Total loss': 0.40797699689865113} | train loss {'Reaction outcome loss': 0.2135215772828762, 'Total loss': 0.2135215772828762}
2022-12-31 12:52:33,270 INFO:     Best model found after epoch 58 of 100.
2022-12-31 12:52:33,270 INFO:   Done with stage: TRAINING
2022-12-31 12:52:33,270 INFO:   Starting stage: EVALUATION
2022-12-31 12:52:33,399 INFO:   Done with stage: EVALUATION
2022-12-31 12:52:33,399 INFO:   Leaving out SEQ value Fold_5
2022-12-31 12:52:33,411 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 12:52:33,411 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:52:34,054 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:52:34,054 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:52:34,122 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:52:34,122 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:52:34,123 INFO:     No hyperparam tuning for this model
2022-12-31 12:52:34,123 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:52:34,123 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:52:34,123 INFO:     None feature selector for col prot
2022-12-31 12:52:34,123 INFO:     None feature selector for col prot
2022-12-31 12:52:34,124 INFO:     None feature selector for col prot
2022-12-31 12:52:34,124 INFO:     None feature selector for col chem
2022-12-31 12:52:34,124 INFO:     None feature selector for col chem
2022-12-31 12:52:34,124 INFO:     None feature selector for col chem
2022-12-31 12:52:34,124 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:52:34,124 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:52:34,126 INFO:     Number of params in model 223921
2022-12-31 12:52:34,129 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:52:34,129 INFO:   Starting stage: TRAINING
2022-12-31 12:52:34,176 INFO:     Val loss before train {'Reaction outcome loss': 1.0318481961886088, 'Total loss': 1.0318481961886088}
2022-12-31 12:52:34,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:34,176 INFO:     Epoch: 0
2022-12-31 12:52:35,795 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7170600851376852, 'Total loss': 0.7170600851376852} | train loss {'Reaction outcome loss': 0.8151694979059739, 'Total loss': 0.8151694979059739}
2022-12-31 12:52:35,795 INFO:     Found new best model at epoch 0
2022-12-31 12:52:35,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:35,796 INFO:     Epoch: 1
2022-12-31 12:52:37,418 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5665305346250534, 'Total loss': 0.5665305346250534} | train loss {'Reaction outcome loss': 0.6017689201170984, 'Total loss': 0.6017689201170984}
2022-12-31 12:52:37,418 INFO:     Found new best model at epoch 1
2022-12-31 12:52:37,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:37,419 INFO:     Epoch: 2
2022-12-31 12:52:39,019 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5345943609873454, 'Total loss': 0.5345943609873454} | train loss {'Reaction outcome loss': 0.522432181444289, 'Total loss': 0.522432181444289}
2022-12-31 12:52:39,019 INFO:     Found new best model at epoch 2
2022-12-31 12:52:39,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:39,020 INFO:     Epoch: 3
2022-12-31 12:52:40,632 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5448495397965113, 'Total loss': 0.5448495397965113} | train loss {'Reaction outcome loss': 0.49904613607171655, 'Total loss': 0.49904613607171655}
2022-12-31 12:52:40,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:40,632 INFO:     Epoch: 4
2022-12-31 12:52:42,297 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5074662427107494, 'Total loss': 0.5074662427107494} | train loss {'Reaction outcome loss': 0.4906066771313224, 'Total loss': 0.4906066771313224}
2022-12-31 12:52:42,297 INFO:     Found new best model at epoch 4
2022-12-31 12:52:42,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:42,298 INFO:     Epoch: 5
2022-12-31 12:52:43,934 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5114789525667827, 'Total loss': 0.5114789525667827} | train loss {'Reaction outcome loss': 0.4688813510170355, 'Total loss': 0.4688813510170355}
2022-12-31 12:52:43,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:43,934 INFO:     Epoch: 6
2022-12-31 12:52:45,598 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5055920680363973, 'Total loss': 0.5055920680363973} | train loss {'Reaction outcome loss': 0.46564899379576463, 'Total loss': 0.46564899379576463}
2022-12-31 12:52:45,598 INFO:     Found new best model at epoch 6
2022-12-31 12:52:45,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:45,599 INFO:     Epoch: 7
2022-12-31 12:52:47,199 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48811841805775963, 'Total loss': 0.48811841805775963} | train loss {'Reaction outcome loss': 0.47196355771123216, 'Total loss': 0.47196355771123216}
2022-12-31 12:52:47,199 INFO:     Found new best model at epoch 7
2022-12-31 12:52:47,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:47,200 INFO:     Epoch: 8
2022-12-31 12:52:48,813 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4968728164831797, 'Total loss': 0.4968728164831797} | train loss {'Reaction outcome loss': 0.4639850548212079, 'Total loss': 0.4639850548212079}
2022-12-31 12:52:48,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:48,813 INFO:     Epoch: 9
2022-12-31 12:52:50,435 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4889106790224711, 'Total loss': 0.4889106790224711} | train loss {'Reaction outcome loss': 0.4592713524277012, 'Total loss': 0.4592713524277012}
2022-12-31 12:52:50,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:50,436 INFO:     Epoch: 10
2022-12-31 12:52:52,056 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49891094168027245, 'Total loss': 0.49891094168027245} | train loss {'Reaction outcome loss': 0.4475835479957902, 'Total loss': 0.4475835479957902}
2022-12-31 12:52:52,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:52,056 INFO:     Epoch: 11
2022-12-31 12:52:53,678 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4875331103801727, 'Total loss': 0.4875331103801727} | train loss {'Reaction outcome loss': 0.45196263332837733, 'Total loss': 0.45196263332837733}
2022-12-31 12:52:53,679 INFO:     Found new best model at epoch 11
2022-12-31 12:52:53,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:53,679 INFO:     Epoch: 12
2022-12-31 12:52:55,300 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4778924306233724, 'Total loss': 0.4778924306233724} | train loss {'Reaction outcome loss': 0.43069237023187074, 'Total loss': 0.43069237023187074}
2022-12-31 12:52:55,301 INFO:     Found new best model at epoch 12
2022-12-31 12:52:55,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:55,302 INFO:     Epoch: 13
2022-12-31 12:52:56,924 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48756867249806723, 'Total loss': 0.48756867249806723} | train loss {'Reaction outcome loss': 0.42717017023318, 'Total loss': 0.42717017023318}
2022-12-31 12:52:56,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:56,925 INFO:     Epoch: 14
2022-12-31 12:52:58,570 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47238100270430244, 'Total loss': 0.47238100270430244} | train loss {'Reaction outcome loss': 0.4202028330553836, 'Total loss': 0.4202028330553836}
2022-12-31 12:52:58,570 INFO:     Found new best model at epoch 14
2022-12-31 12:52:58,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:52:58,571 INFO:     Epoch: 15
2022-12-31 12:53:00,203 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4977982580661774, 'Total loss': 0.4977982580661774} | train loss {'Reaction outcome loss': 0.4126630444889483, 'Total loss': 0.4126630444889483}
2022-12-31 12:53:00,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:00,203 INFO:     Epoch: 16
2022-12-31 12:53:01,832 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4980953236420949, 'Total loss': 0.4980953236420949} | train loss {'Reaction outcome loss': 0.4143296245323575, 'Total loss': 0.4143296245323575}
2022-12-31 12:53:01,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:01,832 INFO:     Epoch: 17
2022-12-31 12:53:03,452 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4961521069208781, 'Total loss': 0.4961521069208781} | train loss {'Reaction outcome loss': 0.42523484326058836, 'Total loss': 0.42523484326058836}
2022-12-31 12:53:03,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:03,452 INFO:     Epoch: 18
2022-12-31 12:53:05,058 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49068551063537597, 'Total loss': 0.49068551063537597} | train loss {'Reaction outcome loss': 0.3967106949193808, 'Total loss': 0.3967106949193808}
2022-12-31 12:53:05,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:05,058 INFO:     Epoch: 19
2022-12-31 12:53:06,656 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47526104748249054, 'Total loss': 0.47526104748249054} | train loss {'Reaction outcome loss': 0.3934725293471221, 'Total loss': 0.3934725293471221}
2022-12-31 12:53:06,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:06,656 INFO:     Epoch: 20
2022-12-31 12:53:08,304 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4696255028247833, 'Total loss': 0.4696255028247833} | train loss {'Reaction outcome loss': 0.3901762101736824, 'Total loss': 0.3901762101736824}
2022-12-31 12:53:08,304 INFO:     Found new best model at epoch 20
2022-12-31 12:53:08,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:08,305 INFO:     Epoch: 21
2022-12-31 12:53:09,956 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4786041816075643, 'Total loss': 0.4786041816075643} | train loss {'Reaction outcome loss': 0.38672627476246463, 'Total loss': 0.38672627476246463}
2022-12-31 12:53:09,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:09,957 INFO:     Epoch: 22
2022-12-31 12:53:11,574 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45787429610888164, 'Total loss': 0.45787429610888164} | train loss {'Reaction outcome loss': 0.37603930481832387, 'Total loss': 0.37603930481832387}
2022-12-31 12:53:11,575 INFO:     Found new best model at epoch 22
2022-12-31 12:53:11,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:11,576 INFO:     Epoch: 23
2022-12-31 12:53:13,193 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5115755061308543, 'Total loss': 0.5115755061308543} | train loss {'Reaction outcome loss': 0.3722805138947307, 'Total loss': 0.3722805138947307}
2022-12-31 12:53:13,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:13,193 INFO:     Epoch: 24
2022-12-31 12:53:14,792 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48152125577131905, 'Total loss': 0.48152125577131905} | train loss {'Reaction outcome loss': 0.383904376566626, 'Total loss': 0.383904376566626}
2022-12-31 12:53:14,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:14,792 INFO:     Epoch: 25
2022-12-31 12:53:16,412 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44791289965311687, 'Total loss': 0.44791289965311687} | train loss {'Reaction outcome loss': 0.4045739375270795, 'Total loss': 0.4045739375270795}
2022-12-31 12:53:16,413 INFO:     Found new best model at epoch 25
2022-12-31 12:53:16,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:16,414 INFO:     Epoch: 26
2022-12-31 12:53:18,075 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47960867087046305, 'Total loss': 0.47960867087046305} | train loss {'Reaction outcome loss': 0.3804687534229479, 'Total loss': 0.3804687534229479}
2022-12-31 12:53:18,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:18,076 INFO:     Epoch: 27
2022-12-31 12:53:19,697 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4948432773351669, 'Total loss': 0.4948432773351669} | train loss {'Reaction outcome loss': 0.3645101873190615, 'Total loss': 0.3645101873190615}
2022-12-31 12:53:19,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:19,697 INFO:     Epoch: 28
2022-12-31 12:53:21,319 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4743588944276174, 'Total loss': 0.4743588944276174} | train loss {'Reaction outcome loss': 0.35976473352723365, 'Total loss': 0.35976473352723365}
2022-12-31 12:53:21,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:21,319 INFO:     Epoch: 29
2022-12-31 12:53:22,946 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4775949815909068, 'Total loss': 0.4775949815909068} | train loss {'Reaction outcome loss': 0.40263684743473754, 'Total loss': 0.40263684743473754}
2022-12-31 12:53:22,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:22,946 INFO:     Epoch: 30
2022-12-31 12:53:24,577 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47910731434822085, 'Total loss': 0.47910731434822085} | train loss {'Reaction outcome loss': 0.3548033375131047, 'Total loss': 0.3548033375131047}
2022-12-31 12:53:24,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:24,577 INFO:     Epoch: 31
2022-12-31 12:53:26,183 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47225088874499005, 'Total loss': 0.47225088874499005} | train loss {'Reaction outcome loss': 0.3738047030754493, 'Total loss': 0.3738047030754493}
2022-12-31 12:53:26,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:26,184 INFO:     Epoch: 32
2022-12-31 12:53:27,801 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4746710270643234, 'Total loss': 0.4746710270643234} | train loss {'Reaction outcome loss': 0.33685125712565056, 'Total loss': 0.33685125712565056}
2022-12-31 12:53:27,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:27,802 INFO:     Epoch: 33
2022-12-31 12:53:29,420 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4638401468594869, 'Total loss': 0.4638401468594869} | train loss {'Reaction outcome loss': 0.3392941377461429, 'Total loss': 0.3392941377461429}
2022-12-31 12:53:29,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:29,420 INFO:     Epoch: 34
2022-12-31 12:53:31,039 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4864622751871745, 'Total loss': 0.4864622751871745} | train loss {'Reaction outcome loss': 0.33495224496510817, 'Total loss': 0.33495224496510817}
2022-12-31 12:53:31,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:31,039 INFO:     Epoch: 35
2022-12-31 12:53:32,656 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4696288009484609, 'Total loss': 0.4696288009484609} | train loss {'Reaction outcome loss': 0.32987770169595443, 'Total loss': 0.32987770169595443}
2022-12-31 12:53:32,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:32,657 INFO:     Epoch: 36
2022-12-31 12:53:34,264 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48344546854496, 'Total loss': 0.48344546854496} | train loss {'Reaction outcome loss': 0.3212999975629551, 'Total loss': 0.3212999975629551}
2022-12-31 12:53:34,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:34,264 INFO:     Epoch: 37
2022-12-31 12:53:35,878 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4397447029749552, 'Total loss': 0.4397447029749552} | train loss {'Reaction outcome loss': 0.31981607868397405, 'Total loss': 0.31981607868397405}
2022-12-31 12:53:35,878 INFO:     Found new best model at epoch 37
2022-12-31 12:53:35,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:35,879 INFO:     Epoch: 38
2022-12-31 12:53:37,493 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46375691294670107, 'Total loss': 0.46375691294670107} | train loss {'Reaction outcome loss': 0.3235829648953201, 'Total loss': 0.3235829648953201}
2022-12-31 12:53:37,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:37,493 INFO:     Epoch: 39
2022-12-31 12:53:39,107 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48974212606747947, 'Total loss': 0.48974212606747947} | train loss {'Reaction outcome loss': 0.3193042021028806, 'Total loss': 0.3193042021028806}
2022-12-31 12:53:39,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:39,107 INFO:     Epoch: 40
2022-12-31 12:53:40,722 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4713594436645508, 'Total loss': 0.4713594436645508} | train loss {'Reaction outcome loss': 0.35630848723045294, 'Total loss': 0.35630848723045294}
2022-12-31 12:53:40,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:40,722 INFO:     Epoch: 41
2022-12-31 12:53:42,324 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4855668306350708, 'Total loss': 0.4855668306350708} | train loss {'Reaction outcome loss': 0.3137765705747449, 'Total loss': 0.3137765705747449}
2022-12-31 12:53:42,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:42,324 INFO:     Epoch: 42
2022-12-31 12:53:43,940 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4564099947611491, 'Total loss': 0.4564099947611491} | train loss {'Reaction outcome loss': 0.31206318434451, 'Total loss': 0.31206318434451}
2022-12-31 12:53:43,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:43,940 INFO:     Epoch: 43
2022-12-31 12:53:45,575 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4528557618459066, 'Total loss': 0.4528557618459066} | train loss {'Reaction outcome loss': 0.307031759256632, 'Total loss': 0.307031759256632}
2022-12-31 12:53:45,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:45,576 INFO:     Epoch: 44
2022-12-31 12:53:47,188 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47366138100624083, 'Total loss': 0.47366138100624083} | train loss {'Reaction outcome loss': 0.3020454028189398, 'Total loss': 0.3020454028189398}
2022-12-31 12:53:47,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:47,188 INFO:     Epoch: 45
2022-12-31 12:53:48,804 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4632298519213994, 'Total loss': 0.4632298519213994} | train loss {'Reaction outcome loss': 0.29873121687737497, 'Total loss': 0.29873121687737497}
2022-12-31 12:53:48,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:48,804 INFO:     Epoch: 46
2022-12-31 12:53:50,406 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4581929882367452, 'Total loss': 0.4581929882367452} | train loss {'Reaction outcome loss': 0.2965461132858974, 'Total loss': 0.2965461132858974}
2022-12-31 12:53:50,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:50,406 INFO:     Epoch: 47
2022-12-31 12:53:52,013 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4534446795781453, 'Total loss': 0.4534446795781453} | train loss {'Reaction outcome loss': 0.29407688039962365, 'Total loss': 0.29407688039962365}
2022-12-31 12:53:52,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:52,013 INFO:     Epoch: 48
2022-12-31 12:53:53,645 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4707119623819987, 'Total loss': 0.4707119623819987} | train loss {'Reaction outcome loss': 0.2988305706463322, 'Total loss': 0.2988305706463322}
2022-12-31 12:53:53,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:53,645 INFO:     Epoch: 49
2022-12-31 12:53:55,261 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48807023068269095, 'Total loss': 0.48807023068269095} | train loss {'Reaction outcome loss': 0.33412533148235735, 'Total loss': 0.33412533148235735}
2022-12-31 12:53:55,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:55,261 INFO:     Epoch: 50
2022-12-31 12:53:56,870 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45205412060022354, 'Total loss': 0.45205412060022354} | train loss {'Reaction outcome loss': 0.29963563902023505, 'Total loss': 0.29963563902023505}
2022-12-31 12:53:56,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:56,870 INFO:     Epoch: 51
2022-12-31 12:53:58,517 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46818124850591025, 'Total loss': 0.46818124850591025} | train loss {'Reaction outcome loss': 0.29396620546670066, 'Total loss': 0.29396620546670066}
2022-12-31 12:53:58,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:53:58,517 INFO:     Epoch: 52
2022-12-31 12:54:00,124 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4463894824186961, 'Total loss': 0.4463894824186961} | train loss {'Reaction outcome loss': 0.28409075630286457, 'Total loss': 0.28409075630286457}
2022-12-31 12:54:00,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:00,124 INFO:     Epoch: 53
2022-12-31 12:54:01,750 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48682956794897714, 'Total loss': 0.48682956794897714} | train loss {'Reaction outcome loss': 0.28357733767971577, 'Total loss': 0.28357733767971577}
2022-12-31 12:54:01,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:01,751 INFO:     Epoch: 54
2022-12-31 12:54:03,367 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4212064842383067, 'Total loss': 0.4212064842383067} | train loss {'Reaction outcome loss': 0.2791000667086759, 'Total loss': 0.2791000667086759}
2022-12-31 12:54:03,368 INFO:     Found new best model at epoch 54
2022-12-31 12:54:03,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:03,369 INFO:     Epoch: 55
2022-12-31 12:54:04,984 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4533188124497732, 'Total loss': 0.4533188124497732} | train loss {'Reaction outcome loss': 0.2725278161935579, 'Total loss': 0.2725278161935579}
2022-12-31 12:54:04,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:04,985 INFO:     Epoch: 56
2022-12-31 12:54:06,601 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48200954000155133, 'Total loss': 0.48200954000155133} | train loss {'Reaction outcome loss': 0.27220490201780456, 'Total loss': 0.27220490201780456}
2022-12-31 12:54:06,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:06,601 INFO:     Epoch: 57
2022-12-31 12:54:08,222 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4844880263010661, 'Total loss': 0.4844880263010661} | train loss {'Reaction outcome loss': 0.27167490933374394, 'Total loss': 0.27167490933374394}
2022-12-31 12:54:08,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:08,223 INFO:     Epoch: 58
2022-12-31 12:54:09,829 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4446070849895477, 'Total loss': 0.4446070849895477} | train loss {'Reaction outcome loss': 0.2683791524015259, 'Total loss': 0.2683791524015259}
2022-12-31 12:54:09,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:09,830 INFO:     Epoch: 59
2022-12-31 12:54:11,447 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43631537184119223, 'Total loss': 0.43631537184119223} | train loss {'Reaction outcome loss': 0.26263288088755316, 'Total loss': 0.26263288088755316}
2022-12-31 12:54:11,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:11,448 INFO:     Epoch: 60
2022-12-31 12:54:13,061 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4577190140883128, 'Total loss': 0.4577190140883128} | train loss {'Reaction outcome loss': 0.2699480059394694, 'Total loss': 0.2699480059394694}
2022-12-31 12:54:13,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:13,062 INFO:     Epoch: 61
2022-12-31 12:54:14,676 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48130934635798134, 'Total loss': 0.48130934635798134} | train loss {'Reaction outcome loss': 0.2658379072326816, 'Total loss': 0.2658379072326816}
2022-12-31 12:54:14,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:14,676 INFO:     Epoch: 62
2022-12-31 12:54:16,290 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45980971852938335, 'Total loss': 0.45980971852938335} | train loss {'Reaction outcome loss': 0.26367138046118826, 'Total loss': 0.26367138046118826}
2022-12-31 12:54:16,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:16,290 INFO:     Epoch: 63
2022-12-31 12:54:17,889 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45580968260765076, 'Total loss': 0.45580968260765076} | train loss {'Reaction outcome loss': 0.2597172993127311, 'Total loss': 0.2597172993127311}
2022-12-31 12:54:17,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:17,889 INFO:     Epoch: 64
2022-12-31 12:54:19,482 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47115016281604766, 'Total loss': 0.47115016281604766} | train loss {'Reaction outcome loss': 0.25894198658879497, 'Total loss': 0.25894198658879497}
2022-12-31 12:54:19,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:19,482 INFO:     Epoch: 65
2022-12-31 12:54:21,109 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4313499500354131, 'Total loss': 0.4313499500354131} | train loss {'Reaction outcome loss': 0.2577291421214308, 'Total loss': 0.2577291421214308}
2022-12-31 12:54:21,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:21,110 INFO:     Epoch: 66
2022-12-31 12:54:22,744 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4625178545713425, 'Total loss': 0.4625178545713425} | train loss {'Reaction outcome loss': 0.25677295896710584, 'Total loss': 0.25677295896710584}
2022-12-31 12:54:22,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:22,745 INFO:     Epoch: 67
2022-12-31 12:54:24,357 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4709990998109182, 'Total loss': 0.4709990998109182} | train loss {'Reaction outcome loss': 0.25821270283473574, 'Total loss': 0.25821270283473574}
2022-12-31 12:54:24,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:24,358 INFO:     Epoch: 68
2022-12-31 12:54:25,971 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4701374004284541, 'Total loss': 0.4701374004284541} | train loss {'Reaction outcome loss': 0.28622494545930566, 'Total loss': 0.28622494545930566}
2022-12-31 12:54:25,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:25,972 INFO:     Epoch: 69
2022-12-31 12:54:27,573 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44294623732566835, 'Total loss': 0.44294623732566835} | train loss {'Reaction outcome loss': 0.26092033028143685, 'Total loss': 0.26092033028143685}
2022-12-31 12:54:27,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:27,573 INFO:     Epoch: 70
2022-12-31 12:54:29,173 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45620100299517313, 'Total loss': 0.45620100299517313} | train loss {'Reaction outcome loss': 0.250485484285847, 'Total loss': 0.250485484285847}
2022-12-31 12:54:29,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:29,174 INFO:     Epoch: 71
2022-12-31 12:54:30,792 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4732998092969259, 'Total loss': 0.4732998092969259} | train loss {'Reaction outcome loss': 0.2493340855150524, 'Total loss': 0.2493340855150524}
2022-12-31 12:54:30,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:30,793 INFO:     Epoch: 72
2022-12-31 12:54:32,411 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4550146912535032, 'Total loss': 0.4550146912535032} | train loss {'Reaction outcome loss': 0.2485189021292857, 'Total loss': 0.2485189021292857}
2022-12-31 12:54:32,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:32,413 INFO:     Epoch: 73
2022-12-31 12:54:34,030 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49119915763537086, 'Total loss': 0.49119915763537086} | train loss {'Reaction outcome loss': 0.24190497719615267, 'Total loss': 0.24190497719615267}
2022-12-31 12:54:34,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:34,031 INFO:     Epoch: 74
2022-12-31 12:54:35,632 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42503174394369125, 'Total loss': 0.42503174394369125} | train loss {'Reaction outcome loss': 0.24505806798149116, 'Total loss': 0.24505806798149116}
2022-12-31 12:54:35,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:35,632 INFO:     Epoch: 75
2022-12-31 12:54:37,240 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49328581194082893, 'Total loss': 0.49328581194082893} | train loss {'Reaction outcome loss': 0.24933806836222927, 'Total loss': 0.24933806836222927}
2022-12-31 12:54:37,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:37,240 INFO:     Epoch: 76
2022-12-31 12:54:38,854 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4536481902003288, 'Total loss': 0.4536481902003288} | train loss {'Reaction outcome loss': 0.24013086833883132, 'Total loss': 0.24013086833883132}
2022-12-31 12:54:38,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:38,854 INFO:     Epoch: 77
2022-12-31 12:54:40,488 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4392109086116155, 'Total loss': 0.4392109086116155} | train loss {'Reaction outcome loss': 0.24078945444742442, 'Total loss': 0.24078945444742442}
2022-12-31 12:54:40,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:40,489 INFO:     Epoch: 78
2022-12-31 12:54:42,126 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44985905289649963, 'Total loss': 0.44985905289649963} | train loss {'Reaction outcome loss': 0.2383392016062567, 'Total loss': 0.2383392016062567}
2022-12-31 12:54:42,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:42,127 INFO:     Epoch: 79
2022-12-31 12:54:43,745 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4251121064027151, 'Total loss': 0.4251121064027151} | train loss {'Reaction outcome loss': 0.23262710120442257, 'Total loss': 0.23262710120442257}
2022-12-31 12:54:43,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:43,745 INFO:     Epoch: 80
2022-12-31 12:54:45,340 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4474201907714208, 'Total loss': 0.4474201907714208} | train loss {'Reaction outcome loss': 0.23573883735467013, 'Total loss': 0.23573883735467013}
2022-12-31 12:54:45,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:45,340 INFO:     Epoch: 81
2022-12-31 12:54:46,951 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4605602810780207, 'Total loss': 0.4605602810780207} | train loss {'Reaction outcome loss': 0.23513679805931303, 'Total loss': 0.23513679805931303}
2022-12-31 12:54:46,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:46,951 INFO:     Epoch: 82
2022-12-31 12:54:48,607 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46437352895736694, 'Total loss': 0.46437352895736694} | train loss {'Reaction outcome loss': 0.23331621416129064, 'Total loss': 0.23331621416129064}
2022-12-31 12:54:48,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:48,608 INFO:     Epoch: 83
2022-12-31 12:54:50,227 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44860098759333294, 'Total loss': 0.44860098759333294} | train loss {'Reaction outcome loss': 0.2342302334516822, 'Total loss': 0.2342302334516822}
2022-12-31 12:54:50,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:50,228 INFO:     Epoch: 84
2022-12-31 12:54:51,841 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4711022694905599, 'Total loss': 0.4711022694905599} | train loss {'Reaction outcome loss': 0.23578517373138363, 'Total loss': 0.23578517373138363}
2022-12-31 12:54:51,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:51,842 INFO:     Epoch: 85
2022-12-31 12:54:53,456 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44787130852540336, 'Total loss': 0.44787130852540336} | train loss {'Reaction outcome loss': 0.23464684892931711, 'Total loss': 0.23464684892931711}
2022-12-31 12:54:53,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:53,456 INFO:     Epoch: 86
2022-12-31 12:54:55,054 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4332715475310882, 'Total loss': 0.4332715475310882} | train loss {'Reaction outcome loss': 0.22823483391793148, 'Total loss': 0.22823483391793148}
2022-12-31 12:54:55,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:55,055 INFO:     Epoch: 87
2022-12-31 12:54:56,673 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4537059158086777, 'Total loss': 0.4537059158086777} | train loss {'Reaction outcome loss': 0.2466789360050166, 'Total loss': 0.2466789360050166}
2022-12-31 12:54:56,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:56,674 INFO:     Epoch: 88
2022-12-31 12:54:58,334 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.52998066842556, 'Total loss': 0.52998066842556} | train loss {'Reaction outcome loss': 0.23794389876496533, 'Total loss': 0.23794389876496533}
2022-12-31 12:54:58,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:58,334 INFO:     Epoch: 89
2022-12-31 12:54:59,990 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46118324299653374, 'Total loss': 0.46118324299653374} | train loss {'Reaction outcome loss': 0.2607889228966087, 'Total loss': 0.2607889228966087}
2022-12-31 12:54:59,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:54:59,991 INFO:     Epoch: 90
2022-12-31 12:55:01,649 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48136759201685586, 'Total loss': 0.48136759201685586} | train loss {'Reaction outcome loss': 0.2335395982313523, 'Total loss': 0.2335395982313523}
2022-12-31 12:55:01,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:01,650 INFO:     Epoch: 91
2022-12-31 12:55:03,264 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4237471183141073, 'Total loss': 0.4237471183141073} | train loss {'Reaction outcome loss': 0.2300781798279048, 'Total loss': 0.2300781798279048}
2022-12-31 12:55:03,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:03,265 INFO:     Epoch: 92
2022-12-31 12:55:04,869 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4563637266556422, 'Total loss': 0.4563637266556422} | train loss {'Reaction outcome loss': 0.26161681774301804, 'Total loss': 0.26161681774301804}
2022-12-31 12:55:04,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:04,869 INFO:     Epoch: 93
2022-12-31 12:55:06,489 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4429969873279333, 'Total loss': 0.4429969873279333} | train loss {'Reaction outcome loss': 0.22111557457569492, 'Total loss': 0.22111557457569492}
2022-12-31 12:55:06,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:06,489 INFO:     Epoch: 94
2022-12-31 12:55:08,108 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4415425380071004, 'Total loss': 0.4415425380071004} | train loss {'Reaction outcome loss': 0.22222637290405398, 'Total loss': 0.22222637290405398}
2022-12-31 12:55:08,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:08,108 INFO:     Epoch: 95
2022-12-31 12:55:09,723 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43878102699915567, 'Total loss': 0.43878102699915567} | train loss {'Reaction outcome loss': 0.22655649098527172, 'Total loss': 0.22655649098527172}
2022-12-31 12:55:09,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:09,724 INFO:     Epoch: 96
2022-12-31 12:55:11,345 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45066232681274415, 'Total loss': 0.45066232681274415} | train loss {'Reaction outcome loss': 0.22104123882625415, 'Total loss': 0.22104123882625415}
2022-12-31 12:55:11,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:11,345 INFO:     Epoch: 97
2022-12-31 12:55:12,941 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4769282559553782, 'Total loss': 0.4769282559553782} | train loss {'Reaction outcome loss': 0.21912259722897864, 'Total loss': 0.21912259722897864}
2022-12-31 12:55:12,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:12,941 INFO:     Epoch: 98
2022-12-31 12:55:14,541 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42433359771966933, 'Total loss': 0.42433359771966933} | train loss {'Reaction outcome loss': 0.21847952830590867, 'Total loss': 0.21847952830590867}
2022-12-31 12:55:14,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:14,541 INFO:     Epoch: 99
2022-12-31 12:55:16,160 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4487092062830925, 'Total loss': 0.4487092062830925} | train loss {'Reaction outcome loss': 0.21425279498478209, 'Total loss': 0.21425279498478209}
2022-12-31 12:55:16,160 INFO:     Best model found after epoch 55 of 100.
2022-12-31 12:55:16,160 INFO:   Done with stage: TRAINING
2022-12-31 12:55:16,161 INFO:   Starting stage: EVALUATION
2022-12-31 12:55:16,290 INFO:   Done with stage: EVALUATION
2022-12-31 12:55:16,290 INFO:   Leaving out SEQ value Fold_6
2022-12-31 12:55:16,302 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 12:55:16,303 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:55:16,949 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:55:16,949 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:55:17,018 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:55:17,018 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:55:17,018 INFO:     No hyperparam tuning for this model
2022-12-31 12:55:17,018 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:55:17,019 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:55:17,019 INFO:     None feature selector for col prot
2022-12-31 12:55:17,019 INFO:     None feature selector for col prot
2022-12-31 12:55:17,019 INFO:     None feature selector for col prot
2022-12-31 12:55:17,020 INFO:     None feature selector for col chem
2022-12-31 12:55:17,020 INFO:     None feature selector for col chem
2022-12-31 12:55:17,020 INFO:     None feature selector for col chem
2022-12-31 12:55:17,020 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:55:17,020 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:55:17,022 INFO:     Number of params in model 223921
2022-12-31 12:55:17,025 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:55:17,025 INFO:   Starting stage: TRAINING
2022-12-31 12:55:17,073 INFO:     Val loss before train {'Reaction outcome loss': 0.9734732906023661, 'Total loss': 0.9734732906023661}
2022-12-31 12:55:17,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:17,073 INFO:     Epoch: 0
2022-12-31 12:55:18,692 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6748014946778615, 'Total loss': 0.6748014946778615} | train loss {'Reaction outcome loss': 0.8041763634888274, 'Total loss': 0.8041763634888274}
2022-12-31 12:55:18,692 INFO:     Found new best model at epoch 0
2022-12-31 12:55:18,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:18,693 INFO:     Epoch: 1
2022-12-31 12:55:20,316 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.540080068508784, 'Total loss': 0.540080068508784} | train loss {'Reaction outcome loss': 0.5978508748732749, 'Total loss': 0.5978508748732749}
2022-12-31 12:55:20,316 INFO:     Found new best model at epoch 1
2022-12-31 12:55:20,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:20,317 INFO:     Epoch: 2
2022-12-31 12:55:21,919 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5557467341423035, 'Total loss': 0.5557467341423035} | train loss {'Reaction outcome loss': 0.5334358761887258, 'Total loss': 0.5334358761887258}
2022-12-31 12:55:21,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:21,920 INFO:     Epoch: 3
2022-12-31 12:55:23,523 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49220685561498007, 'Total loss': 0.49220685561498007} | train loss {'Reaction outcome loss': 0.5078514598121712, 'Total loss': 0.5078514598121712}
2022-12-31 12:55:23,523 INFO:     Found new best model at epoch 3
2022-12-31 12:55:23,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:23,524 INFO:     Epoch: 4
2022-12-31 12:55:25,140 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4746053099632263, 'Total loss': 0.4746053099632263} | train loss {'Reaction outcome loss': 0.491921467417414, 'Total loss': 0.491921467417414}
2022-12-31 12:55:25,140 INFO:     Found new best model at epoch 4
2022-12-31 12:55:25,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:25,141 INFO:     Epoch: 5
2022-12-31 12:55:26,758 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47090134223302205, 'Total loss': 0.47090134223302205} | train loss {'Reaction outcome loss': 0.47946572110110675, 'Total loss': 0.47946572110110675}
2022-12-31 12:55:26,758 INFO:     Found new best model at epoch 5
2022-12-31 12:55:26,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:26,759 INFO:     Epoch: 6
2022-12-31 12:55:28,378 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4620299100875854, 'Total loss': 0.4620299100875854} | train loss {'Reaction outcome loss': 0.47877792793490825, 'Total loss': 0.47877792793490825}
2022-12-31 12:55:28,378 INFO:     Found new best model at epoch 6
2022-12-31 12:55:28,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:28,379 INFO:     Epoch: 7
2022-12-31 12:55:29,984 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44201699693997704, 'Total loss': 0.44201699693997704} | train loss {'Reaction outcome loss': 0.4624511998698169, 'Total loss': 0.4624511998698169}
2022-12-31 12:55:29,984 INFO:     Found new best model at epoch 7
2022-12-31 12:55:29,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:29,985 INFO:     Epoch: 8
2022-12-31 12:55:31,667 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4936404367287954, 'Total loss': 0.4936404367287954} | train loss {'Reaction outcome loss': 0.451837065014383, 'Total loss': 0.451837065014383}
2022-12-31 12:55:31,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:31,668 INFO:     Epoch: 9
2022-12-31 12:55:33,336 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.456976310412089, 'Total loss': 0.456976310412089} | train loss {'Reaction outcome loss': 0.4533401676571326, 'Total loss': 0.4533401676571326}
2022-12-31 12:55:33,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:33,337 INFO:     Epoch: 10
2022-12-31 12:55:35,053 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4721246540546417, 'Total loss': 0.4721246540546417} | train loss {'Reaction outcome loss': 0.4372973837200485, 'Total loss': 0.4372973837200485}
2022-12-31 12:55:35,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:35,053 INFO:     Epoch: 11
2022-12-31 12:55:36,750 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.461111185948054, 'Total loss': 0.461111185948054} | train loss {'Reaction outcome loss': 0.4365385271043984, 'Total loss': 0.4365385271043984}
2022-12-31 12:55:36,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:36,750 INFO:     Epoch: 12
2022-12-31 12:55:38,460 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4507644017537435, 'Total loss': 0.4507644017537435} | train loss {'Reaction outcome loss': 0.42525867867663447, 'Total loss': 0.42525867867663447}
2022-12-31 12:55:38,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:38,460 INFO:     Epoch: 13
2022-12-31 12:55:40,143 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43921705385049187, 'Total loss': 0.43921705385049187} | train loss {'Reaction outcome loss': 0.4263584743983479, 'Total loss': 0.4263584743983479}
2022-12-31 12:55:40,144 INFO:     Found new best model at epoch 13
2022-12-31 12:55:40,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:40,145 INFO:     Epoch: 14
2022-12-31 12:55:41,778 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45409714579582217, 'Total loss': 0.45409714579582217} | train loss {'Reaction outcome loss': 0.4149357496831391, 'Total loss': 0.4149357496831391}
2022-12-31 12:55:41,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:41,778 INFO:     Epoch: 15
2022-12-31 12:55:43,394 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42923637479543686, 'Total loss': 0.42923637479543686} | train loss {'Reaction outcome loss': 0.4090937301785507, 'Total loss': 0.4090937301785507}
2022-12-31 12:55:43,394 INFO:     Found new best model at epoch 15
2022-12-31 12:55:43,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:43,395 INFO:     Epoch: 16
2022-12-31 12:55:45,010 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4363708754380544, 'Total loss': 0.4363708754380544} | train loss {'Reaction outcome loss': 0.40316039743406246, 'Total loss': 0.40316039743406246}
2022-12-31 12:55:45,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:45,010 INFO:     Epoch: 17
2022-12-31 12:55:46,626 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.430326442917188, 'Total loss': 0.430326442917188} | train loss {'Reaction outcome loss': 0.39874364906377313, 'Total loss': 0.39874364906377313}
2022-12-31 12:55:46,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:46,626 INFO:     Epoch: 18
2022-12-31 12:55:48,239 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4636158227920532, 'Total loss': 0.4636158227920532} | train loss {'Reaction outcome loss': 0.3904209062726059, 'Total loss': 0.3904209062726059}
2022-12-31 12:55:48,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:48,239 INFO:     Epoch: 19
2022-12-31 12:55:49,837 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43412893215815224, 'Total loss': 0.43412893215815224} | train loss {'Reaction outcome loss': 0.38665914304204796, 'Total loss': 0.38665914304204796}
2022-12-31 12:55:49,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:49,837 INFO:     Epoch: 20
2022-12-31 12:55:51,432 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41215681036313373, 'Total loss': 0.41215681036313373} | train loss {'Reaction outcome loss': 0.38082679197030805, 'Total loss': 0.38082679197030805}
2022-12-31 12:55:51,432 INFO:     Found new best model at epoch 20
2022-12-31 12:55:51,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:51,433 INFO:     Epoch: 21
2022-12-31 12:55:53,049 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4265853782494863, 'Total loss': 0.4265853782494863} | train loss {'Reaction outcome loss': 0.3760157267055357, 'Total loss': 0.3760157267055357}
2022-12-31 12:55:53,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:53,050 INFO:     Epoch: 22
2022-12-31 12:55:54,666 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4444201429684957, 'Total loss': 0.4444201429684957} | train loss {'Reaction outcome loss': 0.3687476473541036, 'Total loss': 0.3687476473541036}
2022-12-31 12:55:54,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:54,666 INFO:     Epoch: 23
2022-12-31 12:55:56,283 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44163855314254763, 'Total loss': 0.44163855314254763} | train loss {'Reaction outcome loss': 0.36678327356434903, 'Total loss': 0.36678327356434903}
2022-12-31 12:55:56,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:56,283 INFO:     Epoch: 24
2022-12-31 12:55:57,883 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4106346597274145, 'Total loss': 0.4106346597274145} | train loss {'Reaction outcome loss': 0.35873116754560264, 'Total loss': 0.35873116754560264}
2022-12-31 12:55:57,883 INFO:     Found new best model at epoch 24
2022-12-31 12:55:57,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:57,884 INFO:     Epoch: 25
2022-12-31 12:55:59,477 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41038485964139304, 'Total loss': 0.41038485964139304} | train loss {'Reaction outcome loss': 0.35046368345134093, 'Total loss': 0.35046368345134093}
2022-12-31 12:55:59,477 INFO:     Found new best model at epoch 25
2022-12-31 12:55:59,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:55:59,478 INFO:     Epoch: 26
2022-12-31 12:56:01,095 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3931174596150716, 'Total loss': 0.3931174596150716} | train loss {'Reaction outcome loss': 0.3489306398569892, 'Total loss': 0.3489306398569892}
2022-12-31 12:56:01,095 INFO:     Found new best model at epoch 26
2022-12-31 12:56:01,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:01,096 INFO:     Epoch: 27
2022-12-31 12:56:02,713 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3976282387971878, 'Total loss': 0.3976282387971878} | train loss {'Reaction outcome loss': 0.3497305411831997, 'Total loss': 0.3497305411831997}
2022-12-31 12:56:02,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:02,713 INFO:     Epoch: 28
2022-12-31 12:56:04,330 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4140105684598287, 'Total loss': 0.4140105684598287} | train loss {'Reaction outcome loss': 0.3428223130397418, 'Total loss': 0.3428223130397418}
2022-12-31 12:56:04,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:04,330 INFO:     Epoch: 29
2022-12-31 12:56:05,949 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41974892814954123, 'Total loss': 0.41974892814954123} | train loss {'Reaction outcome loss': 0.3339761350882183, 'Total loss': 0.3339761350882183}
2022-12-31 12:56:05,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:05,949 INFO:     Epoch: 30
2022-12-31 12:56:07,548 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3818338771661123, 'Total loss': 0.3818338771661123} | train loss {'Reaction outcome loss': 0.3271827132370498, 'Total loss': 0.3271827132370498}
2022-12-31 12:56:07,548 INFO:     Found new best model at epoch 30
2022-12-31 12:56:07,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:07,549 INFO:     Epoch: 31
2022-12-31 12:56:09,168 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40816726386547086, 'Total loss': 0.40816726386547086} | train loss {'Reaction outcome loss': 0.32509050221058006, 'Total loss': 0.32509050221058006}
2022-12-31 12:56:09,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:09,170 INFO:     Epoch: 32
2022-12-31 12:56:10,800 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4570420265197754, 'Total loss': 0.4570420265197754} | train loss {'Reaction outcome loss': 0.3236558344416885, 'Total loss': 0.3236558344416885}
2022-12-31 12:56:10,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:10,801 INFO:     Epoch: 33
2022-12-31 12:56:12,419 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4159997493028641, 'Total loss': 0.4159997493028641} | train loss {'Reaction outcome loss': 0.3245094450802579, 'Total loss': 0.3245094450802579}
2022-12-31 12:56:12,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:12,419 INFO:     Epoch: 34
2022-12-31 12:56:14,037 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39780136148134865, 'Total loss': 0.39780136148134865} | train loss {'Reaction outcome loss': 0.31205645026067536, 'Total loss': 0.31205645026067536}
2022-12-31 12:56:14,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:14,037 INFO:     Epoch: 35
2022-12-31 12:56:15,576 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41823972513278324, 'Total loss': 0.41823972513278324} | train loss {'Reaction outcome loss': 0.3130524979655493, 'Total loss': 0.3130524979655493}
2022-12-31 12:56:15,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:15,577 INFO:     Epoch: 36
2022-12-31 12:56:16,660 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4262233500679334, 'Total loss': 0.4262233500679334} | train loss {'Reaction outcome loss': 0.30556025697651323, 'Total loss': 0.30556025697651323}
2022-12-31 12:56:16,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:16,660 INFO:     Epoch: 37
2022-12-31 12:56:17,739 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42868234515190123, 'Total loss': 0.42868234515190123} | train loss {'Reaction outcome loss': 0.30153594604468087, 'Total loss': 0.30153594604468087}
2022-12-31 12:56:17,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:17,740 INFO:     Epoch: 38
2022-12-31 12:56:18,820 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4053989738225937, 'Total loss': 0.4053989738225937} | train loss {'Reaction outcome loss': 0.3038287313944166, 'Total loss': 0.3038287313944166}
2022-12-31 12:56:18,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:18,821 INFO:     Epoch: 39
2022-12-31 12:56:19,901 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4226411789655685, 'Total loss': 0.4226411789655685} | train loss {'Reaction outcome loss': 0.29669567001210223, 'Total loss': 0.29669567001210223}
2022-12-31 12:56:19,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:19,901 INFO:     Epoch: 40
2022-12-31 12:56:21,501 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3986363450686137, 'Total loss': 0.3986363450686137} | train loss {'Reaction outcome loss': 0.29157130608489795, 'Total loss': 0.29157130608489795}
2022-12-31 12:56:21,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:21,502 INFO:     Epoch: 41
2022-12-31 12:56:23,115 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4025053689877192, 'Total loss': 0.4025053689877192} | train loss {'Reaction outcome loss': 0.2924948576972265, 'Total loss': 0.2924948576972265}
2022-12-31 12:56:23,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:23,116 INFO:     Epoch: 42
2022-12-31 12:56:24,711 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39784440249204633, 'Total loss': 0.39784440249204633} | train loss {'Reaction outcome loss': 0.28684731922532675, 'Total loss': 0.28684731922532675}
2022-12-31 12:56:24,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:24,711 INFO:     Epoch: 43
2022-12-31 12:56:26,326 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39794404606024425, 'Total loss': 0.39794404606024425} | train loss {'Reaction outcome loss': 0.2808459618327204, 'Total loss': 0.2808459618327204}
2022-12-31 12:56:26,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:26,326 INFO:     Epoch: 44
2022-12-31 12:56:27,940 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3880526175101598, 'Total loss': 0.3880526175101598} | train loss {'Reaction outcome loss': 0.27707581236850914, 'Total loss': 0.27707581236850914}
2022-12-31 12:56:27,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:27,941 INFO:     Epoch: 45
2022-12-31 12:56:29,542 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40487841963768006, 'Total loss': 0.40487841963768006} | train loss {'Reaction outcome loss': 0.2712477344871643, 'Total loss': 0.2712477344871643}
2022-12-31 12:56:29,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:29,543 INFO:     Epoch: 46
2022-12-31 12:56:31,162 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3956048647562663, 'Total loss': 0.3956048647562663} | train loss {'Reaction outcome loss': 0.2744713383138395, 'Total loss': 0.2744713383138395}
2022-12-31 12:56:31,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:31,162 INFO:     Epoch: 47
2022-12-31 12:56:32,776 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.414947801331679, 'Total loss': 0.414947801331679} | train loss {'Reaction outcome loss': 0.27360501999055653, 'Total loss': 0.27360501999055653}
2022-12-31 12:56:32,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:32,776 INFO:     Epoch: 48
2022-12-31 12:56:34,376 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3906712581713994, 'Total loss': 0.3906712581713994} | train loss {'Reaction outcome loss': 0.2709348754493338, 'Total loss': 0.2709348754493338}
2022-12-31 12:56:34,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:34,376 INFO:     Epoch: 49
2022-12-31 12:56:35,991 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3820034583409627, 'Total loss': 0.3820034583409627} | train loss {'Reaction outcome loss': 0.264424249193621, 'Total loss': 0.264424249193621}
2022-12-31 12:56:35,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:35,991 INFO:     Epoch: 50
2022-12-31 12:56:37,604 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4222578138113022, 'Total loss': 0.4222578138113022} | train loss {'Reaction outcome loss': 0.27009619331316825, 'Total loss': 0.27009619331316825}
2022-12-31 12:56:37,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:37,604 INFO:     Epoch: 51
2022-12-31 12:56:39,208 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37486816247304283, 'Total loss': 0.37486816247304283} | train loss {'Reaction outcome loss': 0.25914793025823274, 'Total loss': 0.25914793025823274}
2022-12-31 12:56:39,208 INFO:     Found new best model at epoch 51
2022-12-31 12:56:39,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:39,209 INFO:     Epoch: 52
2022-12-31 12:56:40,823 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3900224099556605, 'Total loss': 0.3900224099556605} | train loss {'Reaction outcome loss': 0.2611122802975806, 'Total loss': 0.2611122802975806}
2022-12-31 12:56:40,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:40,824 INFO:     Epoch: 53
2022-12-31 12:56:42,421 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3909148136774699, 'Total loss': 0.3909148136774699} | train loss {'Reaction outcome loss': 0.25658699563479165, 'Total loss': 0.25658699563479165}
2022-12-31 12:56:42,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:42,421 INFO:     Epoch: 54
2022-12-31 12:56:44,065 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3937074566880862, 'Total loss': 0.3937074566880862} | train loss {'Reaction outcome loss': 0.25349001341670857, 'Total loss': 0.25349001341670857}
2022-12-31 12:56:44,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:44,065 INFO:     Epoch: 55
2022-12-31 12:56:45,685 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36903899038831395, 'Total loss': 0.36903899038831395} | train loss {'Reaction outcome loss': 0.24975182163102103, 'Total loss': 0.24975182163102103}
2022-12-31 12:56:45,685 INFO:     Found new best model at epoch 55
2022-12-31 12:56:45,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:45,686 INFO:     Epoch: 56
2022-12-31 12:56:47,280 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38225839535395306, 'Total loss': 0.38225839535395306} | train loss {'Reaction outcome loss': 0.25046030410467934, 'Total loss': 0.25046030410467934}
2022-12-31 12:56:47,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:47,281 INFO:     Epoch: 57
2022-12-31 12:56:48,894 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43333762387434643, 'Total loss': 0.43333762387434643} | train loss {'Reaction outcome loss': 0.25219971261622676, 'Total loss': 0.25219971261622676}
2022-12-31 12:56:48,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:48,895 INFO:     Epoch: 58
2022-12-31 12:56:50,506 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3939826210339864, 'Total loss': 0.3939826210339864} | train loss {'Reaction outcome loss': 0.24192407966628401, 'Total loss': 0.24192407966628401}
2022-12-31 12:56:50,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:50,507 INFO:     Epoch: 59
2022-12-31 12:56:52,112 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39469239513079324, 'Total loss': 0.39469239513079324} | train loss {'Reaction outcome loss': 0.2431560978965854, 'Total loss': 0.2431560978965854}
2022-12-31 12:56:52,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:52,112 INFO:     Epoch: 60
2022-12-31 12:56:53,726 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4500204692284266, 'Total loss': 0.4500204692284266} | train loss {'Reaction outcome loss': 0.2406301428950543, 'Total loss': 0.2406301428950543}
2022-12-31 12:56:53,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:53,726 INFO:     Epoch: 61
2022-12-31 12:56:55,339 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40207796295483905, 'Total loss': 0.40207796295483905} | train loss {'Reaction outcome loss': 0.248071942854982, 'Total loss': 0.248071942854982}
2022-12-31 12:56:55,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:55,339 INFO:     Epoch: 62
2022-12-31 12:56:56,946 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39846693674723305, 'Total loss': 0.39846693674723305} | train loss {'Reaction outcome loss': 0.2409135401921367, 'Total loss': 0.2409135401921367}
2022-12-31 12:56:56,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:56,947 INFO:     Epoch: 63
2022-12-31 12:56:58,562 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40259357293446857, 'Total loss': 0.40259357293446857} | train loss {'Reaction outcome loss': 0.2412231989500755, 'Total loss': 0.2412231989500755}
2022-12-31 12:56:58,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:56:58,562 INFO:     Epoch: 64
2022-12-31 12:57:00,156 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41148455639680226, 'Total loss': 0.41148455639680226} | train loss {'Reaction outcome loss': 0.2329360787027149, 'Total loss': 0.2329360787027149}
2022-12-31 12:57:00,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:00,157 INFO:     Epoch: 65
2022-12-31 12:57:01,765 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39966986576716107, 'Total loss': 0.39966986576716107} | train loss {'Reaction outcome loss': 0.2430756351362497, 'Total loss': 0.2430756351362497}
2022-12-31 12:57:01,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:01,766 INFO:     Epoch: 66
2022-12-31 12:57:03,416 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3839649836222331, 'Total loss': 0.3839649836222331} | train loss {'Reaction outcome loss': 0.2371371182939206, 'Total loss': 0.2371371182939206}
2022-12-31 12:57:03,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:03,416 INFO:     Epoch: 67
2022-12-31 12:57:05,036 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3716317345698675, 'Total loss': 0.3716317345698675} | train loss {'Reaction outcome loss': 0.22958915279875594, 'Total loss': 0.22958915279875594}
2022-12-31 12:57:05,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:05,036 INFO:     Epoch: 68
2022-12-31 12:57:06,660 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38357649048169457, 'Total loss': 0.38357649048169457} | train loss {'Reaction outcome loss': 0.22982707118702925, 'Total loss': 0.22982707118702925}
2022-12-31 12:57:06,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:06,660 INFO:     Epoch: 69
2022-12-31 12:57:08,277 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39186627765496573, 'Total loss': 0.39186627765496573} | train loss {'Reaction outcome loss': 0.22787904017184615, 'Total loss': 0.22787904017184615}
2022-12-31 12:57:08,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:08,277 INFO:     Epoch: 70
2022-12-31 12:57:09,871 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3817666987578074, 'Total loss': 0.3817666987578074} | train loss {'Reaction outcome loss': 0.2296042102742066, 'Total loss': 0.2296042102742066}
2022-12-31 12:57:09,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:09,872 INFO:     Epoch: 71
2022-12-31 12:57:11,487 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41403605341911315, 'Total loss': 0.41403605341911315} | train loss {'Reaction outcome loss': 0.22767644868457576, 'Total loss': 0.22767644868457576}
2022-12-31 12:57:11,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:11,487 INFO:     Epoch: 72
2022-12-31 12:57:13,104 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3705217878023783, 'Total loss': 0.3705217878023783} | train loss {'Reaction outcome loss': 0.23258675958974698, 'Total loss': 0.23258675958974698}
2022-12-31 12:57:13,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:13,104 INFO:     Epoch: 73
2022-12-31 12:57:14,709 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.350547460714976, 'Total loss': 0.350547460714976} | train loss {'Reaction outcome loss': 0.22805100823971122, 'Total loss': 0.22805100823971122}
2022-12-31 12:57:14,710 INFO:     Found new best model at epoch 73
2022-12-31 12:57:14,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:14,710 INFO:     Epoch: 74
2022-12-31 12:57:16,328 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3759143928686778, 'Total loss': 0.3759143928686778} | train loss {'Reaction outcome loss': 0.22683108493093979, 'Total loss': 0.22683108493093979}
2022-12-31 12:57:16,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:16,329 INFO:     Epoch: 75
2022-12-31 12:57:17,969 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4433401793241501, 'Total loss': 0.4433401793241501} | train loss {'Reaction outcome loss': 0.22419596996010427, 'Total loss': 0.22419596996010427}
2022-12-31 12:57:17,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:17,969 INFO:     Epoch: 76
2022-12-31 12:57:19,584 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39035634994506835, 'Total loss': 0.39035634994506835} | train loss {'Reaction outcome loss': 0.2231682790207949, 'Total loss': 0.2231682790207949}
2022-12-31 12:57:19,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:19,584 INFO:     Epoch: 77
2022-12-31 12:57:21,207 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3808075432976087, 'Total loss': 0.3808075432976087} | train loss {'Reaction outcome loss': 0.22522313268821592, 'Total loss': 0.22522313268821592}
2022-12-31 12:57:21,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:21,207 INFO:     Epoch: 78
2022-12-31 12:57:22,825 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3766806875665983, 'Total loss': 0.3766806875665983} | train loss {'Reaction outcome loss': 0.22092204648557554, 'Total loss': 0.22092204648557554}
2022-12-31 12:57:22,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:22,826 INFO:     Epoch: 79
2022-12-31 12:57:24,433 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3681526601314545, 'Total loss': 0.3681526601314545} | train loss {'Reaction outcome loss': 0.2113791171542036, 'Total loss': 0.2113791171542036}
2022-12-31 12:57:24,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:24,434 INFO:     Epoch: 80
2022-12-31 12:57:26,048 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3422601242860158, 'Total loss': 0.3422601242860158} | train loss {'Reaction outcome loss': 0.22745368793768142, 'Total loss': 0.22745368793768142}
2022-12-31 12:57:26,048 INFO:     Found new best model at epoch 80
2022-12-31 12:57:26,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:26,049 INFO:     Epoch: 81
2022-12-31 12:57:27,643 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3664497442543507, 'Total loss': 0.3664497442543507} | train loss {'Reaction outcome loss': 0.21311930801705978, 'Total loss': 0.21311930801705978}
2022-12-31 12:57:27,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:27,643 INFO:     Epoch: 82
2022-12-31 12:57:29,266 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3810754845539729, 'Total loss': 0.3810754845539729} | train loss {'Reaction outcome loss': 0.21403305284974808, 'Total loss': 0.21403305284974808}
2022-12-31 12:57:29,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:29,266 INFO:     Epoch: 83
2022-12-31 12:57:30,924 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3899310141801834, 'Total loss': 0.3899310141801834} | train loss {'Reaction outcome loss': 0.2107189012967077, 'Total loss': 0.2107189012967077}
2022-12-31 12:57:30,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:30,924 INFO:     Epoch: 84
2022-12-31 12:57:32,529 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45996596415837604, 'Total loss': 0.45996596415837604} | train loss {'Reaction outcome loss': 0.21293259839718953, 'Total loss': 0.21293259839718953}
2022-12-31 12:57:32,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:32,529 INFO:     Epoch: 85
2022-12-31 12:57:34,152 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3772080053885778, 'Total loss': 0.3772080053885778} | train loss {'Reaction outcome loss': 0.21302982906572224, 'Total loss': 0.21302982906572224}
2022-12-31 12:57:34,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:34,152 INFO:     Epoch: 86
2022-12-31 12:57:35,770 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41997480392456055, 'Total loss': 0.41997480392456055} | train loss {'Reaction outcome loss': 0.21143642108087235, 'Total loss': 0.21143642108087235}
2022-12-31 12:57:35,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:35,771 INFO:     Epoch: 87
2022-12-31 12:57:37,362 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41071775555610657, 'Total loss': 0.41071775555610657} | train loss {'Reaction outcome loss': 0.21332308814763376, 'Total loss': 0.21332308814763376}
2022-12-31 12:57:37,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:37,362 INFO:     Epoch: 88
2022-12-31 12:57:38,981 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3773816883563995, 'Total loss': 0.3773816883563995} | train loss {'Reaction outcome loss': 0.20587041069642517, 'Total loss': 0.20587041069642517}
2022-12-31 12:57:38,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:38,981 INFO:     Epoch: 89
2022-12-31 12:57:40,598 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38238680362701416, 'Total loss': 0.38238680362701416} | train loss {'Reaction outcome loss': 0.20422068800077864, 'Total loss': 0.20422068800077864}
2022-12-31 12:57:40,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:40,598 INFO:     Epoch: 90
2022-12-31 12:57:42,198 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3896666745344798, 'Total loss': 0.3896666745344798} | train loss {'Reaction outcome loss': 0.2062465727517536, 'Total loss': 0.2062465727517536}
2022-12-31 12:57:42,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:42,199 INFO:     Epoch: 91
2022-12-31 12:57:43,818 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4051696002483368, 'Total loss': 0.4051696002483368} | train loss {'Reaction outcome loss': 0.21252409119952456, 'Total loss': 0.21252409119952456}
2022-12-31 12:57:43,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:43,818 INFO:     Epoch: 92
2022-12-31 12:57:45,440 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3814060042301814, 'Total loss': 0.3814060042301814} | train loss {'Reaction outcome loss': 0.20715193408759922, 'Total loss': 0.20715193408759922}
2022-12-31 12:57:45,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:45,440 INFO:     Epoch: 93
2022-12-31 12:57:47,062 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37699362536271414, 'Total loss': 0.37699362536271414} | train loss {'Reaction outcome loss': 0.20178889426056443, 'Total loss': 0.20178889426056443}
2022-12-31 12:57:47,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:47,063 INFO:     Epoch: 94
2022-12-31 12:57:48,685 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4033853620290756, 'Total loss': 0.4033853620290756} | train loss {'Reaction outcome loss': 0.20263002551957587, 'Total loss': 0.20263002551957587}
2022-12-31 12:57:48,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:48,686 INFO:     Epoch: 95
2022-12-31 12:57:50,303 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37989916404088336, 'Total loss': 0.37989916404088336} | train loss {'Reaction outcome loss': 0.2090457830181352, 'Total loss': 0.2090457830181352}
2022-12-31 12:57:50,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:50,304 INFO:     Epoch: 96
2022-12-31 12:57:51,952 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40082390010356905, 'Total loss': 0.40082390010356905} | train loss {'Reaction outcome loss': 0.19428334777858713, 'Total loss': 0.19428334777858713}
2022-12-31 12:57:51,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:51,953 INFO:     Epoch: 97
2022-12-31 12:57:53,591 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3783564587434133, 'Total loss': 0.3783564587434133} | train loss {'Reaction outcome loss': 0.20450079676422833, 'Total loss': 0.20450079676422833}
2022-12-31 12:57:53,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:53,592 INFO:     Epoch: 98
2022-12-31 12:57:55,199 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.35263256132602694, 'Total loss': 0.35263256132602694} | train loss {'Reaction outcome loss': 0.1966630534238656, 'Total loss': 0.1966630534238656}
2022-12-31 12:57:55,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:55,199 INFO:     Epoch: 99
2022-12-31 12:57:56,821 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4155412048101425, 'Total loss': 0.4155412048101425} | train loss {'Reaction outcome loss': 0.19901056531883965, 'Total loss': 0.19901056531883965}
2022-12-31 12:57:56,821 INFO:     Best model found after epoch 81 of 100.
2022-12-31 12:57:56,821 INFO:   Done with stage: TRAINING
2022-12-31 12:57:56,821 INFO:   Starting stage: EVALUATION
2022-12-31 12:57:56,946 INFO:   Done with stage: EVALUATION
2022-12-31 12:57:56,946 INFO:   Leaving out SEQ value Fold_7
2022-12-31 12:57:56,959 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 12:57:56,959 INFO:   Starting stage: FEATURE SCALING
2022-12-31 12:57:57,609 INFO:   Done with stage: FEATURE SCALING
2022-12-31 12:57:57,609 INFO:   Starting stage: SCALING TARGETS
2022-12-31 12:57:57,678 INFO:   Done with stage: SCALING TARGETS
2022-12-31 12:57:57,678 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:57:57,678 INFO:     No hyperparam tuning for this model
2022-12-31 12:57:57,678 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 12:57:57,678 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 12:57:57,679 INFO:     None feature selector for col prot
2022-12-31 12:57:57,679 INFO:     None feature selector for col prot
2022-12-31 12:57:57,679 INFO:     None feature selector for col prot
2022-12-31 12:57:57,680 INFO:     None feature selector for col chem
2022-12-31 12:57:57,680 INFO:     None feature selector for col chem
2022-12-31 12:57:57,680 INFO:     None feature selector for col chem
2022-12-31 12:57:57,680 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 12:57:57,680 INFO:   Starting stage: BUILD MODEL
2022-12-31 12:57:57,682 INFO:     Number of params in model 223921
2022-12-31 12:57:57,685 INFO:   Done with stage: BUILD MODEL
2022-12-31 12:57:57,685 INFO:   Starting stage: TRAINING
2022-12-31 12:57:57,731 INFO:     Val loss before train {'Reaction outcome loss': 1.0339425365130106, 'Total loss': 1.0339425365130106}
2022-12-31 12:57:57,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:57,731 INFO:     Epoch: 0
2022-12-31 12:57:59,335 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.733494903643926, 'Total loss': 0.733494903643926} | train loss {'Reaction outcome loss': 0.8066806187483377, 'Total loss': 0.8066806187483377}
2022-12-31 12:57:59,335 INFO:     Found new best model at epoch 0
2022-12-31 12:57:59,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:57:59,336 INFO:     Epoch: 1
2022-12-31 12:58:00,962 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5977914810180665, 'Total loss': 0.5977914810180665} | train loss {'Reaction outcome loss': 0.6010926674634541, 'Total loss': 0.6010926674634541}
2022-12-31 12:58:00,963 INFO:     Found new best model at epoch 1
2022-12-31 12:58:00,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:00,963 INFO:     Epoch: 2
2022-12-31 12:58:02,604 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5739760597546896, 'Total loss': 0.5739760597546896} | train loss {'Reaction outcome loss': 0.5254520801860934, 'Total loss': 0.5254520801860934}
2022-12-31 12:58:02,604 INFO:     Found new best model at epoch 2
2022-12-31 12:58:02,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:02,605 INFO:     Epoch: 3
2022-12-31 12:58:04,203 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.56090008020401, 'Total loss': 0.56090008020401} | train loss {'Reaction outcome loss': 0.4979192119643146, 'Total loss': 0.4979192119643146}
2022-12-31 12:58:04,203 INFO:     Found new best model at epoch 3
2022-12-31 12:58:04,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:04,204 INFO:     Epoch: 4
2022-12-31 12:58:05,826 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5606058776378632, 'Total loss': 0.5606058776378632} | train loss {'Reaction outcome loss': 0.4837731429600974, 'Total loss': 0.4837731429600974}
2022-12-31 12:58:05,827 INFO:     Found new best model at epoch 4
2022-12-31 12:58:05,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:05,828 INFO:     Epoch: 5
2022-12-31 12:58:07,445 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5771523137887319, 'Total loss': 0.5771523137887319} | train loss {'Reaction outcome loss': 0.46992588301427957, 'Total loss': 0.46992588301427957}
2022-12-31 12:58:07,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:07,445 INFO:     Epoch: 6
2022-12-31 12:58:09,049 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5519552985827129, 'Total loss': 0.5519552985827129} | train loss {'Reaction outcome loss': 0.4615938568803808, 'Total loss': 0.4615938568803808}
2022-12-31 12:58:09,049 INFO:     Found new best model at epoch 6
2022-12-31 12:58:09,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:09,050 INFO:     Epoch: 7
2022-12-31 12:58:10,659 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5606524844964346, 'Total loss': 0.5606524844964346} | train loss {'Reaction outcome loss': 0.454723774633683, 'Total loss': 0.454723774633683}
2022-12-31 12:58:10,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:10,659 INFO:     Epoch: 8
2022-12-31 12:58:12,323 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5201207240422566, 'Total loss': 0.5201207240422566} | train loss {'Reaction outcome loss': 0.4472814224902473, 'Total loss': 0.4472814224902473}
2022-12-31 12:58:12,323 INFO:     Found new best model at epoch 8
2022-12-31 12:58:12,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:12,324 INFO:     Epoch: 9
2022-12-31 12:58:13,928 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5158351540565491, 'Total loss': 0.5158351540565491} | train loss {'Reaction outcome loss': 0.4452530328278507, 'Total loss': 0.4452530328278507}
2022-12-31 12:58:13,938 INFO:     Found new best model at epoch 9
2022-12-31 12:58:13,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:13,939 INFO:     Epoch: 10
2022-12-31 12:58:15,560 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5110982755819956, 'Total loss': 0.5110982755819956} | train loss {'Reaction outcome loss': 0.43377369131207033, 'Total loss': 0.43377369131207033}
2022-12-31 12:58:15,560 INFO:     Found new best model at epoch 10
2022-12-31 12:58:15,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:15,561 INFO:     Epoch: 11
2022-12-31 12:58:17,174 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5330290098985037, 'Total loss': 0.5330290098985037} | train loss {'Reaction outcome loss': 0.4268681433872195, 'Total loss': 0.4268681433872195}
2022-12-31 12:58:17,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:17,175 INFO:     Epoch: 12
2022-12-31 12:58:18,779 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5063957591851552, 'Total loss': 0.5063957591851552} | train loss {'Reaction outcome loss': 0.42393362495227843, 'Total loss': 0.42393362495227843}
2022-12-31 12:58:18,779 INFO:     Found new best model at epoch 12
2022-12-31 12:58:18,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:18,780 INFO:     Epoch: 13
2022-12-31 12:58:20,399 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5471806108951569, 'Total loss': 0.5471806108951569} | train loss {'Reaction outcome loss': 0.41894752139541647, 'Total loss': 0.41894752139541647}
2022-12-31 12:58:20,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:20,399 INFO:     Epoch: 14
2022-12-31 12:58:22,001 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5295598308245341, 'Total loss': 0.5295598308245341} | train loss {'Reaction outcome loss': 0.4101753342452893, 'Total loss': 0.4101753342452893}
2022-12-31 12:58:22,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:22,001 INFO:     Epoch: 15
2022-12-31 12:58:23,615 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.526485276222229, 'Total loss': 0.526485276222229} | train loss {'Reaction outcome loss': 0.4071597257353339, 'Total loss': 0.4071597257353339}
2022-12-31 12:58:23,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:23,616 INFO:     Epoch: 16
2022-12-31 12:58:25,226 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5033674399058025, 'Total loss': 0.5033674399058025} | train loss {'Reaction outcome loss': 0.3968859007481203, 'Total loss': 0.3968859007481203}
2022-12-31 12:58:25,226 INFO:     Found new best model at epoch 16
2022-12-31 12:58:25,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:25,227 INFO:     Epoch: 17
2022-12-31 12:58:26,820 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5215084294478098, 'Total loss': 0.5215084294478098} | train loss {'Reaction outcome loss': 0.3924175572147869, 'Total loss': 0.3924175572147869}
2022-12-31 12:58:26,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:26,821 INFO:     Epoch: 18
2022-12-31 12:58:28,429 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5116590668757757, 'Total loss': 0.5116590668757757} | train loss {'Reaction outcome loss': 0.38790639185948494, 'Total loss': 0.38790639185948494}
2022-12-31 12:58:28,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:28,430 INFO:     Epoch: 19
2022-12-31 12:58:30,041 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5032838622728983, 'Total loss': 0.5032838622728983} | train loss {'Reaction outcome loss': 0.39026695987485377, 'Total loss': 0.39026695987485377}
2022-12-31 12:58:30,041 INFO:     Found new best model at epoch 19
2022-12-31 12:58:30,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:30,042 INFO:     Epoch: 20
2022-12-31 12:58:31,669 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4861355245113373, 'Total loss': 0.4861355245113373} | train loss {'Reaction outcome loss': 0.372536447423675, 'Total loss': 0.372536447423675}
2022-12-31 12:58:31,669 INFO:     Found new best model at epoch 20
2022-12-31 12:58:31,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:31,670 INFO:     Epoch: 21
2022-12-31 12:58:33,318 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.491299569606781, 'Total loss': 0.491299569606781} | train loss {'Reaction outcome loss': 0.36946045252282694, 'Total loss': 0.36946045252282694}
2022-12-31 12:58:33,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:33,318 INFO:     Epoch: 22
2022-12-31 12:58:34,939 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49219760596752166, 'Total loss': 0.49219760596752166} | train loss {'Reaction outcome loss': 0.3692434018592112, 'Total loss': 0.3692434018592112}
2022-12-31 12:58:34,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:34,939 INFO:     Epoch: 23
2022-12-31 12:58:36,534 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5054590582847596, 'Total loss': 0.5054590582847596} | train loss {'Reaction outcome loss': 0.3608951808393862, 'Total loss': 0.3608951808393862}
2022-12-31 12:58:36,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:36,535 INFO:     Epoch: 24
2022-12-31 12:58:38,146 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4889994204044342, 'Total loss': 0.4889994204044342} | train loss {'Reaction outcome loss': 0.35975041939786195, 'Total loss': 0.35975041939786195}
2022-12-31 12:58:38,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:38,147 INFO:     Epoch: 25
2022-12-31 12:58:39,747 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45819611152013145, 'Total loss': 0.45819611152013145} | train loss {'Reaction outcome loss': 0.35301894869399847, 'Total loss': 0.35301894869399847}
2022-12-31 12:58:39,747 INFO:     Found new best model at epoch 25
2022-12-31 12:58:39,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:39,748 INFO:     Epoch: 26
2022-12-31 12:58:41,392 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4635144978761673, 'Total loss': 0.4635144978761673} | train loss {'Reaction outcome loss': 0.3491679322956271, 'Total loss': 0.3491679322956271}
2022-12-31 12:58:41,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:41,392 INFO:     Epoch: 27
2022-12-31 12:58:43,026 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45236037075519564, 'Total loss': 0.45236037075519564} | train loss {'Reaction outcome loss': 0.33979673756266326, 'Total loss': 0.33979673756266326}
2022-12-31 12:58:43,026 INFO:     Found new best model at epoch 27
2022-12-31 12:58:43,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:43,027 INFO:     Epoch: 28
2022-12-31 12:58:44,628 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4473648856083552, 'Total loss': 0.4473648856083552} | train loss {'Reaction outcome loss': 0.33664683058911715, 'Total loss': 0.33664683058911715}
2022-12-31 12:58:44,628 INFO:     Found new best model at epoch 28
2022-12-31 12:58:44,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:44,629 INFO:     Epoch: 29
2022-12-31 12:58:46,242 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45676967600981394, 'Total loss': 0.45676967600981394} | train loss {'Reaction outcome loss': 0.3275686877675435, 'Total loss': 0.3275686877675435}
2022-12-31 12:58:46,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:46,243 INFO:     Epoch: 30
2022-12-31 12:58:47,863 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43341435492038727, 'Total loss': 0.43341435492038727} | train loss {'Reaction outcome loss': 0.3286355568317945, 'Total loss': 0.3286355568317945}
2022-12-31 12:58:47,864 INFO:     Found new best model at epoch 30
2022-12-31 12:58:47,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:47,865 INFO:     Epoch: 31
2022-12-31 12:58:49,464 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43455512126286827, 'Total loss': 0.43455512126286827} | train loss {'Reaction outcome loss': 0.3255777128094585, 'Total loss': 0.3255777128094585}
2022-12-31 12:58:49,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:49,464 INFO:     Epoch: 32
2022-12-31 12:58:51,077 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4393973290920258, 'Total loss': 0.4393973290920258} | train loss {'Reaction outcome loss': 0.3148262936635353, 'Total loss': 0.3148262936635353}
2022-12-31 12:58:51,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:51,077 INFO:     Epoch: 33
2022-12-31 12:58:52,688 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4699605713287989, 'Total loss': 0.4699605713287989} | train loss {'Reaction outcome loss': 0.31509391780579565, 'Total loss': 0.31509391780579565}
2022-12-31 12:58:52,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:52,688 INFO:     Epoch: 34
2022-12-31 12:58:54,289 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4348180512587229, 'Total loss': 0.4348180512587229} | train loss {'Reaction outcome loss': 0.3134815435493466, 'Total loss': 0.3134815435493466}
2022-12-31 12:58:54,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:54,290 INFO:     Epoch: 35
2022-12-31 12:58:55,899 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47408438126246133, 'Total loss': 0.47408438126246133} | train loss {'Reaction outcome loss': 0.30199076451146, 'Total loss': 0.30199076451146}
2022-12-31 12:58:55,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:55,899 INFO:     Epoch: 36
2022-12-31 12:58:57,523 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47271695733070374, 'Total loss': 0.47271695733070374} | train loss {'Reaction outcome loss': 0.30755493456383476, 'Total loss': 0.30755493456383476}
2022-12-31 12:58:57,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:57,524 INFO:     Epoch: 37
2022-12-31 12:58:59,165 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46620957056681317, 'Total loss': 0.46620957056681317} | train loss {'Reaction outcome loss': 0.29988539466358693, 'Total loss': 0.29988539466358693}
2022-12-31 12:58:59,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:58:59,166 INFO:     Epoch: 38
2022-12-31 12:59:00,789 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4359952410062154, 'Total loss': 0.4359952410062154} | train loss {'Reaction outcome loss': 0.2933657206460457, 'Total loss': 0.2933657206460457}
2022-12-31 12:59:00,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:00,789 INFO:     Epoch: 39
2022-12-31 12:59:02,398 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4381022055943807, 'Total loss': 0.4381022055943807} | train loss {'Reaction outcome loss': 0.29939420905892167, 'Total loss': 0.29939420905892167}
2022-12-31 12:59:02,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:02,399 INFO:     Epoch: 40
2022-12-31 12:59:04,006 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43020004431406655, 'Total loss': 0.43020004431406655} | train loss {'Reaction outcome loss': 0.28692017318109314, 'Total loss': 0.28692017318109314}
2022-12-31 12:59:04,006 INFO:     Found new best model at epoch 40
2022-12-31 12:59:04,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:04,007 INFO:     Epoch: 41
2022-12-31 12:59:05,619 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4774170955022176, 'Total loss': 0.4774170955022176} | train loss {'Reaction outcome loss': 0.29047810592913886, 'Total loss': 0.29047810592913886}
2022-12-31 12:59:05,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:05,619 INFO:     Epoch: 42
2022-12-31 12:59:07,225 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41619451145331066, 'Total loss': 0.41619451145331066} | train loss {'Reaction outcome loss': 0.2837650982212504, 'Total loss': 0.2837650982212504}
2022-12-31 12:59:07,225 INFO:     Found new best model at epoch 42
2022-12-31 12:59:07,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:07,226 INFO:     Epoch: 43
2022-12-31 12:59:08,845 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4209657152493795, 'Total loss': 0.4209657152493795} | train loss {'Reaction outcome loss': 0.28104137755688346, 'Total loss': 0.28104137755688346}
2022-12-31 12:59:08,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:08,845 INFO:     Epoch: 44
2022-12-31 12:59:10,457 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3867898225784302, 'Total loss': 0.3867898225784302} | train loss {'Reaction outcome loss': 0.2743475551747243, 'Total loss': 0.2743475551747243}
2022-12-31 12:59:10,457 INFO:     Found new best model at epoch 44
2022-12-31 12:59:10,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:10,458 INFO:     Epoch: 45
2022-12-31 12:59:12,062 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4173892920215925, 'Total loss': 0.4173892920215925} | train loss {'Reaction outcome loss': 0.27761615167240805, 'Total loss': 0.27761615167240805}
2022-12-31 12:59:12,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:12,062 INFO:     Epoch: 46
2022-12-31 12:59:13,682 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4377978841463725, 'Total loss': 0.4377978841463725} | train loss {'Reaction outcome loss': 0.2727017084856111, 'Total loss': 0.2727017084856111}
2022-12-31 12:59:13,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:13,682 INFO:     Epoch: 47
2022-12-31 12:59:15,330 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44699792663256327, 'Total loss': 0.44699792663256327} | train loss {'Reaction outcome loss': 0.2727215717469312, 'Total loss': 0.2727215717469312}
2022-12-31 12:59:15,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:15,331 INFO:     Epoch: 48
2022-12-31 12:59:16,936 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4028453084329764, 'Total loss': 0.4028453084329764} | train loss {'Reaction outcome loss': 0.2654495673112921, 'Total loss': 0.2654495673112921}
2022-12-31 12:59:16,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:16,936 INFO:     Epoch: 49
2022-12-31 12:59:18,549 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40971440970897677, 'Total loss': 0.40971440970897677} | train loss {'Reaction outcome loss': 0.26731450776384624, 'Total loss': 0.26731450776384624}
2022-12-31 12:59:18,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:18,549 INFO:     Epoch: 50
2022-12-31 12:59:20,160 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3976093252499898, 'Total loss': 0.3976093252499898} | train loss {'Reaction outcome loss': 0.26484095554677806, 'Total loss': 0.26484095554677806}
2022-12-31 12:59:20,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:20,160 INFO:     Epoch: 51
2022-12-31 12:59:21,761 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4524846524000168, 'Total loss': 0.4524846524000168} | train loss {'Reaction outcome loss': 0.261320475946157, 'Total loss': 0.261320475946157}
2022-12-31 12:59:21,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:21,762 INFO:     Epoch: 52
2022-12-31 12:59:23,369 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4204274624586105, 'Total loss': 0.4204274624586105} | train loss {'Reaction outcome loss': 0.2615289137251541, 'Total loss': 0.2615289137251541}
2022-12-31 12:59:23,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:23,369 INFO:     Epoch: 53
2022-12-31 12:59:24,997 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3926427185535431, 'Total loss': 0.3926427185535431} | train loss {'Reaction outcome loss': 0.26045984023717983, 'Total loss': 0.26045984023717983}
2022-12-31 12:59:24,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:24,999 INFO:     Epoch: 54
2022-12-31 12:59:26,622 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3902115593353907, 'Total loss': 0.3902115593353907} | train loss {'Reaction outcome loss': 0.2562511681111711, 'Total loss': 0.2562511681111711}
2022-12-31 12:59:26,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:26,623 INFO:     Epoch: 55
2022-12-31 12:59:28,239 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4073062926530838, 'Total loss': 0.4073062926530838} | train loss {'Reaction outcome loss': 0.2540430732555553, 'Total loss': 0.2540430732555553}
2022-12-31 12:59:28,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:28,239 INFO:     Epoch: 56
2022-12-31 12:59:29,850 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38280055423577625, 'Total loss': 0.38280055423577625} | train loss {'Reaction outcome loss': 0.2531620235911937, 'Total loss': 0.2531620235911937}
2022-12-31 12:59:29,850 INFO:     Found new best model at epoch 56
2022-12-31 12:59:29,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:29,851 INFO:     Epoch: 57
2022-12-31 12:59:31,503 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4555725365877151, 'Total loss': 0.4555725365877151} | train loss {'Reaction outcome loss': 0.25055685679727513, 'Total loss': 0.25055685679727513}
2022-12-31 12:59:31,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:31,504 INFO:     Epoch: 58
2022-12-31 12:59:33,141 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41051751673221587, 'Total loss': 0.41051751673221587} | train loss {'Reaction outcome loss': 0.2549694027240634, 'Total loss': 0.2549694027240634}
2022-12-31 12:59:33,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:33,141 INFO:     Epoch: 59
2022-12-31 12:59:34,748 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41017074286937716, 'Total loss': 0.41017074286937716} | train loss {'Reaction outcome loss': 0.2468067088470347, 'Total loss': 0.2468067088470347}
2022-12-31 12:59:34,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:34,748 INFO:     Epoch: 60
2022-12-31 12:59:36,361 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4053019682566325, 'Total loss': 0.4053019682566325} | train loss {'Reaction outcome loss': 0.24544785456859677, 'Total loss': 0.24544785456859677}
2022-12-31 12:59:36,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:36,361 INFO:     Epoch: 61
2022-12-31 12:59:37,988 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45075399180253345, 'Total loss': 0.45075399180253345} | train loss {'Reaction outcome loss': 0.23968015434993734, 'Total loss': 0.23968015434993734}
2022-12-31 12:59:37,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:37,988 INFO:     Epoch: 62
2022-12-31 12:59:39,613 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39940440356731416, 'Total loss': 0.39940440356731416} | train loss {'Reaction outcome loss': 0.2373256019992411, 'Total loss': 0.2373256019992411}
2022-12-31 12:59:39,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:39,613 INFO:     Epoch: 63
2022-12-31 12:59:41,260 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3957925905783971, 'Total loss': 0.3957925905783971} | train loss {'Reaction outcome loss': 0.24156381831998644, 'Total loss': 0.24156381831998644}
2022-12-31 12:59:41,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:41,260 INFO:     Epoch: 64
2022-12-31 12:59:42,887 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42970315714677176, 'Total loss': 0.42970315714677176} | train loss {'Reaction outcome loss': 0.23624712729739153, 'Total loss': 0.23624712729739153}
2022-12-31 12:59:42,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:42,888 INFO:     Epoch: 65
2022-12-31 12:59:44,500 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3899705151716868, 'Total loss': 0.3899705151716868} | train loss {'Reaction outcome loss': 0.23816467743595585, 'Total loss': 0.23816467743595585}
2022-12-31 12:59:44,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:44,501 INFO:     Epoch: 66
2022-12-31 12:59:46,141 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.396773025393486, 'Total loss': 0.396773025393486} | train loss {'Reaction outcome loss': 0.2409695702594863, 'Total loss': 0.2409695702594863}
2022-12-31 12:59:46,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:46,141 INFO:     Epoch: 67
2022-12-31 12:59:47,772 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38554413517316183, 'Total loss': 0.38554413517316183} | train loss {'Reaction outcome loss': 0.23168692029071197, 'Total loss': 0.23168692029071197}
2022-12-31 12:59:47,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:47,773 INFO:     Epoch: 68
2022-12-31 12:59:49,385 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40001110136508944, 'Total loss': 0.40001110136508944} | train loss {'Reaction outcome loss': 0.2307967949214825, 'Total loss': 0.2307967949214825}
2022-12-31 12:59:49,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:49,386 INFO:     Epoch: 69
2022-12-31 12:59:51,006 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4383643289407094, 'Total loss': 0.4383643289407094} | train loss {'Reaction outcome loss': 0.2339092409675302, 'Total loss': 0.2339092409675302}
2022-12-31 12:59:51,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:51,006 INFO:     Epoch: 70
2022-12-31 12:59:52,614 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39028433958689374, 'Total loss': 0.39028433958689374} | train loss {'Reaction outcome loss': 0.227748873411587, 'Total loss': 0.227748873411587}
2022-12-31 12:59:52,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:52,614 INFO:     Epoch: 71
2022-12-31 12:59:54,232 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4106943200031916, 'Total loss': 0.4106943200031916} | train loss {'Reaction outcome loss': 0.23043555775758162, 'Total loss': 0.23043555775758162}
2022-12-31 12:59:54,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:54,232 INFO:     Epoch: 72
2022-12-31 12:59:55,850 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38748741944630943, 'Total loss': 0.38748741944630943} | train loss {'Reaction outcome loss': 0.22211902052002694, 'Total loss': 0.22211902052002694}
2022-12-31 12:59:55,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:55,850 INFO:     Epoch: 73
2022-12-31 12:59:57,456 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43548800945281985, 'Total loss': 0.43548800945281985} | train loss {'Reaction outcome loss': 0.22540059297712056, 'Total loss': 0.22540059297712056}
2022-12-31 12:59:57,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:57,457 INFO:     Epoch: 74
2022-12-31 12:59:59,076 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38166393836339313, 'Total loss': 0.38166393836339313} | train loss {'Reaction outcome loss': 0.2193148017992074, 'Total loss': 0.2193148017992074}
2022-12-31 12:59:59,076 INFO:     Found new best model at epoch 74
2022-12-31 12:59:59,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 12:59:59,077 INFO:     Epoch: 75
2022-12-31 13:00:00,696 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.425663818915685, 'Total loss': 0.425663818915685} | train loss {'Reaction outcome loss': 0.22601616976359046, 'Total loss': 0.22601616976359046}
2022-12-31 13:00:00,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:00,697 INFO:     Epoch: 76
2022-12-31 13:00:02,331 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3899110476175944, 'Total loss': 0.3899110476175944} | train loss {'Reaction outcome loss': 0.22278663335832016, 'Total loss': 0.22278663335832016}
2022-12-31 13:00:02,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:02,331 INFO:     Epoch: 77
2022-12-31 13:00:03,985 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.457856085896492, 'Total loss': 0.457856085896492} | train loss {'Reaction outcome loss': 0.22080014207625648, 'Total loss': 0.22080014207625648}
2022-12-31 13:00:03,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:03,985 INFO:     Epoch: 78
2022-12-31 13:00:05,624 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47898149540026985, 'Total loss': 0.47898149540026985} | train loss {'Reaction outcome loss': 0.22068644466974674, 'Total loss': 0.22068644466974674}
2022-12-31 13:00:05,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:05,624 INFO:     Epoch: 79
2022-12-31 13:00:07,258 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4275411585966746, 'Total loss': 0.4275411585966746} | train loss {'Reaction outcome loss': 0.21832221522187606, 'Total loss': 0.21832221522187606}
2022-12-31 13:00:07,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:07,259 INFO:     Epoch: 80
2022-12-31 13:00:08,904 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41997326413790387, 'Total loss': 0.41997326413790387} | train loss {'Reaction outcome loss': 0.21727338074857794, 'Total loss': 0.21727338074857794}
2022-12-31 13:00:08,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:08,905 INFO:     Epoch: 81
2022-12-31 13:00:10,528 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4074266036351522, 'Total loss': 0.4074266036351522} | train loss {'Reaction outcome loss': 0.2186722239808916, 'Total loss': 0.2186722239808916}
2022-12-31 13:00:10,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:10,529 INFO:     Epoch: 82
2022-12-31 13:00:12,146 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39738293588161466, 'Total loss': 0.39738293588161466} | train loss {'Reaction outcome loss': 0.21949315479610262, 'Total loss': 0.21949315479610262}
2022-12-31 13:00:12,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:12,146 INFO:     Epoch: 83
2022-12-31 13:00:13,762 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46453239719072975, 'Total loss': 0.46453239719072975} | train loss {'Reaction outcome loss': 0.21351111779789633, 'Total loss': 0.21351111779789633}
2022-12-31 13:00:13,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:13,762 INFO:     Epoch: 84
2022-12-31 13:00:15,366 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41869597882032394, 'Total loss': 0.41869597882032394} | train loss {'Reaction outcome loss': 0.21733239467259133, 'Total loss': 0.21733239467259133}
2022-12-31 13:00:15,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:15,366 INFO:     Epoch: 85
2022-12-31 13:00:16,979 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3978087345759074, 'Total loss': 0.3978087345759074} | train loss {'Reaction outcome loss': 0.2182059916415477, 'Total loss': 0.2182059916415477}
2022-12-31 13:00:16,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:16,979 INFO:     Epoch: 86
2022-12-31 13:00:18,612 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4476854761441549, 'Total loss': 0.4476854761441549} | train loss {'Reaction outcome loss': 0.21774121912512323, 'Total loss': 0.21774121912512323}
2022-12-31 13:00:18,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:18,613 INFO:     Epoch: 87
2022-12-31 13:00:20,235 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4131081978480021, 'Total loss': 0.4131081978480021} | train loss {'Reaction outcome loss': 0.2137548642885276, 'Total loss': 0.2137548642885276}
2022-12-31 13:00:20,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:20,236 INFO:     Epoch: 88
2022-12-31 13:00:21,866 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41027417381604514, 'Total loss': 0.41027417381604514} | train loss {'Reaction outcome loss': 0.21270334324883533, 'Total loss': 0.21270334324883533}
2022-12-31 13:00:21,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:21,866 INFO:     Epoch: 89
2022-12-31 13:00:23,502 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3884492854277293, 'Total loss': 0.3884492854277293} | train loss {'Reaction outcome loss': 0.20361212545514967, 'Total loss': 0.20361212545514967}
2022-12-31 13:00:23,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:23,502 INFO:     Epoch: 90
2022-12-31 13:00:25,108 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4295390476783117, 'Total loss': 0.4295390476783117} | train loss {'Reaction outcome loss': 0.21319225654409465, 'Total loss': 0.21319225654409465}
2022-12-31 13:00:25,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:25,108 INFO:     Epoch: 91
2022-12-31 13:00:26,731 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39852672119935356, 'Total loss': 0.39852672119935356} | train loss {'Reaction outcome loss': 0.209362850541296, 'Total loss': 0.209362850541296}
2022-12-31 13:00:26,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:26,731 INFO:     Epoch: 92
2022-12-31 13:00:28,333 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4106552958488464, 'Total loss': 0.4106552958488464} | train loss {'Reaction outcome loss': 0.20598085133849714, 'Total loss': 0.20598085133849714}
2022-12-31 13:00:28,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:28,334 INFO:     Epoch: 93
2022-12-31 13:00:29,969 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41393268505732217, 'Total loss': 0.41393268505732217} | train loss {'Reaction outcome loss': 0.210956923851898, 'Total loss': 0.210956923851898}
2022-12-31 13:00:29,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:29,969 INFO:     Epoch: 94
2022-12-31 13:00:31,622 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.413211719195048, 'Total loss': 0.413211719195048} | train loss {'Reaction outcome loss': 0.20967477545249763, 'Total loss': 0.20967477545249763}
2022-12-31 13:00:31,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:31,622 INFO:     Epoch: 95
2022-12-31 13:00:33,254 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41228544314702353, 'Total loss': 0.41228544314702353} | train loss {'Reaction outcome loss': 0.20696138205268969, 'Total loss': 0.20696138205268969}
2022-12-31 13:00:33,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:33,254 INFO:     Epoch: 96
2022-12-31 13:00:34,868 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42541554967562356, 'Total loss': 0.42541554967562356} | train loss {'Reaction outcome loss': 0.2066507616184571, 'Total loss': 0.2066507616184571}
2022-12-31 13:00:34,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:34,868 INFO:     Epoch: 97
2022-12-31 13:00:36,494 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4040621762474378, 'Total loss': 0.4040621762474378} | train loss {'Reaction outcome loss': 0.20780454951234242, 'Total loss': 0.20780454951234242}
2022-12-31 13:00:36,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:36,495 INFO:     Epoch: 98
2022-12-31 13:00:38,097 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42917741735776266, 'Total loss': 0.42917741735776266} | train loss {'Reaction outcome loss': 0.20094501851832608, 'Total loss': 0.20094501851832608}
2022-12-31 13:00:38,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:38,097 INFO:     Epoch: 99
2022-12-31 13:00:39,712 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3951652745405833, 'Total loss': 0.3951652745405833} | train loss {'Reaction outcome loss': 0.2084820545228057, 'Total loss': 0.2084820545228057}
2022-12-31 13:00:39,712 INFO:     Best model found after epoch 75 of 100.
2022-12-31 13:00:39,712 INFO:   Done with stage: TRAINING
2022-12-31 13:00:39,712 INFO:   Starting stage: EVALUATION
2022-12-31 13:00:39,835 INFO:   Done with stage: EVALUATION
2022-12-31 13:00:39,835 INFO:   Leaving out SEQ value Fold_8
2022-12-31 13:00:39,847 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 13:00:39,848 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:00:40,512 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:00:40,512 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:00:40,581 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:00:40,581 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:00:40,581 INFO:     No hyperparam tuning for this model
2022-12-31 13:00:40,581 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:00:40,582 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:00:40,582 INFO:     None feature selector for col prot
2022-12-31 13:00:40,582 INFO:     None feature selector for col prot
2022-12-31 13:00:40,582 INFO:     None feature selector for col prot
2022-12-31 13:00:40,583 INFO:     None feature selector for col chem
2022-12-31 13:00:40,583 INFO:     None feature selector for col chem
2022-12-31 13:00:40,583 INFO:     None feature selector for col chem
2022-12-31 13:00:40,583 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:00:40,583 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:00:40,585 INFO:     Number of params in model 223921
2022-12-31 13:00:40,588 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:00:40,588 INFO:   Starting stage: TRAINING
2022-12-31 13:00:40,634 INFO:     Val loss before train {'Reaction outcome loss': 0.9713966568311055, 'Total loss': 0.9713966568311055}
2022-12-31 13:00:40,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:40,635 INFO:     Epoch: 0
2022-12-31 13:00:42,232 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.66454718708992, 'Total loss': 0.66454718708992} | train loss {'Reaction outcome loss': 0.8080339355374071, 'Total loss': 0.8080339355374071}
2022-12-31 13:00:42,233 INFO:     Found new best model at epoch 0
2022-12-31 13:00:42,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:42,233 INFO:     Epoch: 1
2022-12-31 13:00:43,852 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5749446074167888, 'Total loss': 0.5749446074167888} | train loss {'Reaction outcome loss': 0.5948259001496897, 'Total loss': 0.5948259001496897}
2022-12-31 13:00:43,852 INFO:     Found new best model at epoch 1
2022-12-31 13:00:43,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:43,853 INFO:     Epoch: 2
2022-12-31 13:00:45,493 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5046625792980194, 'Total loss': 0.5046625792980194} | train loss {'Reaction outcome loss': 0.5337762286624324, 'Total loss': 0.5337762286624324}
2022-12-31 13:00:45,493 INFO:     Found new best model at epoch 2
2022-12-31 13:00:45,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:45,494 INFO:     Epoch: 3
2022-12-31 13:00:47,119 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.512506843606631, 'Total loss': 0.512506843606631} | train loss {'Reaction outcome loss': 0.506934699330089, 'Total loss': 0.506934699330089}
2022-12-31 13:00:47,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:47,119 INFO:     Epoch: 4
2022-12-31 13:00:48,740 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5054794251918793, 'Total loss': 0.5054794251918793} | train loss {'Reaction outcome loss': 0.49602390217867137, 'Total loss': 0.49602390217867137}
2022-12-31 13:00:48,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:48,740 INFO:     Epoch: 5
2022-12-31 13:00:50,362 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4647374331951141, 'Total loss': 0.4647374331951141} | train loss {'Reaction outcome loss': 0.4859035879319756, 'Total loss': 0.4859035879319756}
2022-12-31 13:00:50,362 INFO:     Found new best model at epoch 5
2022-12-31 13:00:50,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:50,363 INFO:     Epoch: 6
2022-12-31 13:00:51,965 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4561209897200266, 'Total loss': 0.4561209897200266} | train loss {'Reaction outcome loss': 0.47029795381997036, 'Total loss': 0.47029795381997036}
2022-12-31 13:00:51,965 INFO:     Found new best model at epoch 6
2022-12-31 13:00:51,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:51,966 INFO:     Epoch: 7
2022-12-31 13:00:53,585 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4719675342241923, 'Total loss': 0.4719675342241923} | train loss {'Reaction outcome loss': 0.46825730999669446, 'Total loss': 0.46825730999669446}
2022-12-31 13:00:53,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:53,585 INFO:     Epoch: 8
2022-12-31 13:00:55,210 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4518408497174581, 'Total loss': 0.4518408497174581} | train loss {'Reaction outcome loss': 0.46038462393765844, 'Total loss': 0.46038462393765844}
2022-12-31 13:00:55,210 INFO:     Found new best model at epoch 8
2022-12-31 13:00:55,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:55,211 INFO:     Epoch: 9
2022-12-31 13:00:56,849 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45630059440930687, 'Total loss': 0.45630059440930687} | train loss {'Reaction outcome loss': 0.45210542158637235, 'Total loss': 0.45210542158637235}
2022-12-31 13:00:56,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:56,850 INFO:     Epoch: 10
2022-12-31 13:00:58,505 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46843911409378053, 'Total loss': 0.46843911409378053} | train loss {'Reaction outcome loss': 0.4423101359326056, 'Total loss': 0.4423101359326056}
2022-12-31 13:00:58,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:00:58,505 INFO:     Epoch: 11
2022-12-31 13:01:00,136 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45060421427090963, 'Total loss': 0.45060421427090963} | train loss {'Reaction outcome loss': 0.43768435770423836, 'Total loss': 0.43768435770423836}
2022-12-31 13:01:00,136 INFO:     Found new best model at epoch 11
2022-12-31 13:01:00,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:00,137 INFO:     Epoch: 12
2022-12-31 13:01:01,760 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45527089238166807, 'Total loss': 0.45527089238166807} | train loss {'Reaction outcome loss': 0.43418594791355547, 'Total loss': 0.43418594791355547}
2022-12-31 13:01:01,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:01,761 INFO:     Epoch: 13
2022-12-31 13:01:03,415 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44602552155653635, 'Total loss': 0.44602552155653635} | train loss {'Reaction outcome loss': 0.42406627627271176, 'Total loss': 0.42406627627271176}
2022-12-31 13:01:03,415 INFO:     Found new best model at epoch 13
2022-12-31 13:01:03,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:03,416 INFO:     Epoch: 14
2022-12-31 13:01:05,033 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4387523929278056, 'Total loss': 0.4387523929278056} | train loss {'Reaction outcome loss': 0.4207769824521421, 'Total loss': 0.4207769824521421}
2022-12-31 13:01:05,033 INFO:     Found new best model at epoch 14
2022-12-31 13:01:05,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:05,034 INFO:     Epoch: 15
2022-12-31 13:01:06,663 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.421970397233963, 'Total loss': 0.421970397233963} | train loss {'Reaction outcome loss': 0.41252310517570173, 'Total loss': 0.41252310517570173}
2022-12-31 13:01:06,664 INFO:     Found new best model at epoch 15
2022-12-31 13:01:06,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:06,665 INFO:     Epoch: 16
2022-12-31 13:01:08,290 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44907214045524596, 'Total loss': 0.44907214045524596} | train loss {'Reaction outcome loss': 0.41219935213830927, 'Total loss': 0.41219935213830927}
2022-12-31 13:01:08,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:08,290 INFO:     Epoch: 17
2022-12-31 13:01:09,902 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42409748236338296, 'Total loss': 0.42409748236338296} | train loss {'Reaction outcome loss': 0.4017084970370957, 'Total loss': 0.4017084970370957}
2022-12-31 13:01:09,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:09,902 INFO:     Epoch: 18
2022-12-31 13:01:11,530 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43531880974769593, 'Total loss': 0.43531880974769593} | train loss {'Reaction outcome loss': 0.398303687222813, 'Total loss': 0.398303687222813}
2022-12-31 13:01:11,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:11,531 INFO:     Epoch: 19
2022-12-31 13:01:13,159 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4112224300702413, 'Total loss': 0.4112224300702413} | train loss {'Reaction outcome loss': 0.3936892985921044, 'Total loss': 0.3936892985921044}
2022-12-31 13:01:13,159 INFO:     Found new best model at epoch 19
2022-12-31 13:01:13,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:13,160 INFO:     Epoch: 20
2022-12-31 13:01:14,772 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4181342283884684, 'Total loss': 0.4181342283884684} | train loss {'Reaction outcome loss': 0.3865240463173346, 'Total loss': 0.3865240463173346}
2022-12-31 13:01:14,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:14,772 INFO:     Epoch: 21
2022-12-31 13:01:16,428 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41239714324474336, 'Total loss': 0.41239714324474336} | train loss {'Reaction outcome loss': 0.3784987015199145, 'Total loss': 0.3784987015199145}
2022-12-31 13:01:16,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:16,429 INFO:     Epoch: 22
2022-12-31 13:01:18,063 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45094808042049406, 'Total loss': 0.45094808042049406} | train loss {'Reaction outcome loss': 0.3829494254253401, 'Total loss': 0.3829494254253401}
2022-12-31 13:01:18,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:18,064 INFO:     Epoch: 23
2022-12-31 13:01:19,690 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3955282251040141, 'Total loss': 0.3955282251040141} | train loss {'Reaction outcome loss': 0.3755391996474903, 'Total loss': 0.3755391996474903}
2022-12-31 13:01:19,690 INFO:     Found new best model at epoch 23
2022-12-31 13:01:19,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:19,691 INFO:     Epoch: 24
2022-12-31 13:01:21,305 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4376336336135864, 'Total loss': 0.4376336336135864} | train loss {'Reaction outcome loss': 0.36998953363632897, 'Total loss': 0.36998953363632897}
2022-12-31 13:01:21,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:21,305 INFO:     Epoch: 25
2022-12-31 13:01:22,932 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4339624394973119, 'Total loss': 0.4339624394973119} | train loss {'Reaction outcome loss': 0.36648470047686504, 'Total loss': 0.36648470047686504}
2022-12-31 13:01:22,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:22,932 INFO:     Epoch: 26
2022-12-31 13:01:24,568 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3859132354458173, 'Total loss': 0.3859132354458173} | train loss {'Reaction outcome loss': 0.35689343358743064, 'Total loss': 0.35689343358743064}
2022-12-31 13:01:24,569 INFO:     Found new best model at epoch 26
2022-12-31 13:01:24,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:24,570 INFO:     Epoch: 27
2022-12-31 13:01:26,182 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4077676862478256, 'Total loss': 0.4077676862478256} | train loss {'Reaction outcome loss': 0.35488226727350525, 'Total loss': 0.35488226727350525}
2022-12-31 13:01:26,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:26,182 INFO:     Epoch: 28
2022-12-31 13:01:27,784 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42022780179977415, 'Total loss': 0.42022780179977415} | train loss {'Reaction outcome loss': 0.3501346380271636, 'Total loss': 0.3501346380271636}
2022-12-31 13:01:27,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:27,784 INFO:     Epoch: 29
2022-12-31 13:01:29,398 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40353197157382964, 'Total loss': 0.40353197157382964} | train loss {'Reaction outcome loss': 0.3467314042393051, 'Total loss': 0.3467314042393051}
2022-12-31 13:01:29,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:29,398 INFO:     Epoch: 30
2022-12-31 13:01:31,013 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.398186586300532, 'Total loss': 0.398186586300532} | train loss {'Reaction outcome loss': 0.3358984259814562, 'Total loss': 0.3358984259814562}
2022-12-31 13:01:31,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:31,014 INFO:     Epoch: 31
2022-12-31 13:01:32,627 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3916734457015991, 'Total loss': 0.3916734457015991} | train loss {'Reaction outcome loss': 0.33690412568486555, 'Total loss': 0.33690412568486555}
2022-12-31 13:01:32,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:32,627 INFO:     Epoch: 32
2022-12-31 13:01:34,240 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4046168853839239, 'Total loss': 0.4046168853839239} | train loss {'Reaction outcome loss': 0.337394671911367, 'Total loss': 0.337394671911367}
2022-12-31 13:01:34,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:34,240 INFO:     Epoch: 33
2022-12-31 13:01:35,856 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3945255547761917, 'Total loss': 0.3945255547761917} | train loss {'Reaction outcome loss': 0.32967521607983413, 'Total loss': 0.32967521607983413}
2022-12-31 13:01:35,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:35,856 INFO:     Epoch: 34
2022-12-31 13:01:37,476 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4423554648955663, 'Total loss': 0.4423554648955663} | train loss {'Reaction outcome loss': 0.3228722446016456, 'Total loss': 0.3228722446016456}
2022-12-31 13:01:37,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:37,476 INFO:     Epoch: 35
2022-12-31 13:01:39,092 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37860104540983835, 'Total loss': 0.37860104540983835} | train loss {'Reaction outcome loss': 0.3206363646885118, 'Total loss': 0.3206363646885118}
2022-12-31 13:01:39,092 INFO:     Found new best model at epoch 35
2022-12-31 13:01:39,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:39,093 INFO:     Epoch: 36
2022-12-31 13:01:40,704 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39018393655618033, 'Total loss': 0.39018393655618033} | train loss {'Reaction outcome loss': 0.3218953825721672, 'Total loss': 0.3218953825721672}
2022-12-31 13:01:40,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:40,704 INFO:     Epoch: 37
2022-12-31 13:01:42,326 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39740587770938873, 'Total loss': 0.39740587770938873} | train loss {'Reaction outcome loss': 0.3187117659443122, 'Total loss': 0.3187117659443122}
2022-12-31 13:01:42,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:42,327 INFO:     Epoch: 38
2022-12-31 13:01:43,942 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37936384479204815, 'Total loss': 0.37936384479204815} | train loss {'Reaction outcome loss': 0.3196140184245385, 'Total loss': 0.3196140184245385}
2022-12-31 13:01:43,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:43,942 INFO:     Epoch: 39
2022-12-31 13:01:45,542 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3935528407494227, 'Total loss': 0.3935528407494227} | train loss {'Reaction outcome loss': 0.30435679559780804, 'Total loss': 0.30435679559780804}
2022-12-31 13:01:45,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:45,542 INFO:     Epoch: 40
2022-12-31 13:01:47,167 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43103666106859845, 'Total loss': 0.43103666106859845} | train loss {'Reaction outcome loss': 0.30526397027586344, 'Total loss': 0.30526397027586344}
2022-12-31 13:01:47,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:47,167 INFO:     Epoch: 41
2022-12-31 13:01:48,785 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4098330318927765, 'Total loss': 0.4098330318927765} | train loss {'Reaction outcome loss': 0.3018387770986299, 'Total loss': 0.3018387770986299}
2022-12-31 13:01:48,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:48,786 INFO:     Epoch: 42
2022-12-31 13:01:50,384 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40014459093411764, 'Total loss': 0.40014459093411764} | train loss {'Reaction outcome loss': 0.2923742770906605, 'Total loss': 0.2923742770906605}
2022-12-31 13:01:50,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:50,384 INFO:     Epoch: 43
2022-12-31 13:01:51,999 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3935717701911926, 'Total loss': 0.3935717701911926} | train loss {'Reaction outcome loss': 0.2934502009235134, 'Total loss': 0.2934502009235134}
2022-12-31 13:01:51,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:51,999 INFO:     Epoch: 44
2022-12-31 13:01:53,615 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39978134632110596, 'Total loss': 0.39978134632110596} | train loss {'Reaction outcome loss': 0.29565671792368164, 'Total loss': 0.29565671792368164}
2022-12-31 13:01:53,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:53,615 INFO:     Epoch: 45
2022-12-31 13:01:55,222 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40607838034629823, 'Total loss': 0.40607838034629823} | train loss {'Reaction outcome loss': 0.289333660639688, 'Total loss': 0.289333660639688}
2022-12-31 13:01:55,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:55,222 INFO:     Epoch: 46
2022-12-31 13:01:56,840 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3661782945195834, 'Total loss': 0.3661782945195834} | train loss {'Reaction outcome loss': 0.28909807714099056, 'Total loss': 0.28909807714099056}
2022-12-31 13:01:56,840 INFO:     Found new best model at epoch 46
2022-12-31 13:01:56,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:56,841 INFO:     Epoch: 47
2022-12-31 13:01:58,457 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38282427887121834, 'Total loss': 0.38282427887121834} | train loss {'Reaction outcome loss': 0.28425916742923457, 'Total loss': 0.28425916742923457}
2022-12-31 13:01:58,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:01:58,457 INFO:     Epoch: 48
2022-12-31 13:02:00,068 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38949826955795286, 'Total loss': 0.38949826955795286} | train loss {'Reaction outcome loss': 0.27971922709784786, 'Total loss': 0.27971922709784786}
2022-12-31 13:02:00,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:00,068 INFO:     Epoch: 49
2022-12-31 13:02:01,685 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4316317473848661, 'Total loss': 0.4316317473848661} | train loss {'Reaction outcome loss': 0.2786566880313068, 'Total loss': 0.2786566880313068}
2022-12-31 13:02:01,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:01,686 INFO:     Epoch: 50
2022-12-31 13:02:03,289 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3888647069533666, 'Total loss': 0.3888647069533666} | train loss {'Reaction outcome loss': 0.27373827820381536, 'Total loss': 0.27373827820381536}
2022-12-31 13:02:03,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:03,289 INFO:     Epoch: 51
2022-12-31 13:02:04,932 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3758960276842117, 'Total loss': 0.3758960276842117} | train loss {'Reaction outcome loss': 0.27820261426619675, 'Total loss': 0.27820261426619675}
2022-12-31 13:02:04,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:04,932 INFO:     Epoch: 52
2022-12-31 13:02:06,548 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4104543626308441, 'Total loss': 0.4104543626308441} | train loss {'Reaction outcome loss': 0.2724956583890674, 'Total loss': 0.2724956583890674}
2022-12-31 13:02:06,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:06,548 INFO:     Epoch: 53
2022-12-31 13:02:08,143 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3926856885353724, 'Total loss': 0.3926856885353724} | train loss {'Reaction outcome loss': 0.27139754959177026, 'Total loss': 0.27139754959177026}
2022-12-31 13:02:08,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:08,143 INFO:     Epoch: 54
2022-12-31 13:02:09,762 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38267849932114284, 'Total loss': 0.38267849932114284} | train loss {'Reaction outcome loss': 0.26853952632161254, 'Total loss': 0.26853952632161254}
2022-12-31 13:02:09,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:09,762 INFO:     Epoch: 55
2022-12-31 13:02:11,379 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3999566932519277, 'Total loss': 0.3999566932519277} | train loss {'Reaction outcome loss': 0.2644171540958249, 'Total loss': 0.2644171540958249}
2022-12-31 13:02:11,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:11,380 INFO:     Epoch: 56
2022-12-31 13:02:12,979 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.410817489027977, 'Total loss': 0.410817489027977} | train loss {'Reaction outcome loss': 0.26683065970344233, 'Total loss': 0.26683065970344233}
2022-12-31 13:02:12,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:12,981 INFO:     Epoch: 57
2022-12-31 13:02:14,593 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40992487271626793, 'Total loss': 0.40992487271626793} | train loss {'Reaction outcome loss': 0.26028608018364285, 'Total loss': 0.26028608018364285}
2022-12-31 13:02:14,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:14,593 INFO:     Epoch: 58
2022-12-31 13:02:16,220 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3957213054100672, 'Total loss': 0.3957213054100672} | train loss {'Reaction outcome loss': 0.2564911779271782, 'Total loss': 0.2564911779271782}
2022-12-31 13:02:16,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:16,220 INFO:     Epoch: 59
2022-12-31 13:02:17,817 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4020586202541987, 'Total loss': 0.4020586202541987} | train loss {'Reaction outcome loss': 0.2589341456386587, 'Total loss': 0.2589341456386587}
2022-12-31 13:02:17,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:17,817 INFO:     Epoch: 60
2022-12-31 13:02:19,443 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4006974051396052, 'Total loss': 0.4006974051396052} | train loss {'Reaction outcome loss': 0.2576217018874759, 'Total loss': 0.2576217018874759}
2022-12-31 13:02:19,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:19,444 INFO:     Epoch: 61
2022-12-31 13:02:21,049 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39134243230024973, 'Total loss': 0.39134243230024973} | train loss {'Reaction outcome loss': 0.2559986370497985, 'Total loss': 0.2559986370497985}
2022-12-31 13:02:21,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:21,049 INFO:     Epoch: 62
2022-12-31 13:02:22,652 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3915451367696126, 'Total loss': 0.3915451367696126} | train loss {'Reaction outcome loss': 0.2504875724361907, 'Total loss': 0.2504875724361907}
2022-12-31 13:02:22,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:22,652 INFO:     Epoch: 63
2022-12-31 13:02:24,262 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37179007480541865, 'Total loss': 0.37179007480541865} | train loss {'Reaction outcome loss': 0.24803241581020588, 'Total loss': 0.24803241581020588}
2022-12-31 13:02:24,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:24,263 INFO:     Epoch: 64
2022-12-31 13:02:25,857 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36927207273741564, 'Total loss': 0.36927207273741564} | train loss {'Reaction outcome loss': 0.2495892709020243, 'Total loss': 0.2495892709020243}
2022-12-31 13:02:25,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:25,857 INFO:     Epoch: 65
2022-12-31 13:02:27,491 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4118174413839976, 'Total loss': 0.4118174413839976} | train loss {'Reaction outcome loss': 0.24504372312112405, 'Total loss': 0.24504372312112405}
2022-12-31 13:02:27,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:27,491 INFO:     Epoch: 66
2022-12-31 13:02:29,122 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39490174055099486, 'Total loss': 0.39490174055099486} | train loss {'Reaction outcome loss': 0.24509171596879564, 'Total loss': 0.24509171596879564}
2022-12-31 13:02:29,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:29,122 INFO:     Epoch: 67
2022-12-31 13:02:30,759 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40023307005564374, 'Total loss': 0.40023307005564374} | train loss {'Reaction outcome loss': 0.24657652284344828, 'Total loss': 0.24657652284344828}
2022-12-31 13:02:30,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:30,759 INFO:     Epoch: 68
2022-12-31 13:02:32,387 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37399228910605115, 'Total loss': 0.37399228910605115} | train loss {'Reaction outcome loss': 0.24405555046476182, 'Total loss': 0.24405555046476182}
2022-12-31 13:02:32,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:32,387 INFO:     Epoch: 69
2022-12-31 13:02:34,041 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4008955230315526, 'Total loss': 0.4008955230315526} | train loss {'Reaction outcome loss': 0.24096341972451132, 'Total loss': 0.24096341972451132}
2022-12-31 13:02:34,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:34,041 INFO:     Epoch: 70
2022-12-31 13:02:35,672 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41364240447680156, 'Total loss': 0.41364240447680156} | train loss {'Reaction outcome loss': 0.2367683316745698, 'Total loss': 0.2367683316745698}
2022-12-31 13:02:35,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:35,672 INFO:     Epoch: 71
2022-12-31 13:02:37,293 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4003367414077123, 'Total loss': 0.4003367414077123} | train loss {'Reaction outcome loss': 0.24041303380355508, 'Total loss': 0.24041303380355508}
2022-12-31 13:02:37,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:37,293 INFO:     Epoch: 72
2022-12-31 13:02:38,923 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39420867959658307, 'Total loss': 0.39420867959658307} | train loss {'Reaction outcome loss': 0.23359363934946403, 'Total loss': 0.23359363934946403}
2022-12-31 13:02:38,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:38,923 INFO:     Epoch: 73
2022-12-31 13:02:40,532 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40934348801771797, 'Total loss': 0.40934348801771797} | train loss {'Reaction outcome loss': 0.23709293734618472, 'Total loss': 0.23709293734618472}
2022-12-31 13:02:40,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:40,533 INFO:     Epoch: 74
2022-12-31 13:02:42,145 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39418372909228006, 'Total loss': 0.39418372909228006} | train loss {'Reaction outcome loss': 0.2339256364273896, 'Total loss': 0.2339256364273896}
2022-12-31 13:02:42,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:42,145 INFO:     Epoch: 75
2022-12-31 13:02:43,769 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39749475518862404, 'Total loss': 0.39749475518862404} | train loss {'Reaction outcome loss': 0.2355552335212592, 'Total loss': 0.2355552335212592}
2022-12-31 13:02:43,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:43,770 INFO:     Epoch: 76
2022-12-31 13:02:45,387 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35860883394877113, 'Total loss': 0.35860883394877113} | train loss {'Reaction outcome loss': 0.23857772786049206, 'Total loss': 0.23857772786049206}
2022-12-31 13:02:45,387 INFO:     Found new best model at epoch 76
2022-12-31 13:02:45,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:45,388 INFO:     Epoch: 77
2022-12-31 13:02:46,994 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3651224752267202, 'Total loss': 0.3651224752267202} | train loss {'Reaction outcome loss': 0.22566803200472993, 'Total loss': 0.22566803200472993}
2022-12-31 13:02:46,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:46,994 INFO:     Epoch: 78
2022-12-31 13:02:48,590 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3814518392086029, 'Total loss': 0.3814518392086029} | train loss {'Reaction outcome loss': 0.2261992783894231, 'Total loss': 0.2261992783894231}
2022-12-31 13:02:48,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:48,591 INFO:     Epoch: 79
2022-12-31 13:02:50,203 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4065880199273427, 'Total loss': 0.4065880199273427} | train loss {'Reaction outcome loss': 0.22369785309644813, 'Total loss': 0.22369785309644813}
2022-12-31 13:02:50,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:50,204 INFO:     Epoch: 80
2022-12-31 13:02:51,814 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4026588678359985, 'Total loss': 0.4026588678359985} | train loss {'Reaction outcome loss': 0.22577856747359576, 'Total loss': 0.22577856747359576}
2022-12-31 13:02:51,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:51,814 INFO:     Epoch: 81
2022-12-31 13:02:53,411 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3801066180070241, 'Total loss': 0.3801066180070241} | train loss {'Reaction outcome loss': 0.2255975728794018, 'Total loss': 0.2255975728794018}
2022-12-31 13:02:53,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:53,412 INFO:     Epoch: 82
2022-12-31 13:02:55,067 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37447931319475175, 'Total loss': 0.37447931319475175} | train loss {'Reaction outcome loss': 0.22786007899562374, 'Total loss': 0.22786007899562374}
2022-12-31 13:02:55,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:55,067 INFO:     Epoch: 83
2022-12-31 13:02:56,723 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3649218345681826, 'Total loss': 0.3649218345681826} | train loss {'Reaction outcome loss': 0.22655527494740185, 'Total loss': 0.22655527494740185}
2022-12-31 13:02:56,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:56,723 INFO:     Epoch: 84
2022-12-31 13:02:58,320 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3982043822606405, 'Total loss': 0.3982043822606405} | train loss {'Reaction outcome loss': 0.22282493033779227, 'Total loss': 0.22282493033779227}
2022-12-31 13:02:58,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:58,321 INFO:     Epoch: 85
2022-12-31 13:02:59,935 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40701114734013877, 'Total loss': 0.40701114734013877} | train loss {'Reaction outcome loss': 0.2256698052160146, 'Total loss': 0.2256698052160146}
2022-12-31 13:02:59,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:02:59,935 INFO:     Epoch: 86
2022-12-31 13:03:01,549 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36893526315689085, 'Total loss': 0.36893526315689085} | train loss {'Reaction outcome loss': 0.21322462203431647, 'Total loss': 0.21322462203431647}
2022-12-31 13:03:01,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:01,550 INFO:     Epoch: 87
2022-12-31 13:03:03,179 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3961562693119049, 'Total loss': 0.3961562693119049} | train loss {'Reaction outcome loss': 0.2206015050653301, 'Total loss': 0.2206015050653301}
2022-12-31 13:03:03,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:03,180 INFO:     Epoch: 88
2022-12-31 13:03:04,799 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4141287793715795, 'Total loss': 0.4141287793715795} | train loss {'Reaction outcome loss': 0.21539463059109257, 'Total loss': 0.21539463059109257}
2022-12-31 13:03:04,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:04,800 INFO:     Epoch: 89
2022-12-31 13:03:06,395 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39222738419969877, 'Total loss': 0.39222738419969877} | train loss {'Reaction outcome loss': 0.2232449899968903, 'Total loss': 0.2232449899968903}
2022-12-31 13:03:06,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:06,396 INFO:     Epoch: 90
2022-12-31 13:03:08,064 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4401672720909119, 'Total loss': 0.4401672720909119} | train loss {'Reaction outcome loss': 0.21638887492933107, 'Total loss': 0.21638887492933107}
2022-12-31 13:03:08,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:08,065 INFO:     Epoch: 91
2022-12-31 13:03:09,685 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3763922154903412, 'Total loss': 0.3763922154903412} | train loss {'Reaction outcome loss': 0.2177609971485736, 'Total loss': 0.2177609971485736}
2022-12-31 13:03:09,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:09,685 INFO:     Epoch: 92
2022-12-31 13:03:11,283 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4088734904925028, 'Total loss': 0.4088734904925028} | train loss {'Reaction outcome loss': 0.20845306764225668, 'Total loss': 0.20845306764225668}
2022-12-31 13:03:11,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:11,284 INFO:     Epoch: 93
2022-12-31 13:03:12,899 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40168398022651675, 'Total loss': 0.40168398022651675} | train loss {'Reaction outcome loss': 0.2095717083635851, 'Total loss': 0.2095717083635851}
2022-12-31 13:03:12,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:12,900 INFO:     Epoch: 94
2022-12-31 13:03:14,514 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3621959492564201, 'Total loss': 0.3621959492564201} | train loss {'Reaction outcome loss': 0.2260009350813253, 'Total loss': 0.2260009350813253}
2022-12-31 13:03:14,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:14,515 INFO:     Epoch: 95
2022-12-31 13:03:16,106 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4080041617155075, 'Total loss': 0.4080041617155075} | train loss {'Reaction outcome loss': 0.21619042136205446, 'Total loss': 0.21619042136205446}
2022-12-31 13:03:16,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:16,106 INFO:     Epoch: 96
2022-12-31 13:03:17,748 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3939674496650696, 'Total loss': 0.3939674496650696} | train loss {'Reaction outcome loss': 0.2062101437834626, 'Total loss': 0.2062101437834626}
2022-12-31 13:03:17,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:17,749 INFO:     Epoch: 97
2022-12-31 13:03:19,362 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4003141830364863, 'Total loss': 0.4003141830364863} | train loss {'Reaction outcome loss': 0.21362757343893016, 'Total loss': 0.21362757343893016}
2022-12-31 13:03:19,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:19,363 INFO:     Epoch: 98
2022-12-31 13:03:20,962 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4229554762442907, 'Total loss': 0.4229554762442907} | train loss {'Reaction outcome loss': 0.2106957706195783, 'Total loss': 0.2106957706195783}
2022-12-31 13:03:20,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:20,963 INFO:     Epoch: 99
2022-12-31 13:03:22,581 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4174124201138814, 'Total loss': 0.4174124201138814} | train loss {'Reaction outcome loss': 0.21704072131025554, 'Total loss': 0.21704072131025554}
2022-12-31 13:03:22,581 INFO:     Best model found after epoch 77 of 100.
2022-12-31 13:03:22,581 INFO:   Done with stage: TRAINING
2022-12-31 13:03:22,581 INFO:   Starting stage: EVALUATION
2022-12-31 13:03:22,704 INFO:   Done with stage: EVALUATION
2022-12-31 13:03:22,704 INFO:   Leaving out SEQ value Fold_9
2022-12-31 13:03:22,717 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 13:03:22,717 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:03:23,378 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:03:23,378 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:03:23,447 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:03:23,447 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:03:23,447 INFO:     No hyperparam tuning for this model
2022-12-31 13:03:23,447 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:03:23,447 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:03:23,448 INFO:     None feature selector for col prot
2022-12-31 13:03:23,448 INFO:     None feature selector for col prot
2022-12-31 13:03:23,448 INFO:     None feature selector for col prot
2022-12-31 13:03:23,449 INFO:     None feature selector for col chem
2022-12-31 13:03:23,449 INFO:     None feature selector for col chem
2022-12-31 13:03:23,449 INFO:     None feature selector for col chem
2022-12-31 13:03:23,449 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:03:23,449 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:03:23,451 INFO:     Number of params in model 223921
2022-12-31 13:03:23,454 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:03:23,454 INFO:   Starting stage: TRAINING
2022-12-31 13:03:23,501 INFO:     Val loss before train {'Reaction outcome loss': 0.9790738185246786, 'Total loss': 0.9790738185246786}
2022-12-31 13:03:23,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:23,501 INFO:     Epoch: 0
2022-12-31 13:03:25,087 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6747200628121693, 'Total loss': 0.6747200628121693} | train loss {'Reaction outcome loss': 0.8129390540131687, 'Total loss': 0.8129390540131687}
2022-12-31 13:03:25,087 INFO:     Found new best model at epoch 0
2022-12-31 13:03:25,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:25,088 INFO:     Epoch: 1
2022-12-31 13:03:26,689 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5080338835716247, 'Total loss': 0.5080338835716247} | train loss {'Reaction outcome loss': 0.6005774468836123, 'Total loss': 0.6005774468836123}
2022-12-31 13:03:26,690 INFO:     Found new best model at epoch 1
2022-12-31 13:03:26,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:26,691 INFO:     Epoch: 2
2022-12-31 13:03:28,293 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4974532504876455, 'Total loss': 0.4974532504876455} | train loss {'Reaction outcome loss': 0.5257010896057979, 'Total loss': 0.5257010896057979}
2022-12-31 13:03:28,293 INFO:     Found new best model at epoch 2
2022-12-31 13:03:28,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:28,294 INFO:     Epoch: 3
2022-12-31 13:03:29,881 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45502610703309376, 'Total loss': 0.45502610703309376} | train loss {'Reaction outcome loss': 0.49138230808677463, 'Total loss': 0.49138230808677463}
2022-12-31 13:03:29,881 INFO:     Found new best model at epoch 3
2022-12-31 13:03:29,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:29,882 INFO:     Epoch: 4
2022-12-31 13:03:31,483 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4392631163199743, 'Total loss': 0.4392631163199743} | train loss {'Reaction outcome loss': 0.4781764747343794, 'Total loss': 0.4781764747343794}
2022-12-31 13:03:31,483 INFO:     Found new best model at epoch 4
2022-12-31 13:03:31,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:31,484 INFO:     Epoch: 5
2022-12-31 13:03:33,084 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4703066120545069, 'Total loss': 0.4703066120545069} | train loss {'Reaction outcome loss': 0.46799664922656803, 'Total loss': 0.46799664922656803}
2022-12-31 13:03:33,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:33,085 INFO:     Epoch: 6
2022-12-31 13:03:34,669 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43827068408330283, 'Total loss': 0.43827068408330283} | train loss {'Reaction outcome loss': 0.46102310020993226, 'Total loss': 0.46102310020993226}
2022-12-31 13:03:34,669 INFO:     Found new best model at epoch 6
2022-12-31 13:03:34,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:34,670 INFO:     Epoch: 7
2022-12-31 13:03:36,272 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42851431518793104, 'Total loss': 0.42851431518793104} | train loss {'Reaction outcome loss': 0.4523978852225046, 'Total loss': 0.4523978852225046}
2022-12-31 13:03:36,272 INFO:     Found new best model at epoch 7
2022-12-31 13:03:36,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:36,273 INFO:     Epoch: 8
2022-12-31 13:03:37,871 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4218180219332377, 'Total loss': 0.4218180219332377} | train loss {'Reaction outcome loss': 0.44481935052976124, 'Total loss': 0.44481935052976124}
2022-12-31 13:03:37,871 INFO:     Found new best model at epoch 8
2022-12-31 13:03:37,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:37,872 INFO:     Epoch: 9
2022-12-31 13:03:39,456 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42623666326204934, 'Total loss': 0.42623666326204934} | train loss {'Reaction outcome loss': 0.4361020824769988, 'Total loss': 0.4361020824769988}
2022-12-31 13:03:39,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:39,456 INFO:     Epoch: 10
2022-12-31 13:03:41,059 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4123963216940562, 'Total loss': 0.4123963216940562} | train loss {'Reaction outcome loss': 0.431187614472243, 'Total loss': 0.431187614472243}
2022-12-31 13:03:41,059 INFO:     Found new best model at epoch 10
2022-12-31 13:03:41,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:41,060 INFO:     Epoch: 11
2022-12-31 13:03:42,651 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41236368417739866, 'Total loss': 0.41236368417739866} | train loss {'Reaction outcome loss': 0.42442260119710523, 'Total loss': 0.42442260119710523}
2022-12-31 13:03:42,651 INFO:     Found new best model at epoch 11
2022-12-31 13:03:42,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:42,652 INFO:     Epoch: 12
2022-12-31 13:03:44,280 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41623400449752807, 'Total loss': 0.41623400449752807} | train loss {'Reaction outcome loss': 0.41991239908511624, 'Total loss': 0.41991239908511624}
2022-12-31 13:03:44,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:44,281 INFO:     Epoch: 13
2022-12-31 13:03:45,893 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4137765218814214, 'Total loss': 0.4137765218814214} | train loss {'Reaction outcome loss': 0.4082575610628093, 'Total loss': 0.4082575610628093}
2022-12-31 13:03:45,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:45,895 INFO:     Epoch: 14
2022-12-31 13:03:47,509 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3909446313977242, 'Total loss': 0.3909446313977242} | train loss {'Reaction outcome loss': 0.4074522787093246, 'Total loss': 0.4074522787093246}
2022-12-31 13:03:47,509 INFO:     Found new best model at epoch 14
2022-12-31 13:03:47,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:47,510 INFO:     Epoch: 15
2022-12-31 13:03:49,159 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.441063666343689, 'Total loss': 0.441063666343689} | train loss {'Reaction outcome loss': 0.3977901043683073, 'Total loss': 0.3977901043683073}
2022-12-31 13:03:49,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:49,159 INFO:     Epoch: 16
2022-12-31 13:03:50,797 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40834106008211773, 'Total loss': 0.40834106008211773} | train loss {'Reaction outcome loss': 0.40135062023671003, 'Total loss': 0.40135062023671003}
2022-12-31 13:03:50,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:50,797 INFO:     Epoch: 17
2022-12-31 13:03:52,413 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4419424633185069, 'Total loss': 0.4419424633185069} | train loss {'Reaction outcome loss': 0.3933464429021752, 'Total loss': 0.3933464429021752}
2022-12-31 13:03:52,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:52,414 INFO:     Epoch: 18
2022-12-31 13:03:54,060 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4127843956152598, 'Total loss': 0.4127843956152598} | train loss {'Reaction outcome loss': 0.37608637481275264, 'Total loss': 0.37608637481275264}
2022-12-31 13:03:54,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:54,060 INFO:     Epoch: 19
2022-12-31 13:03:55,717 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4352111647526423, 'Total loss': 0.4352111647526423} | train loss {'Reaction outcome loss': 0.378987556880843, 'Total loss': 0.378987556880843}
2022-12-31 13:03:55,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:55,718 INFO:     Epoch: 20
2022-12-31 13:03:57,307 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4313527822494507, 'Total loss': 0.4313527822494507} | train loss {'Reaction outcome loss': 0.3695618653275671, 'Total loss': 0.3695618653275671}
2022-12-31 13:03:57,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:57,308 INFO:     Epoch: 21
2022-12-31 13:03:58,918 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3890947222709656, 'Total loss': 0.3890947222709656} | train loss {'Reaction outcome loss': 0.3638044950844598, 'Total loss': 0.3638044950844598}
2022-12-31 13:03:58,918 INFO:     Found new best model at epoch 21
2022-12-31 13:03:58,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:03:58,919 INFO:     Epoch: 22
2022-12-31 13:04:00,520 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40393367608388264, 'Total loss': 0.40393367608388264} | train loss {'Reaction outcome loss': 0.35694847139020036, 'Total loss': 0.35694847139020036}
2022-12-31 13:04:00,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:00,521 INFO:     Epoch: 23
2022-12-31 13:04:02,117 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4465671281019847, 'Total loss': 0.4465671281019847} | train loss {'Reaction outcome loss': 0.3557664892316735, 'Total loss': 0.3557664892316735}
2022-12-31 13:04:02,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:02,117 INFO:     Epoch: 24
2022-12-31 13:04:03,725 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4333388974269231, 'Total loss': 0.4333388974269231} | train loss {'Reaction outcome loss': 0.3468506996975328, 'Total loss': 0.3468506996975328}
2022-12-31 13:04:03,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:03,726 INFO:     Epoch: 25
2022-12-31 13:04:05,328 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3891694098711014, 'Total loss': 0.3891694098711014} | train loss {'Reaction outcome loss': 0.3418112441516706, 'Total loss': 0.3418112441516706}
2022-12-31 13:04:05,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:05,329 INFO:     Epoch: 26
2022-12-31 13:04:06,924 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39871046245098113, 'Total loss': 0.39871046245098113} | train loss {'Reaction outcome loss': 0.33835939951512933, 'Total loss': 0.33835939951512933}
2022-12-31 13:04:06,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:06,924 INFO:     Epoch: 27
2022-12-31 13:04:08,533 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40114973386128744, 'Total loss': 0.40114973386128744} | train loss {'Reaction outcome loss': 0.33796374081042563, 'Total loss': 0.33796374081042563}
2022-12-31 13:04:08,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:08,533 INFO:     Epoch: 28
2022-12-31 13:04:10,129 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.385953634728988, 'Total loss': 0.385953634728988} | train loss {'Reaction outcome loss': 0.332851712897855, 'Total loss': 0.332851712897855}
2022-12-31 13:04:10,129 INFO:     Found new best model at epoch 28
2022-12-31 13:04:10,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:10,130 INFO:     Epoch: 29
2022-12-31 13:04:11,747 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3818408856789271, 'Total loss': 0.3818408856789271} | train loss {'Reaction outcome loss': 0.32794955380967933, 'Total loss': 0.32794955380967933}
2022-12-31 13:04:11,748 INFO:     Found new best model at epoch 29
2022-12-31 13:04:11,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:11,749 INFO:     Epoch: 30
2022-12-31 13:04:13,358 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4109527160724004, 'Total loss': 0.4109527160724004} | train loss {'Reaction outcome loss': 0.315540342027471, 'Total loss': 0.315540342027471}
2022-12-31 13:04:13,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:13,359 INFO:     Epoch: 31
2022-12-31 13:04:14,949 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39655652865767477, 'Total loss': 0.39655652865767477} | train loss {'Reaction outcome loss': 0.31267155304442357, 'Total loss': 0.31267155304442357}
2022-12-31 13:04:14,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:14,949 INFO:     Epoch: 32
2022-12-31 13:04:16,561 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39803335070610046, 'Total loss': 0.39803335070610046} | train loss {'Reaction outcome loss': 0.3135702716064279, 'Total loss': 0.3135702716064279}
2022-12-31 13:04:16,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:16,562 INFO:     Epoch: 33
2022-12-31 13:04:18,172 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4451385935147603, 'Total loss': 0.4451385935147603} | train loss {'Reaction outcome loss': 0.3073729730625875, 'Total loss': 0.3073729730625875}
2022-12-31 13:04:18,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:18,173 INFO:     Epoch: 34
2022-12-31 13:04:19,766 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4476652959982554, 'Total loss': 0.4476652959982554} | train loss {'Reaction outcome loss': 0.3087600857821585, 'Total loss': 0.3087600857821585}
2022-12-31 13:04:19,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:19,767 INFO:     Epoch: 35
2022-12-31 13:04:21,376 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4299493681639433, 'Total loss': 0.4299493681639433} | train loss {'Reaction outcome loss': 0.3028349212105692, 'Total loss': 0.3028349212105692}
2022-12-31 13:04:21,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:21,378 INFO:     Epoch: 36
2022-12-31 13:04:22,988 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37453267772992455, 'Total loss': 0.37453267772992455} | train loss {'Reaction outcome loss': 0.29569472485378273, 'Total loss': 0.29569472485378273}
2022-12-31 13:04:22,988 INFO:     Found new best model at epoch 36
2022-12-31 13:04:22,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:22,989 INFO:     Epoch: 37
2022-12-31 13:04:24,577 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3926408150543769, 'Total loss': 0.3926408150543769} | train loss {'Reaction outcome loss': 0.2922047048222518, 'Total loss': 0.2922047048222518}
2022-12-31 13:04:24,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:24,577 INFO:     Epoch: 38
2022-12-31 13:04:26,189 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3934681157271067, 'Total loss': 0.3934681157271067} | train loss {'Reaction outcome loss': 0.2922920871893094, 'Total loss': 0.2922920871893094}
2022-12-31 13:04:26,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:26,189 INFO:     Epoch: 39
2022-12-31 13:04:27,799 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40961533387502036, 'Total loss': 0.40961533387502036} | train loss {'Reaction outcome loss': 0.28404278285040035, 'Total loss': 0.28404278285040035}
2022-12-31 13:04:27,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:27,800 INFO:     Epoch: 40
2022-12-31 13:04:29,417 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36650683879852297, 'Total loss': 0.36650683879852297} | train loss {'Reaction outcome loss': 0.29203159856970295, 'Total loss': 0.29203159856970295}
2022-12-31 13:04:29,417 INFO:     Found new best model at epoch 40
2022-12-31 13:04:29,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:29,418 INFO:     Epoch: 41
2022-12-31 13:04:31,047 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4129337340593338, 'Total loss': 0.4129337340593338} | train loss {'Reaction outcome loss': 0.2802920987843162, 'Total loss': 0.2802920987843162}
2022-12-31 13:04:31,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:31,047 INFO:     Epoch: 42
2022-12-31 13:04:32,653 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3747262974580129, 'Total loss': 0.3747262974580129} | train loss {'Reaction outcome loss': 0.27843202034650494, 'Total loss': 0.27843202034650494}
2022-12-31 13:04:32,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:32,653 INFO:     Epoch: 43
2022-12-31 13:04:34,247 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4304644584655762, 'Total loss': 0.4304644584655762} | train loss {'Reaction outcome loss': 0.2764276381391678, 'Total loss': 0.2764276381391678}
2022-12-31 13:04:34,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:34,248 INFO:     Epoch: 44
2022-12-31 13:04:35,851 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4295161177714666, 'Total loss': 0.4295161177714666} | train loss {'Reaction outcome loss': 0.27060770912327037, 'Total loss': 0.27060770912327037}
2022-12-31 13:04:35,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:35,851 INFO:     Epoch: 45
2022-12-31 13:04:37,465 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4257487048705419, 'Total loss': 0.4257487048705419} | train loss {'Reaction outcome loss': 0.2703839937891186, 'Total loss': 0.2703839937891186}
2022-12-31 13:04:37,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:37,465 INFO:     Epoch: 46
2022-12-31 13:04:39,072 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4240229914585749, 'Total loss': 0.4240229914585749} | train loss {'Reaction outcome loss': 0.27915507788858274, 'Total loss': 0.27915507788858274}
2022-12-31 13:04:39,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:39,072 INFO:     Epoch: 47
2022-12-31 13:04:40,678 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3918841620286306, 'Total loss': 0.3918841620286306} | train loss {'Reaction outcome loss': 0.26382525496347975, 'Total loss': 0.26382525496347975}
2022-12-31 13:04:40,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:40,679 INFO:     Epoch: 48
2022-12-31 13:04:42,271 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3758324076732, 'Total loss': 0.3758324076732} | train loss {'Reaction outcome loss': 0.2602247559757781, 'Total loss': 0.2602247559757781}
2022-12-31 13:04:42,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:42,271 INFO:     Epoch: 49
2022-12-31 13:04:43,879 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3853886976838112, 'Total loss': 0.3853886976838112} | train loss {'Reaction outcome loss': 0.2577543427528691, 'Total loss': 0.2577543427528691}
2022-12-31 13:04:43,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:43,879 INFO:     Epoch: 50
2022-12-31 13:04:45,486 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3805626044670741, 'Total loss': 0.3805626044670741} | train loss {'Reaction outcome loss': 0.25342467223314474, 'Total loss': 0.25342467223314474}
2022-12-31 13:04:45,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:45,486 INFO:     Epoch: 51
2022-12-31 13:04:47,078 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3811016211907069, 'Total loss': 0.3811016211907069} | train loss {'Reaction outcome loss': 0.25314628442980514, 'Total loss': 0.25314628442980514}
2022-12-31 13:04:47,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:47,078 INFO:     Epoch: 52
2022-12-31 13:04:48,684 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3486943413813909, 'Total loss': 0.3486943413813909} | train loss {'Reaction outcome loss': 0.2521751399226759, 'Total loss': 0.2521751399226759}
2022-12-31 13:04:48,684 INFO:     Found new best model at epoch 52
2022-12-31 13:04:48,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:48,685 INFO:     Epoch: 53
2022-12-31 13:04:50,290 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41403537889321645, 'Total loss': 0.41403537889321645} | train loss {'Reaction outcome loss': 0.2557357176186612, 'Total loss': 0.2557357176186612}
2022-12-31 13:04:50,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:50,291 INFO:     Epoch: 54
2022-12-31 13:04:51,905 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3684136907259623, 'Total loss': 0.3684136907259623} | train loss {'Reaction outcome loss': 0.2463027265221968, 'Total loss': 0.2463027265221968}
2022-12-31 13:04:51,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:51,905 INFO:     Epoch: 55
2022-12-31 13:04:53,560 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3906972964604696, 'Total loss': 0.3906972964604696} | train loss {'Reaction outcome loss': 0.24562993201760264, 'Total loss': 0.24562993201760264}
2022-12-31 13:04:53,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:53,561 INFO:     Epoch: 56
2022-12-31 13:04:55,186 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3964831074078878, 'Total loss': 0.3964831074078878} | train loss {'Reaction outcome loss': 0.24595973193373558, 'Total loss': 0.24595973193373558}
2022-12-31 13:04:55,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:55,186 INFO:     Epoch: 57
2022-12-31 13:04:56,794 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4166775266329447, 'Total loss': 0.4166775266329447} | train loss {'Reaction outcome loss': 0.246530067107647, 'Total loss': 0.246530067107647}
2022-12-31 13:04:56,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:56,795 INFO:     Epoch: 58
2022-12-31 13:04:58,401 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39844032923380535, 'Total loss': 0.39844032923380535} | train loss {'Reaction outcome loss': 0.23535956436237931, 'Total loss': 0.23535956436237931}
2022-12-31 13:04:58,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:58,401 INFO:     Epoch: 59
2022-12-31 13:04:59,989 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4286069944500923, 'Total loss': 0.4286069944500923} | train loss {'Reaction outcome loss': 0.2401032497983997, 'Total loss': 0.2401032497983997}
2022-12-31 13:04:59,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:04:59,990 INFO:     Epoch: 60
2022-12-31 13:05:01,585 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45516267319520315, 'Total loss': 0.45516267319520315} | train loss {'Reaction outcome loss': 0.2398284723417983, 'Total loss': 0.2398284723417983}
2022-12-31 13:05:01,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:01,585 INFO:     Epoch: 61
2022-12-31 13:05:03,219 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4006426880757014, 'Total loss': 0.4006426880757014} | train loss {'Reaction outcome loss': 0.23975223170960472, 'Total loss': 0.23975223170960472}
2022-12-31 13:05:03,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:03,220 INFO:     Epoch: 62
2022-12-31 13:05:04,825 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3790432949860891, 'Total loss': 0.3790432949860891} | train loss {'Reaction outcome loss': 0.23317646395659794, 'Total loss': 0.23317646395659794}
2022-12-31 13:05:04,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:04,825 INFO:     Epoch: 63
2022-12-31 13:05:06,428 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3903267204761505, 'Total loss': 0.3903267204761505} | train loss {'Reaction outcome loss': 0.24069303246962764, 'Total loss': 0.24069303246962764}
2022-12-31 13:05:06,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:06,428 INFO:     Epoch: 64
2022-12-31 13:05:08,030 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4336009591817856, 'Total loss': 0.4336009591817856} | train loss {'Reaction outcome loss': 0.2283363862466203, 'Total loss': 0.2283363862466203}
2022-12-31 13:05:08,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:08,030 INFO:     Epoch: 65
2022-12-31 13:05:09,625 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35941064755121865, 'Total loss': 0.35941064755121865} | train loss {'Reaction outcome loss': 0.22864043587533228, 'Total loss': 0.22864043587533228}
2022-12-31 13:05:09,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:09,626 INFO:     Epoch: 66
2022-12-31 13:05:11,261 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4276353473464648, 'Total loss': 0.4276353473464648} | train loss {'Reaction outcome loss': 0.2267443294684491, 'Total loss': 0.2267443294684491}
2022-12-31 13:05:11,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:11,261 INFO:     Epoch: 67
2022-12-31 13:05:12,866 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3759509334961573, 'Total loss': 0.3759509334961573} | train loss {'Reaction outcome loss': 0.22770787559340905, 'Total loss': 0.22770787559340905}
2022-12-31 13:05:12,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:12,867 INFO:     Epoch: 68
2022-12-31 13:05:14,462 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3594799190759659, 'Total loss': 0.3594799190759659} | train loss {'Reaction outcome loss': 0.22284910396883523, 'Total loss': 0.22284910396883523}
2022-12-31 13:05:14,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:14,462 INFO:     Epoch: 69
2022-12-31 13:05:16,064 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3682006095846494, 'Total loss': 0.3682006095846494} | train loss {'Reaction outcome loss': 0.23084721097002064, 'Total loss': 0.23084721097002064}
2022-12-31 13:05:16,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:16,065 INFO:     Epoch: 70
2022-12-31 13:05:17,672 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3933763345082601, 'Total loss': 0.3933763345082601} | train loss {'Reaction outcome loss': 0.22310499478485027, 'Total loss': 0.22310499478485027}
2022-12-31 13:05:17,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:17,672 INFO:     Epoch: 71
2022-12-31 13:05:19,259 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38548754950364433, 'Total loss': 0.38548754950364433} | train loss {'Reaction outcome loss': 0.22323921028470253, 'Total loss': 0.22323921028470253}
2022-12-31 13:05:19,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:19,259 INFO:     Epoch: 72
2022-12-31 13:05:20,864 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3924667765696844, 'Total loss': 0.3924667765696844} | train loss {'Reaction outcome loss': 0.22107090379526145, 'Total loss': 0.22107090379526145}
2022-12-31 13:05:20,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:20,864 INFO:     Epoch: 73
2022-12-31 13:05:22,449 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3610081891218821, 'Total loss': 0.3610081891218821} | train loss {'Reaction outcome loss': 0.21870618252369173, 'Total loss': 0.21870618252369173}
2022-12-31 13:05:22,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:22,449 INFO:     Epoch: 74
2022-12-31 13:05:24,054 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41169517238934833, 'Total loss': 0.41169517238934833} | train loss {'Reaction outcome loss': 0.21747951470587376, 'Total loss': 0.21747951470587376}
2022-12-31 13:05:24,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:24,054 INFO:     Epoch: 75
2022-12-31 13:05:25,660 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37717780073483786, 'Total loss': 0.37717780073483786} | train loss {'Reaction outcome loss': 0.22147060720331585, 'Total loss': 0.22147060720331585}
2022-12-31 13:05:25,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:25,660 INFO:     Epoch: 76
2022-12-31 13:05:27,248 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38567756017049154, 'Total loss': 0.38567756017049154} | train loss {'Reaction outcome loss': 0.21847765231980895, 'Total loss': 0.21847765231980895}
2022-12-31 13:05:27,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:27,249 INFO:     Epoch: 77
2022-12-31 13:05:28,859 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38417344391345976, 'Total loss': 0.38417344391345976} | train loss {'Reaction outcome loss': 0.2132845694593487, 'Total loss': 0.2132845694593487}
2022-12-31 13:05:28,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:28,859 INFO:     Epoch: 78
2022-12-31 13:05:30,468 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3639868378639221, 'Total loss': 0.3639868378639221} | train loss {'Reaction outcome loss': 0.20909831863929973, 'Total loss': 0.20909831863929973}
2022-12-31 13:05:30,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:30,468 INFO:     Epoch: 79
2022-12-31 13:05:32,062 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3884394347667694, 'Total loss': 0.3884394347667694} | train loss {'Reaction outcome loss': 0.21086578956213745, 'Total loss': 0.21086578956213745}
2022-12-31 13:05:32,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:32,062 INFO:     Epoch: 80
2022-12-31 13:05:33,670 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4494590292374293, 'Total loss': 0.4494590292374293} | train loss {'Reaction outcome loss': 0.2086089776801693, 'Total loss': 0.2086089776801693}
2022-12-31 13:05:33,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:33,671 INFO:     Epoch: 81
2022-12-31 13:05:35,275 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36903753181298576, 'Total loss': 0.36903753181298576} | train loss {'Reaction outcome loss': 0.20623772103937654, 'Total loss': 0.20623772103937654}
2022-12-31 13:05:35,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:35,276 INFO:     Epoch: 82
2022-12-31 13:05:36,874 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3903397853175799, 'Total loss': 0.3903397853175799} | train loss {'Reaction outcome loss': 0.2153208736520614, 'Total loss': 0.2153208736520614}
2022-12-31 13:05:36,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:36,874 INFO:     Epoch: 83
2022-12-31 13:05:38,503 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40256872177124026, 'Total loss': 0.40256872177124026} | train loss {'Reaction outcome loss': 0.20903113469427084, 'Total loss': 0.20903113469427084}
2022-12-31 13:05:38,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:38,503 INFO:     Epoch: 84
2022-12-31 13:05:40,105 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40495348572731016, 'Total loss': 0.40495348572731016} | train loss {'Reaction outcome loss': 0.20863178258177137, 'Total loss': 0.20863178258177137}
2022-12-31 13:05:40,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:40,105 INFO:     Epoch: 85
2022-12-31 13:05:41,702 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4040797824660937, 'Total loss': 0.4040797824660937} | train loss {'Reaction outcome loss': 0.20820656474883648, 'Total loss': 0.20820656474883648}
2022-12-31 13:05:41,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:41,702 INFO:     Epoch: 86
2022-12-31 13:05:43,308 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3697131420175234, 'Total loss': 0.3697131420175234} | train loss {'Reaction outcome loss': 0.20531405947667403, 'Total loss': 0.20531405947667403}
2022-12-31 13:05:43,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:43,308 INFO:     Epoch: 87
2022-12-31 13:05:44,913 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38022977610429126, 'Total loss': 0.38022977610429126} | train loss {'Reaction outcome loss': 0.20629113942493488, 'Total loss': 0.20629113942493488}
2022-12-31 13:05:44,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:44,914 INFO:     Epoch: 88
2022-12-31 13:05:46,519 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3748055617014567, 'Total loss': 0.3748055617014567} | train loss {'Reaction outcome loss': 0.19369482620870762, 'Total loss': 0.19369482620870762}
2022-12-31 13:05:46,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:46,520 INFO:     Epoch: 89
2022-12-31 13:05:48,127 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.372790456811587, 'Total loss': 0.372790456811587} | train loss {'Reaction outcome loss': 0.19682182321311348, 'Total loss': 0.19682182321311348}
2022-12-31 13:05:48,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:48,127 INFO:     Epoch: 90
2022-12-31 13:05:49,722 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3905173939963182, 'Total loss': 0.3905173939963182} | train loss {'Reaction outcome loss': 0.2027548350747267, 'Total loss': 0.2027548350747267}
2022-12-31 13:05:49,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:49,723 INFO:     Epoch: 91
2022-12-31 13:05:51,328 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3946267814685901, 'Total loss': 0.3946267814685901} | train loss {'Reaction outcome loss': 0.20599903907273373, 'Total loss': 0.20599903907273373}
2022-12-31 13:05:51,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:51,328 INFO:     Epoch: 92
2022-12-31 13:05:52,935 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3732274413108826, 'Total loss': 0.3732274413108826} | train loss {'Reaction outcome loss': 0.2033222257499549, 'Total loss': 0.2033222257499549}
2022-12-31 13:05:52,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:52,935 INFO:     Epoch: 93
2022-12-31 13:05:54,519 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3656311353047689, 'Total loss': 0.3656311353047689} | train loss {'Reaction outcome loss': 0.19528461198737151, 'Total loss': 0.19528461198737151}
2022-12-31 13:05:54,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:54,520 INFO:     Epoch: 94
2022-12-31 13:05:56,152 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4061007370551427, 'Total loss': 0.4061007370551427} | train loss {'Reaction outcome loss': 0.19671923611109166, 'Total loss': 0.19671923611109166}
2022-12-31 13:05:56,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:56,152 INFO:     Epoch: 95
2022-12-31 13:05:57,763 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41457270085811615, 'Total loss': 0.41457270085811615} | train loss {'Reaction outcome loss': 0.19083367801359752, 'Total loss': 0.19083367801359752}
2022-12-31 13:05:57,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:57,764 INFO:     Epoch: 96
2022-12-31 13:05:59,365 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.429005973537763, 'Total loss': 0.429005973537763} | train loss {'Reaction outcome loss': 0.19655167224415898, 'Total loss': 0.19655167224415898}
2022-12-31 13:05:59,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:05:59,365 INFO:     Epoch: 97
2022-12-31 13:06:00,973 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37335897187391914, 'Total loss': 0.37335897187391914} | train loss {'Reaction outcome loss': 0.1924746263785845, 'Total loss': 0.1924746263785845}
2022-12-31 13:06:00,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:00,974 INFO:     Epoch: 98
2022-12-31 13:06:02,584 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38775940587123237, 'Total loss': 0.38775940587123237} | train loss {'Reaction outcome loss': 0.1897000531346476, 'Total loss': 0.1897000531346476}
2022-12-31 13:06:02,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:02,584 INFO:     Epoch: 99
2022-12-31 13:06:04,174 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3962390830119451, 'Total loss': 0.3962390830119451} | train loss {'Reaction outcome loss': 0.19408699845636848, 'Total loss': 0.19408699845636848}
2022-12-31 13:06:04,175 INFO:     Best model found after epoch 53 of 100.
2022-12-31 13:06:04,175 INFO:   Done with stage: TRAINING
2022-12-31 13:06:04,175 INFO:   Starting stage: EVALUATION
2022-12-31 13:06:04,311 INFO:   Done with stage: EVALUATION
2022-12-31 13:06:04,319 INFO:   Leaving out SEQ value Fold_0
2022-12-31 13:06:04,332 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 13:06:04,333 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:06:04,981 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:06:04,981 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:06:05,050 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:06:05,050 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:06:05,050 INFO:     No hyperparam tuning for this model
2022-12-31 13:06:05,050 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:06:05,050 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:06:05,051 INFO:     None feature selector for col prot
2022-12-31 13:06:05,051 INFO:     None feature selector for col prot
2022-12-31 13:06:05,051 INFO:     None feature selector for col prot
2022-12-31 13:06:05,052 INFO:     None feature selector for col chem
2022-12-31 13:06:05,052 INFO:     None feature selector for col chem
2022-12-31 13:06:05,052 INFO:     None feature selector for col chem
2022-12-31 13:06:05,052 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:06:05,052 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:06:05,054 INFO:     Number of params in model 223921
2022-12-31 13:06:05,057 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:06:05,057 INFO:   Starting stage: TRAINING
2022-12-31 13:06:05,102 INFO:     Val loss before train {'Reaction outcome loss': 1.0827839255332947, 'Total loss': 1.0827839255332947}
2022-12-31 13:06:05,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:05,102 INFO:     Epoch: 0
2022-12-31 13:06:06,755 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.739401912689209, 'Total loss': 0.739401912689209} | train loss {'Reaction outcome loss': 0.8120164188155292, 'Total loss': 0.8120164188155292}
2022-12-31 13:06:06,755 INFO:     Found new best model at epoch 0
2022-12-31 13:06:06,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:06,756 INFO:     Epoch: 1
2022-12-31 13:06:08,334 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5894352634747823, 'Total loss': 0.5894352634747823} | train loss {'Reaction outcome loss': 0.6027822250867412, 'Total loss': 0.6027822250867412}
2022-12-31 13:06:08,334 INFO:     Found new best model at epoch 1
2022-12-31 13:06:08,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:08,335 INFO:     Epoch: 2
2022-12-31 13:06:09,942 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6024401168028514, 'Total loss': 0.6024401168028514} | train loss {'Reaction outcome loss': 0.5156069644284944, 'Total loss': 0.5156069644284944}
2022-12-31 13:06:09,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:09,943 INFO:     Epoch: 3
2022-12-31 13:06:11,550 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.580349717537562, 'Total loss': 0.580349717537562} | train loss {'Reaction outcome loss': 0.48872091028377085, 'Total loss': 0.48872091028377085}
2022-12-31 13:06:11,550 INFO:     Found new best model at epoch 3
2022-12-31 13:06:11,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:11,551 INFO:     Epoch: 4
2022-12-31 13:06:13,141 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5903343637784322, 'Total loss': 0.5903343637784322} | train loss {'Reaction outcome loss': 0.47406599246454934, 'Total loss': 0.47406599246454934}
2022-12-31 13:06:13,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:13,141 INFO:     Epoch: 5
2022-12-31 13:06:14,755 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5628104050954182, 'Total loss': 0.5628104050954182} | train loss {'Reaction outcome loss': 0.46466834514136734, 'Total loss': 0.46466834514136734}
2022-12-31 13:06:14,755 INFO:     Found new best model at epoch 5
2022-12-31 13:06:14,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:14,756 INFO:     Epoch: 6
2022-12-31 13:06:16,348 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5649924258391062, 'Total loss': 0.5649924258391062} | train loss {'Reaction outcome loss': 0.45361751035182146, 'Total loss': 0.45361751035182146}
2022-12-31 13:06:16,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:16,348 INFO:     Epoch: 7
2022-12-31 13:06:17,943 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.545709753036499, 'Total loss': 0.545709753036499} | train loss {'Reaction outcome loss': 0.4514523674428028, 'Total loss': 0.4514523674428028}
2022-12-31 13:06:17,943 INFO:     Found new best model at epoch 7
2022-12-31 13:06:17,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:17,944 INFO:     Epoch: 8
2022-12-31 13:06:19,551 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5712141752243042, 'Total loss': 0.5712141752243042} | train loss {'Reaction outcome loss': 0.44074055976676246, 'Total loss': 0.44074055976676246}
2022-12-31 13:06:19,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:19,551 INFO:     Epoch: 9
2022-12-31 13:06:21,161 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5951371411482493, 'Total loss': 0.5951371411482493} | train loss {'Reaction outcome loss': 0.4339679387690377, 'Total loss': 0.4339679387690377}
2022-12-31 13:06:21,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:21,162 INFO:     Epoch: 10
2022-12-31 13:06:22,786 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5594888905684153, 'Total loss': 0.5594888905684153} | train loss {'Reaction outcome loss': 0.43100471218136976, 'Total loss': 0.43100471218136976}
2022-12-31 13:06:22,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:22,787 INFO:     Epoch: 11
2022-12-31 13:06:24,398 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5453945954640707, 'Total loss': 0.5453945954640707} | train loss {'Reaction outcome loss': 0.421526689381495, 'Total loss': 0.421526689381495}
2022-12-31 13:06:24,398 INFO:     Found new best model at epoch 11
2022-12-31 13:06:24,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:24,399 INFO:     Epoch: 12
2022-12-31 13:06:25,986 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5645654598871866, 'Total loss': 0.5645654598871866} | train loss {'Reaction outcome loss': 0.41527532954720686, 'Total loss': 0.41527532954720686}
2022-12-31 13:06:25,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:25,986 INFO:     Epoch: 13
2022-12-31 13:06:27,595 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5048790693283081, 'Total loss': 0.5048790693283081} | train loss {'Reaction outcome loss': 0.4133399339379185, 'Total loss': 0.4133399339379185}
2022-12-31 13:06:27,595 INFO:     Found new best model at epoch 13
2022-12-31 13:06:27,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:27,596 INFO:     Epoch: 14
2022-12-31 13:06:29,205 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5134715338548025, 'Total loss': 0.5134715338548025} | train loss {'Reaction outcome loss': 0.40175870066359093, 'Total loss': 0.40175870066359093}
2022-12-31 13:06:29,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:29,205 INFO:     Epoch: 15
2022-12-31 13:06:30,793 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5306394616762797, 'Total loss': 0.5306394616762797} | train loss {'Reaction outcome loss': 0.3987027601930347, 'Total loss': 0.3987027601930347}
2022-12-31 13:06:30,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:30,794 INFO:     Epoch: 16
2022-12-31 13:06:32,402 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.52968128323555, 'Total loss': 0.52968128323555} | train loss {'Reaction outcome loss': 0.39143519590262077, 'Total loss': 0.39143519590262077}
2022-12-31 13:06:32,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:32,403 INFO:     Epoch: 17
2022-12-31 13:06:34,039 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5532322297493617, 'Total loss': 0.5532322297493617} | train loss {'Reaction outcome loss': 0.3865260272456782, 'Total loss': 0.3865260272456782}
2022-12-31 13:06:34,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:34,040 INFO:     Epoch: 18
2022-12-31 13:06:35,637 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4934861640135447, 'Total loss': 0.4934861640135447} | train loss {'Reaction outcome loss': 0.38017212768105696, 'Total loss': 0.38017212768105696}
2022-12-31 13:06:35,638 INFO:     Found new best model at epoch 18
2022-12-31 13:06:35,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:35,639 INFO:     Epoch: 19
2022-12-31 13:06:37,246 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5216771721839905, 'Total loss': 0.5216771721839905} | train loss {'Reaction outcome loss': 0.38226691497503407, 'Total loss': 0.38226691497503407}
2022-12-31 13:06:37,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:37,246 INFO:     Epoch: 20
2022-12-31 13:06:38,857 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5326039989789327, 'Total loss': 0.5326039989789327} | train loss {'Reaction outcome loss': 0.37394704838303755, 'Total loss': 0.37394704838303755}
2022-12-31 13:06:38,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:38,857 INFO:     Epoch: 21
2022-12-31 13:06:40,474 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5495137294133504, 'Total loss': 0.5495137294133504} | train loss {'Reaction outcome loss': 0.36916689476827635, 'Total loss': 0.36916689476827635}
2022-12-31 13:06:40,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:40,475 INFO:     Epoch: 22
2022-12-31 13:06:42,085 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5164929687976837, 'Total loss': 0.5164929687976837} | train loss {'Reaction outcome loss': 0.3565481404780689, 'Total loss': 0.3565481404780689}
2022-12-31 13:06:42,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:42,085 INFO:     Epoch: 23
2022-12-31 13:06:43,673 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5385761976242065, 'Total loss': 0.5385761976242065} | train loss {'Reaction outcome loss': 0.3521829152031101, 'Total loss': 0.3521829152031101}
2022-12-31 13:06:43,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:43,673 INFO:     Epoch: 24
2022-12-31 13:06:45,286 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48867836197217307, 'Total loss': 0.48867836197217307} | train loss {'Reaction outcome loss': 0.35080112837744454, 'Total loss': 0.35080112837744454}
2022-12-31 13:06:45,286 INFO:     Found new best model at epoch 24
2022-12-31 13:06:45,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:45,287 INFO:     Epoch: 25
2022-12-31 13:06:46,898 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5063364128271739, 'Total loss': 0.5063364128271739} | train loss {'Reaction outcome loss': 0.3442746944127292, 'Total loss': 0.3442746944127292}
2022-12-31 13:06:46,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:46,899 INFO:     Epoch: 26
2022-12-31 13:06:48,504 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5205697993437449, 'Total loss': 0.5205697993437449} | train loss {'Reaction outcome loss': 0.3418170082634383, 'Total loss': 0.3418170082634383}
2022-12-31 13:06:48,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:48,505 INFO:     Epoch: 27
2022-12-31 13:06:49,644 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5336697379748027, 'Total loss': 0.5336697379748027} | train loss {'Reaction outcome loss': 0.3409732737626037, 'Total loss': 0.3409732737626037}
2022-12-31 13:06:49,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:49,645 INFO:     Epoch: 28
2022-12-31 13:06:50,725 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5320328841606776, 'Total loss': 0.5320328841606776} | train loss {'Reaction outcome loss': 0.33804087368023655, 'Total loss': 0.33804087368023655}
2022-12-31 13:06:50,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:50,725 INFO:     Epoch: 29
2022-12-31 13:06:51,810 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5192273885011673, 'Total loss': 0.5192273885011673} | train loss {'Reaction outcome loss': 0.3226618603497309, 'Total loss': 0.3226618603497309}
2022-12-31 13:06:51,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:51,811 INFO:     Epoch: 30
2022-12-31 13:06:52,892 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.492932524283727, 'Total loss': 0.492932524283727} | train loss {'Reaction outcome loss': 0.3284768949867818, 'Total loss': 0.3284768949867818}
2022-12-31 13:06:52,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:52,893 INFO:     Epoch: 31
2022-12-31 13:06:54,367 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5339048604170481, 'Total loss': 0.5339048604170481} | train loss {'Reaction outcome loss': 0.31804533498565646, 'Total loss': 0.31804533498565646}
2022-12-31 13:06:54,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:54,367 INFO:     Epoch: 32
2022-12-31 13:06:55,973 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5054795175790787, 'Total loss': 0.5054795175790787} | train loss {'Reaction outcome loss': 0.3191787781615327, 'Total loss': 0.3191787781615327}
2022-12-31 13:06:55,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:55,973 INFO:     Epoch: 33
2022-12-31 13:06:57,613 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5178160091241201, 'Total loss': 0.5178160091241201} | train loss {'Reaction outcome loss': 0.30909386192903904, 'Total loss': 0.30909386192903904}
2022-12-31 13:06:57,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:57,613 INFO:     Epoch: 34
2022-12-31 13:06:59,244 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49323335687319436, 'Total loss': 0.49323335687319436} | train loss {'Reaction outcome loss': 0.3014860388136258, 'Total loss': 0.3014860388136258}
2022-12-31 13:06:59,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:06:59,244 INFO:     Epoch: 35
2022-12-31 13:07:00,830 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.510226680835088, 'Total loss': 0.510226680835088} | train loss {'Reaction outcome loss': 0.3047443051706918, 'Total loss': 0.3047443051706918}
2022-12-31 13:07:00,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:00,831 INFO:     Epoch: 36
2022-12-31 13:07:02,416 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5235386113325755, 'Total loss': 0.5235386113325755} | train loss {'Reaction outcome loss': 0.2971273295064695, 'Total loss': 0.2971273295064695}
2022-12-31 13:07:02,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:02,416 INFO:     Epoch: 37
2022-12-31 13:07:04,055 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48785832325617473, 'Total loss': 0.48785832325617473} | train loss {'Reaction outcome loss': 0.30796953661870347, 'Total loss': 0.30796953661870347}
2022-12-31 13:07:04,055 INFO:     Found new best model at epoch 37
2022-12-31 13:07:04,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:04,056 INFO:     Epoch: 38
2022-12-31 13:07:05,700 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5052628735701243, 'Total loss': 0.5052628735701243} | train loss {'Reaction outcome loss': 0.2876063638577496, 'Total loss': 0.2876063638577496}
2022-12-31 13:07:05,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:05,701 INFO:     Epoch: 39
2022-12-31 13:07:07,278 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.501709657907486, 'Total loss': 0.501709657907486} | train loss {'Reaction outcome loss': 0.2946869890837774, 'Total loss': 0.2946869890837774}
2022-12-31 13:07:07,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:07,279 INFO:     Epoch: 40
2022-12-31 13:07:08,877 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5125345210234324, 'Total loss': 0.5125345210234324} | train loss {'Reaction outcome loss': 0.28338199870212233, 'Total loss': 0.28338199870212233}
2022-12-31 13:07:08,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:08,877 INFO:     Epoch: 41
2022-12-31 13:07:10,478 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5142073353131612, 'Total loss': 0.5142073353131612} | train loss {'Reaction outcome loss': 0.2825366839848078, 'Total loss': 0.2825366839848078}
2022-12-31 13:07:10,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:10,478 INFO:     Epoch: 42
2022-12-31 13:07:12,076 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4891008933385213, 'Total loss': 0.4891008933385213} | train loss {'Reaction outcome loss': 0.2758465120636851, 'Total loss': 0.2758465120636851}
2022-12-31 13:07:12,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:12,077 INFO:     Epoch: 43
2022-12-31 13:07:13,681 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.515332751472791, 'Total loss': 0.515332751472791} | train loss {'Reaction outcome loss': 0.2748085812522765, 'Total loss': 0.2748085812522765}
2022-12-31 13:07:13,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:13,681 INFO:     Epoch: 44
2022-12-31 13:07:15,319 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5006158530712128, 'Total loss': 0.5006158530712128} | train loss {'Reaction outcome loss': 0.2721320796676361, 'Total loss': 0.2721320796676361}
2022-12-31 13:07:15,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:15,319 INFO:     Epoch: 45
2022-12-31 13:07:16,929 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5432030101617177, 'Total loss': 0.5432030101617177} | train loss {'Reaction outcome loss': 0.2744439398040519, 'Total loss': 0.2744439398040519}
2022-12-31 13:07:16,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:16,929 INFO:     Epoch: 46
2022-12-31 13:07:18,510 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4675491323073705, 'Total loss': 0.4675491323073705} | train loss {'Reaction outcome loss': 0.26826019360799425, 'Total loss': 0.26826019360799425}
2022-12-31 13:07:18,510 INFO:     Found new best model at epoch 46
2022-12-31 13:07:18,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:18,511 INFO:     Epoch: 47
2022-12-31 13:07:20,107 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4960445801417033, 'Total loss': 0.4960445801417033} | train loss {'Reaction outcome loss': 0.2674073649801477, 'Total loss': 0.2674073649801477}
2022-12-31 13:07:20,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:20,107 INFO:     Epoch: 48
2022-12-31 13:07:21,692 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47375617623329164, 'Total loss': 0.47375617623329164} | train loss {'Reaction outcome loss': 0.268737612971968, 'Total loss': 0.268737612971968}
2022-12-31 13:07:21,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:21,693 INFO:     Epoch: 49
2022-12-31 13:07:23,288 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5303588271141052, 'Total loss': 0.5303588271141052} | train loss {'Reaction outcome loss': 0.2643774599516696, 'Total loss': 0.2643774599516696}
2022-12-31 13:07:23,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:23,289 INFO:     Epoch: 50
2022-12-31 13:07:24,883 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5325847913821539, 'Total loss': 0.5325847913821539} | train loss {'Reaction outcome loss': 0.26187608112329547, 'Total loss': 0.26187608112329547}
2022-12-31 13:07:24,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:24,884 INFO:     Epoch: 51
2022-12-31 13:07:26,478 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.552445853749911, 'Total loss': 0.552445853749911} | train loss {'Reaction outcome loss': 0.2521071042865515, 'Total loss': 0.2521071042865515}
2022-12-31 13:07:26,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:26,478 INFO:     Epoch: 52
2022-12-31 13:07:28,058 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.531362263361613, 'Total loss': 0.531362263361613} | train loss {'Reaction outcome loss': 0.26130140962990095, 'Total loss': 0.26130140962990095}
2022-12-31 13:07:28,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:28,058 INFO:     Epoch: 53
2022-12-31 13:07:29,638 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49671035408973696, 'Total loss': 0.49671035408973696} | train loss {'Reaction outcome loss': 0.25880653706182094, 'Total loss': 0.25880653706182094}
2022-12-31 13:07:29,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:29,638 INFO:     Epoch: 54
2022-12-31 13:07:31,268 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5286934971809387, 'Total loss': 0.5286934971809387} | train loss {'Reaction outcome loss': 0.248806305188876, 'Total loss': 0.248806305188876}
2022-12-31 13:07:31,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:31,268 INFO:     Epoch: 55
2022-12-31 13:07:32,900 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5334240953127544, 'Total loss': 0.5334240953127544} | train loss {'Reaction outcome loss': 0.2455191463911838, 'Total loss': 0.2455191463911838}
2022-12-31 13:07:32,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:32,901 INFO:     Epoch: 56
2022-12-31 13:07:34,539 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5171473294496536, 'Total loss': 0.5171473294496536} | train loss {'Reaction outcome loss': 0.25002764443438635, 'Total loss': 0.25002764443438635}
2022-12-31 13:07:34,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:34,539 INFO:     Epoch: 57
2022-12-31 13:07:36,150 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5165210932493209, 'Total loss': 0.5165210932493209} | train loss {'Reaction outcome loss': 0.25247636275624274, 'Total loss': 0.25247636275624274}
2022-12-31 13:07:36,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:36,150 INFO:     Epoch: 58
2022-12-31 13:07:37,748 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5057038585344951, 'Total loss': 0.5057038585344951} | train loss {'Reaction outcome loss': 0.25055566186724354, 'Total loss': 0.25055566186724354}
2022-12-31 13:07:37,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:37,748 INFO:     Epoch: 59
2022-12-31 13:07:39,326 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49014613727728523, 'Total loss': 0.49014613727728523} | train loss {'Reaction outcome loss': 0.24166520467422303, 'Total loss': 0.24166520467422303}
2022-12-31 13:07:39,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:39,327 INFO:     Epoch: 60
2022-12-31 13:07:40,933 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5014528830846151, 'Total loss': 0.5014528830846151} | train loss {'Reaction outcome loss': 0.24197733199672541, 'Total loss': 0.24197733199672541}
2022-12-31 13:07:40,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:40,935 INFO:     Epoch: 61
2022-12-31 13:07:42,530 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5563877344131469, 'Total loss': 0.5563877344131469} | train loss {'Reaction outcome loss': 0.2477726972845458, 'Total loss': 0.2477726972845458}
2022-12-31 13:07:42,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:42,530 INFO:     Epoch: 62
2022-12-31 13:07:44,127 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.50511514544487, 'Total loss': 0.50511514544487} | train loss {'Reaction outcome loss': 0.24494168094366137, 'Total loss': 0.24494168094366137}
2022-12-31 13:07:44,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:44,127 INFO:     Epoch: 63
2022-12-31 13:07:45,715 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5388892928759257, 'Total loss': 0.5388892928759257} | train loss {'Reaction outcome loss': 0.23221111073274248, 'Total loss': 0.23221111073274248}
2022-12-31 13:07:45,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:45,715 INFO:     Epoch: 64
2022-12-31 13:07:47,306 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.532644717892011, 'Total loss': 0.532644717892011} | train loss {'Reaction outcome loss': 0.23870542711394765, 'Total loss': 0.23870542711394765}
2022-12-31 13:07:47,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:47,307 INFO:     Epoch: 65
2022-12-31 13:07:48,921 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5063668747742971, 'Total loss': 0.5063668747742971} | train loss {'Reaction outcome loss': 0.23660782345291906, 'Total loss': 0.23660782345291906}
2022-12-31 13:07:48,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:48,921 INFO:     Epoch: 66
2022-12-31 13:07:50,528 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46727204620838164, 'Total loss': 0.46727204620838164} | train loss {'Reaction outcome loss': 0.2368948882459289, 'Total loss': 0.2368948882459289}
2022-12-31 13:07:50,528 INFO:     Found new best model at epoch 66
2022-12-31 13:07:50,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:50,529 INFO:     Epoch: 67
2022-12-31 13:07:52,112 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5121567224462827, 'Total loss': 0.5121567224462827} | train loss {'Reaction outcome loss': 0.23444142236109197, 'Total loss': 0.23444142236109197}
2022-12-31 13:07:52,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:52,112 INFO:     Epoch: 68
2022-12-31 13:07:53,704 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48830618560314176, 'Total loss': 0.48830618560314176} | train loss {'Reaction outcome loss': 0.2244630936995475, 'Total loss': 0.2244630936995475}
2022-12-31 13:07:53,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:53,704 INFO:     Epoch: 69
2022-12-31 13:07:55,297 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5000430524349213, 'Total loss': 0.5000430524349213} | train loss {'Reaction outcome loss': 0.2306010289335229, 'Total loss': 0.2306010289335229}
2022-12-31 13:07:55,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:55,297 INFO:     Epoch: 70
2022-12-31 13:07:56,876 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5037092318137487, 'Total loss': 0.5037092318137487} | train loss {'Reaction outcome loss': 0.22899039089679718, 'Total loss': 0.22899039089679718}
2022-12-31 13:07:56,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:56,876 INFO:     Epoch: 71
2022-12-31 13:07:58,473 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.519451554119587, 'Total loss': 0.519451554119587} | train loss {'Reaction outcome loss': 0.22208019555376393, 'Total loss': 0.22208019555376393}
2022-12-31 13:07:58,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:07:58,474 INFO:     Epoch: 72
2022-12-31 13:08:00,070 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5206892430782318, 'Total loss': 0.5206892430782318} | train loss {'Reaction outcome loss': 0.23065192146689026, 'Total loss': 0.23065192146689026}
2022-12-31 13:08:00,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:00,071 INFO:     Epoch: 73
2022-12-31 13:08:01,668 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48086326917012534, 'Total loss': 0.48086326917012534} | train loss {'Reaction outcome loss': 0.22850706835148216, 'Total loss': 0.22850706835148216}
2022-12-31 13:08:01,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:01,668 INFO:     Epoch: 74
2022-12-31 13:08:03,258 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48312072157859803, 'Total loss': 0.48312072157859803} | train loss {'Reaction outcome loss': 0.2170741117668141, 'Total loss': 0.2170741117668141}
2022-12-31 13:08:03,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:03,258 INFO:     Epoch: 75
2022-12-31 13:08:04,853 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5023361692825953, 'Total loss': 0.5023361692825953} | train loss {'Reaction outcome loss': 0.2264352421663756, 'Total loss': 0.2264352421663756}
2022-12-31 13:08:04,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:04,854 INFO:     Epoch: 76
2022-12-31 13:08:06,456 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46768421729405724, 'Total loss': 0.46768421729405724} | train loss {'Reaction outcome loss': 0.22438283713303342, 'Total loss': 0.22438283713303342}
2022-12-31 13:08:06,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:06,457 INFO:     Epoch: 77
2022-12-31 13:08:08,093 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5482084274291992, 'Total loss': 0.5482084274291992} | train loss {'Reaction outcome loss': 0.21748188225022197, 'Total loss': 0.21748188225022197}
2022-12-31 13:08:08,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:08,093 INFO:     Epoch: 78
2022-12-31 13:08:09,710 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5431824187437694, 'Total loss': 0.5431824187437694} | train loss {'Reaction outcome loss': 0.21638666724881334, 'Total loss': 0.21638666724881334}
2022-12-31 13:08:09,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:09,710 INFO:     Epoch: 79
2022-12-31 13:08:11,306 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5370822896560034, 'Total loss': 0.5370822896560034} | train loss {'Reaction outcome loss': 0.2255153392924227, 'Total loss': 0.2255153392924227}
2022-12-31 13:08:11,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:11,308 INFO:     Epoch: 80
2022-12-31 13:08:12,891 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47996563613414767, 'Total loss': 0.47996563613414767} | train loss {'Reaction outcome loss': 0.22063907173319455, 'Total loss': 0.22063907173319455}
2022-12-31 13:08:12,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:12,892 INFO:     Epoch: 81
2022-12-31 13:08:14,488 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48647477229436237, 'Total loss': 0.48647477229436237} | train loss {'Reaction outcome loss': 0.20948096822920073, 'Total loss': 0.20948096822920073}
2022-12-31 13:08:14,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:14,488 INFO:     Epoch: 82
2022-12-31 13:08:16,104 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5016849438349406, 'Total loss': 0.5016849438349406} | train loss {'Reaction outcome loss': 0.21103302511746866, 'Total loss': 0.21103302511746866}
2022-12-31 13:08:16,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:16,104 INFO:     Epoch: 83
2022-12-31 13:08:17,739 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5067756791909536, 'Total loss': 0.5067756791909536} | train loss {'Reaction outcome loss': 0.21727695915657674, 'Total loss': 0.21727695915657674}
2022-12-31 13:08:17,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:17,740 INFO:     Epoch: 84
2022-12-31 13:08:19,377 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5180724422136943, 'Total loss': 0.5180724422136943} | train loss {'Reaction outcome loss': 0.21008070696308448, 'Total loss': 0.21008070696308448}
2022-12-31 13:08:19,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:19,377 INFO:     Epoch: 85
2022-12-31 13:08:20,966 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5255700399478277, 'Total loss': 0.5255700399478277} | train loss {'Reaction outcome loss': 0.22001387674470235, 'Total loss': 0.22001387674470235}
2022-12-31 13:08:20,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:20,966 INFO:     Epoch: 86
2022-12-31 13:08:22,558 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49606449405352276, 'Total loss': 0.49606449405352276} | train loss {'Reaction outcome loss': 0.20709270873807206, 'Total loss': 0.20709270873807206}
2022-12-31 13:08:22,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:22,559 INFO:     Epoch: 87
2022-12-31 13:08:24,166 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5212091922760009, 'Total loss': 0.5212091922760009} | train loss {'Reaction outcome loss': 0.21518309303919655, 'Total loss': 0.21518309303919655}
2022-12-31 13:08:24,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:24,166 INFO:     Epoch: 88
2022-12-31 13:08:25,762 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5416177769502004, 'Total loss': 0.5416177769502004} | train loss {'Reaction outcome loss': 0.21292680551563084, 'Total loss': 0.21292680551563084}
2022-12-31 13:08:25,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:25,762 INFO:     Epoch: 89
2022-12-31 13:08:27,358 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5461039423942566, 'Total loss': 0.5461039423942566} | train loss {'Reaction outcome loss': 0.20519985519621495, 'Total loss': 0.20519985519621495}
2022-12-31 13:08:27,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:27,358 INFO:     Epoch: 90
2022-12-31 13:08:28,954 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5344979445139567, 'Total loss': 0.5344979445139567} | train loss {'Reaction outcome loss': 0.20761182701663813, 'Total loss': 0.20761182701663813}
2022-12-31 13:08:28,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:28,954 INFO:     Epoch: 91
2022-12-31 13:08:30,542 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49690671463807423, 'Total loss': 0.49690671463807423} | train loss {'Reaction outcome loss': 0.2155562063651907, 'Total loss': 0.2155562063651907}
2022-12-31 13:08:30,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:30,543 INFO:     Epoch: 92
2022-12-31 13:08:32,137 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4895624965429306, 'Total loss': 0.4895624965429306} | train loss {'Reaction outcome loss': 0.20398430924617897, 'Total loss': 0.20398430924617897}
2022-12-31 13:08:32,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:32,137 INFO:     Epoch: 93
2022-12-31 13:08:33,753 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.503703581293424, 'Total loss': 0.503703581293424} | train loss {'Reaction outcome loss': 0.2054944428866797, 'Total loss': 0.2054944428866797}
2022-12-31 13:08:33,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:33,753 INFO:     Epoch: 94
2022-12-31 13:08:35,365 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.525008867184321, 'Total loss': 0.525008867184321} | train loss {'Reaction outcome loss': 0.20573221119868496, 'Total loss': 0.20573221119868496}
2022-12-31 13:08:35,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:35,366 INFO:     Epoch: 95
2022-12-31 13:08:36,960 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5502363373835881, 'Total loss': 0.5502363373835881} | train loss {'Reaction outcome loss': 0.2095400146106734, 'Total loss': 0.2095400146106734}
2022-12-31 13:08:36,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:36,961 INFO:     Epoch: 96
2022-12-31 13:08:38,557 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5032661606868108, 'Total loss': 0.5032661606868108} | train loss {'Reaction outcome loss': 0.2004409295024119, 'Total loss': 0.2004409295024119}
2022-12-31 13:08:38,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:38,557 INFO:     Epoch: 97
2022-12-31 13:08:40,151 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5630989849567414, 'Total loss': 0.5630989849567414} | train loss {'Reaction outcome loss': 0.20428064532822718, 'Total loss': 0.20428064532822718}
2022-12-31 13:08:40,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:40,152 INFO:     Epoch: 98
2022-12-31 13:08:41,776 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4955658234655857, 'Total loss': 0.4955658234655857} | train loss {'Reaction outcome loss': 0.20142256287708335, 'Total loss': 0.20142256287708335}
2022-12-31 13:08:41,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:41,778 INFO:     Epoch: 99
2022-12-31 13:08:43,375 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.524700590968132, 'Total loss': 0.524700590968132} | train loss {'Reaction outcome loss': 0.19313378277894136, 'Total loss': 0.19313378277894136}
2022-12-31 13:08:43,375 INFO:     Best model found after epoch 67 of 100.
2022-12-31 13:08:43,375 INFO:   Done with stage: TRAINING
2022-12-31 13:08:43,375 INFO:   Starting stage: EVALUATION
2022-12-31 13:08:43,509 INFO:   Done with stage: EVALUATION
2022-12-31 13:08:43,509 INFO:   Leaving out SEQ value Fold_1
2022-12-31 13:08:43,522 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:08:43,522 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:08:44,175 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:08:44,175 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:08:44,244 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:08:44,244 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:08:44,244 INFO:     No hyperparam tuning for this model
2022-12-31 13:08:44,244 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:08:44,244 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:08:44,245 INFO:     None feature selector for col prot
2022-12-31 13:08:44,245 INFO:     None feature selector for col prot
2022-12-31 13:08:44,245 INFO:     None feature selector for col prot
2022-12-31 13:08:44,246 INFO:     None feature selector for col chem
2022-12-31 13:08:44,246 INFO:     None feature selector for col chem
2022-12-31 13:08:44,246 INFO:     None feature selector for col chem
2022-12-31 13:08:44,246 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:08:44,246 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:08:44,248 INFO:     Number of params in model 223921
2022-12-31 13:08:44,251 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:08:44,251 INFO:   Starting stage: TRAINING
2022-12-31 13:08:44,297 INFO:     Val loss before train {'Reaction outcome loss': 1.0241952617963155, 'Total loss': 1.0241952617963155}
2022-12-31 13:08:44,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:44,297 INFO:     Epoch: 0
2022-12-31 13:08:45,906 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6537556986014048, 'Total loss': 0.6537556986014048} | train loss {'Reaction outcome loss': 0.8143063034774547, 'Total loss': 0.8143063034774547}
2022-12-31 13:08:45,907 INFO:     Found new best model at epoch 0
2022-12-31 13:08:45,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:45,908 INFO:     Epoch: 1
2022-12-31 13:08:47,532 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.524720964829127, 'Total loss': 0.524720964829127} | train loss {'Reaction outcome loss': 0.5860135017631009, 'Total loss': 0.5860135017631009}
2022-12-31 13:08:47,532 INFO:     Found new best model at epoch 1
2022-12-31 13:08:47,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:47,533 INFO:     Epoch: 2
2022-12-31 13:08:49,126 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4820896844069163, 'Total loss': 0.4820896844069163} | train loss {'Reaction outcome loss': 0.5318882738550504, 'Total loss': 0.5318882738550504}
2022-12-31 13:08:49,127 INFO:     Found new best model at epoch 2
2022-12-31 13:08:49,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:49,128 INFO:     Epoch: 3
2022-12-31 13:08:50,735 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4579523801803589, 'Total loss': 0.4579523801803589} | train loss {'Reaction outcome loss': 0.515095370106291, 'Total loss': 0.515095370106291}
2022-12-31 13:08:50,735 INFO:     Found new best model at epoch 3
2022-12-31 13:08:50,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:50,736 INFO:     Epoch: 4
2022-12-31 13:08:52,351 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4542591631412506, 'Total loss': 0.4542591631412506} | train loss {'Reaction outcome loss': 0.4903771448475511, 'Total loss': 0.4903771448475511}
2022-12-31 13:08:52,351 INFO:     Found new best model at epoch 4
2022-12-31 13:08:52,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:52,352 INFO:     Epoch: 5
2022-12-31 13:08:53,964 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4563790182272593, 'Total loss': 0.4563790182272593} | train loss {'Reaction outcome loss': 0.4761743513842795, 'Total loss': 0.4761743513842795}
2022-12-31 13:08:53,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:53,964 INFO:     Epoch: 6
2022-12-31 13:08:55,562 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45436783830324806, 'Total loss': 0.45436783830324806} | train loss {'Reaction outcome loss': 0.46908812466384575, 'Total loss': 0.46908812466384575}
2022-12-31 13:08:55,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:55,562 INFO:     Epoch: 7
2022-12-31 13:08:57,162 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45702550411224363, 'Total loss': 0.45702550411224363} | train loss {'Reaction outcome loss': 0.46809613963832025, 'Total loss': 0.46809613963832025}
2022-12-31 13:08:57,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:57,163 INFO:     Epoch: 8
2022-12-31 13:08:58,772 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4345180590947469, 'Total loss': 0.4345180590947469} | train loss {'Reaction outcome loss': 0.4657243819016477, 'Total loss': 0.4657243819016477}
2022-12-31 13:08:58,773 INFO:     Found new best model at epoch 8
2022-12-31 13:08:58,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:08:58,774 INFO:     Epoch: 9
2022-12-31 13:09:00,378 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4831396877765656, 'Total loss': 0.4831396877765656} | train loss {'Reaction outcome loss': 0.457173387966274, 'Total loss': 0.457173387966274}
2022-12-31 13:09:00,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:00,378 INFO:     Epoch: 10
2022-12-31 13:09:01,990 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4522410968939463, 'Total loss': 0.4522410968939463} | train loss {'Reaction outcome loss': 0.44330796340237494, 'Total loss': 0.44330796340237494}
2022-12-31 13:09:01,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:01,991 INFO:     Epoch: 11
2022-12-31 13:09:03,588 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4705066700776418, 'Total loss': 0.4705066700776418} | train loss {'Reaction outcome loss': 0.4747485300337059, 'Total loss': 0.4747485300337059}
2022-12-31 13:09:03,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:03,588 INFO:     Epoch: 12
2022-12-31 13:09:05,207 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4304057369629542, 'Total loss': 0.4304057369629542} | train loss {'Reaction outcome loss': 0.46501126691051153, 'Total loss': 0.46501126691051153}
2022-12-31 13:09:05,207 INFO:     Found new best model at epoch 12
2022-12-31 13:09:05,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:05,208 INFO:     Epoch: 13
2022-12-31 13:09:06,822 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41984194815158843, 'Total loss': 0.41984194815158843} | train loss {'Reaction outcome loss': 0.4611810162541983, 'Total loss': 0.4611810162541983}
2022-12-31 13:09:06,822 INFO:     Found new best model at epoch 13
2022-12-31 13:09:06,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:06,823 INFO:     Epoch: 14
2022-12-31 13:09:08,448 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4098021939396858, 'Total loss': 0.4098021939396858} | train loss {'Reaction outcome loss': 0.42816953563495824, 'Total loss': 0.42816953563495824}
2022-12-31 13:09:08,448 INFO:     Found new best model at epoch 14
2022-12-31 13:09:08,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:08,449 INFO:     Epoch: 15
2022-12-31 13:09:10,041 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41475261052449547, 'Total loss': 0.41475261052449547} | train loss {'Reaction outcome loss': 0.431038578108385, 'Total loss': 0.431038578108385}
2022-12-31 13:09:10,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:10,041 INFO:     Epoch: 16
2022-12-31 13:09:11,633 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.412251153588295, 'Total loss': 0.412251153588295} | train loss {'Reaction outcome loss': 0.4154863560275323, 'Total loss': 0.4154863560275323}
2022-12-31 13:09:11,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:11,633 INFO:     Epoch: 17
2022-12-31 13:09:13,245 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4226306825876236, 'Total loss': 0.4226306825876236} | train loss {'Reaction outcome loss': 0.4094166541877, 'Total loss': 0.4094166541877}
2022-12-31 13:09:13,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:13,245 INFO:     Epoch: 18
2022-12-31 13:09:14,843 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4176678250233332, 'Total loss': 0.4176678250233332} | train loss {'Reaction outcome loss': 0.4212954056531906, 'Total loss': 0.4212954056531906}
2022-12-31 13:09:14,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:14,843 INFO:     Epoch: 19
2022-12-31 13:09:16,435 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44234599073727926, 'Total loss': 0.44234599073727926} | train loss {'Reaction outcome loss': 0.4034118837528471, 'Total loss': 0.4034118837528471}
2022-12-31 13:09:16,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:16,435 INFO:     Epoch: 20
2022-12-31 13:09:18,044 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4183749208847682, 'Total loss': 0.4183749208847682} | train loss {'Reaction outcome loss': 0.40937802756704605, 'Total loss': 0.40937802756704605}
2022-12-31 13:09:18,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:18,045 INFO:     Epoch: 21
2022-12-31 13:09:19,677 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3938560873270035, 'Total loss': 0.3938560873270035} | train loss {'Reaction outcome loss': 0.40587644233111886, 'Total loss': 0.40587644233111886}
2022-12-31 13:09:19,677 INFO:     Found new best model at epoch 21
2022-12-31 13:09:19,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:19,678 INFO:     Epoch: 22
2022-12-31 13:09:21,301 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41616263588269553, 'Total loss': 0.41616263588269553} | train loss {'Reaction outcome loss': 0.4130911451049041, 'Total loss': 0.4130911451049041}
2022-12-31 13:09:21,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:21,301 INFO:     Epoch: 23
2022-12-31 13:09:22,909 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38855064709981285, 'Total loss': 0.38855064709981285} | train loss {'Reaction outcome loss': 0.38857297090462584, 'Total loss': 0.38857297090462584}
2022-12-31 13:09:22,909 INFO:     Found new best model at epoch 23
2022-12-31 13:09:22,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:22,910 INFO:     Epoch: 24
2022-12-31 13:09:24,505 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4096766660610835, 'Total loss': 0.4096766660610835} | train loss {'Reaction outcome loss': 0.3833397192799527, 'Total loss': 0.3833397192799527}
2022-12-31 13:09:24,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:24,505 INFO:     Epoch: 25
2022-12-31 13:09:26,117 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41411333680152895, 'Total loss': 0.41411333680152895} | train loss {'Reaction outcome loss': 0.40763399498942104, 'Total loss': 0.40763399498942104}
2022-12-31 13:09:26,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:26,118 INFO:     Epoch: 26
2022-12-31 13:09:27,699 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41798268059889476, 'Total loss': 0.41798268059889476} | train loss {'Reaction outcome loss': 0.3904799758794083, 'Total loss': 0.3904799758794083}
2022-12-31 13:09:27,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:27,699 INFO:     Epoch: 27
2022-12-31 13:09:29,307 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3918924095729987, 'Total loss': 0.3918924095729987} | train loss {'Reaction outcome loss': 0.3943714383195333, 'Total loss': 0.3943714383195333}
2022-12-31 13:09:29,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:29,307 INFO:     Epoch: 28
2022-12-31 13:09:30,915 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41716649134953815, 'Total loss': 0.41716649134953815} | train loss {'Reaction outcome loss': 0.37019514625865046, 'Total loss': 0.37019514625865046}
2022-12-31 13:09:30,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:30,915 INFO:     Epoch: 29
2022-12-31 13:09:32,523 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3859658012787501, 'Total loss': 0.3859658012787501} | train loss {'Reaction outcome loss': 0.36972254521442927, 'Total loss': 0.36972254521442927}
2022-12-31 13:09:32,523 INFO:     Found new best model at epoch 29
2022-12-31 13:09:32,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:32,524 INFO:     Epoch: 30
2022-12-31 13:09:34,118 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41233897805213926, 'Total loss': 0.41233897805213926} | train loss {'Reaction outcome loss': 0.3655701010325372, 'Total loss': 0.3655701010325372}
2022-12-31 13:09:34,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:34,118 INFO:     Epoch: 31
2022-12-31 13:09:35,722 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3846464107433955, 'Total loss': 0.3846464107433955} | train loss {'Reaction outcome loss': 0.35339305074750516, 'Total loss': 0.35339305074750516}
2022-12-31 13:09:35,722 INFO:     Found new best model at epoch 31
2022-12-31 13:09:35,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:35,723 INFO:     Epoch: 32
2022-12-31 13:09:37,325 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37427606085936227, 'Total loss': 0.37427606085936227} | train loss {'Reaction outcome loss': 0.3486289607556672, 'Total loss': 0.3486289607556672}
2022-12-31 13:09:37,326 INFO:     Found new best model at epoch 32
2022-12-31 13:09:37,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:37,327 INFO:     Epoch: 33
2022-12-31 13:09:38,936 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3962318112452825, 'Total loss': 0.3962318112452825} | train loss {'Reaction outcome loss': 0.33633542656088655, 'Total loss': 0.33633542656088655}
2022-12-31 13:09:38,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:38,937 INFO:     Epoch: 34
2022-12-31 13:09:40,563 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43480433970689775, 'Total loss': 0.43480433970689775} | train loss {'Reaction outcome loss': 0.33961598268048704, 'Total loss': 0.33961598268048704}
2022-12-31 13:09:40,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:40,563 INFO:     Epoch: 35
2022-12-31 13:09:42,164 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3712127983570099, 'Total loss': 0.3712127983570099} | train loss {'Reaction outcome loss': 0.33703117577386077, 'Total loss': 0.33703117577386077}
2022-12-31 13:09:42,164 INFO:     Found new best model at epoch 35
2022-12-31 13:09:42,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:42,165 INFO:     Epoch: 36
2022-12-31 13:09:43,785 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3999089499314626, 'Total loss': 0.3999089499314626} | train loss {'Reaction outcome loss': 0.3477198588695593, 'Total loss': 0.3477198588695593}
2022-12-31 13:09:43,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:43,786 INFO:     Epoch: 37
2022-12-31 13:09:45,379 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36726283679405847, 'Total loss': 0.36726283679405847} | train loss {'Reaction outcome loss': 0.33411017523410363, 'Total loss': 0.33411017523410363}
2022-12-31 13:09:45,379 INFO:     Found new best model at epoch 37
2022-12-31 13:09:45,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:45,380 INFO:     Epoch: 38
2022-12-31 13:09:46,979 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3751997788747152, 'Total loss': 0.3751997788747152} | train loss {'Reaction outcome loss': 0.32774143579307996, 'Total loss': 0.32774143579307996}
2022-12-31 13:09:46,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:46,979 INFO:     Epoch: 39
2022-12-31 13:09:48,604 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4150116761525472, 'Total loss': 0.4150116761525472} | train loss {'Reaction outcome loss': 0.3238056489980132, 'Total loss': 0.3238056489980132}
2022-12-31 13:09:48,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:48,605 INFO:     Epoch: 40
2022-12-31 13:09:50,215 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39476437866687775, 'Total loss': 0.39476437866687775} | train loss {'Reaction outcome loss': 0.3152046848950651, 'Total loss': 0.3152046848950651}
2022-12-31 13:09:50,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:50,215 INFO:     Epoch: 41
2022-12-31 13:09:51,813 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37644974191983543, 'Total loss': 0.37644974191983543} | train loss {'Reaction outcome loss': 0.3060593095918496, 'Total loss': 0.3060593095918496}
2022-12-31 13:09:51,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:51,813 INFO:     Epoch: 42
2022-12-31 13:09:53,423 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3672946294148763, 'Total loss': 0.3672946294148763} | train loss {'Reaction outcome loss': 0.30967104827742215, 'Total loss': 0.30967104827742215}
2022-12-31 13:09:53,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:53,424 INFO:     Epoch: 43
2022-12-31 13:09:55,035 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3867781793077787, 'Total loss': 0.3867781793077787} | train loss {'Reaction outcome loss': 0.3111441879620965, 'Total loss': 0.3111441879620965}
2022-12-31 13:09:55,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:55,036 INFO:     Epoch: 44
2022-12-31 13:09:56,650 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39746018052101134, 'Total loss': 0.39746018052101134} | train loss {'Reaction outcome loss': 0.2944559011662352, 'Total loss': 0.2944559011662352}
2022-12-31 13:09:56,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:56,651 INFO:     Epoch: 45
2022-12-31 13:09:58,281 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36778999169667564, 'Total loss': 0.36778999169667564} | train loss {'Reaction outcome loss': 0.2947609966999996, 'Total loss': 0.2947609966999996}
2022-12-31 13:09:58,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:58,281 INFO:     Epoch: 46
2022-12-31 13:09:59,903 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37095992267131805, 'Total loss': 0.37095992267131805} | train loss {'Reaction outcome loss': 0.29832644307095074, 'Total loss': 0.29832644307095074}
2022-12-31 13:09:59,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:09:59,903 INFO:     Epoch: 47
2022-12-31 13:10:01,505 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3605276743570964, 'Total loss': 0.3605276743570964} | train loss {'Reaction outcome loss': 0.3459973659744297, 'Total loss': 0.3459973659744297}
2022-12-31 13:10:01,505 INFO:     Found new best model at epoch 47
2022-12-31 13:10:01,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:01,506 INFO:     Epoch: 48
2022-12-31 13:10:03,093 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3670871784289678, 'Total loss': 0.3670871784289678} | train loss {'Reaction outcome loss': 0.2964425658456225, 'Total loss': 0.2964425658456225}
2022-12-31 13:10:03,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:03,093 INFO:     Epoch: 49
2022-12-31 13:10:04,706 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37403701146443685, 'Total loss': 0.37403701146443685} | train loss {'Reaction outcome loss': 0.2867887983506923, 'Total loss': 0.2867887983506923}
2022-12-31 13:10:04,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:04,706 INFO:     Epoch: 50
2022-12-31 13:10:06,322 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34879939556121825, 'Total loss': 0.34879939556121825} | train loss {'Reaction outcome loss': 0.2819415652547437, 'Total loss': 0.2819415652547437}
2022-12-31 13:10:06,323 INFO:     Found new best model at epoch 50
2022-12-31 13:10:06,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:06,323 INFO:     Epoch: 51
2022-12-31 13:10:07,933 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3639705250660578, 'Total loss': 0.3639705250660578} | train loss {'Reaction outcome loss': 0.27468615337747376, 'Total loss': 0.27468615337747376}
2022-12-31 13:10:07,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:07,934 INFO:     Epoch: 52
2022-12-31 13:10:09,533 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3861491580804189, 'Total loss': 0.3861491580804189} | train loss {'Reaction outcome loss': 0.2763542983397517, 'Total loss': 0.2763542983397517}
2022-12-31 13:10:09,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:09,533 INFO:     Epoch: 53
2022-12-31 13:10:11,145 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3559239367643992, 'Total loss': 0.3559239367643992} | train loss {'Reaction outcome loss': 0.274175825959031, 'Total loss': 0.274175825959031}
2022-12-31 13:10:11,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:11,145 INFO:     Epoch: 54
2022-12-31 13:10:12,749 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41006367007891337, 'Total loss': 0.41006367007891337} | train loss {'Reaction outcome loss': 0.26988966102320433, 'Total loss': 0.26988966102320433}
2022-12-31 13:10:12,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:12,749 INFO:     Epoch: 55
2022-12-31 13:10:14,369 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37110617756843567, 'Total loss': 0.37110617756843567} | train loss {'Reaction outcome loss': 0.2705406077208033, 'Total loss': 0.2705406077208033}
2022-12-31 13:10:14,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:14,369 INFO:     Epoch: 56
2022-12-31 13:10:15,994 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3610584835211436, 'Total loss': 0.3610584835211436} | train loss {'Reaction outcome loss': 0.26849983444950287, 'Total loss': 0.26849983444950287}
2022-12-31 13:10:15,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:15,995 INFO:     Epoch: 57
2022-12-31 13:10:17,644 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36553764045238496, 'Total loss': 0.36553764045238496} | train loss {'Reaction outcome loss': 0.27090516011568083, 'Total loss': 0.27090516011568083}
2022-12-31 13:10:17,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:17,644 INFO:     Epoch: 58
2022-12-31 13:10:19,233 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3605635424455007, 'Total loss': 0.3605635424455007} | train loss {'Reaction outcome loss': 0.2594531201644401, 'Total loss': 0.2594531201644401}
2022-12-31 13:10:19,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:19,234 INFO:     Epoch: 59
2022-12-31 13:10:20,862 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40163230200608574, 'Total loss': 0.40163230200608574} | train loss {'Reaction outcome loss': 0.26446338151910587, 'Total loss': 0.26446338151910587}
2022-12-31 13:10:20,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:20,862 INFO:     Epoch: 60
2022-12-31 13:10:22,466 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37354589899381, 'Total loss': 0.37354589899381} | train loss {'Reaction outcome loss': 0.2564660079455728, 'Total loss': 0.2564660079455728}
2022-12-31 13:10:22,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:22,466 INFO:     Epoch: 61
2022-12-31 13:10:24,088 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3560959736506144, 'Total loss': 0.3560959736506144} | train loss {'Reaction outcome loss': 0.25464165729025134, 'Total loss': 0.25464165729025134}
2022-12-31 13:10:24,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:24,088 INFO:     Epoch: 62
2022-12-31 13:10:25,711 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39214714070161183, 'Total loss': 0.39214714070161183} | train loss {'Reaction outcome loss': 0.26256591075207986, 'Total loss': 0.26256591075207986}
2022-12-31 13:10:25,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:25,712 INFO:     Epoch: 63
2022-12-31 13:10:27,310 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36422227223714193, 'Total loss': 0.36422227223714193} | train loss {'Reaction outcome loss': 0.2908056244734484, 'Total loss': 0.2908056244734484}
2022-12-31 13:10:27,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:27,310 INFO:     Epoch: 64
2022-12-31 13:10:28,932 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3591877986987432, 'Total loss': 0.3591877986987432} | train loss {'Reaction outcome loss': 0.2555703671717218, 'Total loss': 0.2555703671717218}
2022-12-31 13:10:28,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:28,932 INFO:     Epoch: 65
2022-12-31 13:10:30,542 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3614708214998245, 'Total loss': 0.3614708214998245} | train loss {'Reaction outcome loss': 0.2419918888734147, 'Total loss': 0.2419918888734147}
2022-12-31 13:10:30,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:30,543 INFO:     Epoch: 66
2022-12-31 13:10:32,187 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.34877409363786377, 'Total loss': 0.34877409363786377} | train loss {'Reaction outcome loss': 0.24180861759098832, 'Total loss': 0.24180861759098832}
2022-12-31 13:10:32,187 INFO:     Found new best model at epoch 66
2022-12-31 13:10:32,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:32,188 INFO:     Epoch: 67
2022-12-31 13:10:33,834 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34441499759753547, 'Total loss': 0.34441499759753547} | train loss {'Reaction outcome loss': 0.25291791924046003, 'Total loss': 0.25291791924046003}
2022-12-31 13:10:33,834 INFO:     Found new best model at epoch 67
2022-12-31 13:10:33,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:33,835 INFO:     Epoch: 68
2022-12-31 13:10:35,472 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3440335303544998, 'Total loss': 0.3440335303544998} | train loss {'Reaction outcome loss': 0.241290283222372, 'Total loss': 0.241290283222372}
2022-12-31 13:10:35,472 INFO:     Found new best model at epoch 68
2022-12-31 13:10:35,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:35,473 INFO:     Epoch: 69
2022-12-31 13:10:37,067 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36891146302223204, 'Total loss': 0.36891146302223204} | train loss {'Reaction outcome loss': 0.23696175824844048, 'Total loss': 0.23696175824844048}
2022-12-31 13:10:37,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:37,068 INFO:     Epoch: 70
2022-12-31 13:10:38,698 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4260627160469691, 'Total loss': 0.4260627160469691} | train loss {'Reaction outcome loss': 0.26692064887965505, 'Total loss': 0.26692064887965505}
2022-12-31 13:10:38,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:38,699 INFO:     Epoch: 71
2022-12-31 13:10:40,307 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36712636798620224, 'Total loss': 0.36712636798620224} | train loss {'Reaction outcome loss': 0.29457803389084514, 'Total loss': 0.29457803389084514}
2022-12-31 13:10:40,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:40,308 INFO:     Epoch: 72
2022-12-31 13:10:41,924 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3645649582147598, 'Total loss': 0.3645649582147598} | train loss {'Reaction outcome loss': 0.28192213136176375, 'Total loss': 0.28192213136176375}
2022-12-31 13:10:41,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:41,925 INFO:     Epoch: 73
2022-12-31 13:10:43,536 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3670199216653903, 'Total loss': 0.3670199216653903} | train loss {'Reaction outcome loss': 0.2587231843805795, 'Total loss': 0.2587231843805795}
2022-12-31 13:10:43,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:43,536 INFO:     Epoch: 74
2022-12-31 13:10:45,145 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3818280359109243, 'Total loss': 0.3818280359109243} | train loss {'Reaction outcome loss': 0.2457262528937924, 'Total loss': 0.2457262528937924}
2022-12-31 13:10:45,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:45,145 INFO:     Epoch: 75
2022-12-31 13:10:46,752 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.33646855801343917, 'Total loss': 0.33646855801343917} | train loss {'Reaction outcome loss': 0.24540641601534857, 'Total loss': 0.24540641601534857}
2022-12-31 13:10:46,752 INFO:     Found new best model at epoch 75
2022-12-31 13:10:46,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:46,753 INFO:     Epoch: 76
2022-12-31 13:10:48,376 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.404004235068957, 'Total loss': 0.404004235068957} | train loss {'Reaction outcome loss': 0.2357361954864641, 'Total loss': 0.2357361954864641}
2022-12-31 13:10:48,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:48,376 INFO:     Epoch: 77
2022-12-31 13:10:49,992 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3514949311812719, 'Total loss': 0.3514949311812719} | train loss {'Reaction outcome loss': 0.24306749693873891, 'Total loss': 0.24306749693873891}
2022-12-31 13:10:49,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:49,993 INFO:     Epoch: 78
2022-12-31 13:10:51,608 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3358899017175039, 'Total loss': 0.3358899017175039} | train loss {'Reaction outcome loss': 0.23720234709200694, 'Total loss': 0.23720234709200694}
2022-12-31 13:10:51,608 INFO:     Found new best model at epoch 78
2022-12-31 13:10:51,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:51,609 INFO:     Epoch: 79
2022-12-31 13:10:53,218 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44637654945254324, 'Total loss': 0.44637654945254324} | train loss {'Reaction outcome loss': 0.23096306825839524, 'Total loss': 0.23096306825839524}
2022-12-31 13:10:53,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:53,218 INFO:     Epoch: 80
2022-12-31 13:10:54,816 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35938218931357063, 'Total loss': 0.35938218931357063} | train loss {'Reaction outcome loss': 0.2683139061420292, 'Total loss': 0.2683139061420292}
2022-12-31 13:10:54,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:54,816 INFO:     Epoch: 81
2022-12-31 13:10:56,452 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3727317228913307, 'Total loss': 0.3727317228913307} | train loss {'Reaction outcome loss': 0.2392170857688736, 'Total loss': 0.2392170857688736}
2022-12-31 13:10:56,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:56,452 INFO:     Epoch: 82
2022-12-31 13:10:58,048 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3636850317319234, 'Total loss': 0.3636850317319234} | train loss {'Reaction outcome loss': 0.232755313355997, 'Total loss': 0.232755313355997}
2022-12-31 13:10:58,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:58,048 INFO:     Epoch: 83
2022-12-31 13:10:59,659 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36024129192034404, 'Total loss': 0.36024129192034404} | train loss {'Reaction outcome loss': 0.22491280119720614, 'Total loss': 0.22491280119720614}
2022-12-31 13:10:59,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:10:59,660 INFO:     Epoch: 84
2022-12-31 13:11:01,277 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39954275687535606, 'Total loss': 0.39954275687535606} | train loss {'Reaction outcome loss': 0.23146028281911823, 'Total loss': 0.23146028281911823}
2022-12-31 13:11:01,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:01,277 INFO:     Epoch: 85
2022-12-31 13:11:02,892 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3535544460018476, 'Total loss': 0.3535544460018476} | train loss {'Reaction outcome loss': 0.2302639961940324, 'Total loss': 0.2302639961940324}
2022-12-31 13:11:02,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:02,892 INFO:     Epoch: 86
2022-12-31 13:11:04,488 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.338164026538531, 'Total loss': 0.338164026538531} | train loss {'Reaction outcome loss': 0.22461243154923094, 'Total loss': 0.22461243154923094}
2022-12-31 13:11:04,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:04,488 INFO:     Epoch: 87
2022-12-31 13:11:06,098 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3639773408571879, 'Total loss': 0.3639773408571879} | train loss {'Reaction outcome loss': 0.2179287850126391, 'Total loss': 0.2179287850126391}
2022-12-31 13:11:06,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:06,098 INFO:     Epoch: 88
2022-12-31 13:11:07,691 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3526033103466034, 'Total loss': 0.3526033103466034} | train loss {'Reaction outcome loss': 0.22737404349111562, 'Total loss': 0.22737404349111562}
2022-12-31 13:11:07,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:07,691 INFO:     Epoch: 89
2022-12-31 13:11:09,312 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.333930907646815, 'Total loss': 0.333930907646815} | train loss {'Reaction outcome loss': 0.22142050086308304, 'Total loss': 0.22142050086308304}
2022-12-31 13:11:09,313 INFO:     Found new best model at epoch 89
2022-12-31 13:11:09,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:09,314 INFO:     Epoch: 90
2022-12-31 13:11:10,923 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3600710580746333, 'Total loss': 0.3600710580746333} | train loss {'Reaction outcome loss': 0.224208335353372, 'Total loss': 0.224208335353372}
2022-12-31 13:11:10,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:10,923 INFO:     Epoch: 91
2022-12-31 13:11:12,524 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.374375985066096, 'Total loss': 0.374375985066096} | train loss {'Reaction outcome loss': 0.24198527654389973, 'Total loss': 0.24198527654389973}
2022-12-31 13:11:12,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:12,524 INFO:     Epoch: 92
2022-12-31 13:11:14,136 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3901382644971212, 'Total loss': 0.3901382644971212} | train loss {'Reaction outcome loss': 0.29695520506820816, 'Total loss': 0.29695520506820816}
2022-12-31 13:11:14,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:14,136 INFO:     Epoch: 93
2022-12-31 13:11:15,729 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38647707005341847, 'Total loss': 0.38647707005341847} | train loss {'Reaction outcome loss': 0.2459299939345447, 'Total loss': 0.2459299939345447}
2022-12-31 13:11:15,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:15,729 INFO:     Epoch: 94
2022-12-31 13:11:17,350 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38802676896254223, 'Total loss': 0.38802676896254223} | train loss {'Reaction outcome loss': 0.23572765583631353, 'Total loss': 0.23572765583631353}
2022-12-31 13:11:17,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:17,350 INFO:     Epoch: 95
2022-12-31 13:11:18,959 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3968355725208918, 'Total loss': 0.3968355725208918} | train loss {'Reaction outcome loss': 0.2452755053392679, 'Total loss': 0.2452755053392679}
2022-12-31 13:11:18,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:18,960 INFO:     Epoch: 96
2022-12-31 13:11:20,570 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.357066543896993, 'Total loss': 0.357066543896993} | train loss {'Reaction outcome loss': 0.22783220030259396, 'Total loss': 0.22783220030259396}
2022-12-31 13:11:20,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:20,571 INFO:     Epoch: 97
2022-12-31 13:11:21,863 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37003178894519806, 'Total loss': 0.37003178894519806} | train loss {'Reaction outcome loss': 0.22596531035104409, 'Total loss': 0.22596531035104409}
2022-12-31 13:11:21,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:21,863 INFO:     Epoch: 98
2022-12-31 13:11:22,945 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36653559406598407, 'Total loss': 0.36653559406598407} | train loss {'Reaction outcome loss': 0.22699981942718875, 'Total loss': 0.22699981942718875}
2022-12-31 13:11:22,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:22,946 INFO:     Epoch: 99
2022-12-31 13:11:24,040 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3899194975694021, 'Total loss': 0.3899194975694021} | train loss {'Reaction outcome loss': 0.23003079871060753, 'Total loss': 0.23003079871060753}
2022-12-31 13:11:24,040 INFO:     Best model found after epoch 90 of 100.
2022-12-31 13:11:24,040 INFO:   Done with stage: TRAINING
2022-12-31 13:11:24,040 INFO:   Starting stage: EVALUATION
2022-12-31 13:11:24,167 INFO:   Done with stage: EVALUATION
2022-12-31 13:11:24,168 INFO:   Leaving out SEQ value Fold_2
2022-12-31 13:11:24,180 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 13:11:24,181 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:11:24,828 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:11:24,828 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:11:24,897 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:11:24,897 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:11:24,897 INFO:     No hyperparam tuning for this model
2022-12-31 13:11:24,897 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:11:24,897 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:11:24,898 INFO:     None feature selector for col prot
2022-12-31 13:11:24,898 INFO:     None feature selector for col prot
2022-12-31 13:11:24,898 INFO:     None feature selector for col prot
2022-12-31 13:11:24,899 INFO:     None feature selector for col chem
2022-12-31 13:11:24,899 INFO:     None feature selector for col chem
2022-12-31 13:11:24,899 INFO:     None feature selector for col chem
2022-12-31 13:11:24,899 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:11:24,899 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:11:24,901 INFO:     Number of params in model 223921
2022-12-31 13:11:24,904 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:11:24,904 INFO:   Starting stage: TRAINING
2022-12-31 13:11:24,939 INFO:     Val loss before train {'Reaction outcome loss': 0.970865003267924, 'Total loss': 0.970865003267924}
2022-12-31 13:11:24,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:24,940 INFO:     Epoch: 0
2022-12-31 13:11:26,153 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6205050388971964, 'Total loss': 0.6205050388971964} | train loss {'Reaction outcome loss': 0.8012845739178414, 'Total loss': 0.8012845739178414}
2022-12-31 13:11:26,153 INFO:     Found new best model at epoch 0
2022-12-31 13:11:26,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:26,154 INFO:     Epoch: 1
2022-12-31 13:11:27,764 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4859043498833974, 'Total loss': 0.4859043498833974} | train loss {'Reaction outcome loss': 0.5962401437063287, 'Total loss': 0.5962401437063287}
2022-12-31 13:11:27,765 INFO:     Found new best model at epoch 1
2022-12-31 13:11:27,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:27,766 INFO:     Epoch: 2
2022-12-31 13:11:29,380 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47360452512900036, 'Total loss': 0.47360452512900036} | train loss {'Reaction outcome loss': 0.5300399568611688, 'Total loss': 0.5300399568611688}
2022-12-31 13:11:29,380 INFO:     Found new best model at epoch 2
2022-12-31 13:11:29,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:29,381 INFO:     Epoch: 3
2022-12-31 13:11:31,000 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48897334933280945, 'Total loss': 0.48897334933280945} | train loss {'Reaction outcome loss': 0.5133755580678473, 'Total loss': 0.5133755580678473}
2022-12-31 13:11:31,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:31,000 INFO:     Epoch: 4
2022-12-31 13:11:32,589 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4177211662133535, 'Total loss': 0.4177211662133535} | train loss {'Reaction outcome loss': 0.4971420085125596, 'Total loss': 0.4971420085125596}
2022-12-31 13:11:32,589 INFO:     Found new best model at epoch 4
2022-12-31 13:11:32,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:32,590 INFO:     Epoch: 5
2022-12-31 13:11:34,198 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41744188765684764, 'Total loss': 0.41744188765684764} | train loss {'Reaction outcome loss': 0.4819530673379446, 'Total loss': 0.4819530673379446}
2022-12-31 13:11:34,199 INFO:     Found new best model at epoch 5
2022-12-31 13:11:34,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:34,200 INFO:     Epoch: 6
2022-12-31 13:11:35,799 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4118786990642548, 'Total loss': 0.4118786990642548} | train loss {'Reaction outcome loss': 0.47549013978373394, 'Total loss': 0.47549013978373394}
2022-12-31 13:11:35,799 INFO:     Found new best model at epoch 6
2022-12-31 13:11:35,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:35,800 INFO:     Epoch: 7
2022-12-31 13:11:37,396 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40800404250621797, 'Total loss': 0.40800404250621797} | train loss {'Reaction outcome loss': 0.4616878727165452, 'Total loss': 0.4616878727165452}
2022-12-31 13:11:37,396 INFO:     Found new best model at epoch 7
2022-12-31 13:11:37,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:37,397 INFO:     Epoch: 8
2022-12-31 13:11:38,994 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4020175963640213, 'Total loss': 0.4020175963640213} | train loss {'Reaction outcome loss': 0.4559745430728815, 'Total loss': 0.4559745430728815}
2022-12-31 13:11:38,994 INFO:     Found new best model at epoch 8
2022-12-31 13:11:38,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:38,995 INFO:     Epoch: 9
2022-12-31 13:11:40,614 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39549272656440737, 'Total loss': 0.39549272656440737} | train loss {'Reaction outcome loss': 0.4572863659284411, 'Total loss': 0.4572863659284411}
2022-12-31 13:11:40,615 INFO:     Found new best model at epoch 9
2022-12-31 13:11:40,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:40,616 INFO:     Epoch: 10
2022-12-31 13:11:42,256 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4006710350513458, 'Total loss': 0.4006710350513458} | train loss {'Reaction outcome loss': 0.4485495877962043, 'Total loss': 0.4485495877962043}
2022-12-31 13:11:42,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:42,256 INFO:     Epoch: 11
2022-12-31 13:11:43,886 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37998802661895753, 'Total loss': 0.37998802661895753} | train loss {'Reaction outcome loss': 0.43817633966894914, 'Total loss': 0.43817633966894914}
2022-12-31 13:11:43,886 INFO:     Found new best model at epoch 11
2022-12-31 13:11:43,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:43,887 INFO:     Epoch: 12
2022-12-31 13:11:45,471 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4425460934638977, 'Total loss': 0.4425460934638977} | train loss {'Reaction outcome loss': 0.4319210993873812, 'Total loss': 0.4319210993873812}
2022-12-31 13:11:45,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:45,471 INFO:     Epoch: 13
2022-12-31 13:11:47,072 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39363037745157875, 'Total loss': 0.39363037745157875} | train loss {'Reaction outcome loss': 0.42875179855057793, 'Total loss': 0.42875179855057793}
2022-12-31 13:11:47,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:47,072 INFO:     Epoch: 14
2022-12-31 13:11:48,671 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3742437243461609, 'Total loss': 0.3742437243461609} | train loss {'Reaction outcome loss': 0.4195580132251238, 'Total loss': 0.4195580132251238}
2022-12-31 13:11:48,671 INFO:     Found new best model at epoch 14
2022-12-31 13:11:48,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:48,672 INFO:     Epoch: 15
2022-12-31 13:11:50,251 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39080250561237334, 'Total loss': 0.39080250561237334} | train loss {'Reaction outcome loss': 0.41357340859453173, 'Total loss': 0.41357340859453173}
2022-12-31 13:11:50,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:50,251 INFO:     Epoch: 16
2022-12-31 13:11:51,855 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3566829760869344, 'Total loss': 0.3566829760869344} | train loss {'Reaction outcome loss': 0.4131796745597011, 'Total loss': 0.4131796745597011}
2022-12-31 13:11:51,857 INFO:     Found new best model at epoch 16
2022-12-31 13:11:51,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:51,858 INFO:     Epoch: 17
2022-12-31 13:11:53,431 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3637833615144094, 'Total loss': 0.3637833615144094} | train loss {'Reaction outcome loss': 0.40407325115299575, 'Total loss': 0.40407325115299575}
2022-12-31 13:11:53,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:53,431 INFO:     Epoch: 18
2022-12-31 13:11:55,037 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3719655911127726, 'Total loss': 0.3719655911127726} | train loss {'Reaction outcome loss': 0.40004606444361435, 'Total loss': 0.40004606444361435}
2022-12-31 13:11:55,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:55,037 INFO:     Epoch: 19
2022-12-31 13:11:56,633 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38939815560976665, 'Total loss': 0.38939815560976665} | train loss {'Reaction outcome loss': 0.3868786435927788, 'Total loss': 0.3868786435927788}
2022-12-31 13:11:56,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:56,633 INFO:     Epoch: 20
2022-12-31 13:11:58,230 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37589089622100197, 'Total loss': 0.37589089622100197} | train loss {'Reaction outcome loss': 0.38476130352729426, 'Total loss': 0.38476130352729426}
2022-12-31 13:11:58,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:58,231 INFO:     Epoch: 21
2022-12-31 13:11:59,819 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35377297004063923, 'Total loss': 0.35377297004063923} | train loss {'Reaction outcome loss': 0.38181019715801645, 'Total loss': 0.38181019715801645}
2022-12-31 13:11:59,819 INFO:     Found new best model at epoch 21
2022-12-31 13:11:59,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:11:59,820 INFO:     Epoch: 22
2022-12-31 13:12:01,417 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3504012773434321, 'Total loss': 0.3504012773434321} | train loss {'Reaction outcome loss': 0.37291604215211244, 'Total loss': 0.37291604215211244}
2022-12-31 13:12:01,417 INFO:     Found new best model at epoch 22
2022-12-31 13:12:01,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:01,418 INFO:     Epoch: 23
2022-12-31 13:12:02,997 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3558424820502599, 'Total loss': 0.3558424820502599} | train loss {'Reaction outcome loss': 0.3690404585107182, 'Total loss': 0.3690404585107182}
2022-12-31 13:12:02,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:02,997 INFO:     Epoch: 24
2022-12-31 13:12:04,597 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37106243471304573, 'Total loss': 0.37106243471304573} | train loss {'Reaction outcome loss': 0.3664313190120415, 'Total loss': 0.3664313190120415}
2022-12-31 13:12:04,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:04,597 INFO:     Epoch: 25
2022-12-31 13:12:06,199 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3422098358472188, 'Total loss': 0.3422098358472188} | train loss {'Reaction outcome loss': 0.3633170860690357, 'Total loss': 0.3633170860690357}
2022-12-31 13:12:06,199 INFO:     Found new best model at epoch 25
2022-12-31 13:12:06,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:06,200 INFO:     Epoch: 26
2022-12-31 13:12:07,788 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.327586787690719, 'Total loss': 0.327586787690719} | train loss {'Reaction outcome loss': 0.3510327718227449, 'Total loss': 0.3510327718227449}
2022-12-31 13:12:07,788 INFO:     Found new best model at epoch 26
2022-12-31 13:12:07,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:07,789 INFO:     Epoch: 27
2022-12-31 13:12:09,432 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34038721521695453, 'Total loss': 0.34038721521695453} | train loss {'Reaction outcome loss': 0.3502306757073333, 'Total loss': 0.3502306757073333}
2022-12-31 13:12:09,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:09,432 INFO:     Epoch: 28
2022-12-31 13:12:11,030 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3477899630864461, 'Total loss': 0.3477899630864461} | train loss {'Reaction outcome loss': 0.3424849388373159, 'Total loss': 0.3424849388373159}
2022-12-31 13:12:11,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:11,031 INFO:     Epoch: 29
2022-12-31 13:12:12,625 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.33799902697404227, 'Total loss': 0.33799902697404227} | train loss {'Reaction outcome loss': 0.33886172073165866, 'Total loss': 0.33886172073165866}
2022-12-31 13:12:12,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:12,625 INFO:     Epoch: 30
2022-12-31 13:12:14,230 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.35499970813592274, 'Total loss': 0.35499970813592274} | train loss {'Reaction outcome loss': 0.3326640831184213, 'Total loss': 0.3326640831184213}
2022-12-31 13:12:14,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:14,230 INFO:     Epoch: 31
2022-12-31 13:12:15,834 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3548773099978765, 'Total loss': 0.3548773099978765} | train loss {'Reaction outcome loss': 0.33275767228137837, 'Total loss': 0.33275767228137837}
2022-12-31 13:12:15,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:15,834 INFO:     Epoch: 32
2022-12-31 13:12:17,439 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3724285821119944, 'Total loss': 0.3724285821119944} | train loss {'Reaction outcome loss': 0.3194782639697303, 'Total loss': 0.3194782639697303}
2022-12-31 13:12:17,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:17,439 INFO:     Epoch: 33
2022-12-31 13:12:19,059 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.32534001270929974, 'Total loss': 0.32534001270929974} | train loss {'Reaction outcome loss': 0.32409363036064337, 'Total loss': 0.32409363036064337}
2022-12-31 13:12:19,059 INFO:     Found new best model at epoch 33
2022-12-31 13:12:19,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:19,060 INFO:     Epoch: 34
2022-12-31 13:12:20,648 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.32278862595558167, 'Total loss': 0.32278862595558167} | train loss {'Reaction outcome loss': 0.31616785613833553, 'Total loss': 0.31616785613833553}
2022-12-31 13:12:20,648 INFO:     Found new best model at epoch 34
2022-12-31 13:12:20,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:20,649 INFO:     Epoch: 35
2022-12-31 13:12:22,250 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3158985863129298, 'Total loss': 0.3158985863129298} | train loss {'Reaction outcome loss': 0.3103802388221243, 'Total loss': 0.3103802388221243}
2022-12-31 13:12:22,251 INFO:     Found new best model at epoch 35
2022-12-31 13:12:22,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:22,252 INFO:     Epoch: 36
2022-12-31 13:12:23,855 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.357553327580293, 'Total loss': 0.357553327580293} | train loss {'Reaction outcome loss': 0.31247868447353805, 'Total loss': 0.31247868447353805}
2022-12-31 13:12:23,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:23,855 INFO:     Epoch: 37
2022-12-31 13:12:25,451 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3252526357769966, 'Total loss': 0.3252526357769966} | train loss {'Reaction outcome loss': 0.3043241779571467, 'Total loss': 0.3043241779571467}
2022-12-31 13:12:25,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:25,452 INFO:     Epoch: 38
2022-12-31 13:12:27,069 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.32021743555863696, 'Total loss': 0.32021743555863696} | train loss {'Reaction outcome loss': 0.3026008960539407, 'Total loss': 0.3026008960539407}
2022-12-31 13:12:27,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:27,069 INFO:     Epoch: 39
2022-12-31 13:12:28,678 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3264228751262029, 'Total loss': 0.3264228751262029} | train loss {'Reaction outcome loss': 0.2995590250531252, 'Total loss': 0.2995590250531252}
2022-12-31 13:12:28,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:28,679 INFO:     Epoch: 40
2022-12-31 13:12:30,264 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.29702321539322535, 'Total loss': 0.29702321539322535} | train loss {'Reaction outcome loss': 0.2928633166164377, 'Total loss': 0.2928633166164377}
2022-12-31 13:12:30,264 INFO:     Found new best model at epoch 40
2022-12-31 13:12:30,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:30,265 INFO:     Epoch: 41
2022-12-31 13:12:31,868 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3431032170852025, 'Total loss': 0.3431032170852025} | train loss {'Reaction outcome loss': 0.2937793174119544, 'Total loss': 0.2937793174119544}
2022-12-31 13:12:31,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:31,868 INFO:     Epoch: 42
2022-12-31 13:12:33,478 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.32896662056446074, 'Total loss': 0.32896662056446074} | train loss {'Reaction outcome loss': 0.2929615307137044, 'Total loss': 0.2929615307137044}
2022-12-31 13:12:33,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:33,478 INFO:     Epoch: 43
2022-12-31 13:12:35,073 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.30732587178548176, 'Total loss': 0.30732587178548176} | train loss {'Reaction outcome loss': 0.2830253012587119, 'Total loss': 0.2830253012587119}
2022-12-31 13:12:35,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:35,073 INFO:     Epoch: 44
2022-12-31 13:12:36,717 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.33366923381884894, 'Total loss': 0.33366923381884894} | train loss {'Reaction outcome loss': 0.281829143119772, 'Total loss': 0.281829143119772}
2022-12-31 13:12:36,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:36,718 INFO:     Epoch: 45
2022-12-31 13:12:38,302 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.321105432510376, 'Total loss': 0.321105432510376} | train loss {'Reaction outcome loss': 0.28163351148475696, 'Total loss': 0.28163351148475696}
2022-12-31 13:12:38,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:38,302 INFO:     Epoch: 46
2022-12-31 13:12:39,905 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3087378770112991, 'Total loss': 0.3087378770112991} | train loss {'Reaction outcome loss': 0.28049290008897326, 'Total loss': 0.28049290008897326}
2022-12-31 13:12:39,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:39,905 INFO:     Epoch: 47
2022-12-31 13:12:41,516 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3311358690261841, 'Total loss': 0.3311358690261841} | train loss {'Reaction outcome loss': 0.2760543099529769, 'Total loss': 0.2760543099529769}
2022-12-31 13:12:41,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:41,517 INFO:     Epoch: 48
2022-12-31 13:12:43,121 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3357483396927516, 'Total loss': 0.3357483396927516} | train loss {'Reaction outcome loss': 0.27264734402462076, 'Total loss': 0.27264734402462076}
2022-12-31 13:12:43,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:43,121 INFO:     Epoch: 49
2022-12-31 13:12:44,715 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3270109643538793, 'Total loss': 0.3270109643538793} | train loss {'Reaction outcome loss': 0.2678989231939951, 'Total loss': 0.2678989231939951}
2022-12-31 13:12:44,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:44,716 INFO:     Epoch: 50
2022-12-31 13:12:46,316 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33582916657129924, 'Total loss': 0.33582916657129924} | train loss {'Reaction outcome loss': 0.26340114506111095, 'Total loss': 0.26340114506111095}
2022-12-31 13:12:46,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:46,317 INFO:     Epoch: 51
2022-12-31 13:12:47,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.32667650083700817, 'Total loss': 0.32667650083700817} | train loss {'Reaction outcome loss': 0.2648845323748941, 'Total loss': 0.2648845323748941}
2022-12-31 13:12:47,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:47,912 INFO:     Epoch: 52
2022-12-31 13:12:49,522 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3420740773280462, 'Total loss': 0.3420740773280462} | train loss {'Reaction outcome loss': 0.25432759617203776, 'Total loss': 0.25432759617203776}
2022-12-31 13:12:49,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:49,522 INFO:     Epoch: 53
2022-12-31 13:12:51,124 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.333750640352567, 'Total loss': 0.333750640352567} | train loss {'Reaction outcome loss': 0.2589261534005186, 'Total loss': 0.2589261534005186}
2022-12-31 13:12:51,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:51,125 INFO:     Epoch: 54
2022-12-31 13:12:52,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.30664874116579693, 'Total loss': 0.30664874116579693} | train loss {'Reaction outcome loss': 0.2554977107453194, 'Total loss': 0.2554977107453194}
2022-12-31 13:12:52,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:52,715 INFO:     Epoch: 55
2022-12-31 13:12:54,316 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3488708664973577, 'Total loss': 0.3488708664973577} | train loss {'Reaction outcome loss': 0.26200442587154626, 'Total loss': 0.26200442587154626}
2022-12-31 13:12:54,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:54,316 INFO:     Epoch: 56
2022-12-31 13:12:55,916 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.32325537701447804, 'Total loss': 0.32325537701447804} | train loss {'Reaction outcome loss': 0.25326287760025396, 'Total loss': 0.25326287760025396}
2022-12-31 13:12:55,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:55,917 INFO:     Epoch: 57
2022-12-31 13:12:57,506 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36174099644025165, 'Total loss': 0.36174099644025165} | train loss {'Reaction outcome loss': 0.24995348021986274, 'Total loss': 0.24995348021986274}
2022-12-31 13:12:57,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:57,506 INFO:     Epoch: 58
2022-12-31 13:12:59,114 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.30647001763184867, 'Total loss': 0.30647001763184867} | train loss {'Reaction outcome loss': 0.2497712439945797, 'Total loss': 0.2497712439945797}
2022-12-31 13:12:59,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:12:59,115 INFO:     Epoch: 59
2022-12-31 13:13:00,723 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3061546251177788, 'Total loss': 0.3061546251177788} | train loss {'Reaction outcome loss': 0.2540245987338959, 'Total loss': 0.2540245987338959}
2022-12-31 13:13:00,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:00,723 INFO:     Epoch: 60
2022-12-31 13:13:02,307 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.32393121520678203, 'Total loss': 0.32393121520678203} | train loss {'Reaction outcome loss': 0.24763822021221157, 'Total loss': 0.24763822021221157}
2022-12-31 13:13:02,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:02,307 INFO:     Epoch: 61
2022-12-31 13:13:03,913 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.321376567085584, 'Total loss': 0.321376567085584} | train loss {'Reaction outcome loss': 0.24774325717865986, 'Total loss': 0.24774325717865986}
2022-12-31 13:13:03,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:03,913 INFO:     Epoch: 62
2022-12-31 13:13:05,512 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.32334263424078624, 'Total loss': 0.32334263424078624} | train loss {'Reaction outcome loss': 0.24335930965514513, 'Total loss': 0.24335930965514513}
2022-12-31 13:13:05,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:05,513 INFO:     Epoch: 63
2022-12-31 13:13:07,136 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3217911501725515, 'Total loss': 0.3217911501725515} | train loss {'Reaction outcome loss': 0.247651652208645, 'Total loss': 0.247651652208645}
2022-12-31 13:13:07,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:07,136 INFO:     Epoch: 64
2022-12-31 13:13:08,740 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.31519084572792055, 'Total loss': 0.31519084572792055} | train loss {'Reaction outcome loss': 0.2383796738147953, 'Total loss': 0.2383796738147953}
2022-12-31 13:13:08,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:08,740 INFO:     Epoch: 65
2022-12-31 13:13:10,345 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.314516152938207, 'Total loss': 0.314516152938207} | train loss {'Reaction outcome loss': 0.23687566045916428, 'Total loss': 0.23687566045916428}
2022-12-31 13:13:10,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:10,345 INFO:     Epoch: 66
2022-12-31 13:13:11,929 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.32276464203993477, 'Total loss': 0.32276464203993477} | train loss {'Reaction outcome loss': 0.23141635222917925, 'Total loss': 0.23141635222917925}
2022-12-31 13:13:11,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:11,930 INFO:     Epoch: 67
2022-12-31 13:13:13,560 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.30759673913319907, 'Total loss': 0.30759673913319907} | train loss {'Reaction outcome loss': 0.23355993357942487, 'Total loss': 0.23355993357942487}
2022-12-31 13:13:13,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:13,560 INFO:     Epoch: 68
2022-12-31 13:13:15,159 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3301362360517184, 'Total loss': 0.3301362360517184} | train loss {'Reaction outcome loss': 0.23241481133974598, 'Total loss': 0.23241481133974598}
2022-12-31 13:13:15,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:15,160 INFO:     Epoch: 69
2022-12-31 13:13:16,759 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3109292725721995, 'Total loss': 0.3109292725721995} | train loss {'Reaction outcome loss': 0.2319389775490565, 'Total loss': 0.2319389775490565}
2022-12-31 13:13:16,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:16,759 INFO:     Epoch: 70
2022-12-31 13:13:18,413 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.32135558128356934, 'Total loss': 0.32135558128356934} | train loss {'Reaction outcome loss': 0.23641331286516284, 'Total loss': 0.23641331286516284}
2022-12-31 13:13:18,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:18,414 INFO:     Epoch: 71
2022-12-31 13:13:20,011 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.30915574928124745, 'Total loss': 0.30915574928124745} | train loss {'Reaction outcome loss': 0.2332063857601942, 'Total loss': 0.2332063857601942}
2022-12-31 13:13:20,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:20,011 INFO:     Epoch: 72
2022-12-31 13:13:21,621 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3281828304131826, 'Total loss': 0.3281828304131826} | train loss {'Reaction outcome loss': 0.23079933375664, 'Total loss': 0.23079933375664}
2022-12-31 13:13:21,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:21,621 INFO:     Epoch: 73
2022-12-31 13:13:23,218 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39158705522616705, 'Total loss': 0.39158705522616705} | train loss {'Reaction outcome loss': 0.23048406736041507, 'Total loss': 0.23048406736041507}
2022-12-31 13:13:23,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:23,219 INFO:     Epoch: 74
2022-12-31 13:13:24,834 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3007279177506765, 'Total loss': 0.3007279177506765} | train loss {'Reaction outcome loss': 0.2268731598572357, 'Total loss': 0.2268731598572357}
2022-12-31 13:13:24,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:24,834 INFO:     Epoch: 75
2022-12-31 13:13:26,423 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.32597707509994506, 'Total loss': 0.32597707509994506} | train loss {'Reaction outcome loss': 0.23035520746161903, 'Total loss': 0.23035520746161903}
2022-12-31 13:13:26,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:26,423 INFO:     Epoch: 76
2022-12-31 13:13:28,061 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.30887598196665444, 'Total loss': 0.30887598196665444} | train loss {'Reaction outcome loss': 0.2284713604888559, 'Total loss': 0.2284713604888559}
2022-12-31 13:13:28,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:28,062 INFO:     Epoch: 77
2022-12-31 13:13:29,679 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.31114684908340373, 'Total loss': 0.31114684908340373} | train loss {'Reaction outcome loss': 0.22295085987905516, 'Total loss': 0.22295085987905516}
2022-12-31 13:13:29,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:29,680 INFO:     Epoch: 78
2022-12-31 13:13:31,297 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.314990246295929, 'Total loss': 0.314990246295929} | train loss {'Reaction outcome loss': 0.2205695260424901, 'Total loss': 0.2205695260424901}
2022-12-31 13:13:31,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:31,298 INFO:     Epoch: 79
2022-12-31 13:13:32,905 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3034419352809588, 'Total loss': 0.3034419352809588} | train loss {'Reaction outcome loss': 0.21914195180972562, 'Total loss': 0.21914195180972562}
2022-12-31 13:13:32,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:32,905 INFO:     Epoch: 80
2022-12-31 13:13:34,500 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.29065723915894826, 'Total loss': 0.29065723915894826} | train loss {'Reaction outcome loss': 0.22433234320232903, 'Total loss': 0.22433234320232903}
2022-12-31 13:13:34,501 INFO:     Found new best model at epoch 80
2022-12-31 13:13:34,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:34,502 INFO:     Epoch: 81
2022-12-31 13:13:36,094 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.33662575483322144, 'Total loss': 0.33662575483322144} | train loss {'Reaction outcome loss': 0.21464763253410585, 'Total loss': 0.21464763253410585}
2022-12-31 13:13:36,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:36,095 INFO:     Epoch: 82
2022-12-31 13:13:37,693 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.2835285276174545, 'Total loss': 0.2835285276174545} | train loss {'Reaction outcome loss': 0.21236528364438428, 'Total loss': 0.21236528364438428}
2022-12-31 13:13:37,693 INFO:     Found new best model at epoch 82
2022-12-31 13:13:37,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:37,694 INFO:     Epoch: 83
2022-12-31 13:13:39,273 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3355044474204381, 'Total loss': 0.3355044474204381} | train loss {'Reaction outcome loss': 0.22385391762928805, 'Total loss': 0.22385391762928805}
2022-12-31 13:13:39,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:39,273 INFO:     Epoch: 84
2022-12-31 13:13:40,881 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.28285470853249234, 'Total loss': 0.28285470853249234} | train loss {'Reaction outcome loss': 0.21384445591455828, 'Total loss': 0.21384445591455828}
2022-12-31 13:13:40,881 INFO:     Found new best model at epoch 84
2022-12-31 13:13:40,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:40,882 INFO:     Epoch: 85
2022-12-31 13:13:42,458 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3144530445337296, 'Total loss': 0.3144530445337296} | train loss {'Reaction outcome loss': 0.21179578884293998, 'Total loss': 0.21179578884293998}
2022-12-31 13:13:42,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:42,459 INFO:     Epoch: 86
2022-12-31 13:13:44,081 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.29318641865005096, 'Total loss': 0.29318641865005096} | train loss {'Reaction outcome loss': 0.20959717374172632, 'Total loss': 0.20959717374172632}
2022-12-31 13:13:44,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:44,081 INFO:     Epoch: 87
2022-12-31 13:13:45,676 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3161822338898977, 'Total loss': 0.3161822338898977} | train loss {'Reaction outcome loss': 0.20821791210205015, 'Total loss': 0.20821791210205015}
2022-12-31 13:13:45,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:45,676 INFO:     Epoch: 88
2022-12-31 13:13:47,274 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.31104358633359275, 'Total loss': 0.31104358633359275} | train loss {'Reaction outcome loss': 0.2159885016786628, 'Total loss': 0.2159885016786628}
2022-12-31 13:13:47,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:47,275 INFO:     Epoch: 89
2022-12-31 13:13:48,890 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3386953890323639, 'Total loss': 0.3386953890323639} | train loss {'Reaction outcome loss': 0.21236476597858825, 'Total loss': 0.21236476597858825}
2022-12-31 13:13:48,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:48,890 INFO:     Epoch: 90
2022-12-31 13:13:50,511 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3104216066499551, 'Total loss': 0.3104216066499551} | train loss {'Reaction outcome loss': 0.2097978855408456, 'Total loss': 0.2097978855408456}
2022-12-31 13:13:50,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:50,511 INFO:     Epoch: 91
2022-12-31 13:13:52,115 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3215305209159851, 'Total loss': 0.3215305209159851} | train loss {'Reaction outcome loss': 0.20571560701559277, 'Total loss': 0.20571560701559277}
2022-12-31 13:13:52,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:52,115 INFO:     Epoch: 92
2022-12-31 13:13:53,715 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.31980426559845604, 'Total loss': 0.31980426559845604} | train loss {'Reaction outcome loss': 0.20577404597080753, 'Total loss': 0.20577404597080753}
2022-12-31 13:13:53,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:53,715 INFO:     Epoch: 93
2022-12-31 13:13:55,315 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3015169034401576, 'Total loss': 0.3015169034401576} | train loss {'Reaction outcome loss': 0.19862133031371085, 'Total loss': 0.19862133031371085}
2022-12-31 13:13:55,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:55,316 INFO:     Epoch: 94
2022-12-31 13:13:56,896 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33445859799782435, 'Total loss': 0.33445859799782435} | train loss {'Reaction outcome loss': 0.20643075987914183, 'Total loss': 0.20643075987914183}
2022-12-31 13:13:56,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:56,897 INFO:     Epoch: 95
2022-12-31 13:13:58,497 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.31147842705249784, 'Total loss': 0.31147842705249784} | train loss {'Reaction outcome loss': 0.20387329802216186, 'Total loss': 0.20387329802216186}
2022-12-31 13:13:58,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:13:58,498 INFO:     Epoch: 96
2022-12-31 13:14:00,087 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.30694190387924514, 'Total loss': 0.30694190387924514} | train loss {'Reaction outcome loss': 0.19497120167624993, 'Total loss': 0.19497120167624993}
2022-12-31 13:14:00,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:00,088 INFO:     Epoch: 97
2022-12-31 13:14:01,681 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3329950958490372, 'Total loss': 0.3329950958490372} | train loss {'Reaction outcome loss': 0.19950191355752248, 'Total loss': 0.19950191355752248}
2022-12-31 13:14:01,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:01,681 INFO:     Epoch: 98
2022-12-31 13:14:03,305 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.30937665502230327, 'Total loss': 0.30937665502230327} | train loss {'Reaction outcome loss': 0.20940280722685323, 'Total loss': 0.20940280722685323}
2022-12-31 13:14:03,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:03,305 INFO:     Epoch: 99
2022-12-31 13:14:04,915 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3017928138375282, 'Total loss': 0.3017928138375282} | train loss {'Reaction outcome loss': 0.20627970410932372, 'Total loss': 0.20627970410932372}
2022-12-31 13:14:04,915 INFO:     Best model found after epoch 85 of 100.
2022-12-31 13:14:04,915 INFO:   Done with stage: TRAINING
2022-12-31 13:14:04,915 INFO:   Starting stage: EVALUATION
2022-12-31 13:14:05,049 INFO:   Done with stage: EVALUATION
2022-12-31 13:14:05,049 INFO:   Leaving out SEQ value Fold_3
2022-12-31 13:14:05,062 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 13:14:05,062 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:14:05,705 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:14:05,705 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:14:05,773 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:14:05,773 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:14:05,773 INFO:     No hyperparam tuning for this model
2022-12-31 13:14:05,773 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:14:05,773 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:14:05,774 INFO:     None feature selector for col prot
2022-12-31 13:14:05,774 INFO:     None feature selector for col prot
2022-12-31 13:14:05,774 INFO:     None feature selector for col prot
2022-12-31 13:14:05,775 INFO:     None feature selector for col chem
2022-12-31 13:14:05,775 INFO:     None feature selector for col chem
2022-12-31 13:14:05,775 INFO:     None feature selector for col chem
2022-12-31 13:14:05,775 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:14:05,775 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:14:05,777 INFO:     Number of params in model 223921
2022-12-31 13:14:05,780 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:14:05,780 INFO:   Starting stage: TRAINING
2022-12-31 13:14:05,825 INFO:     Val loss before train {'Reaction outcome loss': 1.0209410309791564, 'Total loss': 1.0209410309791564}
2022-12-31 13:14:05,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:05,825 INFO:     Epoch: 0
2022-12-31 13:14:07,438 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6830738971630732, 'Total loss': 0.6830738971630732} | train loss {'Reaction outcome loss': 0.8129379972542599, 'Total loss': 0.8129379972542599}
2022-12-31 13:14:07,439 INFO:     Found new best model at epoch 0
2022-12-31 13:14:07,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:07,440 INFO:     Epoch: 1
2022-12-31 13:14:09,016 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5812604149182637, 'Total loss': 0.5812604149182637} | train loss {'Reaction outcome loss': 0.6051600388227365, 'Total loss': 0.6051600388227365}
2022-12-31 13:14:09,016 INFO:     Found new best model at epoch 1
2022-12-31 13:14:09,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:09,017 INFO:     Epoch: 2
2022-12-31 13:14:10,609 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5513627191384634, 'Total loss': 0.5513627191384634} | train loss {'Reaction outcome loss': 0.5282928702377138, 'Total loss': 0.5282928702377138}
2022-12-31 13:14:10,609 INFO:     Found new best model at epoch 2
2022-12-31 13:14:10,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:10,610 INFO:     Epoch: 3
2022-12-31 13:14:12,200 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5100321690241496, 'Total loss': 0.5100321690241496} | train loss {'Reaction outcome loss': 0.5097304689032691, 'Total loss': 0.5097304689032691}
2022-12-31 13:14:12,201 INFO:     Found new best model at epoch 3
2022-12-31 13:14:12,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:12,202 INFO:     Epoch: 4
2022-12-31 13:14:13,792 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5303421894709269, 'Total loss': 0.5303421894709269} | train loss {'Reaction outcome loss': 0.4825518780248069, 'Total loss': 0.4825518780248069}
2022-12-31 13:14:13,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:13,793 INFO:     Epoch: 5
2022-12-31 13:14:15,394 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5034542908271153, 'Total loss': 0.5034542908271153} | train loss {'Reaction outcome loss': 0.47569030288593234, 'Total loss': 0.47569030288593234}
2022-12-31 13:14:15,394 INFO:     Found new best model at epoch 5
2022-12-31 13:14:15,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:15,395 INFO:     Epoch: 6
2022-12-31 13:14:16,987 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5254140555858612, 'Total loss': 0.5254140555858612} | train loss {'Reaction outcome loss': 0.46765870860208086, 'Total loss': 0.46765870860208086}
2022-12-31 13:14:16,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:16,987 INFO:     Epoch: 7
2022-12-31 13:14:18,564 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4940102616945902, 'Total loss': 0.4940102616945902} | train loss {'Reaction outcome loss': 0.45450419266349995, 'Total loss': 0.45450419266349995}
2022-12-31 13:14:18,564 INFO:     Found new best model at epoch 7
2022-12-31 13:14:18,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:18,565 INFO:     Epoch: 8
2022-12-31 13:14:20,156 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46984870036443077, 'Total loss': 0.46984870036443077} | train loss {'Reaction outcome loss': 0.4564424302879271, 'Total loss': 0.4564424302879271}
2022-12-31 13:14:20,157 INFO:     Found new best model at epoch 8
2022-12-31 13:14:20,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:20,158 INFO:     Epoch: 9
2022-12-31 13:14:21,748 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5143065194288889, 'Total loss': 0.5143065194288889} | train loss {'Reaction outcome loss': 0.4456051617806211, 'Total loss': 0.4456051617806211}
2022-12-31 13:14:21,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:21,748 INFO:     Epoch: 10
2022-12-31 13:14:23,322 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5028726279735565, 'Total loss': 0.5028726279735565} | train loss {'Reaction outcome loss': 0.4409382029167025, 'Total loss': 0.4409382029167025}
2022-12-31 13:14:23,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:23,322 INFO:     Epoch: 11
2022-12-31 13:14:24,915 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47387116551399233, 'Total loss': 0.47387116551399233} | train loss {'Reaction outcome loss': 0.4322032107538356, 'Total loss': 0.4322032107538356}
2022-12-31 13:14:24,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:24,915 INFO:     Epoch: 12
2022-12-31 13:14:26,486 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4839929501215617, 'Total loss': 0.4839929501215617} | train loss {'Reaction outcome loss': 0.42478804252086544, 'Total loss': 0.42478804252086544}
2022-12-31 13:14:26,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:26,487 INFO:     Epoch: 13
2022-12-31 13:14:28,125 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4717199683189392, 'Total loss': 0.4717199683189392} | train loss {'Reaction outcome loss': 0.4183337702637627, 'Total loss': 0.4183337702637627}
2022-12-31 13:14:28,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:28,126 INFO:     Epoch: 14
2022-12-31 13:14:29,760 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4707487732172012, 'Total loss': 0.4707487732172012} | train loss {'Reaction outcome loss': 0.411372368643572, 'Total loss': 0.411372368643572}
2022-12-31 13:14:29,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:29,760 INFO:     Epoch: 15
2022-12-31 13:14:31,366 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45250502626101174, 'Total loss': 0.45250502626101174} | train loss {'Reaction outcome loss': 0.405905545006878, 'Total loss': 0.405905545006878}
2022-12-31 13:14:31,366 INFO:     Found new best model at epoch 15
2022-12-31 13:14:31,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:31,367 INFO:     Epoch: 16
2022-12-31 13:14:32,966 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4655870467424393, 'Total loss': 0.4655870467424393} | train loss {'Reaction outcome loss': 0.4024881885929422, 'Total loss': 0.4024881885929422}
2022-12-31 13:14:32,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:32,966 INFO:     Epoch: 17
2022-12-31 13:14:34,559 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4698083698749542, 'Total loss': 0.4698083698749542} | train loss {'Reaction outcome loss': 0.397870693778817, 'Total loss': 0.397870693778817}
2022-12-31 13:14:34,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:34,559 INFO:     Epoch: 18
2022-12-31 13:14:36,127 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47982504963874817, 'Total loss': 0.47982504963874817} | train loss {'Reaction outcome loss': 0.3955858654919125, 'Total loss': 0.3955858654919125}
2022-12-31 13:14:36,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:36,129 INFO:     Epoch: 19
2022-12-31 13:14:37,723 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4419562786817551, 'Total loss': 0.4419562786817551} | train loss {'Reaction outcome loss': 0.39262837444469606, 'Total loss': 0.39262837444469606}
2022-12-31 13:14:37,724 INFO:     Found new best model at epoch 19
2022-12-31 13:14:37,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:37,725 INFO:     Epoch: 20
2022-12-31 13:14:39,342 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4478442450364431, 'Total loss': 0.4478442450364431} | train loss {'Reaction outcome loss': 0.37786499004224283, 'Total loss': 0.37786499004224283}
2022-12-31 13:14:39,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:39,342 INFO:     Epoch: 21
2022-12-31 13:14:40,982 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45517266988754274, 'Total loss': 0.45517266988754274} | train loss {'Reaction outcome loss': 0.3734868594441877, 'Total loss': 0.3734868594441877}
2022-12-31 13:14:40,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:40,982 INFO:     Epoch: 22
2022-12-31 13:14:42,586 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47999526262283326, 'Total loss': 0.47999526262283326} | train loss {'Reaction outcome loss': 0.37005446283590226, 'Total loss': 0.37005446283590226}
2022-12-31 13:14:42,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:42,587 INFO:     Epoch: 23
2022-12-31 13:14:44,214 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4332428435484568, 'Total loss': 0.4332428435484568} | train loss {'Reaction outcome loss': 0.3653934500538386, 'Total loss': 0.3653934500538386}
2022-12-31 13:14:44,214 INFO:     Found new best model at epoch 23
2022-12-31 13:14:44,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:44,215 INFO:     Epoch: 24
2022-12-31 13:14:45,779 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4474684476852417, 'Total loss': 0.4474684476852417} | train loss {'Reaction outcome loss': 0.36337982348742937, 'Total loss': 0.36337982348742937}
2022-12-31 13:14:45,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:45,779 INFO:     Epoch: 25
2022-12-31 13:14:47,373 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4471615682045619, 'Total loss': 0.4471615682045619} | train loss {'Reaction outcome loss': 0.35420476658535854, 'Total loss': 0.35420476658535854}
2022-12-31 13:14:47,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:47,373 INFO:     Epoch: 26
2022-12-31 13:14:48,962 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4336575776338577, 'Total loss': 0.4336575776338577} | train loss {'Reaction outcome loss': 0.34632806127699906, 'Total loss': 0.34632806127699906}
2022-12-31 13:14:48,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:48,963 INFO:     Epoch: 27
2022-12-31 13:14:50,537 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4520745555559794, 'Total loss': 0.4520745555559794} | train loss {'Reaction outcome loss': 0.3395760771392029, 'Total loss': 0.3395760771392029}
2022-12-31 13:14:50,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:50,537 INFO:     Epoch: 28
2022-12-31 13:14:52,178 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4478156288464864, 'Total loss': 0.4478156288464864} | train loss {'Reaction outcome loss': 0.3399849113472652, 'Total loss': 0.3399849113472652}
2022-12-31 13:14:52,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:52,178 INFO:     Epoch: 29
2022-12-31 13:14:53,788 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42948844730854036, 'Total loss': 0.42948844730854036} | train loss {'Reaction outcome loss': 0.3351140005766472, 'Total loss': 0.3351140005766472}
2022-12-31 13:14:53,788 INFO:     Found new best model at epoch 29
2022-12-31 13:14:53,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:53,789 INFO:     Epoch: 30
2022-12-31 13:14:55,383 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4601146936416626, 'Total loss': 0.4601146936416626} | train loss {'Reaction outcome loss': 0.3339305579553157, 'Total loss': 0.3339305579553157}
2022-12-31 13:14:55,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:55,384 INFO:     Epoch: 31
2022-12-31 13:14:56,972 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4302463094393412, 'Total loss': 0.4302463094393412} | train loss {'Reaction outcome loss': 0.32220749692452366, 'Total loss': 0.32220749692452366}
2022-12-31 13:14:56,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:56,973 INFO:     Epoch: 32
2022-12-31 13:14:58,567 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4104764168461164, 'Total loss': 0.4104764168461164} | train loss {'Reaction outcome loss': 0.32204741532931397, 'Total loss': 0.32204741532931397}
2022-12-31 13:14:58,568 INFO:     Found new best model at epoch 32
2022-12-31 13:14:58,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:14:58,568 INFO:     Epoch: 33
2022-12-31 13:15:00,143 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4193546305100123, 'Total loss': 0.4193546305100123} | train loss {'Reaction outcome loss': 0.3243473567914613, 'Total loss': 0.3243473567914613}
2022-12-31 13:15:00,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:00,143 INFO:     Epoch: 34
2022-12-31 13:15:01,733 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36910487711429596, 'Total loss': 0.36910487711429596} | train loss {'Reaction outcome loss': 0.32068447659522187, 'Total loss': 0.32068447659522187}
2022-12-31 13:15:01,733 INFO:     Found new best model at epoch 34
2022-12-31 13:15:01,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:01,734 INFO:     Epoch: 35
2022-12-31 13:15:03,334 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40028047959009805, 'Total loss': 0.40028047959009805} | train loss {'Reaction outcome loss': 0.31500637506718165, 'Total loss': 0.31500637506718165}
2022-12-31 13:15:03,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:03,334 INFO:     Epoch: 36
2022-12-31 13:15:04,913 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39227851629257204, 'Total loss': 0.39227851629257204} | train loss {'Reaction outcome loss': 0.310108032841713, 'Total loss': 0.310108032841713}
2022-12-31 13:15:04,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:04,913 INFO:     Epoch: 37
2022-12-31 13:15:06,507 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3856701791286469, 'Total loss': 0.3856701791286469} | train loss {'Reaction outcome loss': 0.308125936914058, 'Total loss': 0.308125936914058}
2022-12-31 13:15:06,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:06,507 INFO:     Epoch: 38
2022-12-31 13:15:08,095 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39553447961807253, 'Total loss': 0.39553447961807253} | train loss {'Reaction outcome loss': 0.30103175886548483, 'Total loss': 0.30103175886548483}
2022-12-31 13:15:08,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:08,095 INFO:     Epoch: 39
2022-12-31 13:15:09,672 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.389506396651268, 'Total loss': 0.389506396651268} | train loss {'Reaction outcome loss': 0.2952570457134273, 'Total loss': 0.2952570457134273}
2022-12-31 13:15:09,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:09,672 INFO:     Epoch: 40
2022-12-31 13:15:11,261 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42603313028812406, 'Total loss': 0.42603313028812406} | train loss {'Reaction outcome loss': 0.2918371590529824, 'Total loss': 0.2918371590529824}
2022-12-31 13:15:11,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:11,263 INFO:     Epoch: 41
2022-12-31 13:15:12,839 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.410187828540802, 'Total loss': 0.410187828540802} | train loss {'Reaction outcome loss': 0.293100844140782, 'Total loss': 0.293100844140782}
2022-12-31 13:15:12,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:12,839 INFO:     Epoch: 42
2022-12-31 13:15:14,436 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39578172663847605, 'Total loss': 0.39578172663847605} | train loss {'Reaction outcome loss': 0.2923878864845732, 'Total loss': 0.2923878864845732}
2022-12-31 13:15:14,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:14,436 INFO:     Epoch: 43
2022-12-31 13:15:16,024 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42431123157342276, 'Total loss': 0.42431123157342276} | train loss {'Reaction outcome loss': 0.2858429523969526, 'Total loss': 0.2858429523969526}
2022-12-31 13:15:16,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:16,024 INFO:     Epoch: 44
2022-12-31 13:15:17,598 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38360314269860585, 'Total loss': 0.38360314269860585} | train loss {'Reaction outcome loss': 0.27979509247255413, 'Total loss': 0.27979509247255413}
2022-12-31 13:15:17,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:17,599 INFO:     Epoch: 45
2022-12-31 13:15:19,174 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3873640656471252, 'Total loss': 0.3873640656471252} | train loss {'Reaction outcome loss': 0.2852866245849884, 'Total loss': 0.2852866245849884}
2022-12-31 13:15:19,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:19,174 INFO:     Epoch: 46
2022-12-31 13:15:20,784 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38150852024555204, 'Total loss': 0.38150852024555204} | train loss {'Reaction outcome loss': 0.2789111442782067, 'Total loss': 0.2789111442782067}
2022-12-31 13:15:20,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:20,784 INFO:     Epoch: 47
2022-12-31 13:15:22,371 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3760570714871089, 'Total loss': 0.3760570714871089} | train loss {'Reaction outcome loss': 0.27484671697839275, 'Total loss': 0.27484671697839275}
2022-12-31 13:15:22,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:22,371 INFO:     Epoch: 48
2022-12-31 13:15:23,997 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3954030285278956, 'Total loss': 0.3954030285278956} | train loss {'Reaction outcome loss': 0.26487821564351244, 'Total loss': 0.26487821564351244}
2022-12-31 13:15:23,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:23,998 INFO:     Epoch: 49
2022-12-31 13:15:25,627 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40405596295992535, 'Total loss': 0.40405596295992535} | train loss {'Reaction outcome loss': 0.26882733355511673, 'Total loss': 0.26882733355511673}
2022-12-31 13:15:25,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:25,627 INFO:     Epoch: 50
2022-12-31 13:15:27,222 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4337904254595439, 'Total loss': 0.4337904254595439} | train loss {'Reaction outcome loss': 0.2720028469509585, 'Total loss': 0.2720028469509585}
2022-12-31 13:15:27,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:27,222 INFO:     Epoch: 51
2022-12-31 13:15:28,815 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37823168834050497, 'Total loss': 0.37823168834050497} | train loss {'Reaction outcome loss': 0.26216379510777776, 'Total loss': 0.26216379510777776}
2022-12-31 13:15:28,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:28,815 INFO:     Epoch: 52
2022-12-31 13:15:30,410 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3577257007360458, 'Total loss': 0.3577257007360458} | train loss {'Reaction outcome loss': 0.2621311076196941, 'Total loss': 0.2621311076196941}
2022-12-31 13:15:30,411 INFO:     Found new best model at epoch 52
2022-12-31 13:15:30,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:30,412 INFO:     Epoch: 53
2022-12-31 13:15:32,015 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4196420798699061, 'Total loss': 0.4196420798699061} | train loss {'Reaction outcome loss': 0.25509567972231695, 'Total loss': 0.25509567972231695}
2022-12-31 13:15:32,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:32,015 INFO:     Epoch: 54
2022-12-31 13:15:33,624 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37828843196233114, 'Total loss': 0.37828843196233114} | train loss {'Reaction outcome loss': 0.2609955705634076, 'Total loss': 0.2609955705634076}
2022-12-31 13:15:33,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:33,624 INFO:     Epoch: 55
2022-12-31 13:15:35,236 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40200675626595817, 'Total loss': 0.40200675626595817} | train loss {'Reaction outcome loss': 0.2521874368354514, 'Total loss': 0.2521874368354514}
2022-12-31 13:15:35,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:35,236 INFO:     Epoch: 56
2022-12-31 13:15:36,836 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3710307528575261, 'Total loss': 0.3710307528575261} | train loss {'Reaction outcome loss': 0.24862721178939928, 'Total loss': 0.24862721178939928}
2022-12-31 13:15:36,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:36,837 INFO:     Epoch: 57
2022-12-31 13:15:38,441 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41025760223468144, 'Total loss': 0.41025760223468144} | train loss {'Reaction outcome loss': 0.2534262249348583, 'Total loss': 0.2534262249348583}
2022-12-31 13:15:38,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:38,442 INFO:     Epoch: 58
2022-12-31 13:15:40,021 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38817025522391, 'Total loss': 0.38817025522391} | train loss {'Reaction outcome loss': 0.2446748759365562, 'Total loss': 0.2446748759365562}
2022-12-31 13:15:40,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:40,021 INFO:     Epoch: 59
2022-12-31 13:15:41,619 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4007916967074076, 'Total loss': 0.4007916967074076} | train loss {'Reaction outcome loss': 0.2427776701707434, 'Total loss': 0.2427776701707434}
2022-12-31 13:15:41,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:41,620 INFO:     Epoch: 60
2022-12-31 13:15:43,219 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4078342517217, 'Total loss': 0.4078342517217} | train loss {'Reaction outcome loss': 0.24062865688346136, 'Total loss': 0.24062865688346136}
2022-12-31 13:15:43,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:43,219 INFO:     Epoch: 61
2022-12-31 13:15:44,799 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39062932630379993, 'Total loss': 0.39062932630379993} | train loss {'Reaction outcome loss': 0.24844522968671479, 'Total loss': 0.24844522968671479}
2022-12-31 13:15:44,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:44,800 INFO:     Epoch: 62
2022-12-31 13:15:46,418 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38901573916276294, 'Total loss': 0.38901573916276294} | train loss {'Reaction outcome loss': 0.2386280122543975, 'Total loss': 0.2386280122543975}
2022-12-31 13:15:46,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:46,419 INFO:     Epoch: 63
2022-12-31 13:15:48,007 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37160703241825105, 'Total loss': 0.37160703241825105} | train loss {'Reaction outcome loss': 0.23352973826993734, 'Total loss': 0.23352973826993734}
2022-12-31 13:15:48,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:48,008 INFO:     Epoch: 64
2022-12-31 13:15:49,608 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4236924558877945, 'Total loss': 0.4236924558877945} | train loss {'Reaction outcome loss': 0.2397640801474943, 'Total loss': 0.2397640801474943}
2022-12-31 13:15:49,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:49,608 INFO:     Epoch: 65
2022-12-31 13:15:51,247 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3815517693758011, 'Total loss': 0.3815517693758011} | train loss {'Reaction outcome loss': 0.23587332527415875, 'Total loss': 0.23587332527415875}
2022-12-31 13:15:51,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:51,247 INFO:     Epoch: 66
2022-12-31 13:15:52,908 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4192397286494573, 'Total loss': 0.4192397286494573} | train loss {'Reaction outcome loss': 0.2326816139749555, 'Total loss': 0.2326816139749555}
2022-12-31 13:15:52,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:52,908 INFO:     Epoch: 67
2022-12-31 13:15:54,516 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3961010714371999, 'Total loss': 0.3961010714371999} | train loss {'Reaction outcome loss': 0.2326770502077791, 'Total loss': 0.2326770502077791}
2022-12-31 13:15:54,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:54,516 INFO:     Epoch: 68
2022-12-31 13:15:56,115 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38469568292299905, 'Total loss': 0.38469568292299905} | train loss {'Reaction outcome loss': 0.23824465700558253, 'Total loss': 0.23824465700558253}
2022-12-31 13:15:56,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:56,115 INFO:     Epoch: 69
2022-12-31 13:15:57,693 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4025476495424906, 'Total loss': 0.4025476495424906} | train loss {'Reaction outcome loss': 0.2382397496793078, 'Total loss': 0.2382397496793078}
2022-12-31 13:15:57,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:57,694 INFO:     Epoch: 70
2022-12-31 13:15:59,319 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4203583349784215, 'Total loss': 0.4203583349784215} | train loss {'Reaction outcome loss': 0.22929041930934885, 'Total loss': 0.22929041930934885}
2022-12-31 13:15:59,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:15:59,319 INFO:     Epoch: 71
2022-12-31 13:16:00,913 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39198199808597567, 'Total loss': 0.39198199808597567} | train loss {'Reaction outcome loss': 0.2342501902686698, 'Total loss': 0.2342501902686698}
2022-12-31 13:16:00,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:00,914 INFO:     Epoch: 72
2022-12-31 13:16:02,510 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3977745215098063, 'Total loss': 0.3977745215098063} | train loss {'Reaction outcome loss': 0.23013650768542246, 'Total loss': 0.23013650768542246}
2022-12-31 13:16:02,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:02,510 INFO:     Epoch: 73
2022-12-31 13:16:04,121 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3533834298451742, 'Total loss': 0.3533834298451742} | train loss {'Reaction outcome loss': 0.2273146520767893, 'Total loss': 0.2273146520767893}
2022-12-31 13:16:04,121 INFO:     Found new best model at epoch 73
2022-12-31 13:16:04,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:04,122 INFO:     Epoch: 74
2022-12-31 13:16:05,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41519330739974974, 'Total loss': 0.41519330739974974} | train loss {'Reaction outcome loss': 0.21510842865530824, 'Total loss': 0.21510842865530824}
2022-12-31 13:16:05,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:05,717 INFO:     Epoch: 75
2022-12-31 13:16:07,314 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37338175177574157, 'Total loss': 0.37338175177574157} | train loss {'Reaction outcome loss': 0.23136684169477678, 'Total loss': 0.23136684169477678}
2022-12-31 13:16:07,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:07,314 INFO:     Epoch: 76
2022-12-31 13:16:08,931 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39827432533105217, 'Total loss': 0.39827432533105217} | train loss {'Reaction outcome loss': 0.2188957049596659, 'Total loss': 0.2188957049596659}
2022-12-31 13:16:08,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:08,932 INFO:     Epoch: 77
2022-12-31 13:16:10,554 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4089926185707251, 'Total loss': 0.4089926185707251} | train loss {'Reaction outcome loss': 0.22658401774071948, 'Total loss': 0.22658401774071948}
2022-12-31 13:16:10,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:10,554 INFO:     Epoch: 78
2022-12-31 13:16:12,132 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3646212155620257, 'Total loss': 0.3646212155620257} | train loss {'Reaction outcome loss': 0.22650172787926573, 'Total loss': 0.22650172787926573}
2022-12-31 13:16:12,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:12,133 INFO:     Epoch: 79
2022-12-31 13:16:13,730 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4206283668677012, 'Total loss': 0.4206283668677012} | train loss {'Reaction outcome loss': 0.2154791956045068, 'Total loss': 0.2154791956045068}
2022-12-31 13:16:13,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:13,730 INFO:     Epoch: 80
2022-12-31 13:16:15,305 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3812077393134435, 'Total loss': 0.3812077393134435} | train loss {'Reaction outcome loss': 0.2124504450360661, 'Total loss': 0.2124504450360661}
2022-12-31 13:16:15,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:15,305 INFO:     Epoch: 81
2022-12-31 13:16:16,922 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3694203684727351, 'Total loss': 0.3694203684727351} | train loss {'Reaction outcome loss': 0.21395271465236887, 'Total loss': 0.21395271465236887}
2022-12-31 13:16:16,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:16,923 INFO:     Epoch: 82
2022-12-31 13:16:18,530 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3782588909069697, 'Total loss': 0.3782588909069697} | train loss {'Reaction outcome loss': 0.21087253572685377, 'Total loss': 0.21087253572685377}
2022-12-31 13:16:18,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:18,531 INFO:     Epoch: 83
2022-12-31 13:16:20,134 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46212954123814903, 'Total loss': 0.46212954123814903} | train loss {'Reaction outcome loss': 0.2123858350578136, 'Total loss': 0.2123858350578136}
2022-12-31 13:16:20,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:20,134 INFO:     Epoch: 84
2022-12-31 13:16:21,732 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37222759425640106, 'Total loss': 0.37222759425640106} | train loss {'Reaction outcome loss': 0.21642892211402728, 'Total loss': 0.21642892211402728}
2022-12-31 13:16:21,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:21,732 INFO:     Epoch: 85
2022-12-31 13:16:23,353 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3842073082923889, 'Total loss': 0.3842073082923889} | train loss {'Reaction outcome loss': 0.2143639032916599, 'Total loss': 0.2143639032916599}
2022-12-31 13:16:23,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:23,354 INFO:     Epoch: 86
2022-12-31 13:16:24,938 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45077883700529736, 'Total loss': 0.45077883700529736} | train loss {'Reaction outcome loss': 0.20991125891851636, 'Total loss': 0.20991125891851636}
2022-12-31 13:16:24,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:24,938 INFO:     Epoch: 87
2022-12-31 13:16:26,531 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4103408103187879, 'Total loss': 0.4103408103187879} | train loss {'Reaction outcome loss': 0.20256381877612717, 'Total loss': 0.20256381877612717}
2022-12-31 13:16:26,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:26,531 INFO:     Epoch: 88
2022-12-31 13:16:28,136 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41147485276063284, 'Total loss': 0.41147485276063284} | train loss {'Reaction outcome loss': 0.2090623540865196, 'Total loss': 0.2090623540865196}
2022-12-31 13:16:28,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:28,136 INFO:     Epoch: 89
2022-12-31 13:16:29,729 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3947177842259407, 'Total loss': 0.3947177842259407} | train loss {'Reaction outcome loss': 0.21221585028323825, 'Total loss': 0.21221585028323825}
2022-12-31 13:16:29,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:29,729 INFO:     Epoch: 90
2022-12-31 13:16:31,308 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3918171803156535, 'Total loss': 0.3918171803156535} | train loss {'Reaction outcome loss': 0.20753090020146345, 'Total loss': 0.20753090020146345}
2022-12-31 13:16:31,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:31,309 INFO:     Epoch: 91
2022-12-31 13:16:32,902 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40276684363683063, 'Total loss': 0.40276684363683063} | train loss {'Reaction outcome loss': 0.20427793515470874, 'Total loss': 0.20427793515470874}
2022-12-31 13:16:32,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:32,902 INFO:     Epoch: 92
2022-12-31 13:16:34,482 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3716027873257796, 'Total loss': 0.3716027873257796} | train loss {'Reaction outcome loss': 0.20583290872829302, 'Total loss': 0.20583290872829302}
2022-12-31 13:16:34,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:34,482 INFO:     Epoch: 93
2022-12-31 13:16:36,075 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4224163214365641, 'Total loss': 0.4224163214365641} | train loss {'Reaction outcome loss': 0.2029110205670198, 'Total loss': 0.2029110205670198}
2022-12-31 13:16:36,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:36,075 INFO:     Epoch: 94
2022-12-31 13:16:37,668 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4007170816262563, 'Total loss': 0.4007170816262563} | train loss {'Reaction outcome loss': 0.20457771371354114, 'Total loss': 0.20457771371354114}
2022-12-31 13:16:37,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:37,669 INFO:     Epoch: 95
2022-12-31 13:16:39,243 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39472597440083823, 'Total loss': 0.39472597440083823} | train loss {'Reaction outcome loss': 0.19417193542906652, 'Total loss': 0.19417193542906652}
2022-12-31 13:16:39,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:39,244 INFO:     Epoch: 96
2022-12-31 13:16:40,837 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36428849945465724, 'Total loss': 0.36428849945465724} | train loss {'Reaction outcome loss': 0.19701399175184114, 'Total loss': 0.19701399175184114}
2022-12-31 13:16:40,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:40,837 INFO:     Epoch: 97
2022-12-31 13:16:42,416 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38831440210342405, 'Total loss': 0.38831440210342405} | train loss {'Reaction outcome loss': 0.19713558691925617, 'Total loss': 0.19713558691925617}
2022-12-31 13:16:42,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:42,416 INFO:     Epoch: 98
2022-12-31 13:16:44,033 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.426239550113678, 'Total loss': 0.426239550113678} | train loss {'Reaction outcome loss': 0.1856540437692251, 'Total loss': 0.1856540437692251}
2022-12-31 13:16:44,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:44,033 INFO:     Epoch: 99
2022-12-31 13:16:45,627 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39738808472951254, 'Total loss': 0.39738808472951254} | train loss {'Reaction outcome loss': 0.19843600960891872, 'Total loss': 0.19843600960891872}
2022-12-31 13:16:45,627 INFO:     Best model found after epoch 74 of 100.
2022-12-31 13:16:45,627 INFO:   Done with stage: TRAINING
2022-12-31 13:16:45,627 INFO:   Starting stage: EVALUATION
2022-12-31 13:16:45,768 INFO:   Done with stage: EVALUATION
2022-12-31 13:16:45,768 INFO:   Leaving out SEQ value Fold_4
2022-12-31 13:16:45,781 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:16:45,781 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:16:46,432 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:16:46,432 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:16:46,500 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:16:46,500 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:16:46,500 INFO:     No hyperparam tuning for this model
2022-12-31 13:16:46,500 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:16:46,500 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:16:46,501 INFO:     None feature selector for col prot
2022-12-31 13:16:46,501 INFO:     None feature selector for col prot
2022-12-31 13:16:46,501 INFO:     None feature selector for col prot
2022-12-31 13:16:46,502 INFO:     None feature selector for col chem
2022-12-31 13:16:46,502 INFO:     None feature selector for col chem
2022-12-31 13:16:46,502 INFO:     None feature selector for col chem
2022-12-31 13:16:46,502 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:16:46,502 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:16:46,504 INFO:     Number of params in model 223921
2022-12-31 13:16:46,507 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:16:46,507 INFO:   Starting stage: TRAINING
2022-12-31 13:16:46,554 INFO:     Val loss before train {'Reaction outcome loss': 1.0580651839574178, 'Total loss': 1.0580651839574178}
2022-12-31 13:16:46,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:46,554 INFO:     Epoch: 0
2022-12-31 13:16:48,144 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7429330209891002, 'Total loss': 0.7429330209891002} | train loss {'Reaction outcome loss': 0.8228189321909694, 'Total loss': 0.8228189321909694}
2022-12-31 13:16:48,145 INFO:     Found new best model at epoch 0
2022-12-31 13:16:48,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:48,146 INFO:     Epoch: 1
2022-12-31 13:16:49,802 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5741344889005026, 'Total loss': 0.5741344889005026} | train loss {'Reaction outcome loss': 0.6001519877165686, 'Total loss': 0.6001519877165686}
2022-12-31 13:16:49,803 INFO:     Found new best model at epoch 1
2022-12-31 13:16:49,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:49,803 INFO:     Epoch: 2
2022-12-31 13:16:51,410 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5877820452054342, 'Total loss': 0.5877820452054342} | train loss {'Reaction outcome loss': 0.5370066926099252, 'Total loss': 0.5370066926099252}
2022-12-31 13:16:51,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:51,410 INFO:     Epoch: 3
2022-12-31 13:16:53,036 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5298103451728821, 'Total loss': 0.5298103451728821} | train loss {'Reaction outcome loss': 0.5209608373934053, 'Total loss': 0.5209608373934053}
2022-12-31 13:16:53,036 INFO:     Found new best model at epoch 3
2022-12-31 13:16:53,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:53,037 INFO:     Epoch: 4
2022-12-31 13:16:54,662 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5006769398848215, 'Total loss': 0.5006769398848215} | train loss {'Reaction outcome loss': 0.4864965265724754, 'Total loss': 0.4864965265724754}
2022-12-31 13:16:54,663 INFO:     Found new best model at epoch 4
2022-12-31 13:16:54,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:54,664 INFO:     Epoch: 5
2022-12-31 13:16:56,275 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5216723342736562, 'Total loss': 0.5216723342736562} | train loss {'Reaction outcome loss': 0.480751222944346, 'Total loss': 0.480751222944346}
2022-12-31 13:16:56,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:56,275 INFO:     Epoch: 6
2022-12-31 13:16:57,877 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5197058210770289, 'Total loss': 0.5197058210770289} | train loss {'Reaction outcome loss': 0.49311904522819794, 'Total loss': 0.49311904522819794}
2022-12-31 13:16:57,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:57,878 INFO:     Epoch: 7
2022-12-31 13:16:59,491 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49853474100430806, 'Total loss': 0.49853474100430806} | train loss {'Reaction outcome loss': 0.47171480948952155, 'Total loss': 0.47171480948952155}
2022-12-31 13:16:59,491 INFO:     Found new best model at epoch 7
2022-12-31 13:16:59,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:16:59,492 INFO:     Epoch: 8
2022-12-31 13:17:01,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4667743066946665, 'Total loss': 0.4667743066946665} | train loss {'Reaction outcome loss': 0.46117496188136115, 'Total loss': 0.46117496188136115}
2022-12-31 13:17:01,104 INFO:     Found new best model at epoch 8
2022-12-31 13:17:01,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:01,105 INFO:     Epoch: 9
2022-12-31 13:17:02,757 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5121839861075084, 'Total loss': 0.5121839861075084} | train loss {'Reaction outcome loss': 0.460545028951289, 'Total loss': 0.460545028951289}
2022-12-31 13:17:02,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:02,757 INFO:     Epoch: 10
2022-12-31 13:17:04,384 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4540612757205963, 'Total loss': 0.4540612757205963} | train loss {'Reaction outcome loss': 0.44818609173450136, 'Total loss': 0.44818609173450136}
2022-12-31 13:17:04,384 INFO:     Found new best model at epoch 10
2022-12-31 13:17:04,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:04,385 INFO:     Epoch: 11
2022-12-31 13:17:05,992 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4577139606078466, 'Total loss': 0.4577139606078466} | train loss {'Reaction outcome loss': 0.4422214516169175, 'Total loss': 0.4422214516169175}
2022-12-31 13:17:05,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:05,992 INFO:     Epoch: 12
2022-12-31 13:17:07,598 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43625704646110536, 'Total loss': 0.43625704646110536} | train loss {'Reaction outcome loss': 0.4361527596694836, 'Total loss': 0.4361527596694836}
2022-12-31 13:17:07,599 INFO:     Found new best model at epoch 12
2022-12-31 13:17:07,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:07,600 INFO:     Epoch: 13
2022-12-31 13:17:09,207 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4197639351089795, 'Total loss': 0.4197639351089795} | train loss {'Reaction outcome loss': 0.4390112775887457, 'Total loss': 0.4390112775887457}
2022-12-31 13:17:09,207 INFO:     Found new best model at epoch 13
2022-12-31 13:17:09,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:09,208 INFO:     Epoch: 14
2022-12-31 13:17:10,819 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4349908212820689, 'Total loss': 0.4349908212820689} | train loss {'Reaction outcome loss': 0.4206213613797445, 'Total loss': 0.4206213613797445}
2022-12-31 13:17:10,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:10,819 INFO:     Epoch: 15
2022-12-31 13:17:12,434 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44987466633319856, 'Total loss': 0.44987466633319856} | train loss {'Reaction outcome loss': 0.41498042190906365, 'Total loss': 0.41498042190906365}
2022-12-31 13:17:12,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:12,434 INFO:     Epoch: 16
2022-12-31 13:17:14,051 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4720940281947454, 'Total loss': 0.4720940281947454} | train loss {'Reaction outcome loss': 0.412578747243337, 'Total loss': 0.412578747243337}
2022-12-31 13:17:14,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:14,051 INFO:     Epoch: 17
2022-12-31 13:17:15,659 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44983354409535725, 'Total loss': 0.44983354409535725} | train loss {'Reaction outcome loss': 0.4429524105609111, 'Total loss': 0.4429524105609111}
2022-12-31 13:17:15,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:15,660 INFO:     Epoch: 18
2022-12-31 13:17:17,275 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4419655154148738, 'Total loss': 0.4419655154148738} | train loss {'Reaction outcome loss': 0.40094595203392097, 'Total loss': 0.40094595203392097}
2022-12-31 13:17:17,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:17,275 INFO:     Epoch: 19
2022-12-31 13:17:18,877 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4287244349718094, 'Total loss': 0.4287244349718094} | train loss {'Reaction outcome loss': 0.3955891858043986, 'Total loss': 0.3955891858043986}
2022-12-31 13:17:18,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:18,878 INFO:     Epoch: 20
2022-12-31 13:17:20,490 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4170904040336609, 'Total loss': 0.4170904040336609} | train loss {'Reaction outcome loss': 0.3867871398916063, 'Total loss': 0.3867871398916063}
2022-12-31 13:17:20,490 INFO:     Found new best model at epoch 20
2022-12-31 13:17:20,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:20,491 INFO:     Epoch: 21
2022-12-31 13:17:22,114 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40968910058339436, 'Total loss': 0.40968910058339436} | train loss {'Reaction outcome loss': 0.3841495458812763, 'Total loss': 0.3841495458812763}
2022-12-31 13:17:22,115 INFO:     Found new best model at epoch 21
2022-12-31 13:17:22,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:22,115 INFO:     Epoch: 22
2022-12-31 13:17:23,730 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4036782180269559, 'Total loss': 0.4036782180269559} | train loss {'Reaction outcome loss': 0.3928057996529168, 'Total loss': 0.3928057996529168}
2022-12-31 13:17:23,730 INFO:     Found new best model at epoch 22
2022-12-31 13:17:23,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:23,731 INFO:     Epoch: 23
2022-12-31 13:17:25,326 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4092733383178711, 'Total loss': 0.4092733383178711} | train loss {'Reaction outcome loss': 0.3853969223513875, 'Total loss': 0.3853969223513875}
2022-12-31 13:17:25,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:25,327 INFO:     Epoch: 24
2022-12-31 13:17:26,942 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39529303908348085, 'Total loss': 0.39529303908348085} | train loss {'Reaction outcome loss': 0.36841876432299614, 'Total loss': 0.36841876432299614}
2022-12-31 13:17:26,942 INFO:     Found new best model at epoch 24
2022-12-31 13:17:26,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:26,943 INFO:     Epoch: 25
2022-12-31 13:17:28,543 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3916467875242233, 'Total loss': 0.3916467875242233} | train loss {'Reaction outcome loss': 0.3581858596670023, 'Total loss': 0.3581858596670023}
2022-12-31 13:17:28,543 INFO:     Found new best model at epoch 25
2022-12-31 13:17:28,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:28,544 INFO:     Epoch: 26
2022-12-31 13:17:30,195 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3802756970127424, 'Total loss': 0.3802756970127424} | train loss {'Reaction outcome loss': 0.3599208160948879, 'Total loss': 0.3599208160948879}
2022-12-31 13:17:30,196 INFO:     Found new best model at epoch 26
2022-12-31 13:17:30,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:30,197 INFO:     Epoch: 27
2022-12-31 13:17:31,836 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3615146497885386, 'Total loss': 0.3615146497885386} | train loss {'Reaction outcome loss': 0.3641947995385398, 'Total loss': 0.3641947995385398}
2022-12-31 13:17:31,836 INFO:     Found new best model at epoch 27
2022-12-31 13:17:31,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:31,837 INFO:     Epoch: 28
2022-12-31 13:17:33,459 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.420689191420873, 'Total loss': 0.420689191420873} | train loss {'Reaction outcome loss': 0.44444820987384603, 'Total loss': 0.44444820987384603}
2022-12-31 13:17:33,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:33,459 INFO:     Epoch: 29
2022-12-31 13:17:35,061 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3850356419881185, 'Total loss': 0.3850356419881185} | train loss {'Reaction outcome loss': 0.3656316178421021, 'Total loss': 0.3656316178421021}
2022-12-31 13:17:35,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:35,062 INFO:     Epoch: 30
2022-12-31 13:17:36,657 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3907408555348714, 'Total loss': 0.3907408555348714} | train loss {'Reaction outcome loss': 0.35074996178888757, 'Total loss': 0.35074996178888757}
2022-12-31 13:17:36,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:36,657 INFO:     Epoch: 31
2022-12-31 13:17:38,319 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3709010531504949, 'Total loss': 0.3709010531504949} | train loss {'Reaction outcome loss': 0.34731024589753995, 'Total loss': 0.34731024589753995}
2022-12-31 13:17:38,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:38,320 INFO:     Epoch: 32
2022-12-31 13:17:39,950 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3980527758598328, 'Total loss': 0.3980527758598328} | train loss {'Reaction outcome loss': 0.34143394322229037, 'Total loss': 0.34143394322229037}
2022-12-31 13:17:39,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:39,950 INFO:     Epoch: 33
2022-12-31 13:17:41,613 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3685345768928528, 'Total loss': 0.3685345768928528} | train loss {'Reaction outcome loss': 0.33340704946211824, 'Total loss': 0.33340704946211824}
2022-12-31 13:17:41,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:41,613 INFO:     Epoch: 34
2022-12-31 13:17:43,255 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35123597731192907, 'Total loss': 0.35123597731192907} | train loss {'Reaction outcome loss': 0.32766048085244803, 'Total loss': 0.32766048085244803}
2022-12-31 13:17:43,255 INFO:     Found new best model at epoch 34
2022-12-31 13:17:43,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:43,257 INFO:     Epoch: 35
2022-12-31 13:17:44,924 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3761273354291916, 'Total loss': 0.3761273354291916} | train loss {'Reaction outcome loss': 0.3220979581060617, 'Total loss': 0.3220979581060617}
2022-12-31 13:17:44,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:44,925 INFO:     Epoch: 36
2022-12-31 13:17:46,574 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36350134561459224, 'Total loss': 0.36350134561459224} | train loss {'Reaction outcome loss': 0.3227013206112324, 'Total loss': 0.3227013206112324}
2022-12-31 13:17:46,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:46,574 INFO:     Epoch: 37
2022-12-31 13:17:48,246 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38626292645931243, 'Total loss': 0.38626292645931243} | train loss {'Reaction outcome loss': 0.3135077391677303, 'Total loss': 0.3135077391677303}
2022-12-31 13:17:48,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:48,246 INFO:     Epoch: 38
2022-12-31 13:17:49,911 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36888109644254047, 'Total loss': 0.36888109644254047} | train loss {'Reaction outcome loss': 0.30646492316188506, 'Total loss': 0.30646492316188506}
2022-12-31 13:17:49,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:49,911 INFO:     Epoch: 39
2022-12-31 13:17:51,572 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38225568731625875, 'Total loss': 0.38225568731625875} | train loss {'Reaction outcome loss': 0.3124273442055868, 'Total loss': 0.3124273442055868}
2022-12-31 13:17:51,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:51,572 INFO:     Epoch: 40
2022-12-31 13:17:53,218 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3826152374347051, 'Total loss': 0.3826152374347051} | train loss {'Reaction outcome loss': 0.31714201253582386, 'Total loss': 0.31714201253582386}
2022-12-31 13:17:53,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:53,218 INFO:     Epoch: 41
2022-12-31 13:17:54,888 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3653888483842214, 'Total loss': 0.3653888483842214} | train loss {'Reaction outcome loss': 0.3056236528666003, 'Total loss': 0.3056236528666003}
2022-12-31 13:17:54,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:54,890 INFO:     Epoch: 42
2022-12-31 13:17:56,535 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3535362645983696, 'Total loss': 0.3535362645983696} | train loss {'Reaction outcome loss': 0.294678354629086, 'Total loss': 0.294678354629086}
2022-12-31 13:17:56,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:56,535 INFO:     Epoch: 43
2022-12-31 13:17:58,158 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3843489001194636, 'Total loss': 0.3843489001194636} | train loss {'Reaction outcome loss': 0.2929841968335508, 'Total loss': 0.2929841968335508}
2022-12-31 13:17:58,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:58,158 INFO:     Epoch: 44
2022-12-31 13:17:59,767 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3972246915102005, 'Total loss': 0.3972246915102005} | train loss {'Reaction outcome loss': 0.29254532199137023, 'Total loss': 0.29254532199137023}
2022-12-31 13:17:59,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:17:59,767 INFO:     Epoch: 45
2022-12-31 13:18:01,355 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4254424204428991, 'Total loss': 0.4254424204428991} | train loss {'Reaction outcome loss': 0.3597640472471012, 'Total loss': 0.3597640472471012}
2022-12-31 13:18:01,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:01,355 INFO:     Epoch: 46
2022-12-31 13:18:02,961 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3642025242249171, 'Total loss': 0.3642025242249171} | train loss {'Reaction outcome loss': 0.30488821364048385, 'Total loss': 0.30488821364048385}
2022-12-31 13:18:02,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:02,962 INFO:     Epoch: 47
2022-12-31 13:18:04,578 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38640087445576987, 'Total loss': 0.38640087445576987} | train loss {'Reaction outcome loss': 0.2841404724339541, 'Total loss': 0.2841404724339541}
2022-12-31 13:18:04,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:04,578 INFO:     Epoch: 48
2022-12-31 13:18:06,185 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37085306147734326, 'Total loss': 0.37085306147734326} | train loss {'Reaction outcome loss': 0.2806889313961501, 'Total loss': 0.2806889313961501}
2022-12-31 13:18:06,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:06,185 INFO:     Epoch: 49
2022-12-31 13:18:07,791 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36689953903357186, 'Total loss': 0.36689953903357186} | train loss {'Reaction outcome loss': 0.2840891964185795, 'Total loss': 0.2840891964185795}
2022-12-31 13:18:07,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:07,791 INFO:     Epoch: 50
2022-12-31 13:18:09,399 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37870670755704244, 'Total loss': 0.37870670755704244} | train loss {'Reaction outcome loss': 0.27592205243221857, 'Total loss': 0.27592205243221857}
2022-12-31 13:18:09,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:09,399 INFO:     Epoch: 51
2022-12-31 13:18:11,005 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3857912460962931, 'Total loss': 0.3857912460962931} | train loss {'Reaction outcome loss': 0.2754617292175417, 'Total loss': 0.2754617292175417}
2022-12-31 13:18:11,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:11,005 INFO:     Epoch: 52
2022-12-31 13:18:12,612 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3598674476146698, 'Total loss': 0.3598674476146698} | train loss {'Reaction outcome loss': 0.27556182865890255, 'Total loss': 0.27556182865890255}
2022-12-31 13:18:12,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:12,612 INFO:     Epoch: 53
2022-12-31 13:18:14,202 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3647611605624358, 'Total loss': 0.3647611605624358} | train loss {'Reaction outcome loss': 0.26675742948292824, 'Total loss': 0.26675742948292824}
2022-12-31 13:18:14,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:14,203 INFO:     Epoch: 54
2022-12-31 13:18:15,809 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37532661606868106, 'Total loss': 0.37532661606868106} | train loss {'Reaction outcome loss': 0.2628846968071994, 'Total loss': 0.2628846968071994}
2022-12-31 13:18:15,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:15,810 INFO:     Epoch: 55
2022-12-31 13:18:17,418 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38034449418385824, 'Total loss': 0.38034449418385824} | train loss {'Reaction outcome loss': 0.2660207146157821, 'Total loss': 0.2660207146157821}
2022-12-31 13:18:17,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:17,418 INFO:     Epoch: 56
2022-12-31 13:18:19,010 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38844533562660216, 'Total loss': 0.38844533562660216} | train loss {'Reaction outcome loss': 0.27182928327659983, 'Total loss': 0.27182928327659983}
2022-12-31 13:18:19,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:19,010 INFO:     Epoch: 57
2022-12-31 13:18:20,610 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36826614538828534, 'Total loss': 0.36826614538828534} | train loss {'Reaction outcome loss': 0.2608336973960673, 'Total loss': 0.2608336973960673}
2022-12-31 13:18:20,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:20,611 INFO:     Epoch: 58
2022-12-31 13:18:22,207 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41452071567376453, 'Total loss': 0.41452071567376453} | train loss {'Reaction outcome loss': 0.28073231739572424, 'Total loss': 0.28073231739572424}
2022-12-31 13:18:22,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:22,207 INFO:     Epoch: 59
2022-12-31 13:18:23,815 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40801018675168355, 'Total loss': 0.40801018675168355} | train loss {'Reaction outcome loss': 0.34814943765757006, 'Total loss': 0.34814943765757006}
2022-12-31 13:18:23,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:23,815 INFO:     Epoch: 60
2022-12-31 13:18:25,425 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4038471708695094, 'Total loss': 0.4038471708695094} | train loss {'Reaction outcome loss': 0.2863618842110146, 'Total loss': 0.2863618842110146}
2022-12-31 13:18:25,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:25,426 INFO:     Epoch: 61
2022-12-31 13:18:27,034 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39230519384145734, 'Total loss': 0.39230519384145734} | train loss {'Reaction outcome loss': 0.2852920525491346, 'Total loss': 0.2852920525491346}
2022-12-31 13:18:27,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:27,035 INFO:     Epoch: 62
2022-12-31 13:18:28,634 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42918668588002523, 'Total loss': 0.42918668588002523} | train loss {'Reaction outcome loss': 0.3044796004527387, 'Total loss': 0.3044796004527387}
2022-12-31 13:18:28,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:28,634 INFO:     Epoch: 63
2022-12-31 13:18:30,246 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3726446290810903, 'Total loss': 0.3726446290810903} | train loss {'Reaction outcome loss': 0.28105254590079404, 'Total loss': 0.28105254590079404}
2022-12-31 13:18:30,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:30,246 INFO:     Epoch: 64
2022-12-31 13:18:31,849 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3973592345913251, 'Total loss': 0.3973592345913251} | train loss {'Reaction outcome loss': 0.28041063531207433, 'Total loss': 0.28041063531207433}
2022-12-31 13:18:31,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:31,850 INFO:     Epoch: 65
2022-12-31 13:18:33,459 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43202784756819407, 'Total loss': 0.43202784756819407} | train loss {'Reaction outcome loss': 0.2611685803403025, 'Total loss': 0.2611685803403025}
2022-12-31 13:18:33,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:33,459 INFO:     Epoch: 66
2022-12-31 13:18:35,068 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39786730309327445, 'Total loss': 0.39786730309327445} | train loss {'Reaction outcome loss': 0.2809178145611625, 'Total loss': 0.2809178145611625}
2022-12-31 13:18:35,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:35,068 INFO:     Epoch: 67
2022-12-31 13:18:36,678 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38094983299573265, 'Total loss': 0.38094983299573265} | train loss {'Reaction outcome loss': 0.26399387672975444, 'Total loss': 0.26399387672975444}
2022-12-31 13:18:36,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:36,678 INFO:     Epoch: 68
2022-12-31 13:18:38,274 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3613404353459676, 'Total loss': 0.3613404353459676} | train loss {'Reaction outcome loss': 0.25192371490186855, 'Total loss': 0.25192371490186855}
2022-12-31 13:18:38,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:38,275 INFO:     Epoch: 69
2022-12-31 13:18:39,871 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3930594911177953, 'Total loss': 0.3930594911177953} | train loss {'Reaction outcome loss': 0.24922897389995446, 'Total loss': 0.24922897389995446}
2022-12-31 13:18:39,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:39,871 INFO:     Epoch: 70
2022-12-31 13:18:41,495 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.35169275142252443, 'Total loss': 0.35169275142252443} | train loss {'Reaction outcome loss': 0.2527795123734403, 'Total loss': 0.2527795123734403}
2022-12-31 13:18:41,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:41,496 INFO:     Epoch: 71
2022-12-31 13:18:43,134 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3705204166471958, 'Total loss': 0.3705204166471958} | train loss {'Reaction outcome loss': 0.25018761745667545, 'Total loss': 0.25018761745667545}
2022-12-31 13:18:43,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:43,134 INFO:     Epoch: 72
2022-12-31 13:18:44,749 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4592807451883952, 'Total loss': 0.4592807451883952} | train loss {'Reaction outcome loss': 0.2419693040513042, 'Total loss': 0.2419693040513042}
2022-12-31 13:18:44,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:44,750 INFO:     Epoch: 73
2022-12-31 13:18:46,336 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41417496701081596, 'Total loss': 0.41417496701081596} | train loss {'Reaction outcome loss': 0.31816271761435005, 'Total loss': 0.31816271761435005}
2022-12-31 13:18:46,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:46,337 INFO:     Epoch: 74
2022-12-31 13:18:47,984 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40517290234565734, 'Total loss': 0.40517290234565734} | train loss {'Reaction outcome loss': 0.25933808117265755, 'Total loss': 0.25933808117265755}
2022-12-31 13:18:47,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:47,985 INFO:     Epoch: 75
2022-12-31 13:18:49,578 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41172699828942616, 'Total loss': 0.41172699828942616} | train loss {'Reaction outcome loss': 0.2552744733993018, 'Total loss': 0.2552744733993018}
2022-12-31 13:18:49,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:49,578 INFO:     Epoch: 76
2022-12-31 13:18:51,187 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4223639110724131, 'Total loss': 0.4223639110724131} | train loss {'Reaction outcome loss': 0.24078886870942687, 'Total loss': 0.24078886870942687}
2022-12-31 13:18:51,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:51,188 INFO:     Epoch: 77
2022-12-31 13:18:52,798 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38981976409753166, 'Total loss': 0.38981976409753166} | train loss {'Reaction outcome loss': 0.24704349674351944, 'Total loss': 0.24704349674351944}
2022-12-31 13:18:52,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:52,798 INFO:     Epoch: 78
2022-12-31 13:18:54,405 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41543615063031514, 'Total loss': 0.41543615063031514} | train loss {'Reaction outcome loss': 0.23562096085083464, 'Total loss': 0.23562096085083464}
2022-12-31 13:18:54,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:54,406 INFO:     Epoch: 79
2022-12-31 13:18:56,016 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3565877283612887, 'Total loss': 0.3565877283612887} | train loss {'Reaction outcome loss': 0.23589800355240595, 'Total loss': 0.23589800355240595}
2022-12-31 13:18:56,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:56,017 INFO:     Epoch: 80
2022-12-31 13:18:57,652 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3930044521888097, 'Total loss': 0.3930044521888097} | train loss {'Reaction outcome loss': 0.22982483086567643, 'Total loss': 0.22982483086567643}
2022-12-31 13:18:57,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:57,652 INFO:     Epoch: 81
2022-12-31 13:18:59,239 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3726944496234258, 'Total loss': 0.3726944496234258} | train loss {'Reaction outcome loss': 0.23845057901453928, 'Total loss': 0.23845057901453928}
2022-12-31 13:18:59,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:18:59,240 INFO:     Epoch: 82
2022-12-31 13:19:00,846 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3842048853635788, 'Total loss': 0.3842048853635788} | train loss {'Reaction outcome loss': 0.23057356728089, 'Total loss': 0.23057356728089}
2022-12-31 13:19:00,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:00,847 INFO:     Epoch: 83
2022-12-31 13:19:02,453 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38007818708817165, 'Total loss': 0.38007818708817165} | train loss {'Reaction outcome loss': 0.2309275121981467, 'Total loss': 0.2309275121981467}
2022-12-31 13:19:02,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:02,454 INFO:     Epoch: 84
2022-12-31 13:19:04,081 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4088203936815262, 'Total loss': 0.4088203936815262} | train loss {'Reaction outcome loss': 0.23829385909976222, 'Total loss': 0.23829385909976222}
2022-12-31 13:19:04,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:04,081 INFO:     Epoch: 85
2022-12-31 13:19:05,685 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3842015286286672, 'Total loss': 0.3842015286286672} | train loss {'Reaction outcome loss': 0.2234932770853988, 'Total loss': 0.2234932770853988}
2022-12-31 13:19:05,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:05,685 INFO:     Epoch: 86
2022-12-31 13:19:07,279 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43144071822365127, 'Total loss': 0.43144071822365127} | train loss {'Reaction outcome loss': 0.2264281746904379, 'Total loss': 0.2264281746904379}
2022-12-31 13:19:07,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:07,279 INFO:     Epoch: 87
2022-12-31 13:19:08,892 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3947677552700043, 'Total loss': 0.3947677552700043} | train loss {'Reaction outcome loss': 0.2794354091924818, 'Total loss': 0.2794354091924818}
2022-12-31 13:19:08,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:08,893 INFO:     Epoch: 88
2022-12-31 13:19:10,504 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40037456651528675, 'Total loss': 0.40037456651528675} | train loss {'Reaction outcome loss': 0.2544403481904579, 'Total loss': 0.2544403481904579}
2022-12-31 13:19:10,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:10,504 INFO:     Epoch: 89
2022-12-31 13:19:12,156 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36910365223884584, 'Total loss': 0.36910365223884584} | train loss {'Reaction outcome loss': 0.2656648093227135, 'Total loss': 0.2656648093227135}
2022-12-31 13:19:12,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:12,157 INFO:     Epoch: 90
2022-12-31 13:19:13,778 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36051607728004453, 'Total loss': 0.36051607728004453} | train loss {'Reaction outcome loss': 0.2414965095349412, 'Total loss': 0.2414965095349412}
2022-12-31 13:19:13,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:13,779 INFO:     Epoch: 91
2022-12-31 13:19:15,429 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39071430067221324, 'Total loss': 0.39071430067221324} | train loss {'Reaction outcome loss': 0.22856786472898355, 'Total loss': 0.22856786472898355}
2022-12-31 13:19:15,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:15,429 INFO:     Epoch: 92
2022-12-31 13:19:17,053 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4043189639846484, 'Total loss': 0.4043189639846484} | train loss {'Reaction outcome loss': 0.22691036418088345, 'Total loss': 0.22691036418088345}
2022-12-31 13:19:17,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:17,054 INFO:     Epoch: 93
2022-12-31 13:19:18,666 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4041344573100408, 'Total loss': 0.4041344573100408} | train loss {'Reaction outcome loss': 0.21704782129002168, 'Total loss': 0.21704782129002168}
2022-12-31 13:19:18,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:18,666 INFO:     Epoch: 94
2022-12-31 13:19:20,278 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38821127712726594, 'Total loss': 0.38821127712726594} | train loss {'Reaction outcome loss': 0.21619372707420448, 'Total loss': 0.21619372707420448}
2022-12-31 13:19:20,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:20,278 INFO:     Epoch: 95
2022-12-31 13:19:21,890 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40175487796465553, 'Total loss': 0.40175487796465553} | train loss {'Reaction outcome loss': 0.22280948485274785, 'Total loss': 0.22280948485274785}
2022-12-31 13:19:21,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:21,891 INFO:     Epoch: 96
2022-12-31 13:19:23,512 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3780483682950338, 'Total loss': 0.3780483682950338} | train loss {'Reaction outcome loss': 0.21874844672688135, 'Total loss': 0.21874844672688135}
2022-12-31 13:19:23,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:23,512 INFO:     Epoch: 97
2022-12-31 13:19:25,155 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38674550255139667, 'Total loss': 0.38674550255139667} | train loss {'Reaction outcome loss': 0.21302993351802824, 'Total loss': 0.21302993351802824}
2022-12-31 13:19:25,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:25,155 INFO:     Epoch: 98
2022-12-31 13:19:26,760 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4329271256923676, 'Total loss': 0.4329271256923676} | train loss {'Reaction outcome loss': 0.21122008248610233, 'Total loss': 0.21122008248610233}
2022-12-31 13:19:26,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:26,760 INFO:     Epoch: 99
2022-12-31 13:19:28,373 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41203295389811195, 'Total loss': 0.41203295389811195} | train loss {'Reaction outcome loss': 0.2146433928468521, 'Total loss': 0.2146433928468521}
2022-12-31 13:19:28,373 INFO:     Best model found after epoch 35 of 100.
2022-12-31 13:19:28,373 INFO:   Done with stage: TRAINING
2022-12-31 13:19:28,373 INFO:   Starting stage: EVALUATION
2022-12-31 13:19:28,502 INFO:   Done with stage: EVALUATION
2022-12-31 13:19:28,502 INFO:   Leaving out SEQ value Fold_5
2022-12-31 13:19:28,514 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:19:28,514 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:19:29,158 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:19:29,158 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:19:29,226 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:19:29,227 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:19:29,227 INFO:     No hyperparam tuning for this model
2022-12-31 13:19:29,227 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:19:29,227 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:19:29,227 INFO:     None feature selector for col prot
2022-12-31 13:19:29,228 INFO:     None feature selector for col prot
2022-12-31 13:19:29,228 INFO:     None feature selector for col prot
2022-12-31 13:19:29,228 INFO:     None feature selector for col chem
2022-12-31 13:19:29,228 INFO:     None feature selector for col chem
2022-12-31 13:19:29,228 INFO:     None feature selector for col chem
2022-12-31 13:19:29,228 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:19:29,229 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:19:29,230 INFO:     Number of params in model 223921
2022-12-31 13:19:29,234 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:19:29,234 INFO:   Starting stage: TRAINING
2022-12-31 13:19:29,279 INFO:     Val loss before train {'Reaction outcome loss': 1.0608286023139955, 'Total loss': 1.0608286023139955}
2022-12-31 13:19:29,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:29,280 INFO:     Epoch: 0
2022-12-31 13:19:30,891 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6841597417990367, 'Total loss': 0.6841597417990367} | train loss {'Reaction outcome loss': 0.8201970979571342, 'Total loss': 0.8201970979571342}
2022-12-31 13:19:30,891 INFO:     Found new best model at epoch 0
2022-12-31 13:19:30,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:30,892 INFO:     Epoch: 1
2022-12-31 13:19:32,486 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4698947638273239, 'Total loss': 0.4698947638273239} | train loss {'Reaction outcome loss': 0.6085137898993233, 'Total loss': 0.6085137898993233}
2022-12-31 13:19:32,486 INFO:     Found new best model at epoch 1
2022-12-31 13:19:32,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:32,487 INFO:     Epoch: 2
2022-12-31 13:19:34,087 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5109718372424443, 'Total loss': 0.5109718372424443} | train loss {'Reaction outcome loss': 0.5342099884241496, 'Total loss': 0.5342099884241496}
2022-12-31 13:19:34,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:34,087 INFO:     Epoch: 3
2022-12-31 13:19:35,699 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46433075368404386, 'Total loss': 0.46433075368404386} | train loss {'Reaction outcome loss': 0.5012172648554121, 'Total loss': 0.5012172648554121}
2022-12-31 13:19:35,699 INFO:     Found new best model at epoch 3
2022-12-31 13:19:35,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:35,700 INFO:     Epoch: 4
2022-12-31 13:19:37,331 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4331238687038422, 'Total loss': 0.4331238687038422} | train loss {'Reaction outcome loss': 0.4874678631484499, 'Total loss': 0.4874678631484499}
2022-12-31 13:19:37,332 INFO:     Found new best model at epoch 4
2022-12-31 13:19:37,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:37,333 INFO:     Epoch: 5
2022-12-31 13:19:38,982 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4561786452929179, 'Total loss': 0.4561786452929179} | train loss {'Reaction outcome loss': 0.47795773516206636, 'Total loss': 0.47795773516206636}
2022-12-31 13:19:38,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:38,982 INFO:     Epoch: 6
2022-12-31 13:19:40,575 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5238206406434377, 'Total loss': 0.5238206406434377} | train loss {'Reaction outcome loss': 0.49417488568502926, 'Total loss': 0.49417488568502926}
2022-12-31 13:19:40,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:40,575 INFO:     Epoch: 7
2022-12-31 13:19:42,205 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42035086651643117, 'Total loss': 0.42035086651643117} | train loss {'Reaction outcome loss': 0.49370557103163487, 'Total loss': 0.49370557103163487}
2022-12-31 13:19:42,205 INFO:     Found new best model at epoch 7
2022-12-31 13:19:42,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:42,206 INFO:     Epoch: 8
2022-12-31 13:19:43,798 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4343019147713979, 'Total loss': 0.4343019147713979} | train loss {'Reaction outcome loss': 0.44940695511615847, 'Total loss': 0.44940695511615847}
2022-12-31 13:19:43,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:43,799 INFO:     Epoch: 9
2022-12-31 13:19:45,411 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43612627387046815, 'Total loss': 0.43612627387046815} | train loss {'Reaction outcome loss': 0.44434243426287034, 'Total loss': 0.44434243426287034}
2022-12-31 13:19:45,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:45,411 INFO:     Epoch: 10
2022-12-31 13:19:47,034 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4209956576426824, 'Total loss': 0.4209956576426824} | train loss {'Reaction outcome loss': 0.44148498405179387, 'Total loss': 0.44148498405179387}
2022-12-31 13:19:47,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:47,034 INFO:     Epoch: 11
2022-12-31 13:19:48,670 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45096842646598817, 'Total loss': 0.45096842646598817} | train loss {'Reaction outcome loss': 0.45088881046335766, 'Total loss': 0.45088881046335766}
2022-12-31 13:19:48,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:48,670 INFO:     Epoch: 12
2022-12-31 13:19:50,273 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4334465265274048, 'Total loss': 0.4334465265274048} | train loss {'Reaction outcome loss': 0.48839956929399364, 'Total loss': 0.48839956929399364}
2022-12-31 13:19:50,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:50,273 INFO:     Epoch: 13
2022-12-31 13:19:51,885 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4336853245894114, 'Total loss': 0.4336853245894114} | train loss {'Reaction outcome loss': 0.43704756918916665, 'Total loss': 0.43704756918916665}
2022-12-31 13:19:51,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:51,885 INFO:     Epoch: 14
2022-12-31 13:19:53,507 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41673823595047, 'Total loss': 0.41673823595047} | train loss {'Reaction outcome loss': 0.4347567387141179, 'Total loss': 0.4347567387141179}
2022-12-31 13:19:53,508 INFO:     Found new best model at epoch 14
2022-12-31 13:19:53,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:53,509 INFO:     Epoch: 15
2022-12-31 13:19:55,130 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40698157449563344, 'Total loss': 0.40698157449563344} | train loss {'Reaction outcome loss': 0.4489535782756149, 'Total loss': 0.4489535782756149}
2022-12-31 13:19:55,130 INFO:     Found new best model at epoch 15
2022-12-31 13:19:55,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:55,131 INFO:     Epoch: 16
2022-12-31 13:19:56,767 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44370257953802744, 'Total loss': 0.44370257953802744} | train loss {'Reaction outcome loss': 0.4373172395795152, 'Total loss': 0.4373172395795152}
2022-12-31 13:19:56,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:56,768 INFO:     Epoch: 17
2022-12-31 13:19:58,379 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38292269607385, 'Total loss': 0.38292269607385} | train loss {'Reaction outcome loss': 0.42242273194521357, 'Total loss': 0.42242273194521357}
2022-12-31 13:19:58,379 INFO:     Found new best model at epoch 17
2022-12-31 13:19:58,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:19:58,380 INFO:     Epoch: 18
2022-12-31 13:20:00,006 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42435897290706637, 'Total loss': 0.42435897290706637} | train loss {'Reaction outcome loss': 0.40944621630984807, 'Total loss': 0.40944621630984807}
2022-12-31 13:20:00,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:00,006 INFO:     Epoch: 19
2022-12-31 13:20:01,605 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40232460101445516, 'Total loss': 0.40232460101445516} | train loss {'Reaction outcome loss': 0.4174194159661082, 'Total loss': 0.4174194159661082}
2022-12-31 13:20:01,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:01,605 INFO:     Epoch: 20
2022-12-31 13:20:03,218 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39610232015450797, 'Total loss': 0.39610232015450797} | train loss {'Reaction outcome loss': 0.4282672658454681, 'Total loss': 0.4282672658454681}
2022-12-31 13:20:03,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:03,219 INFO:     Epoch: 21
2022-12-31 13:20:04,833 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41258357266585033, 'Total loss': 0.41258357266585033} | train loss {'Reaction outcome loss': 0.4326650549411315, 'Total loss': 0.4326650549411315}
2022-12-31 13:20:04,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:04,833 INFO:     Epoch: 22
2022-12-31 13:20:06,447 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3896028697490692, 'Total loss': 0.3896028697490692} | train loss {'Reaction outcome loss': 0.3930174145321159, 'Total loss': 0.3930174145321159}
2022-12-31 13:20:06,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:06,447 INFO:     Epoch: 23
2022-12-31 13:20:08,049 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3845991015434265, 'Total loss': 0.3845991015434265} | train loss {'Reaction outcome loss': 0.38232207651320926, 'Total loss': 0.38232207651320926}
2022-12-31 13:20:08,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:08,050 INFO:     Epoch: 24
2022-12-31 13:20:09,683 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41884761253992714, 'Total loss': 0.41884761253992714} | train loss {'Reaction outcome loss': 0.38047177422170836, 'Total loss': 0.38047177422170836}
2022-12-31 13:20:09,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:09,683 INFO:     Epoch: 25
2022-12-31 13:20:11,282 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3644673148790995, 'Total loss': 0.3644673148790995} | train loss {'Reaction outcome loss': 0.3984296302162651, 'Total loss': 0.3984296302162651}
2022-12-31 13:20:11,282 INFO:     Found new best model at epoch 25
2022-12-31 13:20:11,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:11,283 INFO:     Epoch: 26
2022-12-31 13:20:12,895 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3864140619834264, 'Total loss': 0.3864140619834264} | train loss {'Reaction outcome loss': 0.3967453237670217, 'Total loss': 0.3967453237670217}
2022-12-31 13:20:12,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:12,895 INFO:     Epoch: 27
2022-12-31 13:20:14,508 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38681543270746865, 'Total loss': 0.38681543270746865} | train loss {'Reaction outcome loss': 0.3740092208743959, 'Total loss': 0.3740092208743959}
2022-12-31 13:20:14,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:14,509 INFO:     Epoch: 28
2022-12-31 13:20:16,121 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41073948244253794, 'Total loss': 0.41073948244253794} | train loss {'Reaction outcome loss': 0.3751585972967787, 'Total loss': 0.3751585972967787}
2022-12-31 13:20:16,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:16,122 INFO:     Epoch: 29
2022-12-31 13:20:17,739 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37731773977478344, 'Total loss': 0.37731773977478344} | train loss {'Reaction outcome loss': 0.39646229995549587, 'Total loss': 0.39646229995549587}
2022-12-31 13:20:17,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:17,740 INFO:     Epoch: 30
2022-12-31 13:20:19,345 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3792632699012756, 'Total loss': 0.3792632699012756} | train loss {'Reaction outcome loss': 0.3777337494859661, 'Total loss': 0.3777337494859661}
2022-12-31 13:20:19,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:19,345 INFO:     Epoch: 31
2022-12-31 13:20:20,951 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38168854266405106, 'Total loss': 0.38168854266405106} | train loss {'Reaction outcome loss': 0.37662374114691943, 'Total loss': 0.37662374114691943}
2022-12-31 13:20:20,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:20,951 INFO:     Epoch: 32
2022-12-31 13:20:22,566 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36705622225999834, 'Total loss': 0.36705622225999834} | train loss {'Reaction outcome loss': 0.35912617806183256, 'Total loss': 0.35912617806183256}
2022-12-31 13:20:22,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:22,566 INFO:     Epoch: 33
2022-12-31 13:20:24,181 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.378686253229777, 'Total loss': 0.378686253229777} | train loss {'Reaction outcome loss': 0.35082577835630113, 'Total loss': 0.35082577835630113}
2022-12-31 13:20:24,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:24,181 INFO:     Epoch: 34
2022-12-31 13:20:25,769 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4011990676323573, 'Total loss': 0.4011990676323573} | train loss {'Reaction outcome loss': 0.3483456370582723, 'Total loss': 0.3483456370582723}
2022-12-31 13:20:25,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:25,769 INFO:     Epoch: 35
2022-12-31 13:20:27,403 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38103579183419545, 'Total loss': 0.38103579183419545} | train loss {'Reaction outcome loss': 0.3412219023439979, 'Total loss': 0.3412219023439979}
2022-12-31 13:20:27,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:27,404 INFO:     Epoch: 36
2022-12-31 13:20:29,030 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41768032709757485, 'Total loss': 0.41768032709757485} | train loss {'Reaction outcome loss': 0.33629847314137884, 'Total loss': 0.33629847314137884}
2022-12-31 13:20:29,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:29,030 INFO:     Epoch: 37
2022-12-31 13:20:30,673 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3618644833564758, 'Total loss': 0.3618644833564758} | train loss {'Reaction outcome loss': 0.3327937661062764, 'Total loss': 0.3327937661062764}
2022-12-31 13:20:30,673 INFO:     Found new best model at epoch 37
2022-12-31 13:20:30,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:30,674 INFO:     Epoch: 38
2022-12-31 13:20:32,303 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3931856110692024, 'Total loss': 0.3931856110692024} | train loss {'Reaction outcome loss': 0.3346362867775589, 'Total loss': 0.3346362867775589}
2022-12-31 13:20:32,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:32,303 INFO:     Epoch: 39
2022-12-31 13:20:33,944 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3990472048521042, 'Total loss': 0.3990472048521042} | train loss {'Reaction outcome loss': 0.32438791368791053, 'Total loss': 0.32438791368791053}
2022-12-31 13:20:33,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:33,945 INFO:     Epoch: 40
2022-12-31 13:20:35,534 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3547169213493665, 'Total loss': 0.3547169213493665} | train loss {'Reaction outcome loss': 0.33067127552382863, 'Total loss': 0.33067127552382863}
2022-12-31 13:20:35,535 INFO:     Found new best model at epoch 40
2022-12-31 13:20:35,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:35,535 INFO:     Epoch: 41
2022-12-31 13:20:37,151 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3478957831859589, 'Total loss': 0.3478957831859589} | train loss {'Reaction outcome loss': 0.3180988824426912, 'Total loss': 0.3180988824426912}
2022-12-31 13:20:37,151 INFO:     Found new best model at epoch 41
2022-12-31 13:20:37,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:37,152 INFO:     Epoch: 42
2022-12-31 13:20:38,744 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3490463584661484, 'Total loss': 0.3490463584661484} | train loss {'Reaction outcome loss': 0.31185093379673967, 'Total loss': 0.31185093379673967}
2022-12-31 13:20:38,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:38,745 INFO:     Epoch: 43
2022-12-31 13:20:40,362 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3820536563793818, 'Total loss': 0.3820536563793818} | train loss {'Reaction outcome loss': 0.3135833363171996, 'Total loss': 0.3135833363171996}
2022-12-31 13:20:40,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:40,362 INFO:     Epoch: 44
2022-12-31 13:20:41,975 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35893130699793496, 'Total loss': 0.35893130699793496} | train loss {'Reaction outcome loss': 0.3128477982684052, 'Total loss': 0.3128477982684052}
2022-12-31 13:20:41,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:41,975 INFO:     Epoch: 45
2022-12-31 13:20:43,598 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4125613252321879, 'Total loss': 0.4125613252321879} | train loss {'Reaction outcome loss': 0.3160047653819556, 'Total loss': 0.3160047653819556}
2022-12-31 13:20:43,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:43,598 INFO:     Epoch: 46
2022-12-31 13:20:45,198 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36720083057880404, 'Total loss': 0.36720083057880404} | train loss {'Reaction outcome loss': 0.33236600643199316, 'Total loss': 0.33236600643199316}
2022-12-31 13:20:45,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:45,199 INFO:     Epoch: 47
2022-12-31 13:20:46,799 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3358369717995326, 'Total loss': 0.3358369717995326} | train loss {'Reaction outcome loss': 0.30725883371264173, 'Total loss': 0.30725883371264173}
2022-12-31 13:20:46,799 INFO:     Found new best model at epoch 47
2022-12-31 13:20:46,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:46,800 INFO:     Epoch: 48
2022-12-31 13:20:48,423 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3548165480295817, 'Total loss': 0.3548165480295817} | train loss {'Reaction outcome loss': 0.3054587388870077, 'Total loss': 0.3054587388870077}
2022-12-31 13:20:48,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:48,423 INFO:     Epoch: 49
2022-12-31 13:20:50,065 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3759310225645701, 'Total loss': 0.3759310225645701} | train loss {'Reaction outcome loss': 0.31976833322298026, 'Total loss': 0.31976833322298026}
2022-12-31 13:20:50,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:50,066 INFO:     Epoch: 50
2022-12-31 13:20:51,696 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38142011339465776, 'Total loss': 0.38142011339465776} | train loss {'Reaction outcome loss': 0.3025651378017189, 'Total loss': 0.3025651378017189}
2022-12-31 13:20:51,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:51,696 INFO:     Epoch: 51
2022-12-31 13:20:53,303 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3537169779340426, 'Total loss': 0.3537169779340426} | train loss {'Reaction outcome loss': 0.30126195427647623, 'Total loss': 0.30126195427647623}
2022-12-31 13:20:53,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:53,303 INFO:     Epoch: 52
2022-12-31 13:20:54,945 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35889662156502405, 'Total loss': 0.35889662156502405} | train loss {'Reaction outcome loss': 0.29492073041467887, 'Total loss': 0.29492073041467887}
2022-12-31 13:20:54,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:54,945 INFO:     Epoch: 53
2022-12-31 13:20:56,533 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4174318313598633, 'Total loss': 0.4174318313598633} | train loss {'Reaction outcome loss': 0.2888632284773295, 'Total loss': 0.2888632284773295}
2022-12-31 13:20:56,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:56,533 INFO:     Epoch: 54
2022-12-31 13:20:58,145 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3537659386793772, 'Total loss': 0.3537659386793772} | train loss {'Reaction outcome loss': 0.29375321492704604, 'Total loss': 0.29375321492704604}
2022-12-31 13:20:58,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:58,146 INFO:     Epoch: 55
2022-12-31 13:20:59,757 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38237836956977844, 'Total loss': 0.38237836956977844} | train loss {'Reaction outcome loss': 0.28682496651721967, 'Total loss': 0.28682496651721967}
2022-12-31 13:20:59,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:20:59,757 INFO:     Epoch: 56
2022-12-31 13:21:01,372 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3402580867211024, 'Total loss': 0.3402580867211024} | train loss {'Reaction outcome loss': 0.2789862756007874, 'Total loss': 0.2789862756007874}
2022-12-31 13:21:01,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:01,372 INFO:     Epoch: 57
2022-12-31 13:21:02,966 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37203482339779537, 'Total loss': 0.37203482339779537} | train loss {'Reaction outcome loss': 0.2807042251418655, 'Total loss': 0.2807042251418655}
2022-12-31 13:21:02,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:02,966 INFO:     Epoch: 58
2022-12-31 13:21:04,575 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34671150843302406, 'Total loss': 0.34671150843302406} | train loss {'Reaction outcome loss': 0.2764509477069339, 'Total loss': 0.2764509477069339}
2022-12-31 13:21:04,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:04,575 INFO:     Epoch: 59
2022-12-31 13:21:06,195 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.332554230093956, 'Total loss': 0.332554230093956} | train loss {'Reaction outcome loss': 0.2726153662901513, 'Total loss': 0.2726153662901513}
2022-12-31 13:21:06,195 INFO:     Found new best model at epoch 59
2022-12-31 13:21:06,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:06,196 INFO:     Epoch: 60
2022-12-31 13:21:07,807 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3266073097785314, 'Total loss': 0.3266073097785314} | train loss {'Reaction outcome loss': 0.271402127785183, 'Total loss': 0.271402127785183}
2022-12-31 13:21:07,807 INFO:     Found new best model at epoch 60
2022-12-31 13:21:07,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:07,808 INFO:     Epoch: 61
2022-12-31 13:21:09,440 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35095736955602963, 'Total loss': 0.35095736955602963} | train loss {'Reaction outcome loss': 0.2691500711683319, 'Total loss': 0.2691500711683319}
2022-12-31 13:21:09,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:09,441 INFO:     Epoch: 62
2022-12-31 13:21:11,055 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3621469035744667, 'Total loss': 0.3621469035744667} | train loss {'Reaction outcome loss': 0.2694060361802416, 'Total loss': 0.2694060361802416}
2022-12-31 13:21:11,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:11,055 INFO:     Epoch: 63
2022-12-31 13:21:12,687 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37036873698234557, 'Total loss': 0.37036873698234557} | train loss {'Reaction outcome loss': 0.26175286478141113, 'Total loss': 0.26175286478141113}
2022-12-31 13:21:12,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:12,687 INFO:     Epoch: 64
2022-12-31 13:21:14,285 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3690413256486257, 'Total loss': 0.3690413256486257} | train loss {'Reaction outcome loss': 0.26064216762619175, 'Total loss': 0.26064216762619175}
2022-12-31 13:21:14,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:14,286 INFO:     Epoch: 65
2022-12-31 13:21:15,898 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35658387690782545, 'Total loss': 0.35658387690782545} | train loss {'Reaction outcome loss': 0.2591308283913152, 'Total loss': 0.2591308283913152}
2022-12-31 13:21:15,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:15,898 INFO:     Epoch: 66
2022-12-31 13:21:17,508 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3120384653409322, 'Total loss': 0.3120384653409322} | train loss {'Reaction outcome loss': 0.25870032933797094, 'Total loss': 0.25870032933797094}
2022-12-31 13:21:17,509 INFO:     Found new best model at epoch 66
2022-12-31 13:21:17,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:17,510 INFO:     Epoch: 67
2022-12-31 13:21:19,124 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3202398175994555, 'Total loss': 0.3202398175994555} | train loss {'Reaction outcome loss': 0.26104829129864177, 'Total loss': 0.26104829129864177}
2022-12-31 13:21:19,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:19,124 INFO:     Epoch: 68
2022-12-31 13:21:20,741 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3507809842626254, 'Total loss': 0.3507809842626254} | train loss {'Reaction outcome loss': 0.25817763627476426, 'Total loss': 0.25817763627476426}
2022-12-31 13:21:20,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:20,742 INFO:     Epoch: 69
2022-12-31 13:21:22,358 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3680192361275355, 'Total loss': 0.3680192361275355} | train loss {'Reaction outcome loss': 0.26011116511021415, 'Total loss': 0.26011116511021415}
2022-12-31 13:21:22,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:22,358 INFO:     Epoch: 70
2022-12-31 13:21:23,966 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34958954254786173, 'Total loss': 0.34958954254786173} | train loss {'Reaction outcome loss': 0.2578669314245707, 'Total loss': 0.2578669314245707}
2022-12-31 13:21:23,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:23,966 INFO:     Epoch: 71
2022-12-31 13:21:25,589 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3365899840990702, 'Total loss': 0.3365899840990702} | train loss {'Reaction outcome loss': 0.3677938274015922, 'Total loss': 0.3677938274015922}
2022-12-31 13:21:25,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:25,589 INFO:     Epoch: 72
2022-12-31 13:21:27,200 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3467768669128418, 'Total loss': 0.3467768669128418} | train loss {'Reaction outcome loss': 0.27931323706887773, 'Total loss': 0.27931323706887773}
2022-12-31 13:21:27,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:27,200 INFO:     Epoch: 73
2022-12-31 13:21:28,814 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.32675502995649974, 'Total loss': 0.32675502995649974} | train loss {'Reaction outcome loss': 0.2630702786019369, 'Total loss': 0.2630702786019369}
2022-12-31 13:21:28,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:28,815 INFO:     Epoch: 74
2022-12-31 13:21:30,406 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3569335560003916, 'Total loss': 0.3569335560003916} | train loss {'Reaction outcome loss': 0.25370324169375963, 'Total loss': 0.25370324169375963}
2022-12-31 13:21:30,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:30,406 INFO:     Epoch: 75
2022-12-31 13:21:31,999 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3713579888145129, 'Total loss': 0.3713579888145129} | train loss {'Reaction outcome loss': 0.2531641310121378, 'Total loss': 0.2531641310121378}
2022-12-31 13:21:31,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:31,999 INFO:     Epoch: 76
2022-12-31 13:21:33,609 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34775438010692594, 'Total loss': 0.34775438010692594} | train loss {'Reaction outcome loss': 0.24770423802442235, 'Total loss': 0.24770423802442235}
2022-12-31 13:21:33,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:33,609 INFO:     Epoch: 77
2022-12-31 13:21:35,217 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.34770493110020956, 'Total loss': 0.34770493110020956} | train loss {'Reaction outcome loss': 0.24602750098953644, 'Total loss': 0.24602750098953644}
2022-12-31 13:21:35,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:35,217 INFO:     Epoch: 78
2022-12-31 13:21:36,826 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3473291978240013, 'Total loss': 0.3473291978240013} | train loss {'Reaction outcome loss': 0.24679274643953567, 'Total loss': 0.24679274643953567}
2022-12-31 13:21:36,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:36,826 INFO:     Epoch: 79
2022-12-31 13:21:38,420 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.33494424223899844, 'Total loss': 0.33494424223899844} | train loss {'Reaction outcome loss': 0.24037408185245443, 'Total loss': 0.24037408185245443}
2022-12-31 13:21:38,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:38,420 INFO:     Epoch: 80
2022-12-31 13:21:40,008 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3453282465537389, 'Total loss': 0.3453282465537389} | train loss {'Reaction outcome loss': 0.24239231369363656, 'Total loss': 0.24239231369363656}
2022-12-31 13:21:40,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:40,009 INFO:     Epoch: 81
2022-12-31 13:21:41,607 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3443990925947825, 'Total loss': 0.3443990925947825} | train loss {'Reaction outcome loss': 0.2442943850351646, 'Total loss': 0.2442943850351646}
2022-12-31 13:21:41,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:41,607 INFO:     Epoch: 82
2022-12-31 13:21:43,239 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3498051096995672, 'Total loss': 0.3498051096995672} | train loss {'Reaction outcome loss': 0.23733425375531372, 'Total loss': 0.23733425375531372}
2022-12-31 13:21:43,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:43,240 INFO:     Epoch: 83
2022-12-31 13:21:44,871 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35777420898278556, 'Total loss': 0.35777420898278556} | train loss {'Reaction outcome loss': 0.23120104103261416, 'Total loss': 0.23120104103261416}
2022-12-31 13:21:44,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:44,871 INFO:     Epoch: 84
2022-12-31 13:21:46,498 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35317722856998446, 'Total loss': 0.35317722856998446} | train loss {'Reaction outcome loss': 0.23218167259229644, 'Total loss': 0.23218167259229644}
2022-12-31 13:21:46,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:46,499 INFO:     Epoch: 85
2022-12-31 13:21:48,104 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.360537917415301, 'Total loss': 0.360537917415301} | train loss {'Reaction outcome loss': 0.2261822518162855, 'Total loss': 0.2261822518162855}
2022-12-31 13:21:48,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:48,105 INFO:     Epoch: 86
2022-12-31 13:21:49,691 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3243710125486056, 'Total loss': 0.3243710125486056} | train loss {'Reaction outcome loss': 0.2349067310715327, 'Total loss': 0.2349067310715327}
2022-12-31 13:21:49,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:49,691 INFO:     Epoch: 87
2022-12-31 13:21:51,312 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3710057626167933, 'Total loss': 0.3710057626167933} | train loss {'Reaction outcome loss': 0.22204733765734683, 'Total loss': 0.22204733765734683}
2022-12-31 13:21:51,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:51,312 INFO:     Epoch: 88
2022-12-31 13:21:52,961 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.32369835873444874, 'Total loss': 0.32369835873444874} | train loss {'Reaction outcome loss': 0.23143392513283406, 'Total loss': 0.23143392513283406}
2022-12-31 13:21:52,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:52,962 INFO:     Epoch: 89
2022-12-31 13:21:54,604 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.30718789299329124, 'Total loss': 0.30718789299329124} | train loss {'Reaction outcome loss': 0.2238966845911489, 'Total loss': 0.2238966845911489}
2022-12-31 13:21:54,604 INFO:     Found new best model at epoch 89
2022-12-31 13:21:54,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:54,605 INFO:     Epoch: 90
2022-12-31 13:21:56,245 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37341405749320983, 'Total loss': 0.37341405749320983} | train loss {'Reaction outcome loss': 0.22386799302182844, 'Total loss': 0.22386799302182844}
2022-12-31 13:21:56,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:56,245 INFO:     Epoch: 91
2022-12-31 13:21:57,353 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3684350142876307, 'Total loss': 0.3684350142876307} | train loss {'Reaction outcome loss': 0.23345880501437932, 'Total loss': 0.23345880501437932}
2022-12-31 13:21:57,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:57,354 INFO:     Epoch: 92
2022-12-31 13:21:58,437 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36104904587070147, 'Total loss': 0.36104904587070147} | train loss {'Reaction outcome loss': 0.24506721263616413, 'Total loss': 0.24506721263616413}
2022-12-31 13:21:58,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:58,437 INFO:     Epoch: 93
2022-12-31 13:21:59,511 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3812064747015635, 'Total loss': 0.3812064747015635} | train loss {'Reaction outcome loss': 0.27414711505390593, 'Total loss': 0.27414711505390593}
2022-12-31 13:21:59,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:21:59,512 INFO:     Epoch: 94
2022-12-31 13:22:00,581 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3266736934582392, 'Total loss': 0.3266736934582392} | train loss {'Reaction outcome loss': 0.2271920952273607, 'Total loss': 0.2271920952273607}
2022-12-31 13:22:00,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:00,581 INFO:     Epoch: 95
2022-12-31 13:22:02,068 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.34976257383823395, 'Total loss': 0.34976257383823395} | train loss {'Reaction outcome loss': 0.21811375215361625, 'Total loss': 0.21811375215361625}
2022-12-31 13:22:02,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:02,068 INFO:     Epoch: 96
2022-12-31 13:22:03,664 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35079781810442606, 'Total loss': 0.35079781810442606} | train loss {'Reaction outcome loss': 0.22052095772401578, 'Total loss': 0.22052095772401578}
2022-12-31 13:22:03,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:03,664 INFO:     Epoch: 97
2022-12-31 13:22:05,296 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.34056755652030307, 'Total loss': 0.34056755652030307} | train loss {'Reaction outcome loss': 0.22689383710393737, 'Total loss': 0.22689383710393737}
2022-12-31 13:22:05,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:05,297 INFO:     Epoch: 98
2022-12-31 13:22:06,886 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34311231126387914, 'Total loss': 0.34311231126387914} | train loss {'Reaction outcome loss': 0.22115081088091043, 'Total loss': 0.22115081088091043}
2022-12-31 13:22:06,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:06,886 INFO:     Epoch: 99
2022-12-31 13:22:08,473 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3211541518568993, 'Total loss': 0.3211541518568993} | train loss {'Reaction outcome loss': 0.22016096594945891, 'Total loss': 0.22016096594945891}
2022-12-31 13:22:08,473 INFO:     Best model found after epoch 90 of 100.
2022-12-31 13:22:08,473 INFO:   Done with stage: TRAINING
2022-12-31 13:22:08,473 INFO:   Starting stage: EVALUATION
2022-12-31 13:22:08,602 INFO:   Done with stage: EVALUATION
2022-12-31 13:22:08,602 INFO:   Leaving out SEQ value Fold_6
2022-12-31 13:22:08,615 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:22:08,615 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:22:09,268 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:22:09,268 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:22:09,337 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:22:09,337 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:22:09,337 INFO:     No hyperparam tuning for this model
2022-12-31 13:22:09,337 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:22:09,337 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:22:09,338 INFO:     None feature selector for col prot
2022-12-31 13:22:09,338 INFO:     None feature selector for col prot
2022-12-31 13:22:09,338 INFO:     None feature selector for col prot
2022-12-31 13:22:09,339 INFO:     None feature selector for col chem
2022-12-31 13:22:09,339 INFO:     None feature selector for col chem
2022-12-31 13:22:09,339 INFO:     None feature selector for col chem
2022-12-31 13:22:09,339 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:22:09,339 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:22:09,341 INFO:     Number of params in model 223921
2022-12-31 13:22:09,344 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:22:09,344 INFO:   Starting stage: TRAINING
2022-12-31 13:22:09,389 INFO:     Val loss before train {'Reaction outcome loss': 0.9996256709098816, 'Total loss': 0.9996256709098816}
2022-12-31 13:22:09,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:09,389 INFO:     Epoch: 0
2022-12-31 13:22:10,986 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6868672966957092, 'Total loss': 0.6868672966957092} | train loss {'Reaction outcome loss': 0.8282215654634048, 'Total loss': 0.8282215654634048}
2022-12-31 13:22:10,987 INFO:     Found new best model at epoch 0
2022-12-31 13:22:10,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:10,988 INFO:     Epoch: 1
2022-12-31 13:22:12,594 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6049164315064748, 'Total loss': 0.6049164315064748} | train loss {'Reaction outcome loss': 0.618983732185502, 'Total loss': 0.618983732185502}
2022-12-31 13:22:12,594 INFO:     Found new best model at epoch 1
2022-12-31 13:22:12,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:12,595 INFO:     Epoch: 2
2022-12-31 13:22:14,195 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5394734481970469, 'Total loss': 0.5394734481970469} | train loss {'Reaction outcome loss': 0.5424277858515067, 'Total loss': 0.5424277858515067}
2022-12-31 13:22:14,195 INFO:     Found new best model at epoch 2
2022-12-31 13:22:14,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:14,196 INFO:     Epoch: 3
2022-12-31 13:22:15,793 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5999412635962168, 'Total loss': 0.5999412635962168} | train loss {'Reaction outcome loss': 0.5063659476413243, 'Total loss': 0.5063659476413243}
2022-12-31 13:22:15,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:15,793 INFO:     Epoch: 4
2022-12-31 13:22:17,402 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.542824759085973, 'Total loss': 0.542824759085973} | train loss {'Reaction outcome loss': 0.4965958139341176, 'Total loss': 0.4965958139341176}
2022-12-31 13:22:17,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:17,403 INFO:     Epoch: 5
2022-12-31 13:22:18,976 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5493639389673869, 'Total loss': 0.5493639389673869} | train loss {'Reaction outcome loss': 0.48858202929082123, 'Total loss': 0.48858202929082123}
2022-12-31 13:22:18,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:18,977 INFO:     Epoch: 6
2022-12-31 13:22:20,606 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49929569760958353, 'Total loss': 0.49929569760958353} | train loss {'Reaction outcome loss': 0.510407291892646, 'Total loss': 0.510407291892646}
2022-12-31 13:22:20,607 INFO:     Found new best model at epoch 6
2022-12-31 13:22:20,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:20,608 INFO:     Epoch: 7
2022-12-31 13:22:22,213 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5211123585700989, 'Total loss': 0.5211123585700989} | train loss {'Reaction outcome loss': 0.4754280269793842, 'Total loss': 0.4754280269793842}
2022-12-31 13:22:22,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:22,214 INFO:     Epoch: 8
2022-12-31 13:22:23,836 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.481611759463946, 'Total loss': 0.481611759463946} | train loss {'Reaction outcome loss': 0.4623393669920177, 'Total loss': 0.4623393669920177}
2022-12-31 13:22:23,836 INFO:     Found new best model at epoch 8
2022-12-31 13:22:23,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:23,837 INFO:     Epoch: 9
2022-12-31 13:22:25,493 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5525429507096609, 'Total loss': 0.5525429507096609} | train loss {'Reaction outcome loss': 0.4558569769496503, 'Total loss': 0.4558569769496503}
2022-12-31 13:22:25,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:25,493 INFO:     Epoch: 10
2022-12-31 13:22:27,102 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5113655298948288, 'Total loss': 0.5113655298948288} | train loss {'Reaction outcome loss': 0.46378221806261916, 'Total loss': 0.46378221806261916}
2022-12-31 13:22:27,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:27,102 INFO:     Epoch: 11
2022-12-31 13:22:28,713 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48491092920303347, 'Total loss': 0.48491092920303347} | train loss {'Reaction outcome loss': 0.43628299753923994, 'Total loss': 0.43628299753923994}
2022-12-31 13:22:28,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:28,713 INFO:     Epoch: 12
2022-12-31 13:22:30,338 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49277650912602744, 'Total loss': 0.49277650912602744} | train loss {'Reaction outcome loss': 0.4387095298152417, 'Total loss': 0.4387095298152417}
2022-12-31 13:22:30,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:30,339 INFO:     Epoch: 13
2022-12-31 13:22:31,947 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48940519988536835, 'Total loss': 0.48940519988536835} | train loss {'Reaction outcome loss': 0.42594716703667695, 'Total loss': 0.42594716703667695}
2022-12-31 13:22:31,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:31,947 INFO:     Epoch: 14
2022-12-31 13:22:33,548 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5192389984925588, 'Total loss': 0.5192389984925588} | train loss {'Reaction outcome loss': 0.44389860137649206, 'Total loss': 0.44389860137649206}
2022-12-31 13:22:33,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:33,548 INFO:     Epoch: 15
2022-12-31 13:22:35,156 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4557858402530352, 'Total loss': 0.4557858402530352} | train loss {'Reaction outcome loss': 0.45091764094389003, 'Total loss': 0.45091764094389003}
2022-12-31 13:22:35,156 INFO:     Found new best model at epoch 15
2022-12-31 13:22:35,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:35,157 INFO:     Epoch: 16
2022-12-31 13:22:36,756 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48599547147750854, 'Total loss': 0.48599547147750854} | train loss {'Reaction outcome loss': 0.4228328087542584, 'Total loss': 0.4228328087542584}
2022-12-31 13:22:36,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:36,756 INFO:     Epoch: 17
2022-12-31 13:22:38,367 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48670897881189984, 'Total loss': 0.48670897881189984} | train loss {'Reaction outcome loss': 0.4144484860904492, 'Total loss': 0.4144484860904492}
2022-12-31 13:22:38,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:38,367 INFO:     Epoch: 18
2022-12-31 13:22:39,977 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48315759301185607, 'Total loss': 0.48315759301185607} | train loss {'Reaction outcome loss': 0.408541323563111, 'Total loss': 0.408541323563111}
2022-12-31 13:22:39,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:39,977 INFO:     Epoch: 19
2022-12-31 13:22:41,571 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44951054553190867, 'Total loss': 0.44951054553190867} | train loss {'Reaction outcome loss': 0.41583167350904987, 'Total loss': 0.41583167350904987}
2022-12-31 13:22:41,571 INFO:     Found new best model at epoch 19
2022-12-31 13:22:41,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:41,572 INFO:     Epoch: 20
2022-12-31 13:22:43,178 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.485183314482371, 'Total loss': 0.485183314482371} | train loss {'Reaction outcome loss': 0.39047203730476304, 'Total loss': 0.39047203730476304}
2022-12-31 13:22:43,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:43,178 INFO:     Epoch: 21
2022-12-31 13:22:44,795 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4657502969106038, 'Total loss': 0.4657502969106038} | train loss {'Reaction outcome loss': 0.3869066211543437, 'Total loss': 0.3869066211543437}
2022-12-31 13:22:44,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:44,795 INFO:     Epoch: 22
2022-12-31 13:22:46,384 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4598394274711609, 'Total loss': 0.4598394274711609} | train loss {'Reaction outcome loss': 0.38158406259363814, 'Total loss': 0.38158406259363814}
2022-12-31 13:22:46,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:46,386 INFO:     Epoch: 23
2022-12-31 13:22:47,993 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4727407197157542, 'Total loss': 0.4727407197157542} | train loss {'Reaction outcome loss': 0.3713548686878378, 'Total loss': 0.3713548686878378}
2022-12-31 13:22:47,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:47,993 INFO:     Epoch: 24
2022-12-31 13:22:49,599 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4594496667385101, 'Total loss': 0.4594496667385101} | train loss {'Reaction outcome loss': 0.3690798451980168, 'Total loss': 0.3690798451980168}
2022-12-31 13:22:49,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:49,599 INFO:     Epoch: 25
2022-12-31 13:22:51,199 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4770227531592051, 'Total loss': 0.4770227531592051} | train loss {'Reaction outcome loss': 0.3692963399478923, 'Total loss': 0.3692963399478923}
2022-12-31 13:22:51,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:51,199 INFO:     Epoch: 26
2022-12-31 13:22:52,807 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4453510999679565, 'Total loss': 0.4453510999679565} | train loss {'Reaction outcome loss': 0.3710772164327943, 'Total loss': 0.3710772164327943}
2022-12-31 13:22:52,808 INFO:     Found new best model at epoch 26
2022-12-31 13:22:52,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:52,809 INFO:     Epoch: 27
2022-12-31 13:22:54,415 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47156646649042766, 'Total loss': 0.47156646649042766} | train loss {'Reaction outcome loss': 0.3667060499690284, 'Total loss': 0.3667060499690284}
2022-12-31 13:22:54,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:54,415 INFO:     Epoch: 28
2022-12-31 13:22:56,014 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4415449589490891, 'Total loss': 0.4415449589490891} | train loss {'Reaction outcome loss': 0.34470241817824326, 'Total loss': 0.34470241817824326}
2022-12-31 13:22:56,015 INFO:     Found new best model at epoch 28
2022-12-31 13:22:56,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:56,016 INFO:     Epoch: 29
2022-12-31 13:22:57,633 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4752223332722982, 'Total loss': 0.4752223332722982} | train loss {'Reaction outcome loss': 0.34985735689195385, 'Total loss': 0.34985735689195385}
2022-12-31 13:22:57,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:57,634 INFO:     Epoch: 30
2022-12-31 13:22:59,237 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4732709805170695, 'Total loss': 0.4732709805170695} | train loss {'Reaction outcome loss': 0.3418148866976085, 'Total loss': 0.3418148866976085}
2022-12-31 13:22:59,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:22:59,237 INFO:     Epoch: 31
2022-12-31 13:23:00,820 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4540226995944977, 'Total loss': 0.4540226995944977} | train loss {'Reaction outcome loss': 0.3322874587006811, 'Total loss': 0.3322874587006811}
2022-12-31 13:23:00,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:00,821 INFO:     Epoch: 32
2022-12-31 13:23:02,454 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42757315436999005, 'Total loss': 0.42757315436999005} | train loss {'Reaction outcome loss': 0.33291643829611334, 'Total loss': 0.33291643829611334}
2022-12-31 13:23:02,454 INFO:     Found new best model at epoch 32
2022-12-31 13:23:02,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:02,455 INFO:     Epoch: 33
2022-12-31 13:23:04,063 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4873714745044708, 'Total loss': 0.4873714745044708} | train loss {'Reaction outcome loss': 0.32749048322253604, 'Total loss': 0.32749048322253604}
2022-12-31 13:23:04,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:04,063 INFO:     Epoch: 34
2022-12-31 13:23:05,675 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44026093383630116, 'Total loss': 0.44026093383630116} | train loss {'Reaction outcome loss': 0.3263374046959064, 'Total loss': 0.3263374046959064}
2022-12-31 13:23:05,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:05,676 INFO:     Epoch: 35
2022-12-31 13:23:07,285 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4648051848014196, 'Total loss': 0.4648051848014196} | train loss {'Reaction outcome loss': 0.3219159800733062, 'Total loss': 0.3219159800733062}
2022-12-31 13:23:07,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:07,285 INFO:     Epoch: 36
2022-12-31 13:23:08,880 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4608328213294347, 'Total loss': 0.4608328213294347} | train loss {'Reaction outcome loss': 0.32246879423442093, 'Total loss': 0.32246879423442093}
2022-12-31 13:23:08,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:08,880 INFO:     Epoch: 37
2022-12-31 13:23:10,489 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5078066835800806, 'Total loss': 0.5078066835800806} | train loss {'Reaction outcome loss': 0.38465783375220886, 'Total loss': 0.38465783375220886}
2022-12-31 13:23:10,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:10,490 INFO:     Epoch: 38
2022-12-31 13:23:12,101 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46778910557428993, 'Total loss': 0.46778910557428993} | train loss {'Reaction outcome loss': 0.4132149743888041, 'Total loss': 0.4132149743888041}
2022-12-31 13:23:12,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:12,101 INFO:     Epoch: 39
2022-12-31 13:23:13,704 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4499946425358454, 'Total loss': 0.4499946425358454} | train loss {'Reaction outcome loss': 0.3507460376544707, 'Total loss': 0.3507460376544707}
2022-12-31 13:23:13,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:13,704 INFO:     Epoch: 40
2022-12-31 13:23:15,317 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43670847415924074, 'Total loss': 0.43670847415924074} | train loss {'Reaction outcome loss': 0.3339209422955047, 'Total loss': 0.3339209422955047}
2022-12-31 13:23:15,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:15,317 INFO:     Epoch: 41
2022-12-31 13:23:16,927 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43057546665271124, 'Total loss': 0.43057546665271124} | train loss {'Reaction outcome loss': 0.31288702779747307, 'Total loss': 0.31288702779747307}
2022-12-31 13:23:16,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:16,927 INFO:     Epoch: 42
2022-12-31 13:23:18,550 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45479679306348164, 'Total loss': 0.45479679306348164} | train loss {'Reaction outcome loss': 0.309798146021026, 'Total loss': 0.309798146021026}
2022-12-31 13:23:18,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:18,550 INFO:     Epoch: 43
2022-12-31 13:23:20,170 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5004081328709921, 'Total loss': 0.5004081328709921} | train loss {'Reaction outcome loss': 0.3013874756352511, 'Total loss': 0.3013874756352511}
2022-12-31 13:23:20,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:20,170 INFO:     Epoch: 44
2022-12-31 13:23:21,808 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4252980728944143, 'Total loss': 0.4252980728944143} | train loss {'Reaction outcome loss': 0.3042140340468799, 'Total loss': 0.3042140340468799}
2022-12-31 13:23:21,808 INFO:     Found new best model at epoch 44
2022-12-31 13:23:21,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:21,809 INFO:     Epoch: 45
2022-12-31 13:23:23,434 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5038809537887573, 'Total loss': 0.5038809537887573} | train loss {'Reaction outcome loss': 0.3006050676829519, 'Total loss': 0.3006050676829519}
2022-12-31 13:23:23,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:23,435 INFO:     Epoch: 46
2022-12-31 13:23:25,055 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4460671742757161, 'Total loss': 0.4460671742757161} | train loss {'Reaction outcome loss': 0.2986128503662653, 'Total loss': 0.2986128503662653}
2022-12-31 13:23:25,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:25,055 INFO:     Epoch: 47
2022-12-31 13:23:26,651 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5198291838169098, 'Total loss': 0.5198291838169098} | train loss {'Reaction outcome loss': 0.3016039232278, 'Total loss': 0.3016039232278}
2022-12-31 13:23:26,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:26,652 INFO:     Epoch: 48
2022-12-31 13:23:28,290 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45482204357783, 'Total loss': 0.45482204357783} | train loss {'Reaction outcome loss': 0.30938970957599254, 'Total loss': 0.30938970957599254}
2022-12-31 13:23:28,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:28,290 INFO:     Epoch: 49
2022-12-31 13:23:29,931 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.458312863111496, 'Total loss': 0.458312863111496} | train loss {'Reaction outcome loss': 0.2891089207074348, 'Total loss': 0.2891089207074348}
2022-12-31 13:23:29,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:29,932 INFO:     Epoch: 50
2022-12-31 13:23:31,544 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4703483462333679, 'Total loss': 0.4703483462333679} | train loss {'Reaction outcome loss': 0.2867899178027469, 'Total loss': 0.2867899178027469}
2022-12-31 13:23:31,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:31,545 INFO:     Epoch: 51
2022-12-31 13:23:33,179 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.435625159740448, 'Total loss': 0.435625159740448} | train loss {'Reaction outcome loss': 0.29275343581980123, 'Total loss': 0.29275343581980123}
2022-12-31 13:23:33,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:33,179 INFO:     Epoch: 52
2022-12-31 13:23:34,816 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42813496589660643, 'Total loss': 0.42813496589660643} | train loss {'Reaction outcome loss': 0.2831241553261255, 'Total loss': 0.2831241553261255}
2022-12-31 13:23:34,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:34,817 INFO:     Epoch: 53
2022-12-31 13:23:36,439 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4303286373615265, 'Total loss': 0.4303286373615265} | train loss {'Reaction outcome loss': 0.2803243380849776, 'Total loss': 0.2803243380849776}
2022-12-31 13:23:36,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:36,440 INFO:     Epoch: 54
2022-12-31 13:23:38,088 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4774092713991801, 'Total loss': 0.4774092713991801} | train loss {'Reaction outcome loss': 0.3008900045862664, 'Total loss': 0.3008900045862664}
2022-12-31 13:23:38,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:38,088 INFO:     Epoch: 55
2022-12-31 13:23:39,726 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47009981870651246, 'Total loss': 0.47009981870651246} | train loss {'Reaction outcome loss': 0.30170110122138716, 'Total loss': 0.30170110122138716}
2022-12-31 13:23:39,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:39,726 INFO:     Epoch: 56
2022-12-31 13:23:41,343 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4413158098856608, 'Total loss': 0.4413158098856608} | train loss {'Reaction outcome loss': 0.2857046081579925, 'Total loss': 0.2857046081579925}
2022-12-31 13:23:41,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:41,343 INFO:     Epoch: 57
2022-12-31 13:23:42,986 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4340902591745059, 'Total loss': 0.4340902591745059} | train loss {'Reaction outcome loss': 0.28207786046170996, 'Total loss': 0.28207786046170996}
2022-12-31 13:23:42,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:42,987 INFO:     Epoch: 58
2022-12-31 13:23:44,610 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43144522806008656, 'Total loss': 0.43144522806008656} | train loss {'Reaction outcome loss': 0.27598134208296804, 'Total loss': 0.27598134208296804}
2022-12-31 13:23:44,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:44,610 INFO:     Epoch: 59
2022-12-31 13:23:46,233 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44427068034807843, 'Total loss': 0.44427068034807843} | train loss {'Reaction outcome loss': 0.264181034205451, 'Total loss': 0.264181034205451}
2022-12-31 13:23:46,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:46,233 INFO:     Epoch: 60
2022-12-31 13:23:47,869 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44496780236562095, 'Total loss': 0.44496780236562095} | train loss {'Reaction outcome loss': 0.2691734449774916, 'Total loss': 0.2691734449774916}
2022-12-31 13:23:47,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:47,869 INFO:     Epoch: 61
2022-12-31 13:23:49,491 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4367119501034419, 'Total loss': 0.4367119501034419} | train loss {'Reaction outcome loss': 0.2663540564073259, 'Total loss': 0.2663540564073259}
2022-12-31 13:23:49,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:49,492 INFO:     Epoch: 62
2022-12-31 13:23:51,128 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43847816189130145, 'Total loss': 0.43847816189130145} | train loss {'Reaction outcome loss': 0.26687824452781805, 'Total loss': 0.26687824452781805}
2022-12-31 13:23:51,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:51,128 INFO:     Epoch: 63
2022-12-31 13:23:52,762 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43695000211397805, 'Total loss': 0.43695000211397805} | train loss {'Reaction outcome loss': 0.266101017628081, 'Total loss': 0.266101017628081}
2022-12-31 13:23:52,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:52,762 INFO:     Epoch: 64
2022-12-31 13:23:54,385 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42266527911027274, 'Total loss': 0.42266527911027274} | train loss {'Reaction outcome loss': 0.2648655439969962, 'Total loss': 0.2648655439969962}
2022-12-31 13:23:54,386 INFO:     Found new best model at epoch 64
2022-12-31 13:23:54,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:54,387 INFO:     Epoch: 65
2022-12-31 13:23:56,034 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42127164006233214, 'Total loss': 0.42127164006233214} | train loss {'Reaction outcome loss': 0.25566705513536336, 'Total loss': 0.25566705513536336}
2022-12-31 13:23:56,034 INFO:     Found new best model at epoch 65
2022-12-31 13:23:56,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:56,035 INFO:     Epoch: 66
2022-12-31 13:23:57,664 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45543710390726727, 'Total loss': 0.45543710390726727} | train loss {'Reaction outcome loss': 0.2521236295258437, 'Total loss': 0.2521236295258437}
2022-12-31 13:23:57,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:57,664 INFO:     Epoch: 67
2022-12-31 13:23:59,289 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4330009579658508, 'Total loss': 0.4330009579658508} | train loss {'Reaction outcome loss': 0.24877287478454452, 'Total loss': 0.24877287478454452}
2022-12-31 13:23:59,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:23:59,290 INFO:     Epoch: 68
2022-12-31 13:24:00,941 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45229193369547527, 'Total loss': 0.45229193369547527} | train loss {'Reaction outcome loss': 0.2482727980274923, 'Total loss': 0.2482727980274923}
2022-12-31 13:24:00,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:00,941 INFO:     Epoch: 69
2022-12-31 13:24:02,579 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40741513172785443, 'Total loss': 0.40741513172785443} | train loss {'Reaction outcome loss': 0.2564945848274004, 'Total loss': 0.2564945848274004}
2022-12-31 13:24:02,580 INFO:     Found new best model at epoch 69
2022-12-31 13:24:02,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:02,580 INFO:     Epoch: 70
2022-12-31 13:24:04,196 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4482809449235598, 'Total loss': 0.4482809449235598} | train loss {'Reaction outcome loss': 0.24872787335070956, 'Total loss': 0.24872787335070956}
2022-12-31 13:24:04,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:04,197 INFO:     Epoch: 71
2022-12-31 13:24:05,804 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4755520204703013, 'Total loss': 0.4755520204703013} | train loss {'Reaction outcome loss': 0.24293264756156335, 'Total loss': 0.24293264756156335}
2022-12-31 13:24:05,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:05,805 INFO:     Epoch: 72
2022-12-31 13:24:07,438 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4488736112912496, 'Total loss': 0.4488736112912496} | train loss {'Reaction outcome loss': 0.24728642962872982, 'Total loss': 0.24728642962872982}
2022-12-31 13:24:07,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:07,438 INFO:     Epoch: 73
2022-12-31 13:24:09,063 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4550734351078669, 'Total loss': 0.4550734351078669} | train loss {'Reaction outcome loss': 0.24162076023133958, 'Total loss': 0.24162076023133958}
2022-12-31 13:24:09,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:09,063 INFO:     Epoch: 74
2022-12-31 13:24:10,709 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4441408554712931, 'Total loss': 0.4441408554712931} | train loss {'Reaction outcome loss': 0.24017694982456675, 'Total loss': 0.24017694982456675}
2022-12-31 13:24:10,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:10,710 INFO:     Epoch: 75
2022-12-31 13:24:12,336 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4190786192814509, 'Total loss': 0.4190786192814509} | train loss {'Reaction outcome loss': 0.2395976484462997, 'Total loss': 0.2395976484462997}
2022-12-31 13:24:12,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:12,337 INFO:     Epoch: 76
2022-12-31 13:24:13,948 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4342535763978958, 'Total loss': 0.4342535763978958} | train loss {'Reaction outcome loss': 0.23295360654816066, 'Total loss': 0.23295360654816066}
2022-12-31 13:24:13,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:13,948 INFO:     Epoch: 77
2022-12-31 13:24:15,559 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4248499164978663, 'Total loss': 0.4248499164978663} | train loss {'Reaction outcome loss': 0.23919119617135765, 'Total loss': 0.23919119617135765}
2022-12-31 13:24:15,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:15,559 INFO:     Epoch: 78
2022-12-31 13:24:17,149 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4617016166448593, 'Total loss': 0.4617016166448593} | train loss {'Reaction outcome loss': 0.2446085657870424, 'Total loss': 0.2446085657870424}
2022-12-31 13:24:17,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:17,149 INFO:     Epoch: 79
2022-12-31 13:24:18,768 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4670459508895874, 'Total loss': 0.4670459508895874} | train loss {'Reaction outcome loss': 0.2665162180158971, 'Total loss': 0.2665162180158971}
2022-12-31 13:24:18,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:18,769 INFO:     Epoch: 80
2022-12-31 13:24:20,400 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4313494250178337, 'Total loss': 0.4313494250178337} | train loss {'Reaction outcome loss': 0.2607467973080086, 'Total loss': 0.2607467973080086}
2022-12-31 13:24:20,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:20,401 INFO:     Epoch: 81
2022-12-31 13:24:21,998 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43492252826690675, 'Total loss': 0.43492252826690675} | train loss {'Reaction outcome loss': 0.23696640881277836, 'Total loss': 0.23696640881277836}
2022-12-31 13:24:21,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:21,998 INFO:     Epoch: 82
2022-12-31 13:24:23,606 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4269289235273997, 'Total loss': 0.4269289235273997} | train loss {'Reaction outcome loss': 0.24472140141533336, 'Total loss': 0.24472140141533336}
2022-12-31 13:24:23,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:23,607 INFO:     Epoch: 83
2022-12-31 13:24:25,222 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4730774939060211, 'Total loss': 0.4730774939060211} | train loss {'Reaction outcome loss': 0.24754890698460402, 'Total loss': 0.24754890698460402}
2022-12-31 13:24:25,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:25,222 INFO:     Epoch: 84
2022-12-31 13:24:26,821 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4389355182647705, 'Total loss': 0.4389355182647705} | train loss {'Reaction outcome loss': 0.22539238543401513, 'Total loss': 0.22539238543401513}
2022-12-31 13:24:26,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:26,821 INFO:     Epoch: 85
2022-12-31 13:24:28,457 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4473193347454071, 'Total loss': 0.4473193347454071} | train loss {'Reaction outcome loss': 0.22996184541725728, 'Total loss': 0.22996184541725728}
2022-12-31 13:24:28,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:28,457 INFO:     Epoch: 86
2022-12-31 13:24:30,090 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41783535679181416, 'Total loss': 0.41783535679181416} | train loss {'Reaction outcome loss': 0.22845222442613347, 'Total loss': 0.22845222442613347}
2022-12-31 13:24:30,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:30,090 INFO:     Epoch: 87
2022-12-31 13:24:31,690 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4529879023631414, 'Total loss': 0.4529879023631414} | train loss {'Reaction outcome loss': 0.2237866294462288, 'Total loss': 0.2237866294462288}
2022-12-31 13:24:31,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:31,691 INFO:     Epoch: 88
2022-12-31 13:24:33,301 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42644810676574707, 'Total loss': 0.42644810676574707} | train loss {'Reaction outcome loss': 0.2574288987662589, 'Total loss': 0.2574288987662589}
2022-12-31 13:24:33,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:33,301 INFO:     Epoch: 89
2022-12-31 13:24:34,894 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43801347017288206, 'Total loss': 0.43801347017288206} | train loss {'Reaction outcome loss': 0.2435483269636398, 'Total loss': 0.2435483269636398}
2022-12-31 13:24:34,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:34,895 INFO:     Epoch: 90
2022-12-31 13:24:36,508 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4444894591967265, 'Total loss': 0.4444894591967265} | train loss {'Reaction outcome loss': 0.253063186033008, 'Total loss': 0.253063186033008}
2022-12-31 13:24:36,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:36,509 INFO:     Epoch: 91
2022-12-31 13:24:38,132 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43342867493629456, 'Total loss': 0.43342867493629456} | train loss {'Reaction outcome loss': 0.23282808430182436, 'Total loss': 0.23282808430182436}
2022-12-31 13:24:38,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:38,132 INFO:     Epoch: 92
2022-12-31 13:24:39,732 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4103214425345262, 'Total loss': 0.4103214425345262} | train loss {'Reaction outcome loss': 0.2219692891433268, 'Total loss': 0.2219692891433268}
2022-12-31 13:24:39,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:39,732 INFO:     Epoch: 93
2022-12-31 13:24:41,353 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48011403580506645, 'Total loss': 0.48011403580506645} | train loss {'Reaction outcome loss': 0.22074430931082833, 'Total loss': 0.22074430931082833}
2022-12-31 13:24:41,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:41,354 INFO:     Epoch: 94
2022-12-31 13:24:42,964 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.452176171541214, 'Total loss': 0.452176171541214} | train loss {'Reaction outcome loss': 0.22241171322968803, 'Total loss': 0.22241171322968803}
2022-12-31 13:24:42,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:42,964 INFO:     Epoch: 95
2022-12-31 13:24:44,563 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47761704921722414, 'Total loss': 0.47761704921722414} | train loss {'Reaction outcome loss': 0.2175725872385437, 'Total loss': 0.2175725872385437}
2022-12-31 13:24:44,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:44,563 INFO:     Epoch: 96
2022-12-31 13:24:46,170 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4399065593878428, 'Total loss': 0.4399065593878428} | train loss {'Reaction outcome loss': 0.2198833792680344, 'Total loss': 0.2198833792680344}
2022-12-31 13:24:46,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:46,170 INFO:     Epoch: 97
2022-12-31 13:24:47,784 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4554088721672694, 'Total loss': 0.4554088721672694} | train loss {'Reaction outcome loss': 0.2158840905134296, 'Total loss': 0.2158840905134296}
2022-12-31 13:24:47,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:47,784 INFO:     Epoch: 98
2022-12-31 13:24:49,396 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5166762888431549, 'Total loss': 0.5166762888431549} | train loss {'Reaction outcome loss': 0.21465789600662663, 'Total loss': 0.21465789600662663}
2022-12-31 13:24:49,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:49,397 INFO:     Epoch: 99
2022-12-31 13:24:51,010 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40868736803531647, 'Total loss': 0.40868736803531647} | train loss {'Reaction outcome loss': 0.21484171636942503, 'Total loss': 0.21484171636942503}
2022-12-31 13:24:51,010 INFO:     Best model found after epoch 70 of 100.
2022-12-31 13:24:51,010 INFO:   Done with stage: TRAINING
2022-12-31 13:24:51,010 INFO:   Starting stage: EVALUATION
2022-12-31 13:24:51,140 INFO:   Done with stage: EVALUATION
2022-12-31 13:24:51,140 INFO:   Leaving out SEQ value Fold_7
2022-12-31 13:24:51,153 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 13:24:51,153 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:24:51,808 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:24:51,808 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:24:51,879 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:24:51,879 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:24:51,879 INFO:     No hyperparam tuning for this model
2022-12-31 13:24:51,879 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:24:51,879 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:24:51,880 INFO:     None feature selector for col prot
2022-12-31 13:24:51,880 INFO:     None feature selector for col prot
2022-12-31 13:24:51,880 INFO:     None feature selector for col prot
2022-12-31 13:24:51,881 INFO:     None feature selector for col chem
2022-12-31 13:24:51,881 INFO:     None feature selector for col chem
2022-12-31 13:24:51,881 INFO:     None feature selector for col chem
2022-12-31 13:24:51,881 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:24:51,881 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:24:51,883 INFO:     Number of params in model 223921
2022-12-31 13:24:51,886 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:24:51,886 INFO:   Starting stage: TRAINING
2022-12-31 13:24:51,932 INFO:     Val loss before train {'Reaction outcome loss': 1.0429510116577148, 'Total loss': 1.0429510116577148}
2022-12-31 13:24:51,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:51,933 INFO:     Epoch: 0
2022-12-31 13:24:53,540 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7652421077092488, 'Total loss': 0.7652421077092488} | train loss {'Reaction outcome loss': 0.8057841098050348, 'Total loss': 0.8057841098050348}
2022-12-31 13:24:53,541 INFO:     Found new best model at epoch 0
2022-12-31 13:24:53,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:53,542 INFO:     Epoch: 1
2022-12-31 13:24:55,156 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.564812958240509, 'Total loss': 0.564812958240509} | train loss {'Reaction outcome loss': 0.5854341266710406, 'Total loss': 0.5854341266710406}
2022-12-31 13:24:55,156 INFO:     Found new best model at epoch 1
2022-12-31 13:24:55,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:55,157 INFO:     Epoch: 2
2022-12-31 13:24:56,773 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5064752002557119, 'Total loss': 0.5064752002557119} | train loss {'Reaction outcome loss': 0.5257415010825822, 'Total loss': 0.5257415010825822}
2022-12-31 13:24:56,773 INFO:     Found new best model at epoch 2
2022-12-31 13:24:56,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:56,774 INFO:     Epoch: 3
2022-12-31 13:24:58,388 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5586213707923889, 'Total loss': 0.5586213707923889} | train loss {'Reaction outcome loss': 0.5005098115182095, 'Total loss': 0.5005098115182095}
2022-12-31 13:24:58,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:24:58,388 INFO:     Epoch: 4
2022-12-31 13:25:00,031 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5134900689125061, 'Total loss': 0.5134900689125061} | train loss {'Reaction outcome loss': 0.49044691483466635, 'Total loss': 0.49044691483466635}
2022-12-31 13:25:00,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:00,032 INFO:     Epoch: 5
2022-12-31 13:25:01,680 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49296435912450154, 'Total loss': 0.49296435912450154} | train loss {'Reaction outcome loss': 0.4748164677340201, 'Total loss': 0.4748164677340201}
2022-12-31 13:25:01,680 INFO:     Found new best model at epoch 5
2022-12-31 13:25:01,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:01,681 INFO:     Epoch: 6
2022-12-31 13:25:03,304 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5277690728505452, 'Total loss': 0.5277690728505452} | train loss {'Reaction outcome loss': 0.4664170644128366, 'Total loss': 0.4664170644128366}
2022-12-31 13:25:03,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:03,304 INFO:     Epoch: 7
2022-12-31 13:25:04,922 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5028472125530243, 'Total loss': 0.5028472125530243} | train loss {'Reaction outcome loss': 0.4573240277192653, 'Total loss': 0.4573240277192653}
2022-12-31 13:25:04,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:04,922 INFO:     Epoch: 8
2022-12-31 13:25:06,522 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4941535194714864, 'Total loss': 0.4941535194714864} | train loss {'Reaction outcome loss': 0.44831923328151774, 'Total loss': 0.44831923328151774}
2022-12-31 13:25:06,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:06,522 INFO:     Epoch: 9
2022-12-31 13:25:08,172 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48589128255844116, 'Total loss': 0.48589128255844116} | train loss {'Reaction outcome loss': 0.44324780527219876, 'Total loss': 0.44324780527219876}
2022-12-31 13:25:08,172 INFO:     Found new best model at epoch 9
2022-12-31 13:25:08,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:08,173 INFO:     Epoch: 10
2022-12-31 13:25:09,811 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49927669564882915, 'Total loss': 0.49927669564882915} | train loss {'Reaction outcome loss': 0.4394207482195933, 'Total loss': 0.4394207482195933}
2022-12-31 13:25:09,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:09,813 INFO:     Epoch: 11
2022-12-31 13:25:11,419 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.481332861383756, 'Total loss': 0.481332861383756} | train loss {'Reaction outcome loss': 0.43046573154117224, 'Total loss': 0.43046573154117224}
2022-12-31 13:25:11,419 INFO:     Found new best model at epoch 11
2022-12-31 13:25:11,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:11,420 INFO:     Epoch: 12
2022-12-31 13:25:13,034 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45676560600598654, 'Total loss': 0.45676560600598654} | train loss {'Reaction outcome loss': 0.4258211624643863, 'Total loss': 0.4258211624643863}
2022-12-31 13:25:13,034 INFO:     Found new best model at epoch 12
2022-12-31 13:25:13,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:13,035 INFO:     Epoch: 13
2022-12-31 13:25:14,649 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4884980301062266, 'Total loss': 0.4884980301062266} | train loss {'Reaction outcome loss': 0.4195288692194202, 'Total loss': 0.4195288692194202}
2022-12-31 13:25:14,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:14,649 INFO:     Epoch: 14
2022-12-31 13:25:16,273 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4669940193494161, 'Total loss': 0.4669940193494161} | train loss {'Reaction outcome loss': 0.40683158753365817, 'Total loss': 0.40683158753365817}
2022-12-31 13:25:16,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:16,274 INFO:     Epoch: 15
2022-12-31 13:25:17,891 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4734418272972107, 'Total loss': 0.4734418272972107} | train loss {'Reaction outcome loss': 0.40454271755816706, 'Total loss': 0.40454271755816706}
2022-12-31 13:25:17,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:17,892 INFO:     Epoch: 16
2022-12-31 13:25:19,508 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4715203722318014, 'Total loss': 0.4715203722318014} | train loss {'Reaction outcome loss': 0.40072782057932566, 'Total loss': 0.40072782057932566}
2022-12-31 13:25:19,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:19,508 INFO:     Epoch: 17
2022-12-31 13:25:21,119 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44232472678025564, 'Total loss': 0.44232472678025564} | train loss {'Reaction outcome loss': 0.3925878743940312, 'Total loss': 0.3925878743940312}
2022-12-31 13:25:21,119 INFO:     Found new best model at epoch 17
2022-12-31 13:25:21,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:21,120 INFO:     Epoch: 18
2022-12-31 13:25:22,736 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4474351356426875, 'Total loss': 0.4474351356426875} | train loss {'Reaction outcome loss': 0.39025540614924276, 'Total loss': 0.39025540614924276}
2022-12-31 13:25:22,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:22,737 INFO:     Epoch: 19
2022-12-31 13:25:24,341 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4675893634557724, 'Total loss': 0.4675893634557724} | train loss {'Reaction outcome loss': 0.3812772996911934, 'Total loss': 0.3812772996911934}
2022-12-31 13:25:24,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:24,341 INFO:     Epoch: 20
2022-12-31 13:25:25,960 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43980871538321176, 'Total loss': 0.43980871538321176} | train loss {'Reaction outcome loss': 0.37791952271592744, 'Total loss': 0.37791952271592744}
2022-12-31 13:25:25,960 INFO:     Found new best model at epoch 20
2022-12-31 13:25:25,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:25,961 INFO:     Epoch: 21
2022-12-31 13:25:27,576 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4454050292571386, 'Total loss': 0.4454050292571386} | train loss {'Reaction outcome loss': 0.37103934970680985, 'Total loss': 0.37103934970680985}
2022-12-31 13:25:27,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:27,577 INFO:     Epoch: 22
2022-12-31 13:25:29,168 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44310321609179176, 'Total loss': 0.44310321609179176} | train loss {'Reaction outcome loss': 0.36825868576119525, 'Total loss': 0.36825868576119525}
2022-12-31 13:25:29,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:29,169 INFO:     Epoch: 23
2022-12-31 13:25:30,814 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4554121394952138, 'Total loss': 0.4554121394952138} | train loss {'Reaction outcome loss': 0.3635449954964194, 'Total loss': 0.3635449954964194}
2022-12-31 13:25:30,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:30,815 INFO:     Epoch: 24
2022-12-31 13:25:32,460 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43653141856193545, 'Total loss': 0.43653141856193545} | train loss {'Reaction outcome loss': 0.36020868215104734, 'Total loss': 0.36020868215104734}
2022-12-31 13:25:32,460 INFO:     Found new best model at epoch 24
2022-12-31 13:25:32,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:32,461 INFO:     Epoch: 25
2022-12-31 13:25:34,097 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47407461404800416, 'Total loss': 0.47407461404800416} | train loss {'Reaction outcome loss': 0.3515753814217631, 'Total loss': 0.3515753814217631}
2022-12-31 13:25:34,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:34,097 INFO:     Epoch: 26
2022-12-31 13:25:35,716 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45342875917752584, 'Total loss': 0.45342875917752584} | train loss {'Reaction outcome loss': 0.34729827340651936, 'Total loss': 0.34729827340651936}
2022-12-31 13:25:35,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:35,716 INFO:     Epoch: 27
2022-12-31 13:25:37,336 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4545307636260986, 'Total loss': 0.4545307636260986} | train loss {'Reaction outcome loss': 0.34400069767387337, 'Total loss': 0.34400069767387337}
2022-12-31 13:25:37,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:37,336 INFO:     Epoch: 28
2022-12-31 13:25:38,947 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40727295478185016, 'Total loss': 0.40727295478185016} | train loss {'Reaction outcome loss': 0.3383351041118376, 'Total loss': 0.3383351041118376}
2022-12-31 13:25:38,947 INFO:     Found new best model at epoch 28
2022-12-31 13:25:38,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:38,948 INFO:     Epoch: 29
2022-12-31 13:25:40,599 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4068966706593831, 'Total loss': 0.4068966706593831} | train loss {'Reaction outcome loss': 0.3298190686219651, 'Total loss': 0.3298190686219651}
2022-12-31 13:25:40,599 INFO:     Found new best model at epoch 29
2022-12-31 13:25:40,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:40,600 INFO:     Epoch: 30
2022-12-31 13:25:42,252 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4271576722462972, 'Total loss': 0.4271576722462972} | train loss {'Reaction outcome loss': 0.3295785218531044, 'Total loss': 0.3295785218531044}
2022-12-31 13:25:42,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:42,252 INFO:     Epoch: 31
2022-12-31 13:25:43,876 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42819261153539023, 'Total loss': 0.42819261153539023} | train loss {'Reaction outcome loss': 0.32294941938310756, 'Total loss': 0.32294941938310756}
2022-12-31 13:25:43,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:43,877 INFO:     Epoch: 32
2022-12-31 13:25:45,487 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.435333389043808, 'Total loss': 0.435333389043808} | train loss {'Reaction outcome loss': 0.32194411238178017, 'Total loss': 0.32194411238178017}
2022-12-31 13:25:45,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:45,488 INFO:     Epoch: 33
2022-12-31 13:25:47,104 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4330825517574946, 'Total loss': 0.4330825517574946} | train loss {'Reaction outcome loss': 0.3144963826002412, 'Total loss': 0.3144963826002412}
2022-12-31 13:25:47,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:47,105 INFO:     Epoch: 34
2022-12-31 13:25:48,729 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4209186196327209, 'Total loss': 0.4209186196327209} | train loss {'Reaction outcome loss': 0.3128070586801436, 'Total loss': 0.3128070586801436}
2022-12-31 13:25:48,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:48,729 INFO:     Epoch: 35
2022-12-31 13:25:50,346 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3971657812595367, 'Total loss': 0.3971657812595367} | train loss {'Reaction outcome loss': 0.3076007997193491, 'Total loss': 0.3076007997193491}
2022-12-31 13:25:50,346 INFO:     Found new best model at epoch 35
2022-12-31 13:25:50,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:50,347 INFO:     Epoch: 36
2022-12-31 13:25:51,947 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4369517147541046, 'Total loss': 0.4369517147541046} | train loss {'Reaction outcome loss': 0.30029193922500746, 'Total loss': 0.30029193922500746}
2022-12-31 13:25:51,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:51,947 INFO:     Epoch: 37
2022-12-31 13:25:53,566 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43199206789334615, 'Total loss': 0.43199206789334615} | train loss {'Reaction outcome loss': 0.30026226918404714, 'Total loss': 0.30026226918404714}
2022-12-31 13:25:53,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:53,566 INFO:     Epoch: 38
2022-12-31 13:25:55,204 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4003284603357315, 'Total loss': 0.4003284603357315} | train loss {'Reaction outcome loss': 0.2937799879359855, 'Total loss': 0.2937799879359855}
2022-12-31 13:25:55,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:55,204 INFO:     Epoch: 39
2022-12-31 13:25:56,813 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43318668703238167, 'Total loss': 0.43318668703238167} | train loss {'Reaction outcome loss': 0.29517310949223996, 'Total loss': 0.29517310949223996}
2022-12-31 13:25:56,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:56,813 INFO:     Epoch: 40
2022-12-31 13:25:58,428 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39437060058116913, 'Total loss': 0.39437060058116913} | train loss {'Reaction outcome loss': 0.28815455698418274, 'Total loss': 0.28815455698418274}
2022-12-31 13:25:58,428 INFO:     Found new best model at epoch 40
2022-12-31 13:25:58,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:25:58,429 INFO:     Epoch: 41
2022-12-31 13:26:00,076 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46409960091114044, 'Total loss': 0.46409960091114044} | train loss {'Reaction outcome loss': 0.2792032166562356, 'Total loss': 0.2792032166562356}
2022-12-31 13:26:00,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:00,076 INFO:     Epoch: 42
2022-12-31 13:26:01,675 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4157290130853653, 'Total loss': 0.4157290130853653} | train loss {'Reaction outcome loss': 0.28347893726309287, 'Total loss': 0.28347893726309287}
2022-12-31 13:26:01,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:01,676 INFO:     Epoch: 43
2022-12-31 13:26:03,291 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4010179440180461, 'Total loss': 0.4010179440180461} | train loss {'Reaction outcome loss': 0.27780366867834483, 'Total loss': 0.27780366867834483}
2022-12-31 13:26:03,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:03,291 INFO:     Epoch: 44
2022-12-31 13:26:04,909 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.418128576874733, 'Total loss': 0.418128576874733} | train loss {'Reaction outcome loss': 0.2749576493492518, 'Total loss': 0.2749576493492518}
2022-12-31 13:26:04,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:04,909 INFO:     Epoch: 45
2022-12-31 13:26:06,513 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4120417912801107, 'Total loss': 0.4120417912801107} | train loss {'Reaction outcome loss': 0.2720455347361978, 'Total loss': 0.2720455347361978}
2022-12-31 13:26:06,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:06,514 INFO:     Epoch: 46
2022-12-31 13:26:08,146 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43856614232063296, 'Total loss': 0.43856614232063296} | train loss {'Reaction outcome loss': 0.26779711754851393, 'Total loss': 0.26779711754851393}
2022-12-31 13:26:08,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:08,146 INFO:     Epoch: 47
2022-12-31 13:26:09,779 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4239716420571009, 'Total loss': 0.4239716420571009} | train loss {'Reaction outcome loss': 0.2614478598405953, 'Total loss': 0.2614478598405953}
2022-12-31 13:26:09,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:09,779 INFO:     Epoch: 48
2022-12-31 13:26:11,396 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38665140569210055, 'Total loss': 0.38665140569210055} | train loss {'Reaction outcome loss': 0.27014408045404653, 'Total loss': 0.27014408045404653}
2022-12-31 13:26:11,396 INFO:     Found new best model at epoch 48
2022-12-31 13:26:11,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:11,397 INFO:     Epoch: 49
2022-12-31 13:26:13,018 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42410281201203665, 'Total loss': 0.42410281201203665} | train loss {'Reaction outcome loss': 0.25881309389045953, 'Total loss': 0.25881309389045953}
2022-12-31 13:26:13,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:13,018 INFO:     Epoch: 50
2022-12-31 13:26:14,603 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45145061016082766, 'Total loss': 0.45145061016082766} | train loss {'Reaction outcome loss': 0.2561103835406071, 'Total loss': 0.2561103835406071}
2022-12-31 13:26:14,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:14,603 INFO:     Epoch: 51
2022-12-31 13:26:16,218 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4128005842367808, 'Total loss': 0.4128005842367808} | train loss {'Reaction outcome loss': 0.2577271057017121, 'Total loss': 0.2577271057017121}
2022-12-31 13:26:16,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:16,218 INFO:     Epoch: 52
2022-12-31 13:26:17,840 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4641510794560115, 'Total loss': 0.4641510794560115} | train loss {'Reaction outcome loss': 0.2589046708997406, 'Total loss': 0.2589046708997406}
2022-12-31 13:26:17,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:17,840 INFO:     Epoch: 53
2022-12-31 13:26:19,442 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4040582825740178, 'Total loss': 0.4040582825740178} | train loss {'Reaction outcome loss': 0.24829921727522616, 'Total loss': 0.24829921727522616}
2022-12-31 13:26:19,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:19,442 INFO:     Epoch: 54
2022-12-31 13:26:21,066 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44109506607055665, 'Total loss': 0.44109506607055665} | train loss {'Reaction outcome loss': 0.24491973300649372, 'Total loss': 0.24491973300649372}
2022-12-31 13:26:21,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:21,066 INFO:     Epoch: 55
2022-12-31 13:26:22,709 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4213568389415741, 'Total loss': 0.4213568389415741} | train loss {'Reaction outcome loss': 0.24445696859637323, 'Total loss': 0.24445696859637323}
2022-12-31 13:26:22,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:22,710 INFO:     Epoch: 56
2022-12-31 13:26:24,327 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42890312472979225, 'Total loss': 0.42890312472979225} | train loss {'Reaction outcome loss': 0.2466499927631892, 'Total loss': 0.2466499927631892}
2022-12-31 13:26:24,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:24,328 INFO:     Epoch: 57
2022-12-31 13:26:25,958 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3998588147262732, 'Total loss': 0.3998588147262732} | train loss {'Reaction outcome loss': 0.2420443240620384, 'Total loss': 0.2420443240620384}
2022-12-31 13:26:25,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:25,959 INFO:     Epoch: 58
2022-12-31 13:26:27,584 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38292580246925356, 'Total loss': 0.38292580246925356} | train loss {'Reaction outcome loss': 0.23457325062973405, 'Total loss': 0.23457325062973405}
2022-12-31 13:26:27,584 INFO:     Found new best model at epoch 58
2022-12-31 13:26:27,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:27,585 INFO:     Epoch: 59
2022-12-31 13:26:28,740 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4232084512710571, 'Total loss': 0.4232084512710571} | train loss {'Reaction outcome loss': 0.2378031844777536, 'Total loss': 0.2378031844777536}
2022-12-31 13:26:28,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:28,741 INFO:     Epoch: 60
2022-12-31 13:26:29,826 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42690915763378146, 'Total loss': 0.42690915763378146} | train loss {'Reaction outcome loss': 0.24035038115181, 'Total loss': 0.24035038115181}
2022-12-31 13:26:29,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:29,826 INFO:     Epoch: 61
2022-12-31 13:26:30,917 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4272553394238154, 'Total loss': 0.4272553394238154} | train loss {'Reaction outcome loss': 0.23384083430904773, 'Total loss': 0.23384083430904773}
2022-12-31 13:26:30,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:30,917 INFO:     Epoch: 62
2022-12-31 13:26:32,004 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4146894057591756, 'Total loss': 0.4146894057591756} | train loss {'Reaction outcome loss': 0.23766983806118638, 'Total loss': 0.23766983806118638}
2022-12-31 13:26:32,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:32,004 INFO:     Epoch: 63
2022-12-31 13:26:33,457 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.412230384349823, 'Total loss': 0.412230384349823} | train loss {'Reaction outcome loss': 0.22694842116604644, 'Total loss': 0.22694842116604644}
2022-12-31 13:26:33,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:33,457 INFO:     Epoch: 64
2022-12-31 13:26:35,085 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4325385371843974, 'Total loss': 0.4325385371843974} | train loss {'Reaction outcome loss': 0.23817920847207524, 'Total loss': 0.23817920847207524}
2022-12-31 13:26:35,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:35,085 INFO:     Epoch: 65
2022-12-31 13:26:36,706 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3848067094882329, 'Total loss': 0.3848067094882329} | train loss {'Reaction outcome loss': 0.22695528647260546, 'Total loss': 0.22695528647260546}
2022-12-31 13:26:36,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:36,706 INFO:     Epoch: 66
2022-12-31 13:26:38,340 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4382535378138224, 'Total loss': 0.4382535378138224} | train loss {'Reaction outcome loss': 0.2270974700577853, 'Total loss': 0.2270974700577853}
2022-12-31 13:26:38,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:38,340 INFO:     Epoch: 67
2022-12-31 13:26:39,974 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.438247482975324, 'Total loss': 0.438247482975324} | train loss {'Reaction outcome loss': 0.22925399748830375, 'Total loss': 0.22925399748830375}
2022-12-31 13:26:39,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:39,974 INFO:     Epoch: 68
2022-12-31 13:26:41,580 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3968849976857503, 'Total loss': 0.3968849976857503} | train loss {'Reaction outcome loss': 0.22411595610397386, 'Total loss': 0.22411595610397386}
2022-12-31 13:26:41,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:41,580 INFO:     Epoch: 69
2022-12-31 13:26:43,208 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46021878321965537, 'Total loss': 0.46021878321965537} | train loss {'Reaction outcome loss': 0.22148797324176084, 'Total loss': 0.22148797324176084}
2022-12-31 13:26:43,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:43,209 INFO:     Epoch: 70
2022-12-31 13:26:44,835 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4014798348148664, 'Total loss': 0.4014798348148664} | train loss {'Reaction outcome loss': 0.22791470485715876, 'Total loss': 0.22791470485715876}
2022-12-31 13:26:44,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:44,836 INFO:     Epoch: 71
2022-12-31 13:26:46,454 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4354212393363317, 'Total loss': 0.4354212393363317} | train loss {'Reaction outcome loss': 0.22541928785560578, 'Total loss': 0.22541928785560578}
2022-12-31 13:26:46,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:46,454 INFO:     Epoch: 72
2022-12-31 13:26:48,076 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4581717222929001, 'Total loss': 0.4581717222929001} | train loss {'Reaction outcome loss': 0.21908018980108013, 'Total loss': 0.21908018980108013}
2022-12-31 13:26:48,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:48,076 INFO:     Epoch: 73
2022-12-31 13:26:49,680 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4510475973288218, 'Total loss': 0.4510475973288218} | train loss {'Reaction outcome loss': 0.22139716961350467, 'Total loss': 0.22139716961350467}
2022-12-31 13:26:49,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:49,680 INFO:     Epoch: 74
2022-12-31 13:26:51,321 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4688092738389969, 'Total loss': 0.4688092738389969} | train loss {'Reaction outcome loss': 0.21592421970911835, 'Total loss': 0.21592421970911835}
2022-12-31 13:26:51,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:51,321 INFO:     Epoch: 75
2022-12-31 13:26:52,970 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4136978862186273, 'Total loss': 0.4136978862186273} | train loss {'Reaction outcome loss': 0.2233715109486765, 'Total loss': 0.2233715109486765}
2022-12-31 13:26:52,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:52,970 INFO:     Epoch: 76
2022-12-31 13:26:54,596 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4306280275185903, 'Total loss': 0.4306280275185903} | train loss {'Reaction outcome loss': 0.21522782617904218, 'Total loss': 0.21522782617904218}
2022-12-31 13:26:54,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:54,596 INFO:     Epoch: 77
2022-12-31 13:26:56,228 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4117870012919108, 'Total loss': 0.4117870012919108} | train loss {'Reaction outcome loss': 0.21496792213607996, 'Total loss': 0.21496792213607996}
2022-12-31 13:26:56,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:56,228 INFO:     Epoch: 78
2022-12-31 13:26:57,836 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4127912700176239, 'Total loss': 0.4127912700176239} | train loss {'Reaction outcome loss': 0.21519857808436513, 'Total loss': 0.21519857808436513}
2022-12-31 13:26:57,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:57,837 INFO:     Epoch: 79
2022-12-31 13:26:59,457 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4298151989777883, 'Total loss': 0.4298151989777883} | train loss {'Reaction outcome loss': 0.2127504819055972, 'Total loss': 0.2127504819055972}
2022-12-31 13:26:59,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:26:59,457 INFO:     Epoch: 80
2022-12-31 13:27:01,063 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4301511069138845, 'Total loss': 0.4301511069138845} | train loss {'Reaction outcome loss': 0.20824302993849297, 'Total loss': 0.20824302993849297}
2022-12-31 13:27:01,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:01,064 INFO:     Epoch: 81
2022-12-31 13:27:02,683 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4390266478061676, 'Total loss': 0.4390266478061676} | train loss {'Reaction outcome loss': 0.2113658485376017, 'Total loss': 0.2113658485376017}
2022-12-31 13:27:02,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:02,683 INFO:     Epoch: 82
2022-12-31 13:27:04,302 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4650914748509725, 'Total loss': 0.4650914748509725} | train loss {'Reaction outcome loss': 0.2117461392030604, 'Total loss': 0.2117461392030604}
2022-12-31 13:27:04,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:04,303 INFO:     Epoch: 83
2022-12-31 13:27:05,921 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44602725307146707, 'Total loss': 0.44602725307146707} | train loss {'Reaction outcome loss': 0.21295568921236785, 'Total loss': 0.21295568921236785}
2022-12-31 13:27:05,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:05,921 INFO:     Epoch: 84
2022-12-31 13:27:07,548 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4424525598684947, 'Total loss': 0.4424525598684947} | train loss {'Reaction outcome loss': 0.2053537134363548, 'Total loss': 0.2053537134363548}
2022-12-31 13:27:07,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:07,549 INFO:     Epoch: 85
2022-12-31 13:27:09,167 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44531364341576896, 'Total loss': 0.44531364341576896} | train loss {'Reaction outcome loss': 0.20487885175790596, 'Total loss': 0.20487885175790596}
2022-12-31 13:27:09,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:09,167 INFO:     Epoch: 86
2022-12-31 13:27:10,789 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42762838999430336, 'Total loss': 0.42762838999430336} | train loss {'Reaction outcome loss': 0.20980345452076585, 'Total loss': 0.20980345452076585}
2022-12-31 13:27:10,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:10,789 INFO:     Epoch: 87
2022-12-31 13:27:12,410 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4120075136423111, 'Total loss': 0.4120075136423111} | train loss {'Reaction outcome loss': 0.20099466865620028, 'Total loss': 0.20099466865620028}
2022-12-31 13:27:12,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:12,410 INFO:     Epoch: 88
2022-12-31 13:27:14,030 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39384636878967283, 'Total loss': 0.39384636878967283} | train loss {'Reaction outcome loss': 0.21487650745262524, 'Total loss': 0.21487650745262524}
2022-12-31 13:27:14,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:14,031 INFO:     Epoch: 89
2022-12-31 13:27:15,633 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43824096421400704, 'Total loss': 0.43824096421400704} | train loss {'Reaction outcome loss': 0.20152522280597085, 'Total loss': 0.20152522280597085}
2022-12-31 13:27:15,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:15,633 INFO:     Epoch: 90
2022-12-31 13:27:17,282 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45186736633380253, 'Total loss': 0.45186736633380253} | train loss {'Reaction outcome loss': 0.19866138583029005, 'Total loss': 0.19866138583029005}
2022-12-31 13:27:17,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:17,283 INFO:     Epoch: 91
2022-12-31 13:27:18,895 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4215322355429331, 'Total loss': 0.4215322355429331} | train loss {'Reaction outcome loss': 0.20427425882849667, 'Total loss': 0.20427425882849667}
2022-12-31 13:27:18,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:18,896 INFO:     Epoch: 92
2022-12-31 13:27:20,556 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41576836705207826, 'Total loss': 0.41576836705207826} | train loss {'Reaction outcome loss': 0.202532910212323, 'Total loss': 0.202532910212323}
2022-12-31 13:27:20,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:20,556 INFO:     Epoch: 93
2022-12-31 13:27:22,214 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4106135884920756, 'Total loss': 0.4106135884920756} | train loss {'Reaction outcome loss': 0.1966604439319794, 'Total loss': 0.1966604439319794}
2022-12-31 13:27:22,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:22,214 INFO:     Epoch: 94
2022-12-31 13:27:23,875 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4281584590673447, 'Total loss': 0.4281584590673447} | train loss {'Reaction outcome loss': 0.1998726962880645, 'Total loss': 0.1998726962880645}
2022-12-31 13:27:23,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:23,875 INFO:     Epoch: 95
2022-12-31 13:27:25,502 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44838664432366687, 'Total loss': 0.44838664432366687} | train loss {'Reaction outcome loss': 0.20260194645327137, 'Total loss': 0.20260194645327137}
2022-12-31 13:27:25,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:25,502 INFO:     Epoch: 96
2022-12-31 13:27:27,130 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4448902795712153, 'Total loss': 0.4448902795712153} | train loss {'Reaction outcome loss': 0.19892602048088068, 'Total loss': 0.19892602048088068}
2022-12-31 13:27:27,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:27,130 INFO:     Epoch: 97
2022-12-31 13:27:28,786 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4313397447268168, 'Total loss': 0.4313397447268168} | train loss {'Reaction outcome loss': 0.19712948448122194, 'Total loss': 0.19712948448122194}
2022-12-31 13:27:28,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:28,787 INFO:     Epoch: 98
2022-12-31 13:27:30,443 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4305956174929937, 'Total loss': 0.4305956174929937} | train loss {'Reaction outcome loss': 0.19023165964128094, 'Total loss': 0.19023165964128094}
2022-12-31 13:27:30,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:30,443 INFO:     Epoch: 99
2022-12-31 13:27:32,102 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46785903175671895, 'Total loss': 0.46785903175671895} | train loss {'Reaction outcome loss': 0.1989016828197811, 'Total loss': 0.1989016828197811}
2022-12-31 13:27:32,103 INFO:     Best model found after epoch 59 of 100.
2022-12-31 13:27:32,103 INFO:   Done with stage: TRAINING
2022-12-31 13:27:32,103 INFO:   Starting stage: EVALUATION
2022-12-31 13:27:32,227 INFO:   Done with stage: EVALUATION
2022-12-31 13:27:32,227 INFO:   Leaving out SEQ value Fold_8
2022-12-31 13:27:32,239 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 13:27:32,239 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:27:32,891 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:27:32,891 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:27:32,959 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:27:32,959 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:27:32,959 INFO:     No hyperparam tuning for this model
2022-12-31 13:27:32,959 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:27:32,959 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:27:32,960 INFO:     None feature selector for col prot
2022-12-31 13:27:32,960 INFO:     None feature selector for col prot
2022-12-31 13:27:32,960 INFO:     None feature selector for col prot
2022-12-31 13:27:32,961 INFO:     None feature selector for col chem
2022-12-31 13:27:32,961 INFO:     None feature selector for col chem
2022-12-31 13:27:32,961 INFO:     None feature selector for col chem
2022-12-31 13:27:32,961 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:27:32,961 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:27:32,963 INFO:     Number of params in model 223921
2022-12-31 13:27:32,966 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:27:32,966 INFO:   Starting stage: TRAINING
2022-12-31 13:27:33,011 INFO:     Val loss before train {'Reaction outcome loss': 1.0287371118863424, 'Total loss': 1.0287371118863424}
2022-12-31 13:27:33,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:33,011 INFO:     Epoch: 0
2022-12-31 13:27:34,596 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7182995518048604, 'Total loss': 0.7182995518048604} | train loss {'Reaction outcome loss': 0.8004670494642013, 'Total loss': 0.8004670494642013}
2022-12-31 13:27:34,596 INFO:     Found new best model at epoch 0
2022-12-31 13:27:34,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:34,597 INFO:     Epoch: 1
2022-12-31 13:27:36,174 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5545394579569499, 'Total loss': 0.5545394579569499} | train loss {'Reaction outcome loss': 0.5921356472776923, 'Total loss': 0.5921356472776923}
2022-12-31 13:27:36,174 INFO:     Found new best model at epoch 1
2022-12-31 13:27:36,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:36,175 INFO:     Epoch: 2
2022-12-31 13:27:37,769 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5451187709967296, 'Total loss': 0.5451187709967296} | train loss {'Reaction outcome loss': 0.5242740383624157, 'Total loss': 0.5242740383624157}
2022-12-31 13:27:37,769 INFO:     Found new best model at epoch 2
2022-12-31 13:27:37,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:37,770 INFO:     Epoch: 3
2022-12-31 13:27:39,362 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4970191478729248, 'Total loss': 0.4970191478729248} | train loss {'Reaction outcome loss': 0.5092973760960303, 'Total loss': 0.5092973760960303}
2022-12-31 13:27:39,362 INFO:     Found new best model at epoch 3
2022-12-31 13:27:39,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:39,363 INFO:     Epoch: 4
2022-12-31 13:27:40,955 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44866094483683505, 'Total loss': 0.44866094483683505} | train loss {'Reaction outcome loss': 0.48849546379877096, 'Total loss': 0.48849546379877096}
2022-12-31 13:27:40,955 INFO:     Found new best model at epoch 4
2022-12-31 13:27:40,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:40,956 INFO:     Epoch: 5
2022-12-31 13:27:42,548 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4648823400338491, 'Total loss': 0.4648823400338491} | train loss {'Reaction outcome loss': 0.47680126795129024, 'Total loss': 0.47680126795129024}
2022-12-31 13:27:42,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:42,549 INFO:     Epoch: 6
2022-12-31 13:27:44,134 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44910663763682046, 'Total loss': 0.44910663763682046} | train loss {'Reaction outcome loss': 0.4683843985909507, 'Total loss': 0.4683843985909507}
2022-12-31 13:27:44,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:44,135 INFO:     Epoch: 7
2022-12-31 13:27:45,738 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45343133608500164, 'Total loss': 0.45343133608500164} | train loss {'Reaction outcome loss': 0.4629800014006786, 'Total loss': 0.4629800014006786}
2022-12-31 13:27:45,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:45,738 INFO:     Epoch: 8
2022-12-31 13:27:47,321 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44850667715072634, 'Total loss': 0.44850667715072634} | train loss {'Reaction outcome loss': 0.4504944054826057, 'Total loss': 0.4504944054826057}
2022-12-31 13:27:47,321 INFO:     Found new best model at epoch 8
2022-12-31 13:27:47,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:47,322 INFO:     Epoch: 9
2022-12-31 13:27:48,945 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47162065903345746, 'Total loss': 0.47162065903345746} | train loss {'Reaction outcome loss': 0.44901887076350794, 'Total loss': 0.44901887076350794}
2022-12-31 13:27:48,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:48,946 INFO:     Epoch: 10
2022-12-31 13:27:50,520 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4594648281733195, 'Total loss': 0.4594648281733195} | train loss {'Reaction outcome loss': 0.4428426241263365, 'Total loss': 0.4428426241263365}
2022-12-31 13:27:50,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:50,521 INFO:     Epoch: 11
2022-12-31 13:27:52,124 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44010670979817706, 'Total loss': 0.44010670979817706} | train loss {'Reaction outcome loss': 0.43770965442552673, 'Total loss': 0.43770965442552673}
2022-12-31 13:27:52,124 INFO:     Found new best model at epoch 11
2022-12-31 13:27:52,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:52,125 INFO:     Epoch: 12
2022-12-31 13:27:53,692 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43356672724088036, 'Total loss': 0.43356672724088036} | train loss {'Reaction outcome loss': 0.4241656006583364, 'Total loss': 0.4241656006583364}
2022-12-31 13:27:53,692 INFO:     Found new best model at epoch 12
2022-12-31 13:27:53,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:53,693 INFO:     Epoch: 13
2022-12-31 13:27:55,277 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4309998542070389, 'Total loss': 0.4309998542070389} | train loss {'Reaction outcome loss': 0.4260758875490545, 'Total loss': 0.4260758875490545}
2022-12-31 13:27:55,277 INFO:     Found new best model at epoch 13
2022-12-31 13:27:55,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:55,278 INFO:     Epoch: 14
2022-12-31 13:27:56,867 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44145920475323996, 'Total loss': 0.44145920475323996} | train loss {'Reaction outcome loss': 0.4206164014208448, 'Total loss': 0.4206164014208448}
2022-12-31 13:27:56,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:56,867 INFO:     Epoch: 15
2022-12-31 13:27:58,456 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4478398154179255, 'Total loss': 0.4478398154179255} | train loss {'Reaction outcome loss': 0.4065920746929589, 'Total loss': 0.4065920746929589}
2022-12-31 13:27:58,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:27:58,456 INFO:     Epoch: 16
2022-12-31 13:28:00,046 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.439738271633784, 'Total loss': 0.439738271633784} | train loss {'Reaction outcome loss': 0.4059767803866348, 'Total loss': 0.4059767803866348}
2022-12-31 13:28:00,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:00,047 INFO:     Epoch: 17
2022-12-31 13:28:01,617 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4213549425204595, 'Total loss': 0.4213549425204595} | train loss {'Reaction outcome loss': 0.3965121567225418, 'Total loss': 0.3965121567225418}
2022-12-31 13:28:01,617 INFO:     Found new best model at epoch 17
2022-12-31 13:28:01,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:01,618 INFO:     Epoch: 18
2022-12-31 13:28:03,191 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.442793462673823, 'Total loss': 0.442793462673823} | train loss {'Reaction outcome loss': 0.3930701448858439, 'Total loss': 0.3930701448858439}
2022-12-31 13:28:03,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:03,191 INFO:     Epoch: 19
2022-12-31 13:28:04,781 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4202792505423228, 'Total loss': 0.4202792505423228} | train loss {'Reaction outcome loss': 0.38659402831788464, 'Total loss': 0.38659402831788464}
2022-12-31 13:28:04,781 INFO:     Found new best model at epoch 19
2022-12-31 13:28:04,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:04,782 INFO:     Epoch: 20
2022-12-31 13:28:06,369 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40918027112881344, 'Total loss': 0.40918027112881344} | train loss {'Reaction outcome loss': 0.38790283384886415, 'Total loss': 0.38790283384886415}
2022-12-31 13:28:06,370 INFO:     Found new best model at epoch 20
2022-12-31 13:28:06,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:06,371 INFO:     Epoch: 21
2022-12-31 13:28:07,959 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4225162883599599, 'Total loss': 0.4225162883599599} | train loss {'Reaction outcome loss': 0.3755487653225551, 'Total loss': 0.3755487653225551}
2022-12-31 13:28:07,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:07,959 INFO:     Epoch: 22
2022-12-31 13:28:09,532 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42578908105691277, 'Total loss': 0.42578908105691277} | train loss {'Reaction outcome loss': 0.3700448502496485, 'Total loss': 0.3700448502496485}
2022-12-31 13:28:09,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:09,532 INFO:     Epoch: 23
2022-12-31 13:28:11,115 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42033769289652506, 'Total loss': 0.42033769289652506} | train loss {'Reaction outcome loss': 0.3686840509067907, 'Total loss': 0.3686840509067907}
2022-12-31 13:28:11,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:11,115 INFO:     Epoch: 24
2022-12-31 13:28:12,691 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39151400327682495, 'Total loss': 0.39151400327682495} | train loss {'Reaction outcome loss': 0.36247848327213644, 'Total loss': 0.36247848327213644}
2022-12-31 13:28:12,691 INFO:     Found new best model at epoch 24
2022-12-31 13:28:12,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:12,692 INFO:     Epoch: 25
2022-12-31 13:28:14,278 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4189252634843191, 'Total loss': 0.4189252634843191} | train loss {'Reaction outcome loss': 0.36513471090313276, 'Total loss': 0.36513471090313276}
2022-12-31 13:28:14,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:14,279 INFO:     Epoch: 26
2022-12-31 13:28:15,867 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3799755245447159, 'Total loss': 0.3799755245447159} | train loss {'Reaction outcome loss': 0.35315715353390126, 'Total loss': 0.35315715353390126}
2022-12-31 13:28:15,867 INFO:     Found new best model at epoch 26
2022-12-31 13:28:15,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:15,868 INFO:     Epoch: 27
2022-12-31 13:28:17,469 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4225769211848577, 'Total loss': 0.4225769211848577} | train loss {'Reaction outcome loss': 0.35176667453714344, 'Total loss': 0.35176667453714344}
2022-12-31 13:28:17,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:17,469 INFO:     Epoch: 28
2022-12-31 13:28:19,055 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.387641574939092, 'Total loss': 0.387641574939092} | train loss {'Reaction outcome loss': 0.3454033952383768, 'Total loss': 0.3454033952383768}
2022-12-31 13:28:19,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:19,056 INFO:     Epoch: 29
2022-12-31 13:28:20,653 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41488527655601504, 'Total loss': 0.41488527655601504} | train loss {'Reaction outcome loss': 0.3467437002685044, 'Total loss': 0.3467437002685044}
2022-12-31 13:28:20,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:20,653 INFO:     Epoch: 30
2022-12-31 13:28:22,270 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38014281789461773, 'Total loss': 0.38014281789461773} | train loss {'Reaction outcome loss': 0.33494377065272557, 'Total loss': 0.33494377065272557}
2022-12-31 13:28:22,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:22,270 INFO:     Epoch: 31
2022-12-31 13:28:23,846 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3521391830717524, 'Total loss': 0.3521391830717524} | train loss {'Reaction outcome loss': 0.3353069911509643, 'Total loss': 0.3353069911509643}
2022-12-31 13:28:23,846 INFO:     Found new best model at epoch 31
2022-12-31 13:28:23,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:23,847 INFO:     Epoch: 32
2022-12-31 13:28:25,430 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3646871566772461, 'Total loss': 0.3646871566772461} | train loss {'Reaction outcome loss': 0.3256160724949051, 'Total loss': 0.3256160724949051}
2022-12-31 13:28:25,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:25,430 INFO:     Epoch: 33
2022-12-31 13:28:27,063 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3977094113826752, 'Total loss': 0.3977094113826752} | train loss {'Reaction outcome loss': 0.3307521228197512, 'Total loss': 0.3307521228197512}
2022-12-31 13:28:27,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:27,063 INFO:     Epoch: 34
2022-12-31 13:28:28,671 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3735648105541865, 'Total loss': 0.3735648105541865} | train loss {'Reaction outcome loss': 0.31710340759474714, 'Total loss': 0.31710340759474714}
2022-12-31 13:28:28,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:28,672 INFO:     Epoch: 35
2022-12-31 13:28:30,282 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37687932153542836, 'Total loss': 0.37687932153542836} | train loss {'Reaction outcome loss': 0.3190754960963141, 'Total loss': 0.3190754960963141}
2022-12-31 13:28:30,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:30,283 INFO:     Epoch: 36
2022-12-31 13:28:31,912 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.35262354612350466, 'Total loss': 0.35262354612350466} | train loss {'Reaction outcome loss': 0.31564953354197545, 'Total loss': 0.31564953354197545}
2022-12-31 13:28:31,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:31,913 INFO:     Epoch: 37
2022-12-31 13:28:33,548 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3741424441337585, 'Total loss': 0.3741424441337585} | train loss {'Reaction outcome loss': 0.30804585744609764, 'Total loss': 0.30804585744609764}
2022-12-31 13:28:33,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:33,548 INFO:     Epoch: 38
2022-12-31 13:28:35,183 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3547963539759318, 'Total loss': 0.3547963539759318} | train loss {'Reaction outcome loss': 0.30827086309701096, 'Total loss': 0.30827086309701096}
2022-12-31 13:28:35,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:35,185 INFO:     Epoch: 39
2022-12-31 13:28:36,760 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3927637832860152, 'Total loss': 0.3927637832860152} | train loss {'Reaction outcome loss': 0.30305166400614236, 'Total loss': 0.30305166400614236}
2022-12-31 13:28:36,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:36,760 INFO:     Epoch: 40
2022-12-31 13:28:38,395 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3720941960811615, 'Total loss': 0.3720941960811615} | train loss {'Reaction outcome loss': 0.3030540310528689, 'Total loss': 0.3030540310528689}
2022-12-31 13:28:38,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:38,396 INFO:     Epoch: 41
2022-12-31 13:28:40,001 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3897791956861814, 'Total loss': 0.3897791956861814} | train loss {'Reaction outcome loss': 0.2955227316845031, 'Total loss': 0.2955227316845031}
2022-12-31 13:28:40,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:40,001 INFO:     Epoch: 42
2022-12-31 13:28:41,615 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3760632872581482, 'Total loss': 0.3760632872581482} | train loss {'Reaction outcome loss': 0.28826079265156507, 'Total loss': 0.28826079265156507}
2022-12-31 13:28:41,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:41,616 INFO:     Epoch: 43
2022-12-31 13:28:43,212 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3815541307131449, 'Total loss': 0.3815541307131449} | train loss {'Reaction outcome loss': 0.28370540339888617, 'Total loss': 0.28370540339888617}
2022-12-31 13:28:43,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:43,212 INFO:     Epoch: 44
2022-12-31 13:28:44,808 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38718629628419876, 'Total loss': 0.38718629628419876} | train loss {'Reaction outcome loss': 0.2913380941655828, 'Total loss': 0.2913380941655828}
2022-12-31 13:28:44,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:44,809 INFO:     Epoch: 45
2022-12-31 13:28:46,393 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36598203976949056, 'Total loss': 0.36598203976949056} | train loss {'Reaction outcome loss': 0.2864330904114814, 'Total loss': 0.2864330904114814}
2022-12-31 13:28:46,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:46,393 INFO:     Epoch: 46
2022-12-31 13:28:47,976 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35631338755289715, 'Total loss': 0.35631338755289715} | train loss {'Reaction outcome loss': 0.28236292269858687, 'Total loss': 0.28236292269858687}
2022-12-31 13:28:47,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:47,976 INFO:     Epoch: 47
2022-12-31 13:28:49,575 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35728349089622496, 'Total loss': 0.35728349089622496} | train loss {'Reaction outcome loss': 0.28188384221627927, 'Total loss': 0.28188384221627927}
2022-12-31 13:28:49,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:49,575 INFO:     Epoch: 48
2022-12-31 13:28:51,178 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3752125918865204, 'Total loss': 0.3752125918865204} | train loss {'Reaction outcome loss': 0.2721508592230715, 'Total loss': 0.2721508592230715}
2022-12-31 13:28:51,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:51,178 INFO:     Epoch: 49
2022-12-31 13:28:52,794 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.33282290895779926, 'Total loss': 0.33282290895779926} | train loss {'Reaction outcome loss': 0.27482629088418825, 'Total loss': 0.27482629088418825}
2022-12-31 13:28:52,794 INFO:     Found new best model at epoch 49
2022-12-31 13:28:52,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:52,795 INFO:     Epoch: 50
2022-12-31 13:28:54,390 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33557190001010895, 'Total loss': 0.33557190001010895} | train loss {'Reaction outcome loss': 0.2670368526212789, 'Total loss': 0.2670368526212789}
2022-12-31 13:28:54,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:54,391 INFO:     Epoch: 51
2022-12-31 13:28:55,975 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3517677843570709, 'Total loss': 0.3517677843570709} | train loss {'Reaction outcome loss': 0.26078050410299947, 'Total loss': 0.26078050410299947}
2022-12-31 13:28:55,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:55,975 INFO:     Epoch: 52
2022-12-31 13:28:57,567 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3416053156057994, 'Total loss': 0.3416053156057994} | train loss {'Reaction outcome loss': 0.2673464729399471, 'Total loss': 0.2673464729399471}
2022-12-31 13:28:57,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:57,567 INFO:     Epoch: 53
2022-12-31 13:28:59,168 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3747282952070236, 'Total loss': 0.3747282952070236} | train loss {'Reaction outcome loss': 0.26014399916042774, 'Total loss': 0.26014399916042774}
2022-12-31 13:28:59,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:28:59,168 INFO:     Epoch: 54
2022-12-31 13:29:00,765 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3356016208728155, 'Total loss': 0.3356016208728155} | train loss {'Reaction outcome loss': 0.26012881654877584, 'Total loss': 0.26012881654877584}
2022-12-31 13:29:00,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:00,765 INFO:     Epoch: 55
2022-12-31 13:29:02,362 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35998071332772574, 'Total loss': 0.35998071332772574} | train loss {'Reaction outcome loss': 0.2574278011699736, 'Total loss': 0.2574278011699736}
2022-12-31 13:29:02,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:02,362 INFO:     Epoch: 56
2022-12-31 13:29:03,934 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3590206980705261, 'Total loss': 0.3590206980705261} | train loss {'Reaction outcome loss': 0.2542135156554617, 'Total loss': 0.2542135156554617}
2022-12-31 13:29:03,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:03,934 INFO:     Epoch: 57
2022-12-31 13:29:05,557 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3540786315997442, 'Total loss': 0.3540786315997442} | train loss {'Reaction outcome loss': 0.2679642604616208, 'Total loss': 0.2679642604616208}
2022-12-31 13:29:05,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:05,558 INFO:     Epoch: 58
2022-12-31 13:29:07,147 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3492390563090642, 'Total loss': 0.3492390563090642} | train loss {'Reaction outcome loss': 0.25263636256994565, 'Total loss': 0.25263636256994565}
2022-12-31 13:29:07,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:07,147 INFO:     Epoch: 59
2022-12-31 13:29:08,741 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3164861356218656, 'Total loss': 0.3164861356218656} | train loss {'Reaction outcome loss': 0.2546373723900362, 'Total loss': 0.2546373723900362}
2022-12-31 13:29:08,741 INFO:     Found new best model at epoch 59
2022-12-31 13:29:08,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:08,742 INFO:     Epoch: 60
2022-12-31 13:29:10,341 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3342965945601463, 'Total loss': 0.3342965945601463} | train loss {'Reaction outcome loss': 0.2466357429494788, 'Total loss': 0.2466357429494788}
2022-12-31 13:29:10,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:10,341 INFO:     Epoch: 61
2022-12-31 13:29:11,937 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3317091718316078, 'Total loss': 0.3317091718316078} | train loss {'Reaction outcome loss': 0.25239152263426956, 'Total loss': 0.25239152263426956}
2022-12-31 13:29:11,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:11,938 INFO:     Epoch: 62
2022-12-31 13:29:13,523 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3294522086779276, 'Total loss': 0.3294522086779276} | train loss {'Reaction outcome loss': 0.2461001218566091, 'Total loss': 0.2461001218566091}
2022-12-31 13:29:13,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:13,524 INFO:     Epoch: 63
2022-12-31 13:29:15,142 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3549102077881495, 'Total loss': 0.3549102077881495} | train loss {'Reaction outcome loss': 0.24967020051383274, 'Total loss': 0.24967020051383274}
2022-12-31 13:29:15,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:15,143 INFO:     Epoch: 64
2022-12-31 13:29:16,741 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3241225222746531, 'Total loss': 0.3241225222746531} | train loss {'Reaction outcome loss': 0.24255515939313851, 'Total loss': 0.24255515939313851}
2022-12-31 13:29:16,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:16,741 INFO:     Epoch: 65
2022-12-31 13:29:18,339 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3425718863805135, 'Total loss': 0.3425718863805135} | train loss {'Reaction outcome loss': 0.2399816112558702, 'Total loss': 0.2399816112558702}
2022-12-31 13:29:18,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:18,339 INFO:     Epoch: 66
2022-12-31 13:29:19,938 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3800440073013306, 'Total loss': 0.3800440073013306} | train loss {'Reaction outcome loss': 0.24929684587505274, 'Total loss': 0.24929684587505274}
2022-12-31 13:29:19,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:19,938 INFO:     Epoch: 67
2022-12-31 13:29:21,571 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38005713919798534, 'Total loss': 0.38005713919798534} | train loss {'Reaction outcome loss': 0.2451109320825928, 'Total loss': 0.2451109320825928}
2022-12-31 13:29:21,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:21,572 INFO:     Epoch: 68
2022-12-31 13:29:23,177 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36184473435084025, 'Total loss': 0.36184473435084025} | train loss {'Reaction outcome loss': 0.23355485743164142, 'Total loss': 0.23355485743164142}
2022-12-31 13:29:23,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:23,177 INFO:     Epoch: 69
2022-12-31 13:29:24,758 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3126345843076706, 'Total loss': 0.3126345843076706} | train loss {'Reaction outcome loss': 0.24701385065612994, 'Total loss': 0.24701385065612994}
2022-12-31 13:29:24,759 INFO:     Found new best model at epoch 69
2022-12-31 13:29:24,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:24,760 INFO:     Epoch: 70
2022-12-31 13:29:26,353 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.31849961876869204, 'Total loss': 0.31849961876869204} | train loss {'Reaction outcome loss': 0.22897007293920732, 'Total loss': 0.22897007293920732}
2022-12-31 13:29:26,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:26,353 INFO:     Epoch: 71
2022-12-31 13:29:27,946 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4176601121822993, 'Total loss': 0.4176601121822993} | train loss {'Reaction outcome loss': 0.22762831133336592, 'Total loss': 0.22762831133336592}
2022-12-31 13:29:27,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:27,947 INFO:     Epoch: 72
2022-12-31 13:29:29,541 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.32755189935366313, 'Total loss': 0.32755189935366313} | train loss {'Reaction outcome loss': 0.2351968997523134, 'Total loss': 0.2351968997523134}
2022-12-31 13:29:29,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:29,541 INFO:     Epoch: 73
2022-12-31 13:29:31,137 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33258001605669657, 'Total loss': 0.33258001605669657} | train loss {'Reaction outcome loss': 0.23522258835124882, 'Total loss': 0.23522258835124882}
2022-12-31 13:29:31,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:31,138 INFO:     Epoch: 74
2022-12-31 13:29:32,730 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3712777093052864, 'Total loss': 0.3712777093052864} | train loss {'Reaction outcome loss': 0.23079915994935202, 'Total loss': 0.23079915994935202}
2022-12-31 13:29:32,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:32,730 INFO:     Epoch: 75
2022-12-31 13:29:34,333 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.34251658817132313, 'Total loss': 0.34251658817132313} | train loss {'Reaction outcome loss': 0.22224176942537993, 'Total loss': 0.22224176942537993}
2022-12-31 13:29:34,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:34,334 INFO:     Epoch: 76
2022-12-31 13:29:35,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.31929609055320424, 'Total loss': 0.31929609055320424} | train loss {'Reaction outcome loss': 0.22978329433353392, 'Total loss': 0.22978329433353392}
2022-12-31 13:29:35,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:35,937 INFO:     Epoch: 77
2022-12-31 13:29:37,553 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.34204300319155057, 'Total loss': 0.34204300319155057} | train loss {'Reaction outcome loss': 0.22570194766580404, 'Total loss': 0.22570194766580404}
2022-12-31 13:29:37,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:37,555 INFO:     Epoch: 78
2022-12-31 13:29:39,161 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3448920706907908, 'Total loss': 0.3448920706907908} | train loss {'Reaction outcome loss': 0.22612903813316382, 'Total loss': 0.22612903813316382}
2022-12-31 13:29:39,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:39,161 INFO:     Epoch: 79
2022-12-31 13:29:40,747 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.33366019328435265, 'Total loss': 0.33366019328435265} | train loss {'Reaction outcome loss': 0.21809043731172006, 'Total loss': 0.21809043731172006}
2022-12-31 13:29:40,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:40,748 INFO:     Epoch: 80
2022-12-31 13:29:42,335 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3969518025716146, 'Total loss': 0.3969518025716146} | train loss {'Reaction outcome loss': 0.2232088524943743, 'Total loss': 0.2232088524943743}
2022-12-31 13:29:42,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:42,336 INFO:     Epoch: 81
2022-12-31 13:29:43,972 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35965952773888904, 'Total loss': 0.35965952773888904} | train loss {'Reaction outcome loss': 0.22110056674496814, 'Total loss': 0.22110056674496814}
2022-12-31 13:29:43,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:43,973 INFO:     Epoch: 82
2022-12-31 13:29:45,563 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3305763942499956, 'Total loss': 0.3305763942499956} | train loss {'Reaction outcome loss': 0.21671265740657136, 'Total loss': 0.21671265740657136}
2022-12-31 13:29:45,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:45,564 INFO:     Epoch: 83
2022-12-31 13:29:47,175 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35725224775572617, 'Total loss': 0.35725224775572617} | train loss {'Reaction outcome loss': 0.22040121275044622, 'Total loss': 0.22040121275044622}
2022-12-31 13:29:47,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:47,175 INFO:     Epoch: 84
2022-12-31 13:29:48,787 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35208318730195365, 'Total loss': 0.35208318730195365} | train loss {'Reaction outcome loss': 0.21335208138635198, 'Total loss': 0.21335208138635198}
2022-12-31 13:29:48,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:48,787 INFO:     Epoch: 85
2022-12-31 13:29:50,388 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33838635981082915, 'Total loss': 0.33838635981082915} | train loss {'Reaction outcome loss': 0.21011486992874479, 'Total loss': 0.21011486992874479}
2022-12-31 13:29:50,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:50,388 INFO:     Epoch: 86
2022-12-31 13:29:51,976 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33865272303422295, 'Total loss': 0.33865272303422295} | train loss {'Reaction outcome loss': 0.21070453508896925, 'Total loss': 0.21070453508896925}
2022-12-31 13:29:51,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:51,976 INFO:     Epoch: 87
2022-12-31 13:29:53,568 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34147070546944935, 'Total loss': 0.34147070546944935} | train loss {'Reaction outcome loss': 0.21700789140121185, 'Total loss': 0.21700789140121185}
2022-12-31 13:29:53,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:53,569 INFO:     Epoch: 88
2022-12-31 13:29:55,161 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3210740894079208, 'Total loss': 0.3210740894079208} | train loss {'Reaction outcome loss': 0.21752691053318016, 'Total loss': 0.21752691053318016}
2022-12-31 13:29:55,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:55,161 INFO:     Epoch: 89
2022-12-31 13:29:56,753 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3431633776674668, 'Total loss': 0.3431633776674668} | train loss {'Reaction outcome loss': 0.2176066517502397, 'Total loss': 0.2176066517502397}
2022-12-31 13:29:56,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:56,754 INFO:     Epoch: 90
2022-12-31 13:29:58,328 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.345811598499616, 'Total loss': 0.345811598499616} | train loss {'Reaction outcome loss': 0.21280926439720085, 'Total loss': 0.21280926439720085}
2022-12-31 13:29:58,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:58,328 INFO:     Epoch: 91
2022-12-31 13:29:59,921 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34592645267645517, 'Total loss': 0.34592645267645517} | train loss {'Reaction outcome loss': 0.20610983063374738, 'Total loss': 0.20610983063374738}
2022-12-31 13:29:59,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:29:59,922 INFO:     Epoch: 92
2022-12-31 13:30:01,511 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3402869050701459, 'Total loss': 0.3402869050701459} | train loss {'Reaction outcome loss': 0.20535192207429873, 'Total loss': 0.20535192207429873}
2022-12-31 13:30:01,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:01,511 INFO:     Epoch: 93
2022-12-31 13:30:03,103 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3387745755414168, 'Total loss': 0.3387745755414168} | train loss {'Reaction outcome loss': 0.20403324461443137, 'Total loss': 0.20403324461443137}
2022-12-31 13:30:03,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:03,103 INFO:     Epoch: 94
2022-12-31 13:30:04,695 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.32364571740229925, 'Total loss': 0.32364571740229925} | train loss {'Reaction outcome loss': 0.20499242469327245, 'Total loss': 0.20499242469327245}
2022-12-31 13:30:04,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:04,695 INFO:     Epoch: 95
2022-12-31 13:30:06,289 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.34773373703161875, 'Total loss': 0.34773373703161875} | train loss {'Reaction outcome loss': 0.2085889894788191, 'Total loss': 0.2085889894788191}
2022-12-31 13:30:06,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:06,289 INFO:     Epoch: 96
2022-12-31 13:30:07,865 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3668253719806671, 'Total loss': 0.3668253719806671} | train loss {'Reaction outcome loss': 0.20313861245637413, 'Total loss': 0.20313861245637413}
2022-12-31 13:30:07,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:07,865 INFO:     Epoch: 97
2022-12-31 13:30:09,460 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.315360401570797, 'Total loss': 0.315360401570797} | train loss {'Reaction outcome loss': 0.20338743905990553, 'Total loss': 0.20338743905990553}
2022-12-31 13:30:09,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:09,460 INFO:     Epoch: 98
2022-12-31 13:30:11,088 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.30928243895371754, 'Total loss': 0.30928243895371754} | train loss {'Reaction outcome loss': 0.19817554616393188, 'Total loss': 0.19817554616393188}
2022-12-31 13:30:11,088 INFO:     Found new best model at epoch 98
2022-12-31 13:30:11,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:11,089 INFO:     Epoch: 99
2022-12-31 13:30:12,693 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34039153158664703, 'Total loss': 0.34039153158664703} | train loss {'Reaction outcome loss': 0.2014677081420854, 'Total loss': 0.2014677081420854}
2022-12-31 13:30:12,694 INFO:     Best model found after epoch 99 of 100.
2022-12-31 13:30:12,694 INFO:   Done with stage: TRAINING
2022-12-31 13:30:12,695 INFO:   Starting stage: EVALUATION
2022-12-31 13:30:12,836 INFO:   Done with stage: EVALUATION
2022-12-31 13:30:12,837 INFO:   Leaving out SEQ value Fold_9
2022-12-31 13:30:12,849 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 13:30:12,849 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:30:13,507 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:30:13,507 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:30:13,576 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:30:13,576 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:30:13,576 INFO:     No hyperparam tuning for this model
2022-12-31 13:30:13,576 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:30:13,576 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:30:13,577 INFO:     None feature selector for col prot
2022-12-31 13:30:13,577 INFO:     None feature selector for col prot
2022-12-31 13:30:13,577 INFO:     None feature selector for col prot
2022-12-31 13:30:13,578 INFO:     None feature selector for col chem
2022-12-31 13:30:13,578 INFO:     None feature selector for col chem
2022-12-31 13:30:13,578 INFO:     None feature selector for col chem
2022-12-31 13:30:13,578 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:30:13,578 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:30:13,580 INFO:     Number of params in model 223921
2022-12-31 13:30:13,583 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:30:13,583 INFO:   Starting stage: TRAINING
2022-12-31 13:30:13,628 INFO:     Val loss before train {'Reaction outcome loss': 0.9515570203463236, 'Total loss': 0.9515570203463236}
2022-12-31 13:30:13,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:13,628 INFO:     Epoch: 0
2022-12-31 13:30:15,283 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6551014244556427, 'Total loss': 0.6551014244556427} | train loss {'Reaction outcome loss': 0.8263149631582873, 'Total loss': 0.8263149631582873}
2022-12-31 13:30:15,283 INFO:     Found new best model at epoch 0
2022-12-31 13:30:15,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:15,284 INFO:     Epoch: 1
2022-12-31 13:30:16,892 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5065445403258005, 'Total loss': 0.5065445403258005} | train loss {'Reaction outcome loss': 0.6067131443036592, 'Total loss': 0.6067131443036592}
2022-12-31 13:30:16,892 INFO:     Found new best model at epoch 1
2022-12-31 13:30:16,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:16,893 INFO:     Epoch: 2
2022-12-31 13:30:18,511 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5040649573008219, 'Total loss': 0.5040649573008219} | train loss {'Reaction outcome loss': 0.5383158563922028, 'Total loss': 0.5383158563922028}
2022-12-31 13:30:18,511 INFO:     Found new best model at epoch 2
2022-12-31 13:30:18,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:18,512 INFO:     Epoch: 3
2022-12-31 13:30:20,132 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4760824223359426, 'Total loss': 0.4760824223359426} | train loss {'Reaction outcome loss': 0.5177476410938945, 'Total loss': 0.5177476410938945}
2022-12-31 13:30:20,133 INFO:     Found new best model at epoch 3
2022-12-31 13:30:20,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:20,134 INFO:     Epoch: 4
2022-12-31 13:30:21,751 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4819190581639608, 'Total loss': 0.4819190581639608} | train loss {'Reaction outcome loss': 0.4992122673278251, 'Total loss': 0.4992122673278251}
2022-12-31 13:30:21,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:21,751 INFO:     Epoch: 5
2022-12-31 13:30:23,366 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4686370611190796, 'Total loss': 0.4686370611190796} | train loss {'Reaction outcome loss': 0.4851677664673285, 'Total loss': 0.4851677664673285}
2022-12-31 13:30:23,366 INFO:     Found new best model at epoch 5
2022-12-31 13:30:23,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:23,367 INFO:     Epoch: 6
2022-12-31 13:30:24,980 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4458790530761083, 'Total loss': 0.4458790530761083} | train loss {'Reaction outcome loss': 0.47700440889015955, 'Total loss': 0.47700440889015955}
2022-12-31 13:30:24,980 INFO:     Found new best model at epoch 6
2022-12-31 13:30:24,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:24,981 INFO:     Epoch: 7
2022-12-31 13:30:26,601 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46340014537175495, 'Total loss': 0.46340014537175495} | train loss {'Reaction outcome loss': 0.4696312343923624, 'Total loss': 0.4696312343923624}
2022-12-31 13:30:26,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:26,601 INFO:     Epoch: 8
2022-12-31 13:30:28,218 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4521076465646426, 'Total loss': 0.4521076465646426} | train loss {'Reaction outcome loss': 0.4588691598402894, 'Total loss': 0.4588691598402894}
2022-12-31 13:30:28,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:28,219 INFO:     Epoch: 9
2022-12-31 13:30:29,856 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43859347701072693, 'Total loss': 0.43859347701072693} | train loss {'Reaction outcome loss': 0.4569942067622708, 'Total loss': 0.4569942067622708}
2022-12-31 13:30:29,856 INFO:     Found new best model at epoch 9
2022-12-31 13:30:29,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:29,857 INFO:     Epoch: 10
2022-12-31 13:30:31,496 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44659477372964224, 'Total loss': 0.44659477372964224} | train loss {'Reaction outcome loss': 0.4499332602488865, 'Total loss': 0.4499332602488865}
2022-12-31 13:30:31,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:31,496 INFO:     Epoch: 11
2022-12-31 13:30:33,146 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47293212711811067, 'Total loss': 0.47293212711811067} | train loss {'Reaction outcome loss': 0.44248792330065356, 'Total loss': 0.44248792330065356}
2022-12-31 13:30:33,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:33,147 INFO:     Epoch: 12
2022-12-31 13:30:34,762 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41819302638371786, 'Total loss': 0.41819302638371786} | train loss {'Reaction outcome loss': 0.43592309658600537, 'Total loss': 0.43592309658600537}
2022-12-31 13:30:34,763 INFO:     Found new best model at epoch 12
2022-12-31 13:30:34,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:34,764 INFO:     Epoch: 13
2022-12-31 13:30:36,364 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43733028570810956, 'Total loss': 0.43733028570810956} | train loss {'Reaction outcome loss': 0.4326329844254019, 'Total loss': 0.4326329844254019}
2022-12-31 13:30:36,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:36,364 INFO:     Epoch: 14
2022-12-31 13:30:37,977 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41098596851030983, 'Total loss': 0.41098596851030983} | train loss {'Reaction outcome loss': 0.4253614781834589, 'Total loss': 0.4253614781834589}
2022-12-31 13:30:37,977 INFO:     Found new best model at epoch 14
2022-12-31 13:30:37,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:37,978 INFO:     Epoch: 15
2022-12-31 13:30:39,615 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4027633249759674, 'Total loss': 0.4027633249759674} | train loss {'Reaction outcome loss': 0.4206491190711514, 'Total loss': 0.4206491190711514}
2022-12-31 13:30:39,615 INFO:     Found new best model at epoch 15
2022-12-31 13:30:39,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:39,616 INFO:     Epoch: 16
2022-12-31 13:30:41,246 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4197191218535105, 'Total loss': 0.4197191218535105} | train loss {'Reaction outcome loss': 0.4139766152746411, 'Total loss': 0.4139766152746411}
2022-12-31 13:30:41,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:41,246 INFO:     Epoch: 17
2022-12-31 13:30:42,887 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39286398390928906, 'Total loss': 0.39286398390928906} | train loss {'Reaction outcome loss': 0.40885572525460795, 'Total loss': 0.40885572525460795}
2022-12-31 13:30:42,888 INFO:     Found new best model at epoch 17
2022-12-31 13:30:42,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:42,889 INFO:     Epoch: 18
2022-12-31 13:30:44,506 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41167854766050976, 'Total loss': 0.41167854766050976} | train loss {'Reaction outcome loss': 0.39708808744965046, 'Total loss': 0.39708808744965046}
2022-12-31 13:30:44,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:44,506 INFO:     Epoch: 19
2022-12-31 13:30:46,118 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4052129646142324, 'Total loss': 0.4052129646142324} | train loss {'Reaction outcome loss': 0.39812121421959423, 'Total loss': 0.39812121421959423}
2022-12-31 13:30:46,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:46,118 INFO:     Epoch: 20
2022-12-31 13:30:47,755 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39130014677842456, 'Total loss': 0.39130014677842456} | train loss {'Reaction outcome loss': 0.39124894023802304, 'Total loss': 0.39124894023802304}
2022-12-31 13:30:47,755 INFO:     Found new best model at epoch 20
2022-12-31 13:30:47,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:47,756 INFO:     Epoch: 21
2022-12-31 13:30:49,399 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3877337644497553, 'Total loss': 0.3877337644497553} | train loss {'Reaction outcome loss': 0.385699721557569, 'Total loss': 0.385699721557569}
2022-12-31 13:30:49,400 INFO:     Found new best model at epoch 21
2022-12-31 13:30:49,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:49,401 INFO:     Epoch: 22
2022-12-31 13:30:51,046 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3908093810081482, 'Total loss': 0.3908093810081482} | train loss {'Reaction outcome loss': 0.37594570617598316, 'Total loss': 0.37594570617598316}
2022-12-31 13:30:51,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:51,046 INFO:     Epoch: 23
2022-12-31 13:30:52,678 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42299196422100066, 'Total loss': 0.42299196422100066} | train loss {'Reaction outcome loss': 0.37714731841203536, 'Total loss': 0.37714731841203536}
2022-12-31 13:30:52,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:52,678 INFO:     Epoch: 24
2022-12-31 13:30:54,282 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3956815987825394, 'Total loss': 0.3956815987825394} | train loss {'Reaction outcome loss': 0.36682091822800655, 'Total loss': 0.36682091822800655}
2022-12-31 13:30:54,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:54,282 INFO:     Epoch: 25
2022-12-31 13:30:55,919 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3690961937109629, 'Total loss': 0.3690961937109629} | train loss {'Reaction outcome loss': 0.3672925668771947, 'Total loss': 0.3672925668771947}
2022-12-31 13:30:55,920 INFO:     Found new best model at epoch 25
2022-12-31 13:30:55,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:55,920 INFO:     Epoch: 26
2022-12-31 13:30:57,572 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3713841994603475, 'Total loss': 0.3713841994603475} | train loss {'Reaction outcome loss': 0.36418822805804035, 'Total loss': 0.36418822805804035}
2022-12-31 13:30:57,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:57,572 INFO:     Epoch: 27
2022-12-31 13:30:59,196 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3487662747502327, 'Total loss': 0.3487662747502327} | train loss {'Reaction outcome loss': 0.35905339641476364, 'Total loss': 0.35905339641476364}
2022-12-31 13:30:59,196 INFO:     Found new best model at epoch 27
2022-12-31 13:30:59,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:30:59,197 INFO:     Epoch: 28
2022-12-31 13:31:00,855 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.34912233948707583, 'Total loss': 0.34912233948707583} | train loss {'Reaction outcome loss': 0.34752405155113886, 'Total loss': 0.34752405155113886}
2022-12-31 13:31:00,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:00,855 INFO:     Epoch: 29
2022-12-31 13:31:02,468 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.374228236079216, 'Total loss': 0.374228236079216} | train loss {'Reaction outcome loss': 0.34363125466375144, 'Total loss': 0.34363125466375144}
2022-12-31 13:31:02,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:02,469 INFO:     Epoch: 30
2022-12-31 13:31:04,072 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3875324587027232, 'Total loss': 0.3875324587027232} | train loss {'Reaction outcome loss': 0.33924912494550113, 'Total loss': 0.33924912494550113}
2022-12-31 13:31:04,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:04,073 INFO:     Epoch: 31
2022-12-31 13:31:05,689 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3947261373202006, 'Total loss': 0.3947261373202006} | train loss {'Reaction outcome loss': 0.33553858615108345, 'Total loss': 0.33553858615108345}
2022-12-31 13:31:05,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:05,689 INFO:     Epoch: 32
2022-12-31 13:31:07,303 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3535837948322296, 'Total loss': 0.3535837948322296} | train loss {'Reaction outcome loss': 0.32702448709938503, 'Total loss': 0.32702448709938503}
2022-12-31 13:31:07,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:07,304 INFO:     Epoch: 33
2022-12-31 13:31:08,949 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3738638162612915, 'Total loss': 0.3738638162612915} | train loss {'Reaction outcome loss': 0.32553515084329926, 'Total loss': 0.32553515084329926}
2022-12-31 13:31:08,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:08,950 INFO:     Epoch: 34
2022-12-31 13:31:10,548 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37600523928801216, 'Total loss': 0.37600523928801216} | train loss {'Reaction outcome loss': 0.318198371127194, 'Total loss': 0.318198371127194}
2022-12-31 13:31:10,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:10,548 INFO:     Epoch: 35
2022-12-31 13:31:12,192 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3802439093589783, 'Total loss': 0.3802439093589783} | train loss {'Reaction outcome loss': 0.3167617737117227, 'Total loss': 0.3167617737117227}
2022-12-31 13:31:12,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:12,192 INFO:     Epoch: 36
2022-12-31 13:31:13,820 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3642793546120326, 'Total loss': 0.3642793546120326} | train loss {'Reaction outcome loss': 0.31720126718820646, 'Total loss': 0.31720126718820646}
2022-12-31 13:31:13,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:13,821 INFO:     Epoch: 37
2022-12-31 13:31:15,465 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3410104880730311, 'Total loss': 0.3410104880730311} | train loss {'Reaction outcome loss': 0.31002995847902576, 'Total loss': 0.31002995847902576}
2022-12-31 13:31:15,465 INFO:     Found new best model at epoch 37
2022-12-31 13:31:15,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:15,466 INFO:     Epoch: 38
2022-12-31 13:31:17,099 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36770463387171426, 'Total loss': 0.36770463387171426} | train loss {'Reaction outcome loss': 0.3094028021992329, 'Total loss': 0.3094028021992329}
2022-12-31 13:31:17,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:17,100 INFO:     Epoch: 39
2022-12-31 13:31:18,729 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3645077476898829, 'Total loss': 0.3645077476898829} | train loss {'Reaction outcome loss': 0.3094755258908771, 'Total loss': 0.3094755258908771}
2022-12-31 13:31:18,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:18,729 INFO:     Epoch: 40
2022-12-31 13:31:20,350 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35391422907511394, 'Total loss': 0.35391422907511394} | train loss {'Reaction outcome loss': 0.2929047158909188, 'Total loss': 0.2929047158909188}
2022-12-31 13:31:20,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:20,351 INFO:     Epoch: 41
2022-12-31 13:31:21,961 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.33222027743856114, 'Total loss': 0.33222027743856114} | train loss {'Reaction outcome loss': 0.30369604777020237, 'Total loss': 0.30369604777020237}
2022-12-31 13:31:21,961 INFO:     Found new best model at epoch 41
2022-12-31 13:31:21,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:21,962 INFO:     Epoch: 42
2022-12-31 13:31:23,605 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3567870934804281, 'Total loss': 0.3567870934804281} | train loss {'Reaction outcome loss': 0.29472082213159073, 'Total loss': 0.29472082213159073}
2022-12-31 13:31:23,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:23,605 INFO:     Epoch: 43
2022-12-31 13:31:25,247 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3570856720209122, 'Total loss': 0.3570856720209122} | train loss {'Reaction outcome loss': 0.28567303805897815, 'Total loss': 0.28567303805897815}
2022-12-31 13:31:25,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:25,247 INFO:     Epoch: 44
2022-12-31 13:31:26,861 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4062576532363892, 'Total loss': 0.4062576532363892} | train loss {'Reaction outcome loss': 0.29163191228136687, 'Total loss': 0.29163191228136687}
2022-12-31 13:31:26,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:26,861 INFO:     Epoch: 45
2022-12-31 13:31:28,474 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3484355390071869, 'Total loss': 0.3484355390071869} | train loss {'Reaction outcome loss': 0.28169642604672307, 'Total loss': 0.28169642604672307}
2022-12-31 13:31:28,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:28,475 INFO:     Epoch: 46
2022-12-31 13:31:30,080 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34463850110769273, 'Total loss': 0.34463850110769273} | train loss {'Reaction outcome loss': 0.2752732582228924, 'Total loss': 0.2752732582228924}
2022-12-31 13:31:30,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:30,080 INFO:     Epoch: 47
2022-12-31 13:31:31,673 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3423177887996038, 'Total loss': 0.3423177887996038} | train loss {'Reaction outcome loss': 0.2754459885833281, 'Total loss': 0.2754459885833281}
2022-12-31 13:31:31,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:31,673 INFO:     Epoch: 48
2022-12-31 13:31:33,304 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.355677359799544, 'Total loss': 0.355677359799544} | train loss {'Reaction outcome loss': 0.274326618545645, 'Total loss': 0.274326618545645}
2022-12-31 13:31:33,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:33,305 INFO:     Epoch: 49
2022-12-31 13:31:34,936 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3706348717212677, 'Total loss': 0.3706348717212677} | train loss {'Reaction outcome loss': 0.27185377224419094, 'Total loss': 0.27185377224419094}
2022-12-31 13:31:34,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:34,937 INFO:     Epoch: 50
2022-12-31 13:31:36,550 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3976337025562922, 'Total loss': 0.3976337025562922} | train loss {'Reaction outcome loss': 0.26469514213690687, 'Total loss': 0.26469514213690687}
2022-12-31 13:31:36,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:36,551 INFO:     Epoch: 51
2022-12-31 13:31:38,149 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36988717714945474, 'Total loss': 0.36988717714945474} | train loss {'Reaction outcome loss': 0.2663274174993219, 'Total loss': 0.2663274174993219}
2022-12-31 13:31:38,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:38,149 INFO:     Epoch: 52
2022-12-31 13:31:39,753 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34336819847424827, 'Total loss': 0.34336819847424827} | train loss {'Reaction outcome loss': 0.2672601416572552, 'Total loss': 0.2672601416572552}
2022-12-31 13:31:39,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:39,753 INFO:     Epoch: 53
2022-12-31 13:31:41,372 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.33883519619703295, 'Total loss': 0.33883519619703295} | train loss {'Reaction outcome loss': 0.2644022236433593, 'Total loss': 0.2644022236433593}
2022-12-31 13:31:41,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:41,372 INFO:     Epoch: 54
2022-12-31 13:31:42,987 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3482234944899877, 'Total loss': 0.3482234944899877} | train loss {'Reaction outcome loss': 0.2560091772476473, 'Total loss': 0.2560091772476473}
2022-12-31 13:31:42,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:42,987 INFO:     Epoch: 55
2022-12-31 13:31:44,603 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38191222747166953, 'Total loss': 0.38191222747166953} | train loss {'Reaction outcome loss': 0.2543195787723099, 'Total loss': 0.2543195787723099}
2022-12-31 13:31:44,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:44,604 INFO:     Epoch: 56
2022-12-31 13:31:46,215 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.33624426027139026, 'Total loss': 0.33624426027139026} | train loss {'Reaction outcome loss': 0.25768522966975876, 'Total loss': 0.25768522966975876}
2022-12-31 13:31:46,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:46,215 INFO:     Epoch: 57
2022-12-31 13:31:47,832 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3629084448019663, 'Total loss': 0.3629084448019663} | train loss {'Reaction outcome loss': 0.25882425740199827, 'Total loss': 0.25882425740199827}
2022-12-31 13:31:47,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:47,832 INFO:     Epoch: 58
2022-12-31 13:31:49,434 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3597520589828491, 'Total loss': 0.3597520589828491} | train loss {'Reaction outcome loss': 0.25675201450309815, 'Total loss': 0.25675201450309815}
2022-12-31 13:31:49,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:49,434 INFO:     Epoch: 59
2022-12-31 13:31:51,049 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3231786782542864, 'Total loss': 0.3231786782542864} | train loss {'Reaction outcome loss': 0.2528175665368242, 'Total loss': 0.2528175665368242}
2022-12-31 13:31:51,050 INFO:     Found new best model at epoch 59
2022-12-31 13:31:51,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:51,051 INFO:     Epoch: 60
2022-12-31 13:31:52,666 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3250789552927017, 'Total loss': 0.3250789552927017} | train loss {'Reaction outcome loss': 0.2438775997891323, 'Total loss': 0.2438775997891323}
2022-12-31 13:31:52,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:52,666 INFO:     Epoch: 61
2022-12-31 13:31:54,282 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3340160191059113, 'Total loss': 0.3340160191059113} | train loss {'Reaction outcome loss': 0.24731620282795455, 'Total loss': 0.24731620282795455}
2022-12-31 13:31:54,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:54,283 INFO:     Epoch: 62
2022-12-31 13:31:55,875 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34251982271671294, 'Total loss': 0.34251982271671294} | train loss {'Reaction outcome loss': 0.2494962581228263, 'Total loss': 0.2494962581228263}
2022-12-31 13:31:55,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:55,876 INFO:     Epoch: 63
2022-12-31 13:31:57,488 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3427519122759501, 'Total loss': 0.3427519122759501} | train loss {'Reaction outcome loss': 0.24257317024689934, 'Total loss': 0.24257317024689934}
2022-12-31 13:31:57,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:57,488 INFO:     Epoch: 64
2022-12-31 13:31:59,100 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37890515724817914, 'Total loss': 0.37890515724817914} | train loss {'Reaction outcome loss': 0.23942641655003336, 'Total loss': 0.23942641655003336}
2022-12-31 13:31:59,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:31:59,100 INFO:     Epoch: 65
2022-12-31 13:32:00,712 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3322497566541036, 'Total loss': 0.3322497566541036} | train loss {'Reaction outcome loss': 0.24257464606032475, 'Total loss': 0.24257464606032475}
2022-12-31 13:32:00,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:00,713 INFO:     Epoch: 66
2022-12-31 13:32:02,325 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.32275976513822874, 'Total loss': 0.32275976513822874} | train loss {'Reaction outcome loss': 0.23871151121864465, 'Total loss': 0.23871151121864465}
2022-12-31 13:32:02,325 INFO:     Found new best model at epoch 66
2022-12-31 13:32:02,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:02,326 INFO:     Epoch: 67
2022-12-31 13:32:03,936 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34374558726946514, 'Total loss': 0.34374558726946514} | train loss {'Reaction outcome loss': 0.23948590551580332, 'Total loss': 0.23948590551580332}
2022-12-31 13:32:03,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:03,937 INFO:     Epoch: 68
2022-12-31 13:32:05,528 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.32050062517325084, 'Total loss': 0.32050062517325084} | train loss {'Reaction outcome loss': 0.23100703324624994, 'Total loss': 0.23100703324624994}
2022-12-31 13:32:05,528 INFO:     Found new best model at epoch 68
2022-12-31 13:32:05,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:05,529 INFO:     Epoch: 69
2022-12-31 13:32:07,127 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3200168584783872, 'Total loss': 0.3200168584783872} | train loss {'Reaction outcome loss': 0.2402394606869681, 'Total loss': 0.2402394606869681}
2022-12-31 13:32:07,128 INFO:     Found new best model at epoch 69
2022-12-31 13:32:07,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:07,129 INFO:     Epoch: 70
2022-12-31 13:32:08,739 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37927385171254474, 'Total loss': 0.37927385171254474} | train loss {'Reaction outcome loss': 0.23407685315565943, 'Total loss': 0.23407685315565943}
2022-12-31 13:32:08,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:08,739 INFO:     Epoch: 71
2022-12-31 13:32:10,350 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34185009598731997, 'Total loss': 0.34185009598731997} | train loss {'Reaction outcome loss': 0.23691817725393316, 'Total loss': 0.23691817725393316}
2022-12-31 13:32:10,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:10,351 INFO:     Epoch: 72
2022-12-31 13:32:11,963 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3298288176457087, 'Total loss': 0.3298288176457087} | train loss {'Reaction outcome loss': 0.2332405418910705, 'Total loss': 0.2332405418910705}
2022-12-31 13:32:11,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:11,963 INFO:     Epoch: 73
2022-12-31 13:32:13,570 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3197622428337733, 'Total loss': 0.3197622428337733} | train loss {'Reaction outcome loss': 0.23020192588064214, 'Total loss': 0.23020192588064214}
2022-12-31 13:32:13,570 INFO:     Found new best model at epoch 73
2022-12-31 13:32:13,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:13,571 INFO:     Epoch: 74
2022-12-31 13:32:15,167 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.32072529892126717, 'Total loss': 0.32072529892126717} | train loss {'Reaction outcome loss': 0.22733653514286242, 'Total loss': 0.22733653514286242}
2022-12-31 13:32:15,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:15,168 INFO:     Epoch: 75
2022-12-31 13:32:16,779 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.33788140217463175, 'Total loss': 0.33788140217463175} | train loss {'Reaction outcome loss': 0.22729136901722702, 'Total loss': 0.22729136901722702}
2022-12-31 13:32:16,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:16,779 INFO:     Epoch: 76
2022-12-31 13:32:18,443 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34609229465325675, 'Total loss': 0.34609229465325675} | train loss {'Reaction outcome loss': 0.22927964818310867, 'Total loss': 0.22927964818310867}
2022-12-31 13:32:18,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:18,444 INFO:     Epoch: 77
2022-12-31 13:32:20,094 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.31745242873827617, 'Total loss': 0.31745242873827617} | train loss {'Reaction outcome loss': 0.22593185994168913, 'Total loss': 0.22593185994168913}
2022-12-31 13:32:20,094 INFO:     Found new best model at epoch 77
2022-12-31 13:32:20,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:20,095 INFO:     Epoch: 78
2022-12-31 13:32:21,706 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36190975507100426, 'Total loss': 0.36190975507100426} | train loss {'Reaction outcome loss': 0.21961411071894185, 'Total loss': 0.21961411071894185}
2022-12-31 13:32:21,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:21,707 INFO:     Epoch: 79
2022-12-31 13:32:23,312 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3658749888340632, 'Total loss': 0.3658749888340632} | train loss {'Reaction outcome loss': 0.2188061758109271, 'Total loss': 0.2188061758109271}
2022-12-31 13:32:23,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:23,313 INFO:     Epoch: 80
2022-12-31 13:32:24,937 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.353185185790062, 'Total loss': 0.353185185790062} | train loss {'Reaction outcome loss': 0.2275309261196841, 'Total loss': 0.2275309261196841}
2022-12-31 13:32:24,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:24,937 INFO:     Epoch: 81
2022-12-31 13:32:26,597 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36233986616134645, 'Total loss': 0.36233986616134645} | train loss {'Reaction outcome loss': 0.2213356659414805, 'Total loss': 0.2213356659414805}
2022-12-31 13:32:26,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:26,597 INFO:     Epoch: 82
2022-12-31 13:32:28,252 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34226833482583363, 'Total loss': 0.34226833482583363} | train loss {'Reaction outcome loss': 0.22261630887643094, 'Total loss': 0.22261630887643094}
2022-12-31 13:32:28,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:28,253 INFO:     Epoch: 83
2022-12-31 13:32:29,904 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.356446502606074, 'Total loss': 0.356446502606074} | train loss {'Reaction outcome loss': 0.21935155601761833, 'Total loss': 0.21935155601761833}
2022-12-31 13:32:29,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:29,904 INFO:     Epoch: 84
2022-12-31 13:32:31,515 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36447305579980216, 'Total loss': 0.36447305579980216} | train loss {'Reaction outcome loss': 0.22013475643706235, 'Total loss': 0.22013475643706235}
2022-12-31 13:32:31,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:31,515 INFO:     Epoch: 85
2022-12-31 13:32:33,141 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.34960815459489825, 'Total loss': 0.34960815459489825} | train loss {'Reaction outcome loss': 0.21991978270348014, 'Total loss': 0.21991978270348014}
2022-12-31 13:32:33,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:33,141 INFO:     Epoch: 86
2022-12-31 13:32:34,757 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.32876496265331906, 'Total loss': 0.32876496265331906} | train loss {'Reaction outcome loss': 0.20819450039349308, 'Total loss': 0.20819450039349308}
2022-12-31 13:32:34,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:34,758 INFO:     Epoch: 87
2022-12-31 13:32:36,370 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3238215615351995, 'Total loss': 0.3238215615351995} | train loss {'Reaction outcome loss': 0.2156558338256842, 'Total loss': 0.2156558338256842}
2022-12-31 13:32:36,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:36,370 INFO:     Epoch: 88
2022-12-31 13:32:37,981 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.33907644550005595, 'Total loss': 0.33907644550005595} | train loss {'Reaction outcome loss': 0.2157548821467355, 'Total loss': 0.2157548821467355}
2022-12-31 13:32:37,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:37,981 INFO:     Epoch: 89
2022-12-31 13:32:39,594 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3141844362020493, 'Total loss': 0.3141844362020493} | train loss {'Reaction outcome loss': 0.2119282275196232, 'Total loss': 0.2119282275196232}
2022-12-31 13:32:39,594 INFO:     Found new best model at epoch 89
2022-12-31 13:32:39,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:39,595 INFO:     Epoch: 90
2022-12-31 13:32:41,194 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.34809921781222025, 'Total loss': 0.34809921781222025} | train loss {'Reaction outcome loss': 0.2106411087760426, 'Total loss': 0.2106411087760426}
2022-12-31 13:32:41,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:41,194 INFO:     Epoch: 91
2022-12-31 13:32:42,791 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36057990392049155, 'Total loss': 0.36057990392049155} | train loss {'Reaction outcome loss': 0.2167750772371189, 'Total loss': 0.2167750772371189}
2022-12-31 13:32:42,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:42,791 INFO:     Epoch: 92
2022-12-31 13:32:44,409 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.349251185854276, 'Total loss': 0.349251185854276} | train loss {'Reaction outcome loss': 0.21016987815284127, 'Total loss': 0.21016987815284127}
2022-12-31 13:32:44,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:44,409 INFO:     Epoch: 93
2022-12-31 13:32:46,021 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3416488806406657, 'Total loss': 0.3416488806406657} | train loss {'Reaction outcome loss': 0.20713591260922945, 'Total loss': 0.20713591260922945}
2022-12-31 13:32:46,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:46,022 INFO:     Epoch: 94
2022-12-31 13:32:47,667 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3643156111240387, 'Total loss': 0.3643156111240387} | train loss {'Reaction outcome loss': 0.2045545429394779, 'Total loss': 0.2045545429394779}
2022-12-31 13:32:47,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:47,668 INFO:     Epoch: 95
2022-12-31 13:32:49,326 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.31429727872212726, 'Total loss': 0.31429727872212726} | train loss {'Reaction outcome loss': 0.19993860113841316, 'Total loss': 0.19993860113841316}
2022-12-31 13:32:49,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:49,326 INFO:     Epoch: 96
2022-12-31 13:32:50,929 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3530077859759331, 'Total loss': 0.3530077859759331} | train loss {'Reaction outcome loss': 0.20743197653886428, 'Total loss': 0.20743197653886428}
2022-12-31 13:32:50,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:50,929 INFO:     Epoch: 97
2022-12-31 13:32:52,528 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3413309633731842, 'Total loss': 0.3413309633731842} | train loss {'Reaction outcome loss': 0.20520340745414636, 'Total loss': 0.20520340745414636}
2022-12-31 13:32:52,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:52,529 INFO:     Epoch: 98
2022-12-31 13:32:54,140 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33789411981900536, 'Total loss': 0.33789411981900536} | train loss {'Reaction outcome loss': 0.20212006215207842, 'Total loss': 0.20212006215207842}
2022-12-31 13:32:54,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:54,141 INFO:     Epoch: 99
2022-12-31 13:32:55,752 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.33150726606448494, 'Total loss': 0.33150726606448494} | train loss {'Reaction outcome loss': 0.1983778699795423, 'Total loss': 0.1983778699795423}
2022-12-31 13:32:55,752 INFO:     Best model found after epoch 90 of 100.
2022-12-31 13:32:55,753 INFO:   Done with stage: TRAINING
2022-12-31 13:32:55,753 INFO:   Starting stage: EVALUATION
2022-12-31 13:32:55,875 INFO:   Done with stage: EVALUATION
2022-12-31 13:32:55,883 INFO:   Leaving out SEQ value Fold_0
2022-12-31 13:32:55,896 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:32:55,896 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:32:56,549 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:32:56,549 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:32:56,617 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:32:56,617 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:32:56,617 INFO:     No hyperparam tuning for this model
2022-12-31 13:32:56,617 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:32:56,617 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:32:56,618 INFO:     None feature selector for col prot
2022-12-31 13:32:56,618 INFO:     None feature selector for col prot
2022-12-31 13:32:56,618 INFO:     None feature selector for col prot
2022-12-31 13:32:56,619 INFO:     None feature selector for col chem
2022-12-31 13:32:56,619 INFO:     None feature selector for col chem
2022-12-31 13:32:56,619 INFO:     None feature selector for col chem
2022-12-31 13:32:56,619 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:32:56,619 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:32:56,621 INFO:     Number of params in model 223921
2022-12-31 13:32:56,624 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:32:56,624 INFO:   Starting stage: TRAINING
2022-12-31 13:32:56,669 INFO:     Val loss before train {'Reaction outcome loss': 0.9717883785565694, 'Total loss': 0.9717883785565694}
2022-12-31 13:32:56,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:56,669 INFO:     Epoch: 0
2022-12-31 13:32:58,275 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6117253343264262, 'Total loss': 0.6117253343264262} | train loss {'Reaction outcome loss': 0.813192519750716, 'Total loss': 0.813192519750716}
2022-12-31 13:32:58,275 INFO:     Found new best model at epoch 0
2022-12-31 13:32:58,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:58,276 INFO:     Epoch: 1
2022-12-31 13:32:59,864 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5542161762714386, 'Total loss': 0.5542161762714386} | train loss {'Reaction outcome loss': 0.5975534569417663, 'Total loss': 0.5975534569417663}
2022-12-31 13:32:59,864 INFO:     Found new best model at epoch 1
2022-12-31 13:32:59,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:32:59,865 INFO:     Epoch: 2
2022-12-31 13:33:01,461 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5314128299554189, 'Total loss': 0.5314128299554189} | train loss {'Reaction outcome loss': 0.5338583164612182, 'Total loss': 0.5338583164612182}
2022-12-31 13:33:01,461 INFO:     Found new best model at epoch 2
2022-12-31 13:33:01,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:01,462 INFO:     Epoch: 3
2022-12-31 13:33:03,084 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47117996017138164, 'Total loss': 0.47117996017138164} | train loss {'Reaction outcome loss': 0.5079082362657494, 'Total loss': 0.5079082362657494}
2022-12-31 13:33:03,084 INFO:     Found new best model at epoch 3
2022-12-31 13:33:03,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:03,085 INFO:     Epoch: 4
2022-12-31 13:33:04,689 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4757262349128723, 'Total loss': 0.4757262349128723} | train loss {'Reaction outcome loss': 0.4911379718906719, 'Total loss': 0.4911379718906719}
2022-12-31 13:33:04,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:04,689 INFO:     Epoch: 5
2022-12-31 13:33:06,293 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45949281652768453, 'Total loss': 0.45949281652768453} | train loss {'Reaction outcome loss': 0.4774161451968594, 'Total loss': 0.4774161451968594}
2022-12-31 13:33:06,293 INFO:     Found new best model at epoch 5
2022-12-31 13:33:06,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:06,294 INFO:     Epoch: 6
2022-12-31 13:33:07,876 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44071398079395296, 'Total loss': 0.44071398079395296} | train loss {'Reaction outcome loss': 0.4811992026381262, 'Total loss': 0.4811992026381262}
2022-12-31 13:33:07,876 INFO:     Found new best model at epoch 6
2022-12-31 13:33:07,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:07,877 INFO:     Epoch: 7
2022-12-31 13:33:09,467 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4549946268399557, 'Total loss': 0.4549946268399557} | train loss {'Reaction outcome loss': 0.4655222917933935, 'Total loss': 0.4655222917933935}
2022-12-31 13:33:09,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:09,468 INFO:     Epoch: 8
2022-12-31 13:33:11,066 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4281039635340373, 'Total loss': 0.4281039635340373} | train loss {'Reaction outcome loss': 0.45881447658530966, 'Total loss': 0.45881447658530966}
2022-12-31 13:33:11,067 INFO:     Found new best model at epoch 8
2022-12-31 13:33:11,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:11,068 INFO:     Epoch: 9
2022-12-31 13:33:12,672 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4547737866640091, 'Total loss': 0.4547737866640091} | train loss {'Reaction outcome loss': 0.4490312673151493, 'Total loss': 0.4490312673151493}
2022-12-31 13:33:12,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:12,673 INFO:     Epoch: 10
2022-12-31 13:33:14,279 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.420137823621432, 'Total loss': 0.420137823621432} | train loss {'Reaction outcome loss': 0.4402280261443145, 'Total loss': 0.4402280261443145}
2022-12-31 13:33:14,279 INFO:     Found new best model at epoch 10
2022-12-31 13:33:14,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:14,280 INFO:     Epoch: 11
2022-12-31 13:33:15,884 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4364194929599762, 'Total loss': 0.4364194929599762} | train loss {'Reaction outcome loss': 0.43865528800866427, 'Total loss': 0.43865528800866427}
2022-12-31 13:33:15,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:15,884 INFO:     Epoch: 12
2022-12-31 13:33:17,469 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41955857078234354, 'Total loss': 0.41955857078234354} | train loss {'Reaction outcome loss': 0.44236121871981066, 'Total loss': 0.44236121871981066}
2022-12-31 13:33:17,470 INFO:     Found new best model at epoch 12
2022-12-31 13:33:17,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:17,471 INFO:     Epoch: 13
2022-12-31 13:33:19,061 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44658848841985066, 'Total loss': 0.44658848841985066} | train loss {'Reaction outcome loss': 0.4490586669332739, 'Total loss': 0.4490586669332739}
2022-12-31 13:33:19,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:19,061 INFO:     Epoch: 14
2022-12-31 13:33:20,670 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4011610967417558, 'Total loss': 0.4011610967417558} | train loss {'Reaction outcome loss': 0.42294346383425696, 'Total loss': 0.42294346383425696}
2022-12-31 13:33:20,670 INFO:     Found new best model at epoch 14
2022-12-31 13:33:20,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:20,671 INFO:     Epoch: 15
2022-12-31 13:33:22,311 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43016283015410106, 'Total loss': 0.43016283015410106} | train loss {'Reaction outcome loss': 0.42150365371101844, 'Total loss': 0.42150365371101844}
2022-12-31 13:33:22,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:22,311 INFO:     Epoch: 16
2022-12-31 13:33:23,931 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4352085669835409, 'Total loss': 0.4352085669835409} | train loss {'Reaction outcome loss': 0.4126406873414374, 'Total loss': 0.4126406873414374}
2022-12-31 13:33:23,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:23,932 INFO:     Epoch: 17
2022-12-31 13:33:25,580 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4293882538874944, 'Total loss': 0.4293882538874944} | train loss {'Reaction outcome loss': 0.40891740629845974, 'Total loss': 0.40891740629845974}
2022-12-31 13:33:25,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:25,580 INFO:     Epoch: 18
2022-12-31 13:33:27,194 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41674479047457375, 'Total loss': 0.41674479047457375} | train loss {'Reaction outcome loss': 0.4028495282149432, 'Total loss': 0.4028495282149432}
2022-12-31 13:33:27,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:27,194 INFO:     Epoch: 19
2022-12-31 13:33:28,812 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3938664197921753, 'Total loss': 0.3938664197921753} | train loss {'Reaction outcome loss': 0.39813909864228597, 'Total loss': 0.39813909864228597}
2022-12-31 13:33:28,812 INFO:     Found new best model at epoch 19
2022-12-31 13:33:28,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:28,813 INFO:     Epoch: 20
2022-12-31 13:33:30,431 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4134509821732839, 'Total loss': 0.4134509821732839} | train loss {'Reaction outcome loss': 0.4085278685974038, 'Total loss': 0.4085278685974038}
2022-12-31 13:33:30,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:30,432 INFO:     Epoch: 21
2022-12-31 13:33:32,071 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41581068833669027, 'Total loss': 0.41581068833669027} | train loss {'Reaction outcome loss': 0.43882125613374123, 'Total loss': 0.43882125613374123}
2022-12-31 13:33:32,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:32,071 INFO:     Epoch: 22
2022-12-31 13:33:33,698 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37945028841495515, 'Total loss': 0.37945028841495515} | train loss {'Reaction outcome loss': 0.41300401318400964, 'Total loss': 0.41300401318400964}
2022-12-31 13:33:33,698 INFO:     Found new best model at epoch 22
2022-12-31 13:33:33,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:33,699 INFO:     Epoch: 23
2022-12-31 13:33:35,322 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39414812326431276, 'Total loss': 0.39414812326431276} | train loss {'Reaction outcome loss': 0.38407801088887145, 'Total loss': 0.38407801088887145}
2022-12-31 13:33:35,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:35,323 INFO:     Epoch: 24
2022-12-31 13:33:36,912 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39650104294220606, 'Total loss': 0.39650104294220606} | train loss {'Reaction outcome loss': 0.3831697844940683, 'Total loss': 0.3831697844940683}
2022-12-31 13:33:36,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:36,913 INFO:     Epoch: 25
2022-12-31 13:33:38,518 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39038454194863637, 'Total loss': 0.39038454194863637} | train loss {'Reaction outcome loss': 0.38222048180245294, 'Total loss': 0.38222048180245294}
2022-12-31 13:33:38,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:38,518 INFO:     Epoch: 26
2022-12-31 13:33:40,124 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37880078156789143, 'Total loss': 0.37880078156789143} | train loss {'Reaction outcome loss': 0.3713500133532788, 'Total loss': 0.3713500133532788}
2022-12-31 13:33:40,124 INFO:     Found new best model at epoch 26
2022-12-31 13:33:40,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:40,125 INFO:     Epoch: 27
2022-12-31 13:33:41,753 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.36711529990037284, 'Total loss': 0.36711529990037284} | train loss {'Reaction outcome loss': 0.36593242413431837, 'Total loss': 0.36593242413431837}
2022-12-31 13:33:41,753 INFO:     Found new best model at epoch 27
2022-12-31 13:33:41,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:41,754 INFO:     Epoch: 28
2022-12-31 13:33:43,370 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39192393720149993, 'Total loss': 0.39192393720149993} | train loss {'Reaction outcome loss': 0.36134654369907104, 'Total loss': 0.36134654369907104}
2022-12-31 13:33:43,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:43,370 INFO:     Epoch: 29
2022-12-31 13:33:44,969 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4092096577088038, 'Total loss': 0.4092096577088038} | train loss {'Reaction outcome loss': 0.3585252276743236, 'Total loss': 0.3585252276743236}
2022-12-31 13:33:44,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:44,970 INFO:     Epoch: 30
2022-12-31 13:33:46,595 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.383751172820727, 'Total loss': 0.383751172820727} | train loss {'Reaction outcome loss': 0.34685663163553976, 'Total loss': 0.34685663163553976}
2022-12-31 13:33:46,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:46,596 INFO:     Epoch: 31
2022-12-31 13:33:48,259 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3830686678489049, 'Total loss': 0.3830686678489049} | train loss {'Reaction outcome loss': 0.34840525856133603, 'Total loss': 0.34840525856133603}
2022-12-31 13:33:48,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:48,260 INFO:     Epoch: 32
2022-12-31 13:33:49,926 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.360376825928688, 'Total loss': 0.360376825928688} | train loss {'Reaction outcome loss': 0.34417807700895314, 'Total loss': 0.34417807700895314}
2022-12-31 13:33:49,927 INFO:     Found new best model at epoch 32
2022-12-31 13:33:49,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:49,928 INFO:     Epoch: 33
2022-12-31 13:33:51,585 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.35489205121994016, 'Total loss': 0.35489205121994016} | train loss {'Reaction outcome loss': 0.3321474889580038, 'Total loss': 0.3321474889580038}
2022-12-31 13:33:51,585 INFO:     Found new best model at epoch 33
2022-12-31 13:33:51,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:51,586 INFO:     Epoch: 34
2022-12-31 13:33:53,240 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36176411906878153, 'Total loss': 0.36176411906878153} | train loss {'Reaction outcome loss': 0.32761067056191573, 'Total loss': 0.32761067056191573}
2022-12-31 13:33:53,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:53,241 INFO:     Epoch: 35
2022-12-31 13:33:54,895 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3690102239449819, 'Total loss': 0.3690102239449819} | train loss {'Reaction outcome loss': 0.32530639680993295, 'Total loss': 0.32530639680993295}
2022-12-31 13:33:54,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:54,895 INFO:     Epoch: 36
2022-12-31 13:33:56,549 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36488785843054455, 'Total loss': 0.36488785843054455} | train loss {'Reaction outcome loss': 0.32419125670212845, 'Total loss': 0.32419125670212845}
2022-12-31 13:33:56,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:56,549 INFO:     Epoch: 37
2022-12-31 13:33:58,208 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3603524227937063, 'Total loss': 0.3603524227937063} | train loss {'Reaction outcome loss': 0.31867664492776804, 'Total loss': 0.31867664492776804}
2022-12-31 13:33:58,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:58,208 INFO:     Epoch: 38
2022-12-31 13:33:59,871 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34334717492262523, 'Total loss': 0.34334717492262523} | train loss {'Reaction outcome loss': 0.3083866403169889, 'Total loss': 0.3083866403169889}
2022-12-31 13:33:59,872 INFO:     Found new best model at epoch 38
2022-12-31 13:33:59,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:33:59,873 INFO:     Epoch: 39
2022-12-31 13:34:01,537 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3881878390908241, 'Total loss': 0.3881878390908241} | train loss {'Reaction outcome loss': 0.3086246363677344, 'Total loss': 0.3086246363677344}
2022-12-31 13:34:01,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:01,538 INFO:     Epoch: 40
2022-12-31 13:34:03,188 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.408245454231898, 'Total loss': 0.408245454231898} | train loss {'Reaction outcome loss': 0.30777040286077373, 'Total loss': 0.30777040286077373}
2022-12-31 13:34:03,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:03,189 INFO:     Epoch: 41
2022-12-31 13:34:04,836 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4150236735741297, 'Total loss': 0.4150236735741297} | train loss {'Reaction outcome loss': 0.3215550431387796, 'Total loss': 0.3215550431387796}
2022-12-31 13:34:04,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:04,837 INFO:     Epoch: 42
2022-12-31 13:34:06,503 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3985813081264496, 'Total loss': 0.3985813081264496} | train loss {'Reaction outcome loss': 0.31831348981622665, 'Total loss': 0.31831348981622665}
2022-12-31 13:34:06,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:06,503 INFO:     Epoch: 43
2022-12-31 13:34:08,169 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3435883730649948, 'Total loss': 0.3435883730649948} | train loss {'Reaction outcome loss': 0.30055167009561334, 'Total loss': 0.30055167009561334}
2022-12-31 13:34:08,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:08,170 INFO:     Epoch: 44
2022-12-31 13:34:09,836 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3930869390567144, 'Total loss': 0.3930869390567144} | train loss {'Reaction outcome loss': 0.2918551380617841, 'Total loss': 0.2918551380617841}
2022-12-31 13:34:09,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:09,836 INFO:     Epoch: 45
2022-12-31 13:34:11,500 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3629043996334076, 'Total loss': 0.3629043996334076} | train loss {'Reaction outcome loss': 0.2898941186486163, 'Total loss': 0.2898941186486163}
2022-12-31 13:34:11,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:11,500 INFO:     Epoch: 46
2022-12-31 13:34:13,152 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3824380040168762, 'Total loss': 0.3824380040168762} | train loss {'Reaction outcome loss': 0.28286074540761363, 'Total loss': 0.28286074540761363}
2022-12-31 13:34:13,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:13,153 INFO:     Epoch: 47
2022-12-31 13:34:14,777 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3636240303516388, 'Total loss': 0.3636240303516388} | train loss {'Reaction outcome loss': 0.2936155943038023, 'Total loss': 0.2936155943038023}
2022-12-31 13:34:14,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:14,777 INFO:     Epoch: 48
2022-12-31 13:34:16,436 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3569275975227356, 'Total loss': 0.3569275975227356} | train loss {'Reaction outcome loss': 0.2814224699944042, 'Total loss': 0.2814224699944042}
2022-12-31 13:34:16,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:16,436 INFO:     Epoch: 49
2022-12-31 13:34:18,100 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3789299974838893, 'Total loss': 0.3789299974838893} | train loss {'Reaction outcome loss': 0.2936520593011401, 'Total loss': 0.2936520593011401}
2022-12-31 13:34:18,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:18,100 INFO:     Epoch: 50
2022-12-31 13:34:19,744 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3610959400733312, 'Total loss': 0.3610959400733312} | train loss {'Reaction outcome loss': 0.2760659462866792, 'Total loss': 0.2760659462866792}
2022-12-31 13:34:19,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:19,744 INFO:     Epoch: 51
2022-12-31 13:34:21,334 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36933261851469673, 'Total loss': 0.36933261851469673} | train loss {'Reaction outcome loss': 0.2744690131704387, 'Total loss': 0.2744690131704387}
2022-12-31 13:34:21,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:21,334 INFO:     Epoch: 52
2022-12-31 13:34:22,948 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3382143959403038, 'Total loss': 0.3382143959403038} | train loss {'Reaction outcome loss': 0.27463265678480914, 'Total loss': 0.27463265678480914}
2022-12-31 13:34:22,948 INFO:     Found new best model at epoch 52
2022-12-31 13:34:22,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:22,949 INFO:     Epoch: 53
2022-12-31 13:34:24,559 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3447504103183746, 'Total loss': 0.3447504103183746} | train loss {'Reaction outcome loss': 0.26891196336172457, 'Total loss': 0.26891196336172457}
2022-12-31 13:34:24,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:24,559 INFO:     Epoch: 54
2022-12-31 13:34:26,171 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4025952706734339, 'Total loss': 0.4025952706734339} | train loss {'Reaction outcome loss': 0.27069385944987123, 'Total loss': 0.27069385944987123}
2022-12-31 13:34:26,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:26,172 INFO:     Epoch: 55
2022-12-31 13:34:27,782 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3855657860636711, 'Total loss': 0.3855657860636711} | train loss {'Reaction outcome loss': 0.28441153955308424, 'Total loss': 0.28441153955308424}
2022-12-31 13:34:27,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:27,782 INFO:     Epoch: 56
2022-12-31 13:34:29,393 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4072568307320277, 'Total loss': 0.4072568307320277} | train loss {'Reaction outcome loss': 0.2654577329488255, 'Total loss': 0.2654577329488255}
2022-12-31 13:34:29,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:29,395 INFO:     Epoch: 57
2022-12-31 13:34:30,989 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3954765776793162, 'Total loss': 0.3954765776793162} | train loss {'Reaction outcome loss': 0.2575880005851091, 'Total loss': 0.2575880005851091}
2022-12-31 13:34:30,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:30,989 INFO:     Epoch: 58
2022-12-31 13:34:32,593 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40092089076836906, 'Total loss': 0.40092089076836906} | train loss {'Reaction outcome loss': 0.26085544327835797, 'Total loss': 0.26085544327835797}
2022-12-31 13:34:32,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:32,593 INFO:     Epoch: 59
2022-12-31 13:34:34,208 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3455444425344467, 'Total loss': 0.3455444425344467} | train loss {'Reaction outcome loss': 0.2505578429682182, 'Total loss': 0.2505578429682182}
2022-12-31 13:34:34,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:34,208 INFO:     Epoch: 60
2022-12-31 13:34:35,824 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3500675027569135, 'Total loss': 0.3500675027569135} | train loss {'Reaction outcome loss': 0.2570964846498733, 'Total loss': 0.2570964846498733}
2022-12-31 13:34:35,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:35,824 INFO:     Epoch: 61
2022-12-31 13:34:37,438 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.33372676372528076, 'Total loss': 0.33372676372528076} | train loss {'Reaction outcome loss': 0.24683340449743243, 'Total loss': 0.24683340449743243}
2022-12-31 13:34:37,439 INFO:     Found new best model at epoch 61
2022-12-31 13:34:37,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:37,440 INFO:     Epoch: 62
2022-12-31 13:34:39,038 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.33742330471674603, 'Total loss': 0.33742330471674603} | train loss {'Reaction outcome loss': 0.25115626301292493, 'Total loss': 0.25115626301292493}
2022-12-31 13:34:39,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:39,038 INFO:     Epoch: 63
2022-12-31 13:34:40,663 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3554537072777748, 'Total loss': 0.3554537072777748} | train loss {'Reaction outcome loss': 0.24270595892290736, 'Total loss': 0.24270595892290736}
2022-12-31 13:34:40,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:40,663 INFO:     Epoch: 64
2022-12-31 13:34:42,264 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34327677885691327, 'Total loss': 0.34327677885691327} | train loss {'Reaction outcome loss': 0.2518961230905362, 'Total loss': 0.2518961230905362}
2022-12-31 13:34:42,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:42,264 INFO:     Epoch: 65
2022-12-31 13:34:43,878 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3712709108988444, 'Total loss': 0.3712709108988444} | train loss {'Reaction outcome loss': 0.24187826556980313, 'Total loss': 0.24187826556980313}
2022-12-31 13:34:43,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:43,878 INFO:     Epoch: 66
2022-12-31 13:34:45,506 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43490334252516427, 'Total loss': 0.43490334252516427} | train loss {'Reaction outcome loss': 0.23928458881256529, 'Total loss': 0.23928458881256529}
2022-12-31 13:34:45,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:45,507 INFO:     Epoch: 67
2022-12-31 13:34:47,118 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37554657061894736, 'Total loss': 0.37554657061894736} | train loss {'Reaction outcome loss': 0.24189408462953524, 'Total loss': 0.24189408462953524}
2022-12-31 13:34:47,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:47,119 INFO:     Epoch: 68
2022-12-31 13:34:48,709 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34909028311570484, 'Total loss': 0.34909028311570484} | train loss {'Reaction outcome loss': 0.24489623909450028, 'Total loss': 0.24489623909450028}
2022-12-31 13:34:48,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:48,710 INFO:     Epoch: 69
2022-12-31 13:34:50,309 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.33604200979073845, 'Total loss': 0.33604200979073845} | train loss {'Reaction outcome loss': 0.2434879278092348, 'Total loss': 0.2434879278092348}
2022-12-31 13:34:50,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:50,309 INFO:     Epoch: 70
2022-12-31 13:34:51,919 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39911767542362214, 'Total loss': 0.39911767542362214} | train loss {'Reaction outcome loss': 0.24063018176947598, 'Total loss': 0.24063018176947598}
2022-12-31 13:34:51,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:51,920 INFO:     Epoch: 71
2022-12-31 13:34:53,530 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4016667785743872, 'Total loss': 0.4016667785743872} | train loss {'Reaction outcome loss': 0.29503850112466706, 'Total loss': 0.29503850112466706}
2022-12-31 13:34:53,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:53,530 INFO:     Epoch: 72
2022-12-31 13:34:55,164 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38808561861515045, 'Total loss': 0.38808561861515045} | train loss {'Reaction outcome loss': 0.25827877006520505, 'Total loss': 0.25827877006520505}
2022-12-31 13:34:55,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:55,164 INFO:     Epoch: 73
2022-12-31 13:34:56,779 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37897276083628334, 'Total loss': 0.37897276083628334} | train loss {'Reaction outcome loss': 0.2377265968977514, 'Total loss': 0.2377265968977514}
2022-12-31 13:34:56,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:56,779 INFO:     Epoch: 74
2022-12-31 13:34:58,370 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4014724090695381, 'Total loss': 0.4014724090695381} | train loss {'Reaction outcome loss': 0.23353361937072317, 'Total loss': 0.23353361937072317}
2022-12-31 13:34:58,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:58,371 INFO:     Epoch: 75
2022-12-31 13:34:59,965 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3869698335727056, 'Total loss': 0.3869698335727056} | train loss {'Reaction outcome loss': 0.23427567509276306, 'Total loss': 0.23427567509276306}
2022-12-31 13:34:59,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:34:59,965 INFO:     Epoch: 76
2022-12-31 13:35:01,570 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34980670909086864, 'Total loss': 0.34980670909086864} | train loss {'Reaction outcome loss': 0.23418589069413667, 'Total loss': 0.23418589069413667}
2022-12-31 13:35:01,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:01,570 INFO:     Epoch: 77
2022-12-31 13:35:03,177 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36801005800565084, 'Total loss': 0.36801005800565084} | train loss {'Reaction outcome loss': 0.233496789085726, 'Total loss': 0.233496789085726}
2022-12-31 13:35:03,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:03,177 INFO:     Epoch: 78
2022-12-31 13:35:04,784 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35601217349370323, 'Total loss': 0.35601217349370323} | train loss {'Reaction outcome loss': 0.2279379727214278, 'Total loss': 0.2279379727214278}
2022-12-31 13:35:04,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:04,786 INFO:     Epoch: 79
2022-12-31 13:35:06,374 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3703106959660848, 'Total loss': 0.3703106959660848} | train loss {'Reaction outcome loss': 0.23297405691751602, 'Total loss': 0.23297405691751602}
2022-12-31 13:35:06,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:06,374 INFO:     Epoch: 80
2022-12-31 13:35:07,973 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38793900310993196, 'Total loss': 0.38793900310993196} | train loss {'Reaction outcome loss': 0.2272963684387134, 'Total loss': 0.2272963684387134}
2022-12-31 13:35:07,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:07,973 INFO:     Epoch: 81
2022-12-31 13:35:09,588 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3713172604640325, 'Total loss': 0.3713172604640325} | train loss {'Reaction outcome loss': 0.22084604391001197, 'Total loss': 0.22084604391001197}
2022-12-31 13:35:09,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:09,588 INFO:     Epoch: 82
2022-12-31 13:35:11,191 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39500154852867125, 'Total loss': 0.39500154852867125} | train loss {'Reaction outcome loss': 0.22485967636769771, 'Total loss': 0.22485967636769771}
2022-12-31 13:35:11,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:11,191 INFO:     Epoch: 83
2022-12-31 13:35:12,804 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3857181578874588, 'Total loss': 0.3857181578874588} | train loss {'Reaction outcome loss': 0.226644545137959, 'Total loss': 0.226644545137959}
2022-12-31 13:35:12,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:12,804 INFO:     Epoch: 84
2022-12-31 13:35:14,442 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.407596884171168, 'Total loss': 0.407596884171168} | train loss {'Reaction outcome loss': 0.2294064980891088, 'Total loss': 0.2294064980891088}
2022-12-31 13:35:14,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:14,442 INFO:     Epoch: 85
2022-12-31 13:35:16,040 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40027002890904745, 'Total loss': 0.40027002890904745} | train loss {'Reaction outcome loss': 0.3149616607732479, 'Total loss': 0.3149616607732479}
2022-12-31 13:35:16,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:16,041 INFO:     Epoch: 86
2022-12-31 13:35:17,638 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3688418507575989, 'Total loss': 0.3688418507575989} | train loss {'Reaction outcome loss': 0.2678972982848527, 'Total loss': 0.2678972982848527}
2022-12-31 13:35:17,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:17,639 INFO:     Epoch: 87
2022-12-31 13:35:19,247 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33203798333803813, 'Total loss': 0.33203798333803813} | train loss {'Reaction outcome loss': 0.24880357552994636, 'Total loss': 0.24880357552994636}
2022-12-31 13:35:19,247 INFO:     Found new best model at epoch 87
2022-12-31 13:35:19,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:19,248 INFO:     Epoch: 88
2022-12-31 13:35:20,856 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38654914597670237, 'Total loss': 0.38654914597670237} | train loss {'Reaction outcome loss': 0.24140669410310997, 'Total loss': 0.24140669410310997}
2022-12-31 13:35:20,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:20,857 INFO:     Epoch: 89
2022-12-31 13:35:22,462 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.33331746061642964, 'Total loss': 0.33331746061642964} | train loss {'Reaction outcome loss': 0.24107637496511586, 'Total loss': 0.24107637496511586}
2022-12-31 13:35:22,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:22,463 INFO:     Epoch: 90
2022-12-31 13:35:24,059 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36024547666311263, 'Total loss': 0.36024547666311263} | train loss {'Reaction outcome loss': 0.229220174024796, 'Total loss': 0.229220174024796}
2022-12-31 13:35:24,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:24,060 INFO:     Epoch: 91
2022-12-31 13:35:25,648 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38309578647216164, 'Total loss': 0.38309578647216164} | train loss {'Reaction outcome loss': 0.23380734106657378, 'Total loss': 0.23380734106657378}
2022-12-31 13:35:25,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:25,648 INFO:     Epoch: 92
2022-12-31 13:35:27,244 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3940550277630488, 'Total loss': 0.3940550277630488} | train loss {'Reaction outcome loss': 0.23100495185328485, 'Total loss': 0.23100495185328485}
2022-12-31 13:35:27,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:27,244 INFO:     Epoch: 93
2022-12-31 13:35:28,852 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.376343867679437, 'Total loss': 0.376343867679437} | train loss {'Reaction outcome loss': 0.2219654936157842, 'Total loss': 0.2219654936157842}
2022-12-31 13:35:28,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:28,852 INFO:     Epoch: 94
2022-12-31 13:35:30,505 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36570804516474403, 'Total loss': 0.36570804516474403} | train loss {'Reaction outcome loss': 0.21744421490059365, 'Total loss': 0.21744421490059365}
2022-12-31 13:35:30,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:30,505 INFO:     Epoch: 95
2022-12-31 13:35:32,156 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3727415382862091, 'Total loss': 0.3727415382862091} | train loss {'Reaction outcome loss': 0.22448196400104609, 'Total loss': 0.22448196400104609}
2022-12-31 13:35:32,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:32,156 INFO:     Epoch: 96
2022-12-31 13:35:33,765 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34774117519458136, 'Total loss': 0.34774117519458136} | train loss {'Reaction outcome loss': 0.22103014003483043, 'Total loss': 0.22103014003483043}
2022-12-31 13:35:33,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:33,765 INFO:     Epoch: 97
2022-12-31 13:35:35,372 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.35012739300727846, 'Total loss': 0.35012739300727846} | train loss {'Reaction outcome loss': 0.22529635357036107, 'Total loss': 0.22529635357036107}
2022-12-31 13:35:35,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:35,372 INFO:     Epoch: 98
2022-12-31 13:35:37,027 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36511852641900383, 'Total loss': 0.36511852641900383} | train loss {'Reaction outcome loss': 0.22596138204950705, 'Total loss': 0.22596138204950705}
2022-12-31 13:35:37,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:37,027 INFO:     Epoch: 99
2022-12-31 13:35:38,660 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3804078797499339, 'Total loss': 0.3804078797499339} | train loss {'Reaction outcome loss': 0.21614421071464437, 'Total loss': 0.21614421071464437}
2022-12-31 13:35:38,660 INFO:     Best model found after epoch 88 of 100.
2022-12-31 13:35:38,660 INFO:   Done with stage: TRAINING
2022-12-31 13:35:38,660 INFO:   Starting stage: EVALUATION
2022-12-31 13:35:38,791 INFO:   Done with stage: EVALUATION
2022-12-31 13:35:38,791 INFO:   Leaving out SEQ value Fold_1
2022-12-31 13:35:38,804 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 13:35:38,804 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:35:39,450 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:35:39,451 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:35:39,518 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:35:39,519 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:35:39,519 INFO:     No hyperparam tuning for this model
2022-12-31 13:35:39,520 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:35:39,520 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:35:39,520 INFO:     None feature selector for col prot
2022-12-31 13:35:39,520 INFO:     None feature selector for col prot
2022-12-31 13:35:39,521 INFO:     None feature selector for col prot
2022-12-31 13:35:39,521 INFO:     None feature selector for col chem
2022-12-31 13:35:39,521 INFO:     None feature selector for col chem
2022-12-31 13:35:39,521 INFO:     None feature selector for col chem
2022-12-31 13:35:39,521 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:35:39,521 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:35:39,523 INFO:     Number of params in model 223921
2022-12-31 13:35:39,526 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:35:39,526 INFO:   Starting stage: TRAINING
2022-12-31 13:35:39,571 INFO:     Val loss before train {'Reaction outcome loss': 1.1659054319063822, 'Total loss': 1.1659054319063822}
2022-12-31 13:35:39,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:39,571 INFO:     Epoch: 0
2022-12-31 13:35:41,194 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8030347863833109, 'Total loss': 0.8030347863833109} | train loss {'Reaction outcome loss': 0.8192140352242108, 'Total loss': 0.8192140352242108}
2022-12-31 13:35:41,194 INFO:     Found new best model at epoch 0
2022-12-31 13:35:41,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:41,195 INFO:     Epoch: 1
2022-12-31 13:35:42,754 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5860795974731445, 'Total loss': 0.5860795974731445} | train loss {'Reaction outcome loss': 0.5941758593509998, 'Total loss': 0.5941758593509998}
2022-12-31 13:35:42,754 INFO:     Found new best model at epoch 1
2022-12-31 13:35:42,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:42,755 INFO:     Epoch: 2
2022-12-31 13:35:44,346 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6044743816057842, 'Total loss': 0.6044743816057842} | train loss {'Reaction outcome loss': 0.535006955211013, 'Total loss': 0.535006955211013}
2022-12-31 13:35:44,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:44,346 INFO:     Epoch: 3
2022-12-31 13:35:45,951 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5721849004427592, 'Total loss': 0.5721849004427592} | train loss {'Reaction outcome loss': 0.5182440641621382, 'Total loss': 0.5182440641621382}
2022-12-31 13:35:45,952 INFO:     Found new best model at epoch 3
2022-12-31 13:35:45,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:45,953 INFO:     Epoch: 4
2022-12-31 13:35:47,524 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4994048992792765, 'Total loss': 0.4994048992792765} | train loss {'Reaction outcome loss': 0.49604363272110913, 'Total loss': 0.49604363272110913}
2022-12-31 13:35:47,524 INFO:     Found new best model at epoch 4
2022-12-31 13:35:47,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:47,525 INFO:     Epoch: 5
2022-12-31 13:35:49,100 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5319958508014679, 'Total loss': 0.5319958508014679} | train loss {'Reaction outcome loss': 0.48685957298947435, 'Total loss': 0.48685957298947435}
2022-12-31 13:35:49,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:49,100 INFO:     Epoch: 6
2022-12-31 13:35:50,675 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5089621980985005, 'Total loss': 0.5089621980985005} | train loss {'Reaction outcome loss': 0.47682624461466094, 'Total loss': 0.47682624461466094}
2022-12-31 13:35:50,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:50,675 INFO:     Epoch: 7
2022-12-31 13:35:52,271 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5476320167382558, 'Total loss': 0.5476320167382558} | train loss {'Reaction outcome loss': 0.47310061708807505, 'Total loss': 0.47310061708807505}
2022-12-31 13:35:52,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:52,271 INFO:     Epoch: 8
2022-12-31 13:35:53,836 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5246405700842539, 'Total loss': 0.5246405700842539} | train loss {'Reaction outcome loss': 0.4651417303349259, 'Total loss': 0.4651417303349259}
2022-12-31 13:35:53,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:53,836 INFO:     Epoch: 9
2022-12-31 13:35:55,416 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5028138399124146, 'Total loss': 0.5028138399124146} | train loss {'Reaction outcome loss': 0.46154277318078213, 'Total loss': 0.46154277318078213}
2022-12-31 13:35:55,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:55,416 INFO:     Epoch: 10
2022-12-31 13:35:57,002 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5133230785528818, 'Total loss': 0.5133230785528818} | train loss {'Reaction outcome loss': 0.4461570481642586, 'Total loss': 0.4461570481642586}
2022-12-31 13:35:57,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:57,002 INFO:     Epoch: 11
2022-12-31 13:35:58,562 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4924761990706126, 'Total loss': 0.4924761990706126} | train loss {'Reaction outcome loss': 0.4429773782891981, 'Total loss': 0.4429773782891981}
2022-12-31 13:35:58,562 INFO:     Found new best model at epoch 11
2022-12-31 13:35:58,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:35:58,563 INFO:     Epoch: 12
2022-12-31 13:36:00,131 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4972141335407893, 'Total loss': 0.4972141335407893} | train loss {'Reaction outcome loss': 0.4356093492455148, 'Total loss': 0.4356093492455148}
2022-12-31 13:36:00,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:00,131 INFO:     Epoch: 13
2022-12-31 13:36:01,734 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4730572998523712, 'Total loss': 0.4730572998523712} | train loss {'Reaction outcome loss': 0.42917002358119866, 'Total loss': 0.42917002358119866}
2022-12-31 13:36:01,734 INFO:     Found new best model at epoch 13
2022-12-31 13:36:01,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:01,735 INFO:     Epoch: 14
2022-12-31 13:36:03,313 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5147341251373291, 'Total loss': 0.5147341251373291} | train loss {'Reaction outcome loss': 0.42684836553691496, 'Total loss': 0.42684836553691496}
2022-12-31 13:36:03,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:03,314 INFO:     Epoch: 15
2022-12-31 13:36:04,891 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5030369381109874, 'Total loss': 0.5030369381109874} | train loss {'Reaction outcome loss': 0.4219878987852498, 'Total loss': 0.4219878987852498}
2022-12-31 13:36:04,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:04,892 INFO:     Epoch: 16
2022-12-31 13:36:06,469 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4740001300970713, 'Total loss': 0.4740001300970713} | train loss {'Reaction outcome loss': 0.4150884641932385, 'Total loss': 0.4150884641932385}
2022-12-31 13:36:06,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:06,470 INFO:     Epoch: 17
2022-12-31 13:36:08,050 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4713518003622691, 'Total loss': 0.4713518003622691} | train loss {'Reaction outcome loss': 0.4084156228167544, 'Total loss': 0.4084156228167544}
2022-12-31 13:36:08,050 INFO:     Found new best model at epoch 17
2022-12-31 13:36:08,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:08,051 INFO:     Epoch: 18
2022-12-31 13:36:09,609 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4663846741120021, 'Total loss': 0.4663846741120021} | train loss {'Reaction outcome loss': 0.400807408292905, 'Total loss': 0.400807408292905}
2022-12-31 13:36:09,609 INFO:     Found new best model at epoch 18
2022-12-31 13:36:09,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:09,610 INFO:     Epoch: 19
2022-12-31 13:36:11,174 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.487242317199707, 'Total loss': 0.487242317199707} | train loss {'Reaction outcome loss': 0.3981368397104784, 'Total loss': 0.3981368397104784}
2022-12-31 13:36:11,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:11,176 INFO:     Epoch: 20
2022-12-31 13:36:12,753 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46424476901690165, 'Total loss': 0.46424476901690165} | train loss {'Reaction outcome loss': 0.3880272460654653, 'Total loss': 0.3880272460654653}
2022-12-31 13:36:12,753 INFO:     Found new best model at epoch 20
2022-12-31 13:36:12,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:12,754 INFO:     Epoch: 21
2022-12-31 13:36:14,332 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46721331775188446, 'Total loss': 0.46721331775188446} | train loss {'Reaction outcome loss': 0.3793802403490922, 'Total loss': 0.3793802403490922}
2022-12-31 13:36:14,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:14,332 INFO:     Epoch: 22
2022-12-31 13:36:15,912 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45453291734059653, 'Total loss': 0.45453291734059653} | train loss {'Reaction outcome loss': 0.37864956391693483, 'Total loss': 0.37864956391693483}
2022-12-31 13:36:15,912 INFO:     Found new best model at epoch 22
2022-12-31 13:36:15,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:15,913 INFO:     Epoch: 23
2022-12-31 13:36:17,491 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4368893623352051, 'Total loss': 0.4368893623352051} | train loss {'Reaction outcome loss': 0.37664068850424015, 'Total loss': 0.37664068850424015}
2022-12-31 13:36:17,492 INFO:     Found new best model at epoch 23
2022-12-31 13:36:17,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:17,493 INFO:     Epoch: 24
2022-12-31 13:36:19,063 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44649880826473237, 'Total loss': 0.44649880826473237} | train loss {'Reaction outcome loss': 0.3650868099553998, 'Total loss': 0.3650868099553998}
2022-12-31 13:36:19,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:19,063 INFO:     Epoch: 25
2022-12-31 13:36:20,632 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4497150788704554, 'Total loss': 0.4497150788704554} | train loss {'Reaction outcome loss': 0.3569536635521593, 'Total loss': 0.3569536635521593}
2022-12-31 13:36:20,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:20,632 INFO:     Epoch: 26
2022-12-31 13:36:22,210 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4219378426671028, 'Total loss': 0.4219378426671028} | train loss {'Reaction outcome loss': 0.3587382829222292, 'Total loss': 0.3587382829222292}
2022-12-31 13:36:22,210 INFO:     Found new best model at epoch 26
2022-12-31 13:36:22,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:22,211 INFO:     Epoch: 27
2022-12-31 13:36:23,789 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5070809036493301, 'Total loss': 0.5070809036493301} | train loss {'Reaction outcome loss': 0.34808685383123666, 'Total loss': 0.34808685383123666}
2022-12-31 13:36:23,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:23,789 INFO:     Epoch: 28
2022-12-31 13:36:25,368 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49143266876538594, 'Total loss': 0.49143266876538594} | train loss {'Reaction outcome loss': 0.3474058139368177, 'Total loss': 0.3474058139368177}
2022-12-31 13:36:25,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:25,369 INFO:     Epoch: 29
2022-12-31 13:36:26,931 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.465886390209198, 'Total loss': 0.465886390209198} | train loss {'Reaction outcome loss': 0.34320095485261887, 'Total loss': 0.34320095485261887}
2022-12-31 13:36:26,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:26,931 INFO:     Epoch: 30
2022-12-31 13:36:28,522 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47817742625872295, 'Total loss': 0.47817742625872295} | train loss {'Reaction outcome loss': 0.34012230026546, 'Total loss': 0.34012230026546}
2022-12-31 13:36:28,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:28,523 INFO:     Epoch: 31
2022-12-31 13:36:30,134 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4363675554593404, 'Total loss': 0.4363675554593404} | train loss {'Reaction outcome loss': 0.3327219811202855, 'Total loss': 0.3327219811202855}
2022-12-31 13:36:30,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:30,135 INFO:     Epoch: 32
2022-12-31 13:36:31,776 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4378002732992172, 'Total loss': 0.4378002732992172} | train loss {'Reaction outcome loss': 0.3312056029414779, 'Total loss': 0.3312056029414779}
2022-12-31 13:36:31,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:31,777 INFO:     Epoch: 33
2022-12-31 13:36:33,419 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41940210660298666, 'Total loss': 0.41940210660298666} | train loss {'Reaction outcome loss': 0.3219141919866919, 'Total loss': 0.3219141919866919}
2022-12-31 13:36:33,419 INFO:     Found new best model at epoch 33
2022-12-31 13:36:33,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:33,421 INFO:     Epoch: 34
2022-12-31 13:36:35,067 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42219444836179415, 'Total loss': 0.42219444836179415} | train loss {'Reaction outcome loss': 0.32063547758268696, 'Total loss': 0.32063547758268696}
2022-12-31 13:36:35,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:35,067 INFO:     Epoch: 35
2022-12-31 13:36:36,676 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4333037078380585, 'Total loss': 0.4333037078380585} | train loss {'Reaction outcome loss': 0.3165528216430182, 'Total loss': 0.3165528216430182}
2022-12-31 13:36:36,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:36,676 INFO:     Epoch: 36
2022-12-31 13:36:38,299 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5160810947418213, 'Total loss': 0.5160810947418213} | train loss {'Reaction outcome loss': 0.31613987236115326, 'Total loss': 0.31613987236115326}
2022-12-31 13:36:38,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:38,299 INFO:     Epoch: 37
2022-12-31 13:36:39,945 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4264290640751521, 'Total loss': 0.4264290640751521} | train loss {'Reaction outcome loss': 0.3116445492169514, 'Total loss': 0.3116445492169514}
2022-12-31 13:36:39,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:39,945 INFO:     Epoch: 38
2022-12-31 13:36:41,589 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4467609236637751, 'Total loss': 0.4467609236637751} | train loss {'Reaction outcome loss': 0.3083040785470572, 'Total loss': 0.3083040785470572}
2022-12-31 13:36:41,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:41,590 INFO:     Epoch: 39
2022-12-31 13:36:43,231 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40832793911298115, 'Total loss': 0.40832793911298115} | train loss {'Reaction outcome loss': 0.3023390174736836, 'Total loss': 0.3023390174736836}
2022-12-31 13:36:43,231 INFO:     Found new best model at epoch 39
2022-12-31 13:36:43,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:43,232 INFO:     Epoch: 40
2022-12-31 13:36:44,872 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38988974286864203, 'Total loss': 0.38988974286864203} | train loss {'Reaction outcome loss': 0.30034550434713875, 'Total loss': 0.30034550434713875}
2022-12-31 13:36:44,872 INFO:     Found new best model at epoch 40
2022-12-31 13:36:44,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:44,874 INFO:     Epoch: 41
2022-12-31 13:36:46,485 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5057763874530792, 'Total loss': 0.5057763874530792} | train loss {'Reaction outcome loss': 0.29341906544192253, 'Total loss': 0.29341906544192253}
2022-12-31 13:36:46,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:46,486 INFO:     Epoch: 42
2022-12-31 13:36:48,108 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4517837127049764, 'Total loss': 0.4517837127049764} | train loss {'Reaction outcome loss': 0.3000148626326195, 'Total loss': 0.3000148626326195}
2022-12-31 13:36:48,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:48,108 INFO:     Epoch: 43
2022-12-31 13:36:49,753 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45010301321744917, 'Total loss': 0.45010301321744917} | train loss {'Reaction outcome loss': 0.29343578535582304, 'Total loss': 0.29343578535582304}
2022-12-31 13:36:49,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:49,753 INFO:     Epoch: 44
2022-12-31 13:36:51,400 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4041751140728593, 'Total loss': 0.4041751140728593} | train loss {'Reaction outcome loss': 0.28364682095847005, 'Total loss': 0.28364682095847005}
2022-12-31 13:36:51,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:51,401 INFO:     Epoch: 45
2022-12-31 13:36:53,042 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4466858059167862, 'Total loss': 0.4466858059167862} | train loss {'Reaction outcome loss': 0.2868342539398653, 'Total loss': 0.2868342539398653}
2022-12-31 13:36:53,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:53,043 INFO:     Epoch: 46
2022-12-31 13:36:54,679 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3990068664153417, 'Total loss': 0.3990068664153417} | train loss {'Reaction outcome loss': 0.27949209786209234, 'Total loss': 0.27949209786209234}
2022-12-31 13:36:54,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:54,679 INFO:     Epoch: 47
2022-12-31 13:36:56,287 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43507768313090006, 'Total loss': 0.43507768313090006} | train loss {'Reaction outcome loss': 0.28063951200389775, 'Total loss': 0.28063951200389775}
2022-12-31 13:36:56,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:56,287 INFO:     Epoch: 48
2022-12-31 13:36:57,917 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4457884890337785, 'Total loss': 0.4457884890337785} | train loss {'Reaction outcome loss': 0.27834432143236876, 'Total loss': 0.27834432143236876}
2022-12-31 13:36:57,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:57,917 INFO:     Epoch: 49
2022-12-31 13:36:59,534 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40661447644233706, 'Total loss': 0.40661447644233706} | train loss {'Reaction outcome loss': 0.27172655843170807, 'Total loss': 0.27172655843170807}
2022-12-31 13:36:59,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:36:59,534 INFO:     Epoch: 50
2022-12-31 13:37:01,163 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41473299662272134, 'Total loss': 0.41473299662272134} | train loss {'Reaction outcome loss': 0.27379462594420706, 'Total loss': 0.27379462594420706}
2022-12-31 13:37:01,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:01,164 INFO:     Epoch: 51
2022-12-31 13:37:02,785 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5039965550104777, 'Total loss': 0.5039965550104777} | train loss {'Reaction outcome loss': 0.2726356290225833, 'Total loss': 0.2726356290225833}
2022-12-31 13:37:02,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:02,785 INFO:     Epoch: 52
2022-12-31 13:37:04,307 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41941187977790834, 'Total loss': 0.41941187977790834} | train loss {'Reaction outcome loss': 0.26613342460945966, 'Total loss': 0.26613342460945966}
2022-12-31 13:37:04,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:04,307 INFO:     Epoch: 53
2022-12-31 13:37:05,383 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4291568468014399, 'Total loss': 0.4291568468014399} | train loss {'Reaction outcome loss': 0.2720868013029389, 'Total loss': 0.2720868013029389}
2022-12-31 13:37:05,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:05,384 INFO:     Epoch: 54
2022-12-31 13:37:06,444 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4362330635388692, 'Total loss': 0.4362330635388692} | train loss {'Reaction outcome loss': 0.268456436473725, 'Total loss': 0.268456436473725}
2022-12-31 13:37:06,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:06,444 INFO:     Epoch: 55
2022-12-31 13:37:07,498 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49338353872299195, 'Total loss': 0.49338353872299195} | train loss {'Reaction outcome loss': 0.2693346762321752, 'Total loss': 0.2693346762321752}
2022-12-31 13:37:07,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:07,498 INFO:     Epoch: 56
2022-12-31 13:37:08,552 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4430428390701612, 'Total loss': 0.4430428390701612} | train loss {'Reaction outcome loss': 0.25820883209525, 'Total loss': 0.25820883209525}
2022-12-31 13:37:08,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:08,552 INFO:     Epoch: 57
2022-12-31 13:37:10,115 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4114154895146688, 'Total loss': 0.4114154895146688} | train loss {'Reaction outcome loss': 0.25806398122018115, 'Total loss': 0.25806398122018115}
2022-12-31 13:37:10,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:10,115 INFO:     Epoch: 58
2022-12-31 13:37:11,750 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42104590361317, 'Total loss': 0.42104590361317} | train loss {'Reaction outcome loss': 0.25896961914162353, 'Total loss': 0.25896961914162353}
2022-12-31 13:37:11,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:11,751 INFO:     Epoch: 59
2022-12-31 13:37:13,340 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4705196032921473, 'Total loss': 0.4705196032921473} | train loss {'Reaction outcome loss': 0.24821436071142938, 'Total loss': 0.24821436071142938}
2022-12-31 13:37:13,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:13,340 INFO:     Epoch: 60
2022-12-31 13:37:14,931 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4213968629638354, 'Total loss': 0.4213968629638354} | train loss {'Reaction outcome loss': 0.2538861271365102, 'Total loss': 0.2538861271365102}
2022-12-31 13:37:14,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:14,932 INFO:     Epoch: 61
2022-12-31 13:37:16,517 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45372514724731444, 'Total loss': 0.45372514724731444} | train loss {'Reaction outcome loss': 0.24644045067119422, 'Total loss': 0.24644045067119422}
2022-12-31 13:37:16,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:16,517 INFO:     Epoch: 62
2022-12-31 13:37:18,082 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3648438774049282, 'Total loss': 0.3648438774049282} | train loss {'Reaction outcome loss': 0.24452590664704346, 'Total loss': 0.24452590664704346}
2022-12-31 13:37:18,083 INFO:     Found new best model at epoch 62
2022-12-31 13:37:18,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:18,084 INFO:     Epoch: 63
2022-12-31 13:37:19,707 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4224440763394038, 'Total loss': 0.4224440763394038} | train loss {'Reaction outcome loss': 0.24692991565624287, 'Total loss': 0.24692991565624287}
2022-12-31 13:37:19,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:19,707 INFO:     Epoch: 64
2022-12-31 13:37:21,293 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43673683106899264, 'Total loss': 0.43673683106899264} | train loss {'Reaction outcome loss': 0.2472664793520286, 'Total loss': 0.2472664793520286}
2022-12-31 13:37:21,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:21,293 INFO:     Epoch: 65
2022-12-31 13:37:22,866 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4150973419348399, 'Total loss': 0.4150973419348399} | train loss {'Reaction outcome loss': 0.24499904883619933, 'Total loss': 0.24499904883619933}
2022-12-31 13:37:22,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:22,867 INFO:     Epoch: 66
2022-12-31 13:37:24,453 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43826359510421753, 'Total loss': 0.43826359510421753} | train loss {'Reaction outcome loss': 0.2417524693348201, 'Total loss': 0.2417524693348201}
2022-12-31 13:37:24,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:24,453 INFO:     Epoch: 67
2022-12-31 13:37:26,042 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42955332895119985, 'Total loss': 0.42955332895119985} | train loss {'Reaction outcome loss': 0.242498150707061, 'Total loss': 0.242498150707061}
2022-12-31 13:37:26,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:26,042 INFO:     Epoch: 68
2022-12-31 13:37:27,616 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4367060209314028, 'Total loss': 0.4367060209314028} | train loss {'Reaction outcome loss': 0.24267057910204154, 'Total loss': 0.24267057910204154}
2022-12-31 13:37:27,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:27,617 INFO:     Epoch: 69
2022-12-31 13:37:29,199 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40455095171928407, 'Total loss': 0.40455095171928407} | train loss {'Reaction outcome loss': 0.24095458919491716, 'Total loss': 0.24095458919491716}
2022-12-31 13:37:29,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:29,199 INFO:     Epoch: 70
2022-12-31 13:37:30,771 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39597760438919066, 'Total loss': 0.39597760438919066} | train loss {'Reaction outcome loss': 0.2419582615328121, 'Total loss': 0.2419582615328121}
2022-12-31 13:37:30,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:30,772 INFO:     Epoch: 71
2022-12-31 13:37:32,352 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43318199515342715, 'Total loss': 0.43318199515342715} | train loss {'Reaction outcome loss': 0.2299122418452233, 'Total loss': 0.2299122418452233}
2022-12-31 13:37:32,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:32,352 INFO:     Epoch: 72
2022-12-31 13:37:33,933 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43304978708426156, 'Total loss': 0.43304978708426156} | train loss {'Reaction outcome loss': 0.2362017290687319, 'Total loss': 0.2362017290687319}
2022-12-31 13:37:33,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:33,934 INFO:     Epoch: 73
2022-12-31 13:37:35,514 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4066511193911235, 'Total loss': 0.4066511193911235} | train loss {'Reaction outcome loss': 0.23228901415733394, 'Total loss': 0.23228901415733394}
2022-12-31 13:37:35,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:35,515 INFO:     Epoch: 74
2022-12-31 13:37:37,077 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40247799141022067, 'Total loss': 0.40247799141022067} | train loss {'Reaction outcome loss': 0.2323435752264248, 'Total loss': 0.2323435752264248}
2022-12-31 13:37:37,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:37,078 INFO:     Epoch: 75
2022-12-31 13:37:38,659 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41224430774648985, 'Total loss': 0.41224430774648985} | train loss {'Reaction outcome loss': 0.22781913172164966, 'Total loss': 0.22781913172164966}
2022-12-31 13:37:38,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:38,660 INFO:     Epoch: 76
2022-12-31 13:37:40,223 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45255401035149895, 'Total loss': 0.45255401035149895} | train loss {'Reaction outcome loss': 0.23338516041416524, 'Total loss': 0.23338516041416524}
2022-12-31 13:37:40,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:40,223 INFO:     Epoch: 77
2022-12-31 13:37:41,825 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42546714742978414, 'Total loss': 0.42546714742978414} | train loss {'Reaction outcome loss': 0.22848776954731378, 'Total loss': 0.22848776954731378}
2022-12-31 13:37:41,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:41,825 INFO:     Epoch: 78
2022-12-31 13:37:43,410 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41181676983833315, 'Total loss': 0.41181676983833315} | train loss {'Reaction outcome loss': 0.2253201674546263, 'Total loss': 0.2253201674546263}
2022-12-31 13:37:43,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:43,410 INFO:     Epoch: 79
2022-12-31 13:37:45,009 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43151221175988513, 'Total loss': 0.43151221175988513} | train loss {'Reaction outcome loss': 0.22564777386859333, 'Total loss': 0.22564777386859333}
2022-12-31 13:37:45,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:45,009 INFO:     Epoch: 80
2022-12-31 13:37:46,590 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4366671403249105, 'Total loss': 0.4366671403249105} | train loss {'Reaction outcome loss': 0.22902754500398337, 'Total loss': 0.22902754500398337}
2022-12-31 13:37:46,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:46,590 INFO:     Epoch: 81
2022-12-31 13:37:48,196 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45329476296901705, 'Total loss': 0.45329476296901705} | train loss {'Reaction outcome loss': 0.22395843393220893, 'Total loss': 0.22395843393220893}
2022-12-31 13:37:48,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:48,197 INFO:     Epoch: 82
2022-12-31 13:37:49,766 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40437509715557096, 'Total loss': 0.40437509715557096} | train loss {'Reaction outcome loss': 0.22190246375696907, 'Total loss': 0.22190246375696907}
2022-12-31 13:37:49,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:49,766 INFO:     Epoch: 83
2022-12-31 13:37:51,347 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4329879422982534, 'Total loss': 0.4329879422982534} | train loss {'Reaction outcome loss': 0.21838247687366835, 'Total loss': 0.21838247687366835}
2022-12-31 13:37:51,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:51,347 INFO:     Epoch: 84
2022-12-31 13:37:52,928 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4157654717564583, 'Total loss': 0.4157654717564583} | train loss {'Reaction outcome loss': 0.22536954406057777, 'Total loss': 0.22536954406057777}
2022-12-31 13:37:52,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:52,929 INFO:     Epoch: 85
2022-12-31 13:37:54,500 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4193715373675028, 'Total loss': 0.4193715373675028} | train loss {'Reaction outcome loss': 0.21772813990134815, 'Total loss': 0.21772813990134815}
2022-12-31 13:37:54,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:54,500 INFO:     Epoch: 86
2022-12-31 13:37:56,127 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4472729653120041, 'Total loss': 0.4472729653120041} | train loss {'Reaction outcome loss': 0.2179193452990363, 'Total loss': 0.2179193452990363}
2022-12-31 13:37:56,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:56,127 INFO:     Epoch: 87
2022-12-31 13:37:57,712 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.402596008280913, 'Total loss': 0.402596008280913} | train loss {'Reaction outcome loss': 0.22280962396811735, 'Total loss': 0.22280962396811735}
2022-12-31 13:37:57,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:57,712 INFO:     Epoch: 88
2022-12-31 13:37:59,292 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3911876119673252, 'Total loss': 0.3911876119673252} | train loss {'Reaction outcome loss': 0.21035284023883158, 'Total loss': 0.21035284023883158}
2022-12-31 13:37:59,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:37:59,293 INFO:     Epoch: 89
2022-12-31 13:38:00,870 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45841659406820934, 'Total loss': 0.45841659406820934} | train loss {'Reaction outcome loss': 0.22035053779278294, 'Total loss': 0.22035053779278294}
2022-12-31 13:38:00,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:00,871 INFO:     Epoch: 90
2022-12-31 13:38:02,449 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4494492808977763, 'Total loss': 0.4494492808977763} | train loss {'Reaction outcome loss': 0.2106418765778911, 'Total loss': 0.2106418765778911}
2022-12-31 13:38:02,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:02,449 INFO:     Epoch: 91
2022-12-31 13:38:04,010 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40860326985518136, 'Total loss': 0.40860326985518136} | train loss {'Reaction outcome loss': 0.2101101418922748, 'Total loss': 0.2101101418922748}
2022-12-31 13:38:04,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:04,010 INFO:     Epoch: 92
2022-12-31 13:38:05,590 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42384716123342514, 'Total loss': 0.42384716123342514} | train loss {'Reaction outcome loss': 0.21460158441119528, 'Total loss': 0.21460158441119528}
2022-12-31 13:38:05,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:05,590 INFO:     Epoch: 93
2022-12-31 13:38:07,169 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4518221060434977, 'Total loss': 0.4518221060434977} | train loss {'Reaction outcome loss': 0.20985114430438218, 'Total loss': 0.20985114430438218}
2022-12-31 13:38:07,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:07,170 INFO:     Epoch: 94
2022-12-31 13:38:08,731 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3902369638284047, 'Total loss': 0.3902369638284047} | train loss {'Reaction outcome loss': 0.2050175233039579, 'Total loss': 0.2050175233039579}
2022-12-31 13:38:08,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:08,731 INFO:     Epoch: 95
2022-12-31 13:38:10,343 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41119324962298076, 'Total loss': 0.41119324962298076} | train loss {'Reaction outcome loss': 0.2117277850496593, 'Total loss': 0.2117277850496593}
2022-12-31 13:38:10,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:10,343 INFO:     Epoch: 96
2022-12-31 13:38:11,950 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.361455770333608, 'Total loss': 0.361455770333608} | train loss {'Reaction outcome loss': 0.20823202463643578, 'Total loss': 0.20823202463643578}
2022-12-31 13:38:11,951 INFO:     Found new best model at epoch 96
2022-12-31 13:38:11,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:11,952 INFO:     Epoch: 97
2022-12-31 13:38:13,545 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40623335589965187, 'Total loss': 0.40623335589965187} | train loss {'Reaction outcome loss': 0.20629068400119724, 'Total loss': 0.20629068400119724}
2022-12-31 13:38:13,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:13,546 INFO:     Epoch: 98
2022-12-31 13:38:15,131 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42137110233306885, 'Total loss': 0.42137110233306885} | train loss {'Reaction outcome loss': 0.20738623342115942, 'Total loss': 0.20738623342115942}
2022-12-31 13:38:15,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:15,131 INFO:     Epoch: 99
2022-12-31 13:38:16,706 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4110742916663488, 'Total loss': 0.4110742916663488} | train loss {'Reaction outcome loss': 0.204858242578777, 'Total loss': 0.204858242578777}
2022-12-31 13:38:16,706 INFO:     Best model found after epoch 97 of 100.
2022-12-31 13:38:16,706 INFO:   Done with stage: TRAINING
2022-12-31 13:38:16,706 INFO:   Starting stage: EVALUATION
2022-12-31 13:38:16,852 INFO:   Done with stage: EVALUATION
2022-12-31 13:38:16,852 INFO:   Leaving out SEQ value Fold_2
2022-12-31 13:38:16,865 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 13:38:16,865 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:38:17,516 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:38:17,516 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:38:17,584 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:38:17,584 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:38:17,584 INFO:     No hyperparam tuning for this model
2022-12-31 13:38:17,584 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:38:17,584 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:38:17,585 INFO:     None feature selector for col prot
2022-12-31 13:38:17,585 INFO:     None feature selector for col prot
2022-12-31 13:38:17,586 INFO:     None feature selector for col prot
2022-12-31 13:38:17,586 INFO:     None feature selector for col chem
2022-12-31 13:38:17,586 INFO:     None feature selector for col chem
2022-12-31 13:38:17,586 INFO:     None feature selector for col chem
2022-12-31 13:38:17,586 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:38:17,586 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:38:17,588 INFO:     Number of params in model 223921
2022-12-31 13:38:17,591 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:38:17,592 INFO:   Starting stage: TRAINING
2022-12-31 13:38:17,638 INFO:     Val loss before train {'Reaction outcome loss': 0.9400974194208781, 'Total loss': 0.9400974194208781}
2022-12-31 13:38:17,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:17,638 INFO:     Epoch: 0
2022-12-31 13:38:19,232 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6826137165228526, 'Total loss': 0.6826137165228526} | train loss {'Reaction outcome loss': 0.8388081643268139, 'Total loss': 0.8388081643268139}
2022-12-31 13:38:19,232 INFO:     Found new best model at epoch 0
2022-12-31 13:38:19,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:19,233 INFO:     Epoch: 1
2022-12-31 13:38:20,829 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5193544159332911, 'Total loss': 0.5193544159332911} | train loss {'Reaction outcome loss': 0.620897404360075, 'Total loss': 0.620897404360075}
2022-12-31 13:38:20,829 INFO:     Found new best model at epoch 1
2022-12-31 13:38:20,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:20,830 INFO:     Epoch: 2
2022-12-31 13:38:22,443 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5083771407604217, 'Total loss': 0.5083771407604217} | train loss {'Reaction outcome loss': 0.5474814756290756, 'Total loss': 0.5474814756290756}
2022-12-31 13:38:22,443 INFO:     Found new best model at epoch 2
2022-12-31 13:38:22,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:22,444 INFO:     Epoch: 3
2022-12-31 13:38:24,042 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.482490344842275, 'Total loss': 0.482490344842275} | train loss {'Reaction outcome loss': 0.5201479413539823, 'Total loss': 0.5201479413539823}
2022-12-31 13:38:24,043 INFO:     Found new best model at epoch 3
2022-12-31 13:38:24,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:24,044 INFO:     Epoch: 4
2022-12-31 13:38:25,626 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48697246611118317, 'Total loss': 0.48697246611118317} | train loss {'Reaction outcome loss': 0.4981596091911741, 'Total loss': 0.4981596091911741}
2022-12-31 13:38:25,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:25,627 INFO:     Epoch: 5
2022-12-31 13:38:27,224 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4590224633614222, 'Total loss': 0.4590224633614222} | train loss {'Reaction outcome loss': 0.48655368132095267, 'Total loss': 0.48655368132095267}
2022-12-31 13:38:27,225 INFO:     Found new best model at epoch 5
2022-12-31 13:38:27,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:27,226 INFO:     Epoch: 6
2022-12-31 13:38:28,857 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45895235538482665, 'Total loss': 0.45895235538482665} | train loss {'Reaction outcome loss': 0.47890740725463327, 'Total loss': 0.47890740725463327}
2022-12-31 13:38:28,857 INFO:     Found new best model at epoch 6
2022-12-31 13:38:28,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:28,858 INFO:     Epoch: 7
2022-12-31 13:38:30,450 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4629135976235072, 'Total loss': 0.4629135976235072} | train loss {'Reaction outcome loss': 0.46759828272527154, 'Total loss': 0.46759828272527154}
2022-12-31 13:38:30,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:30,451 INFO:     Epoch: 8
2022-12-31 13:38:32,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47699222366015115, 'Total loss': 0.47699222366015115} | train loss {'Reaction outcome loss': 0.4542917174688221, 'Total loss': 0.4542917174688221}
2022-12-31 13:38:32,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:32,104 INFO:     Epoch: 9
2022-12-31 13:38:33,687 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.481245489915212, 'Total loss': 0.481245489915212} | train loss {'Reaction outcome loss': 0.4603988631308949, 'Total loss': 0.4603988631308949}
2022-12-31 13:38:33,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:33,687 INFO:     Epoch: 10
2022-12-31 13:38:35,291 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44568003217379254, 'Total loss': 0.44568003217379254} | train loss {'Reaction outcome loss': 0.4544700043425508, 'Total loss': 0.4544700043425508}
2022-12-31 13:38:35,291 INFO:     Found new best model at epoch 10
2022-12-31 13:38:35,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:35,292 INFO:     Epoch: 11
2022-12-31 13:38:36,894 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4559653381506602, 'Total loss': 0.4559653381506602} | train loss {'Reaction outcome loss': 0.4415707357608489, 'Total loss': 0.4415707357608489}
2022-12-31 13:38:36,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:36,895 INFO:     Epoch: 12
2022-12-31 13:38:38,528 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4434896399577459, 'Total loss': 0.4434896399577459} | train loss {'Reaction outcome loss': 0.4334782373268891, 'Total loss': 0.4334782373268891}
2022-12-31 13:38:38,529 INFO:     Found new best model at epoch 12
2022-12-31 13:38:38,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:38,530 INFO:     Epoch: 13
2022-12-31 13:38:40,135 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43429885705312093, 'Total loss': 0.43429885705312093} | train loss {'Reaction outcome loss': 0.426530573000438, 'Total loss': 0.426530573000438}
2022-12-31 13:38:40,135 INFO:     Found new best model at epoch 13
2022-12-31 13:38:40,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:40,136 INFO:     Epoch: 14
2022-12-31 13:38:41,784 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41065910855929055, 'Total loss': 0.41065910855929055} | train loss {'Reaction outcome loss': 0.4241786890520449, 'Total loss': 0.4241786890520449}
2022-12-31 13:38:41,784 INFO:     Found new best model at epoch 14
2022-12-31 13:38:41,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:41,785 INFO:     Epoch: 15
2022-12-31 13:38:43,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44902874032656354, 'Total loss': 0.44902874032656354} | train loss {'Reaction outcome loss': 0.42057208553717956, 'Total loss': 0.42057208553717956}
2022-12-31 13:38:43,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:43,386 INFO:     Epoch: 16
2022-12-31 13:38:44,995 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43950762748718264, 'Total loss': 0.43950762748718264} | train loss {'Reaction outcome loss': 0.4128687005408489, 'Total loss': 0.4128687005408489}
2022-12-31 13:38:44,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:44,995 INFO:     Epoch: 17
2022-12-31 13:38:46,596 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4193184365828832, 'Total loss': 0.4193184365828832} | train loss {'Reaction outcome loss': 0.405843523460148, 'Total loss': 0.405843523460148}
2022-12-31 13:38:46,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:46,596 INFO:     Epoch: 18
2022-12-31 13:38:48,188 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4389246900876363, 'Total loss': 0.4389246900876363} | train loss {'Reaction outcome loss': 0.4005718939278248, 'Total loss': 0.4005718939278248}
2022-12-31 13:38:48,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:48,188 INFO:     Epoch: 19
2022-12-31 13:38:49,781 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42510167757670086, 'Total loss': 0.42510167757670086} | train loss {'Reaction outcome loss': 0.393573820563781, 'Total loss': 0.393573820563781}
2022-12-31 13:38:49,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:49,781 INFO:     Epoch: 20
2022-12-31 13:38:51,383 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4139597256978353, 'Total loss': 0.4139597256978353} | train loss {'Reaction outcome loss': 0.3849825318630812, 'Total loss': 0.3849825318630812}
2022-12-31 13:38:51,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:51,383 INFO:     Epoch: 21
2022-12-31 13:38:52,969 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4071257551511129, 'Total loss': 0.4071257551511129} | train loss {'Reaction outcome loss': 0.38180113050841935, 'Total loss': 0.38180113050841935}
2022-12-31 13:38:52,969 INFO:     Found new best model at epoch 21
2022-12-31 13:38:52,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:52,970 INFO:     Epoch: 22
2022-12-31 13:38:54,570 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45036318004131315, 'Total loss': 0.45036318004131315} | train loss {'Reaction outcome loss': 0.37534183870158055, 'Total loss': 0.37534183870158055}
2022-12-31 13:38:54,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:54,572 INFO:     Epoch: 23
2022-12-31 13:38:56,172 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.419335675239563, 'Total loss': 0.419335675239563} | train loss {'Reaction outcome loss': 0.37310824758053696, 'Total loss': 0.37310824758053696}
2022-12-31 13:38:56,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:56,172 INFO:     Epoch: 24
2022-12-31 13:38:57,762 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40711387197176613, 'Total loss': 0.40711387197176613} | train loss {'Reaction outcome loss': 0.36575616942378725, 'Total loss': 0.36575616942378725}
2022-12-31 13:38:57,762 INFO:     Found new best model at epoch 24
2022-12-31 13:38:57,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:57,763 INFO:     Epoch: 25
2022-12-31 13:38:59,349 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4308090527852376, 'Total loss': 0.4308090527852376} | train loss {'Reaction outcome loss': 0.36601029654597717, 'Total loss': 0.36601029654597717}
2022-12-31 13:38:59,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:38:59,349 INFO:     Epoch: 26
2022-12-31 13:39:00,931 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4018193413813909, 'Total loss': 0.4018193413813909} | train loss {'Reaction outcome loss': 0.35682805594954176, 'Total loss': 0.35682805594954176}
2022-12-31 13:39:00,931 INFO:     Found new best model at epoch 26
2022-12-31 13:39:00,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:00,932 INFO:     Epoch: 27
2022-12-31 13:39:02,534 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3786849160989126, 'Total loss': 0.3786849160989126} | train loss {'Reaction outcome loss': 0.344628290307239, 'Total loss': 0.344628290307239}
2022-12-31 13:39:02,534 INFO:     Found new best model at epoch 27
2022-12-31 13:39:02,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:02,535 INFO:     Epoch: 28
2022-12-31 13:39:04,136 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3641237378120422, 'Total loss': 0.3641237378120422} | train loss {'Reaction outcome loss': 0.3515690740497008, 'Total loss': 0.3515690740497008}
2022-12-31 13:39:04,136 INFO:     Found new best model at epoch 28
2022-12-31 13:39:04,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:04,137 INFO:     Epoch: 29
2022-12-31 13:39:05,747 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4022203594446182, 'Total loss': 0.4022203594446182} | train loss {'Reaction outcome loss': 0.3428180588640436, 'Total loss': 0.3428180588640436}
2022-12-31 13:39:05,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:05,747 INFO:     Epoch: 30
2022-12-31 13:39:07,327 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4037296076615651, 'Total loss': 0.4037296076615651} | train loss {'Reaction outcome loss': 0.3393272178614662, 'Total loss': 0.3393272178614662}
2022-12-31 13:39:07,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:07,328 INFO:     Epoch: 31
2022-12-31 13:39:08,983 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4026618073383967, 'Total loss': 0.4026618073383967} | train loss {'Reaction outcome loss': 0.33100356864505004, 'Total loss': 0.33100356864505004}
2022-12-31 13:39:08,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:08,983 INFO:     Epoch: 32
2022-12-31 13:39:10,586 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38581815858681995, 'Total loss': 0.38581815858681995} | train loss {'Reaction outcome loss': 0.3331335545891393, 'Total loss': 0.3331335545891393}
2022-12-31 13:39:10,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:10,586 INFO:     Epoch: 33
2022-12-31 13:39:12,191 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.372590027252833, 'Total loss': 0.372590027252833} | train loss {'Reaction outcome loss': 0.3196675469894914, 'Total loss': 0.3196675469894914}
2022-12-31 13:39:12,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:12,191 INFO:     Epoch: 34
2022-12-31 13:39:13,806 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39977726141611736, 'Total loss': 0.39977726141611736} | train loss {'Reaction outcome loss': 0.31603530677456926, 'Total loss': 0.31603530677456926}
2022-12-31 13:39:13,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:13,806 INFO:     Epoch: 35
2022-12-31 13:39:15,412 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38543142278989156, 'Total loss': 0.38543142278989156} | train loss {'Reaction outcome loss': 0.31493550783743823, 'Total loss': 0.31493550783743823}
2022-12-31 13:39:15,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:15,412 INFO:     Epoch: 36
2022-12-31 13:39:17,040 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37471658090750376, 'Total loss': 0.37471658090750376} | train loss {'Reaction outcome loss': 0.3184074205720294, 'Total loss': 0.3184074205720294}
2022-12-31 13:39:17,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:17,040 INFO:     Epoch: 37
2022-12-31 13:39:18,669 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39404319127400717, 'Total loss': 0.39404319127400717} | train loss {'Reaction outcome loss': 0.30533699566212885, 'Total loss': 0.30533699566212885}
2022-12-31 13:39:18,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:18,669 INFO:     Epoch: 38
2022-12-31 13:39:20,260 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3767654021581014, 'Total loss': 0.3767654021581014} | train loss {'Reaction outcome loss': 0.30422841344219054, 'Total loss': 0.30422841344219054}
2022-12-31 13:39:20,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:20,261 INFO:     Epoch: 39
2022-12-31 13:39:21,866 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37381547689437866, 'Total loss': 0.37381547689437866} | train loss {'Reaction outcome loss': 0.2953259088099003, 'Total loss': 0.2953259088099003}
2022-12-31 13:39:21,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:21,866 INFO:     Epoch: 40
2022-12-31 13:39:23,471 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3637479717532794, 'Total loss': 0.3637479717532794} | train loss {'Reaction outcome loss': 0.29393511391958616, 'Total loss': 0.29393511391958616}
2022-12-31 13:39:23,471 INFO:     Found new best model at epoch 40
2022-12-31 13:39:23,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:23,472 INFO:     Epoch: 41
2022-12-31 13:39:25,056 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3704782416423162, 'Total loss': 0.3704782416423162} | train loss {'Reaction outcome loss': 0.2872262783212601, 'Total loss': 0.2872262783212601}
2022-12-31 13:39:25,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:25,057 INFO:     Epoch: 42
2022-12-31 13:39:26,663 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3454075962305069, 'Total loss': 0.3454075962305069} | train loss {'Reaction outcome loss': 0.2893300811304663, 'Total loss': 0.2893300811304663}
2022-12-31 13:39:26,663 INFO:     Found new best model at epoch 42
2022-12-31 13:39:26,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:26,664 INFO:     Epoch: 43
2022-12-31 13:39:28,253 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35870492458343506, 'Total loss': 0.35870492458343506} | train loss {'Reaction outcome loss': 0.28946938164477803, 'Total loss': 0.28946938164477803}
2022-12-31 13:39:28,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:28,254 INFO:     Epoch: 44
2022-12-31 13:39:29,863 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3659097671508789, 'Total loss': 0.3659097671508789} | train loss {'Reaction outcome loss': 0.27763454709881846, 'Total loss': 0.27763454709881846}
2022-12-31 13:39:29,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:29,863 INFO:     Epoch: 45
2022-12-31 13:39:31,469 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3548462981979052, 'Total loss': 0.3548462981979052} | train loss {'Reaction outcome loss': 0.2772577008110111, 'Total loss': 0.2772577008110111}
2022-12-31 13:39:31,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:31,470 INFO:     Epoch: 46
2022-12-31 13:39:33,074 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37389504015445707, 'Total loss': 0.37389504015445707} | train loss {'Reaction outcome loss': 0.27913505944294215, 'Total loss': 0.27913505944294215}
2022-12-31 13:39:33,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:33,074 INFO:     Epoch: 47
2022-12-31 13:39:34,685 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35056695143381755, 'Total loss': 0.35056695143381755} | train loss {'Reaction outcome loss': 0.28022042305691397, 'Total loss': 0.28022042305691397}
2022-12-31 13:39:34,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:34,685 INFO:     Epoch: 48
2022-12-31 13:39:36,312 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3685568739970525, 'Total loss': 0.3685568739970525} | train loss {'Reaction outcome loss': 0.2704327711903483, 'Total loss': 0.2704327711903483}
2022-12-31 13:39:36,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:36,313 INFO:     Epoch: 49
2022-12-31 13:39:37,896 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3630365148186684, 'Total loss': 0.3630365148186684} | train loss {'Reaction outcome loss': 0.2690043805071907, 'Total loss': 0.2690043805071907}
2022-12-31 13:39:37,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:37,896 INFO:     Epoch: 50
2022-12-31 13:39:39,501 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33143703639507294, 'Total loss': 0.33143703639507294} | train loss {'Reaction outcome loss': 0.27236157387875726, 'Total loss': 0.27236157387875726}
2022-12-31 13:39:39,501 INFO:     Found new best model at epoch 50
2022-12-31 13:39:39,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:39,502 INFO:     Epoch: 51
2022-12-31 13:39:41,105 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36981307963530224, 'Total loss': 0.36981307963530224} | train loss {'Reaction outcome loss': 0.2615757575326592, 'Total loss': 0.2615757575326592}
2022-12-31 13:39:41,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:41,105 INFO:     Epoch: 52
2022-12-31 13:39:42,691 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.32968820035457613, 'Total loss': 0.32968820035457613} | train loss {'Reaction outcome loss': 0.25734138685231006, 'Total loss': 0.25734138685231006}
2022-12-31 13:39:42,691 INFO:     Found new best model at epoch 52
2022-12-31 13:39:42,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:42,692 INFO:     Epoch: 53
2022-12-31 13:39:44,294 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35382646024227143, 'Total loss': 0.35382646024227143} | train loss {'Reaction outcome loss': 0.26027897693706253, 'Total loss': 0.26027897693706253}
2022-12-31 13:39:44,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:44,295 INFO:     Epoch: 54
2022-12-31 13:39:45,913 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4288228174050649, 'Total loss': 0.4288228174050649} | train loss {'Reaction outcome loss': 0.25731299658489487, 'Total loss': 0.25731299658489487}
2022-12-31 13:39:45,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:45,913 INFO:     Epoch: 55
2022-12-31 13:39:47,513 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36860971252123514, 'Total loss': 0.36860971252123514} | train loss {'Reaction outcome loss': 0.25424363213951573, 'Total loss': 0.25424363213951573}
2022-12-31 13:39:47,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:47,513 INFO:     Epoch: 56
2022-12-31 13:39:49,119 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3828388830025991, 'Total loss': 0.3828388830025991} | train loss {'Reaction outcome loss': 0.25511663227620784, 'Total loss': 0.25511663227620784}
2022-12-31 13:39:49,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:49,119 INFO:     Epoch: 57
2022-12-31 13:39:50,724 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.34461816151936847, 'Total loss': 0.34461816151936847} | train loss {'Reaction outcome loss': 0.2547733014734992, 'Total loss': 0.2547733014734992}
2022-12-31 13:39:50,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:50,724 INFO:     Epoch: 58
2022-12-31 13:39:52,311 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37842947940031685, 'Total loss': 0.37842947940031685} | train loss {'Reaction outcome loss': 0.25288768373021897, 'Total loss': 0.25288768373021897}
2022-12-31 13:39:52,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:52,311 INFO:     Epoch: 59
2022-12-31 13:39:53,916 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40837029218673704, 'Total loss': 0.40837029218673704} | train loss {'Reaction outcome loss': 0.24538897975164392, 'Total loss': 0.24538897975164392}
2022-12-31 13:39:53,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:53,916 INFO:     Epoch: 60
2022-12-31 13:39:55,507 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3677624980608622, 'Total loss': 0.3677624980608622} | train loss {'Reaction outcome loss': 0.24943001492180095, 'Total loss': 0.24943001492180095}
2022-12-31 13:39:55,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:55,509 INFO:     Epoch: 61
2022-12-31 13:39:57,112 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.34988703231016793, 'Total loss': 0.34988703231016793} | train loss {'Reaction outcome loss': 0.24563071267665737, 'Total loss': 0.24563071267665737}
2022-12-31 13:39:57,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:57,112 INFO:     Epoch: 62
2022-12-31 13:39:58,721 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34942962328592936, 'Total loss': 0.34942962328592936} | train loss {'Reaction outcome loss': 0.23385083201565665, 'Total loss': 0.23385083201565665}
2022-12-31 13:39:58,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:39:58,721 INFO:     Epoch: 63
2022-12-31 13:40:00,338 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3977742612361908, 'Total loss': 0.3977742612361908} | train loss {'Reaction outcome loss': 0.24066169322706268, 'Total loss': 0.24066169322706268}
2022-12-31 13:40:00,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:00,338 INFO:     Epoch: 64
2022-12-31 13:40:01,956 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34904907643795013, 'Total loss': 0.34904907643795013} | train loss {'Reaction outcome loss': 0.23942922144094958, 'Total loss': 0.23942922144094958}
2022-12-31 13:40:01,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:01,956 INFO:     Epoch: 65
2022-12-31 13:40:03,556 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37180227438608804, 'Total loss': 0.37180227438608804} | train loss {'Reaction outcome loss': 0.23496154865698657, 'Total loss': 0.23496154865698657}
2022-12-31 13:40:03,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:03,556 INFO:     Epoch: 66
2022-12-31 13:40:05,162 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3579706947008769, 'Total loss': 0.3579706947008769} | train loss {'Reaction outcome loss': 0.2360630785488952, 'Total loss': 0.2360630785488952}
2022-12-31 13:40:05,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:05,162 INFO:     Epoch: 67
2022-12-31 13:40:06,805 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36973653237024945, 'Total loss': 0.36973653237024945} | train loss {'Reaction outcome loss': 0.2298033092932327, 'Total loss': 0.2298033092932327}
2022-12-31 13:40:06,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:06,805 INFO:     Epoch: 68
2022-12-31 13:40:08,462 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38554138292868934, 'Total loss': 0.38554138292868934} | train loss {'Reaction outcome loss': 0.23614977239665105, 'Total loss': 0.23614977239665105}
2022-12-31 13:40:08,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:08,462 INFO:     Epoch: 69
2022-12-31 13:40:10,089 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3462940245866776, 'Total loss': 0.3462940245866776} | train loss {'Reaction outcome loss': 0.2301076553238515, 'Total loss': 0.2301076553238515}
2022-12-31 13:40:10,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:10,090 INFO:     Epoch: 70
2022-12-31 13:40:11,756 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.33347603380680085, 'Total loss': 0.33347603380680085} | train loss {'Reaction outcome loss': 0.23285215579136445, 'Total loss': 0.23285215579136445}
2022-12-31 13:40:11,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:11,756 INFO:     Epoch: 71
2022-12-31 13:40:13,400 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3368730718890826, 'Total loss': 0.3368730718890826} | train loss {'Reaction outcome loss': 0.2304464941300506, 'Total loss': 0.2304464941300506}
2022-12-31 13:40:13,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:13,400 INFO:     Epoch: 72
2022-12-31 13:40:15,050 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35757478748758637, 'Total loss': 0.35757478748758637} | train loss {'Reaction outcome loss': 0.2255571660157429, 'Total loss': 0.2255571660157429}
2022-12-31 13:40:15,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:15,051 INFO:     Epoch: 73
2022-12-31 13:40:16,670 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34372023344039915, 'Total loss': 0.34372023344039915} | train loss {'Reaction outcome loss': 0.23409773068108264, 'Total loss': 0.23409773068108264}
2022-12-31 13:40:16,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:16,671 INFO:     Epoch: 74
2022-12-31 13:40:18,304 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3880377928415934, 'Total loss': 0.3880377928415934} | train loss {'Reaction outcome loss': 0.22320787641253784, 'Total loss': 0.22320787641253784}
2022-12-31 13:40:18,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:18,304 INFO:     Epoch: 75
2022-12-31 13:40:19,925 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3505838976552089, 'Total loss': 0.3505838976552089} | train loss {'Reaction outcome loss': 0.22365797833831857, 'Total loss': 0.22365797833831857}
2022-12-31 13:40:19,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:19,925 INFO:     Epoch: 76
2022-12-31 13:40:21,565 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35377001067002617, 'Total loss': 0.35377001067002617} | train loss {'Reaction outcome loss': 0.21864301886708631, 'Total loss': 0.21864301886708631}
2022-12-31 13:40:21,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:21,565 INFO:     Epoch: 77
2022-12-31 13:40:23,150 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3663848797480265, 'Total loss': 0.3663848797480265} | train loss {'Reaction outcome loss': 0.22034382085948095, 'Total loss': 0.22034382085948095}
2022-12-31 13:40:23,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:23,150 INFO:     Epoch: 78
2022-12-31 13:40:24,748 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37057788769404093, 'Total loss': 0.37057788769404093} | train loss {'Reaction outcome loss': 0.22149301220384174, 'Total loss': 0.22149301220384174}
2022-12-31 13:40:24,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:24,748 INFO:     Epoch: 79
2022-12-31 13:40:26,344 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3744958321253459, 'Total loss': 0.3744958321253459} | train loss {'Reaction outcome loss': 0.22223253837059231, 'Total loss': 0.22223253837059231}
2022-12-31 13:40:26,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:26,344 INFO:     Epoch: 80
2022-12-31 13:40:27,941 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3476937415699164, 'Total loss': 0.3476937415699164} | train loss {'Reaction outcome loss': 0.21553571212928008, 'Total loss': 0.21553571212928008}
2022-12-31 13:40:27,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:27,942 INFO:     Epoch: 81
2022-12-31 13:40:29,522 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37774490217367807, 'Total loss': 0.37774490217367807} | train loss {'Reaction outcome loss': 0.21654112040860593, 'Total loss': 0.21654112040860593}
2022-12-31 13:40:29,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:29,522 INFO:     Epoch: 82
2022-12-31 13:40:31,120 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3369833206137021, 'Total loss': 0.3369833206137021} | train loss {'Reaction outcome loss': 0.2142598994898807, 'Total loss': 0.2142598994898807}
2022-12-31 13:40:31,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:31,120 INFO:     Epoch: 83
2022-12-31 13:40:32,729 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3678066909313202, 'Total loss': 0.3678066909313202} | train loss {'Reaction outcome loss': 0.2224724313420971, 'Total loss': 0.2224724313420971}
2022-12-31 13:40:32,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:32,731 INFO:     Epoch: 84
2022-12-31 13:40:34,346 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3335023283958435, 'Total loss': 0.3335023283958435} | train loss {'Reaction outcome loss': 0.21349888487997717, 'Total loss': 0.21349888487997717}
2022-12-31 13:40:34,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:34,347 INFO:     Epoch: 85
2022-12-31 13:40:35,952 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3448086529970169, 'Total loss': 0.3448086529970169} | train loss {'Reaction outcome loss': 0.2183420386056613, 'Total loss': 0.2183420386056613}
2022-12-31 13:40:35,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:35,952 INFO:     Epoch: 86
2022-12-31 13:40:37,532 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35053868889808654, 'Total loss': 0.35053868889808654} | train loss {'Reaction outcome loss': 0.21632437865474147, 'Total loss': 0.21632437865474147}
2022-12-31 13:40:37,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:37,532 INFO:     Epoch: 87
2022-12-31 13:40:39,178 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3635893568396568, 'Total loss': 0.3635893568396568} | train loss {'Reaction outcome loss': 0.2111563567398456, 'Total loss': 0.2111563567398456}
2022-12-31 13:40:39,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:39,179 INFO:     Epoch: 88
2022-12-31 13:40:40,762 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.350686248143514, 'Total loss': 0.350686248143514} | train loss {'Reaction outcome loss': 0.2070099022103487, 'Total loss': 0.2070099022103487}
2022-12-31 13:40:40,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:40,762 INFO:     Epoch: 89
2022-12-31 13:40:42,371 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3876969228188197, 'Total loss': 0.3876969228188197} | train loss {'Reaction outcome loss': 0.20504900150979957, 'Total loss': 0.20504900150979957}
2022-12-31 13:40:42,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:42,371 INFO:     Epoch: 90
2022-12-31 13:40:43,968 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38776506582895914, 'Total loss': 0.38776506582895914} | train loss {'Reaction outcome loss': 0.2174900628517579, 'Total loss': 0.2174900628517579}
2022-12-31 13:40:43,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:43,969 INFO:     Epoch: 91
2022-12-31 13:40:45,568 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4047000924746195, 'Total loss': 0.4047000924746195} | train loss {'Reaction outcome loss': 0.21167263810108178, 'Total loss': 0.21167263810108178}
2022-12-31 13:40:45,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:45,569 INFO:     Epoch: 92
2022-12-31 13:40:47,153 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38078698962926866, 'Total loss': 0.38078698962926866} | train loss {'Reaction outcome loss': 0.20232314072603727, 'Total loss': 0.20232314072603727}
2022-12-31 13:40:47,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:47,154 INFO:     Epoch: 93
2022-12-31 13:40:48,753 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3466147775451342, 'Total loss': 0.3466147775451342} | train loss {'Reaction outcome loss': 0.20482436845752064, 'Total loss': 0.20482436845752064}
2022-12-31 13:40:48,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:48,753 INFO:     Epoch: 94
2022-12-31 13:40:50,337 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36461515227953595, 'Total loss': 0.36461515227953595} | train loss {'Reaction outcome loss': 0.2069254228165441, 'Total loss': 0.2069254228165441}
2022-12-31 13:40:50,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:50,337 INFO:     Epoch: 95
2022-12-31 13:40:51,939 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4027917981147766, 'Total loss': 0.4027917981147766} | train loss {'Reaction outcome loss': 0.20041239612402706, 'Total loss': 0.20041239612402706}
2022-12-31 13:40:51,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:51,940 INFO:     Epoch: 96
2022-12-31 13:40:53,540 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37066611150900525, 'Total loss': 0.37066611150900525} | train loss {'Reaction outcome loss': 0.20277959748382007, 'Total loss': 0.20277959748382007}
2022-12-31 13:40:53,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:53,540 INFO:     Epoch: 97
2022-12-31 13:40:55,141 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3679774716496468, 'Total loss': 0.3679774716496468} | train loss {'Reaction outcome loss': 0.19982165939099814, 'Total loss': 0.19982165939099814}
2022-12-31 13:40:55,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:55,142 INFO:     Epoch: 98
2022-12-31 13:40:56,739 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34277087450027466, 'Total loss': 0.34277087450027466} | train loss {'Reaction outcome loss': 0.19591781002109068, 'Total loss': 0.19591781002109068}
2022-12-31 13:40:56,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:56,739 INFO:     Epoch: 99
2022-12-31 13:40:58,340 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3674396296342214, 'Total loss': 0.3674396296342214} | train loss {'Reaction outcome loss': 0.19524970133347017, 'Total loss': 0.19524970133347017}
2022-12-31 13:40:58,340 INFO:     Best model found after epoch 53 of 100.
2022-12-31 13:40:58,340 INFO:   Done with stage: TRAINING
2022-12-31 13:40:58,340 INFO:   Starting stage: EVALUATION
2022-12-31 13:40:58,473 INFO:   Done with stage: EVALUATION
2022-12-31 13:40:58,473 INFO:   Leaving out SEQ value Fold_3
2022-12-31 13:40:58,486 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 13:40:58,486 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:40:59,127 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:40:59,127 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:40:59,195 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:40:59,195 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:40:59,195 INFO:     No hyperparam tuning for this model
2022-12-31 13:40:59,195 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:40:59,195 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:40:59,196 INFO:     None feature selector for col prot
2022-12-31 13:40:59,196 INFO:     None feature selector for col prot
2022-12-31 13:40:59,196 INFO:     None feature selector for col prot
2022-12-31 13:40:59,197 INFO:     None feature selector for col chem
2022-12-31 13:40:59,197 INFO:     None feature selector for col chem
2022-12-31 13:40:59,197 INFO:     None feature selector for col chem
2022-12-31 13:40:59,197 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:40:59,197 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:40:59,199 INFO:     Number of params in model 223921
2022-12-31 13:40:59,202 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:40:59,202 INFO:   Starting stage: TRAINING
2022-12-31 13:40:59,246 INFO:     Val loss before train {'Reaction outcome loss': 0.9609422087669373, 'Total loss': 0.9609422087669373}
2022-12-31 13:40:59,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:40:59,246 INFO:     Epoch: 0
2022-12-31 13:41:00,857 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6104825218518575, 'Total loss': 0.6104825218518575} | train loss {'Reaction outcome loss': 0.8221719279123919, 'Total loss': 0.8221719279123919}
2022-12-31 13:41:00,857 INFO:     Found new best model at epoch 0
2022-12-31 13:41:00,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:00,858 INFO:     Epoch: 1
2022-12-31 13:41:02,457 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5071087936560313, 'Total loss': 0.5071087936560313} | train loss {'Reaction outcome loss': 0.6049566305901882, 'Total loss': 0.6049566305901882}
2022-12-31 13:41:02,457 INFO:     Found new best model at epoch 1
2022-12-31 13:41:02,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:02,458 INFO:     Epoch: 2
2022-12-31 13:41:04,041 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5031781991322836, 'Total loss': 0.5031781991322836} | train loss {'Reaction outcome loss': 0.5318104051542978, 'Total loss': 0.5318104051542978}
2022-12-31 13:41:04,041 INFO:     Found new best model at epoch 2
2022-12-31 13:41:04,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:04,042 INFO:     Epoch: 3
2022-12-31 13:41:05,639 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4836124221483866, 'Total loss': 0.4836124221483866} | train loss {'Reaction outcome loss': 0.5065614173229593, 'Total loss': 0.5065614173229593}
2022-12-31 13:41:05,639 INFO:     Found new best model at epoch 3
2022-12-31 13:41:05,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:05,640 INFO:     Epoch: 4
2022-12-31 13:41:07,229 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4693683485190074, 'Total loss': 0.4693683485190074} | train loss {'Reaction outcome loss': 0.4931321425812088, 'Total loss': 0.4931321425812088}
2022-12-31 13:41:07,230 INFO:     Found new best model at epoch 4
2022-12-31 13:41:07,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:07,231 INFO:     Epoch: 5
2022-12-31 13:41:08,820 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4964787075916926, 'Total loss': 0.4964787075916926} | train loss {'Reaction outcome loss': 0.47951831978603, 'Total loss': 0.47951831978603}
2022-12-31 13:41:08,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:08,820 INFO:     Epoch: 6
2022-12-31 13:41:10,420 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48848494291305544, 'Total loss': 0.48848494291305544} | train loss {'Reaction outcome loss': 0.4702473103891324, 'Total loss': 0.4702473103891324}
2022-12-31 13:41:10,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:10,420 INFO:     Epoch: 7
2022-12-31 13:41:12,019 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47650308211644493, 'Total loss': 0.47650308211644493} | train loss {'Reaction outcome loss': 0.46565195803877213, 'Total loss': 0.46565195803877213}
2022-12-31 13:41:12,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:12,019 INFO:     Epoch: 8
2022-12-31 13:41:13,592 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47177491585413617, 'Total loss': 0.47177491585413617} | train loss {'Reaction outcome loss': 0.45450225842260095, 'Total loss': 0.45450225842260095}
2022-12-31 13:41:13,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:13,593 INFO:     Epoch: 9
2022-12-31 13:41:15,199 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4883733093738556, 'Total loss': 0.4883733093738556} | train loss {'Reaction outcome loss': 0.45045443374092564, 'Total loss': 0.45045443374092564}
2022-12-31 13:41:15,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:15,199 INFO:     Epoch: 10
2022-12-31 13:41:16,783 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46131607294082644, 'Total loss': 0.46131607294082644} | train loss {'Reaction outcome loss': 0.44547316048593416, 'Total loss': 0.44547316048593416}
2022-12-31 13:41:16,783 INFO:     Found new best model at epoch 10
2022-12-31 13:41:16,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:16,784 INFO:     Epoch: 11
2022-12-31 13:41:18,388 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44823233087857567, 'Total loss': 0.44823233087857567} | train loss {'Reaction outcome loss': 0.4343888039571525, 'Total loss': 0.4343888039571525}
2022-12-31 13:41:18,388 INFO:     Found new best model at epoch 11
2022-12-31 13:41:18,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:18,389 INFO:     Epoch: 12
2022-12-31 13:41:19,993 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44915195206801095, 'Total loss': 0.44915195206801095} | train loss {'Reaction outcome loss': 0.4275532136977154, 'Total loss': 0.4275532136977154}
2022-12-31 13:41:19,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:19,993 INFO:     Epoch: 13
2022-12-31 13:41:21,621 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4664264559745789, 'Total loss': 0.4664264559745789} | train loss {'Reaction outcome loss': 0.42624120370750007, 'Total loss': 0.42624120370750007}
2022-12-31 13:41:21,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:21,621 INFO:     Epoch: 14
2022-12-31 13:41:23,217 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4736858228842417, 'Total loss': 0.4736858228842417} | train loss {'Reaction outcome loss': 0.41612895189301813, 'Total loss': 0.41612895189301813}
2022-12-31 13:41:23,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:23,217 INFO:     Epoch: 15
2022-12-31 13:41:24,849 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45673679212729135, 'Total loss': 0.45673679212729135} | train loss {'Reaction outcome loss': 0.41692889476344536, 'Total loss': 0.41692889476344536}
2022-12-31 13:41:24,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:24,849 INFO:     Epoch: 16
2022-12-31 13:41:26,431 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43972771763801577, 'Total loss': 0.43972771763801577} | train loss {'Reaction outcome loss': 0.4055062314889727, 'Total loss': 0.4055062314889727}
2022-12-31 13:41:26,432 INFO:     Found new best model at epoch 16
2022-12-31 13:41:26,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:26,433 INFO:     Epoch: 17
2022-12-31 13:41:28,071 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4247497882694006, 'Total loss': 0.4247497882694006} | train loss {'Reaction outcome loss': 0.3977515714882064, 'Total loss': 0.3977515714882064}
2022-12-31 13:41:28,071 INFO:     Found new best model at epoch 17
2022-12-31 13:41:28,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:28,072 INFO:     Epoch: 18
2022-12-31 13:41:29,696 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4000835170348485, 'Total loss': 0.4000835170348485} | train loss {'Reaction outcome loss': 0.39305729291191066, 'Total loss': 0.39305729291191066}
2022-12-31 13:41:29,697 INFO:     Found new best model at epoch 18
2022-12-31 13:41:29,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:29,698 INFO:     Epoch: 19
2022-12-31 13:41:31,269 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4230290651321411, 'Total loss': 0.4230290651321411} | train loss {'Reaction outcome loss': 0.3870418574525057, 'Total loss': 0.3870418574525057}
2022-12-31 13:41:31,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:31,269 INFO:     Epoch: 20
2022-12-31 13:41:32,908 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4330092241366704, 'Total loss': 0.4330092241366704} | train loss {'Reaction outcome loss': 0.38923806601958555, 'Total loss': 0.38923806601958555}
2022-12-31 13:41:32,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:32,908 INFO:     Epoch: 21
2022-12-31 13:41:34,520 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4417101562023163, 'Total loss': 0.4417101562023163} | train loss {'Reaction outcome loss': 0.3827556240623885, 'Total loss': 0.3827556240623885}
2022-12-31 13:41:34,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:34,520 INFO:     Epoch: 22
2022-12-31 13:41:35,615 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42166760663191477, 'Total loss': 0.42166760663191477} | train loss {'Reaction outcome loss': 0.36937137383179075, 'Total loss': 0.36937137383179075}
2022-12-31 13:41:35,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:35,615 INFO:     Epoch: 23
2022-12-31 13:41:36,701 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4092947284380595, 'Total loss': 0.4092947284380595} | train loss {'Reaction outcome loss': 0.36712800423159214, 'Total loss': 0.36712800423159214}
2022-12-31 13:41:36,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:36,701 INFO:     Epoch: 24
2022-12-31 13:41:37,785 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4182441751162211, 'Total loss': 0.4182441751162211} | train loss {'Reaction outcome loss': 0.36275123269127235, 'Total loss': 0.36275123269127235}
2022-12-31 13:41:37,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:37,785 INFO:     Epoch: 25
2022-12-31 13:41:38,872 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44363521635532377, 'Total loss': 0.44363521635532377} | train loss {'Reaction outcome loss': 0.35082163520320486, 'Total loss': 0.35082163520320486}
2022-12-31 13:41:38,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:38,872 INFO:     Epoch: 26
2022-12-31 13:41:40,395 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4215760111808777, 'Total loss': 0.4215760111808777} | train loss {'Reaction outcome loss': 0.3517954300300483, 'Total loss': 0.3517954300300483}
2022-12-31 13:41:40,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:40,395 INFO:     Epoch: 27
2022-12-31 13:41:41,992 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3950441092252731, 'Total loss': 0.3950441092252731} | train loss {'Reaction outcome loss': 0.3414014052790012, 'Total loss': 0.3414014052790012}
2022-12-31 13:41:41,992 INFO:     Found new best model at epoch 27
2022-12-31 13:41:41,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:41,993 INFO:     Epoch: 28
2022-12-31 13:41:43,588 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42470713158448536, 'Total loss': 0.42470713158448536} | train loss {'Reaction outcome loss': 0.3371506978343003, 'Total loss': 0.3371506978343003}
2022-12-31 13:41:43,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:43,589 INFO:     Epoch: 29
2022-12-31 13:41:45,184 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47475389440854393, 'Total loss': 0.47475389440854393} | train loss {'Reaction outcome loss': 0.3318450850346228, 'Total loss': 0.3318450850346228}
2022-12-31 13:41:45,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:45,185 INFO:     Epoch: 30
2022-12-31 13:41:46,793 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4252801567316055, 'Total loss': 0.4252801567316055} | train loss {'Reaction outcome loss': 0.32778478253388055, 'Total loss': 0.32778478253388055}
2022-12-31 13:41:46,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:46,793 INFO:     Epoch: 31
2022-12-31 13:41:48,360 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44955504735310875, 'Total loss': 0.44955504735310875} | train loss {'Reaction outcome loss': 0.3226151323748113, 'Total loss': 0.3226151323748113}
2022-12-31 13:41:48,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:48,360 INFO:     Epoch: 32
2022-12-31 13:41:49,957 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4236528058846792, 'Total loss': 0.4236528058846792} | train loss {'Reaction outcome loss': 0.3238663744099819, 'Total loss': 0.3238663744099819}
2022-12-31 13:41:49,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:49,958 INFO:     Epoch: 33
2022-12-31 13:41:51,554 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4127014319101969, 'Total loss': 0.4127014319101969} | train loss {'Reaction outcome loss': 0.31196050517206647, 'Total loss': 0.31196050517206647}
2022-12-31 13:41:51,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:51,554 INFO:     Epoch: 34
2022-12-31 13:41:53,150 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4408096412817637, 'Total loss': 0.4408096412817637} | train loss {'Reaction outcome loss': 0.3136699016063209, 'Total loss': 0.3136699016063209}
2022-12-31 13:41:53,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:53,150 INFO:     Epoch: 35
2022-12-31 13:41:54,745 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39702554444471994, 'Total loss': 0.39702554444471994} | train loss {'Reaction outcome loss': 0.3039478634613274, 'Total loss': 0.3039478634613274}
2022-12-31 13:41:54,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:54,746 INFO:     Epoch: 36
2022-12-31 13:41:56,319 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3970784038305283, 'Total loss': 0.3970784038305283} | train loss {'Reaction outcome loss': 0.3026501062686426, 'Total loss': 0.3026501062686426}
2022-12-31 13:41:56,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:56,319 INFO:     Epoch: 37
2022-12-31 13:41:57,936 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.391613890727361, 'Total loss': 0.391613890727361} | train loss {'Reaction outcome loss': 0.29365038357838225, 'Total loss': 0.29365038357838225}
2022-12-31 13:41:57,937 INFO:     Found new best model at epoch 37
2022-12-31 13:41:57,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:57,938 INFO:     Epoch: 38
2022-12-31 13:41:59,591 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39165958513816196, 'Total loss': 0.39165958513816196} | train loss {'Reaction outcome loss': 0.29813376634660427, 'Total loss': 0.29813376634660427}
2022-12-31 13:41:59,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:41:59,591 INFO:     Epoch: 39
2022-12-31 13:42:01,246 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43839644889036816, 'Total loss': 0.43839644889036816} | train loss {'Reaction outcome loss': 0.2909740825747921, 'Total loss': 0.2909740825747921}
2022-12-31 13:42:01,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:01,247 INFO:     Epoch: 40
2022-12-31 13:42:02,903 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43030117750167846, 'Total loss': 0.43030117750167846} | train loss {'Reaction outcome loss': 0.28948896983298505, 'Total loss': 0.28948896983298505}
2022-12-31 13:42:02,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:02,904 INFO:     Epoch: 41
2022-12-31 13:42:04,560 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42447198629379274, 'Total loss': 0.42447198629379274} | train loss {'Reaction outcome loss': 0.28359150456903626, 'Total loss': 0.28359150456903626}
2022-12-31 13:42:04,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:04,560 INFO:     Epoch: 42
2022-12-31 13:42:06,183 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43444169958432516, 'Total loss': 0.43444169958432516} | train loss {'Reaction outcome loss': 0.27995926832413154, 'Total loss': 0.27995926832413154}
2022-12-31 13:42:06,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:06,183 INFO:     Epoch: 43
2022-12-31 13:42:07,770 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42468584775924684, 'Total loss': 0.42468584775924684} | train loss {'Reaction outcome loss': 0.2790427412701784, 'Total loss': 0.2790427412701784}
2022-12-31 13:42:07,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:07,770 INFO:     Epoch: 44
2022-12-31 13:42:09,370 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3991549084583918, 'Total loss': 0.3991549084583918} | train loss {'Reaction outcome loss': 0.27784965554401825, 'Total loss': 0.27784965554401825}
2022-12-31 13:42:09,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:09,370 INFO:     Epoch: 45
2022-12-31 13:42:10,969 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39823975761731467, 'Total loss': 0.39823975761731467} | train loss {'Reaction outcome loss': 0.27807252447589903, 'Total loss': 0.27807252447589903}
2022-12-31 13:42:10,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:10,969 INFO:     Epoch: 46
2022-12-31 13:42:12,566 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4131300330162048, 'Total loss': 0.4131300330162048} | train loss {'Reaction outcome loss': 0.26932283953158526, 'Total loss': 0.26932283953158526}
2022-12-31 13:42:12,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:12,566 INFO:     Epoch: 47
2022-12-31 13:42:14,164 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42014136612415315, 'Total loss': 0.42014136612415315} | train loss {'Reaction outcome loss': 0.262656198896087, 'Total loss': 0.262656198896087}
2022-12-31 13:42:14,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:14,166 INFO:     Epoch: 48
2022-12-31 13:42:15,731 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37374691863854725, 'Total loss': 0.37374691863854725} | train loss {'Reaction outcome loss': 0.26661637543707434, 'Total loss': 0.26661637543707434}
2022-12-31 13:42:15,732 INFO:     Found new best model at epoch 48
2022-12-31 13:42:15,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:15,732 INFO:     Epoch: 49
2022-12-31 13:42:17,352 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4269549270470937, 'Total loss': 0.4269549270470937} | train loss {'Reaction outcome loss': 0.2563337644385378, 'Total loss': 0.2563337644385378}
2022-12-31 13:42:17,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:17,352 INFO:     Epoch: 50
2022-12-31 13:42:18,979 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4145708978176117, 'Total loss': 0.4145708978176117} | train loss {'Reaction outcome loss': 0.26800747407450726, 'Total loss': 0.26800747407450726}
2022-12-31 13:42:18,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:18,979 INFO:     Epoch: 51
2022-12-31 13:42:20,581 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3889211495717367, 'Total loss': 0.3889211495717367} | train loss {'Reaction outcome loss': 0.2612194783686504, 'Total loss': 0.2612194783686504}
2022-12-31 13:42:20,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:20,582 INFO:     Epoch: 52
2022-12-31 13:42:22,179 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.415155303478241, 'Total loss': 0.415155303478241} | train loss {'Reaction outcome loss': 0.251148949859895, 'Total loss': 0.251148949859895}
2022-12-31 13:42:22,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:22,179 INFO:     Epoch: 53
2022-12-31 13:42:23,785 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3740967700878779, 'Total loss': 0.3740967700878779} | train loss {'Reaction outcome loss': 0.2550667081245758, 'Total loss': 0.2550667081245758}
2022-12-31 13:42:23,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:23,785 INFO:     Epoch: 54
2022-12-31 13:42:25,372 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3909587025642395, 'Total loss': 0.3909587025642395} | train loss {'Reaction outcome loss': 0.25591705010755217, 'Total loss': 0.25591705010755217}
2022-12-31 13:42:25,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:25,373 INFO:     Epoch: 55
2022-12-31 13:42:26,988 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.378633455435435, 'Total loss': 0.378633455435435} | train loss {'Reaction outcome loss': 0.25265600663154336, 'Total loss': 0.25265600663154336}
2022-12-31 13:42:26,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:26,988 INFO:     Epoch: 56
2022-12-31 13:42:28,586 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4187692254781723, 'Total loss': 0.4187692254781723} | train loss {'Reaction outcome loss': 0.244479447249731, 'Total loss': 0.244479447249731}
2022-12-31 13:42:28,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:28,586 INFO:     Epoch: 57
2022-12-31 13:42:30,184 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41772564550240837, 'Total loss': 0.41772564550240837} | train loss {'Reaction outcome loss': 0.24439664555536786, 'Total loss': 0.24439664555536786}
2022-12-31 13:42:30,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:30,184 INFO:     Epoch: 58
2022-12-31 13:42:31,782 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3907099907596906, 'Total loss': 0.3907099907596906} | train loss {'Reaction outcome loss': 0.24320238272584702, 'Total loss': 0.24320238272584702}
2022-12-31 13:42:31,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:31,783 INFO:     Epoch: 59
2022-12-31 13:42:33,373 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3633127182722092, 'Total loss': 0.3633127182722092} | train loss {'Reaction outcome loss': 0.23963066180284223, 'Total loss': 0.23963066180284223}
2022-12-31 13:42:33,374 INFO:     Found new best model at epoch 59
2022-12-31 13:42:33,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:33,375 INFO:     Epoch: 60
2022-12-31 13:42:34,998 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3616705705722173, 'Total loss': 0.3616705705722173} | train loss {'Reaction outcome loss': 0.24095882812555688, 'Total loss': 0.24095882812555688}
2022-12-31 13:42:34,998 INFO:     Found new best model at epoch 60
2022-12-31 13:42:34,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:34,999 INFO:     Epoch: 61
2022-12-31 13:42:36,622 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4379317174355189, 'Total loss': 0.4379317174355189} | train loss {'Reaction outcome loss': 0.2472599087296611, 'Total loss': 0.2472599087296611}
2022-12-31 13:42:36,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:36,622 INFO:     Epoch: 62
2022-12-31 13:42:38,240 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4266067147254944, 'Total loss': 0.4266067147254944} | train loss {'Reaction outcome loss': 0.24167946095231677, 'Total loss': 0.24167946095231677}
2022-12-31 13:42:38,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:38,241 INFO:     Epoch: 63
2022-12-31 13:42:39,837 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38767183423042295, 'Total loss': 0.38767183423042295} | train loss {'Reaction outcome loss': 0.23631419303969745, 'Total loss': 0.23631419303969745}
2022-12-31 13:42:39,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:39,837 INFO:     Epoch: 64
2022-12-31 13:42:41,431 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4267757793267568, 'Total loss': 0.4267757793267568} | train loss {'Reaction outcome loss': 0.2345955006329574, 'Total loss': 0.2345955006329574}
2022-12-31 13:42:41,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:41,431 INFO:     Epoch: 65
2022-12-31 13:42:43,007 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4420234461625417, 'Total loss': 0.4420234461625417} | train loss {'Reaction outcome loss': 0.23457588542959767, 'Total loss': 0.23457588542959767}
2022-12-31 13:42:43,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:43,007 INFO:     Epoch: 66
2022-12-31 13:42:44,660 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38627227681378523, 'Total loss': 0.38627227681378523} | train loss {'Reaction outcome loss': 0.23458443545348887, 'Total loss': 0.23458443545348887}
2022-12-31 13:42:44,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:44,661 INFO:     Epoch: 67
2022-12-31 13:42:46,263 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36660202592611313, 'Total loss': 0.36660202592611313} | train loss {'Reaction outcome loss': 0.2315142478413173, 'Total loss': 0.2315142478413173}
2022-12-31 13:42:46,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:46,264 INFO:     Epoch: 68
2022-12-31 13:42:47,916 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.403361572821935, 'Total loss': 0.403361572821935} | train loss {'Reaction outcome loss': 0.23961653667808014, 'Total loss': 0.23961653667808014}
2022-12-31 13:42:47,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:47,916 INFO:     Epoch: 69
2022-12-31 13:42:49,572 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41037317713101706, 'Total loss': 0.41037317713101706} | train loss {'Reaction outcome loss': 0.22653492402122186, 'Total loss': 0.22653492402122186}
2022-12-31 13:42:49,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:49,572 INFO:     Epoch: 70
2022-12-31 13:42:51,186 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37617051204045615, 'Total loss': 0.37617051204045615} | train loss {'Reaction outcome loss': 0.22612416048119538, 'Total loss': 0.22612416048119538}
2022-12-31 13:42:51,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:51,187 INFO:     Epoch: 71
2022-12-31 13:42:52,801 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3875255266825358, 'Total loss': 0.3875255266825358} | train loss {'Reaction outcome loss': 0.22618419743639273, 'Total loss': 0.22618419743639273}
2022-12-31 13:42:52,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:52,801 INFO:     Epoch: 72
2022-12-31 13:42:54,394 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.402335861325264, 'Total loss': 0.402335861325264} | train loss {'Reaction outcome loss': 0.22968128142728858, 'Total loss': 0.22968128142728858}
2022-12-31 13:42:54,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:54,394 INFO:     Epoch: 73
2022-12-31 13:42:55,990 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4001292238632838, 'Total loss': 0.4001292238632838} | train loss {'Reaction outcome loss': 0.2259304298726964, 'Total loss': 0.2259304298726964}
2022-12-31 13:42:55,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:55,990 INFO:     Epoch: 74
2022-12-31 13:42:57,585 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40886369297901787, 'Total loss': 0.40886369297901787} | train loss {'Reaction outcome loss': 0.21975421095878755, 'Total loss': 0.21975421095878755}
2022-12-31 13:42:57,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:57,585 INFO:     Epoch: 75
2022-12-31 13:42:59,181 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46385209063688915, 'Total loss': 0.46385209063688915} | train loss {'Reaction outcome loss': 0.22952591497315109, 'Total loss': 0.22952591497315109}
2022-12-31 13:42:59,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:42:59,181 INFO:     Epoch: 76
2022-12-31 13:43:00,777 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4028780261675517, 'Total loss': 0.4028780261675517} | train loss {'Reaction outcome loss': 0.22834208601555467, 'Total loss': 0.22834208601555467}
2022-12-31 13:43:00,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:00,777 INFO:     Epoch: 77
2022-12-31 13:43:02,367 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39888688425223034, 'Total loss': 0.39888688425223034} | train loss {'Reaction outcome loss': 0.2216772509426096, 'Total loss': 0.2216772509426096}
2022-12-31 13:43:02,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:02,367 INFO:     Epoch: 78
2022-12-31 13:43:03,965 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4072169323762258, 'Total loss': 0.4072169323762258} | train loss {'Reaction outcome loss': 0.2203004112140867, 'Total loss': 0.2203004112140867}
2022-12-31 13:43:03,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:03,966 INFO:     Epoch: 79
2022-12-31 13:43:05,617 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39115491807460784, 'Total loss': 0.39115491807460784} | train loss {'Reaction outcome loss': 0.21836836239064697, 'Total loss': 0.21836836239064697}
2022-12-31 13:43:05,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:05,618 INFO:     Epoch: 80
2022-12-31 13:43:07,244 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3879595657189687, 'Total loss': 0.3879595657189687} | train loss {'Reaction outcome loss': 0.2160378830187893, 'Total loss': 0.2160378830187893}
2022-12-31 13:43:07,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:07,244 INFO:     Epoch: 81
2022-12-31 13:43:08,828 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3930438021818797, 'Total loss': 0.3930438021818797} | train loss {'Reaction outcome loss': 0.21535057721346834, 'Total loss': 0.21535057721346834}
2022-12-31 13:43:08,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:08,828 INFO:     Epoch: 82
2022-12-31 13:43:10,410 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3857496758302053, 'Total loss': 0.3857496758302053} | train loss {'Reaction outcome loss': 0.21174755944686868, 'Total loss': 0.21174755944686868}
2022-12-31 13:43:10,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:10,411 INFO:     Epoch: 83
2022-12-31 13:43:12,021 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41085799435774484, 'Total loss': 0.41085799435774484} | train loss {'Reaction outcome loss': 0.21632497018053584, 'Total loss': 0.21632497018053584}
2022-12-31 13:43:12,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:12,021 INFO:     Epoch: 84
2022-12-31 13:43:13,620 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3904458835721016, 'Total loss': 0.3904458835721016} | train loss {'Reaction outcome loss': 0.22156799406520206, 'Total loss': 0.22156799406520206}
2022-12-31 13:43:13,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:13,620 INFO:     Epoch: 85
2022-12-31 13:43:15,222 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39121636797984444, 'Total loss': 0.39121636797984444} | train loss {'Reaction outcome loss': 0.2117335311660584, 'Total loss': 0.2117335311660584}
2022-12-31 13:43:15,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:15,222 INFO:     Epoch: 86
2022-12-31 13:43:16,872 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3854043811559677, 'Total loss': 0.3854043811559677} | train loss {'Reaction outcome loss': 0.21424801835287227, 'Total loss': 0.21424801835287227}
2022-12-31 13:43:16,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:16,872 INFO:     Epoch: 87
2022-12-31 13:43:18,496 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40598469351728755, 'Total loss': 0.40598469351728755} | train loss {'Reaction outcome loss': 0.20708440924335245, 'Total loss': 0.20708440924335245}
2022-12-31 13:43:18,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:18,496 INFO:     Epoch: 88
2022-12-31 13:43:20,105 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4097360173861186, 'Total loss': 0.4097360173861186} | train loss {'Reaction outcome loss': 0.213491933277543, 'Total loss': 0.213491933277543}
2022-12-31 13:43:20,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:20,105 INFO:     Epoch: 89
2022-12-31 13:43:21,720 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4160380830367406, 'Total loss': 0.4160380830367406} | train loss {'Reaction outcome loss': 0.2016323774893272, 'Total loss': 0.2016323774893272}
2022-12-31 13:43:21,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:21,722 INFO:     Epoch: 90
2022-12-31 13:43:23,347 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41630020638306936, 'Total loss': 0.41630020638306936} | train loss {'Reaction outcome loss': 0.206734967149495, 'Total loss': 0.206734967149495}
2022-12-31 13:43:23,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:23,347 INFO:     Epoch: 91
2022-12-31 13:43:24,953 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40664242108662924, 'Total loss': 0.40664242108662924} | train loss {'Reaction outcome loss': 0.21738554779304206, 'Total loss': 0.21738554779304206}
2022-12-31 13:43:24,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:24,953 INFO:     Epoch: 92
2022-12-31 13:43:26,565 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3969211995601654, 'Total loss': 0.3969211995601654} | train loss {'Reaction outcome loss': 0.20612301313093978, 'Total loss': 0.20612301313093978}
2022-12-31 13:43:26,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:26,565 INFO:     Epoch: 93
2022-12-31 13:43:28,149 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42552070717016854, 'Total loss': 0.42552070717016854} | train loss {'Reaction outcome loss': 0.20625347972432845, 'Total loss': 0.20625347972432845}
2022-12-31 13:43:28,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:28,150 INFO:     Epoch: 94
2022-12-31 13:43:29,790 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4168071319659551, 'Total loss': 0.4168071319659551} | train loss {'Reaction outcome loss': 0.2031382956766408, 'Total loss': 0.2031382956766408}
2022-12-31 13:43:29,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:29,790 INFO:     Epoch: 95
2022-12-31 13:43:31,395 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40718433757623035, 'Total loss': 0.40718433757623035} | train loss {'Reaction outcome loss': 0.2103105187076178, 'Total loss': 0.2103105187076178}
2022-12-31 13:43:31,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:31,395 INFO:     Epoch: 96
2022-12-31 13:43:33,004 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4102435976266861, 'Total loss': 0.4102435976266861} | train loss {'Reaction outcome loss': 0.2065640599840749, 'Total loss': 0.2065640599840749}
2022-12-31 13:43:33,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:33,004 INFO:     Epoch: 97
2022-12-31 13:43:34,609 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.419356240828832, 'Total loss': 0.419356240828832} | train loss {'Reaction outcome loss': 0.21007280023156727, 'Total loss': 0.21007280023156727}
2022-12-31 13:43:34,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:34,609 INFO:     Epoch: 98
2022-12-31 13:43:36,208 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39505530198415123, 'Total loss': 0.39505530198415123} | train loss {'Reaction outcome loss': 0.20127127397751068, 'Total loss': 0.20127127397751068}
2022-12-31 13:43:36,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:36,208 INFO:     Epoch: 99
2022-12-31 13:43:37,800 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4092030564943949, 'Total loss': 0.4092030564943949} | train loss {'Reaction outcome loss': 0.20493042025796687, 'Total loss': 0.20493042025796687}
2022-12-31 13:43:37,800 INFO:     Best model found after epoch 61 of 100.
2022-12-31 13:43:37,800 INFO:   Done with stage: TRAINING
2022-12-31 13:43:37,800 INFO:   Starting stage: EVALUATION
2022-12-31 13:43:37,933 INFO:   Done with stage: EVALUATION
2022-12-31 13:43:37,934 INFO:   Leaving out SEQ value Fold_4
2022-12-31 13:43:37,946 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:43:37,946 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:43:38,590 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:43:38,590 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:43:38,658 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:43:38,658 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:43:38,658 INFO:     No hyperparam tuning for this model
2022-12-31 13:43:38,658 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:43:38,658 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:43:38,659 INFO:     None feature selector for col prot
2022-12-31 13:43:38,659 INFO:     None feature selector for col prot
2022-12-31 13:43:38,659 INFO:     None feature selector for col prot
2022-12-31 13:43:38,659 INFO:     None feature selector for col chem
2022-12-31 13:43:38,659 INFO:     None feature selector for col chem
2022-12-31 13:43:38,659 INFO:     None feature selector for col chem
2022-12-31 13:43:38,660 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:43:38,660 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:43:38,661 INFO:     Number of params in model 223921
2022-12-31 13:43:38,665 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:43:38,665 INFO:   Starting stage: TRAINING
2022-12-31 13:43:38,710 INFO:     Val loss before train {'Reaction outcome loss': 0.8950757841269176, 'Total loss': 0.8950757841269176}
2022-12-31 13:43:38,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:38,710 INFO:     Epoch: 0
2022-12-31 13:43:40,326 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6790952841440837, 'Total loss': 0.6790952841440837} | train loss {'Reaction outcome loss': 0.8196704170626142, 'Total loss': 0.8196704170626142}
2022-12-31 13:43:40,327 INFO:     Found new best model at epoch 0
2022-12-31 13:43:40,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:40,328 INFO:     Epoch: 1
2022-12-31 13:43:41,946 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49553090929985044, 'Total loss': 0.49553090929985044} | train loss {'Reaction outcome loss': 0.5935547274091969, 'Total loss': 0.5935547274091969}
2022-12-31 13:43:41,946 INFO:     Found new best model at epoch 1
2022-12-31 13:43:41,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:41,947 INFO:     Epoch: 2
2022-12-31 13:43:43,572 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4645048956076304, 'Total loss': 0.4645048956076304} | train loss {'Reaction outcome loss': 0.5161430064092755, 'Total loss': 0.5161430064092755}
2022-12-31 13:43:43,572 INFO:     Found new best model at epoch 2
2022-12-31 13:43:43,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:43,573 INFO:     Epoch: 3
2022-12-31 13:43:45,166 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4769993563493093, 'Total loss': 0.4769993563493093} | train loss {'Reaction outcome loss': 0.48977577120598836, 'Total loss': 0.48977577120598836}
2022-12-31 13:43:45,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:45,166 INFO:     Epoch: 4
2022-12-31 13:43:46,774 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47376153667767845, 'Total loss': 0.47376153667767845} | train loss {'Reaction outcome loss': 0.4745206045710433, 'Total loss': 0.4745206045710433}
2022-12-31 13:43:46,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:46,775 INFO:     Epoch: 5
2022-12-31 13:43:48,385 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42978551785151164, 'Total loss': 0.42978551785151164} | train loss {'Reaction outcome loss': 0.4632999933547462, 'Total loss': 0.4632999933547462}
2022-12-31 13:43:48,385 INFO:     Found new best model at epoch 5
2022-12-31 13:43:48,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:48,386 INFO:     Epoch: 6
2022-12-31 13:43:50,001 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43553290764490765, 'Total loss': 0.43553290764490765} | train loss {'Reaction outcome loss': 0.46045620463437575, 'Total loss': 0.46045620463437575}
2022-12-31 13:43:50,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:50,001 INFO:     Epoch: 7
2022-12-31 13:43:51,619 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4232326209545135, 'Total loss': 0.4232326209545135} | train loss {'Reaction outcome loss': 0.4506196775812276, 'Total loss': 0.4506196775812276}
2022-12-31 13:43:51,620 INFO:     Found new best model at epoch 7
2022-12-31 13:43:51,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:51,621 INFO:     Epoch: 8
2022-12-31 13:43:53,237 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4217047492663066, 'Total loss': 0.4217047492663066} | train loss {'Reaction outcome loss': 0.43963316768571054, 'Total loss': 0.43963316768571054}
2022-12-31 13:43:53,238 INFO:     Found new best model at epoch 8
2022-12-31 13:43:53,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:53,239 INFO:     Epoch: 9
2022-12-31 13:43:54,850 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4285116493701935, 'Total loss': 0.4285116493701935} | train loss {'Reaction outcome loss': 0.43158470250847936, 'Total loss': 0.43158470250847936}
2022-12-31 13:43:54,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:54,850 INFO:     Epoch: 10
2022-12-31 13:43:56,456 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.440309602022171, 'Total loss': 0.440309602022171} | train loss {'Reaction outcome loss': 0.44786789937727695, 'Total loss': 0.44786789937727695}
2022-12-31 13:43:56,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:56,457 INFO:     Epoch: 11
2022-12-31 13:43:58,073 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4707864423592885, 'Total loss': 0.4707864423592885} | train loss {'Reaction outcome loss': 0.49798113663775334, 'Total loss': 0.49798113663775334}
2022-12-31 13:43:58,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:58,073 INFO:     Epoch: 12
2022-12-31 13:43:59,689 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4485511581103007, 'Total loss': 0.4485511581103007} | train loss {'Reaction outcome loss': 0.46418165917629783, 'Total loss': 0.46418165917629783}
2022-12-31 13:43:59,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:43:59,689 INFO:     Epoch: 13
2022-12-31 13:44:01,305 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4612530767917633, 'Total loss': 0.4612530767917633} | train loss {'Reaction outcome loss': 0.4396439643046967, 'Total loss': 0.4396439643046967}
2022-12-31 13:44:01,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:01,305 INFO:     Epoch: 14
2022-12-31 13:44:02,922 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4517224460840225, 'Total loss': 0.4517224460840225} | train loss {'Reaction outcome loss': 0.4194247682875805, 'Total loss': 0.4194247682875805}
2022-12-31 13:44:02,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:02,923 INFO:     Epoch: 15
2022-12-31 13:44:04,499 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.415697913368543, 'Total loss': 0.415697913368543} | train loss {'Reaction outcome loss': 0.4149344103221876, 'Total loss': 0.4149344103221876}
2022-12-31 13:44:04,499 INFO:     Found new best model at epoch 15
2022-12-31 13:44:04,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:04,500 INFO:     Epoch: 16
2022-12-31 13:44:06,117 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4426842987537384, 'Total loss': 0.4426842987537384} | train loss {'Reaction outcome loss': 0.4199974478536245, 'Total loss': 0.4199974478536245}
2022-12-31 13:44:06,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:06,118 INFO:     Epoch: 17
2022-12-31 13:44:07,736 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.451680917541186, 'Total loss': 0.451680917541186} | train loss {'Reaction outcome loss': 0.3998096638470483, 'Total loss': 0.3998096638470483}
2022-12-31 13:44:07,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:07,736 INFO:     Epoch: 18
2022-12-31 13:44:09,349 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42483919858932495, 'Total loss': 0.42483919858932495} | train loss {'Reaction outcome loss': 0.3975405436875113, 'Total loss': 0.3975405436875113}
2022-12-31 13:44:09,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:09,349 INFO:     Epoch: 19
2022-12-31 13:44:10,962 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42879283328851064, 'Total loss': 0.42879283328851064} | train loss {'Reaction outcome loss': 0.39347052090570156, 'Total loss': 0.39347052090570156}
2022-12-31 13:44:10,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:10,963 INFO:     Epoch: 20
2022-12-31 13:44:12,555 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42193876107533773, 'Total loss': 0.42193876107533773} | train loss {'Reaction outcome loss': 0.38871621652411914, 'Total loss': 0.38871621652411914}
2022-12-31 13:44:12,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:12,555 INFO:     Epoch: 21
2022-12-31 13:44:14,155 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4148441235224406, 'Total loss': 0.4148441235224406} | train loss {'Reaction outcome loss': 0.3835625382329243, 'Total loss': 0.3835625382329243}
2022-12-31 13:44:14,156 INFO:     Found new best model at epoch 21
2022-12-31 13:44:14,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:14,157 INFO:     Epoch: 22
2022-12-31 13:44:15,781 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41640171806017556, 'Total loss': 0.41640171806017556} | train loss {'Reaction outcome loss': 0.3789858988729184, 'Total loss': 0.3789858988729184}
2022-12-31 13:44:15,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:15,782 INFO:     Epoch: 23
2022-12-31 13:44:17,398 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4251847227414449, 'Total loss': 0.4251847227414449} | train loss {'Reaction outcome loss': 0.3733253424152676, 'Total loss': 0.3733253424152676}
2022-12-31 13:44:17,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:17,398 INFO:     Epoch: 24
2022-12-31 13:44:19,017 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4124265929063161, 'Total loss': 0.4124265929063161} | train loss {'Reaction outcome loss': 0.3708660081838784, 'Total loss': 0.3708660081838784}
2022-12-31 13:44:19,017 INFO:     Found new best model at epoch 24
2022-12-31 13:44:19,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:19,018 INFO:     Epoch: 25
2022-12-31 13:44:20,634 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4214740455150604, 'Total loss': 0.4214740455150604} | train loss {'Reaction outcome loss': 0.3658929079462288, 'Total loss': 0.3658929079462288}
2022-12-31 13:44:20,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:20,634 INFO:     Epoch: 26
2022-12-31 13:44:22,237 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4068445305029551, 'Total loss': 0.4068445305029551} | train loss {'Reaction outcome loss': 0.35971807307618886, 'Total loss': 0.35971807307618886}
2022-12-31 13:44:22,237 INFO:     Found new best model at epoch 26
2022-12-31 13:44:22,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:22,238 INFO:     Epoch: 27
2022-12-31 13:44:23,848 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39118679563204445, 'Total loss': 0.39118679563204445} | train loss {'Reaction outcome loss': 0.3612471115168022, 'Total loss': 0.3612471115168022}
2022-12-31 13:44:23,849 INFO:     Found new best model at epoch 27
2022-12-31 13:44:23,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:23,850 INFO:     Epoch: 28
2022-12-31 13:44:25,463 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41262751817703247, 'Total loss': 0.41262751817703247} | train loss {'Reaction outcome loss': 0.35102600653055194, 'Total loss': 0.35102600653055194}
2022-12-31 13:44:25,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:25,463 INFO:     Epoch: 29
2022-12-31 13:44:27,079 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39292105635007224, 'Total loss': 0.39292105635007224} | train loss {'Reaction outcome loss': 0.3551853070224541, 'Total loss': 0.3551853070224541}
2022-12-31 13:44:27,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:27,081 INFO:     Epoch: 30
2022-12-31 13:44:28,694 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42175502876440685, 'Total loss': 0.42175502876440685} | train loss {'Reaction outcome loss': 0.35196293876472645, 'Total loss': 0.35196293876472645}
2022-12-31 13:44:28,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:28,694 INFO:     Epoch: 31
2022-12-31 13:44:30,291 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4267314443985621, 'Total loss': 0.4267314443985621} | train loss {'Reaction outcome loss': 0.34717559606592724, 'Total loss': 0.34717559606592724}
2022-12-31 13:44:30,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:30,292 INFO:     Epoch: 32
2022-12-31 13:44:31,902 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4349203904469808, 'Total loss': 0.4349203904469808} | train loss {'Reaction outcome loss': 0.34027822146975045, 'Total loss': 0.34027822146975045}
2022-12-31 13:44:31,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:31,902 INFO:     Epoch: 33
2022-12-31 13:44:33,541 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3965313603480657, 'Total loss': 0.3965313603480657} | train loss {'Reaction outcome loss': 0.36688481114696764, 'Total loss': 0.36688481114696764}
2022-12-31 13:44:33,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:33,542 INFO:     Epoch: 34
2022-12-31 13:44:35,158 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38916443983713783, 'Total loss': 0.38916443983713783} | train loss {'Reaction outcome loss': 0.33574619297397096, 'Total loss': 0.33574619297397096}
2022-12-31 13:44:35,158 INFO:     Found new best model at epoch 34
2022-12-31 13:44:35,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:35,159 INFO:     Epoch: 35
2022-12-31 13:44:36,774 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41011421581109364, 'Total loss': 0.41011421581109364} | train loss {'Reaction outcome loss': 0.33293223270363564, 'Total loss': 0.33293223270363564}
2022-12-31 13:44:36,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:36,774 INFO:     Epoch: 36
2022-12-31 13:44:38,403 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4120808720588684, 'Total loss': 0.4120808720588684} | train loss {'Reaction outcome loss': 0.3283419319809384, 'Total loss': 0.3283419319809384}
2022-12-31 13:44:38,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:38,403 INFO:     Epoch: 37
2022-12-31 13:44:39,990 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.414315339922905, 'Total loss': 0.414315339922905} | train loss {'Reaction outcome loss': 0.32778841292188654, 'Total loss': 0.32778841292188654}
2022-12-31 13:44:39,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:39,991 INFO:     Epoch: 38
2022-12-31 13:44:41,587 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4073538273572922, 'Total loss': 0.4073538273572922} | train loss {'Reaction outcome loss': 0.35558521588994324, 'Total loss': 0.35558521588994324}
2022-12-31 13:44:41,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:41,587 INFO:     Epoch: 39
2022-12-31 13:44:43,198 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4051323850949605, 'Total loss': 0.4051323850949605} | train loss {'Reaction outcome loss': 0.3174695762657169, 'Total loss': 0.3174695762657169}
2022-12-31 13:44:43,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:43,198 INFO:     Epoch: 40
2022-12-31 13:44:44,809 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35063528815905254, 'Total loss': 0.35063528815905254} | train loss {'Reaction outcome loss': 0.32680447674557805, 'Total loss': 0.32680447674557805}
2022-12-31 13:44:44,809 INFO:     Found new best model at epoch 40
2022-12-31 13:44:44,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:44,810 INFO:     Epoch: 41
2022-12-31 13:44:46,420 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38004018167654674, 'Total loss': 0.38004018167654674} | train loss {'Reaction outcome loss': 0.31051684921892136, 'Total loss': 0.31051684921892136}
2022-12-31 13:44:46,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:46,421 INFO:     Epoch: 42
2022-12-31 13:44:48,083 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4026559660832087, 'Total loss': 0.4026559660832087} | train loss {'Reaction outcome loss': 0.30697140910880355, 'Total loss': 0.30697140910880355}
2022-12-31 13:44:48,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:48,083 INFO:     Epoch: 43
2022-12-31 13:44:49,665 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4073701699574788, 'Total loss': 0.4073701699574788} | train loss {'Reaction outcome loss': 0.3136934099610949, 'Total loss': 0.3136934099610949}
2022-12-31 13:44:49,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:49,665 INFO:     Epoch: 44
2022-12-31 13:44:51,275 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.34858418703079225, 'Total loss': 0.34858418703079225} | train loss {'Reaction outcome loss': 0.35530952489563683, 'Total loss': 0.35530952489563683}
2022-12-31 13:44:51,275 INFO:     Found new best model at epoch 44
2022-12-31 13:44:51,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:51,276 INFO:     Epoch: 45
2022-12-31 13:44:52,885 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38864468038082123, 'Total loss': 0.38864468038082123} | train loss {'Reaction outcome loss': 0.3064939382536028, 'Total loss': 0.3064939382536028}
2022-12-31 13:44:52,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:52,885 INFO:     Epoch: 46
2022-12-31 13:44:54,496 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38320899109045664, 'Total loss': 0.38320899109045664} | train loss {'Reaction outcome loss': 0.30025010350737313, 'Total loss': 0.30025010350737313}
2022-12-31 13:44:54,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:54,496 INFO:     Epoch: 47
2022-12-31 13:44:56,105 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.384336057305336, 'Total loss': 0.384336057305336} | train loss {'Reaction outcome loss': 0.28963138289100904, 'Total loss': 0.28963138289100904}
2022-12-31 13:44:56,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:56,105 INFO:     Epoch: 48
2022-12-31 13:44:57,696 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39314301013946534, 'Total loss': 0.39314301013946534} | train loss {'Reaction outcome loss': 0.2932030083746582, 'Total loss': 0.2932030083746582}
2022-12-31 13:44:57,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:57,698 INFO:     Epoch: 49
2022-12-31 13:44:59,310 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35957265794277193, 'Total loss': 0.35957265794277193} | train loss {'Reaction outcome loss': 0.3041361730948151, 'Total loss': 0.3041361730948151}
2022-12-31 13:44:59,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:44:59,310 INFO:     Epoch: 50
2022-12-31 13:45:00,939 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3856595277786255, 'Total loss': 0.3856595277786255} | train loss {'Reaction outcome loss': 0.2854471347476963, 'Total loss': 0.2854471347476963}
2022-12-31 13:45:00,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:00,939 INFO:     Epoch: 51
2022-12-31 13:45:02,594 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40207026998202006, 'Total loss': 0.40207026998202006} | train loss {'Reaction outcome loss': 0.28255571877504565, 'Total loss': 0.28255571877504565}
2022-12-31 13:45:02,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:02,594 INFO:     Epoch: 52
2022-12-31 13:45:04,213 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3839797884225845, 'Total loss': 0.3839797884225845} | train loss {'Reaction outcome loss': 0.28364383754576894, 'Total loss': 0.28364383754576894}
2022-12-31 13:45:04,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:04,214 INFO:     Epoch: 53
2022-12-31 13:45:05,839 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37752674023310345, 'Total loss': 0.37752674023310345} | train loss {'Reaction outcome loss': 0.27810277870647016, 'Total loss': 0.27810277870647016}
2022-12-31 13:45:05,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:05,839 INFO:     Epoch: 54
2022-12-31 13:45:07,426 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3765224208434423, 'Total loss': 0.3765224208434423} | train loss {'Reaction outcome loss': 0.2682189694445486, 'Total loss': 0.2682189694445486}
2022-12-31 13:45:07,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:07,426 INFO:     Epoch: 55
2022-12-31 13:45:09,059 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37235742608706157, 'Total loss': 0.37235742608706157} | train loss {'Reaction outcome loss': 0.27227326223721215, 'Total loss': 0.27227326223721215}
2022-12-31 13:45:09,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:09,060 INFO:     Epoch: 56
2022-12-31 13:45:10,671 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37413551807403567, 'Total loss': 0.37413551807403567} | train loss {'Reaction outcome loss': 0.26692943793107365, 'Total loss': 0.26692943793107365}
2022-12-31 13:45:10,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:10,671 INFO:     Epoch: 57
2022-12-31 13:45:12,282 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39804311096668243, 'Total loss': 0.39804311096668243} | train loss {'Reaction outcome loss': 0.26582095285445667, 'Total loss': 0.26582095285445667}
2022-12-31 13:45:12,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:12,282 INFO:     Epoch: 58
2022-12-31 13:45:13,906 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40647524197896323, 'Total loss': 0.40647524197896323} | train loss {'Reaction outcome loss': 0.26394259015627985, 'Total loss': 0.26394259015627985}
2022-12-31 13:45:13,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:13,906 INFO:     Epoch: 59
2022-12-31 13:45:15,501 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3774783005317052, 'Total loss': 0.3774783005317052} | train loss {'Reaction outcome loss': 0.2576935721795119, 'Total loss': 0.2576935721795119}
2022-12-31 13:45:15,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:15,501 INFO:     Epoch: 60
2022-12-31 13:45:17,097 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40340163310368854, 'Total loss': 0.40340163310368854} | train loss {'Reaction outcome loss': 0.2807152848150851, 'Total loss': 0.2807152848150851}
2022-12-31 13:45:17,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:17,098 INFO:     Epoch: 61
2022-12-31 13:45:18,708 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4317566782236099, 'Total loss': 0.4317566782236099} | train loss {'Reaction outcome loss': 0.379316906763816, 'Total loss': 0.379316906763816}
2022-12-31 13:45:18,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:18,708 INFO:     Epoch: 62
2022-12-31 13:45:20,319 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3722882638374964, 'Total loss': 0.3722882638374964} | train loss {'Reaction outcome loss': 0.2818863892900771, 'Total loss': 0.2818863892900771}
2022-12-31 13:45:20,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:20,319 INFO:     Epoch: 63
2022-12-31 13:45:21,928 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35997348303596177, 'Total loss': 0.35997348303596177} | train loss {'Reaction outcome loss': 0.2668682221269262, 'Total loss': 0.2668682221269262}
2022-12-31 13:45:21,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:21,929 INFO:     Epoch: 64
2022-12-31 13:45:23,548 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3404985904693604, 'Total loss': 0.3404985904693604} | train loss {'Reaction outcome loss': 0.2604001231318768, 'Total loss': 0.2604001231318768}
2022-12-31 13:45:23,548 INFO:     Found new best model at epoch 64
2022-12-31 13:45:23,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:23,549 INFO:     Epoch: 65
2022-12-31 13:45:25,149 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4037172844012578, 'Total loss': 0.4037172844012578} | train loss {'Reaction outcome loss': 0.2568329288489253, 'Total loss': 0.2568329288489253}
2022-12-31 13:45:25,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:25,149 INFO:     Epoch: 66
2022-12-31 13:45:26,745 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3539138734340668, 'Total loss': 0.3539138734340668} | train loss {'Reaction outcome loss': 0.25147686194395646, 'Total loss': 0.25147686194395646}
2022-12-31 13:45:26,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:26,745 INFO:     Epoch: 67
2022-12-31 13:45:28,352 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3800494780143102, 'Total loss': 0.3800494780143102} | train loss {'Reaction outcome loss': 0.25476521470894414, 'Total loss': 0.25476521470894414}
2022-12-31 13:45:28,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:28,352 INFO:     Epoch: 68
2022-12-31 13:45:29,963 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3496200074752172, 'Total loss': 0.3496200074752172} | train loss {'Reaction outcome loss': 0.2564933464821914, 'Total loss': 0.2564933464821914}
2022-12-31 13:45:29,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:29,963 INFO:     Epoch: 69
2022-12-31 13:45:31,579 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36731790999571484, 'Total loss': 0.36731790999571484} | train loss {'Reaction outcome loss': 0.2434554218813993, 'Total loss': 0.2434554218813993}
2022-12-31 13:45:31,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:31,579 INFO:     Epoch: 70
2022-12-31 13:45:33,187 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3772358079751333, 'Total loss': 0.3772358079751333} | train loss {'Reaction outcome loss': 0.24558423254297784, 'Total loss': 0.24558423254297784}
2022-12-31 13:45:33,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:33,188 INFO:     Epoch: 71
2022-12-31 13:45:34,768 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3954425493876139, 'Total loss': 0.3954425493876139} | train loss {'Reaction outcome loss': 0.2498409387021177, 'Total loss': 0.2498409387021177}
2022-12-31 13:45:34,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:34,770 INFO:     Epoch: 72
2022-12-31 13:45:36,380 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.34133656124273937, 'Total loss': 0.34133656124273937} | train loss {'Reaction outcome loss': 0.2543169877144333, 'Total loss': 0.2543169877144333}
2022-12-31 13:45:36,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:36,380 INFO:     Epoch: 73
2022-12-31 13:45:37,990 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34675964415073396, 'Total loss': 0.34675964415073396} | train loss {'Reaction outcome loss': 0.24046244798228145, 'Total loss': 0.24046244798228145}
2022-12-31 13:45:37,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:37,991 INFO:     Epoch: 74
2022-12-31 13:45:39,603 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3516576891144117, 'Total loss': 0.3516576891144117} | train loss {'Reaction outcome loss': 0.2373812443313817, 'Total loss': 0.2373812443313817}
2022-12-31 13:45:39,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:39,604 INFO:     Epoch: 75
2022-12-31 13:45:41,214 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35728221038977304, 'Total loss': 0.35728221038977304} | train loss {'Reaction outcome loss': 0.2351576364867008, 'Total loss': 0.2351576364867008}
2022-12-31 13:45:41,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:41,215 INFO:     Epoch: 76
2022-12-31 13:45:42,804 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3889755298693975, 'Total loss': 0.3889755298693975} | train loss {'Reaction outcome loss': 0.22947509430156535, 'Total loss': 0.22947509430156535}
2022-12-31 13:45:42,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:42,805 INFO:     Epoch: 77
2022-12-31 13:45:44,402 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35694746176401776, 'Total loss': 0.35694746176401776} | train loss {'Reaction outcome loss': 0.2410828707439393, 'Total loss': 0.2410828707439393}
2022-12-31 13:45:44,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:44,402 INFO:     Epoch: 78
2022-12-31 13:45:46,012 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4056500643491745, 'Total loss': 0.4056500643491745} | train loss {'Reaction outcome loss': 0.22966113726041562, 'Total loss': 0.22966113726041562}
2022-12-31 13:45:46,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:46,012 INFO:     Epoch: 79
2022-12-31 13:45:47,632 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43356325129667916, 'Total loss': 0.43356325129667916} | train loss {'Reaction outcome loss': 0.24596968729156946, 'Total loss': 0.24596968729156946}
2022-12-31 13:45:47,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:47,632 INFO:     Epoch: 80
2022-12-31 13:45:49,244 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3471502681573232, 'Total loss': 0.3471502681573232} | train loss {'Reaction outcome loss': 0.33596225278333935, 'Total loss': 0.33596225278333935}
2022-12-31 13:45:49,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:49,244 INFO:     Epoch: 81
2022-12-31 13:45:50,851 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3410635270178318, 'Total loss': 0.3410635270178318} | train loss {'Reaction outcome loss': 0.24732867064364877, 'Total loss': 0.24732867064364877}
2022-12-31 13:45:50,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:50,852 INFO:     Epoch: 82
2022-12-31 13:45:52,431 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37698474725087483, 'Total loss': 0.37698474725087483} | train loss {'Reaction outcome loss': 0.23053473707451316, 'Total loss': 0.23053473707451316}
2022-12-31 13:45:52,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:52,431 INFO:     Epoch: 83
2022-12-31 13:45:54,039 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3579495499531428, 'Total loss': 0.3579495499531428} | train loss {'Reaction outcome loss': 0.22374426858816837, 'Total loss': 0.22374426858816837}
2022-12-31 13:45:54,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:54,040 INFO:     Epoch: 84
2022-12-31 13:45:55,649 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35624703963597615, 'Total loss': 0.35624703963597615} | train loss {'Reaction outcome loss': 0.2233904570179141, 'Total loss': 0.2233904570179141}
2022-12-31 13:45:55,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:55,649 INFO:     Epoch: 85
2022-12-31 13:45:57,259 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4003141095240911, 'Total loss': 0.4003141095240911} | train loss {'Reaction outcome loss': 0.23579287328048731, 'Total loss': 0.23579287328048731}
2022-12-31 13:45:57,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:57,260 INFO:     Epoch: 86
2022-12-31 13:45:58,872 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3839672068754832, 'Total loss': 0.3839672068754832} | train loss {'Reaction outcome loss': 0.2217272273988203, 'Total loss': 0.2217272273988203}
2022-12-31 13:45:58,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:45:58,872 INFO:     Epoch: 87
2022-12-31 13:46:00,473 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3652614156405131, 'Total loss': 0.3652614156405131} | train loss {'Reaction outcome loss': 0.21712461577924946, 'Total loss': 0.21712461577924946}
2022-12-31 13:46:00,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:00,473 INFO:     Epoch: 88
2022-12-31 13:46:02,063 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3540660878022512, 'Total loss': 0.3540660878022512} | train loss {'Reaction outcome loss': 0.22328413448058596, 'Total loss': 0.22328413448058596}
2022-12-31 13:46:02,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:02,063 INFO:     Epoch: 89
2022-12-31 13:46:03,711 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35267699758211773, 'Total loss': 0.35267699758211773} | train loss {'Reaction outcome loss': 0.22329253284049733, 'Total loss': 0.22329253284049733}
2022-12-31 13:46:03,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:03,711 INFO:     Epoch: 90
2022-12-31 13:46:05,348 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3699912349383036, 'Total loss': 0.3699912349383036} | train loss {'Reaction outcome loss': 0.21994445355992048, 'Total loss': 0.21994445355992048}
2022-12-31 13:46:05,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:05,348 INFO:     Epoch: 91
2022-12-31 13:46:06,999 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4068821241458257, 'Total loss': 0.4068821241458257} | train loss {'Reaction outcome loss': 0.21337983501396832, 'Total loss': 0.21337983501396832}
2022-12-31 13:46:06,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:06,999 INFO:     Epoch: 92
2022-12-31 13:46:08,611 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36708817183971404, 'Total loss': 0.36708817183971404} | train loss {'Reaction outcome loss': 0.2133552666584391, 'Total loss': 0.2133552666584391}
2022-12-31 13:46:08,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:08,612 INFO:     Epoch: 93
2022-12-31 13:46:10,200 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3900578379631042, 'Total loss': 0.3900578379631042} | train loss {'Reaction outcome loss': 0.21858087899433315, 'Total loss': 0.21858087899433315}
2022-12-31 13:46:10,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:10,201 INFO:     Epoch: 94
2022-12-31 13:46:11,799 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4282022496064504, 'Total loss': 0.4282022496064504} | train loss {'Reaction outcome loss': 0.3576894813070438, 'Total loss': 0.3576894813070438}
2022-12-31 13:46:11,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:11,799 INFO:     Epoch: 95
2022-12-31 13:46:13,410 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3690854589144389, 'Total loss': 0.3690854589144389} | train loss {'Reaction outcome loss': 0.27743036091071216, 'Total loss': 0.27743036091071216}
2022-12-31 13:46:13,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:13,411 INFO:     Epoch: 96
2022-12-31 13:46:15,024 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37000213662783304, 'Total loss': 0.37000213662783304} | train loss {'Reaction outcome loss': 0.24909639832311062, 'Total loss': 0.24909639832311062}
2022-12-31 13:46:15,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:15,024 INFO:     Epoch: 97
2022-12-31 13:46:16,637 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3849331796169281, 'Total loss': 0.3849331796169281} | train loss {'Reaction outcome loss': 0.24096284385439873, 'Total loss': 0.24096284385439873}
2022-12-31 13:46:16,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:16,638 INFO:     Epoch: 98
2022-12-31 13:46:18,250 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3822625815868378, 'Total loss': 0.3822625815868378} | train loss {'Reaction outcome loss': 0.23513231486203554, 'Total loss': 0.23513231486203554}
2022-12-31 13:46:18,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:18,250 INFO:     Epoch: 99
2022-12-31 13:46:19,842 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3756422586739063, 'Total loss': 0.3756422586739063} | train loss {'Reaction outcome loss': 0.23124686934971722, 'Total loss': 0.23124686934971722}
2022-12-31 13:46:19,843 INFO:     Best model found after epoch 65 of 100.
2022-12-31 13:46:19,843 INFO:   Done with stage: TRAINING
2022-12-31 13:46:19,843 INFO:   Starting stage: EVALUATION
2022-12-31 13:46:19,974 INFO:   Done with stage: EVALUATION
2022-12-31 13:46:19,974 INFO:   Leaving out SEQ value Fold_5
2022-12-31 13:46:19,986 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 13:46:19,986 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:46:20,629 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:46:20,629 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:46:20,698 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:46:20,698 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:46:20,698 INFO:     No hyperparam tuning for this model
2022-12-31 13:46:20,698 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:46:20,698 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:46:20,699 INFO:     None feature selector for col prot
2022-12-31 13:46:20,699 INFO:     None feature selector for col prot
2022-12-31 13:46:20,699 INFO:     None feature selector for col prot
2022-12-31 13:46:20,700 INFO:     None feature selector for col chem
2022-12-31 13:46:20,700 INFO:     None feature selector for col chem
2022-12-31 13:46:20,700 INFO:     None feature selector for col chem
2022-12-31 13:46:20,700 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:46:20,700 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:46:20,702 INFO:     Number of params in model 223921
2022-12-31 13:46:20,705 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:46:20,705 INFO:   Starting stage: TRAINING
2022-12-31 13:46:20,749 INFO:     Val loss before train {'Reaction outcome loss': 0.9368270675341288, 'Total loss': 0.9368270675341288}
2022-12-31 13:46:20,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:20,749 INFO:     Epoch: 0
2022-12-31 13:46:22,379 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6626130700111389, 'Total loss': 0.6626130700111389} | train loss {'Reaction outcome loss': 0.8114943453766379, 'Total loss': 0.8114943453766379}
2022-12-31 13:46:22,379 INFO:     Found new best model at epoch 0
2022-12-31 13:46:22,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:22,380 INFO:     Epoch: 1
2022-12-31 13:46:24,017 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5533023794492086, 'Total loss': 0.5533023794492086} | train loss {'Reaction outcome loss': 0.6047965896043537, 'Total loss': 0.6047965896043537}
2022-12-31 13:46:24,017 INFO:     Found new best model at epoch 1
2022-12-31 13:46:24,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:24,018 INFO:     Epoch: 2
2022-12-31 13:46:25,668 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.551182069381078, 'Total loss': 0.551182069381078} | train loss {'Reaction outcome loss': 0.5276594494439204, 'Total loss': 0.5276594494439204}
2022-12-31 13:46:25,668 INFO:     Found new best model at epoch 2
2022-12-31 13:46:25,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:25,669 INFO:     Epoch: 3
2022-12-31 13:46:27,272 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5362608313560486, 'Total loss': 0.5362608313560486} | train loss {'Reaction outcome loss': 0.4965476571760453, 'Total loss': 0.4965476571760453}
2022-12-31 13:46:27,272 INFO:     Found new best model at epoch 3
2022-12-31 13:46:27,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:27,273 INFO:     Epoch: 4
2022-12-31 13:46:28,866 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5369474569956462, 'Total loss': 0.5369474569956462} | train loss {'Reaction outcome loss': 0.4895904825912916, 'Total loss': 0.4895904825912916}
2022-12-31 13:46:28,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:28,867 INFO:     Epoch: 5
2022-12-31 13:46:30,489 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5507959206899007, 'Total loss': 0.5507959206899007} | train loss {'Reaction outcome loss': 0.47447118343321426, 'Total loss': 0.47447118343321426}
2022-12-31 13:46:30,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:30,489 INFO:     Epoch: 6
2022-12-31 13:46:32,109 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5238720357418061, 'Total loss': 0.5238720357418061} | train loss {'Reaction outcome loss': 0.46917468868868445, 'Total loss': 0.46917468868868445}
2022-12-31 13:46:32,109 INFO:     Found new best model at epoch 6
2022-12-31 13:46:32,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:32,110 INFO:     Epoch: 7
2022-12-31 13:46:33,731 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4942897081375122, 'Total loss': 0.4942897081375122} | train loss {'Reaction outcome loss': 0.4628504075728599, 'Total loss': 0.4628504075728599}
2022-12-31 13:46:33,731 INFO:     Found new best model at epoch 7
2022-12-31 13:46:33,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:33,732 INFO:     Epoch: 8
2022-12-31 13:46:35,368 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.53079887231191, 'Total loss': 0.53079887231191} | train loss {'Reaction outcome loss': 0.4573601575749876, 'Total loss': 0.4573601575749876}
2022-12-31 13:46:35,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:35,368 INFO:     Epoch: 9
2022-12-31 13:46:36,966 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5368632237116496, 'Total loss': 0.5368632237116496} | train loss {'Reaction outcome loss': 0.4494337012406291, 'Total loss': 0.4494337012406291}
2022-12-31 13:46:36,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:36,967 INFO:     Epoch: 10
2022-12-31 13:46:38,583 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5123074471950531, 'Total loss': 0.5123074471950531} | train loss {'Reaction outcome loss': 0.4389274000906342, 'Total loss': 0.4389274000906342}
2022-12-31 13:46:38,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:38,583 INFO:     Epoch: 11
2022-12-31 13:46:40,222 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5275642037391662, 'Total loss': 0.5275642037391662} | train loss {'Reaction outcome loss': 0.431660770294038, 'Total loss': 0.431660770294038}
2022-12-31 13:46:40,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:40,222 INFO:     Epoch: 12
2022-12-31 13:46:41,843 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49812453587849936, 'Total loss': 0.49812453587849936} | train loss {'Reaction outcome loss': 0.4277723410607245, 'Total loss': 0.4277723410607245}
2022-12-31 13:46:41,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:41,843 INFO:     Epoch: 13
2022-12-31 13:46:43,463 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5177210589249929, 'Total loss': 0.5177210589249929} | train loss {'Reaction outcome loss': 0.4208623232716688, 'Total loss': 0.4208623232716688}
2022-12-31 13:46:43,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:43,463 INFO:     Epoch: 14
2022-12-31 13:46:45,083 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4910484751065572, 'Total loss': 0.4910484751065572} | train loss {'Reaction outcome loss': 0.4178034106424139, 'Total loss': 0.4178034106424139}
2022-12-31 13:46:45,084 INFO:     Found new best model at epoch 14
2022-12-31 13:46:45,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:45,085 INFO:     Epoch: 15
2022-12-31 13:46:46,666 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5009816646575928, 'Total loss': 0.5009816646575928} | train loss {'Reaction outcome loss': 0.40998847406048206, 'Total loss': 0.40998847406048206}
2022-12-31 13:46:46,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:46,666 INFO:     Epoch: 16
2022-12-31 13:46:48,306 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5128726085027059, 'Total loss': 0.5128726085027059} | train loss {'Reaction outcome loss': 0.4003690189618066, 'Total loss': 0.4003690189618066}
2022-12-31 13:46:48,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:48,308 INFO:     Epoch: 17
2022-12-31 13:46:49,926 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5234736859798431, 'Total loss': 0.5234736859798431} | train loss {'Reaction outcome loss': 0.394761239605475, 'Total loss': 0.394761239605475}
2022-12-31 13:46:49,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:49,926 INFO:     Epoch: 18
2022-12-31 13:46:51,546 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4974356770515442, 'Total loss': 0.4974356770515442} | train loss {'Reaction outcome loss': 0.39084268100425223, 'Total loss': 0.39084268100425223}
2022-12-31 13:46:51,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:51,547 INFO:     Epoch: 19
2022-12-31 13:46:53,166 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4950818141301473, 'Total loss': 0.4950818141301473} | train loss {'Reaction outcome loss': 0.387220678306336, 'Total loss': 0.387220678306336}
2022-12-31 13:46:53,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:53,167 INFO:     Epoch: 20
2022-12-31 13:46:54,769 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.482136736313502, 'Total loss': 0.482136736313502} | train loss {'Reaction outcome loss': 0.3758666050832194, 'Total loss': 0.3758666050832194}
2022-12-31 13:46:54,769 INFO:     Found new best model at epoch 20
2022-12-31 13:46:54,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:54,770 INFO:     Epoch: 21
2022-12-31 13:46:56,401 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48824029564857485, 'Total loss': 0.48824029564857485} | train loss {'Reaction outcome loss': 0.37086327481571085, 'Total loss': 0.37086327481571085}
2022-12-31 13:46:56,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:56,402 INFO:     Epoch: 22
2022-12-31 13:46:58,050 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.502017080783844, 'Total loss': 0.502017080783844} | train loss {'Reaction outcome loss': 0.3666477212245284, 'Total loss': 0.3666477212245284}
2022-12-31 13:46:58,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:58,050 INFO:     Epoch: 23
2022-12-31 13:46:59,674 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4776234567165375, 'Total loss': 0.4776234567165375} | train loss {'Reaction outcome loss': 0.3618391938911018, 'Total loss': 0.3618391938911018}
2022-12-31 13:46:59,675 INFO:     Found new best model at epoch 23
2022-12-31 13:46:59,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:46:59,676 INFO:     Epoch: 24
2022-12-31 13:47:01,294 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4810302257537842, 'Total loss': 0.4810302257537842} | train loss {'Reaction outcome loss': 0.354615869881444, 'Total loss': 0.354615869881444}
2022-12-31 13:47:01,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:01,295 INFO:     Epoch: 25
2022-12-31 13:47:02,920 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4901780754327774, 'Total loss': 0.4901780754327774} | train loss {'Reaction outcome loss': 0.35370733099401214, 'Total loss': 0.35370733099401214}
2022-12-31 13:47:02,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:02,921 INFO:     Epoch: 26
2022-12-31 13:47:04,515 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48198797305425006, 'Total loss': 0.48198797305425006} | train loss {'Reaction outcome loss': 0.3403779719737678, 'Total loss': 0.3403779719737678}
2022-12-31 13:47:04,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:04,515 INFO:     Epoch: 27
2022-12-31 13:47:06,163 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46932568252086637, 'Total loss': 0.46932568252086637} | train loss {'Reaction outcome loss': 0.3399443787788226, 'Total loss': 0.3399443787788226}
2022-12-31 13:47:06,163 INFO:     Found new best model at epoch 27
2022-12-31 13:47:06,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:06,164 INFO:     Epoch: 28
2022-12-31 13:47:07,792 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4974763015906016, 'Total loss': 0.4974763015906016} | train loss {'Reaction outcome loss': 0.33923203382466244, 'Total loss': 0.33923203382466244}
2022-12-31 13:47:07,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:07,793 INFO:     Epoch: 29
2022-12-31 13:47:09,437 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5027209103107453, 'Total loss': 0.5027209103107453} | train loss {'Reaction outcome loss': 0.33788778159484967, 'Total loss': 0.33788778159484967}
2022-12-31 13:47:09,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:09,437 INFO:     Epoch: 30
2022-12-31 13:47:11,065 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48473289608955383, 'Total loss': 0.48473289608955383} | train loss {'Reaction outcome loss': 0.3260114175613822, 'Total loss': 0.3260114175613822}
2022-12-31 13:47:11,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:11,066 INFO:     Epoch: 31
2022-12-31 13:47:12,702 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4650094032287598, 'Total loss': 0.4650094032287598} | train loss {'Reaction outcome loss': 0.3265797557033572, 'Total loss': 0.3265797557033572}
2022-12-31 13:47:12,702 INFO:     Found new best model at epoch 31
2022-12-31 13:47:12,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:12,703 INFO:     Epoch: 32
2022-12-31 13:47:14,325 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47204865515232086, 'Total loss': 0.47204865515232086} | train loss {'Reaction outcome loss': 0.3179924898118534, 'Total loss': 0.3179924898118534}
2022-12-31 13:47:14,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:14,325 INFO:     Epoch: 33
2022-12-31 13:47:15,959 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4968689521153768, 'Total loss': 0.4968689521153768} | train loss {'Reaction outcome loss': 0.31341660980283137, 'Total loss': 0.31341660980283137}
2022-12-31 13:47:15,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:15,960 INFO:     Epoch: 34
2022-12-31 13:47:17,609 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5098347822825114, 'Total loss': 0.5098347822825114} | train loss {'Reaction outcome loss': 0.3146975851930436, 'Total loss': 0.3146975851930436}
2022-12-31 13:47:17,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:17,610 INFO:     Epoch: 35
2022-12-31 13:47:19,279 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46818170448144275, 'Total loss': 0.46818170448144275} | train loss {'Reaction outcome loss': 0.3039362905042696, 'Total loss': 0.3039362905042696}
2022-12-31 13:47:19,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:19,279 INFO:     Epoch: 36
2022-12-31 13:47:20,899 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49591765403747556, 'Total loss': 0.49591765403747556} | train loss {'Reaction outcome loss': 0.30501273949546504, 'Total loss': 0.30501273949546504}
2022-12-31 13:47:20,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:20,899 INFO:     Epoch: 37
2022-12-31 13:47:22,485 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47955973744392394, 'Total loss': 0.47955973744392394} | train loss {'Reaction outcome loss': 0.3093942441987647, 'Total loss': 0.3093942441987647}
2022-12-31 13:47:22,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:22,486 INFO:     Epoch: 38
2022-12-31 13:47:24,107 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4820759435494741, 'Total loss': 0.4820759435494741} | train loss {'Reaction outcome loss': 0.2982658478246484, 'Total loss': 0.2982658478246484}
2022-12-31 13:47:24,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:24,107 INFO:     Epoch: 39
2022-12-31 13:47:25,723 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.55960893034935, 'Total loss': 0.55960893034935} | train loss {'Reaction outcome loss': 0.29540582982964464, 'Total loss': 0.29540582982964464}
2022-12-31 13:47:25,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:25,723 INFO:     Epoch: 40
2022-12-31 13:47:27,339 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5066050350666046, 'Total loss': 0.5066050350666046} | train loss {'Reaction outcome loss': 0.29366706479811494, 'Total loss': 0.29366706479811494}
2022-12-31 13:47:27,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:27,339 INFO:     Epoch: 41
2022-12-31 13:47:28,956 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4769098480542501, 'Total loss': 0.4769098480542501} | train loss {'Reaction outcome loss': 0.2887338305208227, 'Total loss': 0.2887338305208227}
2022-12-31 13:47:28,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:28,957 INFO:     Epoch: 42
2022-12-31 13:47:30,573 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45179949402809144, 'Total loss': 0.45179949402809144} | train loss {'Reaction outcome loss': 0.2916468121649341, 'Total loss': 0.2916468121649341}
2022-12-31 13:47:30,573 INFO:     Found new best model at epoch 42
2022-12-31 13:47:30,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:30,574 INFO:     Epoch: 43
2022-12-31 13:47:32,151 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47099324067433673, 'Total loss': 0.47099324067433673} | train loss {'Reaction outcome loss': 0.28189787606201017, 'Total loss': 0.28189787606201017}
2022-12-31 13:47:32,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:32,151 INFO:     Epoch: 44
2022-12-31 13:47:33,767 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46508024136225384, 'Total loss': 0.46508024136225384} | train loss {'Reaction outcome loss': 0.28186853815018054, 'Total loss': 0.28186853815018054}
2022-12-31 13:47:33,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:33,768 INFO:     Epoch: 45
2022-12-31 13:47:35,397 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.51401320596536, 'Total loss': 0.51401320596536} | train loss {'Reaction outcome loss': 0.27514750963675416, 'Total loss': 0.27514750963675416}
2022-12-31 13:47:35,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:35,397 INFO:     Epoch: 46
2022-12-31 13:47:37,015 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.52144549091657, 'Total loss': 0.52144549091657} | train loss {'Reaction outcome loss': 0.28091112931766665, 'Total loss': 0.28091112931766665}
2022-12-31 13:47:37,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:37,015 INFO:     Epoch: 47
2022-12-31 13:47:38,630 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45915459394454955, 'Total loss': 0.45915459394454955} | train loss {'Reaction outcome loss': 0.27621605989627457, 'Total loss': 0.27621605989627457}
2022-12-31 13:47:38,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:38,631 INFO:     Epoch: 48
2022-12-31 13:47:40,235 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46702307065327964, 'Total loss': 0.46702307065327964} | train loss {'Reaction outcome loss': 0.2743667592075973, 'Total loss': 0.2743667592075973}
2022-12-31 13:47:40,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:40,235 INFO:     Epoch: 49
2022-12-31 13:47:41,842 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48736281295617423, 'Total loss': 0.48736281295617423} | train loss {'Reaction outcome loss': 0.26891573932734636, 'Total loss': 0.26891573932734636}
2022-12-31 13:47:41,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:41,843 INFO:     Epoch: 50
2022-12-31 13:47:43,456 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5069383005301158, 'Total loss': 0.5069383005301158} | train loss {'Reaction outcome loss': 0.2652797099565986, 'Total loss': 0.2652797099565986}
2022-12-31 13:47:43,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:43,457 INFO:     Epoch: 51
2022-12-31 13:47:45,073 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46999280552069345, 'Total loss': 0.46999280552069345} | train loss {'Reaction outcome loss': 0.2697250360643175, 'Total loss': 0.2697250360643175}
2022-12-31 13:47:45,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:45,073 INFO:     Epoch: 52
2022-12-31 13:47:46,695 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5082852373520533, 'Total loss': 0.5082852373520533} | train loss {'Reaction outcome loss': 0.26471317390027027, 'Total loss': 0.26471317390027027}
2022-12-31 13:47:46,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:46,695 INFO:     Epoch: 53
2022-12-31 13:47:48,335 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45298956831296283, 'Total loss': 0.45298956831296283} | train loss {'Reaction outcome loss': 0.2621286876687935, 'Total loss': 0.2621286876687935}
2022-12-31 13:47:48,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:48,336 INFO:     Epoch: 54
2022-12-31 13:47:49,919 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5339149137338003, 'Total loss': 0.5339149137338003} | train loss {'Reaction outcome loss': 0.2615675853854482, 'Total loss': 0.2615675853854482}
2022-12-31 13:47:49,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:49,920 INFO:     Epoch: 55
2022-12-31 13:47:51,551 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4622763087352117, 'Total loss': 0.4622763087352117} | train loss {'Reaction outcome loss': 0.2616685738632395, 'Total loss': 0.2616685738632395}
2022-12-31 13:47:51,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:51,551 INFO:     Epoch: 56
2022-12-31 13:47:53,189 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47119861245155337, 'Total loss': 0.47119861245155337} | train loss {'Reaction outcome loss': 0.25954066208876425, 'Total loss': 0.25954066208876425}
2022-12-31 13:47:53,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:53,189 INFO:     Epoch: 57
2022-12-31 13:47:54,807 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4745078881581624, 'Total loss': 0.4745078881581624} | train loss {'Reaction outcome loss': 0.2567832130225987, 'Total loss': 0.2567832130225987}
2022-12-31 13:47:54,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:54,807 INFO:     Epoch: 58
2022-12-31 13:47:56,425 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4392661208907763, 'Total loss': 0.4392661208907763} | train loss {'Reaction outcome loss': 0.25158540078771674, 'Total loss': 0.25158540078771674}
2022-12-31 13:47:56,426 INFO:     Found new best model at epoch 58
2022-12-31 13:47:56,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:56,427 INFO:     Epoch: 59
2022-12-31 13:47:58,020 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49171530107657113, 'Total loss': 0.49171530107657113} | train loss {'Reaction outcome loss': 0.253285319756192, 'Total loss': 0.253285319756192}
2022-12-31 13:47:58,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:58,021 INFO:     Epoch: 60
2022-12-31 13:47:59,628 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4868048181136449, 'Total loss': 0.4868048181136449} | train loss {'Reaction outcome loss': 0.2532762735006181, 'Total loss': 0.2532762735006181}
2022-12-31 13:47:59,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:47:59,628 INFO:     Epoch: 61
2022-12-31 13:48:01,247 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49068225622177125, 'Total loss': 0.49068225622177125} | train loss {'Reaction outcome loss': 0.2517044771368538, 'Total loss': 0.2517044771368538}
2022-12-31 13:48:01,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:01,247 INFO:     Epoch: 62
2022-12-31 13:48:02,872 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5087377885977428, 'Total loss': 0.5087377885977428} | train loss {'Reaction outcome loss': 0.2499087892795513, 'Total loss': 0.2499087892795513}
2022-12-31 13:48:02,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:02,872 INFO:     Epoch: 63
2022-12-31 13:48:04,500 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4970126301050186, 'Total loss': 0.4970126301050186} | train loss {'Reaction outcome loss': 0.2511290682056105, 'Total loss': 0.2511290682056105}
2022-12-31 13:48:04,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:04,501 INFO:     Epoch: 64
2022-12-31 13:48:06,122 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4336589515209198, 'Total loss': 0.4336589515209198} | train loss {'Reaction outcome loss': 0.24843036889734035, 'Total loss': 0.24843036889734035}
2022-12-31 13:48:06,122 INFO:     Found new best model at epoch 64
2022-12-31 13:48:06,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:06,123 INFO:     Epoch: 65
2022-12-31 13:48:07,710 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5139281193415324, 'Total loss': 0.5139281193415324} | train loss {'Reaction outcome loss': 0.2533304283213852, 'Total loss': 0.2533304283213852}
2022-12-31 13:48:07,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:07,710 INFO:     Epoch: 66
2022-12-31 13:48:09,339 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4679464300473531, 'Total loss': 0.4679464300473531} | train loss {'Reaction outcome loss': 0.24142969162321049, 'Total loss': 0.24142969162321049}
2022-12-31 13:48:09,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:09,340 INFO:     Epoch: 67
2022-12-31 13:48:10,970 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4639674117167791, 'Total loss': 0.4639674117167791} | train loss {'Reaction outcome loss': 0.2448972003662199, 'Total loss': 0.2448972003662199}
2022-12-31 13:48:10,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:10,970 INFO:     Epoch: 68
2022-12-31 13:48:12,628 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4790671626726786, 'Total loss': 0.4790671626726786} | train loss {'Reaction outcome loss': 0.2368458420549274, 'Total loss': 0.2368458420549274}
2022-12-31 13:48:12,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:12,628 INFO:     Epoch: 69
2022-12-31 13:48:14,250 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46199657718340553, 'Total loss': 0.46199657718340553} | train loss {'Reaction outcome loss': 0.2375731754254563, 'Total loss': 0.2375731754254563}
2022-12-31 13:48:14,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:14,250 INFO:     Epoch: 70
2022-12-31 13:48:15,867 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46796260476112367, 'Total loss': 0.46796260476112367} | train loss {'Reaction outcome loss': 0.23355956873200862, 'Total loss': 0.23355956873200862}
2022-12-31 13:48:15,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:15,868 INFO:     Epoch: 71
2022-12-31 13:48:17,467 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4487426166733106, 'Total loss': 0.4487426166733106} | train loss {'Reaction outcome loss': 0.23111630638637698, 'Total loss': 0.23111630638637698}
2022-12-31 13:48:17,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:17,468 INFO:     Epoch: 72
2022-12-31 13:48:19,102 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46197121938069663, 'Total loss': 0.46197121938069663} | train loss {'Reaction outcome loss': 0.23146967607338506, 'Total loss': 0.23146967607338506}
2022-12-31 13:48:19,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:19,102 INFO:     Epoch: 73
2022-12-31 13:48:20,725 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4827646593252818, 'Total loss': 0.4827646593252818} | train loss {'Reaction outcome loss': 0.2297425690823191, 'Total loss': 0.2297425690823191}
2022-12-31 13:48:20,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:20,725 INFO:     Epoch: 74
2022-12-31 13:48:22,396 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.490472807486852, 'Total loss': 0.490472807486852} | train loss {'Reaction outcome loss': 0.22849351545587343, 'Total loss': 0.22849351545587343}
2022-12-31 13:48:22,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:22,396 INFO:     Epoch: 75
2022-12-31 13:48:24,062 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4603374938170115, 'Total loss': 0.4603374938170115} | train loss {'Reaction outcome loss': 0.23247542040631014, 'Total loss': 0.23247542040631014}
2022-12-31 13:48:24,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:24,063 INFO:     Epoch: 76
2022-12-31 13:48:25,684 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4880972961584727, 'Total loss': 0.4880972961584727} | train loss {'Reaction outcome loss': 0.23439724304938575, 'Total loss': 0.23439724304938575}
2022-12-31 13:48:25,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:25,684 INFO:     Epoch: 77
2022-12-31 13:48:27,287 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4696787456671397, 'Total loss': 0.4696787456671397} | train loss {'Reaction outcome loss': 0.23132123539916874, 'Total loss': 0.23132123539916874}
2022-12-31 13:48:27,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:27,287 INFO:     Epoch: 78
2022-12-31 13:48:28,908 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4493319575985273, 'Total loss': 0.4493319575985273} | train loss {'Reaction outcome loss': 0.2225444628335939, 'Total loss': 0.2225444628335939}
2022-12-31 13:48:28,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:28,908 INFO:     Epoch: 79
2022-12-31 13:48:30,526 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4355915347735087, 'Total loss': 0.4355915347735087} | train loss {'Reaction outcome loss': 0.22897254609728118, 'Total loss': 0.22897254609728118}
2022-12-31 13:48:30,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:30,527 INFO:     Epoch: 80
2022-12-31 13:48:32,146 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4342157413562139, 'Total loss': 0.4342157413562139} | train loss {'Reaction outcome loss': 0.22085392289536093, 'Total loss': 0.22085392289536093}
2022-12-31 13:48:32,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:32,147 INFO:     Epoch: 81
2022-12-31 13:48:33,769 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45620278219381966, 'Total loss': 0.45620278219381966} | train loss {'Reaction outcome loss': 0.2293031042044989, 'Total loss': 0.2293031042044989}
2022-12-31 13:48:33,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:33,770 INFO:     Epoch: 82
2022-12-31 13:48:35,364 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44837217330932616, 'Total loss': 0.44837217330932616} | train loss {'Reaction outcome loss': 0.22218863396074906, 'Total loss': 0.22218863396074906}
2022-12-31 13:48:35,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:35,364 INFO:     Epoch: 83
2022-12-31 13:48:36,982 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4545181214809418, 'Total loss': 0.4545181214809418} | train loss {'Reaction outcome loss': 0.22505259715585502, 'Total loss': 0.22505259715585502}
2022-12-31 13:48:36,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:36,982 INFO:     Epoch: 84
2022-12-31 13:48:38,603 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47109146416187286, 'Total loss': 0.47109146416187286} | train loss {'Reaction outcome loss': 0.22919529483784729, 'Total loss': 0.22919529483784729}
2022-12-31 13:48:38,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:38,603 INFO:     Epoch: 85
2022-12-31 13:48:40,224 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43152187739809356, 'Total loss': 0.43152187739809356} | train loss {'Reaction outcome loss': 0.21802651086008507, 'Total loss': 0.21802651086008507}
2022-12-31 13:48:40,225 INFO:     Found new best model at epoch 85
2022-12-31 13:48:40,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:40,226 INFO:     Epoch: 86
2022-12-31 13:48:41,843 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45037817358970644, 'Total loss': 0.45037817358970644} | train loss {'Reaction outcome loss': 0.21189120096500816, 'Total loss': 0.21189120096500816}
2022-12-31 13:48:41,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:41,844 INFO:     Epoch: 87
2022-12-31 13:48:43,445 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44645883440971373, 'Total loss': 0.44645883440971373} | train loss {'Reaction outcome loss': 0.21785369904086477, 'Total loss': 0.21785369904086477}
2022-12-31 13:48:43,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:43,445 INFO:     Epoch: 88
2022-12-31 13:48:45,044 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48881596823533374, 'Total loss': 0.48881596823533374} | train loss {'Reaction outcome loss': 0.21994849108159542, 'Total loss': 0.21994849108159542}
2022-12-31 13:48:45,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:45,044 INFO:     Epoch: 89
2022-12-31 13:48:46,662 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4937969744205475, 'Total loss': 0.4937969744205475} | train loss {'Reaction outcome loss': 0.21622814586392808, 'Total loss': 0.21622814586392808}
2022-12-31 13:48:46,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:46,663 INFO:     Epoch: 90
2022-12-31 13:48:48,310 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4314278503259023, 'Total loss': 0.4314278503259023} | train loss {'Reaction outcome loss': 0.21241030313531845, 'Total loss': 0.21241030313531845}
2022-12-31 13:48:48,310 INFO:     Found new best model at epoch 90
2022-12-31 13:48:48,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:48,311 INFO:     Epoch: 91
2022-12-31 13:48:49,928 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49607734779516854, 'Total loss': 0.49607734779516854} | train loss {'Reaction outcome loss': 0.22602577277523087, 'Total loss': 0.22602577277523087}
2022-12-31 13:48:49,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:49,928 INFO:     Epoch: 92
2022-12-31 13:48:51,552 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4343758483727773, 'Total loss': 0.4343758483727773} | train loss {'Reaction outcome loss': 0.21593122316073854, 'Total loss': 0.21593122316073854}
2022-12-31 13:48:51,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:51,552 INFO:     Epoch: 93
2022-12-31 13:48:53,134 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.467087976137797, 'Total loss': 0.467087976137797} | train loss {'Reaction outcome loss': 0.21302245612447873, 'Total loss': 0.21302245612447873}
2022-12-31 13:48:53,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:53,135 INFO:     Epoch: 94
2022-12-31 13:48:54,800 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47709346810976666, 'Total loss': 0.47709346810976666} | train loss {'Reaction outcome loss': 0.22413372660613878, 'Total loss': 0.22413372660613878}
2022-12-31 13:48:54,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:54,801 INFO:     Epoch: 95
2022-12-31 13:48:56,467 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4455747981866201, 'Total loss': 0.4455747981866201} | train loss {'Reaction outcome loss': 0.2151989364720854, 'Total loss': 0.2151989364720854}
2022-12-31 13:48:56,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:56,467 INFO:     Epoch: 96
2022-12-31 13:48:58,133 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.474752210577329, 'Total loss': 0.474752210577329} | train loss {'Reaction outcome loss': 0.20810288993056716, 'Total loss': 0.20810288993056716}
2022-12-31 13:48:58,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:58,133 INFO:     Epoch: 97
2022-12-31 13:48:59,797 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44983871579170226, 'Total loss': 0.44983871579170226} | train loss {'Reaction outcome loss': 0.20582046929329956, 'Total loss': 0.20582046929329956}
2022-12-31 13:48:59,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:48:59,797 INFO:     Epoch: 98
2022-12-31 13:49:01,403 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4388200302918752, 'Total loss': 0.4388200302918752} | train loss {'Reaction outcome loss': 0.21298318757719295, 'Total loss': 0.21298318757719295}
2022-12-31 13:49:01,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:01,403 INFO:     Epoch: 99
2022-12-31 13:49:03,002 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48101042906443275, 'Total loss': 0.48101042906443275} | train loss {'Reaction outcome loss': 0.2211847962670378, 'Total loss': 0.2211847962670378}
2022-12-31 13:49:03,002 INFO:     Best model found after epoch 91 of 100.
2022-12-31 13:49:03,003 INFO:   Done with stage: TRAINING
2022-12-31 13:49:03,003 INFO:   Starting stage: EVALUATION
2022-12-31 13:49:03,125 INFO:   Done with stage: EVALUATION
2022-12-31 13:49:03,125 INFO:   Leaving out SEQ value Fold_6
2022-12-31 13:49:03,137 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 13:49:03,138 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:49:03,796 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:49:03,796 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:49:03,865 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:49:03,865 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:49:03,865 INFO:     No hyperparam tuning for this model
2022-12-31 13:49:03,865 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:49:03,865 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:49:03,866 INFO:     None feature selector for col prot
2022-12-31 13:49:03,866 INFO:     None feature selector for col prot
2022-12-31 13:49:03,866 INFO:     None feature selector for col prot
2022-12-31 13:49:03,867 INFO:     None feature selector for col chem
2022-12-31 13:49:03,867 INFO:     None feature selector for col chem
2022-12-31 13:49:03,867 INFO:     None feature selector for col chem
2022-12-31 13:49:03,867 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:49:03,867 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:49:03,869 INFO:     Number of params in model 223921
2022-12-31 13:49:03,872 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:49:03,872 INFO:   Starting stage: TRAINING
2022-12-31 13:49:03,916 INFO:     Val loss before train {'Reaction outcome loss': 0.9045598367849986, 'Total loss': 0.9045598367849986}
2022-12-31 13:49:03,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:03,916 INFO:     Epoch: 0
2022-12-31 13:49:05,578 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.605892280737559, 'Total loss': 0.605892280737559} | train loss {'Reaction outcome loss': 0.824441047136534, 'Total loss': 0.824441047136534}
2022-12-31 13:49:05,579 INFO:     Found new best model at epoch 0
2022-12-31 13:49:05,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:05,579 INFO:     Epoch: 1
2022-12-31 13:49:07,228 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5433245559533437, 'Total loss': 0.5433245559533437} | train loss {'Reaction outcome loss': 0.5970010076404049, 'Total loss': 0.5970010076404049}
2022-12-31 13:49:07,228 INFO:     Found new best model at epoch 1
2022-12-31 13:49:07,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:07,229 INFO:     Epoch: 2
2022-12-31 13:49:08,847 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5159952878952027, 'Total loss': 0.5159952878952027} | train loss {'Reaction outcome loss': 0.5253956596558705, 'Total loss': 0.5253956596558705}
2022-12-31 13:49:08,849 INFO:     Found new best model at epoch 2
2022-12-31 13:49:08,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:08,850 INFO:     Epoch: 3
2022-12-31 13:49:10,442 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4945007185141245, 'Total loss': 0.4945007185141245} | train loss {'Reaction outcome loss': 0.5002555600249811, 'Total loss': 0.5002555600249811}
2022-12-31 13:49:10,442 INFO:     Found new best model at epoch 3
2022-12-31 13:49:10,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:10,443 INFO:     Epoch: 4
2022-12-31 13:49:12,075 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5022494355837505, 'Total loss': 0.5022494355837505} | train loss {'Reaction outcome loss': 0.48966188223138185, 'Total loss': 0.48966188223138185}
2022-12-31 13:49:12,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:12,075 INFO:     Epoch: 5
2022-12-31 13:49:13,737 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4797365893920263, 'Total loss': 0.4797365893920263} | train loss {'Reaction outcome loss': 0.48079795737344005, 'Total loss': 0.48079795737344005}
2022-12-31 13:49:13,737 INFO:     Found new best model at epoch 5
2022-12-31 13:49:13,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:13,738 INFO:     Epoch: 6
2022-12-31 13:49:15,376 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49069437086582185, 'Total loss': 0.49069437086582185} | train loss {'Reaction outcome loss': 0.46265046032219587, 'Total loss': 0.46265046032219587}
2022-12-31 13:49:15,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:15,378 INFO:     Epoch: 7
2022-12-31 13:49:16,995 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.450507715344429, 'Total loss': 0.450507715344429} | train loss {'Reaction outcome loss': 0.4635805986579575, 'Total loss': 0.4635805986579575}
2022-12-31 13:49:16,995 INFO:     Found new best model at epoch 7
2022-12-31 13:49:16,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:16,996 INFO:     Epoch: 8
2022-12-31 13:49:18,621 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4648769070704778, 'Total loss': 0.4648769070704778} | train loss {'Reaction outcome loss': 0.456906986446372, 'Total loss': 0.456906986446372}
2022-12-31 13:49:18,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:18,621 INFO:     Epoch: 9
2022-12-31 13:49:20,207 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43278871675332387, 'Total loss': 0.43278871675332387} | train loss {'Reaction outcome loss': 0.4470189639807608, 'Total loss': 0.4470189639807608}
2022-12-31 13:49:20,207 INFO:     Found new best model at epoch 9
2022-12-31 13:49:20,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:20,208 INFO:     Epoch: 10
2022-12-31 13:49:21,819 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44385626912117004, 'Total loss': 0.44385626912117004} | train loss {'Reaction outcome loss': 0.44260969214706214, 'Total loss': 0.44260969214706214}
2022-12-31 13:49:21,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:21,820 INFO:     Epoch: 11
2022-12-31 13:49:23,467 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46946884791056315, 'Total loss': 0.46946884791056315} | train loss {'Reaction outcome loss': 0.4389841506250929, 'Total loss': 0.4389841506250929}
2022-12-31 13:49:23,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:23,467 INFO:     Epoch: 12
2022-12-31 13:49:25,099 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4294277489185333, 'Total loss': 0.4294277489185333} | train loss {'Reaction outcome loss': 0.4246011361318375, 'Total loss': 0.4246011361318375}
2022-12-31 13:49:25,099 INFO:     Found new best model at epoch 12
2022-12-31 13:49:25,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:25,100 INFO:     Epoch: 13
2022-12-31 13:49:26,747 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4270084579785665, 'Total loss': 0.4270084579785665} | train loss {'Reaction outcome loss': 0.4234233551830161, 'Total loss': 0.4234233551830161}
2022-12-31 13:49:26,747 INFO:     Found new best model at epoch 13
2022-12-31 13:49:26,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:26,748 INFO:     Epoch: 14
2022-12-31 13:49:28,360 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44026524225870767, 'Total loss': 0.44026524225870767} | train loss {'Reaction outcome loss': 0.4199259484502813, 'Total loss': 0.4199259484502813}
2022-12-31 13:49:28,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:28,361 INFO:     Epoch: 15
2022-12-31 13:49:29,968 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44635410408178966, 'Total loss': 0.44635410408178966} | train loss {'Reaction outcome loss': 0.4122785850552445, 'Total loss': 0.4122785850552445}
2022-12-31 13:49:29,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:29,968 INFO:     Epoch: 16
2022-12-31 13:49:31,614 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4312313030163447, 'Total loss': 0.4312313030163447} | train loss {'Reaction outcome loss': 0.4082945250916137, 'Total loss': 0.4082945250916137}
2022-12-31 13:49:31,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:31,614 INFO:     Epoch: 17
2022-12-31 13:49:33,273 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4487224717934926, 'Total loss': 0.4487224717934926} | train loss {'Reaction outcome loss': 0.4068107562213598, 'Total loss': 0.4068107562213598}
2022-12-31 13:49:33,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:33,273 INFO:     Epoch: 18
2022-12-31 13:49:34,888 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43086048662662507, 'Total loss': 0.43086048662662507} | train loss {'Reaction outcome loss': 0.39707843523593583, 'Total loss': 0.39707843523593583}
2022-12-31 13:49:34,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:34,888 INFO:     Epoch: 19
2022-12-31 13:49:36,511 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4144400705893834, 'Total loss': 0.4144400705893834} | train loss {'Reaction outcome loss': 0.39603819318841943, 'Total loss': 0.39603819318841943}
2022-12-31 13:49:36,511 INFO:     Found new best model at epoch 19
2022-12-31 13:49:36,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:36,512 INFO:     Epoch: 20
2022-12-31 13:49:38,122 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44843850334485374, 'Total loss': 0.44843850334485374} | train loss {'Reaction outcome loss': 0.3862921872616675, 'Total loss': 0.3862921872616675}
2022-12-31 13:49:38,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:38,123 INFO:     Epoch: 21
2022-12-31 13:49:39,752 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4265272945165634, 'Total loss': 0.4265272945165634} | train loss {'Reaction outcome loss': 0.3828852031285797, 'Total loss': 0.3828852031285797}
2022-12-31 13:49:39,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:39,753 INFO:     Epoch: 22
2022-12-31 13:49:41,380 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45511904954910276, 'Total loss': 0.45511904954910276} | train loss {'Reaction outcome loss': 0.3739767459890257, 'Total loss': 0.3739767459890257}
2022-12-31 13:49:41,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:41,381 INFO:     Epoch: 23
2022-12-31 13:49:42,997 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40846917827924095, 'Total loss': 0.40846917827924095} | train loss {'Reaction outcome loss': 0.3687522351365227, 'Total loss': 0.3687522351365227}
2022-12-31 13:49:42,998 INFO:     Found new best model at epoch 23
2022-12-31 13:49:42,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:42,999 INFO:     Epoch: 24
2022-12-31 13:49:44,613 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4241644680500031, 'Total loss': 0.4241644680500031} | train loss {'Reaction outcome loss': 0.3641417053417178, 'Total loss': 0.3641417053417178}
2022-12-31 13:49:44,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:44,613 INFO:     Epoch: 25
2022-12-31 13:49:46,222 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.416208216547966, 'Total loss': 0.416208216547966} | train loss {'Reaction outcome loss': 0.36357129896429474, 'Total loss': 0.36357129896429474}
2022-12-31 13:49:46,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:46,223 INFO:     Epoch: 26
2022-12-31 13:49:47,818 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47206727067629495, 'Total loss': 0.47206727067629495} | train loss {'Reaction outcome loss': 0.3505064841991943, 'Total loss': 0.3505064841991943}
2022-12-31 13:49:47,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:47,818 INFO:     Epoch: 27
2022-12-31 13:49:49,437 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4098104750116666, 'Total loss': 0.4098104750116666} | train loss {'Reaction outcome loss': 0.3539011570009729, 'Total loss': 0.3539011570009729}
2022-12-31 13:49:49,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:49,437 INFO:     Epoch: 28
2022-12-31 13:49:51,056 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41789790987968445, 'Total loss': 0.41789790987968445} | train loss {'Reaction outcome loss': 0.34878353029489517, 'Total loss': 0.34878353029489517}
2022-12-31 13:49:51,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:51,056 INFO:     Epoch: 29
2022-12-31 13:49:52,681 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4396075397729874, 'Total loss': 0.4396075397729874} | train loss {'Reaction outcome loss': 0.3464226247171202, 'Total loss': 0.3464226247171202}
2022-12-31 13:49:52,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:52,681 INFO:     Epoch: 30
2022-12-31 13:49:54,336 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42517287929852804, 'Total loss': 0.42517287929852804} | train loss {'Reaction outcome loss': 0.339257962194806, 'Total loss': 0.339257962194806}
2022-12-31 13:49:54,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:54,336 INFO:     Epoch: 31
2022-12-31 13:49:55,968 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37102140684922535, 'Total loss': 0.37102140684922535} | train loss {'Reaction outcome loss': 0.334492811496077, 'Total loss': 0.334492811496077}
2022-12-31 13:49:55,968 INFO:     Found new best model at epoch 31
2022-12-31 13:49:55,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:55,969 INFO:     Epoch: 32
2022-12-31 13:49:57,567 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3960696369409561, 'Total loss': 0.3960696369409561} | train loss {'Reaction outcome loss': 0.32956017107309415, 'Total loss': 0.32956017107309415}
2022-12-31 13:49:57,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:57,567 INFO:     Epoch: 33
2022-12-31 13:49:59,186 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.393302063147227, 'Total loss': 0.393302063147227} | train loss {'Reaction outcome loss': 0.32951427594042426, 'Total loss': 0.32951427594042426}
2022-12-31 13:49:59,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:49:59,187 INFO:     Epoch: 34
2022-12-31 13:50:00,801 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39553844233353935, 'Total loss': 0.39553844233353935} | train loss {'Reaction outcome loss': 0.31432530337722725, 'Total loss': 0.31432530337722725}
2022-12-31 13:50:00,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:00,801 INFO:     Epoch: 35
2022-12-31 13:50:02,448 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4019020557403564, 'Total loss': 0.4019020557403564} | train loss {'Reaction outcome loss': 0.31394532037771133, 'Total loss': 0.31394532037771133}
2022-12-31 13:50:02,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:02,448 INFO:     Epoch: 36
2022-12-31 13:50:04,075 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4017702221870422, 'Total loss': 0.4017702221870422} | train loss {'Reaction outcome loss': 0.3155721913122098, 'Total loss': 0.3155721913122098}
2022-12-31 13:50:04,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:04,075 INFO:     Epoch: 37
2022-12-31 13:50:05,660 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37286596894264223, 'Total loss': 0.37286596894264223} | train loss {'Reaction outcome loss': 0.3167310718460419, 'Total loss': 0.3167310718460419}
2022-12-31 13:50:05,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:05,660 INFO:     Epoch: 38
2022-12-31 13:50:07,280 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37798264424006145, 'Total loss': 0.37798264424006145} | train loss {'Reaction outcome loss': 0.3058250264570601, 'Total loss': 0.3058250264570601}
2022-12-31 13:50:07,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:07,280 INFO:     Epoch: 39
2022-12-31 13:50:08,900 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39363156457742055, 'Total loss': 0.39363156457742055} | train loss {'Reaction outcome loss': 0.2999618364908205, 'Total loss': 0.2999618364908205}
2022-12-31 13:50:08,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:08,900 INFO:     Epoch: 40
2022-12-31 13:50:10,519 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45316927433013915, 'Total loss': 0.45316927433013915} | train loss {'Reaction outcome loss': 0.29444271145852463, 'Total loss': 0.29444271145852463}
2022-12-31 13:50:10,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:10,520 INFO:     Epoch: 41
2022-12-31 13:50:12,139 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.410320375363032, 'Total loss': 0.410320375363032} | train loss {'Reaction outcome loss': 0.2919956758241791, 'Total loss': 0.2919956758241791}
2022-12-31 13:50:12,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:12,139 INFO:     Epoch: 42
2022-12-31 13:50:13,740 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3761696020762126, 'Total loss': 0.3761696020762126} | train loss {'Reaction outcome loss': 0.28617135478378636, 'Total loss': 0.28617135478378636}
2022-12-31 13:50:13,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:13,740 INFO:     Epoch: 43
2022-12-31 13:50:15,353 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40469999114672345, 'Total loss': 0.40469999114672345} | train loss {'Reaction outcome loss': 0.28676950845477384, 'Total loss': 0.28676950845477384}
2022-12-31 13:50:15,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:15,353 INFO:     Epoch: 44
2022-12-31 13:50:17,023 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3992924233277639, 'Total loss': 0.3992924233277639} | train loss {'Reaction outcome loss': 0.28119597597457874, 'Total loss': 0.28119597597457874}
2022-12-31 13:50:17,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:17,024 INFO:     Epoch: 45
2022-12-31 13:50:18,644 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4132360170284907, 'Total loss': 0.4132360170284907} | train loss {'Reaction outcome loss': 0.2916754457010259, 'Total loss': 0.2916754457010259}
2022-12-31 13:50:18,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:18,644 INFO:     Epoch: 46
2022-12-31 13:50:20,268 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39387909273306526, 'Total loss': 0.39387909273306526} | train loss {'Reaction outcome loss': 0.2829436794568916, 'Total loss': 0.2829436794568916}
2022-12-31 13:50:20,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:20,269 INFO:     Epoch: 47
2022-12-31 13:50:21,896 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39914186000823976, 'Total loss': 0.39914186000823976} | train loss {'Reaction outcome loss': 0.27474865734926845, 'Total loss': 0.27474865734926845}
2022-12-31 13:50:21,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:21,897 INFO:     Epoch: 48
2022-12-31 13:50:23,485 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41861986815929414, 'Total loss': 0.41861986815929414} | train loss {'Reaction outcome loss': 0.27936717988217136, 'Total loss': 0.27936717988217136}
2022-12-31 13:50:23,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:23,485 INFO:     Epoch: 49
2022-12-31 13:50:25,111 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3604619577527046, 'Total loss': 0.3604619577527046} | train loss {'Reaction outcome loss': 0.26860957045363604, 'Total loss': 0.26860957045363604}
2022-12-31 13:50:25,111 INFO:     Found new best model at epoch 49
2022-12-31 13:50:25,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:25,112 INFO:     Epoch: 50
2022-12-31 13:50:26,737 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35529758284489316, 'Total loss': 0.35529758284489316} | train loss {'Reaction outcome loss': 0.26661590975625205, 'Total loss': 0.26661590975625205}
2022-12-31 13:50:26,737 INFO:     Found new best model at epoch 50
2022-12-31 13:50:26,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:26,738 INFO:     Epoch: 51
2022-12-31 13:50:28,366 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4153013606866201, 'Total loss': 0.4153013606866201} | train loss {'Reaction outcome loss': 0.26685819013669604, 'Total loss': 0.26685819013669604}
2022-12-31 13:50:28,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:28,367 INFO:     Epoch: 52
2022-12-31 13:50:29,990 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37971430122852323, 'Total loss': 0.37971430122852323} | train loss {'Reaction outcome loss': 0.26346167225377226, 'Total loss': 0.26346167225377226}
2022-12-31 13:50:29,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:29,991 INFO:     Epoch: 53
2022-12-31 13:50:31,615 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4359761913617452, 'Total loss': 0.4359761913617452} | train loss {'Reaction outcome loss': 0.2563679689400248, 'Total loss': 0.2563679689400248}
2022-12-31 13:50:31,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:31,615 INFO:     Epoch: 54
2022-12-31 13:50:33,200 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39509253601233163, 'Total loss': 0.39509253601233163} | train loss {'Reaction outcome loss': 0.2637302614076043, 'Total loss': 0.2637302614076043}
2022-12-31 13:50:33,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:33,200 INFO:     Epoch: 55
2022-12-31 13:50:34,823 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3924346556266149, 'Total loss': 0.3924346556266149} | train loss {'Reaction outcome loss': 0.25586448792731287, 'Total loss': 0.25586448792731287}
2022-12-31 13:50:34,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:34,823 INFO:     Epoch: 56
2022-12-31 13:50:36,446 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.396624818444252, 'Total loss': 0.396624818444252} | train loss {'Reaction outcome loss': 0.2545902368609225, 'Total loss': 0.2545902368609225}
2022-12-31 13:50:36,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:36,446 INFO:     Epoch: 57
2022-12-31 13:50:38,087 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40935198167959846, 'Total loss': 0.40935198167959846} | train loss {'Reaction outcome loss': 0.25424661558619044, 'Total loss': 0.25424661558619044}
2022-12-31 13:50:38,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:38,087 INFO:     Epoch: 58
2022-12-31 13:50:39,717 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3991448293129603, 'Total loss': 0.3991448293129603} | train loss {'Reaction outcome loss': 0.2535906890239096, 'Total loss': 0.2535906890239096}
2022-12-31 13:50:39,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:39,718 INFO:     Epoch: 59
2022-12-31 13:50:41,335 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4108801528811455, 'Total loss': 0.4108801528811455} | train loss {'Reaction outcome loss': 0.24970577662602228, 'Total loss': 0.24970577662602228}
2022-12-31 13:50:41,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:41,337 INFO:     Epoch: 60
2022-12-31 13:50:42,972 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36400564114252726, 'Total loss': 0.36400564114252726} | train loss {'Reaction outcome loss': 0.24697456621843986, 'Total loss': 0.24697456621843986}
2022-12-31 13:50:42,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:42,972 INFO:     Epoch: 61
2022-12-31 13:50:44,604 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39213904241720837, 'Total loss': 0.39213904241720837} | train loss {'Reaction outcome loss': 0.24276411783669669, 'Total loss': 0.24276411783669669}
2022-12-31 13:50:44,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:44,604 INFO:     Epoch: 62
2022-12-31 13:50:46,223 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3767317553361257, 'Total loss': 0.3767317553361257} | train loss {'Reaction outcome loss': 0.2448358821820481, 'Total loss': 0.2448358821820481}
2022-12-31 13:50:46,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:46,223 INFO:     Epoch: 63
2022-12-31 13:50:47,847 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36945957243442534, 'Total loss': 0.36945957243442534} | train loss {'Reaction outcome loss': 0.2398469638523212, 'Total loss': 0.2398469638523212}
2022-12-31 13:50:47,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:47,848 INFO:     Epoch: 64
2022-12-31 13:50:49,499 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3883908400932948, 'Total loss': 0.3883908400932948} | train loss {'Reaction outcome loss': 0.23832193306825436, 'Total loss': 0.23832193306825436}
2022-12-31 13:50:49,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:49,499 INFO:     Epoch: 65
2022-12-31 13:50:51,096 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40970405737559, 'Total loss': 0.40970405737559} | train loss {'Reaction outcome loss': 0.23695550487790298, 'Total loss': 0.23695550487790298}
2022-12-31 13:50:51,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:51,096 INFO:     Epoch: 66
2022-12-31 13:50:52,761 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3699593139191469, 'Total loss': 0.3699593139191469} | train loss {'Reaction outcome loss': 0.23418969196344755, 'Total loss': 0.23418969196344755}
2022-12-31 13:50:52,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:52,762 INFO:     Epoch: 67
2022-12-31 13:50:54,434 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38437751730283104, 'Total loss': 0.38437751730283104} | train loss {'Reaction outcome loss': 0.2388131171195946, 'Total loss': 0.2388131171195946}
2022-12-31 13:50:54,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:54,434 INFO:     Epoch: 68
2022-12-31 13:50:56,086 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38985930681228637, 'Total loss': 0.38985930681228637} | train loss {'Reaction outcome loss': 0.23691623418554933, 'Total loss': 0.23691623418554933}
2022-12-31 13:50:56,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:56,086 INFO:     Epoch: 69
2022-12-31 13:50:57,742 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38048954705397287, 'Total loss': 0.38048954705397287} | train loss {'Reaction outcome loss': 0.23275511768320406, 'Total loss': 0.23275511768320406}
2022-12-31 13:50:57,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:57,742 INFO:     Epoch: 70
2022-12-31 13:50:59,366 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40115717351436614, 'Total loss': 0.40115717351436614} | train loss {'Reaction outcome loss': 0.2435857720323418, 'Total loss': 0.2435857720323418}
2022-12-31 13:50:59,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:50:59,366 INFO:     Epoch: 71
2022-12-31 13:51:00,970 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37328723867734276, 'Total loss': 0.37328723867734276} | train loss {'Reaction outcome loss': 0.22936215526710133, 'Total loss': 0.22936215526710133}
2022-12-31 13:51:00,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:00,971 INFO:     Epoch: 72
2022-12-31 13:51:02,595 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4015633439024289, 'Total loss': 0.4015633439024289} | train loss {'Reaction outcome loss': 0.23048848777148698, 'Total loss': 0.23048848777148698}
2022-12-31 13:51:02,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:02,595 INFO:     Epoch: 73
2022-12-31 13:51:04,220 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40007962435483935, 'Total loss': 0.40007962435483935} | train loss {'Reaction outcome loss': 0.22840173962771462, 'Total loss': 0.22840173962771462}
2022-12-31 13:51:04,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:04,220 INFO:     Epoch: 74
2022-12-31 13:51:05,843 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3657060523827871, 'Total loss': 0.3657060523827871} | train loss {'Reaction outcome loss': 0.2229440039501186, 'Total loss': 0.2229440039501186}
2022-12-31 13:51:05,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:05,844 INFO:     Epoch: 75
2022-12-31 13:51:07,467 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3833283950885137, 'Total loss': 0.3833283950885137} | train loss {'Reaction outcome loss': 0.22087106964675313, 'Total loss': 0.22087106964675313}
2022-12-31 13:51:07,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:07,467 INFO:     Epoch: 76
2022-12-31 13:51:09,055 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.382329864303271, 'Total loss': 0.382329864303271} | train loss {'Reaction outcome loss': 0.21921579781852474, 'Total loss': 0.21921579781852474}
2022-12-31 13:51:09,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:09,056 INFO:     Epoch: 77
2022-12-31 13:51:10,723 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4082039551188548, 'Total loss': 0.4082039551188548} | train loss {'Reaction outcome loss': 0.22127743196482047, 'Total loss': 0.22127743196482047}
2022-12-31 13:51:10,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:10,723 INFO:     Epoch: 78
2022-12-31 13:51:12,392 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40041110614935554, 'Total loss': 0.40041110614935554} | train loss {'Reaction outcome loss': 0.22055461307456348, 'Total loss': 0.22055461307456348}
2022-12-31 13:51:12,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:12,394 INFO:     Epoch: 79
2022-12-31 13:51:14,017 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44131092031796776, 'Total loss': 0.44131092031796776} | train loss {'Reaction outcome loss': 0.21866052680470668, 'Total loss': 0.21866052680470668}
2022-12-31 13:51:14,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:14,017 INFO:     Epoch: 80
2022-12-31 13:51:15,642 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3875190218289693, 'Total loss': 0.3875190218289693} | train loss {'Reaction outcome loss': 0.22364677632704968, 'Total loss': 0.22364677632704968}
2022-12-31 13:51:15,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:15,642 INFO:     Epoch: 81
2022-12-31 13:51:17,255 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39505972067515055, 'Total loss': 0.39505972067515055} | train loss {'Reaction outcome loss': 0.21745506481062418, 'Total loss': 0.21745506481062418}
2022-12-31 13:51:17,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:17,255 INFO:     Epoch: 82
2022-12-31 13:51:18,837 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.390379365781943, 'Total loss': 0.390379365781943} | train loss {'Reaction outcome loss': 0.21816325747149085, 'Total loss': 0.21816325747149085}
2022-12-31 13:51:18,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:18,838 INFO:     Epoch: 83
2022-12-31 13:51:20,466 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.386559850970904, 'Total loss': 0.386559850970904} | train loss {'Reaction outcome loss': 0.2196679199215307, 'Total loss': 0.2196679199215307}
2022-12-31 13:51:20,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:20,467 INFO:     Epoch: 84
2022-12-31 13:51:22,111 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43505825599034625, 'Total loss': 0.43505825599034625} | train loss {'Reaction outcome loss': 0.2171180899782839, 'Total loss': 0.2171180899782839}
2022-12-31 13:51:22,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:22,111 INFO:     Epoch: 85
2022-12-31 13:51:23,726 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41796880612770715, 'Total loss': 0.41796880612770715} | train loss {'Reaction outcome loss': 0.2189338263729419, 'Total loss': 0.2189338263729419}
2022-12-31 13:51:23,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:23,726 INFO:     Epoch: 86
2022-12-31 13:51:25,378 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4134578496217728, 'Total loss': 0.4134578496217728} | train loss {'Reaction outcome loss': 0.21436588410019122, 'Total loss': 0.21436588410019122}
2022-12-31 13:51:25,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:25,378 INFO:     Epoch: 87
2022-12-31 13:51:26,969 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3664700662096341, 'Total loss': 0.3664700662096341} | train loss {'Reaction outcome loss': 0.21329721663859993, 'Total loss': 0.21329721663859993}
2022-12-31 13:51:26,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:26,970 INFO:     Epoch: 88
2022-12-31 13:51:28,629 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4042977879444758, 'Total loss': 0.4042977879444758} | train loss {'Reaction outcome loss': 0.2110802407850535, 'Total loss': 0.2110802407850535}
2022-12-31 13:51:28,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:28,629 INFO:     Epoch: 89
2022-12-31 13:51:30,296 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3897180845340093, 'Total loss': 0.3897180845340093} | train loss {'Reaction outcome loss': 0.21348527978957776, 'Total loss': 0.21348527978957776}
2022-12-31 13:51:30,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:30,296 INFO:     Epoch: 90
2022-12-31 13:51:31,963 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37585043037931126, 'Total loss': 0.37585043037931126} | train loss {'Reaction outcome loss': 0.21105218932220868, 'Total loss': 0.21105218932220868}
2022-12-31 13:51:31,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:31,964 INFO:     Epoch: 91
2022-12-31 13:51:33,626 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3832863171895345, 'Total loss': 0.3832863171895345} | train loss {'Reaction outcome loss': 0.21372158423953755, 'Total loss': 0.21372158423953755}
2022-12-31 13:51:33,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:33,626 INFO:     Epoch: 92
2022-12-31 13:51:35,298 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3676447242498398, 'Total loss': 0.3676447242498398} | train loss {'Reaction outcome loss': 0.21239968618236832, 'Total loss': 0.21239968618236832}
2022-12-31 13:51:35,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:35,299 INFO:     Epoch: 93
2022-12-31 13:51:36,901 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.360318037122488, 'Total loss': 0.360318037122488} | train loss {'Reaction outcome loss': 0.20708709920080723, 'Total loss': 0.20708709920080723}
2022-12-31 13:51:36,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:36,901 INFO:     Epoch: 94
2022-12-31 13:51:38,518 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3919996003309886, 'Total loss': 0.3919996003309886} | train loss {'Reaction outcome loss': 0.2115499170476887, 'Total loss': 0.2115499170476887}
2022-12-31 13:51:38,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:38,518 INFO:     Epoch: 95
2022-12-31 13:51:40,134 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40787398219108584, 'Total loss': 0.40787398219108584} | train loss {'Reaction outcome loss': 0.20540496545914386, 'Total loss': 0.20540496545914386}
2022-12-31 13:51:40,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:40,135 INFO:     Epoch: 96
2022-12-31 13:51:41,752 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38098763922850293, 'Total loss': 0.38098763922850293} | train loss {'Reaction outcome loss': 0.20800481303611817, 'Total loss': 0.20800481303611817}
2022-12-31 13:51:41,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:41,753 INFO:     Epoch: 97
2022-12-31 13:51:43,369 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38843641380469, 'Total loss': 0.38843641380469} | train loss {'Reaction outcome loss': 0.21232503141521977, 'Total loss': 0.21232503141521977}
2022-12-31 13:51:43,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:43,369 INFO:     Epoch: 98
2022-12-31 13:51:44,965 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4004091660181681, 'Total loss': 0.4004091660181681} | train loss {'Reaction outcome loss': 0.2077181590620146, 'Total loss': 0.2077181590620146}
2022-12-31 13:51:44,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:44,965 INFO:     Epoch: 99
2022-12-31 13:51:46,579 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3758903647462527, 'Total loss': 0.3758903647462527} | train loss {'Reaction outcome loss': 0.20335449841855235, 'Total loss': 0.20335449841855235}
2022-12-31 13:51:46,579 INFO:     Best model found after epoch 51 of 100.
2022-12-31 13:51:46,579 INFO:   Done with stage: TRAINING
2022-12-31 13:51:46,580 INFO:   Starting stage: EVALUATION
2022-12-31 13:51:46,702 INFO:   Done with stage: EVALUATION
2022-12-31 13:51:46,703 INFO:   Leaving out SEQ value Fold_7
2022-12-31 13:51:46,715 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:51:46,715 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:51:47,361 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:51:47,362 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:51:47,430 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:51:47,430 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:51:47,430 INFO:     No hyperparam tuning for this model
2022-12-31 13:51:47,430 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:51:47,430 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:51:47,431 INFO:     None feature selector for col prot
2022-12-31 13:51:47,431 INFO:     None feature selector for col prot
2022-12-31 13:51:47,431 INFO:     None feature selector for col prot
2022-12-31 13:51:47,431 INFO:     None feature selector for col chem
2022-12-31 13:51:47,432 INFO:     None feature selector for col chem
2022-12-31 13:51:47,432 INFO:     None feature selector for col chem
2022-12-31 13:51:47,432 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:51:47,432 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:51:47,433 INFO:     Number of params in model 223921
2022-12-31 13:51:47,437 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:51:47,437 INFO:   Starting stage: TRAINING
2022-12-31 13:51:47,481 INFO:     Val loss before train {'Reaction outcome loss': 1.125662589073181, 'Total loss': 1.125662589073181}
2022-12-31 13:51:47,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:47,481 INFO:     Epoch: 0
2022-12-31 13:51:49,094 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7809838970502218, 'Total loss': 0.7809838970502218} | train loss {'Reaction outcome loss': 0.8109746251822166, 'Total loss': 0.8109746251822166}
2022-12-31 13:51:49,094 INFO:     Found new best model at epoch 0
2022-12-31 13:51:49,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:49,095 INFO:     Epoch: 1
2022-12-31 13:51:50,703 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6269298752148946, 'Total loss': 0.6269298752148946} | train loss {'Reaction outcome loss': 0.5946353354501417, 'Total loss': 0.5946353354501417}
2022-12-31 13:51:50,704 INFO:     Found new best model at epoch 1
2022-12-31 13:51:50,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:50,705 INFO:     Epoch: 2
2022-12-31 13:51:52,321 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6163426816463471, 'Total loss': 0.6163426816463471} | train loss {'Reaction outcome loss': 0.5342368232491224, 'Total loss': 0.5342368232491224}
2022-12-31 13:51:52,321 INFO:     Found new best model at epoch 2
2022-12-31 13:51:52,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:52,322 INFO:     Epoch: 3
2022-12-31 13:51:53,901 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5935456057389578, 'Total loss': 0.5935456057389578} | train loss {'Reaction outcome loss': 0.5155722774106307, 'Total loss': 0.5155722774106307}
2022-12-31 13:51:53,901 INFO:     Found new best model at epoch 3
2022-12-31 13:51:53,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:53,902 INFO:     Epoch: 4
2022-12-31 13:51:55,499 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5696175992488861, 'Total loss': 0.5696175992488861} | train loss {'Reaction outcome loss': 0.4854288102630391, 'Total loss': 0.4854288102630391}
2022-12-31 13:51:55,499 INFO:     Found new best model at epoch 4
2022-12-31 13:51:55,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:55,500 INFO:     Epoch: 5
2022-12-31 13:51:57,131 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5434221317370732, 'Total loss': 0.5434221317370732} | train loss {'Reaction outcome loss': 0.4786189599050714, 'Total loss': 0.4786189599050714}
2022-12-31 13:51:57,131 INFO:     Found new best model at epoch 5
2022-12-31 13:51:57,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:57,132 INFO:     Epoch: 6
2022-12-31 13:51:58,757 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5263197441895803, 'Total loss': 0.5263197441895803} | train loss {'Reaction outcome loss': 0.4659809345928648, 'Total loss': 0.4659809345928648}
2022-12-31 13:51:58,757 INFO:     Found new best model at epoch 6
2022-12-31 13:51:58,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:51:58,758 INFO:     Epoch: 7
2022-12-31 13:52:00,367 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5515545944372813, 'Total loss': 0.5515545944372813} | train loss {'Reaction outcome loss': 0.4618006053353673, 'Total loss': 0.4618006053353673}
2022-12-31 13:52:00,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:00,368 INFO:     Epoch: 8
2022-12-31 13:52:01,978 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5209676603476207, 'Total loss': 0.5209676603476207} | train loss {'Reaction outcome loss': 0.45628149434924126, 'Total loss': 0.45628149434924126}
2022-12-31 13:52:01,978 INFO:     Found new best model at epoch 8
2022-12-31 13:52:01,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:01,979 INFO:     Epoch: 9
2022-12-31 13:52:03,555 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5611166596412659, 'Total loss': 0.5611166596412659} | train loss {'Reaction outcome loss': 0.46237788980816613, 'Total loss': 0.46237788980816613}
2022-12-31 13:52:03,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:03,555 INFO:     Epoch: 10
2022-12-31 13:52:05,165 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5579633335272471, 'Total loss': 0.5579633335272471} | train loss {'Reaction outcome loss': 0.44583490760861966, 'Total loss': 0.44583490760861966}
2022-12-31 13:52:05,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:05,165 INFO:     Epoch: 11
2022-12-31 13:52:06,773 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5145298729340235, 'Total loss': 0.5145298729340235} | train loss {'Reaction outcome loss': 0.4672590051980122, 'Total loss': 0.4672590051980122}
2022-12-31 13:52:06,774 INFO:     Found new best model at epoch 11
2022-12-31 13:52:06,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:06,775 INFO:     Epoch: 12
2022-12-31 13:52:08,384 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5019903540611267, 'Total loss': 0.5019903540611267} | train loss {'Reaction outcome loss': 0.43077044064197817, 'Total loss': 0.43077044064197817}
2022-12-31 13:52:08,384 INFO:     Found new best model at epoch 12
2022-12-31 13:52:08,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:08,385 INFO:     Epoch: 13
2022-12-31 13:52:09,998 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5446401079495747, 'Total loss': 0.5446401079495747} | train loss {'Reaction outcome loss': 0.4234306587052255, 'Total loss': 0.4234306587052255}
2022-12-31 13:52:09,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:09,998 INFO:     Epoch: 14
2022-12-31 13:52:11,534 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5186838686466217, 'Total loss': 0.5186838686466217} | train loss {'Reaction outcome loss': 0.42030821652556566, 'Total loss': 0.42030821652556566}
2022-12-31 13:52:11,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:11,534 INFO:     Epoch: 15
2022-12-31 13:52:12,621 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5038248419761657, 'Total loss': 0.5038248419761657} | train loss {'Reaction outcome loss': 0.4148256358947011, 'Total loss': 0.4148256358947011}
2022-12-31 13:52:12,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:12,621 INFO:     Epoch: 16
2022-12-31 13:52:13,696 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4854505519072215, 'Total loss': 0.4854505519072215} | train loss {'Reaction outcome loss': 0.43488542450780887, 'Total loss': 0.43488542450780887}
2022-12-31 13:52:13,696 INFO:     Found new best model at epoch 16
2022-12-31 13:52:13,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:13,697 INFO:     Epoch: 17
2022-12-31 13:52:14,769 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5403319617112478, 'Total loss': 0.5403319617112478} | train loss {'Reaction outcome loss': 0.40872242458813096, 'Total loss': 0.40872242458813096}
2022-12-31 13:52:14,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:14,769 INFO:     Epoch: 18
2022-12-31 13:52:15,839 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48515032132466634, 'Total loss': 0.48515032132466634} | train loss {'Reaction outcome loss': 0.4032257231951192, 'Total loss': 0.4032257231951192}
2022-12-31 13:52:15,839 INFO:     Found new best model at epoch 18
2022-12-31 13:52:15,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:15,840 INFO:     Epoch: 19
2022-12-31 13:52:17,399 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48200864990552267, 'Total loss': 0.48200864990552267} | train loss {'Reaction outcome loss': 0.40070656592064735, 'Total loss': 0.40070656592064735}
2022-12-31 13:52:17,399 INFO:     Found new best model at epoch 19
2022-12-31 13:52:17,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:17,400 INFO:     Epoch: 20
2022-12-31 13:52:19,002 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48152921795845033, 'Total loss': 0.48152921795845033} | train loss {'Reaction outcome loss': 0.39106792858734296, 'Total loss': 0.39106792858734296}
2022-12-31 13:52:19,002 INFO:     Found new best model at epoch 20
2022-12-31 13:52:19,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:19,003 INFO:     Epoch: 21
2022-12-31 13:52:20,610 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4744268258412679, 'Total loss': 0.4744268258412679} | train loss {'Reaction outcome loss': 0.3875232883324118, 'Total loss': 0.3875232883324118}
2022-12-31 13:52:20,610 INFO:     Found new best model at epoch 21
2022-12-31 13:52:20,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:20,611 INFO:     Epoch: 22
2022-12-31 13:52:22,216 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45737792948881784, 'Total loss': 0.45737792948881784} | train loss {'Reaction outcome loss': 0.3822487079524908, 'Total loss': 0.3822487079524908}
2022-12-31 13:52:22,216 INFO:     Found new best model at epoch 22
2022-12-31 13:52:22,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:22,217 INFO:     Epoch: 23
2022-12-31 13:52:23,824 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4626464913288752, 'Total loss': 0.4626464913288752} | train loss {'Reaction outcome loss': 0.3873460846725325, 'Total loss': 0.3873460846725325}
2022-12-31 13:52:23,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:23,826 INFO:     Epoch: 24
2022-12-31 13:52:25,419 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45821040670077007, 'Total loss': 0.45821040670077007} | train loss {'Reaction outcome loss': 0.37367046545799554, 'Total loss': 0.37367046545799554}
2022-12-31 13:52:25,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:25,419 INFO:     Epoch: 25
2022-12-31 13:52:27,030 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48543648918469745, 'Total loss': 0.48543648918469745} | train loss {'Reaction outcome loss': 0.36536066028249636, 'Total loss': 0.36536066028249636}
2022-12-31 13:52:27,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:27,031 INFO:     Epoch: 26
2022-12-31 13:52:28,626 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46802071829636893, 'Total loss': 0.46802071829636893} | train loss {'Reaction outcome loss': 0.36983596332746843, 'Total loss': 0.36983596332746843}
2022-12-31 13:52:28,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:28,626 INFO:     Epoch: 27
2022-12-31 13:52:30,236 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4560164709885915, 'Total loss': 0.4560164709885915} | train loss {'Reaction outcome loss': 0.3600163513177034, 'Total loss': 0.3600163513177034}
2022-12-31 13:52:30,237 INFO:     Found new best model at epoch 27
2022-12-31 13:52:30,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:30,238 INFO:     Epoch: 28
2022-12-31 13:52:31,856 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4430190702279409, 'Total loss': 0.4430190702279409} | train loss {'Reaction outcome loss': 0.3570833006473865, 'Total loss': 0.3570833006473865}
2022-12-31 13:52:31,857 INFO:     Found new best model at epoch 28
2022-12-31 13:52:31,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:31,858 INFO:     Epoch: 29
2022-12-31 13:52:33,469 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5039460172255834, 'Total loss': 0.5039460172255834} | train loss {'Reaction outcome loss': 0.3546833235608495, 'Total loss': 0.3546833235608495}
2022-12-31 13:52:33,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:33,469 INFO:     Epoch: 30
2022-12-31 13:52:35,061 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4584263543287913, 'Total loss': 0.4584263543287913} | train loss {'Reaction outcome loss': 0.37408817884093826, 'Total loss': 0.37408817884093826}
2022-12-31 13:52:35,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:35,061 INFO:     Epoch: 31
2022-12-31 13:52:36,657 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4398780345916748, 'Total loss': 0.4398780345916748} | train loss {'Reaction outcome loss': 0.39017519634132664, 'Total loss': 0.39017519634132664}
2022-12-31 13:52:36,657 INFO:     Found new best model at epoch 31
2022-12-31 13:52:36,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:36,658 INFO:     Epoch: 32
2022-12-31 13:52:38,273 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46115370889504753, 'Total loss': 0.46115370889504753} | train loss {'Reaction outcome loss': 0.3471244248321982, 'Total loss': 0.3471244248321982}
2022-12-31 13:52:38,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:38,273 INFO:     Epoch: 33
2022-12-31 13:52:39,883 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43661407828330995, 'Total loss': 0.43661407828330995} | train loss {'Reaction outcome loss': 0.34282588139615033, 'Total loss': 0.34282588139615033}
2022-12-31 13:52:39,883 INFO:     Found new best model at epoch 33
2022-12-31 13:52:39,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:39,884 INFO:     Epoch: 34
2022-12-31 13:52:41,491 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4624365250269572, 'Total loss': 0.4624365250269572} | train loss {'Reaction outcome loss': 0.3390151322616831, 'Total loss': 0.3390151322616831}
2022-12-31 13:52:41,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:41,491 INFO:     Epoch: 35
2022-12-31 13:52:43,088 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4268352746963501, 'Total loss': 0.4268352746963501} | train loss {'Reaction outcome loss': 0.33824982011667115, 'Total loss': 0.33824982011667115}
2022-12-31 13:52:43,089 INFO:     Found new best model at epoch 35
2022-12-31 13:52:43,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:43,090 INFO:     Epoch: 36
2022-12-31 13:52:44,721 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44215939442316693, 'Total loss': 0.44215939442316693} | train loss {'Reaction outcome loss': 0.3283479901448131, 'Total loss': 0.3283479901448131}
2022-12-31 13:52:44,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:44,721 INFO:     Epoch: 37
2022-12-31 13:52:46,342 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45189571181933086, 'Total loss': 0.45189571181933086} | train loss {'Reaction outcome loss': 0.3267744186779727, 'Total loss': 0.3267744186779727}
2022-12-31 13:52:46,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:46,342 INFO:     Epoch: 38
2022-12-31 13:52:47,963 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46229662497838336, 'Total loss': 0.46229662497838336} | train loss {'Reaction outcome loss': 0.3411673972842054, 'Total loss': 0.3411673972842054}
2022-12-31 13:52:47,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:47,963 INFO:     Epoch: 39
2022-12-31 13:52:49,577 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48789440393447875, 'Total loss': 0.48789440393447875} | train loss {'Reaction outcome loss': 0.32743576843252714, 'Total loss': 0.32743576843252714}
2022-12-31 13:52:49,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:49,578 INFO:     Epoch: 40
2022-12-31 13:52:51,192 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43984190026919046, 'Total loss': 0.43984190026919046} | train loss {'Reaction outcome loss': 0.31701652930064156, 'Total loss': 0.31701652930064156}
2022-12-31 13:52:51,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:51,192 INFO:     Epoch: 41
2022-12-31 13:52:52,790 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4175406734148661, 'Total loss': 0.4175406734148661} | train loss {'Reaction outcome loss': 0.3162570732225583, 'Total loss': 0.3162570732225583}
2022-12-31 13:52:52,790 INFO:     Found new best model at epoch 41
2022-12-31 13:52:52,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:52,791 INFO:     Epoch: 42
2022-12-31 13:52:54,401 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4519964396953583, 'Total loss': 0.4519964396953583} | train loss {'Reaction outcome loss': 0.3084391889101623, 'Total loss': 0.3084391889101623}
2022-12-31 13:52:54,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:54,403 INFO:     Epoch: 43
2022-12-31 13:52:55,999 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4489085634549459, 'Total loss': 0.4489085634549459} | train loss {'Reaction outcome loss': 0.32207075657619944, 'Total loss': 0.32207075657619944}
2022-12-31 13:52:55,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:55,999 INFO:     Epoch: 44
2022-12-31 13:52:57,613 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3921243985493978, 'Total loss': 0.3921243985493978} | train loss {'Reaction outcome loss': 0.37956701523533254, 'Total loss': 0.37956701523533254}
2022-12-31 13:52:57,614 INFO:     Found new best model at epoch 44
2022-12-31 13:52:57,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:57,615 INFO:     Epoch: 45
2022-12-31 13:52:59,226 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44034166634082794, 'Total loss': 0.44034166634082794} | train loss {'Reaction outcome loss': 0.3225854133606713, 'Total loss': 0.3225854133606713}
2022-12-31 13:52:59,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:52:59,226 INFO:     Epoch: 46
2022-12-31 13:53:00,838 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43826804955800375, 'Total loss': 0.43826804955800375} | train loss {'Reaction outcome loss': 0.34679820894962177, 'Total loss': 0.34679820894962177}
2022-12-31 13:53:00,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:00,839 INFO:     Epoch: 47
2022-12-31 13:53:02,439 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41757149398326876, 'Total loss': 0.41757149398326876} | train loss {'Reaction outcome loss': 0.301868774280276, 'Total loss': 0.301868774280276}
2022-12-31 13:53:02,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:02,439 INFO:     Epoch: 48
2022-12-31 13:53:04,030 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4511427899201711, 'Total loss': 0.4511427899201711} | train loss {'Reaction outcome loss': 0.31198844835465855, 'Total loss': 0.31198844835465855}
2022-12-31 13:53:04,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:04,031 INFO:     Epoch: 49
2022-12-31 13:53:05,654 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42608280579249064, 'Total loss': 0.42608280579249064} | train loss {'Reaction outcome loss': 0.2941623281150132, 'Total loss': 0.2941623281150132}
2022-12-31 13:53:05,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:05,654 INFO:     Epoch: 50
2022-12-31 13:53:07,288 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42208802501360576, 'Total loss': 0.42208802501360576} | train loss {'Reaction outcome loss': 0.29092261928430607, 'Total loss': 0.29092261928430607}
2022-12-31 13:53:07,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:07,288 INFO:     Epoch: 51
2022-12-31 13:53:08,905 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41943269670009614, 'Total loss': 0.41943269670009614} | train loss {'Reaction outcome loss': 0.2905657800839053, 'Total loss': 0.2905657800839053}
2022-12-31 13:53:08,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:08,905 INFO:     Epoch: 52
2022-12-31 13:53:10,496 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4035078153014183, 'Total loss': 0.4035078153014183} | train loss {'Reaction outcome loss': 0.285050137458197, 'Total loss': 0.285050137458197}
2022-12-31 13:53:10,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:10,496 INFO:     Epoch: 53
2022-12-31 13:53:12,103 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4034642457962036, 'Total loss': 0.4034642457962036} | train loss {'Reaction outcome loss': 0.27970499642517255, 'Total loss': 0.27970499642517255}
2022-12-31 13:53:12,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:12,103 INFO:     Epoch: 54
2022-12-31 13:53:13,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4447814166545868, 'Total loss': 0.4447814166545868} | train loss {'Reaction outcome loss': 0.28789588543630723, 'Total loss': 0.28789588543630723}
2022-12-31 13:53:13,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:13,715 INFO:     Epoch: 55
2022-12-31 13:53:15,305 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.447119927406311, 'Total loss': 0.447119927406311} | train loss {'Reaction outcome loss': 0.27653427516191226, 'Total loss': 0.27653427516191226}
2022-12-31 13:53:15,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:15,305 INFO:     Epoch: 56
2022-12-31 13:53:16,944 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.431950768828392, 'Total loss': 0.431950768828392} | train loss {'Reaction outcome loss': 0.2805918689844185, 'Total loss': 0.2805918689844185}
2022-12-31 13:53:16,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:16,944 INFO:     Epoch: 57
2022-12-31 13:53:18,533 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41901500324408214, 'Total loss': 0.41901500324408214} | train loss {'Reaction outcome loss': 0.3130176675225865, 'Total loss': 0.3130176675225865}
2022-12-31 13:53:18,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:18,533 INFO:     Epoch: 58
2022-12-31 13:53:20,135 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4406538744767507, 'Total loss': 0.4406538744767507} | train loss {'Reaction outcome loss': 0.2826447264062312, 'Total loss': 0.2826447264062312}
2022-12-31 13:53:20,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:20,136 INFO:     Epoch: 59
2022-12-31 13:53:21,748 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40830578009287516, 'Total loss': 0.40830578009287516} | train loss {'Reaction outcome loss': 0.27549997605113447, 'Total loss': 0.27549997605113447}
2022-12-31 13:53:21,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:21,748 INFO:     Epoch: 60
2022-12-31 13:53:23,355 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5176818946997325, 'Total loss': 0.5176818946997325} | train loss {'Reaction outcome loss': 0.30843639781401644, 'Total loss': 0.30843639781401644}
2022-12-31 13:53:23,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:23,355 INFO:     Epoch: 61
2022-12-31 13:53:24,991 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4514035125573476, 'Total loss': 0.4514035125573476} | train loss {'Reaction outcome loss': 0.36224997925160424, 'Total loss': 0.36224997925160424}
2022-12-31 13:53:24,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:24,992 INFO:     Epoch: 62
2022-12-31 13:53:26,610 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4370211511850357, 'Total loss': 0.4370211511850357} | train loss {'Reaction outcome loss': 0.30252156492518395, 'Total loss': 0.30252156492518395}
2022-12-31 13:53:26,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:26,610 INFO:     Epoch: 63
2022-12-31 13:53:28,228 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45465898315111797, 'Total loss': 0.45465898315111797} | train loss {'Reaction outcome loss': 0.28413969375517056, 'Total loss': 0.28413969375517056}
2022-12-31 13:53:28,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:28,229 INFO:     Epoch: 64
2022-12-31 13:53:29,836 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42121787667274474, 'Total loss': 0.42121787667274474} | train loss {'Reaction outcome loss': 0.30085349927885807, 'Total loss': 0.30085349927885807}
2022-12-31 13:53:29,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:29,836 INFO:     Epoch: 65
2022-12-31 13:53:31,437 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4699915329615275, 'Total loss': 0.4699915329615275} | train loss {'Reaction outcome loss': 0.28144180263136176, 'Total loss': 0.28144180263136176}
2022-12-31 13:53:31,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:31,438 INFO:     Epoch: 66
2022-12-31 13:53:33,054 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4464163343111674, 'Total loss': 0.4464163343111674} | train loss {'Reaction outcome loss': 0.27639760385415907, 'Total loss': 0.27639760385415907}
2022-12-31 13:53:33,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:33,054 INFO:     Epoch: 67
2022-12-31 13:53:34,672 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41207003593444824, 'Total loss': 0.41207003593444824} | train loss {'Reaction outcome loss': 0.26978627835278923, 'Total loss': 0.26978627835278923}
2022-12-31 13:53:34,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:34,672 INFO:     Epoch: 68
2022-12-31 13:53:36,289 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4321408450603485, 'Total loss': 0.4321408450603485} | train loss {'Reaction outcome loss': 0.273652786348501, 'Total loss': 0.273652786348501}
2022-12-31 13:53:36,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:36,289 INFO:     Epoch: 69
2022-12-31 13:53:37,880 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40985776484012604, 'Total loss': 0.40985776484012604} | train loss {'Reaction outcome loss': 0.26950445350013214, 'Total loss': 0.26950445350013214}
2022-12-31 13:53:37,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:37,880 INFO:     Epoch: 70
2022-12-31 13:53:39,496 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4764014979203542, 'Total loss': 0.4764014979203542} | train loss {'Reaction outcome loss': 0.26611806571726565, 'Total loss': 0.26611806571726565}
2022-12-31 13:53:39,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:39,496 INFO:     Epoch: 71
2022-12-31 13:53:41,100 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3975749055544535, 'Total loss': 0.3975749055544535} | train loss {'Reaction outcome loss': 0.2652209710272407, 'Total loss': 0.2652209710272407}
2022-12-31 13:53:41,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:41,100 INFO:     Epoch: 72
2022-12-31 13:53:42,749 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42045340140660603, 'Total loss': 0.42045340140660603} | train loss {'Reaction outcome loss': 0.26188373747994564, 'Total loss': 0.26188373747994564}
2022-12-31 13:53:42,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:42,749 INFO:     Epoch: 73
2022-12-31 13:53:44,396 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42232547104358675, 'Total loss': 0.42232547104358675} | train loss {'Reaction outcome loss': 0.26863160622778576, 'Total loss': 0.26863160622778576}
2022-12-31 13:53:44,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:44,397 INFO:     Epoch: 74
2022-12-31 13:53:46,042 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4367022921641668, 'Total loss': 0.4367022921641668} | train loss {'Reaction outcome loss': 0.28933978118542314, 'Total loss': 0.28933978118542314}
2022-12-31 13:53:46,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:46,042 INFO:     Epoch: 75
2022-12-31 13:53:47,666 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42449557383855185, 'Total loss': 0.42449557383855185} | train loss {'Reaction outcome loss': 0.25746211467607727, 'Total loss': 0.25746211467607727}
2022-12-31 13:53:47,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:47,667 INFO:     Epoch: 76
2022-12-31 13:53:49,291 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43504674832026163, 'Total loss': 0.43504674832026163} | train loss {'Reaction outcome loss': 0.2508774642576126, 'Total loss': 0.2508774642576126}
2022-12-31 13:53:49,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:49,291 INFO:     Epoch: 77
2022-12-31 13:53:50,943 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4386332035064697, 'Total loss': 0.4386332035064697} | train loss {'Reaction outcome loss': 0.2608128202593197, 'Total loss': 0.2608128202593197}
2022-12-31 13:53:50,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:50,943 INFO:     Epoch: 78
2022-12-31 13:53:52,587 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44839467902978264, 'Total loss': 0.44839467902978264} | train loss {'Reaction outcome loss': 0.2748274288487796, 'Total loss': 0.2748274288487796}
2022-12-31 13:53:52,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:52,588 INFO:     Epoch: 79
2022-12-31 13:53:54,236 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4677928884824117, 'Total loss': 0.4677928884824117} | train loss {'Reaction outcome loss': 0.2563376438844463, 'Total loss': 0.2563376438844463}
2022-12-31 13:53:54,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:54,237 INFO:     Epoch: 80
2022-12-31 13:53:55,843 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4320024867852529, 'Total loss': 0.4320024867852529} | train loss {'Reaction outcome loss': 0.25657634534265683, 'Total loss': 0.25657634534265683}
2022-12-31 13:53:55,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:55,844 INFO:     Epoch: 81
2022-12-31 13:53:57,429 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44258083701133727, 'Total loss': 0.44258083701133727} | train loss {'Reaction outcome loss': 0.2529021889769364, 'Total loss': 0.2529021889769364}
2022-12-31 13:53:57,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:57,429 INFO:     Epoch: 82
2022-12-31 13:53:59,018 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47358714739481605, 'Total loss': 0.47358714739481605} | train loss {'Reaction outcome loss': 0.25093879183206835, 'Total loss': 0.25093879183206835}
2022-12-31 13:53:59,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:53:59,018 INFO:     Epoch: 83
2022-12-31 13:54:00,669 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45547954688469566, 'Total loss': 0.45547954688469566} | train loss {'Reaction outcome loss': 0.25317617592235614, 'Total loss': 0.25317617592235614}
2022-12-31 13:54:00,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:00,670 INFO:     Epoch: 84
2022-12-31 13:54:02,317 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.461789134144783, 'Total loss': 0.461789134144783} | train loss {'Reaction outcome loss': 0.2513048971389029, 'Total loss': 0.2513048971389029}
2022-12-31 13:54:02,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:02,318 INFO:     Epoch: 85
2022-12-31 13:54:03,901 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4280625333388646, 'Total loss': 0.4280625333388646} | train loss {'Reaction outcome loss': 0.24708551417806765, 'Total loss': 0.24708551417806765}
2022-12-31 13:54:03,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:03,902 INFO:     Epoch: 86
2022-12-31 13:54:05,523 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4495869904756546, 'Total loss': 0.4495869904756546} | train loss {'Reaction outcome loss': 0.2450342552086416, 'Total loss': 0.2450342552086416}
2022-12-31 13:54:05,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:05,523 INFO:     Epoch: 87
2022-12-31 13:54:07,107 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4237894922494888, 'Total loss': 0.4237894922494888} | train loss {'Reaction outcome loss': 0.2403786507465934, 'Total loss': 0.2403786507465934}
2022-12-31 13:54:07,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:07,107 INFO:     Epoch: 88
2022-12-31 13:54:08,749 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41833098232746124, 'Total loss': 0.41833098232746124} | train loss {'Reaction outcome loss': 0.24352212806326756, 'Total loss': 0.24352212806326756}
2022-12-31 13:54:08,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:08,750 INFO:     Epoch: 89
2022-12-31 13:54:10,379 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45687109728654224, 'Total loss': 0.45687109728654224} | train loss {'Reaction outcome loss': 0.23473346957399516, 'Total loss': 0.23473346957399516}
2022-12-31 13:54:10,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:10,379 INFO:     Epoch: 90
2022-12-31 13:54:11,995 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.416863289475441, 'Total loss': 0.416863289475441} | train loss {'Reaction outcome loss': 0.2377950362101926, 'Total loss': 0.2377950362101926}
2022-12-31 13:54:11,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:11,996 INFO:     Epoch: 91
2022-12-31 13:54:13,592 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.444166890780131, 'Total loss': 0.444166890780131} | train loss {'Reaction outcome loss': 0.2373402431991923, 'Total loss': 0.2373402431991923}
2022-12-31 13:54:13,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:13,592 INFO:     Epoch: 92
2022-12-31 13:54:15,215 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44070220390955606, 'Total loss': 0.44070220390955606} | train loss {'Reaction outcome loss': 0.23090828890891987, 'Total loss': 0.23090828890891987}
2022-12-31 13:54:15,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:15,216 INFO:     Epoch: 93
2022-12-31 13:54:16,810 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.443751734495163, 'Total loss': 0.443751734495163} | train loss {'Reaction outcome loss': 0.24070280444433975, 'Total loss': 0.24070280444433975}
2022-12-31 13:54:16,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:16,811 INFO:     Epoch: 94
2022-12-31 13:54:18,416 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3960897088050842, 'Total loss': 0.3960897088050842} | train loss {'Reaction outcome loss': 0.22897781620892035, 'Total loss': 0.22897781620892035}
2022-12-31 13:54:18,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:18,416 INFO:     Epoch: 95
2022-12-31 13:54:20,019 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4801278879245122, 'Total loss': 0.4801278879245122} | train loss {'Reaction outcome loss': 0.22742011720792094, 'Total loss': 0.22742011720792094}
2022-12-31 13:54:20,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:20,019 INFO:     Epoch: 96
2022-12-31 13:54:21,627 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4461419979731242, 'Total loss': 0.4461419979731242} | train loss {'Reaction outcome loss': 0.23639734212876015, 'Total loss': 0.23639734212876015}
2022-12-31 13:54:21,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:21,628 INFO:     Epoch: 97
2022-12-31 13:54:23,217 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4415254364411036, 'Total loss': 0.4415254364411036} | train loss {'Reaction outcome loss': 0.2795233980404969, 'Total loss': 0.2795233980404969}
2022-12-31 13:54:23,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:23,218 INFO:     Epoch: 98
2022-12-31 13:54:24,838 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4392874360084534, 'Total loss': 0.4392874360084534} | train loss {'Reaction outcome loss': 0.2325857665889181, 'Total loss': 0.2325857665889181}
2022-12-31 13:54:24,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:24,839 INFO:     Epoch: 99
2022-12-31 13:54:26,455 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.402800914645195, 'Total loss': 0.402800914645195} | train loss {'Reaction outcome loss': 0.23104497886927583, 'Total loss': 0.23104497886927583}
2022-12-31 13:54:26,456 INFO:     Best model found after epoch 45 of 100.
2022-12-31 13:54:26,456 INFO:   Done with stage: TRAINING
2022-12-31 13:54:26,456 INFO:   Starting stage: EVALUATION
2022-12-31 13:54:26,586 INFO:   Done with stage: EVALUATION
2022-12-31 13:54:26,586 INFO:   Leaving out SEQ value Fold_8
2022-12-31 13:54:26,598 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 13:54:26,599 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:54:27,245 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:54:27,246 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:54:27,313 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:54:27,314 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:54:27,314 INFO:     No hyperparam tuning for this model
2022-12-31 13:54:27,314 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:54:27,314 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:54:27,315 INFO:     None feature selector for col prot
2022-12-31 13:54:27,315 INFO:     None feature selector for col prot
2022-12-31 13:54:27,315 INFO:     None feature selector for col prot
2022-12-31 13:54:27,316 INFO:     None feature selector for col chem
2022-12-31 13:54:27,316 INFO:     None feature selector for col chem
2022-12-31 13:54:27,316 INFO:     None feature selector for col chem
2022-12-31 13:54:27,316 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:54:27,316 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:54:27,318 INFO:     Number of params in model 223921
2022-12-31 13:54:27,321 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:54:27,321 INFO:   Starting stage: TRAINING
2022-12-31 13:54:27,365 INFO:     Val loss before train {'Reaction outcome loss': 0.8650683164596558, 'Total loss': 0.8650683164596558}
2022-12-31 13:54:27,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:27,365 INFO:     Epoch: 0
2022-12-31 13:54:28,983 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6050855020682017, 'Total loss': 0.6050855020682017} | train loss {'Reaction outcome loss': 0.8147142776390062, 'Total loss': 0.8147142776390062}
2022-12-31 13:54:28,983 INFO:     Found new best model at epoch 0
2022-12-31 13:54:28,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:28,984 INFO:     Epoch: 1
2022-12-31 13:54:30,582 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5153169095516205, 'Total loss': 0.5153169095516205} | train loss {'Reaction outcome loss': 0.5924958476837534, 'Total loss': 0.5924958476837534}
2022-12-31 13:54:30,582 INFO:     Found new best model at epoch 1
2022-12-31 13:54:30,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:30,583 INFO:     Epoch: 2
2022-12-31 13:54:32,159 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5083406150341034, 'Total loss': 0.5083406150341034} | train loss {'Reaction outcome loss': 0.5246523588243193, 'Total loss': 0.5246523588243193}
2022-12-31 13:54:32,159 INFO:     Found new best model at epoch 2
2022-12-31 13:54:32,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:32,161 INFO:     Epoch: 3
2022-12-31 13:54:33,748 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4582343300183614, 'Total loss': 0.4582343300183614} | train loss {'Reaction outcome loss': 0.5033316145630649, 'Total loss': 0.5033316145630649}
2022-12-31 13:54:33,749 INFO:     Found new best model at epoch 3
2022-12-31 13:54:33,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:33,750 INFO:     Epoch: 4
2022-12-31 13:54:35,345 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4834347069263458, 'Total loss': 0.4834347069263458} | train loss {'Reaction outcome loss': 0.4841356685888158, 'Total loss': 0.4841356685888158}
2022-12-31 13:54:35,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:35,345 INFO:     Epoch: 5
2022-12-31 13:54:36,940 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4892425060272217, 'Total loss': 0.4892425060272217} | train loss {'Reaction outcome loss': 0.4762180555258354, 'Total loss': 0.4762180555258354}
2022-12-31 13:54:36,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:36,940 INFO:     Epoch: 6
2022-12-31 13:54:38,535 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4795043478409449, 'Total loss': 0.4795043478409449} | train loss {'Reaction outcome loss': 0.4626164083933308, 'Total loss': 0.4626164083933308}
2022-12-31 13:54:38,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:38,535 INFO:     Epoch: 7
2022-12-31 13:54:40,124 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4528764883677165, 'Total loss': 0.4528764883677165} | train loss {'Reaction outcome loss': 0.4569911643536422, 'Total loss': 0.4569911643536422}
2022-12-31 13:54:40,124 INFO:     Found new best model at epoch 7
2022-12-31 13:54:40,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:40,125 INFO:     Epoch: 8
2022-12-31 13:54:41,724 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45822130143642426, 'Total loss': 0.45822130143642426} | train loss {'Reaction outcome loss': 0.4516124859669783, 'Total loss': 0.4516124859669783}
2022-12-31 13:54:41,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:41,724 INFO:     Epoch: 9
2022-12-31 13:54:43,308 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42693537573019663, 'Total loss': 0.42693537573019663} | train loss {'Reaction outcome loss': 0.44623378452158324, 'Total loss': 0.44623378452158324}
2022-12-31 13:54:43,308 INFO:     Found new best model at epoch 9
2022-12-31 13:54:43,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:43,309 INFO:     Epoch: 10
2022-12-31 13:54:44,930 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42941256364186603, 'Total loss': 0.42941256364186603} | train loss {'Reaction outcome loss': 0.4365907618707984, 'Total loss': 0.4365907618707984}
2022-12-31 13:54:44,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:44,930 INFO:     Epoch: 11
2022-12-31 13:54:46,529 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44344756603240965, 'Total loss': 0.44344756603240965} | train loss {'Reaction outcome loss': 0.4328553074576559, 'Total loss': 0.4328553074576559}
2022-12-31 13:54:46,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:46,529 INFO:     Epoch: 12
2022-12-31 13:54:48,127 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46190838937958084, 'Total loss': 0.46190838937958084} | train loss {'Reaction outcome loss': 0.42522338625505895, 'Total loss': 0.42522338625505895}
2022-12-31 13:54:48,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:48,127 INFO:     Epoch: 13
2022-12-31 13:54:49,717 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41295457979043326, 'Total loss': 0.41295457979043326} | train loss {'Reaction outcome loss': 0.4192371737402286, 'Total loss': 0.4192371737402286}
2022-12-31 13:54:49,717 INFO:     Found new best model at epoch 13
2022-12-31 13:54:49,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:49,718 INFO:     Epoch: 14
2022-12-31 13:54:51,317 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4537893811861674, 'Total loss': 0.4537893811861674} | train loss {'Reaction outcome loss': 0.4093092991596591, 'Total loss': 0.4093092991596591}
2022-12-31 13:54:51,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:51,317 INFO:     Epoch: 15
2022-12-31 13:54:52,903 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4330417315165202, 'Total loss': 0.4330417315165202} | train loss {'Reaction outcome loss': 0.40855588271778864, 'Total loss': 0.40855588271778864}
2022-12-31 13:54:52,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:52,903 INFO:     Epoch: 16
2022-12-31 13:54:54,502 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4288544694582621, 'Total loss': 0.4288544694582621} | train loss {'Reaction outcome loss': 0.4016519479018493, 'Total loss': 0.4016519479018493}
2022-12-31 13:54:54,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:54,502 INFO:     Epoch: 17
2022-12-31 13:54:56,107 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45668117006619774, 'Total loss': 0.45668117006619774} | train loss {'Reaction outcome loss': 0.4009625723816618, 'Total loss': 0.4009625723816618}
2022-12-31 13:54:56,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:56,107 INFO:     Epoch: 18
2022-12-31 13:54:57,706 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.419316636522611, 'Total loss': 0.419316636522611} | train loss {'Reaction outcome loss': 0.39164048879250996, 'Total loss': 0.39164048879250996}
2022-12-31 13:54:57,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:57,707 INFO:     Epoch: 19
2022-12-31 13:54:59,294 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4300562838713328, 'Total loss': 0.4300562838713328} | train loss {'Reaction outcome loss': 0.38848700053500435, 'Total loss': 0.38848700053500435}
2022-12-31 13:54:59,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:54:59,294 INFO:     Epoch: 20
2022-12-31 13:55:00,877 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48577240109443665, 'Total loss': 0.48577240109443665} | train loss {'Reaction outcome loss': 0.37642445872082325, 'Total loss': 0.37642445872082325}
2022-12-31 13:55:00,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:00,878 INFO:     Epoch: 21
2022-12-31 13:55:02,473 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42980734805266063, 'Total loss': 0.42980734805266063} | train loss {'Reaction outcome loss': 0.37273233468188854, 'Total loss': 0.37273233468188854}
2022-12-31 13:55:02,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:02,473 INFO:     Epoch: 22
2022-12-31 13:55:04,071 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4434177319208781, 'Total loss': 0.4434177319208781} | train loss {'Reaction outcome loss': 0.3677983378624394, 'Total loss': 0.3677983378624394}
2022-12-31 13:55:04,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:04,071 INFO:     Epoch: 23
2022-12-31 13:55:05,670 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43481913208961487, 'Total loss': 0.43481913208961487} | train loss {'Reaction outcome loss': 0.36384334426074133, 'Total loss': 0.36384334426074133}
2022-12-31 13:55:05,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:05,670 INFO:     Epoch: 24
2022-12-31 13:55:07,285 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.416906812787056, 'Total loss': 0.416906812787056} | train loss {'Reaction outcome loss': 0.35392267711079906, 'Total loss': 0.35392267711079906}
2022-12-31 13:55:07,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:07,285 INFO:     Epoch: 25
2022-12-31 13:55:08,874 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4402792274951935, 'Total loss': 0.4402792274951935} | train loss {'Reaction outcome loss': 0.3481781922933394, 'Total loss': 0.3481781922933394}
2022-12-31 13:55:08,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:08,875 INFO:     Epoch: 26
2022-12-31 13:55:10,461 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42816427648067473, 'Total loss': 0.42816427648067473} | train loss {'Reaction outcome loss': 0.34909194397882826, 'Total loss': 0.34909194397882826}
2022-12-31 13:55:10,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:10,462 INFO:     Epoch: 27
2022-12-31 13:55:12,060 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4806437462568283, 'Total loss': 0.4806437462568283} | train loss {'Reaction outcome loss': 0.338046926352447, 'Total loss': 0.338046926352447}
2022-12-31 13:55:12,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:12,060 INFO:     Epoch: 28
2022-12-31 13:55:13,685 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44812556405862175, 'Total loss': 0.44812556405862175} | train loss {'Reaction outcome loss': 0.3389982481616257, 'Total loss': 0.3389982481616257}
2022-12-31 13:55:13,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:13,685 INFO:     Epoch: 29
2022-12-31 13:55:15,283 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45140708088874815, 'Total loss': 0.45140708088874815} | train loss {'Reaction outcome loss': 0.3291007225965931, 'Total loss': 0.3291007225965931}
2022-12-31 13:55:15,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:15,284 INFO:     Epoch: 30
2022-12-31 13:55:16,864 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4016677111387253, 'Total loss': 0.4016677111387253} | train loss {'Reaction outcome loss': 0.32646957635335677, 'Total loss': 0.32646957635335677}
2022-12-31 13:55:16,864 INFO:     Found new best model at epoch 30
2022-12-31 13:55:16,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:16,865 INFO:     Epoch: 31
2022-12-31 13:55:18,450 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41963103612263997, 'Total loss': 0.41963103612263997} | train loss {'Reaction outcome loss': 0.31952690721972143, 'Total loss': 0.31952690721972143}
2022-12-31 13:55:18,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:18,451 INFO:     Epoch: 32
2022-12-31 13:55:20,036 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.397393253693978, 'Total loss': 0.397393253693978} | train loss {'Reaction outcome loss': 0.3155668113299095, 'Total loss': 0.3155668113299095}
2022-12-31 13:55:20,036 INFO:     Found new best model at epoch 32
2022-12-31 13:55:20,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:20,037 INFO:     Epoch: 33
2022-12-31 13:55:21,636 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4241904785235723, 'Total loss': 0.4241904785235723} | train loss {'Reaction outcome loss': 0.3131114423247802, 'Total loss': 0.3131114423247802}
2022-12-31 13:55:21,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:21,636 INFO:     Epoch: 34
2022-12-31 13:55:23,235 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39091425240039823, 'Total loss': 0.39091425240039823} | train loss {'Reaction outcome loss': 0.30845262781873234, 'Total loss': 0.30845262781873234}
2022-12-31 13:55:23,236 INFO:     Found new best model at epoch 34
2022-12-31 13:55:23,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:23,237 INFO:     Epoch: 35
2022-12-31 13:55:24,835 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41761922066410384, 'Total loss': 0.41761922066410384} | train loss {'Reaction outcome loss': 0.3027944287190037, 'Total loss': 0.3027944287190037}
2022-12-31 13:55:24,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:24,835 INFO:     Epoch: 36
2022-12-31 13:55:26,419 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3979449373980363, 'Total loss': 0.3979449373980363} | train loss {'Reaction outcome loss': 0.2969204637962971, 'Total loss': 0.2969204637962971}
2022-12-31 13:55:26,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:26,419 INFO:     Epoch: 37
2022-12-31 13:55:28,043 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4335424304008484, 'Total loss': 0.4335424304008484} | train loss {'Reaction outcome loss': 0.3003192740580896, 'Total loss': 0.3003192740580896}
2022-12-31 13:55:28,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:28,043 INFO:     Epoch: 38
2022-12-31 13:55:29,681 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4569014459848404, 'Total loss': 0.4569014459848404} | train loss {'Reaction outcome loss': 0.2850185240054653, 'Total loss': 0.2850185240054653}
2022-12-31 13:55:29,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:29,681 INFO:     Epoch: 39
2022-12-31 13:55:31,302 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42500186065832773, 'Total loss': 0.42500186065832773} | train loss {'Reaction outcome loss': 0.29127425003633667, 'Total loss': 0.29127425003633667}
2022-12-31 13:55:31,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:31,302 INFO:     Epoch: 40
2022-12-31 13:55:32,912 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42822646697362265, 'Total loss': 0.42822646697362265} | train loss {'Reaction outcome loss': 0.2853452529703831, 'Total loss': 0.2853452529703831}
2022-12-31 13:55:32,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:32,913 INFO:     Epoch: 41
2022-12-31 13:55:34,553 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4527001053094864, 'Total loss': 0.4527001053094864} | train loss {'Reaction outcome loss': 0.28597661939170893, 'Total loss': 0.28597661939170893}
2022-12-31 13:55:34,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:34,553 INFO:     Epoch: 42
2022-12-31 13:55:36,197 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41762573023637134, 'Total loss': 0.41762573023637134} | train loss {'Reaction outcome loss': 0.2793982153364124, 'Total loss': 0.2793982153364124}
2022-12-31 13:55:36,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:36,198 INFO:     Epoch: 43
2022-12-31 13:55:37,809 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4241446961959203, 'Total loss': 0.4241446961959203} | train loss {'Reaction outcome loss': 0.2867834034518604, 'Total loss': 0.2867834034518604}
2022-12-31 13:55:37,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:37,809 INFO:     Epoch: 44
2022-12-31 13:55:39,436 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4238134910662969, 'Total loss': 0.4238134910662969} | train loss {'Reaction outcome loss': 0.2776583262793992, 'Total loss': 0.2776583262793992}
2022-12-31 13:55:39,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:39,437 INFO:     Epoch: 45
2022-12-31 13:55:41,068 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42728865146636963, 'Total loss': 0.42728865146636963} | train loss {'Reaction outcome loss': 0.26700000391498097, 'Total loss': 0.26700000391498097}
2022-12-31 13:55:41,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:41,068 INFO:     Epoch: 46
2022-12-31 13:55:42,694 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4576003700494766, 'Total loss': 0.4576003700494766} | train loss {'Reaction outcome loss': 0.2677058425126937, 'Total loss': 0.2677058425126937}
2022-12-31 13:55:42,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:42,694 INFO:     Epoch: 47
2022-12-31 13:55:44,326 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4158911426862081, 'Total loss': 0.4158911426862081} | train loss {'Reaction outcome loss': 0.2668272681316755, 'Total loss': 0.2668272681316755}
2022-12-31 13:55:44,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:44,326 INFO:     Epoch: 48
2022-12-31 13:55:45,941 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4103997815400362, 'Total loss': 0.4103997815400362} | train loss {'Reaction outcome loss': 0.26371592665295096, 'Total loss': 0.26371592665295096}
2022-12-31 13:55:45,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:45,941 INFO:     Epoch: 49
2022-12-31 13:55:47,551 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4185667415459951, 'Total loss': 0.4185667415459951} | train loss {'Reaction outcome loss': 0.2562109464575557, 'Total loss': 0.2562109464575557}
2022-12-31 13:55:47,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:47,552 INFO:     Epoch: 50
2022-12-31 13:55:49,177 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42285151183605196, 'Total loss': 0.42285151183605196} | train loss {'Reaction outcome loss': 0.2556177945059799, 'Total loss': 0.2556177945059799}
2022-12-31 13:55:49,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:49,178 INFO:     Epoch: 51
2022-12-31 13:55:50,817 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4279117564360301, 'Total loss': 0.4279117564360301} | train loss {'Reaction outcome loss': 0.2526712389866801, 'Total loss': 0.2526712389866801}
2022-12-31 13:55:50,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:50,818 INFO:     Epoch: 52
2022-12-31 13:55:52,444 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3889487644036611, 'Total loss': 0.3889487644036611} | train loss {'Reaction outcome loss': 0.25216349336678967, 'Total loss': 0.25216349336678967}
2022-12-31 13:55:52,445 INFO:     Found new best model at epoch 52
2022-12-31 13:55:52,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:52,446 INFO:     Epoch: 53
2022-12-31 13:55:54,060 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41780022978782655, 'Total loss': 0.41780022978782655} | train loss {'Reaction outcome loss': 0.25564959316249314, 'Total loss': 0.25564959316249314}
2022-12-31 13:55:54,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:54,060 INFO:     Epoch: 54
2022-12-31 13:55:55,687 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.438333186507225, 'Total loss': 0.438333186507225} | train loss {'Reaction outcome loss': 0.24741028852923944, 'Total loss': 0.24741028852923944}
2022-12-31 13:55:55,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:55,688 INFO:     Epoch: 55
2022-12-31 13:55:57,317 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43041973809401196, 'Total loss': 0.43041973809401196} | train loss {'Reaction outcome loss': 0.25387442772052365, 'Total loss': 0.25387442772052365}
2022-12-31 13:55:57,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:57,318 INFO:     Epoch: 56
2022-12-31 13:55:58,944 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4249686668316523, 'Total loss': 0.4249686668316523} | train loss {'Reaction outcome loss': 0.24296289804751856, 'Total loss': 0.24296289804751856}
2022-12-31 13:55:58,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:55:58,945 INFO:     Epoch: 57
2022-12-31 13:56:00,579 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3958286831776301, 'Total loss': 0.3958286831776301} | train loss {'Reaction outcome loss': 0.24306766692902484, 'Total loss': 0.24306766692902484}
2022-12-31 13:56:00,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:00,579 INFO:     Epoch: 58
2022-12-31 13:56:02,218 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4626419628659884, 'Total loss': 0.4626419628659884} | train loss {'Reaction outcome loss': 0.2461280739342753, 'Total loss': 0.2461280739342753}
2022-12-31 13:56:02,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:02,219 INFO:     Epoch: 59
2022-12-31 13:56:03,848 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41488013286143544, 'Total loss': 0.41488013286143544} | train loss {'Reaction outcome loss': 0.24318917578657287, 'Total loss': 0.24318917578657287}
2022-12-31 13:56:03,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:03,849 INFO:     Epoch: 60
2022-12-31 13:56:05,458 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40825031797091166, 'Total loss': 0.40825031797091166} | train loss {'Reaction outcome loss': 0.2420862611301624, 'Total loss': 0.2420862611301624}
2022-12-31 13:56:05,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:05,458 INFO:     Epoch: 61
2022-12-31 13:56:07,086 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4199775864680608, 'Total loss': 0.4199775864680608} | train loss {'Reaction outcome loss': 0.23634963178069052, 'Total loss': 0.23634963178069052}
2022-12-31 13:56:07,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:07,086 INFO:     Epoch: 62
2022-12-31 13:56:08,722 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43133102506399157, 'Total loss': 0.43133102506399157} | train loss {'Reaction outcome loss': 0.23793109713027077, 'Total loss': 0.23793109713027077}
2022-12-31 13:56:08,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:08,722 INFO:     Epoch: 63
2022-12-31 13:56:10,386 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39812732140223184, 'Total loss': 0.39812732140223184} | train loss {'Reaction outcome loss': 0.23252912190654418, 'Total loss': 0.23252912190654418}
2022-12-31 13:56:10,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:10,387 INFO:     Epoch: 64
2022-12-31 13:56:12,022 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3970916956663132, 'Total loss': 0.3970916956663132} | train loss {'Reaction outcome loss': 0.23598657268351012, 'Total loss': 0.23598657268351012}
2022-12-31 13:56:12,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:12,022 INFO:     Epoch: 65
2022-12-31 13:56:13,640 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4181793471177419, 'Total loss': 0.4181793471177419} | train loss {'Reaction outcome loss': 0.23254093946549145, 'Total loss': 0.23254093946549145}
2022-12-31 13:56:13,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:13,640 INFO:     Epoch: 66
2022-12-31 13:56:15,243 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4035208324591319, 'Total loss': 0.4035208324591319} | train loss {'Reaction outcome loss': 0.2310812007363913, 'Total loss': 0.2310812007363913}
2022-12-31 13:56:15,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:15,243 INFO:     Epoch: 67
2022-12-31 13:56:16,868 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3874182234207789, 'Total loss': 0.3874182234207789} | train loss {'Reaction outcome loss': 0.22321235297424516, 'Total loss': 0.22321235297424516}
2022-12-31 13:56:16,868 INFO:     Found new best model at epoch 67
2022-12-31 13:56:16,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:16,869 INFO:     Epoch: 68
2022-12-31 13:56:18,486 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42709546685218813, 'Total loss': 0.42709546685218813} | train loss {'Reaction outcome loss': 0.22860649460246854, 'Total loss': 0.22860649460246854}
2022-12-31 13:56:18,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:18,486 INFO:     Epoch: 69
2022-12-31 13:56:20,089 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4248614400625229, 'Total loss': 0.4248614400625229} | train loss {'Reaction outcome loss': 0.23440342140893866, 'Total loss': 0.23440342140893866}
2022-12-31 13:56:20,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:20,089 INFO:     Epoch: 70
2022-12-31 13:56:21,707 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.406352299451828, 'Total loss': 0.406352299451828} | train loss {'Reaction outcome loss': 0.22014842092664572, 'Total loss': 0.22014842092664572}
2022-12-31 13:56:21,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:21,707 INFO:     Epoch: 71
2022-12-31 13:56:23,326 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4186695978045464, 'Total loss': 0.4186695978045464} | train loss {'Reaction outcome loss': 0.22383340590218775, 'Total loss': 0.22383340590218775}
2022-12-31 13:56:23,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:23,327 INFO:     Epoch: 72
2022-12-31 13:56:24,928 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4129669487476349, 'Total loss': 0.4129669487476349} | train loss {'Reaction outcome loss': 0.21920435216930442, 'Total loss': 0.21920435216930442}
2022-12-31 13:56:24,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:24,928 INFO:     Epoch: 73
2022-12-31 13:56:26,529 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44641763319571814, 'Total loss': 0.44641763319571814} | train loss {'Reaction outcome loss': 0.22050411834714623, 'Total loss': 0.22050411834714623}
2022-12-31 13:56:26,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:26,530 INFO:     Epoch: 74
2022-12-31 13:56:28,127 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43405320843060813, 'Total loss': 0.43405320843060813} | train loss {'Reaction outcome loss': 0.22363843499635258, 'Total loss': 0.22363843499635258}
2022-12-31 13:56:28,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:28,128 INFO:     Epoch: 75
2022-12-31 13:56:29,725 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3945429101586342, 'Total loss': 0.3945429101586342} | train loss {'Reaction outcome loss': 0.21718090323282638, 'Total loss': 0.21718090323282638}
2022-12-31 13:56:29,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:29,725 INFO:     Epoch: 76
2022-12-31 13:56:31,359 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44377734661102297, 'Total loss': 0.44377734661102297} | train loss {'Reaction outcome loss': 0.2189111266298777, 'Total loss': 0.2189111266298777}
2022-12-31 13:56:31,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:31,359 INFO:     Epoch: 77
2022-12-31 13:56:32,949 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4050976534684499, 'Total loss': 0.4050976534684499} | train loss {'Reaction outcome loss': 0.21145063332778258, 'Total loss': 0.21145063332778258}
2022-12-31 13:56:32,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:32,950 INFO:     Epoch: 78
2022-12-31 13:56:34,548 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4596838404734929, 'Total loss': 0.4596838404734929} | train loss {'Reaction outcome loss': 0.21937716003153881, 'Total loss': 0.21937716003153881}
2022-12-31 13:56:34,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:34,549 INFO:     Epoch: 79
2022-12-31 13:56:36,146 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39801961729923885, 'Total loss': 0.39801961729923885} | train loss {'Reaction outcome loss': 0.21608624820781014, 'Total loss': 0.21608624820781014}
2022-12-31 13:56:36,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:36,147 INFO:     Epoch: 80
2022-12-31 13:56:37,743 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44741091132164, 'Total loss': 0.44741091132164} | train loss {'Reaction outcome loss': 0.214237362846569, 'Total loss': 0.214237362846569}
2022-12-31 13:56:37,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:37,743 INFO:     Epoch: 81
2022-12-31 13:56:39,335 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4325952738523483, 'Total loss': 0.4325952738523483} | train loss {'Reaction outcome loss': 0.220547265203221, 'Total loss': 0.220547265203221}
2022-12-31 13:56:39,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:39,335 INFO:     Epoch: 82
2022-12-31 13:56:40,937 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3999986916780472, 'Total loss': 0.3999986916780472} | train loss {'Reaction outcome loss': 0.20963083399650062, 'Total loss': 0.20963083399650062}
2022-12-31 13:56:40,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:40,938 INFO:     Epoch: 83
2022-12-31 13:56:42,058 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4291330923636754, 'Total loss': 0.4291330923636754} | train loss {'Reaction outcome loss': 0.20669045048446333, 'Total loss': 0.20669045048446333}
2022-12-31 13:56:42,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:42,058 INFO:     Epoch: 84
2022-12-31 13:56:43,109 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4277665654818217, 'Total loss': 0.4277665654818217} | train loss {'Reaction outcome loss': 0.2062451430072967, 'Total loss': 0.2062451430072967}
2022-12-31 13:56:43,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:43,109 INFO:     Epoch: 85
2022-12-31 13:56:44,157 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4242507209380468, 'Total loss': 0.4242507209380468} | train loss {'Reaction outcome loss': 0.2049776339006141, 'Total loss': 0.2049776339006141}
2022-12-31 13:56:44,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:44,157 INFO:     Epoch: 86
2022-12-31 13:56:45,216 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40089648266633354, 'Total loss': 0.40089648266633354} | train loss {'Reaction outcome loss': 0.2045212950876975, 'Total loss': 0.2045212950876975}
2022-12-31 13:56:45,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:45,216 INFO:     Epoch: 87
2022-12-31 13:56:46,547 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38965371741602817, 'Total loss': 0.38965371741602817} | train loss {'Reaction outcome loss': 0.20884413999525736, 'Total loss': 0.20884413999525736}
2022-12-31 13:56:46,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:46,548 INFO:     Epoch: 88
2022-12-31 13:56:48,152 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40335379739602406, 'Total loss': 0.40335379739602406} | train loss {'Reaction outcome loss': 0.20592876002328456, 'Total loss': 0.20592876002328456}
2022-12-31 13:56:48,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:48,152 INFO:     Epoch: 89
2022-12-31 13:56:49,751 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4269438058137894, 'Total loss': 0.4269438058137894} | train loss {'Reaction outcome loss': 0.2061689045062683, 'Total loss': 0.2061689045062683}
2022-12-31 13:56:49,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:49,751 INFO:     Epoch: 90
2022-12-31 13:56:51,351 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41477900793155037, 'Total loss': 0.41477900793155037} | train loss {'Reaction outcome loss': 0.2019198216008444, 'Total loss': 0.2019198216008444}
2022-12-31 13:56:51,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:51,351 INFO:     Epoch: 91
2022-12-31 13:56:52,952 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4043322533369064, 'Total loss': 0.4043322533369064} | train loss {'Reaction outcome loss': 0.20117133264735776, 'Total loss': 0.20117133264735776}
2022-12-31 13:56:52,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:52,953 INFO:     Epoch: 92
2022-12-31 13:56:54,543 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44155562818050387, 'Total loss': 0.44155562818050387} | train loss {'Reaction outcome loss': 0.19624243124666876, 'Total loss': 0.19624243124666876}
2022-12-31 13:56:54,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:54,543 INFO:     Epoch: 93
2022-12-31 13:56:56,130 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4003323972225189, 'Total loss': 0.4003323972225189} | train loss {'Reaction outcome loss': 0.20162723280054373, 'Total loss': 0.20162723280054373}
2022-12-31 13:56:56,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:56,131 INFO:     Epoch: 94
2022-12-31 13:56:57,732 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3726305991411209, 'Total loss': 0.3726305991411209} | train loss {'Reaction outcome loss': 0.19903916462467316, 'Total loss': 0.19903916462467316}
2022-12-31 13:56:57,732 INFO:     Found new best model at epoch 94
2022-12-31 13:56:57,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:57,733 INFO:     Epoch: 95
2022-12-31 13:56:59,333 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43982778390248617, 'Total loss': 0.43982778390248617} | train loss {'Reaction outcome loss': 0.2011716987590992, 'Total loss': 0.2011716987590992}
2022-12-31 13:56:59,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:56:59,334 INFO:     Epoch: 96
2022-12-31 13:57:00,935 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49242060085137684, 'Total loss': 0.49242060085137684} | train loss {'Reaction outcome loss': 0.1957090004571598, 'Total loss': 0.1957090004571598}
2022-12-31 13:57:00,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:00,935 INFO:     Epoch: 97
2022-12-31 13:57:02,536 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3643177330493927, 'Total loss': 0.3643177330493927} | train loss {'Reaction outcome loss': 0.19542776108005622, 'Total loss': 0.19542776108005622}
2022-12-31 13:57:02,536 INFO:     Found new best model at epoch 97
2022-12-31 13:57:02,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:02,537 INFO:     Epoch: 98
2022-12-31 13:57:04,117 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4481498241424561, 'Total loss': 0.4481498241424561} | train loss {'Reaction outcome loss': 0.19860522773619876, 'Total loss': 0.19860522773619876}
2022-12-31 13:57:04,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:04,117 INFO:     Epoch: 99
2022-12-31 13:57:05,717 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46542675197124483, 'Total loss': 0.46542675197124483} | train loss {'Reaction outcome loss': 0.19490616587772422, 'Total loss': 0.19490616587772422}
2022-12-31 13:57:05,719 INFO:     Best model found after epoch 98 of 100.
2022-12-31 13:57:05,719 INFO:   Done with stage: TRAINING
2022-12-31 13:57:05,719 INFO:   Starting stage: EVALUATION
2022-12-31 13:57:05,855 INFO:   Done with stage: EVALUATION
2022-12-31 13:57:05,855 INFO:   Leaving out SEQ value Fold_9
2022-12-31 13:57:05,868 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 13:57:05,868 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:57:06,511 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:57:06,511 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:57:06,580 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:57:06,580 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:57:06,580 INFO:     No hyperparam tuning for this model
2022-12-31 13:57:06,580 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:57:06,580 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:57:06,581 INFO:     None feature selector for col prot
2022-12-31 13:57:06,581 INFO:     None feature selector for col prot
2022-12-31 13:57:06,581 INFO:     None feature selector for col prot
2022-12-31 13:57:06,582 INFO:     None feature selector for col chem
2022-12-31 13:57:06,582 INFO:     None feature selector for col chem
2022-12-31 13:57:06,582 INFO:     None feature selector for col chem
2022-12-31 13:57:06,582 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:57:06,582 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:57:06,584 INFO:     Number of params in model 223921
2022-12-31 13:57:06,587 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:57:06,587 INFO:   Starting stage: TRAINING
2022-12-31 13:57:06,632 INFO:     Val loss before train {'Reaction outcome loss': 1.0502525130907694, 'Total loss': 1.0502525130907694}
2022-12-31 13:57:06,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:06,632 INFO:     Epoch: 0
2022-12-31 13:57:08,249 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7279949267705281, 'Total loss': 0.7279949267705281} | train loss {'Reaction outcome loss': 0.8206497705609038, 'Total loss': 0.8206497705609038}
2022-12-31 13:57:08,249 INFO:     Found new best model at epoch 0
2022-12-31 13:57:08,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:08,250 INFO:     Epoch: 1
2022-12-31 13:57:09,866 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5616848687330882, 'Total loss': 0.5616848687330882} | train loss {'Reaction outcome loss': 0.6105066348403774, 'Total loss': 0.6105066348403774}
2022-12-31 13:57:09,866 INFO:     Found new best model at epoch 1
2022-12-31 13:57:09,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:09,867 INFO:     Epoch: 2
2022-12-31 13:57:11,527 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5829529503981272, 'Total loss': 0.5829529503981272} | train loss {'Reaction outcome loss': 0.540460995627918, 'Total loss': 0.540460995627918}
2022-12-31 13:57:11,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:11,527 INFO:     Epoch: 3
2022-12-31 13:57:13,110 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5225243071715037, 'Total loss': 0.5225243071715037} | train loss {'Reaction outcome loss': 0.5466565777011134, 'Total loss': 0.5466565777011134}
2022-12-31 13:57:13,111 INFO:     Found new best model at epoch 3
2022-12-31 13:57:13,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:13,112 INFO:     Epoch: 4
2022-12-31 13:57:14,760 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5251512269179026, 'Total loss': 0.5251512269179026} | train loss {'Reaction outcome loss': 0.4866821536747064, 'Total loss': 0.4866821536747064}
2022-12-31 13:57:14,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:14,761 INFO:     Epoch: 5
2022-12-31 13:57:16,372 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5201298832893372, 'Total loss': 0.5201298832893372} | train loss {'Reaction outcome loss': 0.47875409959343035, 'Total loss': 0.47875409959343035}
2022-12-31 13:57:16,372 INFO:     Found new best model at epoch 5
2022-12-31 13:57:16,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:16,373 INFO:     Epoch: 6
2022-12-31 13:57:17,992 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5156633377075195, 'Total loss': 0.5156633377075195} | train loss {'Reaction outcome loss': 0.47163040871205536, 'Total loss': 0.47163040871205536}
2022-12-31 13:57:17,993 INFO:     Found new best model at epoch 6
2022-12-31 13:57:17,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:17,993 INFO:     Epoch: 7
2022-12-31 13:57:19,604 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4962301701307297, 'Total loss': 0.4962301701307297} | train loss {'Reaction outcome loss': 0.4728041135341577, 'Total loss': 0.4728041135341577}
2022-12-31 13:57:19,605 INFO:     Found new best model at epoch 7
2022-12-31 13:57:19,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:19,605 INFO:     Epoch: 8
2022-12-31 13:57:21,198 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48975160121917727, 'Total loss': 0.48975160121917727} | train loss {'Reaction outcome loss': 0.4501612204796824, 'Total loss': 0.4501612204796824}
2022-12-31 13:57:21,198 INFO:     Found new best model at epoch 8
2022-12-31 13:57:21,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:21,199 INFO:     Epoch: 9
2022-12-31 13:57:22,790 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5109063059091568, 'Total loss': 0.5109063059091568} | train loss {'Reaction outcome loss': 0.4582929603647495, 'Total loss': 0.4582929603647495}
2022-12-31 13:57:22,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:22,790 INFO:     Epoch: 10
2022-12-31 13:57:24,408 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4804828365643819, 'Total loss': 0.4804828365643819} | train loss {'Reaction outcome loss': 0.5156250312600447, 'Total loss': 0.5156250312600447}
2022-12-31 13:57:24,408 INFO:     Found new best model at epoch 10
2022-12-31 13:57:24,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:24,409 INFO:     Epoch: 11
2022-12-31 13:57:26,033 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4887247900168101, 'Total loss': 0.4887247900168101} | train loss {'Reaction outcome loss': 0.4528012295840713, 'Total loss': 0.4528012295840713}
2022-12-31 13:57:26,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:26,034 INFO:     Epoch: 12
2022-12-31 13:57:27,650 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5055600086847941, 'Total loss': 0.5055600086847941} | train loss {'Reaction outcome loss': 0.4283353853498356, 'Total loss': 0.4283353853498356}
2022-12-31 13:57:27,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:27,650 INFO:     Epoch: 13
2022-12-31 13:57:29,267 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48843852877616883, 'Total loss': 0.48843852877616883} | train loss {'Reaction outcome loss': 0.42508564547946054, 'Total loss': 0.42508564547946054}
2022-12-31 13:57:29,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:29,268 INFO:     Epoch: 14
2022-12-31 13:57:30,846 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47903808355331423, 'Total loss': 0.47903808355331423} | train loss {'Reaction outcome loss': 0.4193838980138579, 'Total loss': 0.4193838980138579}
2022-12-31 13:57:30,846 INFO:     Found new best model at epoch 14
2022-12-31 13:57:30,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:30,847 INFO:     Epoch: 15
2022-12-31 13:57:32,461 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5388614465792974, 'Total loss': 0.5388614465792974} | train loss {'Reaction outcome loss': 0.4129515570462715, 'Total loss': 0.4129515570462715}
2022-12-31 13:57:32,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:32,462 INFO:     Epoch: 16
2022-12-31 13:57:34,085 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48429109454154967, 'Total loss': 0.48429109454154967} | train loss {'Reaction outcome loss': 0.40915699539355177, 'Total loss': 0.40915699539355177}
2022-12-31 13:57:34,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:34,086 INFO:     Epoch: 17
2022-12-31 13:57:35,704 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.450880632797877, 'Total loss': 0.450880632797877} | train loss {'Reaction outcome loss': 0.4011355518174452, 'Total loss': 0.4011355518174452}
2022-12-31 13:57:35,704 INFO:     Found new best model at epoch 17
2022-12-31 13:57:35,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:35,705 INFO:     Epoch: 18
2022-12-31 13:57:37,326 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5288043210903803, 'Total loss': 0.5288043210903803} | train loss {'Reaction outcome loss': 0.4007321971644094, 'Total loss': 0.4007321971644094}
2022-12-31 13:57:37,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:37,326 INFO:     Epoch: 19
2022-12-31 13:57:38,943 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4834093828996023, 'Total loss': 0.4834093828996023} | train loss {'Reaction outcome loss': 0.4212125296825948, 'Total loss': 0.4212125296825948}
2022-12-31 13:57:38,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:38,944 INFO:     Epoch: 20
2022-12-31 13:57:40,551 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4842619836330414, 'Total loss': 0.4842619836330414} | train loss {'Reaction outcome loss': 0.4160555598083074, 'Total loss': 0.4160555598083074}
2022-12-31 13:57:40,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:40,552 INFO:     Epoch: 21
2022-12-31 13:57:42,168 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49405967791875205, 'Total loss': 0.49405967791875205} | train loss {'Reaction outcome loss': 0.3919754656355666, 'Total loss': 0.3919754656355666}
2022-12-31 13:57:42,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:42,168 INFO:     Epoch: 22
2022-12-31 13:57:43,786 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4597889532645543, 'Total loss': 0.4597889532645543} | train loss {'Reaction outcome loss': 0.39195085377972305, 'Total loss': 0.39195085377972305}
2022-12-31 13:57:43,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:43,786 INFO:     Epoch: 23
2022-12-31 13:57:45,418 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4583672414223353, 'Total loss': 0.4583672414223353} | train loss {'Reaction outcome loss': 0.3675812081622797, 'Total loss': 0.3675812081622797}
2022-12-31 13:57:45,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:45,418 INFO:     Epoch: 24
2022-12-31 13:57:47,053 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.465988423426946, 'Total loss': 0.465988423426946} | train loss {'Reaction outcome loss': 0.3666150836624961, 'Total loss': 0.3666150836624961}
2022-12-31 13:57:47,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:47,053 INFO:     Epoch: 25
2022-12-31 13:57:48,666 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43337322225173314, 'Total loss': 0.43337322225173314} | train loss {'Reaction outcome loss': 0.35951428242243716, 'Total loss': 0.35951428242243716}
2022-12-31 13:57:48,666 INFO:     Found new best model at epoch 25
2022-12-31 13:57:48,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:48,667 INFO:     Epoch: 26
2022-12-31 13:57:50,255 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.484327949086825, 'Total loss': 0.484327949086825} | train loss {'Reaction outcome loss': 0.36058537043847033, 'Total loss': 0.36058537043847033}
2022-12-31 13:57:50,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:50,256 INFO:     Epoch: 27
2022-12-31 13:57:51,896 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.494027704000473, 'Total loss': 0.494027704000473} | train loss {'Reaction outcome loss': 0.3666533382282174, 'Total loss': 0.3666533382282174}
2022-12-31 13:57:51,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:51,897 INFO:     Epoch: 28
2022-12-31 13:57:53,514 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4613271693388621, 'Total loss': 0.4613271693388621} | train loss {'Reaction outcome loss': 0.355294280483023, 'Total loss': 0.355294280483023}
2022-12-31 13:57:53,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:53,514 INFO:     Epoch: 29
2022-12-31 13:57:55,128 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43787898470958075, 'Total loss': 0.43787898470958075} | train loss {'Reaction outcome loss': 0.35424214441572194, 'Total loss': 0.35424214441572194}
2022-12-31 13:57:55,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:55,128 INFO:     Epoch: 30
2022-12-31 13:57:56,741 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45422166188557944, 'Total loss': 0.45422166188557944} | train loss {'Reaction outcome loss': 0.340320724372957, 'Total loss': 0.340320724372957}
2022-12-31 13:57:56,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:56,741 INFO:     Epoch: 31
2022-12-31 13:57:58,322 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45782604316870373, 'Total loss': 0.45782604316870373} | train loss {'Reaction outcome loss': 0.3370408009437412, 'Total loss': 0.3370408009437412}
2022-12-31 13:57:58,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:58,322 INFO:     Epoch: 32
2022-12-31 13:57:59,937 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44477463165918985, 'Total loss': 0.44477463165918985} | train loss {'Reaction outcome loss': 0.331331580931821, 'Total loss': 0.331331580931821}
2022-12-31 13:57:59,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:57:59,938 INFO:     Epoch: 33
2022-12-31 13:58:01,554 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46552510261535646, 'Total loss': 0.46552510261535646} | train loss {'Reaction outcome loss': 0.3264933990686204, 'Total loss': 0.3264933990686204}
2022-12-31 13:58:01,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:01,554 INFO:     Epoch: 34
2022-12-31 13:58:03,170 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4843170315027237, 'Total loss': 0.4843170315027237} | train loss {'Reaction outcome loss': 0.31935918239363725, 'Total loss': 0.31935918239363725}
2022-12-31 13:58:03,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:03,170 INFO:     Epoch: 35
2022-12-31 13:58:04,782 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4838101734717687, 'Total loss': 0.4838101734717687} | train loss {'Reaction outcome loss': 0.33402761090816796, 'Total loss': 0.33402761090816796}
2022-12-31 13:58:04,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:04,782 INFO:     Epoch: 36
2022-12-31 13:58:06,373 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4537696123123169, 'Total loss': 0.4537696123123169} | train loss {'Reaction outcome loss': 0.3105585837898695, 'Total loss': 0.3105585837898695}
2022-12-31 13:58:06,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:06,373 INFO:     Epoch: 37
2022-12-31 13:58:07,984 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4520018845796585, 'Total loss': 0.4520018845796585} | train loss {'Reaction outcome loss': 0.3142378383950479, 'Total loss': 0.3142378383950479}
2022-12-31 13:58:07,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:07,984 INFO:     Epoch: 38
2022-12-31 13:58:09,596 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4354128271341324, 'Total loss': 0.4354128271341324} | train loss {'Reaction outcome loss': 0.31206456182754017, 'Total loss': 0.31206456182754017}
2022-12-31 13:58:09,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:09,596 INFO:     Epoch: 39
2022-12-31 13:58:11,204 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4414089620113373, 'Total loss': 0.4414089620113373} | train loss {'Reaction outcome loss': 0.2974749489997824, 'Total loss': 0.2974749489997824}
2022-12-31 13:58:11,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:11,205 INFO:     Epoch: 40
2022-12-31 13:58:12,813 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45591241916020714, 'Total loss': 0.45591241916020714} | train loss {'Reaction outcome loss': 0.29779941253903985, 'Total loss': 0.29779941253903985}
2022-12-31 13:58:12,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:12,813 INFO:     Epoch: 41
2022-12-31 13:58:14,422 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44139909942944844, 'Total loss': 0.44139909942944844} | train loss {'Reaction outcome loss': 0.2929342103906084, 'Total loss': 0.2929342103906084}
2022-12-31 13:58:14,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:14,422 INFO:     Epoch: 42
2022-12-31 13:58:16,014 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4520490884780884, 'Total loss': 0.4520490884780884} | train loss {'Reaction outcome loss': 0.2885209926593023, 'Total loss': 0.2885209926593023}
2022-12-31 13:58:16,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:16,014 INFO:     Epoch: 43
2022-12-31 13:58:17,624 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4321445693572362, 'Total loss': 0.4321445693572362} | train loss {'Reaction outcome loss': 0.2884828585762686, 'Total loss': 0.2884828585762686}
2022-12-31 13:58:17,625 INFO:     Found new best model at epoch 43
2022-12-31 13:58:17,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:17,626 INFO:     Epoch: 44
2022-12-31 13:58:19,227 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45790657798449197, 'Total loss': 0.45790657798449197} | train loss {'Reaction outcome loss': 0.2826804510605407, 'Total loss': 0.2826804510605407}
2022-12-31 13:58:19,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:19,228 INFO:     Epoch: 45
2022-12-31 13:58:20,860 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44201623896757763, 'Total loss': 0.44201623896757763} | train loss {'Reaction outcome loss': 0.2778140647012902, 'Total loss': 0.2778140647012902}
2022-12-31 13:58:20,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:20,861 INFO:     Epoch: 46
2022-12-31 13:58:22,512 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45318650007247924, 'Total loss': 0.45318650007247924} | train loss {'Reaction outcome loss': 0.2730592460649095, 'Total loss': 0.2730592460649095}
2022-12-31 13:58:22,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:22,512 INFO:     Epoch: 47
2022-12-31 13:58:24,088 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45491026937961576, 'Total loss': 0.45491026937961576} | train loss {'Reaction outcome loss': 0.272519131919936, 'Total loss': 0.272519131919936}
2022-12-31 13:58:24,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:24,089 INFO:     Epoch: 48
2022-12-31 13:58:25,680 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46247969071070355, 'Total loss': 0.46247969071070355} | train loss {'Reaction outcome loss': 0.2786455737499426, 'Total loss': 0.2786455737499426}
2022-12-31 13:58:25,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:25,680 INFO:     Epoch: 49
2022-12-31 13:58:27,291 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.429389064013958, 'Total loss': 0.429389064013958} | train loss {'Reaction outcome loss': 0.2684213415258969, 'Total loss': 0.2684213415258969}
2022-12-31 13:58:27,291 INFO:     Found new best model at epoch 49
2022-12-31 13:58:27,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:27,292 INFO:     Epoch: 50
2022-12-31 13:58:28,936 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4477857530117035, 'Total loss': 0.4477857530117035} | train loss {'Reaction outcome loss': 0.27199304743861424, 'Total loss': 0.27199304743861424}
2022-12-31 13:58:28,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:28,936 INFO:     Epoch: 51
2022-12-31 13:58:30,559 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4815393884976705, 'Total loss': 0.4815393884976705} | train loss {'Reaction outcome loss': 0.27316447835629876, 'Total loss': 0.27316447835629876}
2022-12-31 13:58:30,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:30,560 INFO:     Epoch: 52
2022-12-31 13:58:32,172 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.437578359246254, 'Total loss': 0.437578359246254} | train loss {'Reaction outcome loss': 0.258420680356369, 'Total loss': 0.258420680356369}
2022-12-31 13:58:32,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:32,173 INFO:     Epoch: 53
2022-12-31 13:58:33,763 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44574585755666096, 'Total loss': 0.44574585755666096} | train loss {'Reaction outcome loss': 0.2540602925489994, 'Total loss': 0.2540602925489994}
2022-12-31 13:58:33,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:33,763 INFO:     Epoch: 54
2022-12-31 13:58:35,361 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4530238846937815, 'Total loss': 0.4530238846937815} | train loss {'Reaction outcome loss': 0.2544526382061195, 'Total loss': 0.2544526382061195}
2022-12-31 13:58:35,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:35,361 INFO:     Epoch: 55
2022-12-31 13:58:36,971 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4293023188908895, 'Total loss': 0.4293023188908895} | train loss {'Reaction outcome loss': 0.25648284776337055, 'Total loss': 0.25648284776337055}
2022-12-31 13:58:36,972 INFO:     Found new best model at epoch 55
2022-12-31 13:58:36,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:36,973 INFO:     Epoch: 56
2022-12-31 13:58:38,586 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45060200889905294, 'Total loss': 0.45060200889905294} | train loss {'Reaction outcome loss': 0.2465743210396149, 'Total loss': 0.2465743210396149}
2022-12-31 13:58:38,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:38,586 INFO:     Epoch: 57
2022-12-31 13:58:40,243 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43890821635723115, 'Total loss': 0.43890821635723115} | train loss {'Reaction outcome loss': 0.24854339686208876, 'Total loss': 0.24854339686208876}
2022-12-31 13:58:40,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:40,244 INFO:     Epoch: 58
2022-12-31 13:58:41,893 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4610920031865438, 'Total loss': 0.4610920031865438} | train loss {'Reaction outcome loss': 0.25071374111660366, 'Total loss': 0.25071374111660366}
2022-12-31 13:58:41,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:41,894 INFO:     Epoch: 59
2022-12-31 13:58:43,488 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4552654355764389, 'Total loss': 0.4552654355764389} | train loss {'Reaction outcome loss': 0.24593817374156113, 'Total loss': 0.24593817374156113}
2022-12-31 13:58:43,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:43,488 INFO:     Epoch: 60
2022-12-31 13:58:45,102 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4425835152467092, 'Total loss': 0.4425835152467092} | train loss {'Reaction outcome loss': 0.24390597775767464, 'Total loss': 0.24390597775767464}
2022-12-31 13:58:45,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:45,102 INFO:     Epoch: 61
2022-12-31 13:58:46,733 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4170039877295494, 'Total loss': 0.4170039877295494} | train loss {'Reaction outcome loss': 0.2475970458756859, 'Total loss': 0.2475970458756859}
2022-12-31 13:58:46,733 INFO:     Found new best model at epoch 61
2022-12-31 13:58:46,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:46,734 INFO:     Epoch: 62
2022-12-31 13:58:48,346 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41647495528062184, 'Total loss': 0.41647495528062184} | train loss {'Reaction outcome loss': 0.24217915947329816, 'Total loss': 0.24217915947329816}
2022-12-31 13:58:48,346 INFO:     Found new best model at epoch 62
2022-12-31 13:58:48,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:48,347 INFO:     Epoch: 63
2022-12-31 13:58:49,959 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5071723441282908, 'Total loss': 0.5071723441282908} | train loss {'Reaction outcome loss': 0.24937261735507543, 'Total loss': 0.24937261735507543}
2022-12-31 13:58:49,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:49,959 INFO:     Epoch: 64
2022-12-31 13:58:51,556 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41562262972195946, 'Total loss': 0.41562262972195946} | train loss {'Reaction outcome loss': 0.31063054276181495, 'Total loss': 0.31063054276181495}
2022-12-31 13:58:51,556 INFO:     Found new best model at epoch 64
2022-12-31 13:58:51,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:51,557 INFO:     Epoch: 65
2022-12-31 13:58:53,177 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44311699469884236, 'Total loss': 0.44311699469884236} | train loss {'Reaction outcome loss': 0.25563820317198616, 'Total loss': 0.25563820317198616}
2022-12-31 13:58:53,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:53,179 INFO:     Epoch: 66
2022-12-31 13:58:54,805 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43027318120002744, 'Total loss': 0.43027318120002744} | train loss {'Reaction outcome loss': 0.2447210423242591, 'Total loss': 0.2447210423242591}
2022-12-31 13:58:54,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:54,805 INFO:     Epoch: 67
2022-12-31 13:58:56,438 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46178792615731556, 'Total loss': 0.46178792615731556} | train loss {'Reaction outcome loss': 0.24349833716489916, 'Total loss': 0.24349833716489916}
2022-12-31 13:58:56,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:56,439 INFO:     Epoch: 68
2022-12-31 13:58:58,048 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4132727017005285, 'Total loss': 0.4132727017005285} | train loss {'Reaction outcome loss': 0.2566525712716849, 'Total loss': 0.2566525712716849}
2022-12-31 13:58:58,048 INFO:     Found new best model at epoch 68
2022-12-31 13:58:58,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:58,049 INFO:     Epoch: 69
2022-12-31 13:58:59,687 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39151826600233713, 'Total loss': 0.39151826600233713} | train loss {'Reaction outcome loss': 0.2459446135773391, 'Total loss': 0.2459446135773391}
2022-12-31 13:58:59,687 INFO:     Found new best model at epoch 69
2022-12-31 13:58:59,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:58:59,688 INFO:     Epoch: 70
2022-12-31 13:59:01,258 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4127388705809911, 'Total loss': 0.4127388705809911} | train loss {'Reaction outcome loss': 0.26493634167464747, 'Total loss': 0.26493634167464747}
2022-12-31 13:59:01,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:01,259 INFO:     Epoch: 71
2022-12-31 13:59:02,883 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44926896393299104, 'Total loss': 0.44926896393299104} | train loss {'Reaction outcome loss': 0.2318151005199953, 'Total loss': 0.2318151005199953}
2022-12-31 13:59:02,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:02,883 INFO:     Epoch: 72
2022-12-31 13:59:04,508 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43646635363499325, 'Total loss': 0.43646635363499325} | train loss {'Reaction outcome loss': 0.23476180055012516, 'Total loss': 0.23476180055012516}
2022-12-31 13:59:04,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:04,508 INFO:     Epoch: 73
2022-12-31 13:59:06,118 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44502443075180054, 'Total loss': 0.44502443075180054} | train loss {'Reaction outcome loss': 0.23053736574555564, 'Total loss': 0.23053736574555564}
2022-12-31 13:59:06,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:06,118 INFO:     Epoch: 74
2022-12-31 13:59:07,726 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4618664135535558, 'Total loss': 0.4618664135535558} | train loss {'Reaction outcome loss': 0.22905687994553128, 'Total loss': 0.22905687994553128}
2022-12-31 13:59:07,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:07,727 INFO:     Epoch: 75
2022-12-31 13:59:09,325 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4299540708462397, 'Total loss': 0.4299540708462397} | train loss {'Reaction outcome loss': 0.22526981254887304, 'Total loss': 0.22526981254887304}
2022-12-31 13:59:09,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:09,325 INFO:     Epoch: 76
2022-12-31 13:59:10,909 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.445354296763738, 'Total loss': 0.445354296763738} | train loss {'Reaction outcome loss': 0.22279925648057597, 'Total loss': 0.22279925648057597}
2022-12-31 13:59:10,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:10,909 INFO:     Epoch: 77
2022-12-31 13:59:12,521 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45187943875789643, 'Total loss': 0.45187943875789643} | train loss {'Reaction outcome loss': 0.22584578086842658, 'Total loss': 0.22584578086842658}
2022-12-31 13:59:12,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:12,521 INFO:     Epoch: 78
2022-12-31 13:59:14,131 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4327102129658063, 'Total loss': 0.4327102129658063} | train loss {'Reaction outcome loss': 0.22613408096451854, 'Total loss': 0.22613408096451854}
2022-12-31 13:59:14,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:14,131 INFO:     Epoch: 79
2022-12-31 13:59:15,742 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42397612233956655, 'Total loss': 0.42397612233956655} | train loss {'Reaction outcome loss': 0.2228964240426728, 'Total loss': 0.2228964240426728}
2022-12-31 13:59:15,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:15,742 INFO:     Epoch: 80
2022-12-31 13:59:17,352 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41541637579600016, 'Total loss': 0.41541637579600016} | train loss {'Reaction outcome loss': 0.22351326937316934, 'Total loss': 0.22351326937316934}
2022-12-31 13:59:17,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:17,352 INFO:     Epoch: 81
2022-12-31 13:59:18,958 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4313468466202418, 'Total loss': 0.4313468466202418} | train loss {'Reaction outcome loss': 0.22140791833373732, 'Total loss': 0.22140791833373732}
2022-12-31 13:59:18,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:18,958 INFO:     Epoch: 82
2022-12-31 13:59:20,557 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40065359870592754, 'Total loss': 0.40065359870592754} | train loss {'Reaction outcome loss': 0.22216481951155415, 'Total loss': 0.22216481951155415}
2022-12-31 13:59:20,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:20,558 INFO:     Epoch: 83
2022-12-31 13:59:22,170 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.461294682820638, 'Total loss': 0.461294682820638} | train loss {'Reaction outcome loss': 0.21639568385317165, 'Total loss': 0.21639568385317165}
2022-12-31 13:59:22,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:22,170 INFO:     Epoch: 84
2022-12-31 13:59:23,784 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4509203553199768, 'Total loss': 0.4509203553199768} | train loss {'Reaction outcome loss': 0.2153206564196254, 'Total loss': 0.2153206564196254}
2022-12-31 13:59:23,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:23,785 INFO:     Epoch: 85
2022-12-31 13:59:25,399 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4334252933661143, 'Total loss': 0.4334252933661143} | train loss {'Reaction outcome loss': 0.21904182528469127, 'Total loss': 0.21904182528469127}
2022-12-31 13:59:25,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:25,399 INFO:     Epoch: 86
2022-12-31 13:59:27,015 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.455334480603536, 'Total loss': 0.455334480603536} | train loss {'Reaction outcome loss': 0.2120331277745182, 'Total loss': 0.2120331277745182}
2022-12-31 13:59:27,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:27,015 INFO:     Epoch: 87
2022-12-31 13:59:28,605 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44888162513573965, 'Total loss': 0.44888162513573965} | train loss {'Reaction outcome loss': 0.21552660683333222, 'Total loss': 0.21552660683333222}
2022-12-31 13:59:28,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:28,606 INFO:     Epoch: 88
2022-12-31 13:59:30,220 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40522353947162626, 'Total loss': 0.40522353947162626} | train loss {'Reaction outcome loss': 0.2165063750707423, 'Total loss': 0.2165063750707423}
2022-12-31 13:59:30,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:30,220 INFO:     Epoch: 89
2022-12-31 13:59:31,837 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41347138384977977, 'Total loss': 0.41347138384977977} | train loss {'Reaction outcome loss': 0.20456798554696648, 'Total loss': 0.20456798554696648}
2022-12-31 13:59:31,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:31,837 INFO:     Epoch: 90
2022-12-31 13:59:33,451 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4743650605281194, 'Total loss': 0.4743650605281194} | train loss {'Reaction outcome loss': 0.20980253220034722, 'Total loss': 0.20980253220034722}
2022-12-31 13:59:33,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:33,451 INFO:     Epoch: 91
2022-12-31 13:59:35,066 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3951605995496114, 'Total loss': 0.3951605995496114} | train loss {'Reaction outcome loss': 0.21129974773941576, 'Total loss': 0.21129974773941576}
2022-12-31 13:59:35,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:35,067 INFO:     Epoch: 92
2022-12-31 13:59:36,663 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4219127044081688, 'Total loss': 0.4219127044081688} | train loss {'Reaction outcome loss': 0.20521876035817896, 'Total loss': 0.20521876035817896}
2022-12-31 13:59:36,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:36,663 INFO:     Epoch: 93
2022-12-31 13:59:38,261 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42066568036874136, 'Total loss': 0.42066568036874136} | train loss {'Reaction outcome loss': 0.205965978241917, 'Total loss': 0.205965978241917}
2022-12-31 13:59:38,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:38,261 INFO:     Epoch: 94
2022-12-31 13:59:39,877 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4305574377377828, 'Total loss': 0.4305574377377828} | train loss {'Reaction outcome loss': 0.29087305413090886, 'Total loss': 0.29087305413090886}
2022-12-31 13:59:39,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:39,877 INFO:     Epoch: 95
2022-12-31 13:59:41,503 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4097478101650874, 'Total loss': 0.4097478101650874} | train loss {'Reaction outcome loss': 0.21914679379172056, 'Total loss': 0.21914679379172056}
2022-12-31 13:59:41,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:41,504 INFO:     Epoch: 96
2022-12-31 13:59:43,118 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4323543056845665, 'Total loss': 0.4323543056845665} | train loss {'Reaction outcome loss': 0.2103967765665468, 'Total loss': 0.2103967765665468}
2022-12-31 13:59:43,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:43,118 INFO:     Epoch: 97
2022-12-31 13:59:44,728 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47169166803359985, 'Total loss': 0.47169166803359985} | train loss {'Reaction outcome loss': 0.21633476050624598, 'Total loss': 0.21633476050624598}
2022-12-31 13:59:44,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:44,728 INFO:     Epoch: 98
2022-12-31 13:59:46,326 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4394615968068441, 'Total loss': 0.4394615968068441} | train loss {'Reaction outcome loss': 0.3643218566017374, 'Total loss': 0.3643218566017374}
2022-12-31 13:59:46,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:46,326 INFO:     Epoch: 99
2022-12-31 13:59:47,971 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43275314569473267, 'Total loss': 0.43275314569473267} | train loss {'Reaction outcome loss': 0.24420541359506842, 'Total loss': 0.24420541359506842}
2022-12-31 13:59:47,972 INFO:     Best model found after epoch 70 of 100.
2022-12-31 13:59:47,972 INFO:   Done with stage: TRAINING
2022-12-31 13:59:47,972 INFO:   Starting stage: EVALUATION
2022-12-31 13:59:48,100 INFO:   Done with stage: EVALUATION
2022-12-31 13:59:48,100 INFO: Done with stage: RUNNING SPLITS
2022-12-31 13:59:48,100 INFO: Starting stage: COMPUTE METRICS
2022-12-31 13:59:49,264 INFO: Done with stage: COMPUTE METRICS
2022-12-31 13:59:49,264 INFO: Starting stage: EXPORT RESULTS
2022-12-31 13:59:49,281 INFO:   Final results averaged over 50 folds: 
2022-12-31 13:59:49,285 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.185047           NaN  0.339782       NaN
2022-12-31 13:59:50,822 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-31 13:59:50,828 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-31 13:59:50,829 DEBUG:   interactive is False
2022-12-31 13:59:50,829 DEBUG:   platform is linux
2022-12-31 13:59:50,829 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-31 13:59:51,003 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-31 13:59:51,005 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-31 13:59:51,433 DEBUG:   Loaded backend agg version unknown.
2022-12-31 13:59:51,435 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 13:59:51,435 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,435 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,435 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,435 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,436 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,437 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,438 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 13:59:51,438 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,438 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,438 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,438 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 13:59:51,438 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,438 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 13:59:51,474 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,475 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,476 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 13:59:51,477 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,477 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 13:59:51,486 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,486 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,487 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 13:59:51,488 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 13:59:51,488 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 13:59:51,767 INFO: Done with stage: EXPORT RESULTS
2022-12-31 13:59:51,767 INFO: Starting stage: SAVE MODEL
2022-12-31 13:59:51,823 INFO: Done with stage: SAVE MODEL
2022-12-31 13:59:51,823 INFO: Wall time for program:  8075.62 seconds
